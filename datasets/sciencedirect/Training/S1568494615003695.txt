@&#MAIN-TITLE@&#
A clustering-ranking method for many-objective optimization

@&#HIGHLIGHTS@&#
A new strategy that consists of clustering and ranking is proposed.The procedure of clustering can maintain the diversity.The convergence relies on the ranking mechanism.The incorporation of two procedures led to a better result.

@&#KEYPHRASES@&#
Many-objective optimization,Clustering,Diversity,Ranking,Convergence,

@&#ABSTRACT@&#
In evolutionary multi-objective optimization, balancing convergence and diversity remains a challenge and especially for many-objective (three or more objectives) optimization problems (MaOPs). To improve convergence and diversity for MaOPs, we propose a new approach: clustering-ranking evolutionary algorithm (crEA), where the two procedures (clustering and ranking) are implemented sequentially. Clustering incorporates the recently proposed non-dominated sorting genetic algorithm III (NSGA-III), using a series of reference lines as the cluster centroid. The solutions are ranked according to the fitness value, which is considered to be the degree of closeness to the true Pareto front. An environmental selection operation is performed on every cluster to promote both convergence and diversity. The proposed algorithm has been tested extensively on nine widely used benchmark problems from the walking fish group (WFG) as well as combinatorial travelling salesman problem (TSP). An extensive comparison with six state-of-the-art algorithms indicates that the proposed crEA is capable of finding a better approximated and distributed solution set.

@&#INTRODUCTION@&#
Many-objective optimization problems (MaOPs) have attracted great attention in the last few decades, due to the large number of real-world applications that have many objectives [1]. In particular, there are many industrial and engineering design problems that require more than three objectives to be maximized or minimized. For example, there are control system design problems with 4–10 objectives [2], and software engineering problems with up to 15 objectives [3].It is commonly accepted that, compared with multi-objective optimization problems (MOPs), MaOPs refer to problems with high-dimensional objectives (in general more than three) [4]. However, they both aim to find a set of Pareto optimal solutions, which are defined as the best trade-off among objectives. When plotted in the objective space, the set of all the Pareto optimal solutions is referred to as the Pareto front (PF).Evolutionary algorithms (EAs) are well suited for MOPs, due to their population based strategy for achieving an approximation to the PF. In general, EAs achieve a Pareto approximation set in MOPs via pursing two goals – approximating the whole PF and maximizing the diversity of solutions. Fundamentally, the balance between convergence and diversity in EAs depends on the selection operator used by the multi-objective evolutionary algorithm (MOEA). There is a significant interest in expending MOEA into MaOPs. These methods can be broadly classified by their selection strategies into three categories: dominance, indicator, and decomposition-based MOEAs [5].Dominance-based algorithms, such as non-dominated sorting genetic algorithm II (NSGA-II) [6], strength Pareto evolutionary algorithm 2 (SPEA2) [7] and Pareto envelope based selection algorithm II (PESA-II) [8], are very effective for low dimensional objectives[48], but lose performance on MaOPs [9]. As empirically shown in the existing literature [1,10,11], the non-dominated objective vectors in each population become very large and most individuals become non-dominated. Thus, these algorithms fail to generate sufficient selection pressure to drive solutions towards the PF. To overcome the drawbacks of Pareto dominance based MOEAs and make the approach suitable for MaOPs, two new methods are introduced: (1) new preference relations; (2) new diversity promotion mechanisms.To derive new preference relations, it is natural to utilize other preference relations to tackle the challenge of too many non-dominated solutions. Some efforts in this direction have been attempted, such as preference order ranking [12], ϵ-dominance [13], fuzzy Pareto dominance [14] and grid dominance [15]. The underlying concept of these methods is to utilize a relaxed form of non-dominated relationship to increase the selective pressure towards the PF, and where possible simultaneously improve the diversity of the obtained solutions. Although existing work depends on several sensitive parameters (e.g. the relaxed parameter ϵ in ϵ-dominance [5]), they can provide some new alternatives for MaOPs.To develop new diversity mechanisms, control strategies are implemented to ensure that the obtained solutions spread through the entire PF uniformly [16]. Several efforts have been made to incorporate this approach. SPEA2 combines strength values with the kth nearest neighbour method to distinguish individuals in the population [7]. It can emphasize the diversity, but the acquired solutions may be distant from the true PF. The grid based diversity maintenance mechanism (hyperbox) is utilized in PESA-II at the mating and environmental selection step [8]. Li et al. proposed a new density estimation method [17], in which a simple shift-based density estimation strategy was used to modify and improve the performance of the NSGA-II, SPEA2, and PESA-II with varying degrees of success. Recently, NSGA-III [18], which uses the process of reference line generation, was proposed. The crowding distance operator from NSGA-II is replaced by a clustering operator, which associates population members with fixed clustering centroids (reference lines). This is a very promising alternative for MaOPs.For decomposition-based methods, a series of easily described and well scaled single-objective problems are utilized in place of an m-objective optimization. The core concept is to decompose the MOP into a series of scalar objective optimization problems [19], based on conventional aggregation approaches. The most typical method is the multi-objective evolutionary algorithm based on decomposition (MOEA/D) [20,21]. It has not only has a high search ability for continuous optimization, but also performs well on problems with complex Pareto sets [10]. MOEA/D can also be considered an aggregation based algorithm since the MOP objectives in MOEA/D are aggregated by a scaling function [17]. Recently, a number of improved versions of MOEA/D have been suggested, mainly focusing on neighbourhood structures [22,23], self-adaptation mechanisms [22], and parallelism.The indicator-based approach introduces a single indicator as an evaluation of performance to guide the process of evolution, which is equivalent to finding the Pareto optimal set [24]. The core concept was originally from Zizler's indicator based evolutionary algorithm (IBEA) [25]. Other attempts based on this concept include the S metric selection evolutionary multi-objective algorithm (SMS-EMOA) [26] and multi-objective covariance matrix adaptation evolution strategy (MO-CMA-ES) [27]. Despite its advantages and clear theoretical properties, the computational cost increases considerably with increasing number of objectives. To relieve computational complexity, other related methods have been proposed. Some included the use of more efficient ways [28] to speed up this process [29], while others attempt to introduce new performance indicators, e.g. R2 method [30,31], promoting the performance of MOEAs.The core concept underlying these algorithms is to balance the convergence and diversity in the whole process of EAs. The algorithms try to select solutions which are closer to the true PF and have a high diversity among each other. Based on this principle and inspired by NSGA-III and decomposition based MOEAs, we introduce two operators. One is a clustering operator takeing advantage of the diversity promotion mechanism used in NSGA-III, while the second is a ranking scheme to push the population towards the true PF. To balance those two aspects of performance, we propose a new selection process that incorporates the clustering and iteratively selects a suitable solution via the ranking metric. The performance of this method is compared with six state-of-the-art algorithms on a series of test problems.The background of our research, including related work and motivation, is presented in Section 2. In Section 3, we present the details of the proposed algorithm. In Section 4, we describe the experimental design to compare the proposed algorithm with peer methods. The comparison results and discussions are in Section 5. Finally, in Section 6 we make our conclusions about the proposed algorithm.The basic purpose of MaOPs is to optimize a problem with m objective functions F(x)=(f1(x), f2(x), …, fm(x)), where x∈Ω is the decision space, and x=(x1, …, xn)Tis a candidate solution;F:Ω→ℝmconsists of m objective functions, which is a mapping from n-dimensional decision space Ω to objective spaceℝm. The dominance relation is defined by x≺y,x≺y:⇔∀i∈(1,…,m):fi(x)≤fi(y);∃j∈(1,…,m):fj(x)<fj(y).A decision vector, x*∈Ω, is Pareto optimal if there is no x∈Ω such that x≺x*. The set of all Pareto optimal points is called a Pareto Set (PS) and the Pareto front (PF) is defined as{f(x)∈ℝm|x∈PS}. For reference-based algorithms, the ideal point z* is defined as a vectorz*=(z1*,…,zm*)T, i.e.,∀i∈(1,…,m),zi*=inf({fi(x)|x∈Ω}).As identified earlier, the main task of many-objective optimization can be divided into two aspects: (1) maximize the diversity of the generated solutions, and (2) minimize the distance from solutions to the PF.Diversity promotion is important to MOEAs to ensure a good approximation to the Pareto optimal solutions. The crowding distance, which serves as a summation of objective-wise distance among population, is adopted in the last accepted non-dominated level in NSGA-II [6] for diversity enhancing. The cluster analysis operator, first applied by Morse [32], reduces the number of non-dominated solutions, and can also be considered as a diversity maintenance mechanism. Following Morse's work, SPEA [33] can be regarded as the most successful algorithm to reduce the PS using clustering. In the environmental selection of SPEA, when the number of solutions in an archive set is excessive, cluster analysis partitions m elements in the archive set into pre-defined number of groups, n, via the average linkage method [32], and excludes the further archived members. In principle, the clustering technique used in SPEA implements a truncation method as well as ensuring diversity. However, this kind of clustering based method has been replaced by nearest neighbour density estimation in SPEA2 [7] since it is not strongly elite preserving and can be very time consuming. Although SPEA performs unsatisfactorily due to computing complexity, it does indicate that clustering based methods may be an outstanding way to promote diversity.NSGA-III [18] has been recently proposed, partly utilizing the clustering mechanism. Compared with the original NSGA-II [6], NSGA-III has significant modification in the selection mechanism, especially the maintenance of diversity. The main procedure of NSGA-III is described as follows.Suppose the size of the parent population, Pt, is N. Initially, a series of reference points are generated by a systematic approach [34]. Thereafter, similar to NSGA-II, the offspring population, Qt, will be produced from Ptwith some operations, including random selection, simulated binary crossover (SBX), and polynomial mutation [35]. A selection mechanism is employed in the combined population Rt=Pt∪Qtto exclude the extra solutions. Specifically, Rtis firstly sorted by the method of fast-non-dominated sorting, and then categorized into different non-dominated levels(F0,F1,…,Fl). The new population Pt+1 is constructed by selecting individuals fromF0toFl, until |Pt+1|=N. It is worth noting that not all the individuals would be selected into Pt+1 due to |Pt∪Qt|=2N. To further eliminate the extra solutions, another selection mechanism is also introduced. In NSGA-II, crowding distance was used to maintain a distribution, and the solutions with larger crowding distance values have a higher priority to be chosen. In contrast, NSGA-III replaces the crowding distance operator by a clustering-like operator. Before that, the objectives and the previous supplied reference points are first normalized so that they can have an identical range. A perpendicular distance is calculated between every normalized solution and a reference line. This distance, which can be considered as a metric for similarity, is utilized to associate each member in population Pt+1 with a reference line.A niche-preservation operation is applied for incremental selection and operates on the individuals from(Pt+1∖Fl). To summarize this procedure, ρjis defined as the niche count for the jth reference point, and μjis the number of members in the front,Fl, already associated with the reference point j. The niche preservation starts from finding the reference point setJmin={j:argminjρj}with minimum ρj, and onej¯∈Jminis randomly chosen. The details of the procedure are shown below.•Ifρj¯=0, then there is no correspond Rtmember associated with the reference pointj¯. This situation can be divided into two cases:–Ifμj¯≠0, the member with the shortest perpendicular distance from the reference line is added to Pt+1. The count ofρj¯is then increased by one.ifμj¯=0, the current reference point is filtered.Ifρj¯≥1, then there is more than one member associated with the reference point inPt+1∖Fl. In that case, a randomly chosen member fromFlthat is associated with the \bar{j}-th reference point is added to Pt+1, and then the count ofρj¯also needs increasing by one.Critically, the selection mechanism depends on some points on a hyper-plane. The reference line, which is joins from the origin to each of these reference points, serves as the centroid of clustering. This clustering scheme not only has satisfactory diversity in objective space, but also has relatively low computing complexity. The worse-case complexity in one generation is O(N2logm−1N) or O(mN2) [18].Since the set of uniformly distributed reference points are able to naturally maintain the diversity, it is also employed in our proposed algorithm, but without the niching procedure. The predefined reference weights are reused to maintain convergence. The convergence mechanism of our algorithm arises largely from MOEA/D, which decomposes a MOP into N scalar optimization sub-problems simultaneously (where N is the size of the population). Thus, the whole PF is transformed into a series of scalar optimization problems [20]. The Tchebycheff function, as a weighted aggregation function, is defined in advance and a MOP can be decomposed into N sub-problems as follows:(1)gte(x|w,z*)=maxi=1m{wi|fi(x)−zi*|},wherez*=(z1*,z2*,…,zm*)is the ideal point, andw=(w1,w2,…,wm)Tis the weight vector. This forces sub-problems with similar weight vectors to have optimal solutions close to each other. In MOEA/D, the replacement mechanism is critical to the whole algorithm. For each neighbouring solution, xuis replaced by an offspring, y only if gte(y|wu, z*)<gte(xu|wu, z*). Eq. (1) indicates the ability of convergence. Since the optimal solution to Eq. (1) is a Pareto optimal solution to the MOP [36,37], MOEA/D has a strong ability to enhance the selection pressure towards PF.MOEA/D's diversity mechanism depends on the nature of its sub-problems, but is too weak to maintain diversity compared with MOEA/D's convergence ability. The clustering mechanism would enhance the diversity of solutions, but Pareto dominance may not strengthen the selection pressure towards the true PF. An ideal way to deal with MaOPs would be to maintain convergence and diversity simultaneously. Motivated by the clustering mechanism and strong convergence ability of MOEA/D, we propose a clustering-ranking evolutionary algorithm (crEA) for MaOPs, which attempts to balance diversity and convergence in every generation.The framework of the proposed algorithm is summarized in Algorithm 1. The reference pointsΛ={λ1,λ2, …,λN}, which are regarded as the preparation for clustering, need to be initialized. Then, following the basic procedure of EAs, the initial population, P0, with N individuals is generated. The ideal point z*, which is necessary for normalization, is updated in step 3. Steps 5–10 show the main evolution procedure for iterative optimization. In steps 6 and 7, the conventional method of recombination and mutation are introduced on the individuals to produce N members, which are considered the input for the UpdateIdealPoint in step 9. We then normalize all 2N individuals via AdptiveNormalize in step 10. Clustering is used to split Rtinto NcclustersCˆ={C1,C2,…,CNc}(Step 11). Ranking is then employed to classify Rtinto different layersFˆ={F1,F2,…,FNf}. Finally, after all the solutions in Rthave been assigned to different layers, the selection operator is employed to select N new individuals for the next generation.Algorithm 1The framework of proposed algorithmRequire:H (The number of divisions)1:Λ←ReferencePoints(H)2: P0←InitializePopulation()3: z*←InitializeIdealPoint(P0)4: t←15: whiletermination criterion not fulfilled do6:  Pt←Recombination(P0)7:  Qt←Mutation(Pt)8:  Rt←Pt∪Qt9:  z*←UpdateIdealPoint(Qt)10:  Rt←AdptiveNormalize(Rt, z*)11:(Cˆ,Nf)←clustering(Rt,Λ)12:Fˆ←ranking(Cˆ,Nf)13:Pt+1←selection(Fˆ)14:  t←t+115: end whileTo emphasize the diversity of the obtained solutions, a cluster operator is employed. A structured set of reference points need to be generated. The basic requirement is to create a set of uniformly distributed units in the objective space. In this work, Das's method is adopted [34], with a user-defined integer H which controls the divisions along each axis.(2)∑i=1mxi=H,xi∈ℕGeometrically, the formulation could be considered as a hyper-plane in m-dimensional space. The total number of such vectors isN=CH+m−1m−1, sincexi∈ℕ. Finally, the evenly distributed reference points,λ, are generated according to(3)λk=xkH,k=1,2,3…,mThe predefined reference points are generated in the normalized hyperplane ensuring∑i=1mfi=1. Taking the three-dimension problem as an example, there areC52=10reference points on a triangle if H=3. Fig. 1illustrates the reference points for H=3, and the details of generator is summarized in Algorithm 2.Algorithm 2Reference point generatorRequire:H (The number of divisions)1:Nr←CH+m−1m−12:{λ1,λ2,…,λNr}←{∅,∅,…,∅}3: fori=1:Nrdo4:   forj=1:mdo5:λi[j]←ReferenceGenerator(j) // Refer to Eq. (3)6:   end for7: end forNormalization would be beneficial to enhance the robustness of the algorithm, especially for scaled optimization problems [18,20]. In NSGA-III, normalization is based on the extreme point in each objective axis. However, in practice, the calculation of the hyper-plane relies on solving a linear system of equations [18], which is computational expensive. We simplify this procedure using a common method of normalization. For a solution x, the normalized objective value is defined as(4)f˜j(x)=fj(x)−zj*zjmax−zj*j=1,2,…,m,wherezjmaxis the maximum value for every objective fjin the population. Given the current population, Pt, and an ideal point, z*, we first initialize the maximum vectorzmax=(z1max,z2max,…,zmmax), then obtain the normalized objective valuef˜jusing z*, zmax, and fj(x). Algorithm 3 shows the pseudocode for normalization.Algorithm 3Adaptive normalizationRequire:Rt(The current population), z* (The ideal point), m (The number of objective function)1: zmax←{−∞,−∞, …,−∞}2: for each solution x in Rtdo3:  forj=1:mdo4:      iffj(x)>zjmaxthen5:zimax←fj(x)6:    end if7:  end for8: end for9: foreach solution x in Rtdo10:   forj=1:mdo11:f˜j(x)←Normalize(fj(x),zjmax,zj*)//Refer to Eq. (4)12:   end for13: end forThe implementation of our proposed algorithm consists of two main operators: clustering and ranking, which are implemented sequentially for diversity and convergence. In terms of clustering, after some naturally differentλhave been initialized, we need to associate every solution on Rtwith a reference line.Algorithm 4Clustering operatorRequire:Rt(The current population), Λ (The reference points set)1: Nc←|Λ|, Nf←02:{C1,C2,…,CNc}←(∅,∅,…,∅)3: foreach solution x in Rtdo4:  index←05:  dmin←+∞6:  n←17:  forj=1:|Λ| do8:d←ComputeDistance(f˜(x),λj)//Refer to Eq. (6)9:     ifd<dminthen10:      dmin←d11:      index←j12:    end if13:  end for14:  Cindex←Cindex∪{x}15:  ifNf<|Cindex| then16:    Nf←|Cindex|17:  end if18: end forLet us consider the perpendicular distance. For clustering, the perpendicular distance, dr,2(x), is defined in Eq. (5) to evaluate the similarity. Suppose thatf˜(x)=(f1˜(x),f2˜(x),…,fm˜(x))Tis the normalized objective vector, then(5)dr,2=f˜(x)−dr,1(x)λi||λi||,where dr,1(x) is the distance between origin and the projection point, p; anddr,1(x)=||f˜(x)·λi||/||λi||. The illustration of this distance is shown in Fig. 2.The final distance for clustering is computed from Eq. (6). The ith solution with minimum distance to the jth reference line can be categorized to the cluster Cj. Algorithm 4 summarizes the main procedure of clustering. Each solution in the current population can be associated with a certain reference line.Taking Fig. 3as an example, the distances between solution E and two reference lines aredλ1,2E=0.0894anddλ2,2E=0.4919. Solution E should associate withλ1sincedλ1,2E<dλ2,2E. Similarly, we can assign solution A and B to the referenceλ1with the minimum dr,2 value (dλ1,2A=dλ1,2B=0.0894,dλ2,2A=0.5814, anddλ2,2B=0.3578).(6)dr,2=f˜(x)−λi||f˜(x)·λi||∥λi∥2The second procedure is to rank the solutions in every cluster to promote convergence. As we mentioned above, the fitness value for ranking comes from the aggregation function, which is defined as Eq. (7).Algorithm 5Ranking operatorRequire:{C1,C2,…,CNc}(The clustered solutions), Nf(The number of layers)1:{F1,F2,…,FNf}←{∅,∅,…,∅}2: fori=1:Ncdo3:  forj=1:|Ci| do4:τi←τi∪fitness(Ci[j],λi) // Refer to Eq. (7)5:  end for6:  Ci←AscendingSort(Ci,τi)7: end for8: fori=1:Nfdo9:  forj=1:Ncdo10:Fj←Fj∪Cj[i]11:   end for12: end for(7)FT(x)=maxk=1m1λk(f˜k(x))Lower values of FT(x) tend to have a high probability to approximate true PF. Geometrically, this metric can serve as a contour line along with the reference vector. To better understand this value, consider the example in Fig. 3. For individuals A and B, their fitness areFTA=max0.30.5,0.81=0.8,andFTB=max0.40.5,0.61=0.8,respectively, and so FTA=FTB. Moreover the fitness value for individual E isFTE=max0.50.5,0.81=1.As shown in Fig. 3, with the same fitness value, the solution A and B are located at same contour line along withλ1(the second blue dashed line in Fig. 3). The contour of solution A and B are closer to the true PF compared with the contour of solution E (the third blue dashed line).In practical use, FT(x) is regarded as a criterion to rank the solutions in each cluster. We first arrange the current solutions in the cluster to different layers using the ranking operator, which sorts the solutions in ascending order by their fitness. After the first iterative ranking step, the first layer of solutions,F1, is composed of individuals with the lowest fitness in the cluster Ci. Then, the ranking operator continues to construct the next layer in each cluster, and the solution with next-lowest fitness will be labelled with theF2. The main processes of fitness calculation and ranking are shown in Algorithm 5.Algorithm 6Selection operatorRequire:{F1,F2,…,FNf}1: Pt+1←∅2: fori=1:Nfdo3:   if|Fi|=min(|Fi|,(N−|Pt+1|)then4:Pt+1←Pt+1∪Fi5:  else6:Shuffle(Fi)7:Pt+1←Pt+1∪Fi[1:(N−|Pt+1|)]8:  end if9: end forFinally, the selection operator is introduced to the solution set. In principle, solutions from lower levels of a ranked set and located at different clusters are preferred choices. In other words, the selection procedure is operated fromF1to higher levels until the number of selected solutions equals the population size (i.e., |Pt+1|=Nc). Algorithm 6 describes the main steps of the selection operator. It is worth noting that, in the last accepted level, the order of solutions need to be shuffled (step 6 in Algorithm 6), which means that if we need to select the rest of solutions in the last accepted level, we may just pick them randomly.To better understand the selection operator, considering the 2-objective minimization instance in Fig. 4as an example. There are six individuals in the objective space. The distance between every individual solution's position and reference line is calculated by Eq. (6). After comparison, solutions a, b, and c are assigned to one cluster C1={a, b, c}, whereas d, e, and f are categorized to another cluster C2={d, e, f}. Fitness is computed for every individual, and sorted (ascending) in each cluster. Based on the fitness, a and d are assigned to layerF1; layerF2contains the individuals b and e; and c and f belong to layerF3. After the cooperation of clustering and ranking, solutions labelled with lower layer and divergent clusters will have high convergence as well as diversity. Following the first iterative selection, individuals a and d are selected into the archive set. The procedure of selection continues until |Pt+1|=N.We analyse the computational complexity of the proposed algorithm, taking an MOP with m objectives and the algorithm with N individuals as an example. From Algorithm 1, the generic operators in steps 6–8 require O(nN) computations. The updating of ideal points (step 9) requires O(mN) computations. The normalization of the population (Step 10) requires O(mN) computations. The clustering and ranking procedures, which are regarded as the key operators for our proposed method, require O(mN2) and O(N2) computations, respectively. Thus, the total complexity of our proposed crEA approximates to O(mN2), which is the same as that of MOEA/D [20].

@&#CONCLUSIONS@&#
