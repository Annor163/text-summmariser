@&#MAIN-TITLE@&#
Ensemble artificial neural networks applied to predict the key risk factors of hip bone fracture for elders

@&#HIGHLIGHTS@&#
We applied Ensemble ANNs model to predict hip bone fracture risk for both male and female elders.Binary coding genetic algorithm was used to code the raw data.We identified the top 10 risk factors for hip fractures from 74 risk factors.The accuracy of the ANN prediction model is very high.

@&#KEYPHRASES@&#
Ensemble artificial neural networks,Back-propagation neural networks,Sensitivity analysis,Connection weights,Hip fracture,

@&#ABSTRACT@&#
Hip bone fracture is one of the most important causes of morbidity and mortality in the elder adults. It is necessary to establish a prediction model to provide suggestions for elders. A total of 725 subjects were involved, including 228 patients with first low-trauma hip fracture and 497 ages-, sex-, and living area-matched controls (215 from the same hospital and 282 from community). All the subjects were interviewed with the same questionnaire, and the answers of the interviewees were recorded to the database. Three-layer back-propagation Artificial Neural Networks (ANN) models were applied for females and males separately in this study to predict the risk of hip bone fracture for elders. Furthermore, to improve the accuracies and the generalizations of the models, the ensemble ANNs method was applied. To understand variables contributions and find the important variables for predicting hip fracture, sensitivity analysis and connection weights approach were applied. In this study, three ANNs prediction models were tested with different architectures. With the fivefold cross-validation method evaluating the performances, one of the three models turned out to be the best prediction model and achieved a big success of prediction. The best area under the receiver operating characteristic (ROC) curve and the accuracy of the prediction model are 0.91±0.028 (mean±SD) and 0.85±0.029 for females, while for males are 0.99±0.015 and 0.93±0.020. With the method of sensitivity analysis and connection weights, input variables were ranked according to contributions/importance, and the top 10 variables show great proportion of contribution to predict hip fracture. The top 10 important variables causing hip fracture for both females and males are similar to our previous results got from logistic regression model and other related researches. In conclusion, ANNs has successfully been used to establish prediction models for predicting the risk of hip bone fracture for both female and male elder adults respectively and identified the top 10 important variables from 74 input variables to predict hip bone fracture of elders. This study verified the performance of ANNs to be a highly efficient prediction model.

@&#INTRODUCTION@&#
Hip fracture is a kind of serious injury for elders. Previous studies have shown that elder adults with hip bone fracture have a relatively higher risk of death [1,2]. The post-fracture one-year mortality rates for the elders with hip fracture are 18–33% [3]. Even if the patients survive after the fracture, some of them still suffer functional loss in daily activities [4]. Moreover, the elders with hip fracture and their family need to shoulder much higher health care costs compared with their matched controls [5]. Therefore, hip fracture is not only a considerable health burden but also an increasing economic burden.To reduce the incidence of this preventable injury and subsequent adverse outcomes, many studies have identified the risk factors for hip fracture [6,7,8]. Bone mineral density is considered to be the standard measure for the diagnosis of osteoporosis and the assessment of fracture risk [9]. Over the last decades, bone density testing has become widespread; yet the hope for a simple, straight predictor of fracture has faded. It is realized that the answer lies not in any single factor like bone density, but rather in assessment of multiple risk factors. Further, the operative risk factors may vary somewhat by populations/ethnicity studied. It is assumed that multi-variable risk assessments are indeed the tools of the future, and bone strength is determined by many factors, not just bone density; therefore many factors contribute to bone weakness. Recently, a matched case-control study carried out a conditional logistic regression to find out the important risk factors with the combined effects of different risk factors [10]. Artificial neural networks (ANNS) are another analysis method suitable for biomedical systems. According to the advantages of nonlinearity, fault tolerance, universality, and real-time operation, ANNs have been proposed as a quite suitable algorithm for modeling complex non-linear relationships in health care research [11,12,13]. Eller-Vainicher et al. [14] identified the promising role of ANN in predicting osteoporotic fracture among postmenopause osteoporosis women. For the comparison of the characteristics between ANNs and logistic regression applied to this epidemiological research field, a study has established prediction models for predicting living setting after hip fracture by ANNs and logistic regression, and shown that ANN is slightly better than logistic regression [15]. Lin et al. found ANN algorithm could reliably predict the mortality of hip fractured patients and outperforms the logistic regression method [16]. Although in many studies ANNs have been shown to exhibit superior predictive power compared to traditional approaches [17,18], they have also been labeled a “black box” because they provide little explanatory insight into the relative influence of the independent variables in the prediction process. This lack of explanatory power is a major concern to researchers since the interpretation of statistical models is desirable for gaining knowledge of the causal relationships. Besides, the significant ranking of each input is very important for the neural network operation. To “illuminate” the “black box”, Olden et al. [19] introduced nine methods for quantifying variable importance in artificial neural networks, of which, sensitivity analysis is a generally used method. The sensitivity analysis methodology is able to show the specific contribution of the input variables while ANN has the capability to handle non-linear, complex ecological data and to incorporate causality [20,21]. Hence, the present study had two primary goals. The first goal was to establish ANNs prediction models to predict the risk of hip fracture for female and male elder adults respectively, and examine them via the ROC curve analysis. With this ANNs models, the second goal of this paper was to use the methods of sensitivity analysis and connection weights to understand the contribution of each input variable and identify the top 10 important variables for predicting hip fracture. These top 10 important variables were also compared with the most influential variables got from conventional logistic regression method [10,22].The data used in this study was collected in the previous case-control matched study for the analysis of risk factors of hip fracture for elder adults aged 60 and older [10]. The data was collected using questionnaire surveys gathered by trained interviewers. The database included a total of 725 subjects, of which, 228 subjects were the patients admitted to the National Taiwan University Hospital with first low-trauma hip fracture, 215 subjects were hospital controls (patients in the same hospital but without hip fracture) and 282 subjects were community controls (randomly selected dwellers) individually matched to the hip fracture patients by age, gender, and living area, and then two control groups were combined together as 497 controls. Since women may have some risk factors different from men, such as reproductive history, etc, female and male models were developed separately, so the data was separated by gender. Of the total 725 subjects, 163 hip fracture patients and 345 controls were women, and 65 hip fracture patients and 152 controls were men. Moreover, in Lan's study [10], they used intraclass correlation coefficient to examine the reliability of the sample data. As a result, the moderate to high agreement suggested that the data was reliable.There are many types of ANNs with different structures. Typical back-propagation neural networks (BPNN) are commonly adopted for solving classification problems. BPNN include an input layer, a hidden layer (or several hidden layers), and an output layer. Each layer contains at least 1 node (neuron). Activation functions (transfer functions) only exist in the hidden nodes and output nodes, and only the inputs for hidden nodes and output nodes will be processed via weights and biases. Typically, the data for ANNs analysis consists of possible inputs and the corresponding targets, and are divided into three parts: training datasets for training models, validation datasets for checking the over-fitting of models, and testing datasets for testing the generalization of models. Avoiding over-fitting is very important to make sure an ANN model can be generalized. Another method for improving the generalization of an ANN model is ensemble ANNs method [23,24]. The learning effect of an ANN is decided by random initial weights. The training process of ANNs is an optimization processing of the connections (i.e., weights and biases) between neurons in different layers. Therefore, different initial points (i.e., initial weights and biases) will lead to different optimization results. The idea of the ensemble method is to train a finite number of component neural networks and then combine the component outputs to reduce the errors come from different initial weights and biases [25,26].Hence, the BPNN and ensemble method were applied in this study. Lan et al. [10] and Tseng et al. [22] did an in-depth analysis of risk factors for hip fracture in elder adults. For comparing to Lan et al. [10] and Tseng et al. [22], a total of 74 risk factors of hip bone fracture were selected to be the inputs for the female BPNN models. The 74 risk factors are listed in Table 1. Excluding 7 factors related to female's reproductive history, 67 of above factors were chosen to be the inputs for male BPNN models. Both female and male models have 1 hidden layer and 1 binary output (hip-fractured defined as 1versus non-hip-fractured as 0). The suitable number of hidden neurons (NHN) depends on many conditions, like the number of inputs and outputs (NINPand NOUT), the amount of noise in the targets, the complexity of the function, regularization, etc. [27]. It is usually necessary to train several networks and estimate the generalization error of each network to find out the suitable hidden layer size. In general, it is essential to employ lots of hidden neurons to avoid overfitting with the use of early stopping method, or it will likely be underfitting [28]. Hence NHNis set to be about twice the NINP(i.e., 140 nodes in hidden layer) at first, and got good generalized prediction results. NHN=140 was set for both female prediction models and male prediction models, since a proportionally small change in NHNwill not lead to an obvious effect on the performance. However, some literatures proposed rules to relate NHNto NINP, NOUT, or number of training patterns [29]. A rule of defining NHN=(NINP+NOUT)/2 was selected to be compared with the result of setting NHN=140 for checking whether the result can be better. The inputs and outputs were normalized into a range between −1 and 1. The activation function of hidden neurons is a tangent sigmoid transfer function, which is defined by:(1)fa=ex−e−xex+e−xwhere fais the output of tangent sigmoid function and x is the input of tangent sigmoid function.The output of a tangent sigmoid function is limited to a range between −1 and 1 for the normalized output −1 and 1 (0 is normalized to −1 and 1 is 1). The activation function of output neurons is a simple linear transfer function.In this study, many risk factors were chosen to be the inputs for the prediction models. If NHNis too large, the size of weights and biases in the networks will be huge, which will cost lots of memory to do the computation and decrease the efficiency. Therefore, for reducing the required memory and obtaining better efficiency, conjugate-gradient algorithms [30] are suitable for the case in this study, and the scaled conjugate-gradient algorithm [31] was chosen to train the models in this study.To apply ensemble method, the process for establishing an ensemble ANN model in this study is explained below and illustrated in Fig. 1.(1)First, the whole database was divided into two parts: 90% and 10%. The 10% part was set to be the testing data for testing the generalization effect.The training data accounts for 80% of the whole database, but was chosen from the 90% part mentioned in step (1). The remaining 10% were the validation data to supervise over-fitting. This step was repeated 20 times such that 20 training data and validation data sets were generated with different combinations and sequences.Each training dataset and validation dataset was used to train 15 networks with different initial weights.The learning effect of each network was tested by the testing data to examine the generalization of the network, and the best networks in each training data and validation dataset were selected to be combined into the ensemble model.Finally, an ensemble ANN model constructed by 20 networks was established. The output of the ensemble ANN model was the average of 20 best networks.In this structure, the best networks were selected to be a member of the ensemble for the least generalization error. However, some of the best networks might be selected just by chance, and not as the global optima, i.e., it just especially matched some certain cases. Hence, the median networks were also tested for each training dataset and validation dataset to be the members of the ensemble model. Other processes were the same with the method of choosing best networks as shown in Fig. 1.The aim of this study is to establish prediction models to predict the risk of hip fracture for elder adults. In Lan's study [10], the risk factors of hip fracture for female and male elder adults were analyzed respectively, because males do not have the risk factors of reproductive history. For comparison, different ensemble BPNN models were established with different number of inputs for female and male elder adults.As a result of above considerations in Section 2.2, it has been decided to establish three types of ensemble BPNN models with different structures and compare their performances.For the females, the three architectures were: (1) 74 inputs/140 hidden nodes/1 output and choosing the best networks in the ensemble method, (2) 74 inputs/37 hidden nodes/1 output and choosing the best networks in the ensemble method, and (3) 74 inputs/140 hidden nodes/1 output and choosing the median networks in the ensemble method.For the males, the three architectures were: (1) 67 inputs/140 hidden nodes/1 output and choosing the best networks in the ensemble method, (2) 67 inputs/34 hidden nodes/1 output and choosing the best networks in the ensemble method, and (3) 67 inputs/140 hidden nodes/1 output and choosing the median networks in the ensemble method.The structure of NHN=(NINP+NOUT)/2 with median networks was not selected since the models with the first structure was selected and examined with good results. If the second and third structures are not better than the first one, the fourth structure type does not need to be considered.The raw data in this study was originally from the questionnaire results in Lan's study [10]. Some of the 74 risk factors (the inputs for the BPNN models) in this study are associated with many questions in the original questionnaire. For example, the risk factor of ethnicity is associated with two questions: (1) the ethnicity of father and (2) the ethnicity of mother. However, in the designed model, there is only one input node for the risk factor of ethnicity. To apply the data of the questionnaire surveys into these ensemble BPNN models, the raw multiple data associated with one risk factor is required to be related to one value for each input node. An idea for transferring multiple data into one value came from genetic algorithms. The method of coding multiple data into one value is explained below and illustrated with an example in Fig. 2.(1)The raw decimal data was transferred to binary values.The multiple binary data was “combined” together into a binary value.The combined binary value was transferred into a decimal value.After the above processing, the multiple questionnaire data can be coded into one value and applied to training, validating or testing ensemble BPNN models.The ultimate goal of the prediction model is to find a set of neural network weights and bias values so that the input data generates output values that best match the target values. However, weights and bias values may match the data extremely well, but when presented with a new, previously unseen set of input data, the neural network would likely predict very poorly. This phenomenon is called over-fitting. To avoid over-fitting, the process of cross-validation is used to estimate the quality of the ANNs prediction model [32].The idea behind k-fold cross-validation is to divide all the available data items into roughly equal-sized sets. Each set is used exactly once as the test set while the remaining data is used as the training set [33]. Based on the fivefold cross-validation method to examine the prediction models produced by the above algorithms, the whole database was randomly divided into ten distinct parts because of the amount of test data is 10% of the whole database [34]. One part was used as testing data, and the remaining nine parts was used in the ensemble method as the 90% part. This procedure was repeated five times such that five datasets (dataset 1, dataset 2… dataset 5) with different testing data can be generated.The receiver operating characteristic (ROC) curve analysis has been widely applied as a useful tool to evaluate performances of classifiers [15,34–36]. In this study, the ROC curve analysis was also applied to estimate the discrimination power of the prediction models. The area under the ROC curve (AUC) is the main performance index of a classification. An AUC of 1.0 implies perfect discrimination, whereas an AUC of 0.5 is equivalent to a random model. The sensitivity (SEN), specificity (SPE), positive prediction value (PPV), and negative prediction value (NPV) was also calculated for each model at the best threshold to classify true or false. Furthermore, the accuracy of each model was calculated at the best threshold, which was defined by the proportion of true predictions of all predictions, to be an additional performance index to enhance the reliability of the result.It is interesting and necessary to consider which of these input variables are most influential. Some of these variables are extremely expensive or cumbersome to gather, requiring an expert assessment of the patients. Since there are 74 input variables for females and 67 input variables for males, the data recording is a significant cost, including financial, material and human resources. Therefore, there is a great deal of motivation to predict important input variables and reduce the number of variables gathered.Sensitivity analysis is a critical step in network modeling process. It provides an idea for the model dynamics responses to a variation in the values of some input variables. The purpose of sensitivity analysis is to study the behavior of a model, and to assess the importance of each independent variable on the values of the dependent variable of the model.A novel sensitivity analysis method was used for the models [19,37], which is simple and effective in identifying key variables. The method is introduced as follows:(1)Sequentially set each input variable to their minimum value (it is ‘−1’ after normalization).Assess the change in the root mean square error (RMSE) of the network. When each input variable was set to ‘−1’, a changed RMSE was obtained. Then calculate the ratio, which is changed RMSE over initial RMSE.Rank the input variables according to the value of ratio. The more important variable is combining with the bigger ratio.Sequentially set each input variable to their maximum value (it is ‘1’ after normalization), then repeat (2) and (3).Since it was based on the fivefold cross-validation method, two ranking results for each dataset were obtained. In order to get the final result for the whole data, the ‘vote method’ was applied. It is got by adding together the ratio of changed RMSE and initial RMSE of each ranked variable in five datasets, and the more important variable has a bigger vote ratio number. The contribution of each variable was also concluded according to vote ratio.In addition, the method of ‘leaving one out’ was also tried, which was sequentially removing each input variable from the neural network. But it is required to rebuild and retrain the neural network at each step, since there are 5 datasets, and each dataset has 74 input variables for females and 67 for males, it is time-consuming. Therefore, it is not suitable for the developed model.In the neural network, the connection weights between neurons are the links between the inputs and the outputs. The relative contributions of the independent variables to the predictive output of the neural network depend primarily on the magnitude and direction of the connection weights. Input variables with larger connection weights represent greater intensities of signal transfer, and therefore are more important in the prediction process compared to variables with smaller weights. The approach is described as calculating the product of the raw input-hidden and hidden-output connection weights between each input neuron and output neuron and sums the products, and then calculating the contribution of each input variable [19,38].

@&#CONCLUSIONS@&#
