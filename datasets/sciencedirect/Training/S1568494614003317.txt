@&#MAIN-TITLE@&#
A memetic algorithm for the re-entrant permutation flowshop scheduling problem to minimize the makespan

@&#HIGHLIGHTS@&#
We study a re-entrant permutation flowshop scheduling problem to minimize the makespan.We develop a memetic algorithm (MA) to obtain near-optimal solutions for the problem.Compared with two existing heuristics and CPLEX, MA is effective and outperforms the two existing heuristics and CPLEX.

@&#KEYPHRASES@&#
Re-entrant permutation flowshop scheduling,Memetic algorithm,Makespan,

@&#ABSTRACT@&#
A common assumption in the classical permutation flowshop scheduling model is that each job is processed on each machine at most once. However, this assumption does not hold for a re-entrant flowshop in which a job may be operated by one or more machines many times. Given that the re-entrant permutation flowshop scheduling problem to minimize the makespan is very complex, we adopt the CPLEX solver and develop a memetic algorithm (MA) to tackle the problem. We conduct computational experiments to test the effectiveness of the proposed algorithm and compare it with two existing heuristics. The results show that CPLEX can solve mid-size problem instances in a reasonable computing time, and the proposed MA is effective in treating the problem and outperforms the two existing heuristics.

@&#INTRODUCTION@&#
In classical scheduling model, it is commonly assumed that each job visits each machine only once (see [1]). However, the assumption that each job is processed on each machine at most once may not be valid in some real-life situations. A job may be processed by the same machine twice or more in practice. Such a processing environment is called the “re-entrant flowshop” in the literature. Examples of the re-entrant flowshop can be found in semiconductor wafer manufacturing [2], signal processing [3], and manufacturing of printed circuit boards [4–7].The defining characteristic of the re-entrant flowshop comprising m machines is that every job in the shop must be processed on the m machines in the following order: M1, M2,…, Mm; M1, M2,…, Mm;…; and M1, M2,…, Mm, with L re-entrants (or levels), i.e., starting on machine M1 and ending on Mm, and the job sequence is the same on any machine at each level. The corresponding scheduling problem is known as the re-entrant flowshop (RFS) scheduling problem. With the imposition of the constraint that no passing of the jobs is allowed, the problem becomes the RPFS scheduling problem.For the RPFS scheduling problem to minimize the makespan, Pan and Chen [8] proposed three extended mixed binary integer program (BIP) formulations and six heuristics to treat the problem with up to n=8 jobs. They used the Lingo optimizer to solve small-sized instances of the problem. Alfieri [9] studied a multi-objective flowshop scheduling problem arising in the cardboard industry, where the objective is to develop a modular decision support system for daily workload planning. The problem setting includes multi-machine stations, sequence-dependent setup times, and work calendars on resources, re-entrant flows, external operations, and transfer batches between stations. Liu [10] applied a genetic algorithm (GA) based method to solve the RFSP scheduling problem involving multiple orders per job, where the objective is to minimize the total weighted tardiness of all the jobs. Rau and Cho [11] proposed GAs to solve the inspection allocation problem in a re-entrant production system. Lin and Lee [12] presented a GA that encodes the problem as multi-level chromosomes to reflect the dependent relationship between the re-entrant possibility and resource consumption. For more studies of the RPFS scheduling problem in different settings, we refer the reader to Choi et al. [13], Chu et al. [14], and Boudhar and Meziani [15]. For more detailed research results on variants of the reentrant scheduling problem, the reader may refer to the surveys of Bellman and Ernest [16], Uzsoy et al. [7], and Lin and Lee [17], among others.Except for the few studies cited above, research on the RPFS scheduling problem is relatively unexplored. Moreover, searching for the optimal solution for the RFSP scheduling problem is only viable for instances involving a small number of jobs. For example, Pan and Chen [8] used the Lingo optimizer to solve problem instances with up to n=8 jobs. Chen [18] developed a branch-and-bound algorithm incorporating five lower bounds to solve problem instances with up to n=15 jobs. Chen et al. [19] further proposed a hybrid tabu search and evaluated its performance with solutions obtained from Lingo for instances with only up to n=4 jobs. In view of these observations, we tackle in this paper the RPFS scheduling problem to minimize the makespan by using the CPLEX solver and a memetic algorithm.The remainder of this paper is organized as follows: In “Notation and problem statement” section we introduce and formulate the problem. In “A memetic algorithm” section we develop a memetic algorithm to obtain near-optimal solutions for the problem. In “Computational experiments” section we provide computational results to assess the performance of the proposed algorithm and compare it with two existing heuristics. We conclude the paper and suggest topics for future research in the last section.In this section we first introduce the notation to be used throughout the paper, followed by the problem formulation.Notation for the problemnthe number of jobsthe number of machinesthe number of levels for each jobmachine number i, where i=1,2,…,mthe code for job j on machine i at level l, where i=1, 2,…, m; j=1, 2,…, n; and l=1, 2,…, Ldenotes the operation ofJiklon machine k at level l, where i=1, 2,…, n; k=1, 2,…, m; and l=1, 2,…, Lthe processing time ofOiklon machine k at level l, where i=1, 2,…, n; k=1, 2,…, m; and l=1, 2,…, L.the completion time ofJijlon machine i at level l, where i=1, 2,…, m; j=1, 2,…, n; and l=1, 2,…, L.the job scheduled in the jth position of a sequence.the completion time ofJijlscheduled in the jth position of a sequence on machine k at level l, where i=1, 2,…, m; j=1, 2,…, n; and l=1, 2,…, Lthe maximum completion time or makespan.a sequence of n jobsthe job arranged in position j of a schedulethe distance between the solutions of π1 and π2a population or schedulethe size of population XWe formally state and formulate the RPFS scheduling problem to minimize the makespan as follows: There are n jobs to be processed on m machines (i.e., M1, M2,…, Mm) where all the machines are available throughout the working period. All the jobs are available at time zero and preemption is not allowed. Technological constraints are known in advance. There is unlimited waiting space for jobs waiting to be processed. The defining characteristic of the re-entrant flowshop is that every job in the shop must be processed on the m machines in the following order: M1, M2,…, Mm; M1, M2,…, Mm;…; and M1, M2,…, Mm, with L re-entrants (or levels), i.e., starting on machine M1 and ending on Mm, and the job sequence is the same on any machine at each level. Furthermore, we assume that the machine order is the same for all the jobs and the job sequence is the same on each machine at each level. In addition, letOijlbe the operation ofJijlandpijlbe the processing time ofOijl, respectively. The objective is to minimize the makespan Cmax. Pan and Chen [8] extended the model of Wilson [20] by formulating the problem as a mixed binary integer program and solving it using the Lingo optimizer (for more details on the MIP model, please refer to [8]). However, they could solve problem instances with up to eight jobs only. Using the same model, we apply the CPLEX optimizer to generate feasible solutions and develop a memetic algorithm (MA) to obtain near-optimal solutions for the problem. For more details on the MIP model and technical computation, the reader may refer to Pan and Chen [8] and Chen [18].MA is a well-known population-based meta-heuristic, which can be used to tackle various combinatorial optimization problems, e.g. [21–24,30,31]. In this paper we propose an improved MA for the RPFS scheduling problem to minimize the makespan. We summarize the key steps of the MA as follows:Proposed Memetic Algorithm1:Initialize population X with n(X) solutions using the method described in “Population initialization” section2:while the stopping criterion is not reached do3:Update the population using the method described in “Population update strategy” section4:(1) Generate a temporary population X′ with n(X) solutions using the crossover and mutation operators based on X.5:(2) Generate a new population Xnew from X∪X′.(3) Set X=Xnew.7:Perform the dynamic local search described in “Dynamic local search” section to improve the best 10 solutions in the current population X.8:Update the best solution found so far.9:Remove the duplicated solutions in X by performing a random insertion move (remove a random job from its current position and insert it to another position) to each duplicated solution.10:if (the diversity index of the population is less than a threshold value) then11:Perform the population restart strategy on X according to the method described in “Population restart strategy” section12:end if13:end while14:Output the best solution found so far by the algorithm.In the proposed MA, a solution (a schedule or sequence) is represented as a permutation of the n jobs, i.e., π=(π(1), π(2),…, π(n)), where the jth number in the permutation π(j) denotes the job arranged in position j of the schedule (sequence).We generate the initial population X with n(X) solutions by two kinds of method. We use the generalization of the insertion technique of Nawaz et al. [29] (which is called NEH) to generate the first solution because NEH is considered to be the best among the constructive heuristics for permutation flowshop scheduling problems [32]. In addition, we also adopt a random generation heuristic that iteratively assigns jobs to random positions to generate the other initial solutions to guarantee good diversity of the initial population.In recent years, evolutionary algorithms such as genetic algorithm, particle swarm optimization, and differential evolution, have been widely used to deal with various kinds of combinatorial optimization problems. One major issue of using evolutionary algorithms is that the population tends to converge quickly at earlier stages of the evolution process (this phenomenon is called premature convergence). Once premature convergence occurs, the algorithm generally becomes trapped in a local optimum and cannot find the global optimal solution. Therefore, it is very important to maintain diversity of the population while preserving good quality solutions. In this paper we develop two improvement strategies to achieve this aim, i.e., we propose a new population update strategy and a population restart strategy based on a diversity index to evolve the population.In traditional evolutionary algorithms such as GA, the parent solutions will be immediately replaced by new offspring solutions if they are better than their parents. Though this can ensure good quality of the population, population diversity may deteriorate as the evolution process continues. To strike a balance between the quality and diversity of new populations, we propose a new population update strategy. In this strategy, we adopt a temporary population X′ to store all the new solutions generated by the crossover and mutation operators, and then generate a new population for the next iteration from the union of X and X′.We divide the new population Xnew into two equal parts: the first half consists of high quality solutions selected from the union of X and X′, and the second half is made up of the solutions that are far from the solutions in the first half. To determine the distance between two solutions, we adopt a distance definition that is often used in the literature [25]. Given two solutions π1=(π1(1), π1(2),…, π1(n)) and π2=(π2(1), π2(2),…, π2(n)), we define the distance between them asd(p1,p2)=∑k=1nsign(|π1(k)−π2(k)|), where sign(s)=1 if s≠0. A small value of d(π1, π2) means that the two solutions are close to each other. The distance of a solution π to a set of solutions S can be defined as the sum of distances between π and each solution in S, i.e.,D(π,S)=∑πk∈Sd(π,πk). Based on these definitions of distance, we can implement the population update strategy in the following manner:Population update strategy1:Input: population X and its diversity.2:fori≔1 to n(X) do3:Randomly select two parent solutions from X;4:Perform a crossover operation to generate an offspring solution and then perform a mutation operation on this offspring to get a new solution;5:Store this new solution in X′.6:end for7:Sequence the solutions in X∪X′ in ascending order of their objective values (i.e., the makespan Cmax), select the best 0.8×n(X) solutions and store them in the new population Xnew, and remove these solutions from X∪X′.8:fori≔1–0.2×n(X) do9:For each solution π left in X∪X′, calculate its distance to Xnew, i.e., D(π, Xnew);10:Select the solution πk with the minimum value of f(πk)/D(πk, Xnew) in X∪X′, in which f(πk) denotes the objective value (i.e., the makespan) of solution πk;11:Add this selected solution to Xnew and remove it from X∪X′.12:end for13:fori≔1 to n(X) −1 do14:forj≔i+1 to n(X) do15:if (the objective values of the ith solution and the jth solution are equal) then16:Perform a random insertion move (remove a random job from its current position and insert it to another position) to the jth solution17:end if18:end for19:end forAlthough the diversity of Xnew can be improved with the help of the population update strategy, the diversity of the whole population still deteriorates as it evolves because the search tends to converge with the guidance of the first 0.8×n(X) good quality solutions. So we develop a population restart strategy to monitor the diversity of the population and improve its diversity whenever necessary.To implement the improvement strategy, we propose a diversity index to measure the diversity of a population based on the differences among solutions in the population. The diversity index is calculated asDiversity=(1/n)×∑i=1n(X)−1∑j=i+1n(X)d(πi,πj)/(n(X)×(n(X)−1)/2), where the second term is the average distance between solutions in the population (denoted as davg). Since the value of davg is within [0,n], the value of the diversity index is within [0,1]. It is clear that a higher diversity index is preferred.During the evolution process, whenever the diversity index of the population is less than a threshold value (denoted as TH), a random insertion move, which removes a random job from its current position and inserts it to another position, will be performed for all the solutions in the population except the best ten solutions. The population restart strategy will not include the best ten solutions because the new population will often be worse if all the solutions are perturbed by the random insertion move. If the ten best solutions are retained, the good search results of the original population can be inherited by the perturbed population.The two-point crossover operator is widely used in the evolutionary algorithms for scheduling problems [26]. In view of this, we adopt the two-point crossover in the proposed MA. The main steps are that for the parent solutions π1 and π2, the operator first selects two cut points, namely ra and rb (ra<rb), and copies the jobs arranged in positions [1,ra] and [rb,n] in solution π1 to the offspring. Then it deletes the jobs that have been included in the offspring from solution π2. Finally, the operator inserts the left jobs in solution π2 to the empty positions of the offspring according to their positions in solution π2. The detailed working of the two-point crossover operator is given in Fig. 1.The mutation operator is an insertion operator that removes a random job from its current position and inserts it to another position. Based on prior tests, we use two consecutive insertion moves to mutate the offspring to obtain greater diversity.Different from traditional evolutionary algorithms, local search is a key component of the MA. For permutation flowshop scheduling problems, the traditional neighborhoods used in the local search are the insertion neighborhood based on the insertion move and the swap neighborhood based on the swap move that exchanges two jobs. In the traditional insertion and swap neighborhoods, during the search process only one move is performed and evaluated each time. Whenever an insertion or a swap move (i.e., move1) is performed on a solution π, the difference between the resulting new solution π′ and the original solution π is very small. If the move move1 cannot improve the current solution π (i.e., the makespan of π′ is worse than π), this move is discarded. However, if another move move2 is subsequently performed based on π′, the new solution π″ may be better than π. So the search space of the two traditional neighborhoods is fixed and small. Therefore, in this paper we develop a dynamic local search method whose search space is large and can be dynamically changed during the search process.Upon comparing 16 algorithms, Park [27] found that the NEH method is the least biased and most effective heuristic to solve the problem to minimize the makespan, while the CDS is the second best. The NEH method follows the rule that a job with a larger processing time on all the machines has priority over a job with a smaller processing time. In view of these observations, in this paper we develop a new neighborhood based on the idea of the NEH method, which represents another kind of stochastic local search method. Given a solution π0=(π(1), π(2),…, π(n)), we perform the local search in the following manner:Dynamic local search1:Inputπb=π0 and kmax=102:fori≔1 to kmaxdo3:Choose a random position r from πb, and delete d consecutive jobs arranged in positions from position r according to the following condition (see Fig. 2):4:if (n−r+1≥d), then5:delete d consecutive jobs π(r), π(r+1),…, π(r+d−1);6:else7:delete consecutive jobs π(r),…, π(n) and then π(1),…, π(d−(n−r+1)). (Note: we illustrate the deletion process in Fig. 2. For simplicity, the deleted jobs are denoted as π(r1), π(r2),…, π(rd) and the resulting partial solution as π′.)8:end if9:Insert the deleted jobs in π′ to construct a new complete solution as follows:10:forj=1 to ddo11:Insert π(rj) in the resulting partial solution π′ in the position that yields the minimum increase in the objective value.11:end for10:if (the objective value of π′ is less than that of πb) then11:Set πb=π′.12:end if13:end forIn comparison with the traditional insertion and swap neighborhoods, the new neighborhood can provide a much larger search space because the move of this neighborhood can remove many jobs from the current solution and then add them simultaneously based on the idea of NEH. Its size is determined by the value of d. When d is large, the neighbourhood's size is large, and vice versa. To make the local search have a good exploration ability at earlier stages and a good exploitation ability at later stages, we use a dynamic strategy to set the value of d. That is, the value of d will be dynamically adjusted from large to small. This strategy first divides the total available run time (or iteration time) into d equal ranges, and then sets the value of d in the k-th range to dmax−k+1, where dmax is the maximum of d. Following the above local search, we perform another local search that has a good exploitation ability. This method is a stochastic search. Given an initial solution π0, this method can be given as follows:Stochastic local search1:Inputπb=π0 and kmax=302:fori≔1 to kmaxdo3:Choose a random position r from πb, and delete the job π(r) arranged in position r from πb.4:Insert this job π(r) to its adjacent position that is randomly selected in [max{r−dmax, 1}, max{r+dmax, n}], and we obtain a new solution π′.5:if (the objective value of π′ is less than that of πb) then6:Set πb=π′.7:end if8:end forWe carried out computational experiments to test the performance of the proposed MA algorithm in solving the RPFS scheduling problem. We coded the MA in C++ and ran it on a personal computer with Intel Core2 Q9550 (2.83GHz) and four GB memory. We used only one core of the CPU in the experiments. We set the parameters of the MA according to our preliminary experiments as follows: the population size was n(X)=100, the search depth of local search was dmax=5, and the threshold value was TH=0.5.We randomly generated the job processing times from a uniform distribution [1,100]. The problem size is determined by n×m×L, where n, m, and L denote the numbers of jobs, machines, and re-entrant times, respectively. In order to evaluate the impact of problem size, we varied the numbers of jobs, machines, and re-entrant times by setting n at 5, 10, 20, and 30, m at 5, 10, and 20, and L at 3, 5, and 10. We tested a total of 33 problem groups and each group had ten instances. Therefore there were a total of 330 test instances. In addition, the setting of the MA was as follows: The number of consecutive jobs removed from a solution was 3, i.e., d=3. We set the number of iterations of the local search at ten and set the stopping criterion at the maximum run time of 0.1×n×m×L, where n is the number of jobs, m is the number of machines, and L is the number re-entrant cycles.For each instance, we first solved it using the CPLEX optimizer to obtain a feasible solution as a lower bound on the optimal solution for the instance. We compare the solution produced by MA with the lower bound obtained by CPLEX in terms of a Gap measure defined as follows:Gap=obj(S)−obj(LB)obj(LB)×100where obj(S) is the objective value obtained by algorithm S and obj(LB) is the value of the lower bound. For each instance, we executed the MA for five independent runs and recorded the minimum gap (denoted as MA(min)) and the average gap (denoted as MA(avg)).For L=3 and L=5, all the 12 problem groups were tested. But for L=10, only nine problem groups were tested because CPLEX could not solve the other three groups. Tables 1–3summarize the computational results.We evaluate the efficacy of the proposed MA in solving the PRFS scheduling problem on the basis of solution quality and solution time in terms of the average gap and CPU time in seconds, respectively. For solution quality, the average gaps of CPLEX and MA are 3.02 and 2.12 in Table 1, 3.42 and 2.69 in Table 2, and 4.02 and 3.58 in Table 3. On the other hand, for solution time, the average CPU times of CPLEX and the MA are 1380.29 and 41.60 in Table 1, 1546.83 and 77.03 in Table 2, and 2082.56 and 160.08 in Table 3. These results show that the MA outperforms CPLEX in terms of both solution quality and solution time. The results also indicate that the time taken by CPLEX or the MA increases when the other conditions are fixed, while the number of machines or re-entrant times becomes larger. In addition, we also compared the MA with two existing heuristics, namely H2 and H5 in Pan and Chen [8]. The main ideas of the H2 and H5 methods are summarized in the following. Following the idea for the Campbell, Dudek and Smith (CDS) algorithm (please refer to [28]), the key elements of H2 are to generate a set of (L×m−1) two-machine problems by dividing the L×m operations into two groups, and then use Johnson's rule to find the best sequence from among the (L×m−1) schedules. Meanwhile, inspired by the NEH algorithm by Nawaz et al. [29], the main steps of H5 are to arrange the jobs in decreasing order of their total processing times and then choose the best partial solution by adding a new job in each step. The results in Tables 1–3 show that the MA performs better than both H2 and H5 in terms of solution quality, but the MA takes longer solution times than H2 and H5. The times taken by the H2 and H5 heuristics are omitted since they are less than a second. H2 and H5 outperform CPELX and the MA in terms of solution time; however, their solution quality is worse than that of CPELX and the MA.In addition, Figs. 1–3show changes in the average gap with respect to n, m, and L, respectively. From Fig. 1, it appears that the MA obtains the best results for all groups of L. The average gap tends to increase as L increases because a larger value of L generally makes the problem more difficult to solve. From Fig. 2, we see that for n=5 and n=10, CPLEX is slightly better than the MA, but its computational time is much longer than that of the MA. For large values of n, the MA gives the best results. The results show that the average gap first increases and then decreases after n=20, which is mainly because CPLEX could not solve the instances in the 30×20×10 combination. From Fig. 3, it is clear that the average gap increases as the number of machines increases because the problem instances with a larger m are clearly more difficult. From the results shown in the three figures, we may conclude that the MA outperforms the other heuristics.In addition, it is noted from column 2 in Tables 1–3 that there are a total of 12 cases with a gap of zero, which means CPLEX finds an optimal solution. CPLEX can reach optimality for instances with n up to 20 and L up to 5. Overall, we recommend that the MA be used since it is stable and able to quickly produce near-optimal solutions.

@&#CONCLUSIONS@&#
In this paper we consider the re-entrant permutation flowshop scheduling problem to minimize the makespan. For this problem, as it requires a large amount of computer memory to use CPLEX to solve the corresponding MIP model, we develop an MA to solve instances of the problem with up to 30 jobs and ten re-entrant cycles only. To evaluate the performance of the MA, we compare it with CPLEX and two existing heuristics. The computational results show that the MA performs better than CPLEX in terms of solution quality and solution time. Moreover, the MA is much better than the two existing heuristics in terms of solution quality but takes longer solution times. The proposed solution provides an approach to handle the considered re-entrant flowshop problem, which is relevant to manufacturing and assembly processes. Future research may consider applying the MA to solve the RPFS scheduling problem involving other scheduling objectives such as the total completion time or total tardiness.