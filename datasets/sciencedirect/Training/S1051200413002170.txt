@&#MAIN-TITLE@&#
Hidden information detection using decision theory and quantized samples: Methodology, difficulties and results

@&#HIGHLIGHTS@&#
Quantization impact on design/performance of optimal hidden data test is studied.For small noise to quantization ratio, the optimal LR test performance is given.Simplification for large noise to quantization ratio is also presented.For unknown medium analysis, a GLR test is proposed and its performance is given.Impact of medium parameters on hidden data detectability are given for the first time.

@&#KEYPHRASES@&#
Hypothesis testing theory,LSB steganalysis,Quantized data,Optimal steganalysis,Nuisance parameters,

@&#ABSTRACT@&#
This paper studies the detection of Least Significant Bits (LSB) steganography in digital media by using hypothesis testing theory. The main goal is threefold: first, it is aimed to design a test whose statistical properties are known, this especially allows the guaranteeing of a false alarm probability. Second, the quantization of samples is studied throughout this paper. Lastly, the use of a linear parametric model of samples is used to estimate unknown parameters and design a test which can be used when no information on cover medium is available. To this end, the steganalysis problem is cast within the framework of hypothesis testing theory and digital media are considered as quantized signals. In a theoretical context where media parameters are assumed to be known, the Likelihood Ratio Test (LRT) is presented. Its statistical performances are analytically established; this highlights the impact of quantization on the most powerful steganalyzer. In a practical situation, when image parameters are unknown, a Generalized LRT (GLRT) is proposed based on a local linear parametric model of samples. The use of such model allows us to establish GLRT statistical properties in order to guarantee a prescribed false-alarm probability. Focusing on digital images, it is shown that the well-known WS (Weighted-Stego) is close to the proposed GLRT using a specific model of cover image. Finally, numerical results on natural images show the relevance of theoretical findings.

@&#INTRODUCTION@&#
Information hiding concerns the transmission of a secret message buried in a host digital medium. It has recently received increasing interest driven by the large number of ensuing application such as watermark-based authentication and fingerprint tracing. Unfortunately, potential malicious uses, among which steganography, have also emerged. The “prisoners problem” [43] illustrates a typical scenario of steganography and steganalysis. Alice and Bob, two prisoners, communicate by embedding a secret binary messageMinto a cover-objectCto obtain a stego-objectSwhich is then sent through a public channel. Wendy, the warden, examines all their communications and tries to detect whether an inspected object Z, either a cover-objectCor a stego-objectS, contains a secret messageMwithout being able to extractM.With many tools available in the public domain, steganography is within the reach of anyone, for legitimate or malicious purpose; it is thus of a crucial interest to be able to efficiently detect steganographic content among a (possibly huge) set of media.Many methods have recently been proposed to detect steganographic content [4,12,37] among which some are very efficient (see results of BOSS contest [2] for example). These methods can be roughly divided into four categories:1.Only a few detectors rely on the hypothesis testing theory [7,9,13,16,32,48]. The performance of these detectors can be expressed analytically which allows the guaranteeing of a prescribed detection-error probability. Unfortunately, these tests lack an accurate cover medium model and therefore exhibit rather poor performances.Many detectors belong to the class of structural detectors[26] which aims at detecting specific modifications of bit replacement using local pixelsʼ correlation. The Regular–Singular (RS) [21] the Sample Pair Analysis (SPA) [14,34] and the triple/quadruple detectors [27] are, for instance, good representatives of this category. These methods usually achieve overall good performances but lack a statistical model of cover media which prevents the analytic calculation of detection performance.The Weighted-Stego-image (WS) analysis, initially proposed in [20] to estimate the payload size and deeply studied in [28,29], forms a class apart which is known to have good detection performance. Similarly to the structural detectors, the WS detectors rely on a local autoregressive model of media. However, the statistical properties of WS algorithms remain unknown; therefore, probabilities of detection errors can only be measured empirically.Lastly, universal or blind detectors aims at detecting any steganographic scheme in any kind of image using a set of selected features and supervised learning methods to train a classifier. As in all applications of supervised learning, a difficult problem is to choose an appropriate feature set which, for detection of hidden information, is usually done empirically. Moreover, the problem of measuring classification error probabilities remains open in the framework of statistical learning [41].However, the application of hypothesis testing theory is not straightforward because of some fundamental difficulties. Firstly, the cover medium is quantized which prevents a direct application of classical hypothesis tests. Secondly, a digital medium exhibits a complex and structured content which acts as nuisance parameters as it has no interest for hidden information detection. Thirdly, no assumption on the size of hidden data (or more precisely on the relative payload) is available to the steganalyst, the tested hypothesis is thus composite.In the present work the embedding scheme is assumed to belong to the commonly used family of LSB replacement scheme. Actually, as of December 2011, WetStone Technologies Inc. has 836 data hiding software among which 582 (70%) uses LSB replacement [22]. In addition, detection of mostly encountered algorithms is more important than the detection on seldom found ones. Thus, requirement of efficient and robust detection methods for the LSB replacement steganographic scheme is still a live research topic.The first step in the application of hypothesis testing theory for steganalysis has been done in [13] in 2004 using a simplistic model of independent and identically distributed (i.i.d.) samples. This methodology was latter proposed in [8,9] in 2011 to design an efficient test using a complex model of cover medium. During the same year, a theoretical approach was also used in [10,50] to design locally most powerful test (around a given hidden message length) which is difficult to apply in practice.The fundamental originalities of the proposed article are that the content of cover medium as well as the impact of quantization are considered. In fact, it is necessary to take into account these two phenomena to apply hypothesis testing theory and to precisely establish the performance of proposed statistical tests.To highlight the contributions of the presented methodology, let us first denote that the detection performance of steganalyzers is usually measured using a fixed hidden data length with a receiver operating characteristic (ROC) curve [15]. However, it is known that in practice, detection results do not only depend on relative payload or embedding rate. For instance, it has been shown that results depend on inspected medium content [5] and hidden data length [38]; the phenomena referred to as “camera mismatch” were also observed during BOSS contest [2]. Likewise, the detection performance of proposed detectors is not compared with an optimal bound or with the most powerful test.In fact, the relation between cover medium properties and detection performance remains unclear for most of steganalyzers and optimal detection performance has only been established under the dubious condition of neglected quantization.On the opposite, this paper proposes a novel methodology to detect information hidden in the LSB of a digital medium using hypothesis testing theory. The main contribution is threefold:1.Throughout this paper, the quantization of pixels is thoroughly studied in order to measure its impact on hidden information detection. It is especially shown that data quantization and hidden information in the LSB plane heavily impact on the test performance.In the ideal context when medium content is known, the statistical performance of the Likelihood Ratio Test (LRT) is then analytically established. This result provides an optimal upper-bound on the power function one can expect from any detector. Moreover, it is shown that detection performance depends on an “Insertion-to-Noise Ratio” (INR) which allows us to understand how some of cover medium properties impact the performance of the LRT.Finally, when the structured content of inspected medium is unknown—that is the expectation and the variance of each sample—this nuisance parameter is explicitly taken into account using a linear parametric model. Based on this model of cover content, a sub-optimal Generalized Likelihood Ratio Test (GLRT) is proposed and its statistical properties are analytically given to guarantee, in practice, a prescribed false-alarm constraint.The paper is organized as follows. Section 2 formally states the problem of steganalysis paying a careful attention to further difficulties. Then, Section 3 details the design of the LRT and the calculation of its performances in the ideal case when the cover medium parameters are assumed to be known. The more realistic case non-i.i.d. samples is studied in Section 4. Section 5 investigates the practical case when no information about cover medium is available. First, the linear parametric model used to estimated unknown parameters of inspected medium is presented. Then, the design of the GLRT is detailed together with the calculation of its statistical properties. Numerical results and comparisons with prior art steganography detectors are presented in Section 6. Finally, Section 7 concludes the paper.Let the vectorC={cn}n=1Nrepresents a digital cover medium of N samples. Each sample is usually quantized with b bits, henceC∈ZNwithZ={0,1,…,2b−1}. The value of a cover samplecnis given by:(1)cn=QΔ(yn),whereyn∈Rdenotes the recorded sample value andQΔ(yn)is the operation of uniform quantization with step Δ defined, for allk∈Z,k≠0,k≠2q−1, by:(2)QΔ(x)=k⇔x∈[Δ(k−1/2);Δ(k+1/2)[.For clarity, effects of quantizer saturation, which arise fork=0andk=2b−1, are neglected in this paper; note that it can be taken into account at the cost of complicated calculations [45].The recorded sample valueyncan be written as [19,24](3)yn=θn+ξn,whereθnis the mathematical expectation ofynandξnis the realization of a zero-mean random variable representing all the noises corrupting the signal during acquisition. For definition, it is assumed in this paper that the mean vectorθ={θn}n=1Nbelongs to a compact set Θ.Let probability mass function (pmf) of the quantized samplecnbe denoted:(4)Pθn={pθn[0],…,pθn[2b−1]}.To model statistically the modification due to insertion of secret messageM, let the payload0<R⩽1be defined as the number of hidden bits per cover medium sample.22For clarity, the relative payload or embedding rate R is not distinguished from the actual change-rate in the present paper. However, those two notions are different for steganographic scheme which does not embed one bit per change, using error correcting codes for instance [36].After insertion of the hidden messageM, a samplesnfrom the stego-mediumS={sn}n=1Nis characterized by the pmf denoted(5)QθnR={qθnR[0],…,qθnR[2b−1]},which, of course, depends on the embedding scheme.The LSB replacement method consists in inserting message bitsMby substituting samplesʼ LSB. This embedding scheme can be modeled statistically thanks to the two following assumptions commonly used in steganalysis [13,21]:A-1Because the message is previously compressed and/or cyphered, each hidden bits of messageM(0 or 1) is drawn from a binomial distributionB(1,1/2).The insertion locations in the cover-object are chosen pseudo-randomly using a secret key, hence, each cover pixelcnis used with the same probability (referred as “mutually independent embedding” in [18]).When inspecting a digital medium Z in order to detect hidden information, the problem one which to solve is to decide between the two following hypotheses:(7){H0={zn∼Pθn,∀n∈{0,…,N}},H1={zn∼QθnR,∀n∈{0,…,N},∀R⩾0}.The goal is to find a testδ:ZN→{H0;H1}such that hypothesisHiis accepted ifδ(Z)=Hi(see [33] for details about statistical hypothesis testing). Let(8)Kα0={δ:supθ∈ΘPH0[δ(Z)=H1]⩽α}be the class of all tests whose false alarm probability is upper-bounded byα0; herePH0[⋅]stands for conditional probability under the null hypothesisH0. The power functionβδ,Rof a test δ is the probability of hidden bits detection defined by:βδ,R=PH1,R[δ(Z)=H1]withPH1,R[⋅]the conditional probability under alternative hypothesisH1: a secret message was hidden with relative payload R. Obviously, it is aimed at finding a test in the classKα0(to meet a prescribed false-alarm probability constraintα0) which maximizes the power functionβδ,R, if possible, uniformly with respect to the relative payload R.The hypothesis testing problem as formulated in (7) highlights three major difficulties of the hidden information detection problem. First, when data are quantized most of the usual results from decision theory are no longer valid. Second, because the relative payload R is unknown the hypothesisH1,Ris composite. Last, the mean vectorθ, representing the structured content of inspected digital medium, acts as a nuisance parameter for which an accurate estimation is an open problem of signal and image processing.The problems of dealing with quantized observations and composite hypotheses are addressed in Sections 3–4 while the problem of dealing with the nuisance parameterθis addressed in Section 5.Let us suppose that the relative payload R as well as the pmfPθnandQθnR, see (4)–(5), are known by the steganalyst. In this case the tested hypotheses (7) are simple and from the relation (6) the Likelihood Ratio (LR) is given, for the observationzn, by:(9)ΛR(zn)=qθnR[zn]pθn[zn]=(1−R)+Rpθn[zn]+pθn[z¯n]2pθn[zn]︸Λ1(zn).It follows from the Neyman–Pearson lemma [33, Theorem 3.2.1] that the most powerful testδnpover the classKα0is the LRT defined by the following decision function:(10)δRnp={H0iflnΛR(Z)=∑n=1NlnΛR(zn)<τα0,H1iflnΛR(Z)=∑n=1NlnΛR(zn)⩾τα0,where the decision threshold is the solution of the equationPH0[ΛR(Z)⩾τα0]=α0,such thatδRnp∈Kα0.Eq. (10) clearly shows that the testδRnponly depends on the observations Z through the quantityΛ1, which corresponds to the LR in the case of a payloadR=1. It is thus proposed to study this LRΛ1in order to get the statistical properties of the testδRnpwhatever the relative payload R might be.For most of the digital media, theξnʼs, representing noise values see (3), are well approximated as realization of independent Gaussian random variablesΞnsatisfyingΞn∼N(0,σn2). This model of noise is quite general and can potentially be applied for a wide range of digital media. Focusing on digital images, which is the most widely used type of media in both steganography and steganalysis, the noise varianceσn2varies from pixel to pixel due to the signal-dependent noise discussed in [19,24].It follows from (1) and (3) thatpθn[k]is defined, for allk∈Z,k≠0,k≠2q−1, by:(11)pθn[k]=1σn∫Δ(k−1/2)Δ(k+1/2)φ(x−θnσn)dx=Φ(Δ(k+12)−θσn)−Φ(Δ(k−12)−θσn),whereφ(⋅)andΦ(⋅)are respectively the standard Gaussian probability density function (pdf) and cumulative distribution function (cdf) defined by:(12)φ(x)=12πexp(−x22)andΦ(x)=∫−∞uφ(u)du.As already explained for Eq. (2), effects of quantizer saturation are omitted from relation (12) for clarity.Using the well-known Taylor series expansion of the function φ[47, p. 931] around the value Δk, the midpoint of quantization step, see (2), a short calculation shows that:(13)pθn[k]=Δσnφ(Δk−θnσn)(1+εθn[k]),where the analytic expression of the corrective termεθn[k]is:(14)εθn[k]=∑i=1∞(−1)i222i(2i+1)!Δ2iσn2iH2i(Δk−θσ)withHithe Hermite polynomial of order i[47, p. 1350].Letk(0)=min{k;k¯}=12(k¯+k−1)represent the integer k whose LSB is set to 0. The termpθn[k]+pθn[k¯]represents the probability thatznbelongs to the interval[Δ(k(0)−1/2);Δ(k(0)+3/2)[and can thus be expressed as the following integral:pθn[k]+pθn[k¯]=1σn∫Δ(k(0)−1/2)Δ(k(0)+3/2)φ(x−θnσn)dx.Similarly to Eq. (13), a short calculation using the Taylor series expansion of the function φ around the valueΔ(k(0)+1/2), permits the writing of:(15)pθn[k]+pθn[k¯]=2Δσnφ(Δ(k(0)+12)−θnσn)(1+εθn(0)[k]),where the corrective termεθn(0)[k]is given as:(16)εθn(0)[k]=∑i=1∞(−1)i222i(2i+1)!Δ2iσn2iH2i(Δ(k(0)+12)−θσ).Using the expressions (13) and (15), it is straightforward to write the logarithm of LRΛ1(zn)(9) as follows:(17)ln(Λ1(zn))=12σn2((Δzn−θn)2−(Δ(zn(0)+12)−θn)2)+ln(1+εθn(zn))−ln(1+εθn(0)(zn(0))),wherezn(0)=min{zn;z¯n}=12(z¯n+zn−1), as previously defined.Due to corrective termsεθn[k]andεθn(0)[k], the exact expression of the LRln(Λ1(zn))is difficult to use in practice. However, by using (14) and (16) a Taylor series expansion shows thatln(1+εθn(zn))−ln(1+εθn(0)(zn(0)))=o(Δ2/σn2). Therefore, in the present paper, it is proposed to neglect these corrective terms in the calculation of the LRln(Λ1(zn)). This simplification is especially accurate in practice because for most digital RAW media it holds thatΔ≪σn.By using the definitionzn(0)=12(z¯n+zn−1)a direct calculation gives:(Δ(zn(0)+12)−θn)2=(Δzn−θn)2+Δ24+Δ(zn−z¯n)(Δzn−θn).Using this result, the LRln(Λ1(zn))can be approximated by:(18)ln(Λ1(zn))=Δ(zn−z¯n)(Δzn−θn)2σn2−Δ28σn2+o(Δ4σn4),where the notationy=o(x)means thaty/xtends to 0 as x tends to 0.Even though the expression (18) ofln(Λ1(zn))is rather simple, it is not straightforward to establish the probability of each type of detection error of the testδR(10). To this end, an asymptotic approach is used by assuming that the number of samples N grows to infinity; this assumption is relevant in practice because the number of samples is very large in—almost—every digital media.To study the asymptotic distribution of the LRln(Λ1(zn)), under both hypothesesH0andH1, it is proposed to apply the well-known Lindebergʼs central limit theorem (CLT) [33, Theorem 11.2.5] from which it follows that:(19)∑n=1Nln(Λ1(zn))−Ei[ln(Λ1(zn))]∑n=1NVari[ln(Λ1(zn))]⇝N(0,1),where fori={0;1}, the notationsEi[⋅]andVari[⋅]respectively denote the mathematical expectation and the variance under the hypothesisHiand ⇝ represents the convergence in distribution as N tends to infinity.It should be noted that the application of Lindebergʼs CLT (19) requires that Lindebergʼs condition is satisfied [33, Eq. (11.11)]. In the present case this condition is easy to verify by using Lyapounovʼs condition [33, Eq. (11.12)] which implies Lindebergʼs condition.It follows from the CLT (19) that to establish the error probabilities of the LR testδR, it is necessary to calculate the two first moments ofΛ1(zn), under both hypothesesH0andH1, under the hypothesisH0, the expectation of the approximated LRln(Λ1(zn))(18) is given by:(20)μ0=def.EH0[ln(Λ1(zn))]=−Δ28σn2+Δm02σn2,where the quantitym0, which represents the impact of quantization, is given by:(21)m0=m0(θn)=EH0[(k−θn)(k−k¯)]=∑k∈ZPH0[zn=k](k−θn)(k−k¯).An explicit expression ofm0is given in Appendix B.Likewise, under the hypothesisH1, assumption A-1 permits us to calculate the expectation of approximated LRln(Λ1(zn)):(22)μ1=def.EH1[ln(Λ1(zn))]=Δ28σn2.A graphical representation of the termμi,i∈{0;1}as a function ofθnis provided in Fig. 1.Likewise, the variance of the LRln(Λ1(zn)), denotedσ01andσ12respectively under hypothesesH0andH1, are given by:(23)σ02=Δ24σn4(EH0[(Δzn−θn)2]−m02),(24)σ12=Δ24σn4(EH0[(Δzn−θn)2]+Δ24).The calculations of the moments (20)–(24) are detailed in Appendix B.It follows from the Neyman–Pearson lemma that the LRTδ1np, based onln(Λ1(Z)), is the most powerful test designed forR=1provided that the decision threshold is correctly chosen. In practice, the assumption that relative payload R is known does not hold; hence, the hypothesisH1becomes composite and the ultimate goal is to find a Uniformly Most Powerful (UMP) test, that is a test that maximizes the power function whatever R might be. Here, it is straightforward to verify that the hypotheses do not admit a monotonic likelihood ratio; therefore the existence of a UMP test is compromised [33, Theorem 3.4.1].The problem of finding an optimal test forR∈[0;1]is deeply studied in [16,10,50]. In [16] it is shown that the testδ1(10), based on the LRln(Λ1(Z))(18) is Asymptotically UMP (AUMP) using the dubious assumption that the quantization step Δ tends to zero, and thus becomes negligible. Taking into account the impact of quantization, a Locally AUMP (LAUMP) test, i.e. a most powerful around a given payloadR⋆, is proposed in [10,50].Because the design of a UMP or an AUMP test for LSB replacement steganalysis seems out of reach, in realistic conditions, it is proposed in the present paper to use the testδ1npdesigned forR=1. The main reason behind this choice is that whatever the real payloadR∈[0;1]might be, each pixel is used or not for hiding a secret bit and hence, actual payload is either 0 or 1 for each pixel.From Eq. (9), the law of total expectation and results (20)–(22) permit us to establish the expectationμRof the LRln(Λ1(zn)):(25)μR=(1−R)μ0+Rμ1=Δ28σn2(2R−1)+(1−R)m02σn2.Similarly, the varianceσR2of the LR for anyR∈[0;1]can be calculated from the law of total variance:(26)σR2=(1−R)(σ02+μ02)+R(σ12+μ12)−((1−R)μ0+Rμ1)2,where the momentsμ0,μ1,σ02andσ12are respectively given in Eqs. (20)–(24).For clarity, let us define fori={0;1}:(27)μ˜i=1N∑n=1NEi[ln(Λ1(zn))],σ˜i2=1N∑n=1NVari[ln(Λ1(zn))],which respectively represent the “mean expectation” and the “mean variance” of the LRln(Λ1(Z)). Obviously, when samples are i.i.d., it immediately follows hasμ˜i=μiandσ˜i2=σi2.It follows from Lindebergʼs CLT (19), that for any relative payloadR∈]0;1], the term1N∑n=1Nln(Λ1(zn))follows, under both hypotheses, the asymptotic distribution given by:(28){1N∑n=1Nln(Λ1(zn))⇝N(μ˜0N;σ˜02)underH0,1N∑n=1Nln(Λ1(zn))⇝N(μ˜RN;σ˜R2)underH1,where the termsμ˜iandσ˜i2are defined in (27). Following the Neyman–Pearson approach, once the false-alarm probabilityα0is defined, it is necessary, first, to calculate the decision thresholdτα0that guarantees this false-alarm probability so thatδ∈Kα0, and second, to maximize the power function of the test δ. The following Theorems 1 and 2 respectively provide an analytic expression for the decision thresholdτα0and for the power functionβδ1.Theorem 1For anyα0∈]0;1[, the threshold value given by:(29)τα0=(σ˜0N)Φ−1(1−α0)+(μ˜0N),whereΦ−1(⋅)is the standard Gaussian inverse cumulative distribution function (cdf), guarantees that asymptotically, as N tends to ∞, the testδ1(10)satisfiesαδ1=α0.Using the result (28) it asymptotically holds that for anyτα0∈R:αδ1=PH0[ln(ΛR(Z))⩾τα0]=1−Φ(τα0−μ˜0Nσ˜0N).Hence, since Φ is an increasing function, for anyα0⩾αδ1one has:Φ−1(1−α0)⩽Φ−1(1−αδ1)=τα0−μ˜0Nσ˜0N⇔τα0⩽(σ˜0N)Φ−1(1−α0)+(μ˜0N).□Theorem 2For anyR∈]0;1]and for anyα0∈]0;1[, assuming that the parametersθ={θn}n=1Nandσ={σn}N=1Nare known, then the power functionβδ1associated with the testδ1(10)is asymptotically given, as N tends to ∞, by:(30)βδ1=1−Φ(σ˜0Φ−1(1−α0)+(μ˜0−μ˜1)RNσ˜R).It can be noted that Theorems 1 and 2 are of crucial interest; the first allows the establishing of the decision threshold which asymptotically allows us to guarantee that the testδ1satisfies a given prescribed false-alarm probability; the decision thresholdτα0(29) does not depend on the relative payload and, thus, holds for anyR∈[0;1]. Theorem 2 is also very useful as it provides the testδ1, optimal forR=1, with an analytic expression of its power function for anyR∈[0;1].Fig. 2provides a graphical representation of the power functionβδ1(30) for a particular case of i.i.d. samples (with constant expectationθnand constant varianceσn2for all n).Remark 1The proposed approach is closely related to the one adopted in [13]: in both cases the Neyman–Pearson lemma is used to obtain a simple expression of the most powerful LRT. However, it is supposed in [13] that the samples are i.i.d., i.e. for alln∈{0,…,N},θn=θandσn2=σ2. Under this assumption it is shown in [13] that the LRT can be written as follows:DKL(PZ,QθR)−DKL(PZ,Pθ)≶H0H1τ,wherePZ={pZ[0],…,pZ[2b−1]}denotes the empirical distribution of analyzed samples andDKL(P,Q)is the Kullback–Leibler divergence between distributions P and Q.By using Eq. (9), a short calculation shows that when samples are i.i.d., the LRln(Λ1(Z))can be written:ln(ΛR(Z))=−N(DKL(PZ,QθnR)−DKL(PZ,Pθn)).However, the fundamental strength of present paper is that samples are not considered i.i.d. and expectation vectorθ={θn}n=1Nis explicitly taken into account as nuisance parameter. This eventually allows us to design a test with a much higher power function by considering properties of each sample.The results presented in Sections 3.2–3.3 explicitly take into account the impact of data quantization and analytically establish the statistical properties of the most powerful testδ1. The impact of quantization on the expectation of the LRln(Λ1(zn))and on the power function of the testδ1is respectively provided in Fig. 1 and in Fig. 2.Even though, the impact of quantization on the performance of the testδ1can easily be calculated numerically using Eqs. (20)–(27), two major difficulties remain in practice. First, providing a simple analytic expression for the expectationμ˜iand for the varianceσ˜i(27) of the LRln(Λ1(Z))is obviously difficult. Second, the decision thresholdτα0depends on the quantitiesμ˜0andσ˜0which both depend on parametersθ={θn}n=1Nandσ={σn}n=1N. In practice, this is a major drawback as it is thus necessary to calculate a specific decision thresholdτα0for each inspected medium.In the present section, it is proposed to overcome these difficulties by studying the behavior of the termm0(θn), for a large set of samples which all have different parametersθnandσn. Unfortunately, this is hardly possible in general and an assumption on these parameters is required. To this end, let us defineζn∈[−Δ;Δ],ζn=θn−Q2Δ(θn), a quantity on which only the moments ofln(Λ1(zn))depends.Without any extra information on a medium Z the following assumption is adopted.A-3Let us assume that in the analyzed medium Z, the valuesζnasymptotically occurs with the same frequency. In other words, denotingNx0,x1,x0<x1,{n/ζn∈[x0,x1]}, that is the number of samples which verifyζn∈[x0;x1], as N tends to infinity it is assumed that:(31)∀x0,x1∈[−Δ;Δ]2,x0<x1,limN→∞Nx0,x1=x1−x02Δ.Using the assumption A-3, the corrective termm0tends to become negligible as the number of pixel N grows to infinity. In fact, Eq. (21) shows thatm0(ζn)=−m0(ζn+Δ); hence, using assumption A-3, the sum of all termsm0(ζn)tends to 0, see Appendix C for details.The following Proposition 1 formalizes this result.Proposition 1Under assumption A-3, the mean expectationμ˜iand the mean varianceσ˜i2(27)of LRln(Λ1(zn))are asymptotically, as N tends to infinity, given by:(32)μ˜0=1N∑n=1N−Δ28σn2,μ˜1=1N∑n=1NΔ28σn2,σ˜02=1N∑n=1NΔ24σn2(1+Δ212σn2),(33)σ˜12=1N∑n=1NΔ24σn2(1+Δ23σn2).From Eqs.(32)and(33)and from the laws of total expectation and total variance, see(25)and(26), it follows that:(34)μ˜R=1N∑n=1NΔ2(2R−1)8σn2,σ˜R2=1N∑n=1NΔ24σn2(1+Δ24σn2(2R−R2)+Δ212σn2).ProofProof of Proposition 1 is given in Appendix C.  □For clarity and simplicity, it is proposed in the present paper to normalize the LRln(Λ1(zn)), using expressions (32) and (33). To this end, let the quantitiesσ¯andln(Λ˜(Z))be defined as:(35)1σ¯2=def.1N∑n=1N[σn2(1+Δ212σn2)]−1,(36)ln(Λ˜(Z))=def.Δσ¯N∑n=1N(zn−z¯n)(Δzn−θn)σn2(1+Δ2/12σn2)=2σ¯N∑n=1N[ln(Λ1(Z))−μ˜0](1+Δ2/12σn2).From these expressions, it immediately follows from Proposition 1 and Lindebergʼs CLT (19) that under the null hypothesisH0one has:(37)ln(Λ˜(Z))⇝N(0,1).Similarly, under the hypothesisH1that Z contains information hidden with a payloadR∈]0;1], one has:(38)ln(Λ˜(Z))=σ¯N∑n=1Nln(Λ˜(zn))⇝N(ϱ,1+γR),withγR=Δ24(2R−R2)∑n=1N[σn2(1+Δ2/12σn2)]−2∑n=1N[σn2(1+Δ2/12σn2)]−1,and the “Insertion-to-Noise Ratio” (INR) ϱ is defined as:(39)ϱ=NRΔ2σ¯.The results (37) and (38) are demonstrated in Appendix C.2.The crucial importance of this INR ϱ for power function is highlighted in Theorems 4 and 6 and throughout numerical results of Section 6.The results (37) and (38) are illustrated in Fig. 3which represents the two first moments of the “simplified” LRln(Λ˜(Z))as a function of relative payloadR∈[0;1]; note that for a better readability, the displayed variance is actuallyVar[ln(Λ˜(Z))]−1=γR.For definition, let the testδ˜associated with the LRln(Λ˜(zn))be defined as:(40)δ˜={H0ifln(Λ˜(Z))=σ¯ΔN∑n=1Nln(Λ˜(zn))<τ˜α0,H1ifln(Λ˜(Z))=σ¯ΔN∑n=1Nln(Λ˜(zn))⩾τ˜α0.Theorem 3For anyα0∈]0;1[, the threshold value given by:(41)τ˜α0=Φ−1(1−α0),asymptotically guarantees thatδ˜(40)satisfiesα0(δ˜1)=α0.Theorem 4For anyR∈]0;1]and for anyα0∈]0;1[, assuming that the parametersθ={θn}n=1Nandσ={σn}N=1Nare known, then the power functionβδ˜associated with the testδ˜(40)is asymptotically given, as N tends to ∞, by:(42)βδ˜=1−Φ(Φ−1(1−α0)−ϱ1+γR).The demonstrations of Theorems 3 and 4 are detailed in Appendix C.  □The main interests of the testδ˜(40) are twofold. First, the decision threshold given by (41) does not depend on any medium parameters but only on the prescribed false-alarm probabilityα0; hence for any analyzed medium, it is straightforward to guarantee a prescribed false-alarm probability. Second, the power function given in Eq. (42) provides a simple expression and an accurate approximation of power function of the most powerful test. The power function as given in (42) can thus be used as an optimal bound for any steganalyzer which aims at detecting LSB replacement.Finally, it can be noted that when the quantization step is small compared to the noise standard deviation, i.e.Δ≪σsee especially [9,8,16] in which the impact of quantization is neglected, Eq. (42) of the power function simplifies toβδ˜=1−Φ(Φ−1(1−α0)+ϱ).Remark 2As discussed in the beginning of Section 3.1, the noise variance varies from sample to sample. This property of noise non-stationarity, or heteroscedasticity, especially studied for digital images in [19,24], helps the steganalyzers because, as shown in Appendix A, one can note that:(43)σ¯2⩽1N∑n=1Nσn2(1+Δ212σn2)⇒ϱ=NRΔ2σ¯⩾NRΔ2(1N∑n=1Nσn2(1+Δ212σn2))−1/2.In other words, Eq. (43) shows that for a given mean variance of pixels (or mean noise level), the INR (39)ϱ is minimal when all the samples have the same variance. It is obvious that the power function as given in Eq. (42) is an increasing function of ϱ. Therefore, for any medium for which the noise heteroscedastic property holds the power function of LRTδ˜(40) is higher than for a medium with the same mean variance whose samples all have the same variance.It should be noted that this result only holds true under assumptions A-1 and A-2. For a steganographic scheme which embeds hidden bits only in selected samples, this result not necessarily holds.In a practical situation, the steganalyst usually has no information on the analyzed medium. From a statistical point of view, the problem is then to use quantized observations to test two composite hypotheses in presence of an unknown nuisance parameterθ. Obviously, the hypothesis testing theory does not provide a general methodology for finding an optimal test for such problems.It is necessary to estimate the parameterθnfor each pixel. However, an estimation of each parameterθnis impossible and hence, the “theoretical” decision problem (7) cannot be solved.To overcome the previously discussed difficulty of dealing with nuisance parameter, the main idea is to group the samples into small sets. This allows us to exploit the redundancies that naturally exist between neighboring samples to estimate locally their expectation.Hence, it is proposed to divide the medium Z into a set of K statistically independent (non-overlapping) “blocks” ofL>0consecutive samples denoted, fork=1,…,K, byzk=(zk,1,…,zk,L)T, whereATis the transpose of matrix A. Of course, L is chosen rather small to ensure a simple local estimation andK=⌊N/L⌋(rounded down) to includes almost—all samples of Z during its inspection.As explained in Section 2, samples are assumed to be statistically independent. Hence, the vector of quantized observationszkcan be written, thanks to (1) and (3), as:zk=QΔ(θk+ξk),where the quantizerQΔ(⋅), defined in (2), is applied to each component individually, the mean vectorθkis defined byθk=(θk,1,…,θk,L)Tand the stochastic termξkis the realization of independent Gaussian vectorΞk∼N(0,Σk), withΣk=diag(σk,12,…,σk,L2).It thus follows from (4) and (5) that the joint distribution of each vector of sampleszkis given by the distribution product, see [3],(44){Pθk=Pθk,1×⋯×Pθk,LunderH0,QθkR=Qθk,1R×⋯×Qθk,LRunderH1.Using the joint distribution of the vector of samples from (44), the alternative hidden information decision problem becomes:(45){H0={zk∼Pθk,∀k=1,…,K},H1={zk∼QθkR,∀k=1,…,K,∀R⩾0}.Problem (45) is strictly equivalent to problem (7) whenθis known. Whenθis unknown, exploiting the redundancies between the pixels of the same block is necessary to limit the number of unknown parameters with respect to the number of samples.The issue is then to model accurately the local redundancies that exist between neighboring samples to allow an efficient estimation ofθk. While some accurate and efficient models of the content of natural images have already been proposed for steganalysis, see [9,8], this problem lies outside the scope of the present paper which aims at applying statistical decision theory for steganalysis. Hence, among the wide range of possible local model, see [1,23], in this paper the mean vectorθkis defined by the following linear parametric model [30,31] for which theory of hypothesis testing is rather well developed:(46)θk=Hak,where H is a matrix of sizeL×panda∈Rp. It is assumed that H is a full rank column matrix, that isrank(H)=p<L. For definition, it is assumed in the rest of this paper thatθ∈Θ=ωKwhere ω is theRpsubspace ofRLdefined byω=im(H).The choice of the matrix H is fundamental for such a parametric model. The problem of designing a good parametric model for local signal approximation is out of the scope of this paper, some discussion can be found in [1,23,35]. In this paper, it is assumed that as long as block size remains rather small, they can efficiently, be modeled by algebraic polynomial, see details in Section 6.1; similarly, due to the small block size, the noise variance is assumed constant over each block:Σk=σ2IL, withILthe identity matrix of size L.It follows from the parametric model (46) that the maximum likelihood estimators of parametersθkandσkare given by:(47)θˆk=PHzkwithPH=H(HTH)−1HT,(48)σˆk2=Δ2L−p|PH⊥zk|22withPH⊥=IL−PH.The parameterθkacts here as nuisance parameter. In fact, as shown in Eqs. (18) and (36) theθnʼs explicitly occur in the decision function of the LR test even though have no interest for hidden information detection. The theoretical aspect of dealing with nuisance parameters for testing statistical hypothesis is discussed in [33, chap. 6]. An efficient and well-known approach consists of using the statistical theory of invariance. Application of optimal invariant tests for image processing has already been studied in [17,40].Let us note that the decision problem described in (45) remains “almost” invariant under the group of translationG:{g(zk)=zk+Hak}[10]; the word “almost” is here due to the quantization without which the invariance would be exact. Hence, it is proposed to use this invariance property to design a test close to the generalized LR test (GLRT) by using the “simplified” LRln(Λ˜(Z))replacing theθnby the estimateθˆk=(θˆk,1,…,θˆk,L)T(47) and the noise varianceσn2+Δ2/12by its estimationσˆk2(48). The proposed testδˆis thus given by:(49)δˆ={H0ifln(Λˆ(Z))=σ¯ˆK∑k=1Kln(Λˆ(zk))<τˆα0,H1ifln(Λˆ(Z))=σ¯ˆK∑k=1Kln(Λˆ(zk))⩾τˆα0,where the decision thresholdτˆα0is the solution ofsupθ∈ΘPH0[Λˆ(Z)⩾τˆα0]=α0to ensure thatδˆ∈Kα. By substituting in the LRln(Λ˜(Z))(36) the expectation and the variance of samples by their estimations, the GLRln(Λˆ(zk))is defined by:(50)ln(Λˆ(zk))=12σˆk2L−p∑l=1L(zk,l−z¯k,l)(Δzk,l−θˆk,l),whereθˆk,landσˆk2are respectively estimation of parameterθkandσk2given by Eqs. (47)–(48) and the termσ¯ˆis defined as:(51)1σ¯ˆ2=1K∑k=1K1σˆk2.Once again, it is proposed to study the probability of each error of the testδˆ(49) by applying Lindebergʼs CLT (19) in order to establish the asymptotic distribution ofln(Λˆ(Z)). To draw a meaningful comparison with the “simplified” LRln(Λ˜(Z))(36), let us defineϱˆas:(52)ϱˆ=K(L−p)RΔ2σ¯ˆ.Assuming thatθ∈Θ, a short algebra that is detailed in Appendix D, immediately permits us to establish that under the null hypothesisH0one has:(53)σ¯ˆK∑n=1Nln(Λˆ(zk))=Λˆ(Z)⇝N(0;1).Under the alternative hypothesisH1, the main difference with the calculations from Section 4 is that data hiding biases the estimated noise varianceσˆk2; in fact, a straightforward calculation permits us to verify that when Z contains information hidden with payloadR∈]0;1], then the mathematical expectation of estimatorσˆk2is:(54)E[σˆk2]=σk2+Δ212+RΔ22=σk2(1+Δ212σk2+RΔ22σk2).Taking into account the bias of noise variance estimator (54), it is shown in Appendix D, that under the alternative hypothesisH1the GLRΛˆ(Z)satisfies:(55)σ¯ˆK∑k=1kln(Λˆ(zk))=Λˆ(Z)⇝N(ϱˆ;1−γˆR),where:(56)γˆR=∑k=1KR2Δ24∑k=1K[σk2(1+Δ2/12σk2+RΔ2/2σk2)]−2∑k=1K[σk2(1+Δ2/12σk2+RΔ2/2σk2)]−1.The asymptotic distributions (53) and (55) of the GLRΛˆ(Z)permit us to calculate analytically the decision threshold that guarantees a false-alarm probability as well as the power function of the testδˆ.Theorem 5For anyα0∈]0;1[and for anyθ∈Θ, the threshold value given by(57)τα0=Φ−1(1−α0),guarantees that asymptotically, as N tends to ∞, the testδˆ(49)satisfiesαδ1=α0.Theorem 6For anyR∈]0;1], for anyα0∈]0;1[and for anyθ∈Θ, the power functionβδˆassociated with the testδˆ(49)is asymptotically, as N tends to ∞, given by:(58)βδˆ=1−Φ(Φ−1(1−α0)−ϱˆ1+γˆR).ProofThe proof of Theorems 5 and 6 are given in Appendix D.  □The comparison between the power function of the LRTβδ1(30) and the power function of the proposed GLR testβδˆ(58), shows that the loss of power of the latter is due to two phenomena. As illustrated in Fig. 4b, the main loss of optimality is due to the use of the parametric model (46) which reduces the number of “free parameter” fromN≈KLtoK(L−p).On the one hand, when p is small the loss of power due to the estimation of sample expectation is small as well. Unfortunately, the assumption that multimedia signals can be represented exactly by a sparse linear parametric model hardly holds true in practice. On the other hand, using a less sparse model with a larger p insure a rather accurate representation of multimedia signals. However, this implies a greater loss of power due the loss of more “free parameters”.This point highlights a general problem of all steganalysis methods which use an estimation or a “calibration” process to estimate cover content: a compromise has to be found between a sparse representation (to keep p small) and a good approximation (to avoid error in the estimation of the expectationθˆk).Note that to emphasize the two different factors of loss of power, the GLRT was performed without the noise estimation (so that the only loss of power is due to content estimation). The results obtained with this theoretical GLR are shown by light green lines in Figs. 4a and 4b.In addition it can be noted that the relative payload R impacts the power function of the proposed GLRT in two different manners. On the one hand, Eq. (55) shows that the variance of the GLR tends to decrease as the embedding increases. This phenomenon has a positive effect on the detection performance because a lower variance of the GLR under the hypothesisH1increases the power function. On the other hand, the definition ofϱˆ(52) shows that the mathematical expectation of the GLR does not linearly depend on R. In fact, the estimated mean variance of pixels increases with the payload R. Therefore, the expectation of the GLR increases fewer when the parametersσk2have to be estimated which causes a loss of power compared to the LRT.These two phenomena are shown in Figs. 4a and 4b. Fig. 4a presents a comparison between the distribution of the LRln(Λ)and the distribution of the GLRln(Λˆ). Similarly, Fig. 4b shows a comparison between LRT and GLRT power function as a function of false alarmβ(α0)(namely, the Receiver Operating Characteristic—ROC—curves). The results presented in Fig. 4b were obtained using 400 blocks of 32 samples which satisfy the polynomial model detailed in Section 6.1. The additive noise follows a zero-mean Gaussian distribution withσk={0.5Δ;2Δ}.In order to highlight the similarity between proposed LR tests and the WS detector [20,29], let us rewrite the LRln(Λ˜(Z))defined in Eq. (36), as follows:(59)σ¯KL∑k=1K∑l=1L1σk,l2(zk,l−z¯k,l)(Δzk,l−θk,l).normalization︷weights︷±1︷residuals︷Similarly the GLRln(Λˆ(Z))used in the testδˆ, see Eq. (50), can alternatively be written as follows:(60)σ¯ˆK(L−p)∑k=1K∑l=1L1σˆk2(zk,l−z¯k,l)(Δzk,l−θˆk,l).normalization︷weights︷±1︷residuals︷These two previous Eqs. (59) and (60) are very similar to the Weighted-Stego-image (WS) detector initially proposed in [20] as an estimator of the relative payload R and later deeply studied in [29]. The estimated payload provided by the WS can be written as follows:(61)w∑k=1K∑l=1L1wk,l(zk,l−z¯k,l)(zk,l−cˆk,l),normalization︷weights︷±1︷residuals︷wherecˆk,lis an estimation of cover pixel value based on a local auto-regressive filtering processcˆk,l=F(Z)k,landwk,l=(σˆk,l2+α)is a weight so that the influence of each pixel depends on the variance neighboring pixels. In the case of the WS, the normalization parameterw=∑k,lwk,lallows us to guarantee thatw∑k,l1/wk,l=1. Different values for α and different filters have been proposed and compared in [29].In comparison with the WS detector, this paper proposes two major novelties. First, the test is derived from the statistical theory of hypothesis testing (see Section 3). Hence, the weightswk,lare theoretically established and not heuristically chosen. Besides, the proposed methodology allows us to calculate analytically the statistical properties of proposed tests and proposed estimators. The same methodology can potentially be applied to a wider range of embedding scheme (a first step has been done in the use of proposed statistical methodology for LSB matching detection in [6,7,11]).Second, the estimatescˆk,lused in the WS (61) are replaced in decision functionΛˆ(Z)(50) by the estimatesθˆk,l, which physically describe the cover image content. It is thus expected that the proposed test has a higher detection performance than the WS and, more important, allows the decision to be taken independently of the expectation of samples considered as a nuisance parameter.Following the arguments given in [1,10,25,42], it was chosen to represent the expectation of samples—i.e. the two-dimensional structured image content—by modeling the expectationθwith a piecewise two-dimensional (2D) polynomial of order p. This model is applied by extracting non-overlapping blocks ofL×Lpixels from the inspected image. By denoting the expectation of pixels from the k-th blockθk={θk;l,m},l∈{1,…,L},m∈{1,…,L}, the 2D polynomial of order p can be written:θk;l,m=∑u=0p∑v=0pak;l,mlumv.By putting these blocks in vector ofL2components denotedθk, this model lead to the following parametrization(62)θk=Hak,H=(1,x,y,x⋅y,x⋅2,y⋅2,x⋅2⋅y,…,x⋅p⋅y⋅p)wherex⋅yandx⋅nrespectively represents the array product and array exponent, made component by component,1∈RL2is a column vector whose elements are ones,x∈RL2andy∈RL2are given by putting into column vectors the following matricesX=(1L2L⋯L−1L11L2L⋯L−1L11L2L⋯L−1L1⋮⋮…⋮⋮1L2L⋯L−1L1)andY=(1L1L⋯1L2L2L⋯2L⋮⋮⋮⋮L−1LL−1L⋯L−1L11⋯1)Fig. 5b presents results obtained from a Monte Carlo simulation with 105 realizations of proposed tests using the rather complex natural image shown in Fig. 5a. To model this image, an algebraic 2D-polynomial of orderp=2was used with block width ofL=4pixels. A zero-mean stationary Gaussian noise withσ=2.6Δwas added to the original image before each simulation; this corresponds to a typical case when quantization step is rather small compared to noise variance. Fig. 5b shows the empirical power function, numerically obtained, as a function of the number of pixel and for some values of prescribed false-alarm probability. The results shown in Fig. 5b emphasize one of the main advantage of the proposed test, the empirically obtained power function is very close the theoretical expected value given by (42) and (58).Though this paper focuses on digital images, the proposed methodology can potentially be applied to detect information hidden in any kind of digital media as long as a linear parametric model can represent accurately the expectation of each sample—that is the cover medium content. To enlarge the application of the proposed GLR test, Fig. 6presents the results obtained from a Monte Carlo simulation using an uncompressed WAV sound (a Doppler-record of in-utero baby heartbeat). Because the sound is a one-dimensional signal, a 1D-polynomial was used instead of the 2D-polynomial model (62) (see [9,8,50] for details on this model). Due to the rather simple content of such a sound, the size of blocks was set toL=32samples and a 1D-polynomial model of orderp=6was used. In this experimentation a stationary Gaussian noise withσ=0.52Δwas added to explore a case in which quantization impact is far from being negligible. In fact, Figs. 5b and 6 together emphasize the accuracy of the established power function when quantization step is negligible (whenσn≫Δ, Fig. 5b) as well as when the quantization is important (whenσn≪Δ, Fig. 6). Fig. 6a shows the power function of the proposed GLRT as a function of false-alarm probability (namely as a ROC curves) for different payloads R. Similarly, Fig. 6b shows the power function of proposed GLRT as a function of samples number and for different payloads R. These results highlight that the power function of proposed GLR test is very close to the theoretically established power, given in Theorem 4. Fig. 6 also shows that the loss of power due to quantization, precisely given by factorγˆRin Eq. (55), is rather important in the present case becauseσ=0.52Δ.To highlight the relevance of theoretical findings in practice, it was chosen to verify numerically that the proposed detection scheme allows the guaranteeing of a prescribed false-alarm probability. For a large scale verification of these results, it is proposed to use RAW images from BOSS contest database [2]. These images were converted in grayscale 16-bits color depth images using the software DCRAW (with command dcraw -j -v -D -4). Finally, non-overlapping images of512×512pixels were extracted from each (non-processed) color channel; this allows us to inspect images which all have the same size, and also allows us to increase the number of tested images. Note that it has been chosen to use RAW images (which are not processed at all after acquisition, see [39] for details) because the proposed Gaussian noise model (11) is especially accurate for such images; on the opposite the post-acquisition operations, such as demosaicing, white balancing, gamma correction and JPEG compression, can heavily change the distribution of pixels [46].Fig. 7shows a comparison between the empirical false-alarm probability of the proposed test as a function of decision thresholdτˆα0and the theoretical false-alarm probability, calculated from Eq. (53). These results were obtained using the 2D-polynomial model of pixels expectations (62) with orderp=2and block widthL=4andL=5pixels. However, it should be highlighted that some phenomena were omitted from proposed model (for instance quantizer saturation and hot/dead pixels). Therefore, Fig. 7 presents two different results for each block widthL=4andL=5pixels; one obtained by taking into account every pixels, and one by only taking into account the blocks for which the proposed model of both Gaussian noise (11) and 2D-polynomial model (62) holds. The selection of these blocks was made by adapting methodology proposed in [42] to identify blocks which can accurately be modeled by a 2D-polynomial model (62).It can be noted from Fig. 7 that the false-alarm probability of proposed GLRTδˆ(49) slightly differs from theoretical results for high detection threshold (typical corresponding to theoretical false-alarm probability ofα0=10−3). This phenomenon can be explained by the use of the CLT which does not permit us to get very accurate tail distribution of the GLR. Note also that some “outliers” pixels, typically dead and hot pixels, are excluded from this result because they do not follow the proposed Gaussian model.For comparing the performance of proposed GLRT, there is a wide range of steganalyzers that potentially could be used.It was chosen to use one of the leading competitors from structural detectors due to their known rather good performance. By using the Regular–Singular detector (RS) [21], the Sample Pair Analysis (SPA) [14] and the SPA Least Square Method (SPA-LSM) [34], it was empirically observed that the RS (with original mask, see [21]) and the SPA-LSM [34] obtained the best performance. Therefore these two steganalyzers were used for comparisons.It was also tried to use detectors based on decision theory such as the LRT based on i.i.d. pixels distributions [13], theχ2attack [48] or a recent improvement of this detector, namely the Generalised Category Attack (GCA) [32], and the AUMP test proposed in [8,9,16]. Only this last AUMP test exhibits a good detection performance during our experimentation. Hence, only the results of the AUMP test are presented in Fig. 10.Finally, as shown in Section 5.3, the expression of proposed GLR is very similar to Weighted-Stego steganalysis (WS) [20]. In addition the WS steganalysis is known to be one of the most efficient steganalyzers dedicated to LSB replacement. Therefore, the improved WS detector proposed in [29] is included in numerical comparisons.33The Matlab source code of RS, AUMP and WS steganalyzers can be downloaded from the website of the DDE (Digital Data Embedding) Laboratory: http://dde.binghamton.edu/download/.Note that it was chosen not to include blind steganalyzers in comparisons. In fact, the main goal of the present article is to design a test with analytically established properties, in order to guarantee a prescribed false-alarm probability, which seems currently out of reach of any supervised learning based steganalysis method.It should also be noted that the use of the estimated variance of pixels in the proposed GLRT is difficult; in fact for most images a very small number of pixels have an estimated variance equals to zero, typically in overexposed areas. Hence, it is proposed to insure that each block has a minimal variance ofσˆk=0.1. The blocks for which estimated variance verifyσˆk<0.1were normalized to set their variance to the acceptable minimum. This empirical rule is similar to the weighting coefficients proposed for WS steganalysis in [20,29], see also Eq. (61), which have been shown to increase the empirical power function.Fig. 8shows a comparison of the power function of the chosen detectors as Receiver Operational Characteristics (ROC) curves. Those results are obtained from RAW images of the BOSS database with payloadR=0.025. For this image database, the proposed GLRT is used with a 2D-polynomial model of orderp=2and two different block width ofL=4andL=5pixels. Though a more accurate model of image content might be used instead of the 2D-polynomial (62), the results shown in Fig. 8 clearly shows that proposed GLRT performs much better than the state-of-the-art competitors. Note that Fig. 8 also shows the theoretical power function of proposed GLRT obtained from Eq. (58) using blocks variance estimation (47) obtained with block widthL=4. It can be observed that the power function of the proposed GLRT is very close to the theoretically established power; the small loss of power can be explained by the block variance threshold and by the use of all pixels blocks while, as previously discussed, the Gaussian model might be not very accurate for all of them.Let us recall that the use of RAW images from BOSS database permits us to obtain results for the case when quantization is rather negligible compared to the noise variance,σn≫Δ. Hence, to complete the numerical provided in Figs. 10 and 8 numerical results on 8 bit images are provided in Fig. 9. Once again, in Fig. 9, the performance of the different detectors is compared through ROC curves and the same two implementations of the proposed GLR test, withL=4andL=5, are used. Note that for the case of 8 bit images, a smaller relative payload ofR=0.01because, even though the quantization has a larger impact, the detection is easier when the ratioΔ/σincreases. Finally, it can be noted from Fig. 9 that the proposed GLR test performs better than its competitors. More interestingly, it can also be noted that the AUMP test is outperformed by the WS detector. This is not surprising because the AUMP detector has been designed for the case whenΔ/σtends to 0 which not holds true for 8 bits images.Figs. 10a and 10b present a numerical comparison of the power function of the chosen detectors; those results are obtained using the same RAW images from BOSS contest database [2]. Again, these images are converted in grayscale 16-bits color depth images and all crop to size512×512pixels. Results shown in Fig. 10a are obtained with a relative payloadR=0.05; this allows us to show that the proposed GLRT still performs much better than its competitors for higher payloads R. Note that, due to their low detection performance and for a better readability, it has been chosen to remove the RS and SPA-LSM detectors from Figs. 10a and 10b.Similarly, Fig. 10b shows the power function of the same steganalyzers for relative payloadR=0.10. The use of a log–log scale allows us to show that for very small false-alarm probability, the WS (with our without bias correction) performs much worse that the other detectors. On the opposite, the AUMP test performs rather well for small false-alarm probability but still has a much lower power function than the proposed GLRT. This phenomenon can be explained by the fact that AUMP test is based on a rather simplistic 1D model of natural image content which is not very accurate for large segment size (while the author of [16] suggest a segment size of 16 pixels). In fact, even though the AUMP detector is relevant for 16 bits images, the error of modeling caused by such a naive model largely impacts this detector for a small set of images.

@&#CONCLUSIONS@&#
This paper is a first step made to apply hypothesis testing theory for the detection of hidden information. The problem of detecting hidden information in the LSB of quantized samples is formally stated and studied with the three following goals. First, taking carefully into account quantization impact, the most powerful LR test is designed in the ideal settings of known samples distributions. The statistical properties of this test are analytically established. This test serves as an upper bound for the power function one can expect from any detector and highlights the significant impact that the quantization of samples might have. Second, the content of inspected medium is explicitly considered as a nuisance parameter modeled by a piecewise linear parametric model. Finally, in a practical context of hidden data detection, it is very important to provide the proposed test with a guaranteed false-alarm probability. Hence, thanks to the precise study of quantization impact and to the linear parametric image model, the statistical properties of the proposed GLR test are asymptotically established. This allows the guaranteeing of a false-alarm probability and to show that the loss of optimality, compare to the optimal LRT, is small.Focusing on digital images, it is shown that the proposed test is close to the well-known Weighted-Stego (WS) detector. Numerical results on a large image database show the relevance of the presented approach to guarantee a false-alarm probability and to detect hidden data with a higher power function than state-of-the-art steganalyzers.A possible future work, which is out of the scope of this paper, is the exploitation of a more accurate image model. Natural images are usually preferred media for information hiding and the use of a specific model which takes into account properties of images is expected to increase the performance of the proposed test. Similarly, the proposed methodology, based on hypothesis theory, could be applied to detect other information hiding schemes by designing tests with known statistical properties.For readability, it is proposed to sketch a proof of Remark 2 first; the next appendices are devoted to the study of LR and GLR statistical study and demonstration of proposed theorems.In Remark 2 it is stated that the heteroscedastic properties helps the steganalyzer in the sense that for a given payload R, and for a given quantization step Δ, the INR ϱ(39) is minimal when all the samples have the same variance (43):(A.1)σ¯2⩽1N∑n=1Nσn2(1+Δ212σn2)⇔1σ¯2⩽N(∑n=1Nσn2(1+Δ212σn2))−1.By using the definition ofσ¯(35) the above equation becomes:1σ¯2=def.1N∑n=1N[σn2(1+Δ212σn2)]−1.For readability, let us define:sn=σn2(1+Δ212σn2)⩾0,in order to rewrite Eq. (A.1) as:1N∑n=1Nsn−1⩽N(∑n=1Nsn)−1⇔(∑n=1Nsn−1)(∑n=1Nsn)⩽N2.Let us defines=(s1,…,sn)andf(s)=(∑n=1Nsn−2)(∑n=1Nsn2); by solving∂f(s)∂sn=0one has:{∑j=2Nsj+(∑j=2Nsj−1)−1=s1,…,∑j≠nsj+(∑j≠nsj−1)−1=sn,…,∑j=1N−1sj+(∑j=1N−1sj−1)−1=sN.Solving these equations lead to find thatf(s)admits a minimum ofN2which is reached whens1=s2=⋯=sn, which ends the proof of Remark 2.The main goal of this appendix is to provide a demonstration of Proposition 1 and Theorems 3 and 4. These proof are divided in three steps. First, Appendix B provides a detailed calculation of the momentsln(Λ1(zn)). Then, Appendix C provides a demonstration of Proposition 1. Eventually, the demonstrations of Theorems 3 and 4 are detailed in Appendix C.2.Let us remind the expression (18) of the LRln(Λ1(zn))(9):ln(Λ1(zn))=Δ(zn−z¯n)(Δzn−θn)2σn2−Δ28σn2+op(Δ2σn4).Neglecting the termo(Δ2/σn4), it obviously suffices to calculate the moments of the term(zn−z¯n)(Δzn−θn)asΔ/2σn2is a constant “scale factor”.Under the hypothesisH0, one hasμ0=−Δ28σn2+Δm0(θn)2σn2, where(B.1)m0=m0(θn)=EH0[(Δzn−θn)(zn−z¯n)]=∑k∈ZΔ(2k+1)−θnσn∫Δ(2k+12)Δ(2k+32)ϕ(x−θnσn)dx−∑k∈Z2kΔ−θnσn∫Δ(2k−12)Δ(2k+12)ϕ(x−θnσn)dx.Similarly, denoting that∀zn∈Z,(zn−z¯n)2=1, the varianceσ02is given by:σ02=def.EH0[ln(Λ1(zn))2]−μ02=Δ24σn4EH0[(Δzn−θ)2−Δ2(Δzn−θ)(zn−z¯n)+Δ216]−Δ482σn4−Δ2m024σn4+Δ3m08σn4=Δ24σn4(EH0[(Δzn−θn)2]−m02)=Δ24σn4(−m02+∑k∈Z(kΔ−θn)2σn∫Δ(k−12)Δ(k+12)ϕ(x−θnσn)dx).The expectationμ1can easily be calculated with assumption A-1, that hidden stego-bits{0;1}are uniformly distributed, which gives from (18):(B.2)EH1[(Δzn−θn)(zn−z¯n)]=12EH1[Δzn−θn|zn−z¯n=1]−12EH1[Δzn−θn|zn−z¯n=−1]=12EH0[Δzn−θn]+14(EH0[Δzn−θn+Δ]−EH0[zn−θn−Δ])=Δ2.From which one gets the result (22):μ1=−Δ28σn2+Δ24σn2=Δ28σn2.Eventually, the varianceσ12can be calculated by denoting that∀zn∈Z,(zn−z¯n)2=1as follows:σ12=def.EH1[ln(Λ1(zn))2]−μ12=Δ24σn4EH1[(Δzn−θ)2−Δ2(Δzn−θ)(zn−z¯n)+Δ216]−Δ482σn2,whereEH1[(Δzn−θn)2]=12EH0[(Δzn−θn)2]+14(EH0[(Δzn−θn−Δ)2]−EH0[(Δzn−θn+Δ)2])=EH0[(Δzn−θn)2]+Δ22,which, together with (B.2), permits the writing of:(B.3)σ12=Δ24σn4(EH0[(Δzn−θn)2]+Δ24).The proof of Theorems 3 and 4 is divided in three steps. First, Appendix C.1 proves the results from Proposition 1. Then Appendix C.2 establishes the asymptotic distribution of LRln(Λ˜(Z)). Finally the demonstration of Theorems 3 and 4 is given in Appendix C.3.Reminding that the quantizer saturation effects are neglected in this paper, it can be noted, from Eq. (B.1), thatm0(θn)=−m0(θn+Δ). Reminding thatζnis defined as followsζn∈[−Δ;Δ],ζn=θn−Q2Δ(θn)and thatNx0,x1,x0<x1,{n,ζn∈[x0,x1]}, represents the number of samples which verifyζn∈[x0;x1]. It follows from the parity properties ofm0(ζn)and Riemann theorem that:limC→∞h∑c=1Cm0(−Δ+ch)N(c−1)h,ch=∫−ΔΔm0(ζn)dζn=0withh=2ΔC. Hence, when the observed samples are not i.i.d. and assumption A-3 holds, the mean expectation of LR, see Eq. (27) is given underH0by:(C.1)μ˜0=limN→∞1N∑n=1NEH0[ln(Λ1(zn))]=limN→∞1N∑n=1N−Δ28σn2+m0(θn)−∑n=1NΔ28σn2+2Δ∫−ΔΔm0(ζn)dζn=−∑n=1NΔ28σn2.In a similar fashion, it and Eq. (23) that using assumption A-3:σ˜02=limN→∞1N∑n=1NVarH0[ln(Λ1(zn))]=limN→∞1NΔ24σn4(EH0[(Δzn−θn)2]−m02).Taking into account assumption A-3 allows us to establish [44,49]:limN→∞1N(EH0[(Δzn−θn)2])=∑n=1Nσn2(1+Δ212σ¯2),while on the other hand the term:limN→∞2ΔN∑n=1Nm0(ζn)2=∫−ΔΔm0(ζn)2=o(Δ2σ¯2).Under the hypothesisH1, Eq. (B.2) clearly shows thatμ1does not depend onθn; it immediately follows from definition (35) of the “simplified” LRln(Λ˜1(zn))that:(C.2)μ˜1=∑n=1NΔ28σn2.Finally, the varianceσ˜12can be immediately deduced from Eqs. (23) and (B.3) that:(C.3)σ˜12=limN→∞1N∑n=1NΔ24σn4(EH0[(Δzn−θn)2]+Δ24)=∑n=1NΔ24σn2(1+Δ212σn2)+o(Δ4σ¯4).From results of Appendix C, it immediately follows from the law of total expectation that for any payloadR∈]0;1]the expectation ofln(Λ1(zn))is given by:(C.4)μ˜R=(1−R)μ˜0+Rμ˜1=1N∑n=1NΔ2(2R−1)8σn2.Likewise, the law of total variance permits the writing of:(C.5)σ˜R2=(1−R)(μ˜02+σ˜02)+R(μ˜12+σ˜12)−((1−R)μ˜0+Rμ˜1)2=1N∑n=1NΔ24σn2(1+Δ24σn2(2R−R2)+Δ212σn2)+o(Δ4σ¯4).Reminding that the “simplified” LRln(Λ˜(Z))is defined as (36):ln(Λ˜(Z))=def.Δσ¯N∑n=1N(zn−z¯n)(Δzn−θn)σn2(1+Δ2/12σn2)=2σ¯N∑n=1N[ln(Λ1(Z))−μ˜0](1+Δ2/12σn2).It immediately follows from the previous results (C.1)–(C.5) that the moments ofln(Λ˜(Z))are given by:(C.6)EH0[ln(Λ˜(Z))]=0,VarH0[ln(Λ˜(Z))]=[σn2(1+Δ212σn2)]−1,EHR[ln(Λ˜(Z))]=RΔ2[σn2(1+Δ212σn2)]−1,VarHR[ln(Λ˜(Z))]=[σn2(1+Δ212σn2)]−1+[σn2(1+Δ212σn2)]−2Δ24(2R−R2).Finally, from the definition ofσ¯(35):1σ¯2=def.1N∑n=1N[σn2(1+Δ212σn2)]−1,and Lindebergʼs CLT (19) it holds that under assumption A-3, one has:(C.7){σ¯N∑n=1Nln(Λ˜(zn))⇝N(0;1)underH0,σ¯N∑n=1Nln(Λ˜(zn))⇝N(NRΔ2σ¯;1+γR)underH1,whereγRis given in (38) and from (39)NRΔ2σ¯=ϱ.It follows from Eq. (C.7), that for a given decision threshold τ the probability that under null hypothesisH0the LRln(Λ˜(Z))exceeds τ is given by:α0(τ)=1−Φ(τ),using the Gaussian inverse cumulative distribution functionΦ−1(⋅)it follows that the decision thresholdτα0which asymptotically, as N tends to ∞, thatδ˜∈Kα0is given by:τ˜α0=Φ−1(1−α0).This ends the demonstration of Theorem 3.Similarly, for a given decision threshold τ the probability that under the hypothesisHRthe LRln(Λ˜(Z))exceeds τ is given by:β(τ)=1−Φ(τ−ϱ1+γR).Replacing the decision threshold τ with the valueτ˜α0one hasβδ˜=1−Φ(Φ−1(1−α0)−ϱ1+γR),which ends the demonstration of Theorem 4.The demonstration of Theorem 5 and 6 is divided in two steps. First, Appendix D.1 studies the properties of ML estimationsθˆkandσˆk2and then establishes the asymptotic distribution of proposed GLRln(Λˆ(Z)). Then, the demonstration of Theorems 5 and 6 is given in Appendix D.2.Let us first recall that the observationszkare defined aszk=QΔ(yk)withyk∼N(Hak,σk2I). It is well known that ifyk∼N(Hak,σk2I)then the ML estimators of the expectationθk=Hakand varianceσk2are:θˆk=PHykwithPH=H(HTH)−1HT,σˆk2=Δ2L−p|PH⊥yk|22withPH⊥=IL−PH.In addition, under the hypothesisH0ifyk∼N(Hak,σk2I), then it holds true that:∑l=1Lyk,l−θˆk,l∼N(0,σk2trace(PH⊥))and‖PH⊥yk‖22σk2∼χL−p2,wheretrace(PH⊥)=L−pandχL−p2represents the (central) chi-squared distribution withL−pdegree of freedom. Hence the ML estimators verify:σˆk2=Δ2L−p|PH⊥yk|22∼Γ(L−p2,2σk2L−p),whereΓ(k,θ)represents the gamma distribution with shape parameter k and scale parameters θ.However, the observationszk=QΔ(yk)are quantized in practice. In such a situation, the exact distributions of expectationθˆkand varianceσˆk2are difficult to establish. Nevertheless, it can be shown [44,49] that the two first moments of those distributions are given, under assumption A-3, by:EH0[∑l=1Lzk,l−θˆk,l]=0;VarH0[∑l=1Lzk,l−θˆk,l]=σk2+Δ212;EH0[σˆk2]=σk2+Δ212;VarH0[σˆk2]=2L−pσk4+Δ212.Therefore it immediately follows from the Delta method [33, Theorem 11.2.14] that under the hypothesisH0:EH0[∑l=1Lzk,l−θˆk,lσˆk]=0;VarH0[∑l=1Lzk,l−θˆk,lσˆk]=L−pσk2+Δ212.Hence it finally follows from the previous calculations (C.1)–(C.3), from the definition ofσ¯ˆ(51):1σ¯ˆ2=1K∑k=1K1σˆk2and from Slutskyʼs theorem [33, Theorem 11.2.11] that under the hypothesisH0:(D.1)ln(Λˆ(Z))=σ¯ˆK∑k=1Kln(Λˆ(zk))∼N(0;1).On the opposite, under the hypothesisH1, the two first moments of estimated expectationθˆkand varianceσˆk2are given by:EHR[∑l=1Lzk,l−θˆk,l]=0;VarH0[∑l=1Lzk,l−θˆk,l]=σk2+Δ212+RΔ22;EHR[σˆk2]=σk2+Δ212+RΔ212;VarH0[σˆk2]=2L−pσk4+Δ212+RΔ22.Therefore it immediately follows from the Delta method [33, Theorem 11.2.14] that under the hypothesisH1:EH0[∑l=1Lzk,l−θˆk,lσˆk]=0;VarH0[∑l=1Lzk,l−θˆk,lσˆk]=L−pσk2+Δ212+RΔ22.Hence it finally follows from the previous calculations (C.1)–(C.3), from the definition ofσ¯ˆ(51) and from Slutskyʼs theorem that under the hypothesisH1:(D.2)ln(Λˆ(Z))=σ¯ˆK∑k=1Kln(Λˆ(zk))∼N(ϱˆ;1−γˆR),whereϱˆandγˆRare respectively defined in Eqs. (52) and (56).The demonstration of Theorems 5 and 6 immediately follows from the results (D.1) and (D.2). First, from the asymptotic distribution ofln(Λˆ(Z)), given in Eq. (D.1) it immediately follows that for any prescribed false-alarm probabilityα0, the decision threshold given by:(D.3)τα0=Φ−1(1−α0),asymptotically guarantees thatPH0[ln(Λˆ(Z))>τα0]=α0. The result (D.3) is straightforward using the proof of Theorem 1 and proves Theorem 5.Then, using the decision threshold given in Eq. (D.3), it follows from the properties of Gaussian random variables that the power function of the GLRTδˆ(Z), defined in Eq. (49), is given by:(D.4)βδˆ=1−Φ(Φ−1(1−α0)−ϱˆ1+γˆR),which ends the proof of Theorem 6.