@&#MAIN-TITLE@&#
Volume visualization based on the intensity and SUSAN transfer function spaces

@&#HIGHLIGHTS@&#
A novel 2D IS transfer function space for distinguishing different materials have been proposed.Boundary of different materials exhibits as a ‘trapezoid’ shape in the proposed space.Boundary information in the IS space is much better brought out in comparison to the IGM space.The IS space provides much more intuitive suggestions than the IGM space in order that transfer functions can be more easily designed.The proposed approach can be used to explore various medical volume data.

@&#KEYPHRASES@&#
Direct volume rendering,Transfer function,3D SUSAN algorithm,Volume visualization,

@&#ABSTRACT@&#
Designing transfer functions is a challenging task for medical volume data visualization, especially when an arch of the same boundary disperses seriously and adjacent arches are intersected in the intensity and gradient magnitude (IGM) transfer function space. In this paper, a novel transfer function space is proposed to better highlight and differentiate different materials in realistic volume datasets. The proposed method combines the intensity values and three-dimensional (3D) SUSAN (Smallest Univalue Segment Assimilating Nucleus) edge responses of the original data to define the intensity and SUSAN (IS) transfer function space. The results of various datasets in volume rendering show that boundary of different materials exhibits a trapezoidal shape in the proposed IS space, and boundary information is much better brought out in comparison to the IGM space. Thus the IS space provides much more intuitive clues than the IGM space in order that transfer functions can be more easily designed. Meanwhile, more details of materials of interest are visible in the rendering images.

@&#INTRODUCTION@&#
With many state-of-the-art imaging modalities used in medicine (e.g., computed tomography (CT) and magnetic resonance imaging (MRI)), a great number of medical volume datasets are being obtained (Fig. 1(a)). Thus there is an urgent need to provide useful methods for identifying structures of interest and obtaining meaningful visualizations of anatomical structures (Fig. 1(b)). A variety of algorithms have been proposed to identify and segment anatomical structures in different volume datasets [1,2] and some rendering techniques are used to render segmented structures [3–5].Direct volume rendering has been proven to be a more useful technique to explore and visualize structures of interest and reveal hidden interesting organs in medical volume data [6,7]. Users can not only easily understand boundary information from the transfer function spaces, but also intuitively design transfer functions while observe 3D visualizations according to adjusted transfer functions (Fig. 1(c)). Therefore, transfer function is a critical element in direct volume rendering. By designing different transfer functions which assign optical properties (e.g., color and opacity) to each voxel, different anatomical structures in volume data can be visualized and distinguished by ray casting algorithms [5,8]. In most cases, no prior information can be available in the volume data, which makes feature selection in the transfer function space become a trial-and-error process. Consequently, an effective transfer function space which can help users to easily distinguish and identify useful features, is necessary and beneficial to get desirable renderings.The transfer function space is defined by using the intensity value or other attributes of the original volume data. As one-dimensional transfer function space [5,9] solely uses intensity values to enhance structures of interest, all voxels having the same intensity values are rendered by the same optical properties which are assigned by transfer functions, no matter whether they belong to the same structure. To discriminate those voxels, multi-dimensional transfer function spaces have been proposed, which use additional properties. In particular, two-dimensional (2D) IGM transfer function space (as shown in Fig. 2(b)) has been proposed to discern features of interest and extract material boundaries [6,10]. In this approach, boundaries of different materials having large gradient values are shown as arches in the space and they are different from homogeneous regions having small gradient values in the space (Figs. 4(b) and 11(f)). Therefore, boundaries of structures of interest can be enhanced by using transfer functions to assign bigger opaque values than interior voxels. Even users can set the opaque values of those interior voxels to zero to eliminate the influence of these undesirable tissues. By utilizing interaction manipulation widgets to select arch shapes [6] (as shown in Figs. 3(c) and 10(d)), transfer functions can be designed by users and used to assign different optical properties to different anatomical structures (Figs. 3(d) and 10(b)). Unfortunately, for realistic volume data, dispersed arches of the same boundary (Figs. 10(d) and 11), incomplete arch of different materials (Figs. 2(b) and 8(a)) and lost arch information (Fig. 4(b)) often occur in the IGM space. As a result, it is difficult for users to design appropriate transfer functions and distinguish structures of interest.Chen et al. [11] tried to use information theory to explain many existing visualization techniques and use it as a theoretic framework for visualization. Roettger et al. [12] added spatial information into the IGM space by deriving the color for easier classification. Wang et al. [13] modeled the IGM space using the Gaussian mixture model to automatically separate initial features. Marks et al. [14] simplified the transfer function's design process by selecting the most proper rendering results from design galleries. Maciejewski [7] defined abstract feature space with a set of metrics derived from the spatial and feature space domains. Park and Bajaj [15] introduced stretched histogram to distinguish overlapping features. Serlie et al. [16] introduced an arch edge model and modeled the neighborhood of sample points by an arch trajectory which makes the technique against erroneous classification resulting from noise. Correa and Ma [17] described feature size using the relative size of each voxel and mapped it to optical parameters. Wesarg et al. [18] derived the size of anatomical structures from volume data by using a threshold-based voxel counting technique and used it as a second property.Marchesin et al. [19] presented the per-pixel-modulated rendering to enhance feature visibility. Wu and Qu [20] proposed a framework for editing resulting images, in which users could directly edit features in rendering images and interactively design transfer functions. Chan et al. [21] rendered images by optimizing the rendering parameters based on visibility, shape, and transparency measures to comply with users’ perception. Ruiz et al. [22] presented an approach to automatically design transfer function.How to visualize more internal structures is one of the most important problems in direct volume rendering. Visibility-based transfer function space was introduced by Correa and Ma [23] to maximize the visibility of interesting features. By using LIDA accumulation [24], more details of the volume data are rendered. Correa and Ma [25] introduced an occlusion spectrum to separate structures in volume data, which encodes the 2D distribution of intensity values and occlusion. Viola et al. [26] introduced the importance-driven feature enhancement approach for automatic focus+context volume rendering. Praßni et al. [27] presented a novel shape-based classification technique for volume visualization by which users distinguished features based on 3D shape and assigned different optical properties to them.Smith and Brady [28] used a completely new definition of edges and proposed the SUSAN algorithm. Owing to its property of structure preserving and noise reduction, the algorithm has been applied to various image vision problems. Marusic et al. [29] applied the SUSAN algorithm to reduce coding artifacts in wavelet video-coding. Mao et al. [30] extended the SUSAN operator to denoise 3D meshes. Claus et al. [31] optimized the SUSAN algorithm by a high speed FPGA implementation. Yu et al. [32] introduced the SUSAN detectors to guide diffusion process, and created the SUSAN-controlled anisotropic diffusion model for speckle reduction and detail preservation.Partial-volume effect (PVE) resulting from the mixture of intensities of voxels belonging to different regions can make boundaries become blurred and exacerbate the ability to recognize ‘arch’ shapes in the IGM space (the x axis represents intensity, the y axis gradient magnitude) (see Fig. 2(b)). The presence of noise in volume data is a typical phenomenon in realistic circumstances, which results in variations of the intensity values around an average value and multiple arches for the same boundary in the IGM transfer function space as shown in Fig. 10(d). Therefore, it is difficult to discern boundary information of interesting structures in the IGM space, especially when different arches are intersected (yellow window in Fig. 3(c)). As a result, anatomical structures of interest cannot be easily explored and visualized just using the 2D IGM transfer function space.Therefore, in this paper, we address these problems by introducing a new IS transfer function space. By combining intensity value of the original data and 3D SUSAN edge responses of each voxel, the IS transfer function space is created, in which boundaries of different materials represent ‘trapezoid’ shapes and boundary information is much better brought out (Figs. 2(a) and 10(c)). Thus the IS space provides much more intuitive suggestions than the IGM space and transfer functions can be more easily designed. Also, we can obtained more details of materials of interest (Figs. 3(b), 8(c) and 11(c)).

@&#CONCLUSIONS@&#
