@&#MAIN-TITLE@&#
On the relevance of sparsity for image classification

@&#HIGHLIGHTS@&#
We investigate the role of sparsity in unsupervised filter learning.We consider the image categorization and pixel classication tasks.We show that sparsity constraints are not needed at run-time.This significantly reduces the time required to compute an image descriptor.

@&#KEYPHRASES@&#
Sparse representations,Image descriptors,Image categorization,Pixel classification,

@&#ABSTRACT@&#
In this paper we empirically analyze the importance of sparsifying representations for classification purposes. We focus on those obtained by convolving images with linear filters, which can be either hand designed or learned, and perform extensive experiments on two important Computer Vision problems, image categorization and pixel classification. To this end, we adopt a simple modular architecture that encompasses many recently proposed models.The key outcome of our investigations is that enforcing sparsity constraints on features extracted in a convolutional architecture does not improve classification performance, whereas it does so when redundancy is artificially introduced. This is very relevant for practical purposes, since it implies that the expensive run-time optimization required to sparsify the representation is not always justified, and therefore that computational costs can be drastically reduced.

@&#INTRODUCTION@&#
Sparse image representations are at the heart of many modern approaches to classification, such as [1–4]. Some neurophysiological evidence [5,6] supports their presence in the human visual cortex. Although this evidence is still in dispute [7], the fact that sparsity constraints can be used to derive filters exhibiting a structure very close to that of receptive fields in V1 [8,9] has played a major role in their widespread acceptance.On a more practical note, the usefulness of sparsity for image processing purposes is widely recognized [10,11,4] along with its suitability as a regularizer for general inverse problems [12]. Part of the appeal of sparse representations is that they are believed to be easily separable in high-dimensional spaces [1,13,14]. They have also been successfully used for classification and shown to improve performance in specific cases [15].In this paper, we will show that the reported classification performance increases [15] stem from the specific setup in which the experiments were performed and that, under different experimental conditions, they do not materialize. More specifically, we will demonstrate that in a shallow recognition architecture and when using convolutional features [16,17] that rely on the now classic functional proposed by Olshausen and Field [9], no gain arises from sparsifying the representations prior to classification. Similar or better results are obtained by directly feeding the features to a classifier. In this setup, sparsity remains key to learning effective features but becomes unnecessary at run-time. By contrast, if we replace the convolutional features by features derived from overlapping patches, which introduce additional redundancy, run-time sparsity helps as reported in [15].This analysis validates in a systematic manner casual observations about convolutional architectures that appeared in the literature over the years [1,18]. It also has important practical consequences since eliminating the run-time sparsifying step can result in substantial computational savings and markedly increase the size of the problems that can be handled. This is because sparsifying remains computationally expensive, even though many recent efforts [19–21], driven in part by the needs of the Compressed Sensing community [22,23], have produced efficient algorithms.In this paper we operate in the context of two key Computer Vision tasks, image categorization and pixel classification. While these two problems might seem only loosely related, state-of-the-art solutions to both involve computing image descriptors either at given locations or densely, post-processing them, and performing a final classification step.This work extends the investigations performed in [16] by comparing our results with related studies available in literature, in particular [15]. Moreover, the inclusion of the pixel classification task in our analysis allows us to validate our claims in two different settings, thus helping us to discount domain-specific biases.Our investigation relies on the modular classification pipeline depicted by Fig. 1, which is designed to encompass representative state-of-the-art methods and to allow for comparisons. In the following section we briefly review these methods. We then describe and analyze our experiments in the fields of image categorization and pixel classification.

@&#CONCLUSIONS@&#
We performed an in-depth analysis of the role of sparsity for image categorization and pixel classification. The consistency of our results for these two very different tasks suggests that sparsity is essential to learn effective filter banks at training time but that enforcing it at run-time is not particularly useful in convolutional architectures, at least when the level of noise remains reasonable. On the other hand, sparsity turns out to be important when redundancy is either introduced (e.g., by extracting features on overlapping patches) or already present in the data (e.g., by considering strongly correlated image channels). Given the high computational burden involved in the enforcement of sparsity, these findings should be taken into account when building actual recognition systems designed to work on large images.One weakness of our approach is that, since the filters are not separable, the convolutions are difficult to compute very efficiently, and generalizing this approach to cubes of data as opposed to images as in [50] would be prohibitively expensive. Future work will therefore focus on optimizing the filters so that this difficulty can be overcome.Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cviu.2014.03.009.Supplementary data 1