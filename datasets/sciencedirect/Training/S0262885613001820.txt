@&#MAIN-TITLE@&#
A measure of information gained through biometric systems

@&#HIGHLIGHTS@&#
We propose an information theoretical measure for biometric systems.We present several useful properties and interpretations of the measure.We prove that the measure can be approximated by the relative entropy.We discuss how to evaluate the measure and show experimental evaluations.

@&#KEYPHRASES@&#
Biometrics,Entropy,Mutual information,Relative entropy,Divergence,

@&#ABSTRACT@&#
We propose a measure of information gained through biometric matching systems. Firstly, we discuss how the information about the identity of a person is derived from biometric samples through a biometric system, and define the “biometric system entropy” or BSE based on mutual information. We present several theoretical properties and interpretations of the BSE, and show how to design a biometric system which maximizes the BSE. Then we prove that the BSE can be approximated asymptotically by the relative entropy D(fG(x)∥fI(x)) where fG(x) and fI(x) are probability mass functions of matching scores between samples from individuals and among population. We also discuss how to evaluate the BSE of a biometric system and show experimental evaluation of the BSE of face, fingerprint and multimodal biometric systems.

@&#INTRODUCTION@&#
Biometric identification systems, which automatically identify a person based on his/her physical or behavioral features, are widely used for various applications. To be used for personal identification, the biometric features are desired to satisfy the following requirements.1.Uniqueness: Biometric feature has to be unique to each individual.Stability: Biometric feature has to be unchangeable for each capture.However most biometrics do not strictly satisfy these requirements, because of the following reasons. Even if feature data are extracted from the same body part of a person, they vary with each capture due to aging, position errors, distortion, measurement errors, environmental noise, and many other factors. These factors make it hard to satisfy the stability. Thus, it is general to consider that two features match when they are similar enough to each other, even if not exactly the same. However this fuzziness causes false matches of features extracted from different bodies; the requirement of uniqueness is also hardly to be satisfied.Since these requirements are hard to be satisfied strictly for most biometric modalities (e.g., fingerprints, faces, vein patterns, irises, and so on), biometric systems inevitably make errors in identifying persons. Therefore it is important to evaluate the identification performance of biometric systems quantitatively.Two kinds of error rates are widely used to evaluate the performance: false match rate (FMR) and false non-match rate (FNMR). FMR is a probability that two feature data extracted from different bodies match, and FNMR is a probability that two feature data from the same person do not match. There is a trade-off between these error rates depending on a threshold parameter t, which is described by a 2-D curve parametrized by (FRT(t),1−FNMRT(t)), called ROC (receiver operating characteristic) curve [2]. Though the ROC curve describes the identification performance precisely, it is not straightforward to understand the ROC curve intuitively or to compare some biometrics with other method such as PIN code by using the ROC curve.On the other hand, there has been some efforts to define and evaluate the individuality of biometrics from the viewpoint of information content or entropy [3–5]. Entropy as a measure of identification performance has the potential to make it possible to compare a certain biometrics (e.g. fingerprints) not only with another biometrics (e.g. irises) but also with PIN, passwords, and many other authentication methods. It has also the potential to enable us to quantify the degree of privacy of biometrics and compare it with other personal identification information such as name, address, birthday, etc. However, no common measure or methodology to evaluate the biometric entropy have been established so far which could be practically applicable to any kind of biometrics.In this paper, we propose a measure of personally identifying information gained through biometric matching systems, and discuss a methodology of evaluation applicable to any kind of biometrics.This paper is an extension of a previously published conference paper [1]. The main enhancements are as follows:1.We discuss the relation between the BSE and the password entropy [6,7] and clarify that both are special cases of a measure of personal identification information defined based on mutual information (Section 3). This clarifies the fact that the BSE can make it possible to compare biometrics with other personal identification information such as names, addresses and PINs.In [1], we showed some information theoretical and statistical properties of the relative entropy D(fG∥fI) between a genuine score distribution fGand an impostor score distribution fI, which is the asymptotic approximation of the BSE. In this paper, we present stronger results: we directly show the properties of the mutual information I(U;X) between the user identity U and the set of scoresX, which is the original definition of the BSE, instead of the approximated version (Section 4). These properties clarify the information theoretical and statistical meaning of the BSE more directly.We show a relation between the BSE and the lower bound of the identification error probability or the Bayes error. The relation indicates that a biometric matching system with larger BSE has potential to achieve lower identification error (Section 4.4).We prove an interesting fact that the maximum of the BSE with respect to a biometric matching system is equal to the Adler's biometric information (BI) of a system [4]. Furthermore we show how to design a biometric matching system so that the BSE achieves the BI of a system (i.e. the maximum value) (Section 5).In [1], we showed that the BSE is asymptotically approximated by D(fG∥fI). In this paper, we additionally proved that D(fG∥fI) also gives a minimum upper bound of the BSE for a fixed system S (Section 6.2). This would help us to understand the meaning of D(fG∥fI) as an approximation of the BSE.We introduce a method of directly estimating the approximated BSE D(fG∥fI) without estimating fGand fI using the generalized k-NN estimator [8], and use it in our experiments (Sections 7.1(2), 7.2).We experimentally evaluate D(fG∥fI) of multimodal biometric systems, in addition to the fingerprint matching system and the face matching system. The results support the property of the BSE of the multimodal biometric system: it is less than or equal to the sum of the BSEs of the subsystems, and depends on the fusion function (Section 7.2).The rest of this paper is organized as follows. Section 2 is a brief review of the previous works. In Section 3, we propose a new measure of information gained through biometric systems: “biometric system entropy” or BSE. Theoretical properties and interpretations of the BSE are discussed in Section 4. In Section 5, we derive an asymptotic approximation and minimum upper bound of the BSE. In Section 6, we show how to evaluate D(fG∥fI) of a biometric system and show experimental evaluation of the BSE of face, fingerprint and multimodal biometric systems. Section 7, we summarize our results and conclusions.

@&#CONCLUSIONS@&#
