@&#MAIN-TITLE@&#
Neuro-fuzzy self-tuning of PID control for semiglobal exponential tracking of robot arms

@&#HIGHLIGHTS@&#
Self-tuning PID control algorithm based on a single feedback gain using a neuro-fuzzy scheme.Proof stability to demonstrate semiglobal exponential tracking.We claim that our proposal stands for the first one that enforces and proves semiglobal exponential tracking for robot arms using model-free self-tuning PID.

@&#KEYPHRASES@&#
Self-tuning PID,Neuro-fuzzy,Robot arms,Model-free tracking,

@&#ABSTRACT@&#
The PID controller with constant feedback gains has withstood as the preferred choice for control of linear plants or linearized plants, and under certain conditions for non-linear ones, where the control of robotic arms excels. In this paper a model-free self-tuning PID controller is proposed for tracking tasks. The key idea is to exploit the passivity-based formulation for robotic arms in order to shape the damping injection to enforce dissipativity and to guarantee semiglobal exponential convergence in the sense of Lyapunov. It is shown that a neuro-fuzzy network can be used to tune dissipation rate gain through a self-tuning policy of a single gain. Experimental studies are presented to confirm the viability of the proposed approach.

@&#INTRODUCTION@&#
Effectiveness and simple model-free control structure are the principal characteristics that make PID controller be useful in several applications. Based only on state feedback, the PID control has been developed for regulation tasks principally, [1–5]. The regulation of robotic arms, without linearization scheme, stands out from the overwhelming contributions in the literature on PID control. In particular, it has become the preferred option in the industrial floor for control of robot manipulators, [6]. To overcome the intrinsic uncertainties of the model commonly encountered in the robotic tasks, [7], some studies have provided the fundamentals for regulation without using the regressor nor any robot parameter, [8]. However, stability for the tracking case with a pure PID structure of non-linear plants, in particular for robotic arms, remains largely elusive in the literature. Additionally, to simplify the complex procedure of tuning constant feedback gains in the time domain for robotic arms, explicit rules rely on advanced stability grounds [9], or in view of the lack of simple procedures knowledge-based schemes have been proposed as an alternative to tuning feedback gains on-line [10]. In this paper, we explore a novel idea to design a self-tuning PID controller for robotic arms to obtain exponentially semiglobal tracking, in the sense of Lyapuonov [11], even under affine unmodeled bounded exogenous disturbance and smooth joint friction.Using a typical passivity-based robot control approach [12,13], it is shown that the error equation can be stabilized in the extended error manifold in the sense of Lyapunov, where the nonlinear integral control term yields a smaller stable domain of attraction. In order to drive the error manifold to zero to ensure the tracking, a neuro-fuzzy network is proposed to extract the knowledge and tune a gain, avoiding any knowledge of robot dynamics, in contrast to [14,15], nor attempting to approximate inverse dynamics, [12]. This gain is used together a PID controller of constant gains, resulting in a self-tuning PID control based on a single feedback gain using a neuro-fuzzy scheme. This self-tuning gain in fact expands or contracts the domain of attraction where passivity is enforced to yield Global Uniformly Ultimately Bounded, GUUB. Once tracking errors are trapped in this domain of attraction, the tuning scheme is synthesized and an exponential convergence to the desired trajectory is enforced, as long as initial conditions belong to the compact set in the neighbourhood of the time-varying desired trajectory. In this sense our proposal extends, by simplifying, the involved neuro-fuzzy structure of [16–18] such that the neuro-fuzzy tuning scheme enforces a dissipative mapping in terms of the error manifold by shaping the dissipation rate function to dominate the robot dynamics. This shows that a simple and intuitive fuzzy-based tuning rules keeps a model-free PID control structure to get tracking.This paper is organized as follows. A short background on self-tuning PID is presented in Section 2 to contextualize our contribution. Then, the proposal is given in Section 3, with the self-tuning policy presented in Section 4. Section 5 shows the main result and its stability analysis, with discussions and remarks in Section 6. Comparative experimental results are presented in Section 7, which highlights the viability and potential of the proposed approach in real robotic arms applications. Final conclusions are provided in Section 8.The seminal work of Ref. [20] established the fundamentals for regulation of robotic arms with PID control using constant gains, and [21] sets the grounds for its applicability to tracking tasks. Afterwards, various schemes of non-constant self-tuning feedback gains have been studied to provide better stability properties, [22]. Schemes such as linearizing robot dynamics, regressor-free or non-constant feedback gains have been introduced for improved performance, e.g. gain scheduling [23], iterative learning control [24], regressor-free [8], neuro-fuzzy [25], adaptive fuzzy [26], or state-dependant tuning gains [27].Among these schemes, in contrast to the classical neural network plus a PID-like stabilizer, see [28,29], there appear other schemes whose PID structure in fact hides a classical function approximation scheme, see [30] for neural networks, with wavelets in [31], recurrent neural networks in [32], and fuzzy neural networks in [33]. Although several schemes claim tracking capabilities with PID control, a close scrutiny shows the lack of stability results or in fact turns out BIBO stability even for LTI plants, at best, similar to [21] for the non-linear robot arm case. From the instrumental work of [34], PID fuzzy-based control for linear plants has been applied indistinctly for a wide family of systems and regimes, including for semiglobal regulation of non-linear robot dynamics [14], however unsuccessfully for tracking regime. Although there are impressive application studies on PID control of complex plants, the vast majority of these contributions share the common characteristic that no stability proof is presented, [35]. Recently, in [36] an adaptive fuzzy controller for tracking of a single-link robot manipulator is proposed based only in the measurement of position while the velocity signals are estimated using an adaptive fuzzy filter observer. The boundedness of the closed loop signals is guaranteed under assumption that the non-linear uncertainties are unknown. Within the large body of literature on PID control, our proposal is aligned to the schemes that preserve only a PID control structure without resorting on any type of inverse dynamics compensation while the feedback gains are time-varying. The proposed self-tuning mechanism, based on dissipation rate using a PID error manifold, facilitates the design controller because the non-autonomous representation of the open-loop error equation is parametrized by such PID error manifold, which is used as the output of the passivity inequality. In this realm, we claim that our proposal stands for the first one that enforces and proves semiglobal exponential tracking for robotic arms using a self-tuning PID, or PD.Consider the Euler–Lagrange formalism to model the energy balance of articulated mechanical systems, then let the well-known non-linear dynamic model of a rigid serial n-link robot manipulator be represented as follows:(1)H(q)q¨+C(q,q˙)q˙+g(q)=τ−τf+τd,whereq∈Rn,q˙∈Rnare the generalized position and velocity joint coordinates, respectively,H(q)∈Rn×ndenotes a symmetric positive definite inertial matrix,C(q,q˙)∈Rn×nrepresents the Coriolis and centripetal forces,g(q)∈Rnmodels the gravity forces, andτ∈Rnstands for the torque input. Termτf=Bq˙+Ctanh(Dq˙)stands for joint friction where B and C are positive definite diagonal n×n matrices modeling viscous damping and kinetic friction, respectively, and boundedD∈R+n×ngives rise to a reasonable approximation of the non-smooth Coulomb friction model. Disturbance torque τdis assumed bounded and possibly slowly time-varying.Let the following linear parametrization of (1), [40],(2)H(q)q¨r+C(q,q˙)q˙r+g(q)+Bq˙r+Ctanh(Dq˙r)−τd=YrΘ,where the regressorYr=Yr(q,q˙,q˙r,q¨r)∈Rn×prepresents the matrix of known terms andΘ∈Rpis a p vector of unknown parameters, [13], andq˙r∈Rnstands for the nominal reference, beingq¨rits derivative. Adding and subtracting (2) into (1), there appears the open-loop error equation:(3)H(q)S˙+C(q,q˙)S=τ−YrΘ,where the error manifold S is defined as:(4)S=q˙−q˙r.Let the nominal reference given by Ref. [19],(5)q˙r=q˙d−αΔq−Ki∫t0tftanh(λSq)dt,where Sqdefines the PD error manifold by:(6)Sq=Δq˙+αΔq,for α, λ, and Kias positive-definite diagonal feedback gain matrices, Δq(t)=q(t)−qd(t) denotes the position tracking error for qd(t)∈C2 (the dependency on t will be dropped subsequently to avoid any confusion and simplify the notation) the bounded differentiable continuous desired trajectory, withq˙dits derivative as the desired velocity, and tanh(λx) is the continuous hyperbolic tangent function ofx∈Rn. Substituting (5) into (4), it renders the extended error manifold:(7)S=Sq+Kiσ,(8)σ˙=tanh(λSq),notice that (7) and (8) stands for a PI error manifold homogeneous in Sq, whose unforced derivativeS˙q=−Kitanh(λSq)has a unique solution at Sq=0. Then, if there exists a controller τ that renders asymptotically S→0, we can show that the unforced solution of (7) and (8) attains an unique asymptotic equilibrium at(Δq,Δq˙)=(0,0)for a storage functionV0=1/2SqTSq. Finally, at this point, observe that σ=0 yields a linear PD error manifold with similar results.In this paper, we exploit the model-free non-linear PID controller with constant gains τ=−KdS and show that it yields GUUB. Moreover, we show that if Kdis chosen on-line using a neuro-fuzzy scheme, then there arises exponential convergence of S. To motivate the structure of this controller, and similar to [21], we show that the well-known result for local stability of robots using the PI error manifold (7) and (8) is valid. This fact will empower our self-tuning proposal to include input knowledge of the user by means of setting bounded multi-valued criteria to tune online Kdbased on a neuro-fuzzy mechanism. In the sequel, we will review some well-known techniques to contextualize our proposal.Before to present the control-system stabilization of unknown regressor and parameters (Section 3.3), it is necessary to briefly explain the passive computed torque with and without adaptation, in order to remark the importance of adaptation by using only one varying parameter, namedKˆd.Aiming at preserving passivity in closed-loop when Yrand Θ are available, it is easy to see that a dissipative mapping is globally valid for a storage (Lyapunov) functionV1=1/2SqTH(q)Sqfor τ=−KdSq+YrΘ whereKd=KdT>0∈R+n×n, [38]. To see this, notice that the following closed loop equation appears:(9)H(q)S˙q+C(q,q˙)Sq=−KdSq−ν1,where ν1=0 is a virtual input defined for analysis purpose. The passivity balance leads to:(10)∫t0tSqTν1dt=∫t0tddtV1(Sq)dt+ξin virtue of the antisymmetry of1/2H˙(q)−C˙(q,q˙), [42], andξ=∫t0tSqTKdSqdt>0stands for the dissipation function, with Kdits dissipation rate gain. In this case, any constant Kdendows the system with dissipative behavior and a global domain of stabilityD0′containing the open setR0of initial conditions X(t0)=X0 is established. More precisely, (10) leads toV˙1(Sq)=−SqTKdSqwhich suggest the GUUB of the origin. Now, let us review the case of unknown Θ in light of the adaptive approach of Ref. [13].When Yris known but Θ is unknown, the well-known adaptive passive computed torque, or simply adaptive control of [13] is defined. Considersτ=−KdSq+YrΘˆ, whereKd=KdT>0∈R+n×n, and the vector of parametric uncertainty ΔΘ is compensated adaptively byΘˆ˙=−ΓYrTSq. This gives rise, by Barbalath Lemma, to the local asymptotic stability using the Lyapunov functionV2=1/2SqTH(q)Sq+1/2ΔΘTΓ−1ΔΘ. In this case, a dissipative mapping can be obtained locally to guarantee tracking with smooth control effort under an over-parameterization of the closed-loop dynamics in virtue of p≫n. Interestingly, this can be re-interpreted as ifΘˆ(t)were time-varying feedback gains that contributes to drive error Sq→0 at the expense of full knowledge of the robot model encoded through Yr. Finally, notice that even though online adaptation of vectorΘˆ(t)is not constant obviously, it does not contribute to the dissipation rate because it targets to compensate for parametric uncertainty ΔΘ, that is, ξ is the same as previous case. Now, let us analyze the case when both Yrand Θ are unknowns.In this case, for unknown Yrand Θ let(11)τ=−KdS=−KdSq−KdKiσ≡−KpΔq−KvΔq˙−Kισ,be a PID controller parametrized by the PI error manifold, whereKd=KdT>0∈R+n×n, Kp=Kdα,Kv=Kd, and Kι=KdKi. The closed-loop system, using (11) and (3), leads to the very same (9):(12)H(q)S˙+C(q,q˙)S=−KdS−ν1,however in this case ν1=YrΘ. Clearly, we obtain (10), that is∫t0tSTν1dτ=∫t0tddtV3(S)dτ+ξfor V3(S)=1/2STH(q)S andξ=∫t0tSTKdSdτ>0. This is not passive because ν1≠0, however, for large enough Kda bounded local domain of stabilityD0can be established to guarantee stability of tracking errors. To see this, consider that there exists positive scalars ρi(i=0, …, 5) that bounds YrΘ, [19,21], as follows:(13)∥H(q)∥≥λm(H(q))>ρ0>0,∥H(q)∥≤λM(H(q))<ρ1<∞,∥C(q,q˙)∥≤ρ2∥q˙∥,∥g(q)∥≤ρ3,∥q˙r∥≤ρ4+α∥Δq∥+Ki∥σ∥,∥q¨r∥≤ρ5+α∥Δq˙∥,where λm(A), λM(A) stand the minimum and maximum eigenvalues of matrixA∈Rn×n, respectively, and ρ4, ρ5 sets the upper bounds for desired velocity and acceleration, respectively. Then, we have that:(14)YrΘ≤∥H(q)∥∥q¨r∥+{∥B∥+∥C(q,q˙)∥}∥q˙r∥+∥g(q)∥+∥C∥∥tanh(Γq˙r)∥≤ρ1α∥Δq˙∥+{λM(B)+ρ2∥q˙∥}·(α∥Δq∥+Ki∥σ∥+ρ4)+λM(C)+ρ¯3≤η(t),whereρ¯3=ρ1ρ5+ρ3, andη(t)=f(Δq,Δq˙,σ,ρi,t). According to (14), we have thatV˙3≤−∥S∥(λm(Kd)∥S∥−η(t)). Thus, there exists a finite time t1>t0 such that ∥S∥>(c/λm(Kd)) for c>supargt≥0η(t) for whichV˙3<0. Then, for small initial conditions X0≤c0, for c0>0, η(t0) belongs to a neighbourhood with radius r>0 centered in the origin S=0. This shows the existence of bounded domain of stabilityD0for a large enough feedback gain Kd, implying that S converges into a set ɛ1 of radius r1>0 bounded by S≤c/λm(Kd)∀t≥t2. Therefore,S˙≤c¯, for some realc¯. Namely,(15)S→ɛ1⇒Sq→ɛ1and(S,Sq)⊂D0∀t≥t2,this stands for local stability of S and the boundedness of all closed-loop signals, in theL∞sense, which leads to the existence of bounded neighbourhoods ɛ2>0, and ɛ3>0 such that∥S∥<ɛ2,∥S˙∥<ɛ3. Finally, in virtue of (7), the boundedness of tracking errors is established, that is∥Δq∥<ɛ4,∥Δq˙∥<ɛ5,∥σ∥<ɛ6,for a PID controllerτ=−KdS=−KdSq−KdKiσ≡−KpΔq−KvΔq˙−Kισwith constant Kd. Thus, we have proved the following result.Proposition 1Consider the closed-loop system(12), then the nonlinear PID controller(11)yields global uniform ultimate boundedness (GUUB) with constant Kdassuming small errors on initial conditions. ▪Remark 1Notice that the size of ɛiis reduced as Kdincreases, however the saturation level of actuators sets a finite upper limit for Kd. An alternative approach is online tuning of Kddepending on the size of position tracking errors. We pursue this idea based on neuro-fuzzy arguments to show that for bounded S, a bounded Kd=f(S) gives rise to local exponential stability, which can be expanded in the semi-global sense, [15]. Now, we review the case of finite Kd(t) under controller τ=−Kd(t)S.In the sequel and provided that Proposition 1 holds, there remains the question on what sort of improvement can be obtained with time-varying Kd, and more important, how to obtain the corresponding stability proof. This question is pertinent because experience indicates that some tasks can be executed more accurately and smoothly when feedback gains are time-varying according to the error and initial conditions rather than using constant gains. Now, consider the following controller:(16)τ=−KˆdS≡−KˆPΔq−KˆDΔq˙−KˆIσ,forKˆP=Kˆdα,KˆD=Kˆd, andKˆI=KˆdKi, for constant positive definite feedback gains α, and Ki. Intuition suggests that a time-varying gain policy can simply consider that if error increases, then increases the gain that affects most such error, and viceversa, and so forth, which eventually will result on (ɛ4, ɛ5)→0 accordingly. This motivates to argue that sinceKˆdshapes the dissipation rate ξ in the passivity inequality (10), it seems reasonable to embrace tuning ofKˆdbased on the deviation of position errors, essentially a greater dissipation rate to greater deviation is required and vice-versa. Clearly, that under unknown YrΘ, an analytical algorithm to tuneKˆdis incomplete, (pag. 26 of [34]), but exploiting user experience and knowledge on system performance, it seems feasible to resort in neuro-fuzzy schemes with the purpose to design a self-tuning algorithm forKˆdwithout any attempt to approximate inverse dynamics.Let a neuro-fuzzy scheme tune the gainKˆdas follows:(17)Kdˆ≡∑i=1rkdi(k)=∑i=1rβi(k)μAi(k),where βi(k) is a parameter to minimize a quadratic cost function of S(k), andμAi(k)stands for the membership function. In this way, and based on user experience, it is assumed the user is able to tune them to obtain tracking for a given bounded and smooth time-varying trajectory, resulting in boundedKˆd, see Fig. 1. The tuning process will be explained later. Let the universe of discourses of S and kdbe defined asS⊂S¯andkd⊂Kˆd, respectively, [34]. Then for each S input, the fuzzy IF-THEN rule, similar to a Sugeno-type model, is defined as:Rule i: IFS IS AiTHENKd=kdi(k)=βi(k)μAi(k), where Aidenotes a linguistic-classified subset linked with the membership function (MF) of the fuzzy state, for i=1, 2,..., r-fuzzy states andkdi(k)⊂Kˆd.We now shows firstly the self-tuning fuzzy logic scheme to obtain βi(k), and then we describe the rationale behind the design ofμAi(k). In fact, the gainKˆd>0is tuned using a two-stages neuro-fuzzy algorithm. In the first stage, fuzzy logic rules are designed based on S vector, while in the second stage, it is used the output of the first stage as inputs of a neural network (with unity weighting between layers) to obtain the corresponding summation to build up the outputKˆd, see Fig. 2.The Rule i indicates that ifS belongs to the fuzzy set Ai, with corresponding membership valueμAi(k), then the fuzzy value of the output of this rule, denoted by kdi(k), is equal to the linear consequence (LC) defined by the productβi(k)μAi(k); where βi(k) andμAi(k)represent the slope of the LC and the membership value of the MF, respectively. Once the rules are processed, the outputKˆdat instant k is computed from the summation of all kdi(k) values by using defuzzification.Each fuzzy rule is transferred through a fuzzy-neural network composed by four layers. This particular configuration has a simple structure able to transfer knowledge about S based on fuzzy rules injected into the network, [16–18]. It can be seen that the input layer simply processes S into the second layer, where each node has a Gaussian or sigmoid MF, given byAi=μAi(k)corresponding to one linguistic level (e.g. negative, positive, etc.). The MFs are processed to the corresponding i-th node of the next (LC layer), which is computed as (17), that is:(18)kdi(k)=βi(k)μAi(k).Finally at the output layer gives rise to (17). This structure allows to tune a suitableKˆdvalue according to user experience on system performance encoded in terms of tracking errors or error manifold S, which is useful to modulate the domains of attractionDi. Now, an adaptive algorithm for LC βi(k) is proposed to minimize a quadratic index of extended error manifold S.Due toKˆd=f(S(k))is an state-dependent non-linear function ofS(k)=Δq˙(k)+αΔq(k)+Kiσ(k)with Δq(k)=q(k)−qd(k),Δq˙(k)=q˙(k)−q˙d(k), and σ(k), representing position and velocity errors, and the integral term, at instant k, respectively. The convex quadratic cost functionF(k)defined as:(19)F(k)=12ST(k)S(k),is minimized as k→∞ when:(20)F(k+1)=12ST(k+1)S(k+1)→0,withS(k+1)=Δq˙(k+1)+αΔq(k+1)+Kiσ(k+1). Thus, the adjustment of Δβi(k) can be defined along the negative gradient of (20) as follows:(21)Δβi(k)=−ηi(k)∂F(k+1)∂βi(k),for ηi(k)>0 the learning rate at instant k for the i-th LC. Applying the chain rule, the term∂F(k+1)/∂βi(k)is obtained as follows:(22)∂F(k+1)∂βi(k)=∂F(k+1)∂S(k+1)·∂S(k+1)∂Δq(k+1)·∂Δq(k+1)∂Kˆd(k)·∂Kˆd(k)∂βi(k).Clearly,(23)∂F(k+1)∂S(k+1)=S(k+1),(24)∂S(k+1)∂Δq(k+1)=α,(25)∂Kˆd(k)∂βi(k)=μAi(k),but the term∂Δq(k+1)/∂Kˆd(k)cannot be computed analytically, yet, for a fast enough sampling rate (relative to the constant time of the electromechanical robot) it can be approximated reasonably by:(26)∂Δq(k+1)∂Kˆd(k)≈Δq(k+1)−Δq(k)Kˆd(k)−Kˆd(k−1)=ΔΔq(k+1)ΔKˆd(k).Now, by design, it is desirable to make the ratio (26) sensible to parameterKˆd(k)so as toKˆd(k)reacts faster than Δq(k+1) does, i.e. the ratio (26) is such that:(27)∂Δq(k+1)∂Kˆd(k)=ϒp≪1,is small and positive, by design. Finally, substituting (23)–(27) into (22), (21) becomes:(28)βi(k+1)=βi(k)−ηi(k)ϒpS(k+1)αμAi(k),given that βi(k+1)=βi(k)+Δβi(k). Note that {ηi(k)ϒp}<ηi(k)∈(0, 1] in virtue of (28), which can be interpreted as a new learning rate.Remark 2On the no dependency of β(k+1) on velocity tracking errors. We underline that stateq˙(k), explicit inΔq˙(k), is omitted purposely in (22) because S(k) is homogeneous in Δq(k), then whenΔq(k)→0⇒Δq˙(k)→0, but the converse is obviously not always true. In this way, this algorithm avoids thatKˆdreacts to typical noise measurements of velocity tracking errors.We are now in the position to state the main result with its stability analysis in the following theorem.TheoremConsider the robot dynamics(1)in closed-loop with the controller(16)with a varyingKˆd, (17). Ifλm(Kˆd)satisfies Proposition1and βi(k) is computed according to(28)then, the extended error manifold S is driven exponentially to zero. Thus, a semiglobal exponential stability of tracking errors is guaranteed,(Δq,Δq˙)→0.Consider a Lyapunov function candidate as follows:(29)V4(k)=12ST(k)S(k),(30)ΔV4(k)=V4(k+1)−V4(k)=12{ST(k+1)S(k+1)−ST(k)S(k)}=12{[S(k)+ΔS(k)]T[S(k)+ΔS(k)]…−S(k)TS(k)}=ΔST(k)[S(k)+12ΔS(k)],for ΔS(k)=S(k+1)−S(k); owing to (26), ΔS(k) can be approximated along small variations of Δβi(k) as follows:(31)ΔS(k)=ΔS(k)Δβi(k)Δβi(k)≈∂S(k+1)∂βi(k)Δβi(k).Similar to (22), ∂S(k+1)/∂βi(k) becomes:(32)∂S(k+1)∂βi(k)=ϒpαμAi(k).Finally, from (28), Δβi(k) becomes:(33)Δβi(k)=−ηi(k)ϒpS(k+1)αμAi(k).Substituting (32) and (33), (31) can be written as follows, using α2=αTα and S(k+1)=S(k)+ΔS(k),(34)ΔS(k)=−ηi(k)ϒp2S(k+1)α2μAi2(k),=−ηi(k)ϒp2α2μAi2(k)[S(k)+ΔS(k)],=−ηi(k)ϒp2α2μAi2(k)S(k)−…ηi(k)ϒp2α2μAi2(k)ΔS(k),=−B¯S(k),whereB¯=B/1+B, andB=ηi(k)ϒp2α2μAi2(k), thenB¯is well posed since0<B¯<1,∀B>0. Finally, from (30) and (34) we obtain:(35)ΔV4(k)=−B¯ST(k)S(k)+12B¯2ST(k)S(k),≤−12γST(k)S(k),≤−γV4(k),for rate γ>0, concluding the exponential convergence of the quadratic convex function V4(k), with the unique equilibrium at S(k)=0, sinceB¯>B¯2. Resorting on definition of S in (4) and (7) and (8), it guarantees thatS(k)→0⇒(Δq,Δq˙)→(0,0)exponentially. ▪

@&#CONCLUSIONS@&#
