@&#MAIN-TITLE@&#
A moving-average filter based hybrid ARIMA–ANN model for forecasting time series data

@&#HIGHLIGHTS@&#
A new ARIMA-ANN prediction model is proposed by exploring time series volatility.The model is applicable for both one-step and multi-step ahead predictions.We examined the model accuracy on sunspots, electricity price and Indian stock data.This model gave better prediction accuracy than many existing ARIMA-ANN models.

@&#KEYPHRASES@&#
Time series forecasting,ARIMA,ANN,Hybrid model,Box–Jenkins methodology,

@&#ABSTRACT@&#
A suitable combination of linear and nonlinear models provides a more accurate prediction model than an individual linear or nonlinear model for forecasting time series data originating from various applications. The linear autoregressive integrated moving average (ARIMA) and nonlinear artificial neural network (ANN) models are explored in this paper to devise a new hybrid ARIMA–ANN model for the prediction of time series data. Many of the hybrid ARIMA–ANN models which exist in the literature apply an ARIMA model to given time series data, consider the error between the original and the ARIMA-predicted data as a nonlinear component, and model it using an ANN in different ways. Though these models give predictions with higher accuracy than the individual models, there is scope for further improvement in the accuracy if the nature of the given time series is taken into account before applying the models. In the work described in this paper, the nature of volatility was explored using a moving-average filter, and then an ARIMA and an ANN model were suitably applied. Using a simulated data set and experimental data sets such as sunspot data, electricity price data, and stock market data, the proposed hybrid ARIMA–ANN model was applied along with individual ARIMA and ANN models and some existing hybrid ARIMA–ANN models. The results obtained from all of these data sets show that for both one-step-ahead and multistep-ahead forecasts, the proposed hybrid model has higher prediction accuracy.Time series forecasting is now a very important research area, owing to the importance of prediction in various applications. Forecasting Internet traffic helps service providers to enhance their services. Forecasting climate change helps the agricultural sector. Forecasting disasters aids in taking necessary precautions and helps mankind to be prepared. Forecasting financial data helps investors to invest safely in the market. However, time series data do not always have the same characteristics. Some time series are seasonal: for example, road traffic is high at some particular times in the day, climate variations repeat according to the seasons, etc. Some other time series are nonseasonal, such as financial and stock market data. Some time series are highly volatile, such as wind speed data, and some are less volatile, such as global temperature and annual rainfall. Some data are almost linear in nature, such as the growth of an animal, plant, or human being, but many other sets of data are nonlinear in nature. Some data are Gaussian in nature, whereas some other data are non-Gaussian. For forecasting such time series data, various prediction techniques have been proposed in the literature, which may use either linear or nonlinear models. A type of linear model, namely the autoregressive integrated moving average (ARIMA), and a type of nonlinear model, the artificial neural network (ANN), were chosen for study in this paper.ARIMA models assume that the present data are a linear function of past data points and past errors. They also assume that the errors are white in nature, and require that the data be made stationary before fitting a linear equation to the data. In the literature, ARIMA models have been applied to various time series data, such as electricity prices [1,2], sugar prices [3], stock market data [4], and wind speeds [5], for the prediction of future values. ARIMA models can help in understanding the dynamics of the data in a given application. Before forecasting time series data, various preprocessing steps can be applied to the raw data if necessary. In [6], a wavelet transformation was applied before forecasting of global temperature data. In [7], new classification and feature extraction techniques were proposed for electrocardiography data. These preprocessing steps can be applied to the raw data to obtain more accurate predictions. In this paper, the basic ARIMA model was chosen as the linear prediction model.One efficient nonlinear technique for time series forecasting is ANNs [8]. ANNs are advantageous compared with ARIMA in many applications because ANNs do not assume linearity. They are capable of fitting a nonlinear function to the given data and do not need the data to be made stationary. They are also adaptive in nature. For these reasons, ANN models have become more popular in forecasting. ANNs have been applied to various time series data, such as electricity demand data [9], financial data [10], river flow data [11], and network data [12], for forecasting. In all these cases ANNs were shown to yield good forecasts compared with ARIMA models. In [13], neural networks were used to predict earthquakes in Chile. There is no universal model which can suit all applications. The prediction accuracy can be improved if two different models are applied to the same data rather than a single model. So, many hybrid techniques have been proposed in the literature, which combine the advantages of two or more individual models.A hybrid ARIMA–ANN model was proposed by Zhang [14], which was shown to give more accurate predictions than the individual models. On Wolf's sunspot data, Canadian lynx data, and exchange rate time series data, this hybrid model was shown to outperform individual ARIMA and ANN models in the case of one-step-ahead prediction. Another hybrid ARIMA–ANN method was proposed by Khashei and Bijari [15], which was shown to give better performance for one-step-ahead forecasting than the method proposed by Zhang [14]. The hybrid method proposed by Zhang was also used for electricity price forecasting in [16] and for water quality time series prediction in [17].In addition to the ARIMA and ANN models, many other prediction models are available in the literature. Some of them are based on support vector machines [18], and some others on fuzzy models [19]. Modified forms of ARIMA models such as SARIMA [20] and FARIMA [21] are also available. GARCH models have also used for financial forecasting, as in [22]. In [23,24], autoregressive (AR) and GARCH models were used for forecasting financial data. Spectral techniques based on SVD were proposed in [16] and the references therein. Decomposition-based ARIMA, ARIMA–GARCH, and ANN models were also studied in [25–27] and elsewhere. Most of the time it is seen that if hybrid models are used instead of one model the prediction accuracy improves, but if the hybrid uses many decompositions and many models, then the accuracy will degrade after some limit and the model will no longer be successful. So, hybrid models should contain a limited number of individual models to retain the simplicity of the model as well as to retain accuracy.In this paper, a new hybrid ARIMA–ANN prediction model is proposed which is suitable for both one-step-ahead and multistep-ahead predictions. In this model, the nature of the time series is first explored with the help of a moving-average (MA) filter and then ARIMA and ANN models are suitably applied. Instead of directly applying the ARIMA or ANN model to the given data, the nature of the volatility of the time series data is first understood, and then the ARIMA and ANN models are applied to the data. This proposed method of prediction was applied to a known data set that was generated by adding linear and nonlinear time series data. The performance accuracy of this method was better than the accuracy obtained by the models of Zhang [14] and Khashei and Bijari [15]. On three different time series data, namely sunspot, electricity price, and financial data, for both one-step and multistep predictions, the proposed method gave better accuracy than the other hybrids [14,15].The rest of the paper is organized as follows. In “ARIMA- and ANN-based modeling techniques” section, the ARIMA, ANN, and some existing hybrid ARIMA–ANN models are described. The proposed method is discussed in detail in “Proposed hybrid ARIMA–ANN model” section. In “Results and discussion” section, the results are discussed in four subsections, along with tables of performance measures and graphs of predicted values. “Conclusion” section ends the paper with a conclusion.Detailed descriptions of the ARIMA and ANN modeling techniques are available in the literature. However, to make the discussion complete, a brief description of these modeling methods is presented in this section. Also, some of the popular existing hybrid modeling schemes are outlined.ARIMA is a linear modeling technique. In this technique, the given time series data are first checked for stationarity. If they are not stationary, a differencing operation is performed. If the data are still nonstationary, differencing is again performed until the data are finally made stationary. If the differencing is performed d times, the integration order of the ARIMA method is said to be d. The resultant data are modeled as an autoregressive moving average (ARMA) time series as follows. The data value at any given time t, say yt, is considered as a function of the previous p data values, say yt−1, yt−2, …, yt−p, and the errors at times t, t−1, …, t−q, say nt, nt−1, …, nt−q. The corresponding ARMA equation is shown in (1). In (1), a1 to apare the autoregressive (AR) coefficients and b1 to bqare the MA coefficients. Thus the time series model is denoted as ARIMA(p, d, q). The ARMA model assumes that the error sequence ntis white noise and is Gaussian distributed, so the variance of this error is also a model parameter. The ARIMA modeling procedure has three steps: (a) identifying the model order, i.e., identifying p and q; (b) estimating the model coefficients; and (c) forecasting the data.Identifying the orders p, q is done using correlation analysis [28], using the nature of the autocorrelation function and partial autocorrelation function. The model coefficients are estimated using the Box–Jenkins method [28]. Of the various estimation approaches other than the nonlinear maximum likelihood approach, which is computationally more complex, Gaussian maximum likelihood estimation (GMLE) approaches [29] are generally used for estimation of the ARIMA model parameters. The model is validated by finding the Akakine information criterion (AIC). The best-suited ARIMA model has the minimum value of the AIC. After all the model coefficients have been estimated, the next values of the time series are predicted using the available past data values and the model coefficients. ARIMA models predict linear time series data with very good accuracy.(1)yt=a1yt−1+a2yt−2+⋯+apyt−p+nt+b1nt−1+⋯+bqnt−qThis is a nonlinear modeling technique which is suitable for modeling over a very wide range of applications. It is more flexible in terms of architecture. The neural-network architecture bears a high similarity to the neurons in the brain, hence the name “artificial neural network.” In this network architecture, there may be two or more layers. For example, a three-layer ANN has three layers, namely an input layer, a hidden layer, and an output layer. The inputs can be of any number. Also, the number of neurons in the hidden layer is flexible. A typical three-layer ANN, with the nomenclature, is shown in Fig. 1. The neurons are processing units which are acyclically linked. Three-layer ANNs are widely used for time series forecasting. To model time series data using such a network, the sequence ytis considered as a nonlinear function of yt−1, …, yt−N. The corresponding equation is shown in (2). In (2), the function g is a nonlinear function, andvtis a noise or error term. The ANN model output can be represented in terms of input and hidden-layer weight parameters. The transfer function of the hidden layer is generally a sigmoid function, shown in (3), and that of the output layer is a linear function. The model coefficients in an ANN are the weights of each link and the bias values, as shown in Fig. 1.(2)yt=g(yt−1,yt−2,…,yt−N)+vt(3)Sigmoid(x)=11+e−xTo obtain these model coefficients, a known data sequence is first given as input to the ANN, and the ANN is trained with this training sequence. Training a neural network can be considered as minimizing the multivariate global error function formed by the weight values. After training of the ANN, its performance is tested and validated. Many other training algorithms are available in the literature [30]. For example, in [14], a reduced gradient-based algorithm was used for training the ANN. In [17] and [15], a scaled conjugate gradient algorithm and a Levenberg–Marquardt (LM) training algorithm, respectively, were incorporated. In the work presented in this paper, the ANN model was trained using an LM training algorithm.The performance of ANNs is better than that of the ARIMA method in many applications. This is because ANNs can model nonlinear time series data accurately, as seen from the model equation in (2).Often, the given data may have both linear and nonlinear characteristics. So, hybrid models using both ANN and ARIMA methods are better than individual models for obtaining accurate predictions. Two existing ARIMA–ANN hybrid models considered for discussion in this paper are illustrated as follows.In 2003, Zhang proposed a hybrid ARIMA–ANN model for time series forecasting. According to this model, any time series data are assumed to be the sum of two components, linear and nonlinear. First, an ARIMA model is fit to the given time series data. Then the error sequence is assumed to be the nonlinear component and is modeled using an ANN. The predictions obtained from both the ARIMA model and the ANN model are combined to obtain the final forecast. This is suitable for both one-step-ahead and multistep-ahead predictions. This model was shown to be better than the individual ARIMA or ANN models in many applications in terms of prediction accuracy [16].In 2010, Khashei and Bijari proposed another hybrid ARIMA–ANN model for time series forecasting. This model also assumes that any time series data are the sum of two components, linear and nonlinear. In this method, first an ARIMA model is fit to the given time series data and one data value is forecasted. Then the past original data values, the present ARIMA-forecasted data value, and the past error sequence values are all given as inputs to an ANN, and the output of the ANN is the final forecasted value. This method was shown to have better performance than Zhang's method in various applications in terms of prediction accuracy [15].In this paper, a new hybrid ARIMA–ANN model is proposed, which is outlined in this section. The technique first characterizes the given data based on the nature of the volatility of the data. Then ARIMA and ANN models are suitably applied. Before describing this technique, we first discuss some interesting facts about ARIMA sequences, which are used in understanding and characterizing the given data.In the hybrid methods proposed by Zhang [14] and by Khashei and Bijari [15], the data are assumed to be the sum of linear and nonlinear components. But the given data are not decomposed into linear and nonlinear components; instead, a linear ARIMA model is fit directly to the data and the error sequence thus obtained is assumed to be the nonlinear component. Thus both of these hybrid methods explore and use the fact that the ARIMA model is linear. Ideal ARIMA sequences have many interesting properties, two of which are linearity and stationarity. Some other statistical facts about ARIMA and ARMA sequences are the following: first, the error sequence ntin (1) is Gaussian or normally distributed and white in nature [28], and second, a Gaussian time series represented as a random vector[ytyt−1yt−2⋯]is joint-Gaussian in nature [31].The second statistical fact can be explored further as follows. A stationary Gaussian time series is always stationary in the strict sense [31]. So, assuming that a given ARMA time series is strictly stationary, one possibility is that this series is a Gaussian time series. Usually, after making the given time series data stationary, estimation of the ARIMA model coefficients is performed using GMLE [29]. In this estimation, the model coefficients are obtained as if the given time series were Gaussian. So, if the given stationary time series is truly Gaussian, then the estimated ARIMA model is a better fit. So, it can be concluded that if the time series is stationary in the strict sense, an ARIMA model is more suitable for Gaussian time series data. Then the random vector[ytyt−1yt−2⋯]is joint-Gaussian and each random variable ytis Gaussian distributed.In general, to diagnose whether a given sequence is normally distributed or not, the Jarque–Bera normality test can be performed. A part of this test checks whether the kurtosis of the sequence, given in (4), is 3 or not:(4)kurtosis=E{(y−E{y})4}(E{(y−E{y})2})2In (4), y is the random variable for which the kurtosis is being computed, and E stands for the expectation operation. If the kurtosis value is 3, then the sequence is Gaussian; such sequences were considered as low-volatility data in the work described in the present paper. Sequences that did not have a kurtosis value of 3 were considered as highly volatile data. A highly volatile time series is either leptokurtic or platykurtic in nature, which means that the distribution is non-Gaussian. Thus we can conclude that ARIMA models are suitable for any time series data when the data have a kurtosis value of approximately 3. With this understanding, the proposed model is described below.Mathematically, the proposed model can be described as follows. The time series data ytare considered as a sum of a low-volatility component ltand a high-volatility component ht, as given in (5). After making sure that ltis stationary, it is modeled as a linear function of past values of the sequence lt−1, lt−2, …, lt−pand the random error sequence nt, nt−1, …, nt−qusing an ARIMA model. This is shown in (6), where f is a linear function. Similarly, htis expressed as a nonlinear function of ht−1, ht−2, …, ht−Nas shown in (7), and is modeled using an ANN. In (7), g represents the nonlinear function, and ɛtrepresents the model error. Using the ARIMA-predicted low-volatility componentlˆtand the ANN-predicted high-volatility componenthˆt, the predicted time series valueyˆtis obtained as represented in (8).(5)yt=lt+ht(6)lˆt=f(lt−1,lt−2,…,lt−p,nt,nt−1,…,nt−q)(7)hˆt=g(ht−1,ht−2,…,ht−N)+ɛt(8)yˆt=lˆt+hˆtThe steps of the algorithm for the proposed hybrid model are given below and are represented as a flow chart in Fig. 2.1Using an MA filter, given in (9), the given time series data are separated or decomposed into two components such that one of the components is less volatile and the other is highly volatile. The length of the MA filter, m, is adjusted so that this decomposition is properly achieved. The first decomposition is ytr, given in (9), which is the smoothed trend component, and has low volatility. The second decomposition obtained from the MA filter is the residual component, given in (10), which has high volatility.The low-volatility component with k=3 is modeled using an ARIMA model and the predictions are obtained as in (6).The high-volatility component with k!=3 is modeled using an ANN and the predictions are obtained as in (7).The predictions obtained from steps 2 and 3 are added to obtain the final predictions as in (8):(9)ytr=1m∑i=t−m+1tyi(10)yres=yt−ytrThe proposed algorithm can give better accuracy compared with the other hybrid models discussed in the previous section, which first directly fit an ARIMA model to the given data. This can be understood from the following reasoning. A linear sequence cannot be accurately modeled by a nonlinear model, and vice versa. A low-volatility series is Gaussian in nature and an ARIMA model suits it better, which implies that it can be modeled accurately using a linear model. Therefore, when the time series is less volatile, it can be considered as a linear sequence. Similarly, if it is highly volatile in nature, it can be considered as a nonlinear sequence. If a linear sequence is modeled by a linear model, the model error will be small. The case for a nonlinear sequence is similar. So, when a given data set is decomposed into low- and high-volatility components, which are almost linear and nonlinear components, respectively, the total model error will be small. On the other hand, if an ARIMA model is directly fit to the data, the separation of linear and nonlinear components is not performed. So, there is a chance that part of the linear component will be modeled by a nonlinear model, resulting in an increase in the model error. Hence, the proposed model can give more accurate results than Zhang's and Khashei and Bijari's models. This fact has been verified using simulated and experimental data sets.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
