@&#MAIN-TITLE@&#
Weakly supervised motion segmentation with particle matching

@&#HIGHLIGHTS@&#
We aim at predicting cerebral palsy at an early stage using normal video camera.A new motion segmentation method is proposed that benefits from prior knowledge.A particle matching technique is used to reduce the dependency on prior knowledge.The proposed method segments the objects, infants body parts, with high performance.The method is tested on a standard benchmark and outperforms the previous methods.

@&#KEYPHRASES@&#
Motion segmentation,Particle matching,Tracking,Cerebral palsy,Computerized diagnosis,

@&#ABSTRACT@&#
Motion segmentation refers to the task of segmenting moving objects subject to their motion in order to distinguish and track them in a video. This is a challenging task in situations where different objects share similar movement patterns, or in cases where one object is occluded by others in part of the scene. In such cases, unsupervised motion segmentation fails and additional information is needed to boost the performance. Based on a formulation of the clustering task as an optimization problem using a multi-labeled Markov Random Field, we develop a semi-supervised motion segmentation algorithm by setting up a framework for incorporating prior knowledge into the segmentation algorithm. Prior knowledge is given in the form of manually labelling trajectories that belong to the various objects in one or more frames of the video. Clearly, one wishes to limit the amount of manual labelling in order for the algorithm to be as autonomous as possible. Towards that end, we propose a particle matching procedure that extends the prior knowledge by automatically matching particles in frames over which fast motion or occlusion occur. The performance of the proposed method is studied through a variety of experiments on videos involving fast and complicated motion, occlusion and re-appearance, and low quality film. The qualitative and quantitative results confirm reliable performance on the types of applications our method is designed for.

@&#INTRODUCTION@&#
In a still scene where objects are visually blended to the background, such as animal camouflage, it is difficult or impossible to distinguish the objects from the background. In such a situation, motion information is a strong clue for visual perception of the surrounding environment. Although the process of motion perception appears straightforward to the human visual system, it is a difficult problem from a computational perspective. Humans are continuously detecting, tracking and registering surrounding objects, and to them occlusion, disocclusion and different motion patterns seem less of an issue. Dissimilar to humans, these could be extremely challenging for a computer-based method.An application where we have to deal with fast and complicated motion patterns is the analysis of an infant’s motion. Such an analysis is needed frequently in the medical world, for example in our application that is to predict cerebral palsy (CP) at an early stage. To do so, we need to extract the motion information out of videos of infants at 2–4 month postterm age. Over the past few years, a number of computer-based movement assessment tools have been developed [1–3]. However, there are problems limiting their practical use. First, they must be installed in a controlled environment. Second, they use instrumentation that might affect the infant’s body movements. Finally, experts are needed for interpretation and analysis of the results. Recently, our research group has been studying the prediction of CP using a normal 2D monocular camera by a simple frame differencing approach without any need for instrumentation on the infant [4–7]. While these early studies show great promises, the algorithms used are sensitive to lighting conditions, clothing and skin color. In addition, the video data is aggregated into movement variables or features that provide limited clinical insight [8].To overcome these problems, we are interested in extracting motion information out of a video and analysing this motion information to separate moving objects (in our case the infant’s body parts) from the background and from each other. In situations like our application, where the objects share similar motions, the motions are fast and with complicated patterns, and occlusion happens frequently, motion cannot be informative enough by itself. Thus, additional information is needed, in our case some prior knowledge about the assignment of the trajectories. The prior knowledge in the present application is manual labeling of the infant’s body parts in one or more frames of the video. Clearly, one wishes to minimize this manual labor such that the segmentation procedure is as autonomous as possible. Incorporating prior knowledge is challenging, and is addressed in Sections 3 and 4. In [9] we proposed an energy minimization technique to incorporate prior knowledge into the segmentation procedure. In the current paper, we improved this motion segmentation method by incorporating an multi-scale particle matching procedure into the method. As a result, less prior knowledge is needed.

@&#CONCLUSIONS@&#
In this paper, we dealt with motion based object segmentation and tracking in a video. Due to insufficiency of motion in situations where objects share similar motion pattern, need for additional information seems inevitable. We proposed a framework to integrate this additional knowledge to the segmentation procedure. The knowledge in our case was a set of assigned trajectories to the true segments, that was prepared by manually labeling some of the frames. We reduced the number of manually labeled frames by integrating a multi-scale particle matching technique to our method. Since the original motive of our work was to extract motion data for predicting cerebral palsy, detailed analytical experiments were adopted on videos of infants in order to see the functionality of our methods for this application. In addition, a standard data set was considered to show the generality of the methods. Quantitative and qualitative results confirmed that the proposed methods boosted the segmentation performance a great deal. Furthermore, the tracker derived from our segmentation methods outperformed the state-of-the-art tracking methods.