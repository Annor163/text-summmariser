@&#MAIN-TITLE@&#
On the use of deep feedforward neural networks for automatic language identification

@&#HIGHLIGHTS@&#
This work presents a comprehensive study on the use of deep neural networks for automatic language identification.It includes a detailed performance analysis for different data selection strategies and DNN architectures.Proposed systems are tested on the NIST Language Recognition Evaluation 2009, against an state-of-the-art i-vector baseline.It also presents a novel approach that combines DNN and i-vector systems by using bottleneck features.The combination of i-vector and bottleneck systems outperforms our baseline system by 45% in EER and Cavg, on 3s and 10s.

@&#KEYPHRASES@&#
LID,DNN,Bottleneck,i-vectors,

@&#ABSTRACT@&#
In this work, we present a comprehensive study on the use of deep neural networks (DNNs) for automatic language identification (LID). Motivated by the recent success of using DNNs in acoustic modeling for speech recognition, we adapt DNNs to the problem of identifying the language in a given utterance from its short-term acoustic features. We propose two different DNN-based approaches. In the first one, the DNN acts as an end-to-end LID classifier, receiving as input the speech features and providing as output the estimated probabilities of the target languages. In the second approach, the DNN is used to extract bottleneck features that are then used as inputs for a state-of-the-art i-vector system. Experiments are conducted in two different scenarios: the complete NIST Language Recognition Evaluation dataset 2009 (LRE'09) and a subset of the Voice of America (VOA) data from LRE'09, in which all languages have the same amount of training data. Results for both datasets demonstrate that the DNN-based systems significantly outperform a state-of-art i-vector system when dealing with short-duration utterances. Furthermore, the combination of the DNN-based and the classical i-vector system leads to additional performance improvements (up to 45% of relative improvement in both EER andCavgon 3s and 10s conditions, respectively).

@&#INTRODUCTION@&#
Automatic language identification (LID) refers to the process of automatically determining the language of a given speech sample (Muthusamy et al., 1994). The need for reliable LID is continuously growing due to a number of factors, including the technological trend toward increased human interaction using hands-free, voice-operated devices and the need to facilitate the coexistence of multiple different languages in an increasingly globalized world (Gonzalez-Dominguez et al., 2014).Driven by recent developments in speaker verification, current state-of-the-art technology in acoustic LID systems involves using i-vector front-end features followed by diverse classification mechanisms that compensate for speaker and session variabilities (Brummer et al., 2012; Li et al., 2013; Sturim et al., 2011). An i-vector is a compact representation (typically from 400 to 600 dimensions) of a whole utterance, derived as a point estimate of the latent variable in a factor analysis model (Dehak et al., 2011; Kenny et al., 2008). While proven to be successful in a variety of scenarios, i-vector based approaches have two major drawbacks. First, i-vectors are point estimates and their robustness quickly degrades as the duration of the utterance decreases. Note that the shorter the utterance, the larger the variance of the posterior probability distribution of the latent variable; and thus, the larger the i-vector uncertainty. Second, in real-time applications, most of the costs associated with i-vector computation occur after completion of the utterance, which introduces an undesirable latency.Motivated by the prominence of deep neural networks (DNNs), which surpass the performance of the previous dominant paradigm, Gaussian mixture models (GMMs), in diverse and challenging machine learning applications – including acoustic modeling (Hinton et al., 2012; Mohamed et al., 2012), visual object recognition (Ciresan et al.), and many others (Yu and Deng, 2011) – we previously introduced a successful LID system based on DNNs in Lopez-Moreno et al.. Unlike previous works on using neural networks for LID (Cole et al., 1989; Leena et al., 2005; Montavon, 2009), this paper represented, to the best of our knowledge, the first time a DNN scheme was applied at large scale for LID and was benchmarked against alternative state-of-the-art approaches. Evaluated using two different datasets – the NIST LRE'09 (3s task) and Google 5M LID – this scheme demonstrated significantly improved performance compared to several i-vector-based state-of-the-art systems (Lopez-Moreno et al.). This scheme has also been successfully applied as a front-end stage for real-time multilingual speech recognition, as described in (Gonzalez-Dominguez et al., 2014).This article builds on our previous work by extensively evaluating and comparing the use of DNNs for LID with an i-vector baseline system in different scenarios. We explore the influence of several factors on the DNN architecture configuration, such as the number of layers, the importance of including the temporal context and the duration of test segments. Further, we present a hybrid approach between the DNN and the i-vector system – the bottleneck system – in an attempt to take the best from both approaches. In this hybrid system, a DNN with a bottleneck hidden layer (40 dimensions) acts as a new step in the feature extraction before the i-vector modeling strategy is implemented. Bottleneck features have recently been used in the context of LID (Jiang et al., 2014; Matĕjka et al., 2014; Richardson et al.). In these previous works, the DNN models were optimized to classify the phonetic units of a specific language, following the standard approach of an acoustic model for automatic speech recognition. Unlike in these previous works, here we propose using the bottleneck features from a DNN directly optimized for language recognition. In this new approach, i) the DNN optimization criterion is coherent with the LID evaluation criterion, and ii) the DNN training process does not require using transcribed audio, which is typically much harder to acquire than language labels. Note that the transcription process involves handwork from experts that are familiarized with specific guidelines (e.g. transcriptions provided in the written domain, or the spoken domain); it is slow, as each utterance typically contains about 2 words/sec and moreover, word level transcriptions needs to be mapped into frame level alignments before a DNN such as the one used in previous works can be trained. That requires bootstrapping from another pre-existing ASR system, typically a GMM-based acoustic model iteratively trained from scratch. Instead, in the process of training lang-id networks, no previous alignments are needed, only one label per utterance is required and annotation guidelines are significantly simpler. Overall, that facilitates the adoption of a bottleneck lang-id system, which has the additional advantage that targets language discrimination in all its intermediate stages.For this study, we conducted experiments using two different datasets: i) a subset of LRE'09 (8 languages) that comprises equal quantities of data for each target language, and ii) the full LRE'09 evaluation dataset (23 languages), which contains significantly different amounts of available data for each target language. This approach enabled us to assess the performance of all the proposed systems in cases of both controlled and uncontrolled conditions.The rest of this paper is organized as follows: Sections 2 and 3 present the i-vector baseline system and the architecture of the DNN-based system. In Section 4, we describe the proposed bottleneck scheme. In Sections 5 and 6, we outline fusion and calibration, and the datasets used during experimentation. Results are then presented in Section 7. Finally, Section 8 summarizes final conclusions and potential future lines of this work.The input audio to our system is segmented into windows of 25ms with 10ms overlap. 7 Mel-frequency cepstral coefficients (MFCCs), including C0, are computed on each frame (Davis and Mermelstein, 1980). Vocal tract length normalization (VTLN) (Welling et al., 1999), cepstral mean and variance normalization, and RASTA filtering (Hermansky and Morgan, 1994) are applied on the MFCCs. Finally, shifted delta cepstra (SDC) features are computed in a 7-1-3-7 configuration (Torres-Carrasquillo et al., 2002), and a 56-dimensional vector is obtained every 10 ms by stacking the MFCCs and the SDC of the current frame. The feature sequence of each utterance is converted into a single i-vector with the i-vector system described next.I–vectors (Dehak et al., 2011) have become a standard approach for speaker identification, and have grown in popularity also for language recognition (Brummer et al., 2012; Dehak et al., 2011; Martinez et al., 2011; McCree, 2014). Apart from language and speaker identification, i–vectors have been shown to be useful also for several different classification problems including emotion recognition (Xia and Liu, 2012), and intelligibility assessment (Martínez et al., 2013). An i–vector is a compact representation of a Gaussian Mixture Model (GMM) supervector (Reynolds et al., 2000), which captures most of the GMM supervectors variability. It is obtained by a Maximum–A–Posteriori (MAP) estimate of the mean of a posterior distribution (Kenny, 2007). In the i–vector framework, we model the utterance-specific supervector m as:(1)m=u+Tw,where u is the UBM GMM mean supervector and T is a low-rank rectangular matrix representing the bases spanning the sub-space, which contains most of the variability in the supervector space. The i–vector is then a MAP estimate of the low-dimensional latent variable w. In our experiments, we have used a GMM containing 2048 Gaussian components with diagonal covariance matrices and the dimensionality of i-vectors was set to 600.For classification, the i-vectors of each language are used to estimate a single Gaussian distribution via maximum likelihood, where the covariance matrix is shared among languages and is equal to the within-class covariance matrix of the training data. During evaluation, every new utterance is evaluated against the models of all the languages. Further details can be found in (Martinez et al., 2011).Recent findings in the field of speech recognition have shown that significant accuracy improvements over classical GMM schemes can be achieved through the use of DNNs. DNNs can be used to generate new feature representations or as final classifiers that directly estimate class posterior scores. Among the most important advantages of DNNs is their multilevel distributed representation of the model's input data (Hinton et al., 2012). This fact makes the DNN an exponentially more compact model than GMMs. Further, DNNs do not impose assumptions on the input data distribution (Mohamed et al., 2012) and have proven successful in exploiting large amounts of data, achieving more robust models without lapsing into overtraining. All of these factors motivate the use of DNNs in language identification. The rest of this section describes the architecture and practical application of our DNN system.The DNN system used in this work is a fully-connected feed-forward neural network with rectified linear units (ReLU) (Zeiler et al., 2013). Thus, an input at level j, xj, is mapped to its corresponding activation yj(input of the layer above) as:(2)yj=ReLU(xj)=max(0,xj)(3)xj=bj+∑iwijyiwhere i is an index over the units of the layer below and bjis the bias of the unit j.The output layer is then configured as a softmax, where hidden units map input yjto a class probability pjin the form:(4)pj=exp(yj)∑lexp(yl)where l is an index over all of the target classes (languages, Fig. 2).As a cost function for backpropagating gradients in the training stage, we use the cross-entropy function defined as:(5)C=−∑jtjlogpjwhere tjrepresents the target probability of the class j for the current evaluated example, taking a value of either 1 (true class) or 0 (false class).From the conceptual architecture explained above, we built a language identification system to work at the frame level as follows:As the input of the net, we used the same features as the i-vector baseline system (56 MFCC-SDC). Specifically, the input layer was fed with 21 frames formed by stacking the current processed frame and its ±10 left/right neighbors. Thus, the input layer comprised a total number of 1176 (21 × 56) visible units, v.On top of the input layer, we stacked a total number ofNhl(4) hidden layers, each containing h (2560) units. Then, we added the softmax layer, whose dimension (s) corresponds to the number of target languages (NL), plus one extra output for the out-of-set (OOS) languages. This OOS class, devoted to unknown test languages, could later allow us to use the system in open-set identification scenarios.Overall, the net was defined by a total of w free parameters (weights + bias),w=(v+1)h+(Nhl−1)(h+1)h+(h+1)s(~23M). The complete topology of the network is depicted in Fig. 1.In terms of the training procedure, we used asynchronous stochastic gradient descent within the DistBelief framework (Dean et al., 2012), which uses computing clusters with thousands of machines to train large models. The learning rate and minibatch size were fixed to 0.001 and 200 samples.11We define sample as the input of the DNN: the feature representation of a single frame besides those from its adjacent frames forming the context.Note that the presented architecture works at the frame level, meaning that each single frame (plus its corresponding context) is fed-forward through the network, obtaining a class posterior probability for all of the target languages. This fact makes the DNNs particularly suitable for real-time applications because, unlike other approaches (i.e. i-vectors), we can potentially make a decision about the language at each new frame. Indeed, at each frame, we can combine the evidence from past frames to get a single similarity score between the test utterance and the targetlanguages. A simple way of doing this combination is to assume that frames are independent and multiply the posterior estimates of the last layer. The score slfor language l of a given test utterance is computed by multiplying the output probabilities plobtained for all of its frames; or equivalently, accumulating the logs as:(6)sl=1N∑t=1Nlogp(Ll|xt​,θ)wherep(Ll|xt​,θ)represents the class probability output for the language l corresponding to the input example at time t, xtby using the DNN defined by parameters θ.Another interesting way to leverage the discriminative power of a DNN is through the use of bottleneck features (Fontaine et al., 1997; Grézl et al., 2009). Typically, in speech recognition, bottleneck features are extracted from a DNN trained to predict phonetic targets, by either using the estimated output probabilities (Hermansky et al., 2000) or the activations of a narrow hidden layer (Grézl et al., 2007), the so-called bottleneck layer. The bottleneck features represent a low-dimensional non-linear transformation of the input features, ready to use for further classification.Utilizing this approach, we extracted bottleneck features from the DNN directly trained for LID, as explained in Section 3, and replaced the last complete hidden layer with a bottleneck layer of 40 dimensions. Then, we modeled those new bottleneck features by using an i-vector strategy. That is, we replaced the standard MFCC-SDC features with bottleneck features as the input of our i-vector baseline system.The underlying motivation of this hybrid architecture is to take the best from both the DNN and the i-vector system approaches. On one hand, we make use of the discriminative power of the DNN model and its capability to learn better feature representations; on the other, we are still able to leverage the generative modeling introduced by the i-vector system.We used multiclass logistic regression in order to combine and calibrate the outputs of individual LID systems (Brümmer and van Leeuwen, 2006). LetskL(xi)be the log-likelihood score for the recognizer k and language L for utterance xi. We derive combined scores as(7)s^L(xi)=∑k=1KαkskL(xi)+βLNote that this is just a generic version of the product rule combination, parameterized by α and β. Defining a multiclass logistic regression model for the class posterior as(8)P(L|s^L(xi))=exp(s^L(xi))∑lexp(s^l(xi))we found α and β to maximize the global log-posterior in a held-out dataset of I utterances(9)Q(α1​,…,αK​,β1​,…βN)=∑i=1I∑l=1NLδtlP(L|s^l(xi))being(10)δiL(wL​,ifxi∈L0,otherwise.where wl(l=1,…,NL) is a weight vector that normalizes the number of samples for every language in the development set (typically, wL= 1 if an equal number of samples per language is used). This fusion and calibration procedure was conducted using the FoCal (Multi-class) toolkit (Brümmer).We evaluate all proposed systems in the framework of the NIST LRE 2009 (LRE'09) evaluation. The LRE'09 includes data from two different audio sources: Conversational Telephone Speech (CTS) and, unlike previous LRE evaluations, telephone speech from broadcast news, which was used for both training and test purposes. Broadcast data were obtained via an automatic acquisition system from “Voice of America” news (VOA) that mixed telephone and non-telephone speech. Up to 2TB of 8kHz raw data containing radio broadcast speech, with corresponding language and audio source labels, were distributed to participants, and a total of 40 languages (23 target and 17 out of set) were included. While the VOA corpus contains over 2000 hours of labeled audio, only the labels from a fraction of about 200 hours were manually verified by the Linguistic Data Consortium (LDC).Due to the large disparity in the amounts of available training material by language and type of audio source, we created two different evaluation sets from LRE'09: LRE09_FULL and LRE09_BDS. LRE09_FULL corresponds to the original LRE'09 evaluation, which includes the original test files and all development training files for each language.22We used the training dataset defined by the I3A research group (University of Zaragoza) in its participation in the LRE'11 evaluation (Martínez et al., 2011).LRE09_BDS, on the other hand, is a balanced subset of 8 languages from automatically labeled VOA audio data. While the LRE09_FULL set uses data from the manually annotated part of the VOA corpus, the LRE09_BDS contains audio from both automatically and manually annotated parts. This dual evaluation approach served two purposes: i) LRE09_FULL, which is a standard benchmark, allowed us to generate results that could be compared with those of other research groups, and ii) LRE09_BDS allowed us to conduct new experiments using a controlled and balanced dataset with more hours of data for each target language. This approach may also help identify a potentially detrimental effect on the LRE09_FULL DNN-based systems due to the lack of data in some target languages. This is important because we previously found that the relative performance of a DNN versus an i-vector system is largely dependent on the amount of available data (Lopez-Moreno et al.).Table 1summarizes the specific training and evaluation data per language used in each dataset.Two different metrics were used to assess the performance of the proposed techniques. As the main error measure to evaluate the capabilities of one-vs.-all language detection, we usedCavg(average detection cost), as defined in the LRE 2009 (Brummer, 2010; NIST, 2009) evaluation plan.Cavgis a measure of the cost of making incorrect decisions and, therefore, considers not only the discrimination capabilities of the system, but also the ability of setting optimal thresholds (i. e., calibration). Further, the well-known metric Equal Error Rate (EER) is a calibration-insensitive metric that indicates the error rate at the operating point where the number of false alarms and the number of false rejections are equal. Since our problem is a detection task where a binary classification is performed for each language, the final EER is the average of the EERs obtained for each language.

@&#CONCLUSIONS@&#
