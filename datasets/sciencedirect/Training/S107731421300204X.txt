@&#MAIN-TITLE@&#
TouchCut: Fast image and video segmentation using single-touch interaction

@&#HIGHLIGHTS@&#
TouchCut requires only a single touch to bootstrap the object segmentation.It incorporates a new model that fuses edge, region, geometric and shape cues.A new fast dominant color extraction scheme to generate edge probability.Temporally propagated shape prior enables extension to video segmentation.Comprehensive qualitative and quantitative evaluations on images and videos.

@&#KEYPHRASES@&#
Object cut-out,Touch interaction,Image and video segmentation,Level set methods,

@&#ABSTRACT@&#
We present TouchCut; a robust and efficient algorithm for segmenting image and video sequences with minimal user interaction. Our algorithm requires only a single finger touch to identify the object of interest in the image or first frame of video. Our approach is based on a level set framework, with an appearance model fusing edge, region texture and geometric information sampled local to the touched point. We first present our image segmentation solution, then extend this framework to progressive (per-frame) video segmentation, encouraging temporal coherence by incorporating motion estimation and a shape prior learned from previous frames. This new approach to visual object cut-out provides a practical solution for image and video segmentation on compact touch screen devices, facilitating spatially localized media manipulation. We describe such a case study, enabling users to selectively stylize video objects to create a hand-painted effect. We demonstrate the advantages of TouchCut by quantitatively comparing against the state of the art both in terms of accuracy, and run-time performance.

@&#INTRODUCTION@&#
The segmentation of objects from cluttered natural images remains a fundamental and inherently challenging Computer Vision problem. The task is generally regarded as under-constrained since, in the absence of high level scene understanding, there can be more than one interpretation of pixels comprising the desired object of interest or ‘foreground’ object. The past decade has seen a trend toward better constraining the segmentation task through: (i) the development and increased reliance on global optimization methods and (ii) the combination of high-level prior scene understanding via user interaction with low-level cues such as color and edges observed in the image.A key challenge of interactive segmentation is to maximize user provided prior information whilst minimizing user intervention. Although recent years have delivered significant advances, a considerable amount of user intervention is still required to achieve a satisfactory segmentation. Typically this involves the user indicating positive and negative class examples of pixels or regions. Often such indications requires correction either automatically to boost discrimination between by the positive or negative classes [1], or by the user iteratively working with the system to supply additional constraints [2]. Regardless of the interaction modality, the goal of any interactive image segmentation is to minimize the amount of effort to cut out a desired object while accurately selecting objects of interest.To address this problem, this paper contributes an efficient algorithm for object segmentation driven by minimal user effort – a single touch. In contrast to previous interaction modes, ranging from roughly marking the desired boundary [3–5] to loosely drawing scribbles labeling the desired object and the background [6–8], to placing a bounding box around the desired object [9,10], our system requires only a single(x,y)coordinate from the user offering an intuitive and maximally “economical” interaction method. Our method has clear applications on emerging touch-screen tablet, mobile and pervasive devices, the form factor of which devices may be inconvenient for fine-motor interaction. Further, in some use cases (e.g. deployment in high throughput, or multi-tasking situations such as driving) the high cognitive load required to trace outlines or regions may also be undesirable.Our core technical contribution is a new model for object segmentation that fuses edge, region, and geometric cues within a level set[11,12] framework. In contrast to previous expanding contour approaches relying on intensity gradient, our proposed model incorporates a probabilistic estimate of edge location derived from a novel dominant color extraction scheme. This scheme offers improved robustness when filling color or texture coherent regions, leading to more accurate localization of the desired object’s boundary. We also fuse this boundary information with a region-based maximum a posteriori (MAP) criterion designed to promote color similarity with pixels local to the touched foreground point. The robustness of this region-based criterion is further enhanced by a consistency constraint enforcing uniformity of deviation from the foreground color model, learned from the touched foreground region. This approach to color consistency, combined with a novel per-pixel adaptive weighting scheme, mitigates the tendency for contour expansion to skip the real boundary when color models of the foreground and background are indistinct. Finally, our proposed model also utilizes the geometric cue implied in single-touch input, that users typically touch image in close vicinity to the geometric center of the desired object.All together, our edge-region-geometry model provides a robust and flexible description of the interactive object segmentation problem, leveraging the flexibility of level set methods to promote accurate boundary placement and strong region connectivity while requiring minimum user interaction. Using an incrementally built foreground color model, our framework also extends to address the temporally coherent video object segmentation problem, creating regions whose shape and neighborhood topology evolve smoothly over time whilst tracking the underlying video content. A motion estimation enabled shape prior is further introduced into the video adaptation to preserve temporal coherence when the foreground and background color distributions are indistinct.Following a literature review, we briefly revisit level set methods in Section 3. We then describe the proposed framework for interactive object segmentation on still images (Section 4), explaining each of the energy terms comprising the proposed energy functional. We extend our system on still images to video sequences in Section 5, presenting an application of our proposed algorithm to tablet-based video manipulation. We present a comparative evaluation with previous work in Section 6 on both a qualitative and quantitative basis, concluding in Section 7.

@&#CONCLUSIONS@&#
