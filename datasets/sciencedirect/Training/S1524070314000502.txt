@&#MAIN-TITLE@&#
Hierarchical Laplacian-based compression of triangle meshes

@&#HIGHLIGHTS@&#
Efficient compression algorithm for triangle meshes is presented.Performance is demonstrated, in particular with respect to perceptual metrics.Hierarchical extension of mesh Laplacian is presented.Prediction of higher order residuals improves performance.

@&#KEYPHRASES@&#
Compression,Perceptual metric,Laplacian,Discrete shape operator,Encoding,Distortion,

@&#ABSTRACT@&#
In this paper, we present an algorithm for efficient encoding of triangle meshes. The algorithm preserves the local relations between vertices by encoding their Laplacian coordinates, while at the same time, it uses a hierarchy of additional vertex constraints that provides global rigidity and low absolute error, even for large meshes. Our scheme outperforms traversal based as well as Laplacian-based compression schemes in terms of both absolute and perceived distortion at a given data rate.

@&#INTRODUCTION@&#
Triangle meshes are getting increasingly popular as a new medium storing shapes of 3D objects, thanks to recent advances in 3D scanning and even 3D printing. Publishing 3D meshes representing products is an attractive new way of marketing, and sharing 3D meshes may be the next step in computer-aided social interaction. Efficient storage of this kind of data is essential in both allowing displaying of the information even on mobile devices with low bandwidth on the content consumer side, as well as in allowing storage of many highly detailed models on the side of the content distributor.The task of mesh compression is to store the triangle mesh in a file that is as small as possible. As with other kinds of media, some precision loss is allowable in most applications in order to achieve even smaller file sizes. This problem has been studied for about two decades now, yet only recently scientists started to seriously analyse the perception-related issues arising from the problem. In particular, measuring the amount of distortion due to the precision loss has recently received much attention. New error metrics have been proposed that capture the perceived distortion much better than mean squared error (MSE) and its derivatives. Along with this progress, new compression algorithms have been suggested, which attempt to minimise the perceived distortion.One of the most efficient algorithms in this regard is the high-pass coding (HPC) proposed by Sorkine et al. [13]. The idea is to express the mesh in terms of local details, using a combinatorial discrete Laplacian. These details are in turn transmitted to the decoder, which solves a linear inverse problem. The approach is very efficient and outperforms all previous methods in terms of perceptual metrics, which usually focus on local similarity of meshes. Despite these advantages, users seem reluctant in adopting this technique, mainly because it lacks a mechanism that would avoid error accumulation. As a result, the performance of HPC in terms of MSE is rather poor, and the algorithm is unable to provide a guarantee of maximum absolute dislocation of vertex positions. This in turn leads to problems when several meshes interact in 3D space by touching each other â€“ even though the HPC compressed meshes show little perceptual distortion, they may intersect or not touch each other correctly, which is a disturbing artifact.In this work, we propose an extension of the HPC algorithm which avoids this problem. We include additional data into the data stream, which describe the higher-level relations between vertices of the mesh, thus limiting the error accumulation and providing a considerable improvement as measured by MSE as well as perceptual metrics. Our extension is expressed in the terms of the original HPC encoding algorithm, and thus it does not require significant changes in the encoding/decoding implementation.

@&#CONCLUSIONS@&#
We have demonstrated that by adding a support structure of additional equations it is possible to construct an algorithm that provides excellent results both in terms of perceived and absolute distortion. Results provided by our compression scheme are visibly better than those of the state of the art, and this conclusion is supported by the measured values.The construction of intermediate reconstructions leads to an increase in running time, which is however only of orderO(log(V))with respect to HPC. The algorithm running time remains within practical range.In the future, we intend to focus on improving the performance of the algorithm, both in terms of efficient compression, as well as fast execution. We believe that the result of intermediate reconstructions can be used to accelerate the solution in the later steps, thus speeding the algorithm up.Another topic of future research is the possibility of encoding the values in reversed order, which would allow the user to display an intermediate decompressed mesh even before the whole data stream has been decoded. Such feature is available in our implementation as well, however, the first approximation is only available after the data from the lowest level (which take up the largest part of the stream) are decoded. Reversing the order of encoding would allow displaying an intermediate reconstruction much sooner, however, the influence of such change on the compression performance is to be investigated.Finally, our results seem to indicate that the used perceptual metrics fail to correctly evaluate the amount of perceived distortion in some cases. It is an interesting pointer for future research to confirm this by a statistically justified subjective experiment. We also believe that the character of the proposed compression method and the proposed hierarchical Laplacian may also be used as a starting point in search for a better error metric.