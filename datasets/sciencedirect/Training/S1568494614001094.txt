@&#MAIN-TITLE@&#
Learning TSK-0 linguistic fuzzy rules by means of local search algorithms

@&#HIGHLIGHTS@&#
Local search methods for learning tsk-0 fuzzy-rule-based systems.Aim at preventing overfitting of the state of the art methods (Least Squares) and improves upon other (Indictive Method).The method based on COR approach is very efficient, and allows robust elimination of rules.Improves the state of the art methods.Improves the performance of the Genetic Algorithm in both precision and number of rules.

@&#KEYPHRASES@&#
Linguistic fuzzy modeling,Evolutionary fuzzy systems,Machine learning,Metaheuristics-based machine learning,Local search,

@&#ABSTRACT@&#
Algorithms for deriving the rule base in Linguistic Fuzzy-Rule Based Systems usually proceed by selecting a set of candidate rules and, afterwards, finding both a subset of them and a combination of values for their consequents. Because of its cost, the latter process can be approached by using metaheuristic techniques such as genetic algorithms. However, existing works show that, if dealing with Mamdani rules – where the consequent is a linguistic label –, a basic local search clearly outperforms the genetic algorithm.In this work we aim to develop a local search algorithm to carry out the described process for the case of TSK-0 fuzzy rules, where the consequent is a real number. The experimental results show that some of the proposed algorithms clearly improve upon the state-of-the-art ones in terms of precision and number of rules, whereas learning times are fairly competitive and are orders of magnitude lower than those required by the genetic algorithm.

@&#INTRODUCTION@&#
Fuzzy Rule-Based Systems (FRBSs) [38] are the most important application of Fuzzy Set Theory [37]. FRBSs are mainly used for modeling and control tasks [18,23,28,30]. Their main advantage, as opposed to other paradigms such as neural networks, is the interpretability of the models. In this respect, there is a subtype of such systems, namely Linguistic Fuzzy Rule-Based Systems (LFRBSs) [27,39], which brings the definition of rules and systems to natural language.Despite the fact that one of the initial (and current [3,40]) purposes of LFRBSs was to make it easier to elicit domain knowledge from experts, it is very common to learn them automatically from data, in particular when they are used for prediction and control. The learning process can be decomposed into two well differentiated tasks: learning the database which contains the definition of the linguistic variables, and deriving the set of fuzzy rules. Although some algorithms perform both tasks simultaneously [1,13,35], they can be carried out independently, in a sequential way. In fact, it is very common to derive the rule base from a pre-defined database [10,12,36], or to use the algorithms for tuning the database once the rules have been learnt [11]. Furthermore, the process of deriving the rules can also be decomposed into two stages: generating the candidate rules; and a second stage which consists of selecting a subset of candidate rules and fixing their consequents.This work focuses on the second part of the rule derivation process, i.e., finding a subset of rules and setting their consequents once the candidate rules are generated. In particular, we studied several specific methods for Takagi-Sugeno-Kang [34] systems of order 0 (TSK-0), which are LFRBSs where the consequent is a real number. We aim to develop a method which is efficient while preserving or even improving upon the results obtained with the state-of-the-art algorithms. For that reason, and in order to perform a complete comparison, we used datasets whose size can be managed by the most expensive methods, as well as the basic scheme to generate candidate rules, which only considers rules with a fixed number of fuzzy predicates (number of input variables in the antecedent).There are few algorithms for TSK-0 rule learning. The two most representative ones in the state of the art are the Inductive Method[24], and the one based on the well-known Least Squares technique for linear regression [32]. In the case of the Inductive Method, the consequent of each rule is determined individually by means of a heuristic technique. This implies not considering the interactions among rules, which are the key point in the expressiveness of FRBSs. The Least-Squares-based method, however, determines all consequents at once, and finds the system which minimizes the training error. However, it tends to overfit. In addition to this, both algorithms take as their starting point the set of candidate rules (their antecedents) which cover at least one input example, and do not reduce the size of such a set. This affects interpretability, since the number of rules is usually large.The algorithms proposed in this study aim to improve upon the accuracy obtained by these two methods and, at the same time, reduce the size of the generated systems. We present two well-differentiated proposals based on local search. In the first one, we carry out a search in the space of subsets of candidate rules, using the aforementioned Least Squares method to determine the optimal set of consequents for each candidate solution which is evaluated. In contrast, the second algorithm, initially tested in [15], only changes one rule at each step of the search. This method is much more efficient, since both the calculation of the optimal consequent for a rule given the rest of the rules, and the update of the error induced by that change, are straightforward. Despite the risk of getting stuck at a local optimum, this algorithm can be expected to outperform populational metaheuristics such as genetic algorithms [22], as is reported in [16] for the case of Mamdani-type rules.This article is divided into 4 sections besides this introduction. First, in Section 2, we introduce TSK fuzzy systems, and describe the two state-of-the-art methods for TSK-0 rule base learning mentioned above. Afterwards, in Section 3, we provide a detailed description of our proposals, which are evaluated experimentally in Section 4. Lastly, in Section 5 we draw some final conclusions and present some lines for future work.Linguistic fuzzy-rule-based systems (LFRBSs) [27,39] were conceived to improve the ability of the expert to introduce or interpret the domain information when performing fuzzy modeling. In the original LFRBSs, also called Mamdani-Type Fuzzy Systems, rules are composed of fuzzy predicates of the form Xiis Ai(e.g. Temperature is High), where Aiis a linguistic label, i.e., a term interpretable by human experts which is associated to a fuzzy set. The variable Xiis called a linguistic variable, and can only take valuesAi∈Ai, whereAiis a predefined and finite set. Therefore, the design of a LFRBS involves the definition of a linguistic DataBase which contains the full specification of the linguistic variables, i.e., the definition of their domains, the fuzzy partitions, the set of linguistic labelsAiwhich can be taken by each input variable Xi, and the labelsBwhich can be taken by the output variable Y.A linguistic rule Rsis expressed as:Rs:IfX1isA1s&…&XiisAis&…&XnisAnsthenY=Bswhere Xiis a domain variable,Ais∈Ai, andBs=B.Given an input exampleel=(x1l,…,xnl,yl), it fires any rule Rsin the system such that∀i=1…nμAis(xi)>ϵ. When a rule is fired by el, it generates as output a fuzzy setBsldefined over the domain of Y as follows:(1)μBsl(x)=μBsl(x)ifμBsl(x)<hslhslifμBsl(x)≥hslwherehsl=T(A1s(x1l),…,Ans(xnl))is the matching degree of elwith Rs, and T is a T-norm. In this work, we will consider the min as T-norm.As the fuzzy sets defining linguistic fuzzy variables usually overlap, an input elcan fire several rules. Consequently, the outputs of such rules must be aggregated into a single output. There are several ways to do this. One of them, the FITA (First Integrate Then Aggregate) approach [14], first defuzzifies (e.g. with the centre of gravity) the output produced by each rule (Bsl) into its corresponding numerical value (vsl), and then carries out the aggregation by calculating the average of such values weighted by the matching degree of each rule. Thus, given a rule baseRB, the predicted output when processing the example elis then obtained as:(2)yˆol=∑Rs∈RB|hsl>ϵhslvsl∑Rs∈RB|hsl>ϵhsl,where ϵ>0 determines the minimum matching degree which fires a rule.There are some variations to the original Mamdani-type systems which aim to improve the accuracy of LFRBSs. Takagi-Sugeno-Kang (TSK) rules [34] are the most important of these. In TSK systems, the consequent of each rule is a polynomial function of the input variables Ps(X1, …, Xn). Therefore, a rule is specified as:Rs:IfX1isA1s&…&XnisAnsthenY=Ps(X1,…,Xn)Given an exampleel=(x1l,…,xnl,yl), the output in a TSK system is obtained as the weighted average – by the matching degree – of the outputs produced by each individual rule in the rule baseRB:(3)yˆol=∑Rs∈RB|hsl>ϵhslPs(x1l,…,xnl)∑Rs∈RB|hsl>ϵhslThe order of a TSK FRBS refers to the degree of Ps. Hence, in TSK-0 systems the consequent is a constant value, and the rules are expressed as:Rs:IfX1isA1s&…&XnisAnsthenY=bswherebs∈ℝ. Therefore, the output produced by an example elwhen processed by a TSK-0 system can be reduced to:(4)yˆol=∑Rs∈RB|hsl>ϵhslbs∑Rs∈RB|hsl>ϵhsl.As can be observed, expressions 3 and 4 are similar to that in Eq. (2).When designing FRBSs for prediction tasks – such as numerical modeling, control, etc. – the rule base is usually derived from data by means of a learning algorithm.In the case of Mamdani LFRBs, the rule learning algorithms take as inputs both a DataSetE={e1,…,el,…,eL}and a DataBase containing the definition of the linguistic variables.11In this article, we use partitions with triangular fuzzy sets. The membership degree of a point x with respect to a triangular function defined in the interval [a,c] and maximum/middle value in b is obtained as:μTriangular(x)=x-ab-a,ifa≤x≤bc-xc-b,ifb≤x≤c0,otherwise.Then, they generate a set of candidate linguistic rules in such a way that every exampleel∈Eis covered by at least one rule; and afterwards, or simultaneously to the generation process, some of the candidate rules are chosen to compose the final rule base [6,12,36].Formally, letSs=(A1s,…,Ais,…,Ans)∈S, withAis∈Ai, be an input subspace of the problem domain.22As mentioned in Section 1, in this work we consider rules of fixed size. Because of this, we only consider input subspaces defined by n labels.It contains the subset of input examplesEs⊆Esuch thatel∈Esif∀i=1…nμAis(xil)>0.The learning algorithms generate a set of candidate rulesCRsfrom each subspace, Ss, in such a way that each rule inCRscoversEs. Therefore, a ruleRs∈CRsis expressed as:Rs:IfX1isA1s&…&XiisAis&…&XnisAnsthenY=Bs.The number of input subspaces grows exponentially with the number of variables and granularity of the fuzzy partitions, since|S|=∏i=1n|Ai|. However, the learning methods usually generate rules which only cover a certain set of subspaces, denotedS+. In general, it is common to consider all non-empty subspaces. In such a case,Ss∈S+if∃el∈E|∀i=1…nμAis(xil)>0.Thus, an input subspace Ssis used to generate candidate rules ifEs≠∅. Therefore, each example elcan generate more than one rule, since input subspaces are defined by fuzzy partitions which overlap.The next step carried out by the learning algorithms is the selection of one rule (in most cases) from each subsetCRs.33Consequents considered to generate each subsetCRsare also derived fromEs. However, as this paper focuses on TSK-0 rules, we will not refer to this. Further information can be found in [6].As all rules inCRshave the same antecedents, the task of selecting one of them can be viewed as fixing the consequent for the rule Rswhich covers the subspace Ss. From now onwards, both concepts will be used without distinction in this article.Although there are some criteria which make it possible to evaluate and select each rule (consequent) individually [12,36], the overall system performance depends on the joint behaviour of the whole set of rules.LetRlbe the set of rules fired by the input el(Rl={Rs∈RB|hsl>ϵ}). The outputyˆlis obtained through a combination of the outputs produced by each rule inRl(expressions 2, 3,4). Thus, the real peformance of a rule Rsmust be evaluated in the context ofRl. In general, ifEs={el∈E|hsl>ϵ}, the evaluation of Rsdepends on those rules Rtsuch thatEs∩Et≠∅. This is called cooperation among rules, and is considered by algorithms such as those based on COR (Cooperative Rules) methodology [6], which set out the problem as a discrete optimization one, and search for the combination of consequents which minimizes the error of the system over the training data.Lastly, it is very important to allow learning algorithms not to include any rule from some of the subsetsCRs. This would be represented by setting Bs=∅. In this way, algorithms can discard rules which degrade the performance of the system (produce overfitting) while, at the same time, the size of the final rule base can be reduced.In the case of TSK-0 LFRBSs, the problem of learning the rule base becomes slightly different. The rule Rsgenerated from an input subspace Ssis expressed as:Rs:IfX1isA1s&…&XiisAis&…&XnisAnsthenY=bs.As bsis a real number, its value must be estimated or found, instead of selected from a finite set of labels, as was the case of Mamdani rules.There are two well-known methods for TSK-0 rule learning. The first one, called the Inductive Method[24], tries to determine the consequent bsfor each rule Rsindividually; whereas the second one, Least Squares, determines all consequents at once by setting out the problem as a linear regression one. Both methods are described in detail below.The Inductive Method is a heuristic technique proposed in [24], and also used in [32] to generate an initial set of TSK-0 fuzzy rules from data. Basically, from each positive input subspace Ss∈S+ it generates a rule Rssuch that:bs=∑el|hsl>0hslyl∑el|hsl>0hsl.Thus, the consequent bsis obtained as the average of the output values ylof each exampleel∈Es, weighted by the matching degrees of elwith each rule Rs.As the Inductive Method produces one rule for each positive input subspace, the final rule base is composed of exactly|S+|fuzzy rules. Moreover, each rule is generated individually. Therefore, this method does not consider cooperation among rules.The problem of finding the right consequents for a TSK-0 LFRBS can be stated as a linear regression one, and solved by minimizing the squared error in the prediction of the training data by means of the well-known Least Squares technique [32]. As this method obtains the consequents of all rules at once, and is guided by the error of the system, it implicity considers cooperation among rules.Given a candidate rulebaseRBo, the output when processing an example elis obtained as shown in Eq. (4). This operation can be vectorized as:yˆol=c1l⋯c|RBo|lb1⋮b|RBo|wherecslis:csl=hsl∑Rt∈RBohtl.Taking into account the L examples included in the data setE, the predictions for each example can be represented with matrix notation as follows:Y=C·B=y1⋮yL=c11⋯c|RBo|1⋮⋮⋮c1L⋯c|RBo|Lb1⋮b|RBo|.By using the normal equation, the values of B can be obtained as:B=(CTC)−1CTYAs calculating the pseudoinverse(CTC)−1is computationally expensive, B can be obtained with the sequential method proposed in [32]. However, this method can still be slow even for small-size problems. Because of this, we have used Singular Value Decomposition [26]. Previous experimentation (with the datasets used in this article) show that this approximate method is, on average, 35 times faster than the sequential one, while preserving, or even improving upon, the results obtained.The methods for learning TSK-0 rules described in the previous section have different problems with regards to precision. Thus, the Inductive Method can perform poorly because of not considering cooperation among rules, whereas Least Squares may overfit the training dataset.Furthermore, both methods learn systems which include one rule obtained from eachSs∈S+. However, there are two important reasons why it becomes important to discard some rules. The first one is related to interpretability, since smaller rule bases are more easily interpretable by human experts. The second one is overfitting which, as mentioned above, may become more significant in the case of Least Squares. For this method, reducing the number of rules can also improve the prediction capability over test cases.In this section, we propose two algorithms for finding smaller and more precise systems. The first one is a Local Search algorithm which explores the possible subsets of rules, and uses Least Squares to determine the optimal consequents for each one of the subsets explored. The second is based on the COR [6,29] methodology, and carries out a heuristic search to determine the optimal combination of consequents. This method is aimed both at increasing the efficiency of the learning process, and reducing overfitting. Moreover, it can be easily modified to implement an Iterated Local Search method, where the local search is restarted several times so as to avoid local optima. Furthermore, the procedure used to generate the different starting points can be exploited to reduce the number of rules.The Least Squares method described in the previous section generates exactly|S+|rules, since it takes into account all the subspacesSs∈S+to generate the candidate rules. However, Least Squares can be applied to any subset ofS+. Thus, ifSo⊆S+, then Least Squares generatesRBowith the|So|rules which minimize the squared error with respect to the training dataset,E.As there are2|S+|possible subsets ofS+, and it is necessary to run Least Squares to carry out each evaluation, the exhaustive search may become computationally unfeasible even for few variables and/or labels. Because of this, we propose to look for the best subset ofS+by means of a heuristic algorithm. In particular, and due to the time required to carry out each evaluation, we use a Local Search[21] procedure.Since the search is defined overP(S+), i.e., subsets ofS+, so is the neighbourhood of a certain configuration. Hence, the neighbourhood of the setSo, expressed asN(So)⊆P(S+), is defined as:So′∈N(So)⇔∃!Ss∈S+|Ss∈So⊕Ss∈So′,i.e.,So′is a neighbour ofSoif both contain the same input subspaces, with the exception of one, Ss, which is included in only one of the sets.It should be noted that, even if two neighboursSoandSo′only differ in the inclusion of one candidate rule, the consequents of the rest of the rules can be different, since Least Squares recalculates all of them at once.Algorithm 1 shows the pseudocode of the method, which has been called LeastSquares-LS (Least Squares Local Search). As can be seen, the method takes as inputs both the datasetEand the linguistic databaseLDB, and implements a standard Hill Climbing[21] process which iteratively moves to the best neighbour of the current solution (by adding or deleting a candidate rule) until there is no possible improvement.The evaluation of every configurationSocorresponds to the evaluation of the generated rule systemRBoover the training datasetE. In this study, we consider the Mean Squared Error (MSE) as a measure. Letyˆolbe the output produced by the LFRBS which contains the set of rulesRBowhen processing the example el. The error is obtained as follows:(5)MSE(RBo,E)=1L∑l=1L(yˆol−yl)2Algorithm 1LeastSquares-LS algorithmprocedureLeastSquares-LS (E,LDB)S+←generateInputSubspaces (E,LDB)So←generateInitialSolucion (S+, P) // P∈{0.5, 0}RBo←LeastSquares (So,E,LDB)repeatfor allSo′∈N(So)doRBo′←LeastSquares (So′,E,LDB)ifMSE(RBo′,E)<MSE(RBo,E)thenRBo←RBo′So←So′end ifend foruntilMSE(RBo,E)does not improvereturnRBoend procedureLastly, since local search algorithms are very sensitive to the initial solution, we have considered two alternatives to test the relevance of this fact:1Starting from a random subset such that the probability of including a subspace Ssin the initial configurationSoisP(Ss∈So)=0.5. Therefore, the expected size of the initial configuration is|S+|/2.Starting from an empty subset of input subspacesP(Ss∈So)=0. As local search is biased towards the initial set of rules, it can be expected that the set of rules obtained by means of this algorithm is even smaller when using the empty set as the starting point.It is worth pointing out that we also considered starting the search from the full setS+. However, we discarded such a possibility for two reasons. First of all, it requires a prohibitive amount of time to execute, much more than the other two initializations. This is due to the fact that the time required by Least Squares depends on the number of rules. Secondly, we carried out some preliminary experiments with the smallest datasets, and even though this algorithm reduces the training error, the results for the test are similar to those obtained with Least Squares, whereas the reduction in the number of rules is not significant.The algorithm presented above is defined overP(S+), and must carry out a Least Squares procedure overEfor every subset of rules evaluated. As this may involve calculating pseudo-inverses of matrices (depending on the numerical method), the process can be very time-consuming, and sometimes requires a significant amount of time (in the order of hours or even days) to finish even for small problems. Moreover, although it can potentially reduce the number of rules, it may still overfit training data.The study in [16] describes an efficient method for learning Mamdani-type rules which is based on the Cooperative Rules (COR) methodology [7,9]. The original COR algorithms use population-based metaheuristics, such as Genetic Algorithms[8] or Ant Colony Optimization [5], to find the optimal combination of consequents for a given set of candidate rules. However, as interaction only occurs among adjacent rules in FRBSs, the method proposed in [16] uses a local search procedure. At each step, it evaluates all possible changes that can be made to each rule in the system, and carries out only the best one. This procedure ends when the error stops decreasing. The results achieved improve upon those obtained with a Genetic Algorithm in terms of MSE, whereas efficiency is considerably better.The aforementioned algorithm, though, cannot be directly applied to TSK-0 rules, since in such a case the problem is a numerical (and not combinatorial) optimization one, and the size of the neighbourhood of a certain configuration is infinite. However, given a rule baseRBo, and a certain input subspace Ss, we describe how to obtain the consequent for the ruleRso– the rule inRBowhich covers Ss– which, given the rest of the rules inRBo, produces the smallest MSE overE[15].Letel∈Esbe all examples covered byRso(i.e., contained in Ss), andRl⊂RBothe set of rules fired by el. The output produced by the systemRBowhen processing elis obtained, according to the inference procedure described in Eq. (4) as:yˆol=∑Rso∈Rlhslbs∑Rso∈Rlhsl=∑Rto∈Rl|Rto≠Rsohtlpt+hslbs∑Rto∈RlhtlIn order to simplify notation, it will be considered thatHol=∑Rto∈RlhtlandHBo−sl=∑Rto∈Rl|Rto≠Rsohtlbt(the output produced by firingRsois separated out). The above equation can then be rewritten as:yˆol=HBo−sl+hslbsHol.The squared error produced byRBowhen processing the example elis:SE(RBo,el)=HBo−sl+hslbsHol−yl2,while the MSE produced by the systemRBowhen calculating the outputs for all the examples covered by the rule Rsis:MSE(RBo,Es)=∑el∈Es((HBo−sl+hslbs/Hol)−yl)2|Es|.As this function is quadratic in bs, it is possible to calculate its minimum as the point whereMSEo(RBo,Es)′=0, i.e, the derivative with respect to bsis 0. The optimum consequent for the rule Rs,bso, is then obtained as:(6)bso=∑el∈Es(2ylHolhsl/Hol2)−∑el∈Es(2HBo−slhsl/Hol2)∑el∈Es(2hsl2/Hol2).The method for calculating the best consequent for a given rule makes it possible to define the neighbourhood of a certain rule baseRBo. Let bsbe the current consequent ofRso∈RBo. The subset of neighbours generated by changing onlyRso, denotedNs(RBo), is obtained by replacing bsby either the best possible consequentbso, or ∅, which represents the non-inclusion of the rule in the system. In this way,|Ns(RBo)|=2. The whole neighbourhood ofRBo, denotedN(RBo), includes the rule bases generated by applying the two possible changes to each one of the rules:N(RBo)=∪Ss∈S+Ns(RBo).Therefore|N(RBo)|=|S+|·2.Algorithm 2 shows the scheme of the Local Search procedure, which is called COR-Local Search. Once an initial solution is generated, this algorithm performs a HillClimbing by carrying out, at each iteration, the step which produces the highest decrement in the MSE. The algorithm stops when no change produces an improvement.Algorithm 2COR Local Search algorithm for TSK-0 rule learningS+←generateInputSubspaces (E,LDB)RBo←GenerateInitialSolution (S+,E,LDB)procedureCOR-LS (RBo,E,LDB)repeatfor allRBo′∈N(RBo)doifMSE(RBo′,E)<MSE(RBo,E)thenRBo←RBo′end ifend foruntilMSE(RBo,E)does not improvereturnRBoend procedureBesides the size of the neighbourhood of a given rule base being relatively small, many calculations can be avoided, as explained in [16].LetNs(RBo)be the subset of neighbours ofRBoobtained by replacing the ruleRso, and letRBos∈Ns(RBo)be one of such neighbours. It is not necessary to evaluate all elements inN(RBos). In fact, ifEs∩Et=∅, there is no need to re-calculate anyNt(RBos). IfRBot∈Nt(RBo), andRBost∈Nt(RBos), then:MSE(RBot,Et)−MSE(RBo,Et)=MSE(RBost,Et)−MSE(RBos,Et),as the change in the ruleRsodoes not affect the outputs for the examples covered byRto.Also in relation to efficiency, it is worth pointing out that, givenMSE(RBo,E),MSE(RBos,E)can be obtained by re-calculating the outputs for only those examples covered by the ruleRso(Es).Lastly, the algorithm may perform an extremely large number of iterations. Nevertheless, there is a point after which the improvements made are insignificant, and evaluations barely reduce the error. There are two strategies that can solve this problem. The first one consists of stopping the search when the improvement produced does not reach a threshold. The second one, which is used in this work, avoids evaluating neighbours when the difference between the best consequent for a certain rule,bso, and its current consequent does not reach a minimum threshold. We have fixed this threshold at 1/20 of the range of the variable.Extensions of local search algorithms can also be efficiently implemented. In [16], an Iterated Local Search[21] algorithm is described. In this method, detailed in Algorithm 3, once the local search reaches a local optimum, the current solution is perturbed and used as a starting point for the subsequent search. This procedure iterates several times, and returns the best solution found.Algorithm 3COR Iterated Local Search algorithmprocedure COR-IterLS (E,LDB)S+←generateInputSubspaces (E,LDB)RBo←GenerateInitialSolution (S+,E,LDB)RBbest←RBoforiteration∈{1…numIterations} doRBo←COR-LS (RBo,E,LDB)RBo←perturbate (RBo,E,LDB)ifMSE(RBbest,E)<MSE(RBo,E)thenRBbest←RBoend ifend forreturnRBbestend procedurePerturbation can be performed by changing some consequents at random. However, we have tried two schemes aimed at reducing the number of rules:1Using the Greedy Elimination process described in Algorithm 4. This process deletes rules by following a greedy criterion - at each step it chooses the rule which produces a smaller increment in the error - while the error of the local optima is not surpassed by more than t%. As the goal of perturbation is to generate a new starting point for the local search, and not to obtain the final system, the risk when eliminating too many rules is not very significant. Therefore, t need not be very small.Deleting some rules at random. Rules are removed unless the induced error is incremented by more than 5%. In such a case, the rule is considered to be important, and therefore is not deleted.Algorithm 4Greedy Elimination procedureprocedure GreedyElimination (RBo,E,LDB)RBo′←RBorepeatRBo′←DeleteWorstRule (RBo′,E,LDB)untilMSE(RBo′,E)>(1+t)·MSE(RBo,E)returnRBo′end procedureFor the experimental evaluation, we used a benchmark composed of 18 different regression datasets. Table 1shows their main characteristics. Some of them (f1, f2, f3, f4) were obtained from [4]; another one, (f5), was obtained by sampling the Schwefell function described in [33]; lastly, the remaining datasets were obtained from [25].All algorithms were run 30 times over each dataset. For each run, the training data were generated by a random selection of 80% of the instances, using the number of execution as seed, and leaving the remaining 20% of the examples for testing. Tables A.6–A.23, included in Appendix A, show the results – averages – for training and test errors, non-covered test examples44For those cases, the systems use the mean of the output variable as prediction. However, we consider that this information is so important as to be reported.(#NC), number of rules included in the final rule base, number of processed instances during the learning process (#inst.), and time (in seconds) needed to run the algorithm.Lastly, Least Squares generates rules where the values of the consequents are not restricted, and only the result of the inference process was restricted to the domain of the output variable. The same criteria were applied to the rest of the algorithms. Moreover, we fixed a wall clock time of 30h. For those cases where one execution exceeds the walltime, the results correspond to the best solution found up to that point.In relation to the proposed algorithms, we used the aforementioned initializations for the Least Squares-LS algorithm: a randomly selected set of rules (Random), and a set with no rules (Empty). As for the COR-Local Search algorithms, including Iterated Local Search, the starting point was obtained by means of the Inductive Method. Moreover, the maximum number of iterations for Iterated Local Search was set to 20.As a baseline for comparison, we tested both the Inductive Method and Least Squares algorithms, described in Section 3.2. Moreover, we evaluated a method which searches the consequents of the rules by means of a genetic algorithm. This method, which is an adaptation of the one proposed for Mamdani rules [8], codifies each individual as an array of real values, also allowing the use of ∅ to represent the non-inclusion of a rule. We have used the BLX-Alpha crossover [19] (α=0.5) with probability 0.9. When one of the alleles involved is ∅, the crossover swaps their values. Mutation was applied with a probability of 0.01. In order to reduce the size of the obtained systems, 75% of the times the mutation operator fixes the value to ∅, whereas in the rest of the cases it generates a random value. The algorithm uses a population of 100 individuals, tournament selection with size 2, and stops when there has not been any improvement for 50 generations. Lastly, it is worth pointing out that the parameter configuration was chosen after a set of previous experiments.Besides the aforementioned settings, it must be considered that all the algorithms presented so far aim to reduce the error in prediction for the training data. However, they do not penalize the excessive number of rules. Thus, many of the rules which are included might not affect the training error, and could be eliminated from the final set of rules. Besides reducing the size of the final system, this would help to prevent overfitting.In Section 3.3, we described a greedy method (Algorithm 4) to perturb solutions by eliminating rules in the COR-ILS. The same method can be used to eliminate useless rules after the search. However, the parameter t, which determines the maximum increase in error allowed, must be reduced substantially. Otherwise, the quality of the obtained set of rules must decrease for both the error in test and the number of non-classified instances. After preliminary experimentation, we fixed the threshold for the training error at 1% (t=0.01).Next, we compare the performance of all algorithms. The study was carried out in two steps. Firstly, we compared the proposed methods, selecting the best one. Afterwards, we compared the outstanding algorithm with the state-of-the-art methods.We used the software provided in [20] to carry out a comparison of the algorithms based on a statistical analysis. For each measure, we proceeded as suggested in [17]: performing a Friedman test first, and then a post-hoc Holms test, with α=0.05. Furthermore, as is suggested in [17] as well, the Friedman test cannot be used when the number of algorithms is smaller than 5. Therefore, we have carried out a Wilcoxon signed rank test in such cases.There are several criteria which must be considered in order to evaluate the algorithms: precision, simplicity, and computational cost of the learning process. The comparisons were carried out in three steps, according to the importance of each measure:1First, we compared the error. Then, those algorithms presenting a statistical difference with respect to the best one, which was marked with •, were crossed out and discarded.Once we had selected those algorithms producing more precise models, we aimed to select the simpler models, that is, those with a smaller number of rules. We proceed in the same way to compare the size in the selected algorithms, crossing out and discarding those presenting a statistical difference with respect to the reference one.Lastly, among the models which are similar in accuracy and number of rules, we selected those requiring less time during the learning process. Although this parameter may not be fully precise, it is more representative than other measures, such as the number of processed instances, since the latter do not reflect the high execution times for those algorithms based on Least Squares.Table 2shows the results of the comparisons. For each measure, the software shows the average rank of each algorithm in the Friedman test.In order to gain greater insight into the results, we provide some numerical results. Due to the difference in the output ranges of the problems, the average values over all the problems might not be informative. Because of that, we have scaled all values in relation to the results obtained by the COR-Local Search+Elimination algorithm which, according to the tests, is the outstanding one. These results are shown in Table 3. It is worth pointing out that the averaged ratios only provide a general overview of the results for the whole benchmark. For more detailed information on the results, we refer the reader to the tables in Appendix A.As mentioned above, the first comparison focuses on precision. One of the things which can be noticed is that all but one of the algorithms which use the Elimination stage present a statistical difference with respect to the most precise, which is COR-Local Search. Not all of them seem to underfit the training examples. In fact, according to Table 3, COR-ILS algorithms, even followed by elimination, obtain on average a similar training error to the reference algorithm. However, the error grows for the test. This effect is different in the case of COR-Local Search, since the precision is not statistically different when applying Elimination.The algorithm Least Squares-LS (Random) is also discarded regardless of whether Elimination is or not added. It might be expected that this algorithm overfits the data. However, it does not seem the case according to the average training error.In relation to the number of rules, Least Squares-LS (Empty) is the algorithm which clearly uses a smaller number of rules among those algorithms similar in performance; and only one algorithm, namely COR-Local Search+Elimination, does not present a statistical difference with respect to it. COR-ILS algorithms, on the other hand, produce systems with a larger set of rules, even when using elimination in the perturbation phase.55Although averages are smaller for COR-ILS algorithms, variance is bigger, and they obtain more rules in more cases. That is the reason why they do not pass the test.Lastly, both Least Squares-LS (Empty) and COR-Local Search+Elimination, are the outstanding proposals, and there is no difference between them if comparing precision and number of rules. However, when comparing the execution times, COR-Local Search+Elimination is about 50 times faster.66When using the sequential method suggested in [32], the difference increases up to 300 times.In the previous stage of the experimentation, we determined that COR-Local Search+Elimination is the outstanding algorithm, since there is no other that is similar in terms of precision, number of rules and learning time.In the second stage, we compared this algorithm with the existing methods. Two of them, the Inductive Method and Least Squares, have been widely used so far. The third one, the COR-Genetic Algorithm, aims to determine whether the use of local search indeed results in some additional benefit over the use of other metaheuristics for this specific problem.We have proceeded in the same way in order to carry out the study. Table 4shows the results of the three-step-statistical comparison, whereas Table 5shows the average for results for all algorithms scaled to those obtained with the reference one which, again, is COR-Local Search+Elimination.As can be observed in Table 4, the COR-Genetic Algorithm obtains the best results in terms of precision. But neither the Inductive Method nor COR-Local Search+Elimination show a statistical difference with this algorithm. When observing the data in Table 5, it seems clear that Least Squares algorithms overfit the training dataset, whereas the problem with Inductive Method+Elimination and COR-Genetic Algorithm+Elimination is just the opposite. Again, it seems that adding an Elimination stage degrades the performance of the algorithms.As for the number of rules, COR-Local Search+Elimination is the algorithm, among those with the same precision, which generates systems with a smaller number of rules, whereas the other two selected algorithms show a significative statistical difference with respect to it. In particular, the Inductive Method uses 48% more rules on average, which is a huge difference.Although COR-Local Search+Elimination is the outstanding algorithm when considering both precision and rules, it is important to point out that execution times are clearly smaller than those required by the COR-Genetic Algorithm, which requires over 400 times the time required by the COR-Local Search+Elimination to learn the models.The experiments have shown that the performance of most algorithms tested are similar (without Elimination) in terms of error. With the exception of Least Squares, which overfits the training dataset, the rest of the algorithms show no significative difference with COR-Local Search.As the other main criterion which has been used to evaluate the algorithms is the number of rules generated, the Elimination stage definitely plays a key role in the comparison of the algorithms. Thus, the precision of many of the methods drops dramatically when eliminating rules, and most of them were discarded because of that. At this point, we must recall that the error for training remains almost the same, and the effect is related to the test. Elimination after COR-Local Search, however, results in a significant reduction in the number of rules without degrading the precision. That leads us to think that COR-Local Search obtains systems which are more robust when it comes to elimination. In fact, 3 shows that the Elimination stage deletes, on average, 17% of the rules. The explanation for this is that, even considering cooperation, this algorithm optimizes individual rules, and the consequents of some other rules might not be so relevant.The last point concerns execution times. In this respect, COR-Local Search is much faster than the Least Squares-LS algorithms or the COR-Genetic Algorithm, which are comparable for precision and simplicity. It is important to point out that in both cases the times required by COR-Local Search are orders of magnitude smaller.

@&#CONCLUSIONS@&#
In this article, we have presented two different local search algorithms for learning TSK-0 rules. One of them searches a subset of candidate rules, and uses an existing method, Least Squares, to fix the consequents and evaluate each candidate subset. For the other proposal, namely COR-Local Search, we have provided a way to calculate the optimal consequent for a rule given the rest of the system. This method makes it possible to implement an efficient local search procedure where the neighbourhood is small, and the evaluation of each neighbour only implies the processing of the examples covered by a rule. Moreover, this method considers cooperation.Judging by the results, it seems that the COR-Local Search+Elimination is clearly the outstanding algorithm among the proposed techniques. There is another proposal, namely Least Squares-LS (Empty), which learns systems that are comparable in terms of precision and size, but it requires over 50 times more computation to learn the models.On the other hand, when compared with the state-of-the-art algorithms, COR-Local Search+Elimination yields results that are similar in error to the COR-Genetic Algorithm. However, the number of rules of the systems obtained with the latter algorithm is bigger. In this regard, it should be noted that the Elimination process has also been tested with the COR-Genetic Algorithm. However, it resulted in a degradation of the precision of the system. Lastly, it is important to point out that the genetic algorithm is orders of magnitude slower.In relation to the other state-of-the-art algorithms, the Inductive Method uses, on average, many more rules than the outstanding algorithm, whereas Least Squares usually presents overfitting.From this study, we can conclude that despite performing poorly for some other general optimization problems, local search is suitable for finding the combination of consequents which yields the best LFRBSs in the case of TSK-0 rules. Besides obtaining results that are similar to, or better than, other state-of-the-art algorithms in terms of precision and number of rules, local search algorithms require, in general, much less time than the genetic algorithm, which is generally used for this task.