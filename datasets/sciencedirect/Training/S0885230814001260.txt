@&#MAIN-TITLE@&#
Four-participant group conversation: A facilitation robot controlling engagement density as the fourth participant

@&#HIGHLIGHTS@&#
We present a framework for facilitation robots in four-participant conversations.The robot regulates imbalanced engagement density as the fourth participant.We propose procedures for obtaining initiatives to control the situation.Conversational situations and facilitation procedures are modeled as POMDP.The experimental results show the evidence of procedures’ acceptability.

@&#KEYPHRASES@&#
Multiparty conversation,Facilitation robot,Conversational strategy,Engagement density control,Multimodal processing,Partially observable Markov decision process,

@&#ABSTRACT@&#
In this paper, we present a framework for facilitation robots that regulate imbalanced engagement density in a four-participant conversation as the forth participant with proper procedures for obtaining initiatives. Four is the special number in multiparty conversations. In three-participant conversations, the minimum unit for multiparty conversations, social imbalance, in which a participant is left behind in the current conversation, sometimes occurs. In such scenarios, a conversational robot has the potential to objectively observe and control situations as the fourth participant. Consequently, we present model procedures for obtaining conversational initiatives in incremental steps to harmonize such four-participant conversations. During the procedures, a facilitator must be aware of both the presence of dominant participants leading the current conversation and the status of any participant that is left behind. We model and optimize these situations and procedures as a partially observable Markov decision process (POMDP), which is suitable for real-world sequential decision processes. The results of experiments conducted to evaluate the proposed procedures show evidence of their acceptability and feeling of groupness.

@&#INTRODUCTION@&#
We present a framework for facilitation robots regulating engagement density to maintain a four-participant conversation as the forth participant with procedural steps obtaining initiatives. Four is the special number in multiparty conversations. The three-participant conversation is the minimum unit where the participants autonomously organize a multiparty conversational situation. The fourth participant is the first person who can objectively observe the conversational situation. In three-participant conversations, social imbalance, in which a participant is left behind in the current conversation, sometimes occurs. In such scenarios, a conversational robot has the potential to objectively observe and control situations as the fourth participant. A four-participant conversational situation, where three participants and a facilitator are participating, is the minimum unit of the facilitation process model.Fig. 1(a) depicts a two-participant conversation. In such situations, conversational context, including engagement (Sidner et al., 2004) and turn-taking (Sacks et al., 1995), is commonly grounded between two interlocutors. Many dialogue systems have dealt with turn-taking within two-participant engagement (Raux and Eskenazi, 2009; Chao and Thomaz, 2012). However, in three-participant conversations as shown in Fig. 1(b), which is the minimum unit for multiparty conversation, engagement and turn-taking cannot always be identified among the participants. In terms of turn-taking in multiparty conversations, the participation structure model was presented by Clark (1996), drawing on Goffman's work (1981). In the participation structure model, each participant is assigned a participation role considered by the current speaker, where speaker, addressee, and side-participant are “ratified participants” (Goffman, 1981). In such three-participant situations, interactions between two dominant participants primarily occur between participants A and B, and the other participants, who cannot properly get the floor to speak for a long while (can neither be promoted to a speaker nor an addressee), tends to get left behind, even though all participants are ratified.Such a social imbalance problem cannot be solved easily because participation roles do not always share common ground among the ratified participants. For example, in Fig. 1(b), participant C might not be able to properly take chances to assume the floor to speak for a while, and thus, from his viewpoint, is left out of the dominant conversation, even though floor exchanges may be well maintained among participants from participant A's viewpoint. If situational comprehension of the participation structure is diverged among the participants and participant A cannot recognize the left-behind situation, he may not be motivated to self-initiate control of the situation. In the left-behind situation, the engagement density may be different between dominant participants and the left-behind participant. The dominant participants’ engagement is so strong that participant C's engagement with others is relatively weak. In addition, it is also possible that participant C cannot share a common interest topic with the other participants. Consequently, socially imbalanced three-participant situations dictate the need for an additional facilitator participant to help the left-behind participant “harmonize” with the other participants. In this context, “harmonize” means maintaining equality of engagement density within the group. A four-participant conversational situation is the minimum unit of the facilitation process model, which has never been discussed substantially in research of both conversational analysis and dialogue systems. Conversational robots have the potential to participate as the fourth participant to facilitate such conversations, as is illustrated in Fig. 2. Kobayashi and Fujie (2013) have discussed the importance of situated human-like conversational robots, which are capable of omitting and understanding conversational protocols. Generally, when a facilitator (robot) steps into the situation to coordinate, it should follow properly established procedures to obtain initiative within situations and give this initiate back to the other participants. To coordinate situations, a facilitator must take the following procedural steps. (1) Be aware of both the presence of dominant participants leading the current conversation and the status of a left-behind participant; (2) obtain an initiative to control the situation and wait for approval from the others, either explicitly or implicitly; and (3) give the floor to a suitable participant (sometimes by initiating a new topic).Various related research on specially situated facilitation agents in multiparty conversations has been conducted. Matsusaka et al. (2003) pioneered the use of a physical robot participating in multiparty conversations. We have previously developed a multiparty quiz-game-type facilitation system for elderly care (Matsuyama et al., 2008) and reported the effectiveness of the existence of a robot (Matsuyama et al., 2010). Dohsaka et al. (2009) developed a thought-evoking dialogue system for multiparty conversations with a quiz-game task. They reported that the existence of agents and empathic expressions is effective for user satisfaction and can increase the number of user utterances. Sidner et al. (2004) developed an agent system that can engage with users, where they defined engagement as “the process by which two (or more) participants establish, maintain and end their perceived connection during interactions they jointly undertake”. Bohus and Horvitz (2009) modeled engagement in multiparty conversations using Sinder's definition. They evaluated the effectiveness of multimodalities, including gaze, gesture, and speech, for a multiparty conversation facilitating agent (Bohus and Horvitz, 2010). In terms of facilitation, Kumar et al. (2011) designed a dialogue action selection model based on Bales’ Socio-Emotional Interaction Categories for text-based character agents. However, there is a lack of profound consideration regarding engagement density in multiparty conversational situations and procedural operations for obtaining initiative to control conversational situations while considering their side-effects, which typically occur in multiparty conversational situations.In this paper, we propose a procedural facilitation process framework to harmonize a four-participant conversational situation. The situations and procedures are modeled and optimized as a partially observable Markov decision process (POMDP), which is suitable for real-world sequential decision processes, including dialogue systems (Williams and Young, 2007). The remainder of this paper is organized as follows. We begin by reviewing facilitation frameworks in small groups and describing procedures for maintaining small groups. In Section 3, we discuss how to model them as POMDP. In Section 4, we give an overview of the architecture of our proposed system. We then discuss three experiments conducted to verify the efficacy of the small group maintenance procedures and the performance of POMDP. Finally, we summarize and conclude this study.In this section, in order to organize the facilitation framework, at first, we review related works of facilitation models in small groups, specifically functional roles of group members that have been defined to analyze facilitation processes. Then we review engagement models, and we propose the harmony model.Benne and Sheats (1948) analyzed functional roles in small groups to understand the activities of individuals in small groups. They categorized functional roles in small groups into three classes: Group task roles, Group building and maintenance roles, and Individual roles. Table 1shows the Benne's categorization of functional roles. The Group task roles are defined as “related to the task which the group is deciding to undertake or has undertaken,” whose roles address concerns about the facilitation and coordination activities for task accomplishment. The Group building and maintenance roles are defined as “oriented toward the functioning of the group as a group,” which contribute to social structures and interpersonal relations. Finally, the Individual roles are directed toward the individual satisfaction of each participant's individual needs. They deal with individual goals that are not relevant either to the group task or to group maintenance. Drawing on Benne's work, Bales proposed interaction process analysis (IPA), a framework for the classification of individual behavior in a two-dimensional role space consisting of a Task area and a Socio-emotional area (Bales, 1950). The roles related to the Task area concern behavioral manifestations that impact the management and solution of problems that a group is addressing. Examples of task-oriented activities include initiating the floor, giving information, and providing suggestions regarding a task. The roles related to the Socio-emotional area affect the interpersonal relationships either by supporting, enforcing, or weakening them. For instance, complementing another person to increase group cohesion and mutual trust among members is one example of positive socio-emotional behavior.In this paper, we employ Benne's Group building and maintenance roles, which are related to Bales's Socio-emotional area, in order to arrange the following three abstract functional roles of group maintenance:1.Observation Role: Overlooking the conversation situation by finding appropriate topics, observing the motivations and moods of the participants, and comprehending the relations between participants in conversations. This person follows the conversation and comments and interprets the group's internal process. This role inherits Observer and commentator and Encourager.Floor Maintenance Role: Maintaining the chance for the floor in the group in a direct/indirect way. This person encourages or asks questions of the person who is not or could not get engaged in conversations, and attempts to keep the communication channel open. This role inherits Gatekeeper, Expediter, and Encourager.Topic Maintenance Role: Maintaining for conflict, ideas, and topics. This person mediates the difference between other members, attempts to reconcile disagreements, and relieves tension in conflict situations. This role inherits Compromiser, Harmonizer, and Standard setter.As we described in Section 1, a facilitator must take the following procedural steps:1.(Observation) Be aware of both the presence of dominant participants leading the current conversation and the status of a participant who is left behind (Observation Role)(Obtaining an initiative) Obtain an initiative to control the situation and wait for approval from the others, either explicitly or implicitly(Floor and topic maintenance) Give a floor to a suitable participant, sometimes with initiating a new topic (Floor Maintenance Role and Topic Maintenance Role)In order to formalize procedural steps obtaining an initiative controlling a situation, we begin by extending the participation structure model in multiparty conversations. The participation structure model was presented by Clark (1996), drawing on Goffman's work (1981). In this model, each participant is assigned a participation role considered by the current speaker, where speaker, addressee, and side-participant are “ratified participants.” Ratified participants include the speaker and addressees, as well as a side-participant who is taking part in the conversation but is not currently being addressed. All other listeners, who we refer to as over-hearers, have no rights or responsibilities within the structure. Over-hearers come in two main types. Bystanders are those who are openly present but not part of the conversation. Eavesdroppers are those who listen in without the speaker's awareness. The speaker must pay close attention to these distinctions when speaking. For example, the speaker must distinguish addressee from side-participants. When the speaker asks an addressee a question, the speaker must make sure that it is the addressee who is intended to answer the question, and not side-participants. However, the speaker must also ensure that the side-participant understands the question directed at the addressee. In addition, the speaker must consider the over-hearers. However, because the over-hearers have no rights or responsibilities in the current conversation, the speaker can treat them as he pleases.In this paper, we extend Clark's model with the concept of engagement. In terms of engagement among conversational participants, Martin et al. proposed the appraisal theory that is concerned with the interpersonal in language, with the subjective presence of writers/speakers in texts as they adopt stances toward both the material they present and those with whom they communicate. It encompasses three sub-categories, namely Attitude, Engagement, and Graduation (Martin and White, 2005). Attitude deals with expressions of affect, judgement, and appreciation. Engagement focuses on language use by which speakers negotiate an interpersonal space for their positions and the strategies which they uses to either acknowledge, ignore, or curtail other voices or points of view. Graduation focuses on the resources by which sparkers regulate the impact of these resources. Sidner et al. dealt with engagement in multimodal ways, including eye gaze. They defined engagement as “the process by which two (or more) participants establish, maintain and end their perceived connection during interactions they jointly undertake” (Sidner et al., 2004). This process includes: (1) initial contact, (2) negotiating a collaboration, (3) checking that other is still taking part in the interaction, (4) evaluating whether to stay involved, and (5) deciding when to end the connection. Based on these previous studies, we define engagement as the process establishing connections among participants using dialogue actions so that they can represent their own positions properly.In Fig. 3(c-1) and (c-2), suppose participant C has been assigned as a side-participant who has not engaged with other participants for a significant time. Participant C's amount of communication traffic with the other participants is significantly less than that of the others. Here, we define “engagement density,” which represents the amount of communication traffic. As a relevant measurement of engagement density, Katzenmaier et al. produced a measure of “utterance density,” which takes the ratio of speech to non-speech behavior per utterance (“a speech activity per a certain unit of time by dividing each utterance duration by the sum of previous and following pause durations”) (Campbell and Scherer, 2010). While the utterance density directly dependents on speech activities, the engagement density is a measurement of amount of communication between interlocutors. Therefore, even if a participant's utterance density is high, it does not mean the engagement density is high. Jokinen (2011) also mentioned that sometimes one of the participants might be less active in turn-taking (engagement) even if the speaking activity in the conversation as a whole is large. Three-participant conversations are likely to produce a difference of density. We define a “harmonized” participant as a participant with high engagement density, and an “un-harmonized” participant as a participant with low engagement density. Consequently, speaker and addressee are always assigned as harmonized participants, and side-participants can be divided into two types in terms of engagement density: harmonized side-participant and un-harmonized side-participant. Fig. 3 shows the extended participation structure based on Clark's model. Although all side-participants are ratified, an un-harmonized side-participant, who is only recognized by the speaker, can sometimes emerge in four-participant situations.In order that a facilitator is transferred an initiative by the current speaker, the facilitator must take procedural steps. First, the facilitator must participate in the current dominant conversation the speaker is leading, try to be “harmonized” to claim an initiative, and then wait for either explicit or implicit approval from the speaker. Let us take the example shown in Fig. 4. In the figure, participants A and B are primarily leading the current conversation. Participant C cannot get the floor to speak, and so the robot desires to give the floor to C. If the robot who is an “un-harmonized” participant speaks to C directly, without being aware of A and B, the conversation might be broken, or separated into two (A–B and C-robot), at best. In order not to break the situation, the robot should participate in the dominant conversation between A and B first, and set the stage such that the robot is approved to initiate the next situation as “harmonized” participant. According to our extended participation structure model in Fig. 3, every person participating in a dominant conversation is at “harmonized” state (participants A, B in Fig. 4), and the other is at “un-harmonized” state (participant C and a robot). After participating in the dominant conversation between A and B, the robot is approved as a “harmonized participant” to initiate the conversation.In terms of the way of controlling engagement, Whittaker et al. analyzed two-participant dialogues to investigate the mechanism how each control was signaled by speakers and how it affects discourse structure, including the lower control level, topic level and global organization level (Whittaker and Stenton, 1988). For the control level, they found that three types of utterances (prompts, repetitions and summaries) were consistently used to signal. For the topic level, they found that interruptions introduce a new topic. And the global organization is organized also by topic initiation. This study argued that not only signal utterances but also topic shifting/initialization plays an important role for engagement control. On the basis of these discussions above, we define the following constraints for both harmonized and un-harmonized participants when they address a next speaker and shift current topics:1.Constraint of addressing:An un-harmonized participant must not address the other un-harmonized participants directly.Constraint of topic shifting:An harmonized participant must not shift the current topic when he/she addresses the other un-harmonized participants.The relationship between subject and target participants that are permitted to approach in the two constraints are shown in Tables 2 and 3. For examples, while a harmonized participant (speaker, addressee and harmonized side-participant) can address an both harmonized (addressee and harmonized side-participant) and un-harmonized (un-harmonized side-participant) participants, an un-harmonized participant can not address another un-harmonized participant. In the following sections, we describe a computational model that has the group maintenance functions discussed above.In order to detect timing of initializing a procedure, a facilitator should care about a unit of consecutive sequence to avoid to break a current conversation. An adjacency pair is a minimal unit of conversational sequence organization (Schegloff and Sacks, 1973), therefore it might be reasonable to employ here. An adjacency pair is characterized by certain features (Schegloff, 2007): (a) composed of two turns, (b) by different speakers, (c) adjacently placed, (d) these two turns are relatively ordered; that is, they are differentiated into “first part parts” and “second pair parts”. First pair parts are utterance types that initiate some exchange, such as question, request, offer, invitation, announcement, etc. Second pair parts are utterance types that are responsive to the action of prior turn, such as answer, grant, reject, accept, decline, agree/disagree, acknowledgement, etc. (e) pair-type related; that is, not every second pair part can properly follow any first pair part. Adjacency pairs compose pair types; types are exchanges, such as greeting-greeting, question-answer, offer-accept/decline, and the like. To compose an adjacency pair, the first and second pair parts come from the same pair type.The basic practice or rule of operation, then by which the minimal form of the adjacency pair is produced is: (1) given the recognizable production of a first pair part, (2) on its first possible completion its speaker should stop, (3) a next speaker should start (often someone selected as next speaker by the first pair part), and (4) should produce a second pair part of the same pair type. Adjacency pair-based sequences can come to have more than two turns. Schegloff discussed expansions of adjacency pairs, including pre-expansion, insert expansion, and post-expansion.11The pre-expansion comes before the first pair part. Examples of pre-expansions include pre-invitation, pre-offer, pre-announcement and other pre-telling, pre-sequence, such as summons-answer sequences that usually occurs in phone calls. The insert expansion is one that happens between a first pair part and a second pair part. Examples of the insert expansion include post-first insert expansions, pre-second insert expansions, and expansions of expansions. A minimum post-expansion happens after a second pair part as a sequence-closing third. Sequence-closing thirds takes a number of forms or combinations of them, three of the most common are “oh,” “okey,” and assessments. “Oh” registers a just-preceding utterance as an informing, as producing a change in its recipient from non-knowing to now-knowing. “Okey” (and some variants, such as “alright”) marks or claims acceptance of a second pair part and the stance that is has adopted and embodies within the sequence. An Assessment in third position articulates a stance taken up, ordinarily by the first pair part speaker, toward what the second pair part speaker has said or done in the prior turn.The product of these features of adjacency pairs may be represented schematically in a very simple transcript diagram as follows:So, which timing can be candidates for a facilitator to initiate procedures? As a facilitator might produce economically short steps of procedures to help a left behind participant, in this paper, we assume every second or third part might be the candidates to initiate. Fig. 5shows transition of harmony state, which describes how a facilitator makes himself/herself harmonized and takes an initiative to control a situation, by employing a concept of adjacency pairs. We assume that an un-harmonized participant needs to be approved by a speaker's second pair part to be harmonized. In the following sections, we will describe a computational model of the procedural process discussed above.In this section, we discuss and present a computational model to enable procedures controlling engagement density. We summarized three procedural steps in Section 2.1: Observation, Obtaining an initiative, and Floor and topic maintenance. Since the model needs such a procedural decision making process, we employ Markov decision process (POMDP) (Williams and Young, 2007), which can maintain parallel state hypotheses and confidence scoring, and cope better with observation errors. In the next subsections, at first, we describe the POMDP basics, and extend it to four-participant group maintenance model.Formally, a POMDP is defined as a tuple β={S, A, T, R, O, Z, γ, b0}, where S is a set of states describing the agent's world, A is a set of actions that the agent may take, T defines a transition probability P(s′|s, a), R defines the immediate expected reward r(s, a), O is a set of observations the agent can receive about the world, and Z defines an observation probability, P(o′|s′, a), γ is a geometric discount factor 0<γ<1, and b0 is an initial belief state b0(s). At each time-step, the world is in some unobserved state s∈S. Since s is not known exactly, a distribution over states is maintained called a belief state b, with initial belief state b0. b(s) indicates the probability of being in a particular state s. Based on b, the machine selects an action a∈A, receives a reward r(s, a), and transitions to an unobserved state s′, where s′ depends only on s and a. The machine then receives an observation o′∈O which is dependent on s′ and a. At each time-step, the belief state distribution b is updated as follows:(1)b′(s′)=p(s′|o′,a,b)=p(o′|s′,a,b)p(s′|a,b)p(o′|a,b)=p(o′|s′,a)∑s∈Sp(s′|a,b,s)p(s|a,b)p(o′|a,b)=p(o′|s′,a)∑s∈Sp(s′|a,s)b(s)p(o′|a,b)The numerator consists of the observation function Z, transition matrix T, and current belief state b. The denominator is independent of s′, and can be regarded as a normalization constant γ, therefore:(2)b′(s′)=γ·P(o′|s′,a)∑sP(s′|s,a)b(s)At each time-step, the agent receives reward rt. The cumulative, infinite-horizon, discounted reward is called the return and it is given by:(3)R=∑t=0∞λtrtwhere λ is the geometric discount factor, 0<λ<1. The goal of the machine is to choose actions in such a way as to maximize the expected return E[λ] to construct a policy which indicates which actions to take at each turn. In general, a policy π can be viewed as a mapping from belief state to action π(b)∈A, and an optimal policy π*(b)∈A is one which maximizes E[λ].In order to realize the three-step group maintenance procedure, we define the states, system actions and rewards of the extended POMDP. As the first step (observation), it is essential to know the existence of un-harmonized (left behind) participant in a current time, which we defined as an extension of the Goffman and Clark's participation structure in Section 2.2. As the second step (obtaining an initiative) and third step (floor and topic maintenance), the system should obey the constraints of addressing and topic shifting we discussed in Section 2.3. And the procedure initiation timing can be defined by employing adjacency pairs, as we discussed in Section 2.4. Also, in order to manage the topic shifting, the system should know the un-harmonized participant's motivation to talk about a current topic.Based on these considerations, we reasonably defined observations as follows: a current status of harmony (a current un-harmonized participant's ID and the robot's own harmony status), and an un-harmonized participant's motivation to speak about a current topic, and a current adjacency pair part to decide if it is allowed to initiate or continue a procedure. Such partially observable information would be given by external modules outside POMDP module (the whole architecture will be described in Section 4), and they could be assumed to have the Markov property. dialogue actions giving a floor to an un-harmonized participant, which would be divided into distinctive two types of actions: initiating a new topic and maintaining a current topic. And the constraints of the procedure we assumed in Section 2.3 (constraints of addressing and topic shifting), can be given as rewards in POMDP.Now, we assume a set of states S can be factored into three components: the harmony states sh, the participants’ motivation states Sm, and the participants’ actions Ap. Hence, the factored POMDP state S is defined as:(4)s=(sh,sm,ap)and the belief state b becomes as follows:(5)b=b(sh,sm,ap)To compute the transition function and observation function, a few intuitive assumptions are made:(6)P(s′|s,a)=P(sh′,sm′,ap′|sh,sm,ap,as)=P(sh′|sh,sm,ap,as)·P(sm′|sh′,sh,sm,ap,as)·P(ap′|sm′,sh′,sh,sm,ap,as)Fig. 6shows the influence diagram depiction of our proposed model. We assume conditional independence as follows.The first term in (6), which we call the harmony modelTsh, indicates how participants harmonize in the current dominant conversation at each time-step. We assume that the participants’ harmony state at each time-step depends only on the previous harmony state, the participants’ action, and the system action. The transition probability can be described as follows:(7)Tsh=P(sh′|sh,ap,as)Table 4shows the states of harmony. In this paper, the harmony model only contains the robot's harmony states. In a four-participant group situation including a robot, as a speaker and an addressee are automatically assigned to be harmonized based on our definition, an un-harmonized participant exists at most only one at same time except for a robot (in Section 4, only participant C is an un-harmonized participant). Because the determined current participation roles (speaker/addressee/harmonized side-participant/un-harmonized side-participant) are given by the participation role recognition module that will be described in Section 4.1, shonly has to estimate the robot's harmony state in this four-participant model. The probabilities of (7) were handcrafted, based on the consideration in Sections 2.3 and 2.4. As Fig. 5 shows, when the harmony state is the Un-Harmonized state and the robot is asked by a current speaker, the state should be changed to the Pre-Harmonized state, where the robot is awaiting the speaker's approval for the Harmonized state. We assume that any dialogue acts from the speaker addressing the robot in the Pre-Harmonized are approvals. Otherwise, the state will be back to the Un-Harmonized. The Harmonized state gradually goes down to the Un-Harmonized state in time-steps unless the robot selects any dialogue acts.We call the second term the participants’ motivation modelTSm, which indicates how an un-harmonized participant has the motivation to take the floor at each time-step. This state implies that the participant who is left behind (target person) has a motivation to speak on the current topic. Thus, this state affects decision-making about topic maintenance. Estimated un-harmonized participants’ motivation at each time-step is given by the motivation estimation module that will be described in Section 4.2. And we assume that a participant's motivation also depends on the previous system action. The transition probability can be described as follows:(8)TSm=P(sm′|as)Table 5shows the left behind participant's motivation states.We call the third term the participants’ action modelTAp, which indicates what actions the participants are likely to take. We assume the participants’ action at each time-step depends on the previous participant's action, the previous system action, and the current robot's harmony state. The transition probability can be described as follows:(9)TAp=P(ap′|sh′,ap,as)Participants’ actions are defined as adjacency pairs as shown in Table 6. As we discussed in Section 2.4, understanding adjacency pairs, minimal units of conversational sequences, is essential to detecting a timing of initializing a procedure. We assume recognizing three parts (first/second/third) is sufficient to detect the timing. Pair types (e.g. greeting-greeting, question-answer, offer-accept/decline) are not distinguished in this case. The transition probabilities of adjacency pair types are based on a corpus we collected. We recorded two four-participant conversational groups (all participants were human subjects), who were given the task of discussing movies.Table 7shows the system actions. The system has six actions available. Answer action is answering a current speaker's question, triggering the Answer Generation module though the Content Planning module. The question action is divided into two types: question-new-topic and question-current-topic. Question-new-topic is a question action with initiating a new topic. A robot can use this action according to the constraint of topic shifting as we discussed in Section 2.3 (Table 3). Question-current-topic is a question action along a current topic, without topic shifting. Simple-reaction is a simple reacting action to a current speaker's call of robot's name (e.g. “SCHEMA!”). Nod generates a nod to a current speaker in other to indicate that the robot is listening to a current speaker's utterance. When the robot has not an initiative controlling a situation, it is most likely to select this action to avoid breaking a current conversational sequence. None does nothing but giving a gaze to a current speaker. Both nod and none are also likely to be used when a belief is not high enough to select a dialogue action.We define the observation probability Z as follows:(10)Z=P(o′|s′,a)=P(o′|sm′,ap′,as)Given the definitions above, the belief state can be updated at each time-step by substituting (7), (8), and (9) into (2):(11)b′(sm′,ap′)=γ·P(o′|sm′,ap′,as)︸observation model·P(sm′|as)︸motivation model·∑apP(ap′|sh′,ap,as)︸participants′actionmodel·∑shP(sh′|sh,ap,as)︸harmony model·b(sm,ap)On the basis of the consideration of the constraints in Section 2.3, the reward measure includes components for both the appropriateness and inappropriateness of the robot's behaviors. Table 8shows examples of rewards we used in our experiments.As an optimization algorithm, we employed approximate value iteration methods with point-based updates. These algorithms have proven to scale very effectively, relying on the fact that performing many fast approximate updates often results in a more useful value function than performing a few exact updates. In this paper, we employed the heuristic search value iteration (HSVI) algorithm proposed by Smith et al., which is one of point-based algorithms (Smith and Simmons, 2012). We used ZMDP22http://www.cs.cmu.edu/~trey/zmdp/.as a policy optimization tool.Based on the studies on small group maintenance, we propose an architecture for conversational robots that has the capability to facilitate small groups, as shown in Fig. 7. The framework primarily comprises three processes: situation understanding, procedural production and language generation. The situation understanding process consists of Participation Role Recognition, Adjacency Pair Recognition, and Motivation Estimation. The procedural production process produces procedural actions maintaining a small group, based on the POMDP model we described in Section 3. The language generation process consists of Question Analysis, Content Planning, Topic Management, Answer Generation and Question Generation. Each participant has a wireless microphone on its chest, connected to each Automatic Speech Recognizer (ASR). RGBD cameras are also set in front of each participant. Each time the system detects a voice activity detection (VAD) by each participant's ASR module, the procedural production is triggered to process information interpreted by the situation understanding process. Content Planner generates a concrete sentence, as referring a current topic and user models. It calls either Answer Generation or Question Generation according to a determined dialogue action output from Procedural Production. In the following subsections, we describe each module of the situation understanding and the language generation processes.The participation role recognition module manages participation roles presented in Fig. 3. In this paper, we employ the following assumptions for role classification in a four-participant situation.1.One speaker always exists in one group at each time-step.One addressee who is addressed by the speaker always exists at each time-step.A side-participants is a participant who is not assigned neither speaker nor addressee.As we defined in Section 2.2, side-participants can be divided into two types: harmonized side-participant and un-harmonized side-participant. Fig. 8shows the participation role recognition process consisting of distinctive three sub-processes: speaker classification, addressee classification, and harmonized/un-harmonized side-participant recognition. Many researches mentioned that acoustic and visual cues, such as gaze direction, face direction, head pose and acoustic information are reliable cues for addressing in multiparty human-human and human–robot interactions (Katzenmaier et al., 2004; Jovanović et al., 2006; Fujie et al., 2006; Johansson et al., 2013). In this paper, the speaker classification is based on the results of face direction classification and VAD. The addressee classification is based on the result of speaker classification, as well as each participant's face direction and VAD. The face directions are captured by depth-RGB cameras (Microsoft Kinect). The best results of classification using Naive Bayes for speaker and addressee classification were 79.4% and 70.9%, respectively.In the final process, another participant, who should be assigned to a side-participant according to our definition above, is estimated whether he/she is harmonized or un-harmonized. In the scenario shown in Fig. 4, participant C may not be able to take the floor for a while. We assume the situation probably resolves itself when the current topic is shifted. Hence, we define the depth of side-participant DepthSPTas the duration that a participant is assigned while the same topic continues, which represents the level of harmony.(12)DepthSPTi=DurationSPTiDurationtopicj(13)HarmonizedSPT=SPTiifDepthSPTi>Thresholdnoneotherwisewhere the suffix i represents a participant's ID.As we discussed in Section 3.2.2, the motivation estimation manages only an un-harmonized participant's motivation to take a floor on the current topic. Thus, this state affects decision making about topic maintenance. We define motivation as an un-harmonized participant's ID and a binary (true/false) variable, which is heuristically calculated as follows:(14)Motivationi=1ifMotivationAmounti>Threshold0otherwiseIn our previous experiment, we analyzed how a conversational robot's existence and its actions can affect users’ impressions in group game situations, using video analysis, SD (Semantic Differential) method and free-form questionnaires. The result of SD method indicates that subjects feel more pleased, and the results of free-form questionnaires showed many participants were motivated to participate in the game, with participation and active actions of a robot. These psychological results correlate with utterance frequency and smiling duration ratio, calculated by annotated data (Matsuyama et al., 2010) Also, according to our observation and discussions of the experiments, even if participant's utterances are not observed frequently, participants motivated to participate are likely to nod frequently, as reacted to a speaker's utterances. Therefore, we assume the amount of motivation of a participant can be calculated by a heuristic linear function of speech, smiling and nodding activities during duration of a certain topic, as follows:(15)MotivationAmounti=∫tstarttend(αfspeechi(t)+βfsmilei(t)+γfnodi(t))dtwhere t represents a current time. tstartand tstartrepresent start and end times of a continuum topic, respectively. α, β and γ are arbitrary coefficients. The speech activities are calculated using results of VAD. The smiling and nodding activities are calculated by smiling detection and nodding detection modules, using Microsoft Kinect's Face Tracking SDK.33http://www.microsoft.com/en-us/kinectforwindows/.In this paper, adjacency pairs are recognized by the results of participation role recognition and speech recognition. Each time the system detects an endpoint of speech from the automatic speech recognition module, it classifies each utterance into one of the six categories shown in Table 6 ({1st, 2nd, 3rd} × {toRobot, notToRobot}). In this paper, adjacency pairs are recognized by the linear-chain conditional random fields (CRF), using results of speech recognition. The following features are used in the prediction process:wordt−2,wordt−1,wordt,wordt+1,wordt+2,wordt−1&wordt,wordt&wordt+1post−2,post−1,post,post+1,post+2,post−1&post,post&post+1spost−2,spost−1,spost,spost+1,spost+2,spost−1&spost,spost&spost+1spkt−2,spkt−1,spkt,spkt+1,spkt+2,spkt−1&spkt,spkt&spkt+1where wordt, post, spostand spktdenotes word, part of speech, subparts of speech, speaker id at time t, respectively. Table 9shows an example of features of adjacency pair we used. We use CRF++ toolkit44https://code.google.com/p/crfpp/.in our experiments.For learning and evaluation, we recorded conversational data where 3 participants are assigned to each group and talked for 10min. We had totally 7 groups (70min with 21 participant). They were instructed that they would talk about movies within movie-related 100 topics we defined beforehand. We used 6 groups for learning, 1 group for evaluation. After we transcribed the recorded conversations, each utterance separated manually by an experimenter. Then each of them is analyzed by a Japanese language morphological analyzer.55http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN.The analyzer allows the part of speech to be further sub-classified, namely the subparts of speech. Based on the analyzed results, we coded each morpheme with an extended BIO encoding scheme. Using the BIO, each word is tagged as either (B)eginning an entity, being (I)n an entity, or being (O)utside of an entity. In this case, we extended it with adjacency pairs: a beginning of a first pair part is coded as “B-1”, and subsequent words are coded as “I-1.” The same rule is applied for both second and third parts (“B-2” or “I-2” for second parts, “B-3” or “I-3” for third parts). As for the successfulness of the coding, the inter-rater agreement using Cohen's kappa (Fleiss et al., 2013) indicated a substantial result between the two raters (κ=0.75). The classification accuracy for each word was 73.5%. And a result of the last word will be the final result of the adjacency pair.In this paper, we define a sequence of topic words as a conversational context. Each system utterance is hooked to one of the topics. For example, the sentence “Audrey is beautiful, isn’t she?” is assumed to belong to the topic “Audrey Hepburn.” In our experimental system, we prepared 100 topic words for each domain. The topics in the movies domain include genres, titles, directors, and actors. After ASR and Japanese language morphological analysis, only nouns are extracted. In the topic classification process, CRF was used. The classification accuracy rate (number of correct answers/total number estimated) was 88.2% under a word error rate for ASR of 0%, and 64.7% under a word error rate for ASR of 20%.The Question Generation Module has two main functions: giving someone the floor and collecting the user model. The user model is preferred for topic maintenance. We define that a user's interests in a certain topic are organized by experiences and preferences. The system extracts this information by directly asking a user his/her experiences and preferences and tracking user's motivation during a certain topic. A preferred new topic for a certain user is determined using cosine similarity of TF-IDF scores. The topic scores (TopicScore) of all topics are calculated on the basis of the cosine similarities of the current topic (CurrentTopic), a user's topic preferences of all topics (PreferenceTopic), and experiences (ExperienceTopic) between the CurrentTopic and each Topic.(16)TopicScorei=αcos(Topici·CurrentTopic)+β∑mcos(Topici·PreferenceTopicm)+γ∑ncos(Topici·ExperienceTopicm)where α>β>γ. Using the TopicScore, the system shifts a topic to another that might be close to an un-harmonized participant's interest.The Answer Generation generates Factoid type answers or Non-factoid type answers (opinions). Factoid answers are generated from a structured database using Semantic Web technologies. After analyzing a question, it is interpreted as a SPARQL query, a resource description framework (RDF) format query language to search RDF databases. We use DBpedia as an RDF database.66http://ja.dbpedia.org/.The opinion (non-factoid type answers) generation process refers opinion data automatically collected from a large amount of reviews in the Web. The opinion generation consists of four processes: document collection, opinion extraction, sentence style conversion, and sentence ranking. As an example task, we collected review documents from the Yahoo! Japan Movie site.77http://movies.yahoo.co.jp.For further explanations of the mechanisms of the Answer Generator, see Matsuyama et al. (in press).For our experimental platform, we used the multimodal conversation robot “SCHEMA([∫e:ma])” (Matsuyama et al., 2009), shown in Fig. 4. SCHEMA is approximately 1.2m in height, which is the same as the level of the eyes of an adult male sitting down in a chair. It has 10 degrees of freedom for right-left eyebrows, eyelids, right-left eyes (roll and pitch) and neck (pitch and yaw). It can express anxiousness and surprise using its eyelids and control its gaze using eyes, neck, and autonomous turret. In addition, it has six degrees of freedom for each arm, which can express gestures. One degree of freedom is assigned to the mouth to indicate explicitly whether the robot is speaking or not. A computer is inside the belly to control the robot's actions, and an external computer sends commands to execute various behaviors though a WiFi network. All modules, including the ASRs and a speech synthesizer are connected to each other though a middleware called the Message-Oriented NEtworked-robot Architecture (MONEA), which we earlier produced (Nakano et al., 2006). Fig. 9shows an example sequence of the proposed system.

@&#CONCLUSIONS@&#
We proposed a framework for conversational robots harmonizing four-participant groups. Based on a representation of conversational situations, we presented a model of procedures obtaining conversational initiatives in incremental steps to harmonize such four-participant conversations. These situations and procedures were modeled and optimized as a partially observable Markov decision process (POMDP). As the results of two user experiments, usages of procedures obtaining initiatives showed evidences of acceptability as a participant's behaviors, and feeling of groupness. As for timings, initiating the procedures just after the second or third adjacency pair parts is felt more appropriate than the first pairs by participants. And the result of the simulation experiment, POMDP showed reasonably better performance for group maintenance than MDP. Because of the robustness of POMDP, it's suitable for procedural group maintenance, including its timing to begin a procedure. The main contribution of this research is that we modeled a facilitation model in four-participant conversational situations, which is the minimum unit of facilitation process. We indicated and defined “harmony of conversation” based on “engagement density” and status of interest sharing.The future work include considering extensions of POMDP model for task goal management, while we discussed mainly aspects of group maintenance for facilitation in this paper. Williams et al. presented the POMDP-based spoken dialogue system (SDS-POMDP), where they modeled the user goal of a task. Based on the idea, we will consider the goal model of a group task for optimization considering longer term rewards. Also, in order to deal with situations of more than four participants, some approximation methods for larger state space of POMDP should be considered.We are also considering extending the participation role recognition module using gaze direction information, mentioned its importance in related work. Jovanović et al. (2006) presented results showed that their addressee classifier performed the best with a combination of conversational context including adjacency pairs, and utterance features and speaker gaze information. Fujie et al. proposed gaze recognition for turn-taking model with a conversational robot (Fujie et al., 2006). In our current study, while we assumed only one addressee at a time for simplification, extensions of addressing model allowing for two or more addressees remains as an open question. As for the motivation estimation module, there are many works on modeling participant's internal states including interests and emotions, relevant to concepts to our motivation model (Gatica-Perez et al., 2005). Since we believe these internal model of participants would be necessary components for model of multiparty conversation, evaluating our motivation module in real conversational situations will be also our future work.