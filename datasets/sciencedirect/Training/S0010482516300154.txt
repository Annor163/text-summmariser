@&#MAIN-TITLE@&#
Automatic cytoplasm and nuclei segmentation for color cervical smear image using an efficient gap-search MRF

@&#HIGHLIGHTS@&#
We proposed a novel gap-search Markov random field (MRF) for accurate cervical smear image segmentation.This method could acquire three regions (nuclei, cytoplasm, and background) automatically by a label-map mechanism.The gap-search algorithm is faster than other three algorithms in the experiments.A copy of source codes will be released as an open source project for continuing studies.

@&#KEYPHRASES@&#
Papanicolaou test,Cervical smear image segmentation,Superpixel feature extraction and selection,Superpixel-based MRF,MRF modeling and inference,Faster MRF,

@&#ABSTRACT@&#
Accurate and effective cervical smear image segmentation is required for automated cervical cell analysis systems. Thus, we proposed a novel superpixel-based Markov random field (MRF) segmentation framework to acquire the nucleus, cytoplasm and image background of cell images. We seek to classify color non-overlapping superpixel-patches on one image for image segmentation. This model describes the whole image as an undirected probabilistic graphical model and was developed using an automatic label-map mechanism for determining nuclear, cytoplasmic and background regions. A gap-search algorithm was designed to enhance the model efficiency. Data show that the algorithms of our framework provide better accuracy for both real-world and the public Herlev datasets. Furthermore, the proposed gap-search algorithm of this model is much more faster than pixel-based and superpixel-based algorithms.

@&#INTRODUCTION@&#
According to the World Health Organization (WHO), cervical cancer is the second most common cancer among women, causing nearly 270,000 deaths each year, most of which are in low- and middle-income countries. In contrast, in developed countries, cervical cancer mortality is less due to annual Papanicolaou smear screenings [1]. In 1942, George Papanicolaou reported a technique named a “Pap test” method [2], which is a simple, low-cost, and effective way for diagnosing cervical cancer. Since then, the Pap smear has become the most common measure for cervical cancer cell screening.Traditionally, Pap smear image analysis is a manual method performed by cytologists. This is time-consuming and error-prone. Because computerized analysis is faster, an automatic and valid method was sought for screening slides [3–9]. But with such a system, cell segmentation is a fundamental step for detecting cancerous cells. First, cells must be divided into three regions: cytoplasmic, nuclear, and background areas. Next, one cell per image is required as well as debris removal from cells [10–12]. Then, morphologic and structural features can be extracted from one cell at a time [13,14]. Finally, abnormal cells must be distinguished from normal ones [15–18]. In real-world cervical cell images, there are complex morphologic structures, “noise” or nonessential information and ambiguous cell boundaries as well as overlapping cells (see Fig. 1). Thus, the segmentation of cervical cells is an important and long standing research field. The cervical smear image segmentation can be divided into three categories: (1) nuclei segmentation [19–23]; (2) free cytoplasm and nuclei segmentation [24–28]; (3) overlapped cells segmentation [29–32].Until now, various segmentation methods were proposed for cervical smear images. These methods can be divided into two classes: region and edge-based algorithms. Region-based algorithms include seed-region growing techniques [3], threshold [19], pixel-classified methods [4,29,21], graph-based approaches [26]. Edge-based algorithms mainly include snake-based methods [20,25,31,30], level-set methods [32].Threshold, seed-region growing, watershed algorithm and Canny edge detector [33] are simple and effective measures. But for real-world images, the situations are complex for perfect cell regions identification. Thus, these techniques are usually used to assist the segmentation process and are sub-steps within a framework. The improved snake-based method [20] proposed by Plissiti has been used to locate nuclear boundaries and Li and colleagues [25] drew both nuclear and cytoplasmic boundaries of a single cell using spatial k-means and a radiating gradient vector flow (RGVF) snake model. Next, Guan׳s group [31] acquired partially overlapped cell contours using a dynamic sparse contour searching (DSCS) and a GVF snake model. These models are accurate for extracting the boundaries for single-cell images but for multi-cell images, detecting bounding-box of each cell is required. Segmentation accuracy relies on the precise of cell bounding-boxes. With a pixel-classified method, Jung and coworkers [29] presented a scheme using an expectation maximum (EM) and a Bayes classifier for separating overlapped nuclei. Kale and GençTav [4] used a threshold technique to remove noise, and then acquired nuclear and cytoplasmic regions using a hierarchical tree and a binary SVM. This work [4] is a segmentation and recognition algorithm of the cervical smear image. For supervised algorithms, labeled-data sets are required to train models such as SVM. Furthermore, the data-labeling process is tedious and labor-intensive. So semi-supervised or unsupervised improvements are required to segment images with little or no training data. In addition, for pixel-classified method the computational complexity of the model must be controlled due to the flexible number of pixels.Recently, superpixel-based methods [27,28], which divided original pixels into reasonable pixel-sets, were usually more efficient than pixel-based models for cervical smear segmentation. After superpixels division, a space-divided Voronoi diagram [28] was used for the multi-cell segmentation. Based on superpixels, supervised deep leaning network [27] shew good performance with fine trained model. For the combination superpixel division with other methods, an important question is how to manage the relationship of irregular superpixels reasonably.Here, we propose a novel superpixel-based MRF segmentation model for dealing with this question. We combined the superpixels with an undirected probabilistic graphical model (i.e. MRF) [34] and described the whole image as a graphic net, composed of the superpixel-nodes and connecting-edges. First, the connecting-edges of the graph reflect spatial information between neighboring superpixels by local probabilistic description. Second, this model acquires three regions without training process using a label-map mechanism. Third, the superpixel-based MRF, which is suitable for complex shapes and ambiguous boundaries, saves time compared to the pixel-based model. Forth, the proposed gap-search algorithm can resolve the superpixel-based model more rapidly. Data show that our framework can offer the requisite accuracy, efficiency and speed.The overview of our framework (see Fig. 2) includes weakening of “noise” with a non-local means filter, generation of node-elements of the MRF model denoted by superpixels, and extraction of a 13-dimensional feature vector from each superpixel. Then, we modeled the image as a superpixel-based MRF. A solution algorithm of this model, an iterative adaptive classified algorithm (IACA), was proposed and we also improved the IACA with a gap-search algorithm.To formally define the proposed model, suppose that the observed imageF={f→p|p∈φ}consists of 13-dimension feature vectors at each superpixelp∈φdenoted by a vectorf→p. The object is to identify the best configuration labelingl^, which maximizes the posteriori probabilityP(l|F), which is the maximum a posteriori(MAP) estimation:(1)l^=argmaxl∈ΩP(l|F,θ)=argmaxl∈Ω(Πp∈φP(f→p|lp))P(l)where Ω denotes the set of all possible configuration labels, θ represents the parameters of the MRF model. Because our aim is to segment the image into homogeneous regions, one superpixel class λ will correspond to one or more homogeneous superpixel patches in the input image. Regularities can be modeled by a white noise with covarianceΣλcentered around the expected mean vectorμλ. So we suppose thatP(f→p|lp)follows a Gaussian distribution and every superpixel classesλ∈Λ={1,2,…,L}are presented by the mean vectorsμλand the covariance matricesΣλ. Furthermore, P(l) is a MRF with respect to a new superpixel-based neighbor system (see Fig. 3). In Fig. 3, a singleton denotes a first order MRF and describes the probability of labels without context and a doubleton reflects the relationship between two neighboring superpixel labels [35].And as seen in Fig. 4, the superpixel data field is composed of the black nodes in one image. The label field consists of the gray nodes. Each black node represents superpixel and has one corresponding gray label node.Maximum global probability is equivalent to minimum global energy function according to the Hammersley–Clifford theorem [36]. When the joint probability distribution of the random variables is strictly positive, it is proven that Gibbs probability distribution is equivalent to the MRF. That is to say, P(l) follows a Gibbs distribution:(2)P(l)=exp(−U(l))Z(β)=∏C∈φexp(−VC(lC))Z(β)where U(l) is the energy function,Z(β)=∑l∈Ω(exp−U(l))is the partition function and the VCdenotes the clique potential of cliqueC∈φhaving the label configuration lC. φ is the set of the second order cliques. The energy of singletons directly reflect the probabilistic modeling of labels without context, while doubleton clique potential express the relationship between neighboring superpixel labels. The superpixel sitesp∈φand the neighboring superpixel correspond to the energy of singletons∑i∈C1V1(li)and doubletons∑i,j∈C2V2(li,lj). Thus the energy function of the defined MRF image segmentation model has the following form:(3)U(l,F)=∑i∈C1V1(li)+∑i,j∈C2V2(li,lj)=∑p∈φ(ln((2π)13|Σlp|+12(f→p−μlp)Σlp−1(f→p−μlp)T))+β∑{i,j}∈φδ(li,lj)In our work, the label layer is defined to be a multi-value Potts physical model for this multi-classified MRF. The definition of the Potts model is as follows:(4)δ(li,lj)={0li=ljβli≠ljwhereβ>0is a parameter controlling the homogeneity of the regions. A larger β makes the region more homogeneous.The nodes of MRF are superpixels, which can be interpreted as a set of neighboring similar pixels. There are many superpixel generated algorithms and we used SLIC [37], a simple line iterative clustering algorithm, to generate superpixels. The parameter setting of this algorithm is a key question as it decides the performance of segmentation model. SLIC has two parameters, m and N. m controls the distance of two superpixels. A smaller m yields more similar pixels in one superpixel and irregular patches (see Fig. 5). The value of m ranges from 1 to 40 in CIELAB color space. Next, N controls the number of superpixels and as N increases, the running time of superpixel-based MRF rises too. For getting rid of the influence of N, we have improved the solution of our model to be a novel gap-search algorithm.In this work, we extracted 13-dimensional features from one superpixel including pixel intensities and the shape of superpixel patches. Pixel intensities come from RGB and CIELAB color space. And we calculated the mean and median pixel intensities from each channel. Because two color spaces own six total channels, we acquired a 12-dimensional feature vector. Then, the ratio of patches area to the minimal enclosing rectangle is extracted as one dimensional feature. So the dimension of feature is 13 shown in Table 1. The last column of Table 1 is zijdenbos similarity index (ZSI) of every dimension, reflects a similar degree between segmented and ground truth regions.In previous [25], spatial k-means was used the pixel for segmentation. We used superpixels instead of the pixels. The number of superpixels is less than the number of original pixels and adopted k-means++ is faster than a k-means [38]. Due to fewer data and a faster clustering algorithm, our initial segmentation is more efficient.For this unsupervised initial segmentation, labels are generated randomly for every image. So we needed to identify the regions corresponding to nuclei, cytoplasm and background rightly. Thus, we designed a label-map mechanism to adjust the unsupervised labels to the correct labels. This mechanism was accomplished using the differences in lightness of regions. Nuclei are the darkest, and the background is lightest so the rest is cytoplasm. First, the centers are identified from three clusters. Then the mean value of L channel in each center is extracted. Next, the three values are sorted and after this re-map processing, the maximal value is the nucleus and a minimal value depicts the background, and an intermediate one is the cytoplasm.The objective function is non-convex, so we applied combinatorial optimization techniques to solve it. The parameters θ of this segmentation model consists of the mean vectorμλ, the covariance matrixΣλand the parameter β. To solve this model, we use an iterative adaptive classified algorithm (IACA) to perform parameter estimation. After the last iteration of IACA, segmentation results can be identified by superpixel labels. IACA has two properties: adaptive and unsupervised. First, the meaning of the adaptive algorithm can be known from its mathematical property. For the algorithm, the MAP estimation becomes as follows:(5)(l^,θ^)=argmaxl,θP(l,F|θ)We employ the approximated method instead:(6)l^=argmaxlP(l,F|θ^)(7)θ^=argmaxθP(l^,F|θ)Eq. (5) is the MAP estimation of the label filed based on the MRF model parametersθ^. And Eq. (6) is the maximum likelihood (ML) of the observed samples and labels(l^,F). The solution of Eqs. (6 and 7) is sub-optimal solutions of the object function Eq. (5). Next, we elaborated on the meaning of unsupervision. In unsupervised situation, initial parameters θ are unknown, and in an iterative process we did not use labeled data. This iterative estimation procedure supposes that a cervical smear image has three regions.For reducing the running time, we improved this IACA by a gap-search mechanism to the literature [39], which proposed a faster algorithm for a pixel-based binary-classified MRF. In our work, each iteration of IACA computes all superpixel labels repeatedly for a optimized solution of multi-classified MRF. Most of labels stay the same with last iteration and most of computations for energy are redundant. Thus, we only needs to update the energy of necessary local regions. So we employed un-smoother regions of k-means++, and drew a searching gap for selecting necessary superpixel to compute energy. The gap-search algorithm of MRF accelerated the solution of model by the set Su of the selected superpixels. In set Su, the elements are the superpixels that overlapped with searching gap patches. The searching gap patches are fixed by the edge pixels of Canny edge detector. We obtained an edge gap by drawing the squares, the centers of which are the pixel points of edge (see Fig. 6.) Algorithm 1 is referred to as the pseudo-code of our gap-search MRF.Algorithm 1Gap-search algorithm for cervical image segmentation – pseudo-code.Input: Cervical smear image Iorg, parameter homogeneity β, maximum iterative times I, the number of classes N, iterative differential threshold δ.Output: Regions of nuclei, cytoplasm and background.Stage 0 - Preprocessing–filter imageIStage 1 - Superpixels generation as node-elements of MRF1. Generate superpixels with SLIC algorithm.2. Extract a 13-dimensional feature vector from each superpixel denoted byF.3. Save superpixel adjacency graph Gadjaccording to the label matrix.Stage 2 - MRF modeling and solution1. Initial segmentation using k-means++.2. Identify three clustered centers.3. Extract L⁎ channel mean values of the three centers.4. Map unsupervised superpixel labels to semantic nuclei, cytoplasm and background rightly using label-map mechanism.5. Input parameters: β, I, N and δ.6. Calculate initial μi, Σi, local energy Elocaland global energy Ei.7. Selected out the set Su of superpixels using gap-search mechanism.8. Repeat9. Update μiand Σiusing maximum likelihood (ML).10.If the superpixel is the element in set Su11. Update Elocaland Eiaccording to Gadj.12. Calculate the difference of energyδk=Ek−Ek−1.13. Save best superpixel-labeled list Lctill current iteration.14. k=k + 1.15. Ifδk<δork>I16. Break.17. Until convergence18. Map Lcto pixel labelsLand mark the image using three labels.19. Output regions of nuclei, cytoplasm and background.Suppose an image of size:w×hwith L labels, then there areL(wh)possible label configuration. We analyzed the complexities of pixel-based MRF, superpixel-based MRF and gap-search MRF. First, the complexity of pixel-based MRF is O(wh). Second, given an image with N superpixels, the complexity of superpixel-based MRF is O(N) and as N increases, the running time increases. Third, due to computing the energy of the superpixels in selected set Su, the complexity of gap-search MRF is proportional to the number of elements in set Su. And the number of elements in set Su is proportional to the number of edge pixels E. So the complexity of gap-search MRF is O(E) and remains stable for one image.We used two datasets, Herlev and a real-world, to verify method performance. Herlev [40] is the most commonly used public dataset and can be freely downloaded from the Internet (see Fig. 1). The real-world dataset contained multi-cell images and a part of this dataset came from the literature [31] (see Fig. 7). Images were acquired by an auto microscopic image screen equipment with a CCD camera (DA-HENG), an optical microscope (Olympus CX31) and a40×magnification lens (numerical aperture=0.65). The size of an image is 1360×1024 and the pixel size is0.238×0.238(microns) in real-world dataset.

@&#CONCLUSIONS@&#
