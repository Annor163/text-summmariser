@&#MAIN-TITLE@&#
Using large clinical corpora for query expansion in text-based cohort identification

@&#HIGHLIGHTS@&#
Demonstrated utility of an in-domain collection (clinical text) for query expansion.Analyzed effect of external collection size on a mixture of relevance models.Any existing query expansion configuration can benefit from an indomain collection.

@&#KEYPHRASES@&#
Cohort identification,Information retrieval,Query expansion,Clinical text,Electronic medical records,

@&#ABSTRACT@&#
In light of the heightened problems of polysemy, synonymy, and hyponymy in clinical text, we hypothesize that patient cohort identification can be improved by using a large, in-domain clinical corpus for query expansion. We evaluate the utility of four auxiliary collections for the Text REtrieval Conference task of IR-based cohort retrieval, considering the effects of collection size, the inherent difficulty of a query, and the interaction between the collections. Each collection was applied to aid in cohort retrieval from the Pittsburgh NLP Repository by using a mixture of relevance models. Measured by mean average precision, performance using any auxiliary resource (MAP=0.386 and above) is shown to improve over the baseline query likelihood model (MAP=0.373). Considering subsets of the Mayo Clinic collection, we found that after including 2.5 billion term instances, retrieval is not improved by adding more instances. However, adding the Mayo Clinic collection did improve performance significantly over any existing setup, with a system using all four auxiliary collections obtaining the best results (MAP=0.4223). Because optimal results in the mixture of relevance models would require selective sampling of the collections, the common sense approach of “use all available data” is inappropriate. However, we found that it was still beneficial to add the Mayo corpus to any mixture of relevance models. On the task of IR-based cohort identification, query expansion with the Mayo Clinic corpus resulted in consistent and significant improvements. As such, any IR query expansion with access to a large clinical corpus could benefit from the additional resource. Additionally, we have shown that more data is not necessarily better, implying that there is value in collection curation.

@&#INTRODUCTION@&#
Electronic medical records (EMRs) have the potential to streamline the processes involved in clinical and translational research. In the past, identification of cohorts for clinical trials or retrospective studies has been a costly endeavor, requiring hours of trained expertise to accomplish manual chart reviews. In the EMR age, this problem of cohort identification may be cast as one of information retrieval (IR). Here, clinical text (e.g., a discharge summary) must be searched alongside structured data (e.g., lab results) to find a pool of patients that fit some criteria, such as symptoms present, family history, or demographics (i.e., the query). But it is challenging for a clinician or epidemiological researcher to formulate an optimal query based on their desired criteria. This is in part because of the inherent diversity of language: ‘cold’ could be a temperature or a disease (polysemy), ‘dyspnea’ could be expressed in a medical record as ‘shortness of breath’ (synonymy), ‘ibuprofen’ could be expressed as ‘pain reliever’ (hyponymy).One effective general-domain IR approach for these problems is to expand queries to include other terms that might be relevant or implied. In the mixture of relevance models approach to query expansion [1], multiple large external text corpora have been used to select what terms might be helpful to add to a query. When searching for patient cohorts in the clinical domain, general-domain collections have been shown to select reasonable terms and improve retrieval performance [2]. What sort of improvement, if any, should be expected if clinical-domain collections are used for this query expansion?In this work, we analyze the effects of including a large, unlabeled corpus of clinical notes into an statistical IR system for cohort identification. In particular, we evaluate the helpfulness of a corpus of Mayo Clinic clinical notes for the Text REtrieval Conference (TREC2http://trec.nist.gov/.2) task of IR-based cohort retrieval, considering the effects of collection size, the inherent difficulty of a query, and the interaction with other widely-available collections. As our results will show, the large clinical corpus is the single most useful collection for query expansion. It is interesting to note, however, that optimal results in the mixture of relevance models would require selective application of this query expansion.The TREC Medical Records Cohort Retrieval Task was to retrieve relevant patient visits from a target text collection of patient records [3,4]. The University of Pittsburgh NLP Repository supplied de-identified medical reports as the target collection for the TREC 2011 and 2012 Medical Records Tracks. A patient visit to the hospital usually generates multiple medical reports, so 100,866 Pittsburgh medical reports corresponded to 17,198 patient visits. This is an approximation of finding actual patients for a cohort (a patient could have multiple hospital visits), which was impossible due to the record de-identification process.Each medical report is an XML file with a fixed set of fields as shown in Fig. 1. We mainly used ICD-9 codes for admit and discharge diagnoses, and the “report text” field which contained the full text of clinical narratives. Medical reports could be mapped to patient visits via a report-to-visit mapping table provided with the Pittsburgh NLP Repository.81 queries (or “topics” in TREC terminology) were developed by TREC assessors, reflecting the types of queries that might be used to identify cohorts for comparative effectiveness research [3]. These queries were designed to require information from the free-text fields, i.e., topics are not answerable solely by the diagnostic codes. The topic usually specifies the patient’s condition, disease, treatment, etc. For example:Topic 107Patients with ductal carcinoma in situ (DCIS)Topic 185Patients who develop thrombocytopenia in pregnancyFor each topic, TREC assessors gave a relevance judgment (highly relevant, relevant, or not relevant) to subsets of the 17,198 visits; these subsets were chosen based on pooled results from TREC Medical Records Track participants. Our evaluations used these 81 relevance-judged topics, with ninefold cross validation to examine the benefit of query expansion.The remainder of this paper is organized as follows: Section 2 highlights related work. Section 3.1 introduces some characteristics of the collections used for query expansion. After some preprocessing in Sections 3.2 and 3.3 describes the retrieval model. Section 4 details the evaluation metrics and experimental setup. Then, Section 5 presents results and discusses the utility of the Mayo corpus under various settings. After some further discussion in Section 6, we summarize our findings in Section 7.

@&#CONCLUSIONS@&#
