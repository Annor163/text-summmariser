@&#MAIN-TITLE@&#
Convergence properties and practical

@&#HIGHLIGHTS@&#
We address the impact of uncertainty when the experts complete the pairwise comparison matrices.We show how the probability of rank reversal (PRR) is reduced by augmenting the number of experts.It is shown that there is not much to be gained by increasing the number of experts beyond 15.The issue of how PRR can be estimated in practice by a single expert group is also addressed.We propose and validate a numerical procedure which yields a reasonable estimate for the PRR.We consider the impact of various aspects which may affect the estimation of probability of rank reversal in the context of pairwise comparisons, such as uncertainty level, alternative preference scales and different weight estimation methods. We also consider the case where the comparisons are carried out in a fuzzy manner. It is revealed that the results hold regardless the aforementioned aspects considered.

@&#KEYPHRASES@&#
Uncertainty modeling,Multiple criteria analysis,Decision analysis,Pairwise comparisons,

@&#ABSTRACT@&#
In this paper, we address the impact of uncertainty introduced when the experts complete pairwise comparison matrices, in the context of multi-criteria decision making. We first discuss how uncertainty can be quantified and modeled and then show how the probability of rank reversal scales with the number of experts. We consider the impact of various aspects which may affect the estimation of probability of rank reversal in the context of pairwise comparisons, such as the uncertainty level, alternative preference scales and different weight estimation methods. We also consider the case where the comparisons are carried out in a fuzzy manner. It is shown that in most circumstances, augmenting the size of the expert group beyond 15 produces a small change in the probability of rank reversal. We next address the issue of how this probability can be estimated in practice, from information gathered simply from the comparison matrices of a single expert group. We propose and validate a scheme which yields an estimate for the probability of rank reversal and test the applicability of this scheme under various conditions. The framework discussed in the paper can allow decision makers to correctly choose the number of experts participating in a pairwise comparison and obtain an estimate of the credibility of the outcome.

@&#INTRODUCTION@&#
Decision making (Bhushan &#38; Rai, 2004; Yager, 2004) consists of choosing a specific course of action between several alternatives and is encountered in countless areas of human activity. In many circumstances, where complex decisions need to be made involving high stakes, it is desirable to proceed in a structured and methodological manner, rather than simply rely on the skills and intuition of a single decision maker. Multi-criteria decision analysis (MCDA) or multi-criteria decision making (MCDM) (Triantaphyllou, 2000) aim at facilitating decision makers in complicated situations where numerous and sometimes conflicting criteria or factors have to be taken into account.MCDM is further classified into multi-objective decision making (MODM) and multi-attribute decision making (MADM) (Pohekar &#38; Ramachandran, 2004). In MODM, a set of objective functions is optimized subject to constraints and hence the efficient solutions in a set of alternatives are sought. MODM typically requires the solution of a series of mathematical programming models in order to reveal implicitly defined efficient solutions. On the other hand, in MADM, a small number of pre-determined alternatives are to be evaluated under a common set of criteria and the best alternative is usually selected by making comparisons between alternatives with respect to each criterion.A fundamental problem in decision making is to grade the importance of a set of alternatives and assign a weight to each of them. The importance of alternatives usually depends on several criteria which can be evaluated within the decision making framework in which pairwise comparisons (PWC) are an essential ingredient (Saaty &#38; Vargas, 2001). In the context of MADM, PWC enables the ranking of alternatives by allowing the experts to compare the various criteria or alternatives in pairs instead of assigning their priorities in a single step (Saaty, 1977). This reduces the influence of subjective point of views, associated with eliciting weights directly. PWC is usually performed in MADM methods such as the Analytic Hierarchy Process (AHP) (Saaty, 2003), the Weighted Product Method (WPM) (Chang &#38; Yeh, 2001), the preference ranking organization method for enrichment evaluation (PROMETHEE) (Brans, Vincke, &#38; Mareschal, 1986), the Analytic Network Process (ANP) (Saaty, 2004) and so on. The aim of this paper is to consider the influence of uncertainty in PWC and how the credibility of the outcome can be assessed. Although the focus is on PWC alone, the results have some implications on the applications of MADM frameworks, particularly in the number of experts that are required and how the credibility of key parts of the framework can be ascertained.In recent years, PWC has been used either as a stand-alone method or as part of complex MADM frameworks on several areas including government (Huanga, Chub, &#38; Chiang, 2008), business (Lee &#38; Kozar, 2006), industry (Chan, Lau &#38; Ip, 2006), healthcare (Liberatore &#38; Nydick, 2008), technology (Gerdsri &#38; Kocaoglu, 2007), education (Zahedi, 1986), communications (Dede, Kamalakis, &#38; Varoutas, 2011a,2011b;Dede, Varoutas, Kamalakis, Fuentetaja, &#38; Javaudin, 2010), agriculture (Abildtrup et al., 2006) and energy planning (Kok &#38; Lootsma, 1985). The method itself has also been the focus of extensive research in the field of decision making. Recently in Fan and Liu (2010), a form of uncertain preference information, called ordinal interval numbers, was used in pairwise comparisons in order to rank the alternatives. In Doumpos and Zopounidis (2004), the issue of how pairwise comparisons can be used for the classification of alternatives in different classes of preference is discussed. The problem of deriving the weights from the pairwise comparison matrices using several alternative approaches is studied in Barzilai (1997) and Choo (2004). In Kwiesielewicz and Van Uden (2004)several issues concerning the inconsistency of the pairwise comparison matrix and its impact on the decision making process are highlighted. In addition, fuzzy pairwise comparison for solving the decision making problems has been proposed in Boenderb, Graan, and Lootsma (1989), Deng (1999) and Mikhailov (2005). In Marimin, Umano, Hatono, and Tamura (1998)linguistic labels are used in order to express fuzzy preference relations in pairwise decision problems. Moreover, Shiraishi, Tsuneshi, and Motomasa (1998)dealt with the properties of the principal eigenvector of PWC matrices.The influence of uncertainty due to the imperfect and subjective expert judgments is of paramount importance when considering the credibility of the outcome of a decision making process. Several studies have attempted to shed some light on this issue in the context of PWC. For example, in Carmone, Karab, and Zanakis (1997), Monte Carlo simulations were performed to study the Incomplete Pairwise Comparisons (IPC) algorithm and investigate the effect of missing information in pairwise comparisons. Furthermore, in Aull-Hyde, Erdogan, and Duke (2006) it has been shown that given a sufficiently large group size, the consistency of the aggregate comparison matrix is guaranteed regardless of the measures used to estimate the consistency of the individual matrices, if the geometric mean method is used to estimate the weights. Moreover, in Hahn (2003) a stochastic characterization of the pairwise comparison judgments is provided, while statistical models for deriving the weights of the alternatives using Markov chain Monte Carlo are also presented. Furthermore, Farkas (2007) theoretically studied the conditions for rank reversal on perturbing the PWC matrices, while Chen and Kocaoglu (2008) also studied the rank reversal problem in this particular context, and came up with an algorithm to analyze the sensitivity of hierarchical decision models.The main purpose of our work is to provide a suitable characterization of the impact of uncertainty in PWC. A first step in order to characterize the impact of uncertainty in PWCs, is to identify a suitable measure for quantifying its effects. Assume for instance that N different alternatives are pairwise compared by M experts, each with possibly a different view on the ranking of the alternatives. As discussed further below in Section 2.1, PWC aims at providing an average ranking, encompassing all these diverse opinions of the experts. It is of course natural to expect that the credibility of the overall process will be increased as the size of the expert group increases. Therefore, one possible way of measuring the trustworthiness of the results is to define the probability of rank reversal (PRR) (Saaty &#38; Vargas, 1984) as follows: Let W1, …, WNbe the weights calculated by the PWC in the case of a very large group of experts (M → ∞). In a practical situation where M is finite, uncertainty may undermine the PWC and the calculated weights wkmay turn out different than Wk. Uncertainty can be due to the difference of opinion among the experts or inconsistent pairwise comparisons. The probability of rank reversal is formally defined as:(1)PRR=P{therankingobtainedbywi,1≤i≤N,isdifferentthanthatofWi}A high PRR implies that the outcome of the PWC in question is not trustworthy and could therefore lead to incorrect decision making. There are two important issues that need to be addressed concerning PRR:a)How does PRR relate to the number of experts M? An obvious way to reduce the effect of uncertainty is simply to increase M, but from a practical point of view, this is not a trivial task. It is usually difficult to locate many experts within a single organization or even in the wider public with sufficient expertise that would be willing to participate in the PWC surveys. On the other hand, there is no clear answer to the question of how many more experts need to participate in order to considerably reduce the uncertainty of the outcome. Say for example, that there are already M = 10 experts participating in the endeavor. How much is there to be gained in terms of PRR by doubling or even quadrupling the size of the group of experts?How can PRR be estimated from actual expert judgments in practice? When applying PWC in a specific decision making problem, one has access to the elements of a limited number of pairwise comparison matrices P(m) (where 1 ≤ m ≤ M). So the question becomes whether one can extract any kind of information regarding PRR and hence the credibility of the results based on just the elements of P(m).The present paper attempts to deal with both points above. We first discuss a model for incorporating uncertainty in PWC and consider a suitable measure for quantifying the uncertainty level. We then discuss how PRR varies with the group size M depending on the uncertainty level and extract several interesting conclusions from this variation. It is shown that there is not much sense in using more than M = 15 experts in the decision making process because the rate of decrease of PRR is already small for M > 15. We then address the issue of how PRR can be estimated from just the values of the pairwise comparison matrices P(m) obtained by the experts. Given this information, we discuss a numerical method for estimating PRR based on Monte Carlo simulation. The results indicate that for a sufficiently large group of experts, one can obtain a reasonable approximation to the actual value of PRR.The rest of the paper is organized as follows: In Section 2, we briefly summarize the PWC method laying the theoretical foundations for incorporating uncertainty and present the model used in our simulations. In Section 3, the results obtained when applying the proposed model are presented and the convergence of the PRR is examined, considering the impact of various aspects which may affect the estimation of probability of rank reversal, such as varying uncertainty level among the experts, alternative preference scales and weight estimation methods. We also consider the case where the judgments are determined in a fuzzy manner. In Section 4 a numerical method is proposed in order to estimate the PRR from the actual user judgments. Finally, some concluding remarks are presented in Section 5.In this section, we introduce the model used for incorporating uncertainty in the pairwise comparison matrices. Section 2.1 provides a brief overview of the pairwise comparison framework, while Section 2.2 considers the effects of uncertainty-induced perturbations under general assumptions. Section 2.3 details the uncertainty model adopted in this paper. In Section 2.4 we describe how we can estimate the probability of rank reversal through Monte Carlo simulation.Within the PWC framework, instead of directly assigning priorities to the various alternatives Aiwith 1 ≤ i ≤ N, each expert compares all possible combinations of Aiand Aj. The outcome of these judgments for the mthexpert are stored in a square N × N reciprocal matrixP(m)=[Pij(m)], which will henceforth be referred to as a pairwise comparison matrix. The value of the elementPij(m)reflects the importance of alternative Aiover Aj. The expert needs to complete only the upper triangular elements (i < j) of P(m) since by definition we havePij(m)=1/Pji(m)andPii(m)=1for a reciprocal matrix. The weightswi(m)of alternative Aiaccording to expert m can be calculated with various ways. The most widely adopted approach is to solve the eigenvalue problemP(m)xq(m)=λq(m)xq(m), whereλq(m)are the eigenvalues of P(m) andxq(m)=[xpq(m)]are the corresponding eigenvectors. Assuming that the eigenvalues are ordered so thatλ1(m)is the largest eigenvalue, then the weight of alternative Aiis estimated by normalizing the elements of the principle eigenvectorx1(m)as follows (Saaty, 2003):(2)wk(m)=x1k(m)[∑l=1Nx1l(m)]−1In order to further simplify the comparisons,Saaty(2008)introduced the nine-level scale shown in Table 1.One way of measuring the inconsistency of a pairwise comparison matrix is to calculate the Consistency Ratio (C.R.) defined as:(3)C.R.=C.I.R.I.In Eq. (3), C.I. is the Consistency Index which is estimated through:(4)C.I.=λ1(m)−NN−1The denominator in Eq. (3) stands for the Random Index (R.I.) which is an average random consistency index derived from a sample of randomly generated reciprocal matrices with elements scaled according to Saaty (2003). Values of C.R. smaller or equal than 0.1 are generally considered as acceptable and in this case, the matrix is said to be nearly consistent (Saaty, 2003).After all the comparisons have been completed, the average weight wkfor each alternative Akis calculated by averaging out the weightswk(m)obtained by the M experts,(5)wk=1M∑m=1Mwk(m)The weights wkdetermine the priorities of the alternatives and hence the outcome of the PWC process. The method of estimating the weights from the PWC matrices is by no means unique. In the next sections we will also consider what happens when the weights are estimated using the geometric mean method. We will also discuss the situation where the pair wise judgments are carried out in a fuzzy manner and the weights are calculated accordingly.Before proceeding to the description of the uncertainty model used in this paper, it is useful to consider the impact of uncertainty in PWC under very general assumptions. From a theoretical standpoint, we may consider that uncertainty acts as a kind of “noise” that impairs the pairwise comparisons. We may think of P(m) as a perturbed version of an initial N × N matrix A, i.e. P(m) = A + ΔP(m) where ΔP(m) =[ΔPij(m)]is a random perturbation matrix, the magnitude of which is related to the level of uncertainty. Since the weightswk(m)are obtained from the perturbed principal eigenvectorx1(m)of P(m), it is interesting to consider howx1(m)is related to the principal eigenvector x1 of A. According to Saaty and Vargas (1987), the first order variationΔx1(m)of the principal eigenvector is determined by:(6)Δx1(m)=x1(m)−x1=∑j=2N(υjTΔP(m)x1(l1−lj)υjTxj)xjwhereυjand xjare the left and right eigenvectors of the initial pairwise comparison matrix A respectively while ljare the corresponding eigenvalues. Expanding the matrix products of Eq. (6) in terms of the individual matrix and vector elements, it is revealed that the elements of the perturbation vectorΔx1(m)=[Δx1p(m)]are a linear combination of the elements of the perturbation elementsΔPij(m). This fact has an important bearing on the statistics of the perturbed weights: if one assumes that a sufficient number of the perturbationsΔPij(m)are statistically uncorrelated, then according to the Central Limit Theorem (CLT) (Rice, 1995),Δx1p(m)being a linear combination of statistically uncorrelated variables, will approximately follow a Gaussian distribution (provided that N is sufficiently large). The weightswk(m)are normalized versions ofx1k(m)and we therefore expect that they will also approximately follow a Gaussian distribution. This can be deduced by considering the changeδwk(m)in the weightswk(m)inferred by the perturbationsΔx1p(m)in the principle eigenvector. Using the fact that (α + Δα)/(β + Δβ) ≅ α/β + Δα/β − (α/β2)Δβ for small Δα and Δβ, one obtains from Eq. (2) an estimate forδwk(m)=wk(m)−Wkas follows:(7)δwk(m)≅Wk{Δx1k(m)x1k−1C∑j=1NΔx1j(m)}where C = ∑lx1l. The above equation suggests that since, as mentioned above,Δx1p(m)is a linear combination ofΔPij(m), the perturbationsδwk(m)will also be Gaussian. More importantly, the statistics of the uncertainty perturbationsΔPij(m)are expected to mainly influence the variance of the Gaussian-like distributed weightswk(m)and have smaller impact on their actual statistical behavior (e.g. their PDF). Furthermore the weights wkin Eq. (5) are the sum ofwk(m)with respect to m and the CLT again points out that wkwill also be approximately Gaussian-distributed. We will numerically verify this claim in Section 3.1.The discussion of Section 2.2 already points out an intuitive way of incorporating uncertainty in the PWC matrices. Instead of assigning a fixed value for the elementsPij(m)we may assume thatPij(m)varies randomly inside an interval [Dij, Uij] (Saaty &#38; Vargas, 1987). In addition, if the experts carry out their comparisons according to Table 1, then the allowed values forPij(m)should be discrete. A word of caution is in order here however: the length Uij− Dijof the interval [Dij, Uij] is not a suitable measure for the level of uncertainty. To illustrate this, consider the intervals I1 = [1/9,1] and I2 = [1, 2] with lengths 1 − 1/9 = 8/9 and 2 − 1 = 1 respectively. Although I1 has a smaller length than I2, it is easy to see that it actually corresponds to higher uncertainty level than I2 since there are nine distinct values of Table 1 (i.e. 1/9, 1/8,…, 1) that are located inside I1 while there are only two such values for I2. This points out that in order to quantify the uncertainty level it is preferable to consider the number nijof discrete values contained in the interval rather than its length. In fact, since an interval with Dij= Uijcorresponds to no uncertainty a more suitable measure of the uncertainty level is nij− 1.Based on the above observation we consider the following mapping of the values V of Table 1, into a set of integers u = q(V) with −8 ≤ u ≤ 8 such that:(8)q(V)={V−1,V≥11−1/V,V<1It is easy to show that the quantity q(Uij) − q(Dij) is equal to nij− 1. Also, for the intervals I1 and I2 considered in the paragraph above, this quantity is 9 and 1 respectively which indicates that indeed I1 corresponds to a much larger uncertainty level than I2. We also define the inverse mapping q−1 of q such that q−1(q(V)) = V.Another interesting question is how the boundaries Dijand Uijare determined in the first place. It is evident that since Dijand Uijcan take a variety of values one can think of them as random variables themselves. One way of randomly selecting Dijand Uijis to start with an initial nearly consistent matrix A = [Aij] and set(9)uij={q(Aij)+|Δuij|,ifq(Aij)+|Δuij|≤88,otherwise(10)dij={q(Aij)−|Δdij|,ifq(Aij)−|Δdij|≥−8−8,otherwisewhere Δuijand Δdijare independent, uniformly distributed variables inside [−s/2, s/2] with variance σ2 determined by(11)σ2=s212=〈Δuij2〉=〈Δdij2〉Eqs. (9)and (10) ensure that the integers uijand dijremain within the interval [−8, 8] and hence q−1(uij) and q−1(dij) correspond to values contained in Table 1. We can therefore choose the uncertainty interval boundaries according to:(12)Dij=q−1(dij)(13)Uij=q−1(uij)Given samples of the randomly generated pairwise comparison matrices P(m), it is interesting to relate the strength of the perturbations s to the expected uncertainty level L = 〈q(Uij) − q(Dij)〉 = 〈nij〉 − 1 shown in Fig. 1. Note that the mapping in Eq. (9) and (10) forces uijand dijto remain bounded inside [−8, 8] even if |Δuij| is large. This implies that L is determined by both s and the value of q(Aij). Given the value of s, the corresponding value of L is estimated by Monte Carlo simulations. The results are plotted in Fig. 1 which provides a means of translating the value of L to the perturbation strength s and will be used in the realization of the uncertainty model described below.Taking into account the above discussion, we now proceed to determine how the probability PRR of rank reversal is related to the uncertainty level L and expert group size M. Our approach is based on Monte Carlo (MC) simulations. In each iteration k, we generate a matrix A(k), the elements of which are randomly chosen from the values of Table 1. If A(k) is not nearly consistent (i.e. C.R. > 0.1 according to Section 2.1) then it is discarded and we recalculate A(k) until this criterion is met. Given the value of L and the value of each elementAij(k)of A(k), we use Eqs. (9) and (10) to estimateuij(k)anddij(k)by generating the random perturbationsΔdij(k)andΔuij(k). The strength of the perturbations s is chosen based on the values of Fig. 1. OnceDij(k)=q(dij(k))andUij(k)=q(uij(k))are determined, we generate a large number of PWC matrices (typically Nmatrix ≅ 104) and distribute them in NG = ࣰ⌊Nmatrix/M⌋ࣻ groups of M nearly consistent matrices P(ν) with 1 ≤ ν ≤ Nmatrix and where ࣰ⌊x⌋ࣻ stands for the largest integer which is smaller than x. In the context of Section 2.2, the matrices P(ν) can be assumed as a perturbed version of A(k) and the perturbation is simply ΔP(ν) = P(ν) − A(k). For each of these NG expert groups we calculate the priorities of the alternatives as discussed in Section 2.1. We then estimate the number FG of groups for which the order of priorities calculated is different than the order of priorities W'kcalculated by averaging out the weights obtained by all the matrices P(ν). The latter priorities corresponds to the order obtained by a very large (M = Nmatrix) group of experts and since Nmatrix is very large, one expects that W'kare approximately equal to the ideal weights Wkcorresponding to the limit of infinite group of experts (M→∞). The probability of rank reversal for iteration k is then approximated as PRR(A(k)) ≅ FG/NG. In the next iteration k + 1 we estimate a different initial matrix A(k+1) and estimate the probability of rank reversal PRR(A(k+1)). The average probability of rank reversal (independent of the choice of the initial matrix) is then calculated as(14)PRR=1NMC∑k=1NMCPRR(A(k))where NMC is the total number of MC iterations. It is interesting to note that one can estimate PRR for many different values of M using the same random samples of the pairwise comparison matrices.In this section, we present the results obtained when we apply the framework described above in Section 2. Section 3.1 presents some numerical results that further validate the first order analysis of Section 2.2, while Section 3.2 examines the convergence properties of PRR.Τo validate our first order analysis, as presented in Section 2.2, we numerically calculate the PDF of a representative average weight wkobtained by a group of experts of size M. The PWC matrices of all experts are calculated as discussed in Sections 2.3 and 2.4 starting from the same nearly consistent N × N initial matrix A with C.R. < 0.1. The results are shown in Figs. 2 and 3, for the cases of M = 10 and M = 40 experts, respectively, both for N = 4 and N = 6 criteria. 106 Monte Carlo (MC) iterations are used and we assume the case where the uncertainty level L is equal to 3. The figure shows the PDFs obtained using either the full weight calculation method outlined in Section 2.1 and the first order approximation given by Eq. (6). Also shown is the Gaussian fit to the former PDF (the Gaussian fit to the latter case is practically the same). The figures illustrate that Eq. (6) is indeed a valid approximation for the individual and hence the average weight perturbations. In addition, the average weights follow a normal distribution in accordance to what has been discussed in the previous paragraph. Similar results are obtained for the rest of the weights as well as for other values of N, L and M. Fig. 3 shows the PDF obtained for M = 40 starting from another initial matrix A.The above discussion in Section 2.2 and the results of this section highlight the fact that to a first order, other than determining the mean value and standard deviation of the priorities wk, the statistics ofΔPij(m)should play a secondary role in the rest of the statistical properties of wk(e.g. the shape of their PDF).Applying the uncertainty model discussed in Sections 2.3 and the Monte Carlo simulation procedure in Section 3.1, we can calculate the probability of rank reversal PRR, in order to estimate its dependence on the expert group size M which is a key issue from a practical point-of-view, as discussed in the introduction. We first examine the convergence properties of PRR with respect to M, in the case of a relative small number of alternatives (N = 3), taking into account a variety of uncertainty level values L. For each value of M, we performed NMC = 103 iterations and on each iteration we generated Nmatrix = 104 random matrices. As indicated in Fig. 4(a), PRR is already low (below 7 percent) even for a group size as small as M = 10 for reasonable values of L. Another important conclusion drawn by the figure is that the convergence speed of PRR is rather slow. For example, for L = 7, PRR changes from 6.8 percent to 3.5 percent when the number of experts is increased from 10 to 20, implying a small practical gain from increasing the expert group size, since PRR is already low for M = 10. The gain is even lower for smaller uncertainty levels. The figure also illustrates that there is not much sense in increasing the number of experts beyond M = 15 since the reduction in PRR is even smaller.In order to examine the reliability of the estimated PRR values we can calculate the confidence intervals. We first start with the statistics of the values Prfor the probability of rank reversal PRR obtained by running multiple Monte Carlo iterations for a single value of M. If all these values are similar, we can deduce that our results are credible. Fig. 5plots the PDF of the calculated PRR values obtained by their histogram over NMC = 103 simulations for N = 3, M = 10 and L = 7. Since the value of PRR in each simulation is calculated as the average over many independent realizations, the Gaussian PDF fits very well with the estimated PDF. We also notice that there are small variations in the calculated PRR values (the PDF is practically non-zero from 0.067 to 0.070). Since the statistics are Gaussian, we may also readily calculate the confidence interval IC for a 95 percent confidence level. Using standard confidence interval formulas (Hanke &#38; Wichern, 2008) we readily find that IC = [0.067, 0.068] and IC = [0.0179, 0.0180] in the case where L = 7, N = 3, M = 10 and L = 1, N = 3, M = 10 respectively. These tight confidence intervals imply that the number of iterations considered in the calculations of Figure 4 is adequate in order to accurately estimate the probability of rank reversal. Similar results are obtained when estimating the confidence intervals of other points in the graphs. For example for M = 40, L = 7, N = 3 we obtain IC=[ 0.0099, 0.01].To further understand the convergence of PRR with respect to M, we calculate the differential decrease ΔPRR(M) in the probability of rank reversal when the group size is increased by ΔΜ = 1 expert:(15)ΔPRR(M)ΔM=|PRR(M+1)−PRR(M)|In Fig. 4(b) we have plotted ΔPRR as a function of M. The figure indicates that even for L = 7, the changes in the probability of rank reversal when an additional expert is added in the group are very small (below 1 percent per expert) at M = 15. It therefore makes little sense of increasing the expert group size beyond that. This is also shown in Fig. 4(a) where increasing M from 15 to 40 has very little impact from a practical point of view, since the additional number of experts only marginally reduces the uncertainty of the outcome.Fig. 6(a) shows the values of PRR for the case where N = 6 alternatives are pairwise compared, assuming the same uncertainty levels as in Fig. 4. As expected, since the number of alternatives is now larger, one obtains higher values for PRR than in (may even exceed 20 percent in some cases). Indicatively, for L = 7 the confidence intervals are IC =[0.22, 0.23] and IC =[0.0245, 0.0255] for M = 10 and M = 40 experts, respectively. Fig. 6(b) shows the corresponding values of ΔPRR and it is deduced that varying the size of the expert group is now more beneficial. For M = 10, PRR is reduced to about 18 percent when the group size is increased by 1 in the case of L = 7. However, for M > 15, the gain becomes progressively smaller as a result of the slow convergence of PRR. Given the practical restrictions of increasing the group size, the figure suggests that using more than 15 experts may not have a strong bearing in the uncertainty of the results.Fig. 7illustrates the convergence of PWC for different values of criteria N and a constant L = 3. We consider the cases where N = 2, N = 4 and N = 6. The model easily allows to consider cases where N > 6, but in actual situations, performing PWC with that many alternatives becomes impractical since the number of pairwise comparisons Nc for each expert is given by Nc = N(N −1)/2 and therefore scales as O(N2). As shown in the figure, PRR does depend on N: For a group size of ten experts (M = 10), PRR ≅ 6 percent when the experts are asked to make pairwise comparisons on six alternatives and this drops slightly to 3.5 percent when the number of criteria is 6. Other than that, the convergence behavior of PRR does not seem dependent on the number of criteria. In all cases, there is no significant gain in increasing the group size beyond 15. This is due to the slow convergence properties of PWC, which seems to hold regardless the number of alternatives used and the uncertainty level.Up to this point, we estimated PRR taking the same uncertainty level associated with each expert in the group. It is also interesting to carry out this estimation when a different uncertainty level L(m) is assumed for each expert m. From a practical point-of-view, this reflects what could happen when the level of expertise varies from participant to participant. Fig. 8(a) shows the values of PRR, as a function of the expert group in the case where the uncertainty level L(m) is randomly selected with equal probability inside the integer interval [1, 7]. The results are shown for N = 3 and N = 6. One obtains similar convergence behaviorto the previous case. Similar results were also obtained if we calculate the differential decrease ΔPRR(M) as shown in Fig. 8(b). The similar convergence behaviorobserved in the case of varying uncertainty level can be explained taking into account the theoretical framework of Section 2.2, where we have shown the statistical properties of the uncertainty perturbations other than their mean value and standard deviation, are not expected to play that big of a role in the statistics of the weight and hence of the PRR. We therefore expect a change in the values of PRR but its convergence behaviorwith respect to M should be more or less the same.The linear preference scale consisting of integers from one to nine and their reciprocals shown in Table 1 is used quite often in applications of the PWC method. Saaty (1991)advocates this scale as the best one to represent weight ratios. Nevertheless, it is interesting to investigate the convergence properties of PRR considering alternative preference scales such as the inverse linear or the logarithmic scale (Ishizaka &#38; Labib, 2011). Instead of the elements in Table 1, in the former scale we use the elements 9/(10 − x) where x ∈{1, 2,…, 9} as well as their inverses (10 − x)/9. The alternative scale {1/9, 2/9,…, 1,…, 9/2, 9} can therefore be indexed in the same way as the scale of Table 1 but with a different mapping q(V). The matrices can again be chosen by randomly selecting the indices as before and applying the alternative mapping. The elements of the logarithmic scale are determined by logα(x + (α − 1)) where x ∈ {1, 2,…, 9} and α > 1 and their inverses and can be again indexed in a similar way. In any case, we may still use L as a measure of uncertainty.Fig. 9(a) and (b) illustrates ΔPRR for the inverse linear and logarithmic scales, respectively in the case N = 6. For the logarithmic scale we assumed a = 2 (Ishizaka, Balkenborg, &#38; Kaplan, 2011). As shown in Fig. 9, the convergence of ΔPRR is again slow, implying that the convergence of PRR is similar even when an alternative preference scale is used by the experts. From Fig. 9(a) and (b) one may deduce that ΔPRR varies in a similar manner as before, again suggesting that there is no significant gain in increasing the group size beyond 15.Another important issue to consider is whether the results presented above depend on the weight estimation method. Instead of estimating the weightswk(m)through the eigenvalue method (EM) discussed in Section 2.1, one could also apply the Geometric Mean Method (GMM) or equivalently the Logarithmic Least Square Method (LLSM) (Saaty, 1990). This method attempts to fit the elements of the pairwise comparison matrix P(m) with a perfectly consistent matrix, i.e. a matrix whose elements are of the formwi(m)/wj(m). The weights are therefore determined by minimizing the following metric through unconstrained nonlinear optimization:(16)QGMM=∑i,j=1N(logPij(m)−log|qi(m)qj(m)|)2After the minimization is performed, we choosewi(m)=|qi(m)|/∑j|qj(m)|to ensure that they are positive and sum up to one. In our implementation we use MATLAB's fminsearch function which is based on the simplex search method (Lagarias, Reeds, Wright, &#38; Wright, 1998).Fig. 10(a) and (b) shows the values of PRR and ΔPRR for the case of GMM, where N = 6 criteria are pairwise compared assuming several uncertainty levels L. It is shown that for both low and high L, one obtains a similar convergence behavior for PRR and ΔPRR as in the EM case. Comparing Fig. 10(a) and (b) with Fig. 6(a) and (b) respectively one also deduces that the actual values of ΔPRR and PRR are approximately the same implying that both weight estimation achieve approximately the same credibility.In this section we investigate the case where the experts carry out their comparisons in a fuzzy manner (Deng, 1999), i.e. by assigning fuzzy numbers in the elements of the pairwise comparison matrix (Chao Chung, 2011). A fuzzy numberb˜does not refer to one single value but rather to a connected set of possible values x centered on b, each with its own weight ub(x) between 0 and 1. This weight distribution is called a membership function. In the special case where the membership function is triangular, then(17)ub(x)={(x−l)/(b−l),l≤x≤b(u−x)/(u−b),b≤x≤u0,otherwisewhere [l, u] is the range of values of x, in which the weight ub(x) is non-zero. The triangular membership function in Eq. (17) is determined by the triplet (l, b, u) which consequently completely determines the fuzzy numberb˜.To carry out fuzzy PWC, we need to define a fuzzy preference scale where fuzzy numbers are used instead of precise numbers as in a conventional preference scale. The pairwise comparison elements will therefore consist of fuzzy rather than precise numbers. The scale adopted can be a fuzzy extension of a conventional scale such as the one in Table 1. The fuzzy scale adopted in this work consists of the fuzzy numbersb˜where b is an integer 1 ≤ b ≤ 9 and whereb˜=(b−1,b,b+1)if 2 ≤ b ≤ 8,1˜=(1,1,1)and9˜=(9,9,9). The scale also contains the reciprocal elements ofb˜as defined in Chao Chung (2011).The procedure for the estimation of the fuzzy weights is based on extension principle theory (Gerla &#38; Scarpati, 1998). Once the pairwise comparison elements(lij(m),bij(m),uij(m))are determined, we apply a constrained minimizationprocedure to estimate the fuzzy weights(ri(m),wi(m),ei(m))for each expert. The function to be minimized is written as:(18)J=∑i=1N∑j=1i≠jN{[lnri(m)lij(m)ej(m)]2+[lnwi(m)wj(m)bij(m)]2+[lnei(m)uij(m)rj(m)]2}The minimization constraints are outlined in (Wang, Elhag, &#38; Hua, 2006). In our implementation we use MATLAB's fmincon function which is based on the interior point algorithm (Waltz, Morales, Nocedal, &#38; Orban, 2006). To calculate the average fuzzy weightsw˜i=(ri,wi,ei), we simply average the points of the individual membership functions, i.e.ri=M−1∑mri(m),wi=M−1∑mwi(m)andei=M−1∑mei(m).In order to incorporate uncertainty in this fuzzy extension of PWC, we consider the following approach where the pairwise comparison matrices of the experts are obtained again by randomly perturbing an initial consistent pairwise comparison matrix A(k) in order to obtain the matrices P(ν) as discussed in Section 3.1. Given P(ν) we then consider its fuzzy extensionP˜(ν)with elementsP˜ij(ν)=(lij(ν),bij(ν),uij(ν))wherebij(ν)=Pij(ν)andIij(ν)anduij(ν)are determined according to the fuzzy scale as discussed above. From this point forward the simulation procedure is the same as before except that the weights are calculated by the minimization of Eq. (18) instead of the eigenvalue method. In the context of fuzzy judgments, we assume that rank reversal occurs whenever there exist at least two indices i, j for which the ordering of the center or the upper edge of the corresponding membership function changes compared to the one obtained by a large group of experts.In Fig. 11(a) and (b) we show ΔPRR in the case of fuzzy judgments as a function of the expert group size, for N = 3, N = 6 criteria respectively. The figures illustrate that even in the case of fuzzy judgments, the convergence of PRR is again slow. For N = 6, ΔPRR is smaller than 0.01 for M > 15 even for large uncertainty levels indicating not much practical gain in further increasing the group size.The previous analysis dealt with the impact of uncertainty in the evaluation of the priorities of the alternatives, quantified in terms of PRR. We now consider the issue of estimating PRR from actual user data, i.e. a relatively small number of pairwise comparison matrices P(m) obtained by a single expert group. In this section, we propose a numerical method to achieve this and validate our approach with numerical simulations.Our scheme for evaluating the probability of rank reversal is described in the dash line frame of Fig. 12. We first extract some information on the statistical properties of the perturbations (step 2 in Fig. 12). One approach is to calculate the maximum and minimum values ofPij(m)with respect to m:(19)Uij′=max{Pij(m)},Dij′=min{Pij(m)}Another approach would be to map the elementsPij(m)to their corresponding integers according to Eq. (8) and then estimate the mean value μijand the standard deviation σijof q(Pij(m)) with respect to m, i.e.(20)μij=1M∑m=1Mq(Pij(m))(21)σij2=1M∑m=1M[q(Pij(m))−μij]2Assuming uniform statistics, Eqs.(19) and (20)–(21) are two alternative methods for determining the statistics of the perturbations. Once these statistics are identified, one can perform Monte Carlo simulations (step 3 in Fig. 12) to determine the probability PRR. In the first case, one generates a large number NPWC of random pairwise comparison matrices R(l) 1 ≤ l ≤ NPWC, the elementsRij(l)of which are uniformly chosen from [D'ij, U'ij]. Note that these matrices do not correspond to pairwise comparison matrices filled out by any actual experts. Rather, they are random matrices numerically generated based on the information extracted by the limited set of user matrices P(m). In the second case, one again generates the random matrices R(l) assuming thatRij(l)follow a uniform distribution which is determined by the mean value μijand standard deviation σij. In any case the random matrices R(l) are distributed into ࣰ⌊NPWC/M⌋ࣻ groups containing M matrices each. The probability of rank reversal can be approximated by calculating the number of times for which the priorities obtained by each of these groups is not the same as that obtained by the initial weights wk(step 4 in Fig. 12). In order to distinguish between the two estimates we designate asPRR(minmax)(Ak)andPRR(std)(Ak)the probabilities of rank reversal obtained by Eqs. (19) and (20)–(21) respectively given the initial matrix Ak. One should note that if the initial group size from which the data are gathered is infinite (M → ∞), the two alternative methods for calculating R(l) are equivalent, hencePRR(minmax)(Ak)=PRR(std)(Ak). However, in the case of finite M they may provide a different estimate for PRR.In order to validate the PRR estimation procedure we again resort to Monte Carlo simulations as suggested by the rest of Fig. 12. In each Monte Carlo iteration k, we calculate an initial matrix Akand estimate the intervals [Dij, Uij] as before (Section 3.1). We then generate the matrices P(m) where 1 ≤ m ≤ Nmatrix. We choose the first M matrices P(m) where 1 ≤ m ≤ M to correspond to the user matrices, while the rest of the matrices are to estimate the actual probability of rank reversal PRR(Ak) which is obtained in the fashion explained in Section 3.1. In accordance to what was discussed in Section 4.1, the matrices P(m) where 1 ≤ m ≤ M are used to estimate either D'ijand U'ijaccording to Eq. (19) or μijand σijaccording to Eqs. (20) and (21) respectively. Afterward we generate the matrices R(l) and use them to estimatePRR(minmax)(Ak)andPRR(std)(Ak)(steps 1 to 4 in the dotted portion of Fig. 12 explained in Section 4.1). To measure the error introduced by the aforementioned estimation methods, we calculate the error function defined by(22)e(u)(Ak)=|PRR(u)(Ak)−PRR(Ak)|where u stands for either “minmax” or “std”. Averaging over many possible of the initial matrices obtained in the different Monte Carlo iterations, we can therefore obtain an estimate for the average error:(23)e(u)=1NMC∑l=1NMCe(u)(Ak)Fig. 13(a) and (b) shows the values of e(std) and e(minmax) obtained by the MC simulations as well as the probability of rank reversal PRR obtained by the procedure outlined in Section 3, for L = 5 and (a) N = 3 and (b) N = 6. We see that the average error depends on the method used for the estimation of the perturbation statistics. The values of e(minmax) are higher than e(std) demonstrating that determining the perturbation statistics through the mean value and standard deviation is much better. This is in accordance with what was discussed in Section 2.2 where the CLT was used to discuss the perturbation statistics. The statistical properties of the perturbed weights resemble those of a Gaussian distribution. In addition, according to the CLT, it is the mean value and the standard deviation that primarily determine this distribution rather than other measures like D'ijand U'ijused in the “minmax” method. We see that for N = 3, the “std” method results in an average error of e(std) = 2 percent for M = 10 which corresponds to less than half the value of PRR implying that the method correctly estimates the order of magnitude of PRR which is important in practical applications of the method. Similar observations are drawn in the case where N = 6, shown in Fig. 13(b) indicating that the method provides reasonable accuracy for increasing number of alternatives. On the other hand, the “minmax” method produces larger errors in the estimation of PRR and especially in the case where N = 6 produces errors which are larger than the value of PRR itself. It is also interesting to investigate the accuracy of both methods under an even greater uncertainty level. In Fig. 14(a) and (b) we show the values of e(std) and e(minmax) in the case where L = 7 again for N = 3 and N = 6 respectively. It is again deduced that the “std” method provides sufficient accuracy when estimating the probability of rank reversal while the “minmax” approach leads to significant larger errors. Both methods however seem to provide a correct estimate regarding the order of magnitude of PRR.Fig. 15discusses the accuracy of the “std” approach for a group size equal to M = 15 which according to Section 3, is a sufficient group size to estimate the priorities of the alternatives, given the limitations of practical PWC applications. It is verified that e(std) is significantly smaller than PRR implying a tolerable error in the estimation of the probability of rank reversal.In the aforementioned results, the eigenvalue method was used for the estimation of PWC weights. Nevertheless, it would be very interesting to investigate the estimation of PRR from actual user data applying the Geometric Mean Method, as analyzed previously in Section 3.2.3. Fig. 16shows the values of PRR and e(u) for the case where N = 3 criteria are pairwise compared assuming an uncertainty level L = 5. The results reveal that the values of PRR, estimated by actual user data, increasing the expert group size is more or less the same as mentioned before in the context of EM in Fig. 13(a). It is again deduced that the “std” method provides sufficient accuracy while the “minmax” approach leads to larger errors.It is also interesting to investigate the estimation of PRR from actual user data considering the representation of judgments by fuzzy numbers, as discussed in Section 3.2.4. Toward this end, we apply the scheme shown in Fig. 12 except that the matrices are now replaced by their fuzzy extensions and the weights are calculated in a fuzzy manner as discussed previously. Again the probability of rank reversal from actual user data can be estimated using both the “minmax” and “std” methods. The uncertainty model is modified in order to incorporate the fuzzy judgments in the opinion of experts when generating the matrices R(l), where the elementsRij(l)either are uniformly chosen from [D'ijU'ij] for the case of “minmax”, or follow a uniform distribution determined by the mean value μijand standard deviation σijfor “std” method. In Fig. 17we show the values of e(std) and e(minmax) in the case where L = 5 and N = 6. Inspection of the results depicted in the figure reveals that similar conclusions are drawn for the estimation of PRR from actual user data in the case of fuzzy judgments. It is obvious that applying either the traditional PWC or the fuzzy triangular representation of PWC judgments, the “std” method prevails against the “minmax” for the estimation of PRR from actual user data.

@&#CONCLUSIONS@&#
In this paper, we applied an uncertainty model to address two important issues concerning the probability of rank reversal in pairwise comparisons. The first issue concerned how this probability is reduced by augmenting the number of experts participating in the surveys. The results dictate that there is not much to be gained by increasing the number of experts beyond 15, even if uncertainty level is large. Using perturbation theory we have argued that the convergence of the probability of rank reversal with the number of experts is not crucially dependent on the uncertainty statistics. We have also shown numerically that the choice of comparison scale and weight selection method does not significantly affect the convergence. The second issue concerned the problem of how the probability of rank reversal can be estimated in practice, from the elements of the pairwise comparison matrices of a single expert group. Two alternative methods have been discussed for extracting information on the statistical behavior of the uncertainty-induced perturbations. It was shown that one of them provides reasonable good accuracy and can therefore be used in practical applications of the method for estimating the credibility of the outcome. Interestingly enough, this conclusion holds under other situations such as fuzzy pairwise judgments, alternative preference scales, weight estimation methods and accounting for a different uncertainty level for each expert in the group.