@&#MAIN-TITLE@&#
MR image super-resolution reconstruction using sparse representation, nonlocal similarity and sparse derivative prior

@&#HIGHLIGHTS@&#
Do MR image SR by jointly using sparsity prior, nonlocal similarity, and sparse derivative prior.Use multi-scale first- and second-order derivative to estimate high-frequency information.Use sparse derivative prior based post-processing to suppress blurring effects in MR images.

@&#KEYPHRASES@&#
Magnetic resonance imaging,Super-resolution,Sparse representation,Sparse derivative prior,Nonlocal similarity,

@&#ABSTRACT@&#
In magnetic resonance (MR) imaging, image spatial resolution is determined by various instrumental limitations and physical considerations. This paper presents a new algorithm for producing a high-resolution version of a low-resolution MR image. The proposed method consists of two consecutive steps: (1) reconstructs a high-resolution MR image from a given low-resolution observation via solving a joint sparse representation and nonlocal similarity L1-norm minimization problem; and (2) applies a sparse derivative prior based post-processing to suppress blurring effects. Extensive experiments on simulated brain MR images and two real clinical MR image datasets validate that the proposed method achieves much better results than many state-of-the-art algorithms in terms of both quantitative measures and visual perception.

@&#INTRODUCTION@&#
Compared with other medical imaging techniques, MR imaging uses non-ionizing radiation and provides distinct microscopic chemical and physical information of molecules. However, the spatial resolution of MR images is limited by various instrumental limitations (e.g., gradients’ intensity, filter bandwidth) and physical considerations. The resolution limitation could result in partial volume effect (PVE), a phenomenon that each pixel in the MR images could contain more than one material or tissue type. To reduce PVEs, a common practice is to magnify the images using standard interpolation techniques. However, interpolation techniques usually do not take into account the fact that a low-resolution (LR) pixel is actually a weighted average of the high-resolution (HR) pixels inside it, thus the magnified HR images are typically featured with blurred edges and tissues.To overcome this problem, various methods have been proposed [1,5–8,11,12,17–20] so far. Among them, super-resolution (SR) is one of the most promising methods and receives much attention in the research community. SR image reconstruction is the process of recovering a HR image from a single (e.g., [2]) or a set of LR images (e.g., [3]). The essential difference between single-frame and multi-frame SR image reconstruction is that new high-frequency information could also be recovered from different LR frames [4]. In MR image analysis, SR was first used to reconstruct a HR image by merging multiple LR acquisitions with subpixel displacements. In [5], Herment et al. reduced total data acquisition time by merging multiple k-space data. Shilling et al. [6] improved the resolution and contrast of MR images by fusing multiple 2D slices with different slice directions. Greenspan et al. [7] used iterative back-projection and Islamet al. [8] used a wavelet-based deblurring approach to improve the resolution of 3D MR images.Though multi-frame SR image reconstruction is theoretically more promising than single-frame SR image reconstruction, it suffers many difficulties in real applications, such as subpixel image registration/acquisition, the increase of computational complexity as frame number increases. On the other hand, many researches [9,10] have demonstrated that, given a proper prior image model, single-frame SR image reconstruction can also be as effective as multi-frame SR image reconstruction. To reconstruct a HR image from a single MR image, Rousseau [11] used the idea presented in [9] and proposed a patch-based nonlocal regularization framework for brain MR image reconstruction. Manjón et al. [12] extended the patch-based nonlocal regularization framework to include a coherence constraint.Recently, a powerful statistical image modeling technique, sparse representation [13,14], has been successfully applied in natural image SR applications [15,16,22]. In MR image analysis, however, many efforts have been focused on applying compressed sensing (CS) [17–20], a technique through which a perfect MR image reconstruction is possible by only a small subset of k-space samples that is far less than the Nyquist sampling theorem. Since these CS-based SR methods [17–20] focus on manipulating k-space samples, they do have many advantages, e.g., theoretical simplicity and low computational cost. Nevertheless, they also present some important drawbacks. For example, recovering high frequency information in the k-space will inevitably cause visual artifacts in the image space, thus they need to work in the frequency and the image space in turn to suppress artifacts [20,21]. On the other hand, sparse representation based techniques manipulate image patches in the image space, thus provide much more interpretable information to human eyes, and more importantly, facilitate experts to adopt a much more flexible observation model (e.g., local motion) and incorporate various image priors. Based on these considerations, Andrea et al. [21] proposed to reconstruct HR 3D brain MR image from LR 3D image volumes using overcomplete dictionaries.Motivated by the ideas presented in Refs. [11,12,21,36,37], in this paper, we propose a new algorithm for reconstructing a HR MR image from a single LR image. The proposed method consists of two consecutive steps: (1) reconstructs a HR MR image from a given LR observation via solving a joint sparse representation and nonlocal similarity L1-norm minimization problem; and (2) applies a sparse derivative prior based post-processing on the reconstructed HR image to suppress blurring effects.The rest of the paper is organized as follows. In Section 2, we give a brief review of SR image reconstruction based on sparse representation. Sections 3 and 4 present the nonlocal similarity and sparse derivative prior image model, respectively. Section 5 presents the new algorithm. Extensive experiments on simulated brain MR images and two real clinical MR image datasets are conducted in Section 6 to verify the efficiency of our method. Finally, we provide discussion in Section 7.In SR image reconstruction, the LR image can be modeled as a down-sampled version of the HR image which has been blurred, i.e.,(1)Y=WZwhere Y is the observed LR image, Z is the original HR image, and W is a degradation operator representing the blur and down-sampling operator which operates on Z to yield Y (geometric shift is not included in W since we focus on the single-frame SR reconstruction). A maximum a posterior (MAP) estimate of the unknown HR image Z can be computed as(2)Z^=argmaxZ{logPr(Z|Y)}=argminZ{‖Y−WZ‖22-logPr(Z)}where Pr(Z) is the prior image model. Many works have been contributed to find a good prior image model, and total variation (TV) [23–26] is one of the most commonly used models. Sparse representation has also been successfully applied as a prior image model as well. Given an image Z, the sparse representation assumes that there exists a sparse vectorΛand a proper learned dictionaryΨ(each column inΨis referred to as an atom), such that(3)Z≈ΨΛ,s.t.‖Λ‖0≤εwhereεis a predefined threshold to control the sparsity ofΛand L0-norm‖⋅‖0counts the number of nonzero elements in a vector.LetΨhandΨlare the coupled two dictionaries for the HR and LR images, respectively. For single-frame SR reconstruction, given a HR image Z and the corresponding LR image Y, there exists a sparse vectorΛsimultaneously satisfies [15](4)Z≈ΨhΛandY≈ΨlΛ,s.t.‖Λ‖0≤ε,With the sparsity prior image model defined in (4), finding the solution to (1) is equivalent to finding the representation of Z overΨh, which can be estimated from its LR observation Y by solving the following L0-norm minimization problem:(5)Λ^=argminΛ{‖Y−ΨlΛ‖22+λ‖Λ‖0}whereλis a parameter controlling the importance of sparsity prior. Since L0-norm is nonconvex and solving (5) is NP-hard, many recent works [13,27] demonstrated that if the coefficientsΛis sparse enough, the solution to (5) can be efficiently approximated by solving the following L1-norm minimization problem(6)Λ^=argminΛ{‖Y−ΨlΛ‖22+λ‖Λ‖1}where L1-norm‖⋅‖1calculates the sum of the absolute of each element in a vector. Notice that (6) is also known as the Lasso in statistical literature [28].OnceΛ^is obtained, Z can then be estimated as(7)Z^=ΨhΛ^Traditionally, we divide an image into overlapped or non-overlapped patches, apply (6) and (7) to each image patch and fuse all the reconstructed HR patches to get the final HR image. To avoid confusion, we use letters in lowercase or uppercase to represent an image patch or an entire image throughout this paper unless otherwise stated. For the convenience of later discussion, we write the patch-based version of (6) and (7) as follows:(8)α^=argminα{‖y−Ψlα‖22+λ‖α‖1}(9)z^=Ψhα^A critical issue in sparse representation prior is the choice of dictionaries. In general, the more redundant the dictionary is, the better SR result will be. Unfortunately, the computational complexity will also increase as the size of dictionary increases. Many dictionary learning algorithms thus aim at getting a compact over-complete dictionary to represent various image patches. Nevertheless, due to the diversity of natural image patterns, it is impossible for such compact dictionary to cover all the patterns. As a result, the similar patterns can well be reconstructed while the dissimilar ones cannot. Considering the fact that either similar or dissimilar patterns, there are often many repetitive patterns throughout an image, such nonlocal redundancy is very helpful in preserving edge sharpness and suppressing noise in the reconstructed images [12,14,29,30]. As a supplementary to the sparse representation prior, in this section, we will develop a nonlocal similarity regularization term for SR image reconstruction.For a given image patch zj, we search for the similar patches within a sufficiently large area around zj. Two similarity criteria have been frequently used so far: (1) a patchzjsis selected as a similar patch to zjifdjs=||zjs−zj||22≤t, where t is a preset threshold, or (2) one can select the patch if it is within the first L (e.g., L=15) closest patches to zj. However, they are all based on Euclidean norm in the vector space and do not truly reflect the similarity between two vectors. In this paper, we use the cosine of the angle between two vectors as the distance measurement,(10)djs=〈zjs,zj〉(||zjs||2⋅||zj||2)Suppose L similar patches (zjs, s=1,2,…,L) have been located for zj, letzjsbe the central pixel ofzjsand zjbe the central pixel of zj. We can use the weighted average ofzjsto predict zj,(11)z^j=∑s=1Lzjscjswherecjsis the weight assigned tozjs, determined by(12)cjs=exp(−djs/h)∑s=1Lexp(−djs/h)wheredjsis determined by (10) and h is a controlling factor of the weight. Considering the fact that there are plenty of repetitive patterns throughout a MR image, the mean squared error between the prediction and the ground truth, i.e.,(13)||zj−z^j||22=||zj−∑s=1Lzjscjs||22should be sufficiently small. Let cjbe the column vector containing all the weightscjsand patch pjbe the column vector containing allzjs. By summing the mean squared prediction error across the whole image patch zj, we get(14)∑zj∈zj||zj−∑s=1Lzjscjs||22=∑zj∈zj||zj−cjTpj||22Since (8) calculates the sparse representation coefficients of HR image patch z only using fidelity constraint and sparsity prior, to incorporate the nonlocal similarity regularization, we revise (8) as follows:(15)α^=argminα{‖y−Ψlα‖22+λ‖α‖1+η∑zj∈z^j||zj−cjTpj||22}whereηis a parameter controlling the contribution of nonlocal similarity regularization. If we define a matrix C as(16)Cjs={cjs,ifzjs∈pj,cjs∈cj0,otherwiseBy substituting (16) andz=Ψlαinto (15), we get(17)α^=argminα{‖y−Ψlα‖22+λ‖α‖1+η||(I−C)Ψlα||22}where I is an identity matrix. By introducing(18)y⁎=[y0]andΓ=[Iη(I−C)]Eq. (17) can further be simplified as(19)α^=argminα{‖y⁎−ΓΨlα‖22+λ‖α‖1}Please note that (19) has exactly the same form of (8), which is also a L1-norm minimization problem.Compared with the TV model, using sparsity prior or nonlocal similarity can improve the quality of the final HR image. However, we will demonstrate in Section 6 that sparsity prior or nonlocal similarity based methods also produce blurry effects along strong edges or in soft tissue areas in the reconstructed MR images. In general, the blurry effect is caused by the average operation in these methods. For sparsity prior based methods, overlapped HR patches are separately reconstructed and the pixels in the overlapped regions are averaged via various strategies to maintain compatibility between adjacent patches, and as a result, the selected averaging strategy largely determines the blurry degree. On the other hand, for nonlocal similarity based methods, L similar patches (not identical patches) are averaged to predict the central pixel of the target patch, and certainly the higher the degree of similarity, the less blurry effect in the final HR MR image. Since balancing the blurry effect of sparsity prior and nonlocal similarity under a unified L1-norm minimization framework is difficult and complicated, in this paper, we adopt the sparse derivative prior image model to suppress blurry effects.For lots of natural images, researchers have found that after applying a localized, oriented, and bandpass filtering operation, the histogram of the filtered images are exponential with high fourth-order statistics (kurtosis) [38–40]. For example,Fig. 1(a) shows a natural image, the histogram of the filtered image via a 1-D filter [−1, 0, 1] is shown in Fig. 1(b). We can model the distribution in Fig. 1(b) via(20)Pr(x)∝exp(−12(|x|σ)α)whereσis the standard deviation, andαis the exponent parameter. Fig. 1(b) reveals the fact that the gradients of an image are largely zeros, i.e., strong derivatives are sparse in a given natural image. Eq. (20) is also known as the natural image prior when0<α<1, for it can model lots of natural images [38–40]. Unlike the TV model assumes local smoothness, the natural image prior tends to encourage a single strong derivative, which would appear as a sharp edge in local regions. The natural image prior has been successively applied in natural image noise reduction [41], compression [42], deconvolution [43,44], and SR as well [36,37]. In [37], Tappen et al. simultaneously used fidelity constraint and natural image prior to perform SR. Kwang and Younghee [36] first used kernel ridge regression and then applied natural image prior based post-processing to suppress ringing artifacts. Nevertheless, to the authors’ best knowledge, by far there are many works reported on natural image processing utilizing natural image prior, little similar job was done on MR images or other medical images. To validate whether the natural image prior can be applied to MR images, we filter a brain MR image (shown inFig. 2(a)) with the same 1-D filter used in Fig. 1 and show the histogram of the filtered image in Fig. 2(b). By comparing Fig. 1 with Fig. 2, it is clear that though the two images shown in Fig. 1(a) and Fig. 2(a) are quite different in nature, the distributions are almost the same, which implies that the natural image prior can also be used in MR image processing.In [37], Tappen et al. estimated the HR patch z by maximizing the following joint posterior probability distribution(21)Pr({z}|{y})=1C∏j,i∈N8(j)exp[−(‖zj−zi‖1σN)α]∏jexp[−(‖Wzj−yj‖2σR)2]where {y} denotes the observed variables corresponding to the pixels in LR image Y, {z} represents the latent variables corresponding to the patch in HR image Z which satisfies y=Wz, N8(j) denotes for 8-connected neighbors of the pixel at location j, C is the normalization constant,σNandσRare standard deviation parameters. The first product in (21) is the natural image prior term and the second one is the fidelity constraint term. Considering that the data fidelity constraint has already been incorporated in the reconstruction process via the coupled two dictionariesΨhandΨl, directly using (21) in our case is unsuitable. In this paper, a modified version of (21) is thus introduced as follows(22)Pr({z}|{z^})=1C∏j,i∈N8(j)exp[−(‖zj−zi‖1σN)α]∏jexp[−(‖zj−z^j‖2σR)2]where {z^} denotes the reconstructed HR patches viaz^=Ψhα^andα^is the solution to (19). The motivation for the replacement of the second product term is intuitive: we want that the final result is not deviate far from the output yielded by (19).To find the solution through which the joint posterior probability distribution (22) is maximized, we first convert (22) into a factor graph (shown inFig. 3, the complete derivation of the factor graph can be traced back to [37]) and then use a max-sum-type belief propagation (BP) algorithm to compute the exact maximum posterior probability at each variable node. To facilitate the optimization, unlike Tappen et al. did in [37] where 16 learned interpolators are used to generate 16h candidates for each latent variable, we use L+1 patches (the source patch got by (19) plus the corresponding L patches got in the step of searching for nonlocal similar patches) as candidates.Based on (22), the logarithm of the required message-passing equations for the factor graph can be summarized as(23)ν[j]→j(zj)=−12(‖zj−z^j‖2/σR)2μ[i,j]→i(zi)=maxzj[μj→[i,j](zj)−12(‖zj−zi‖1/σN)α]μj→[i,j](zj)=ν[j]→j(zj)+∑k∈N8(j)\iμ[j,k]→j(zj)whereν[j]→jcalculates the message sent from constraint node [j] to variable node zj,μ[i,j]→irepresents the message sent from constraint node [i,j] to variable node zi, andμj→[i,j]is the message sent from variable node j to constraint node [i,j]. In (23),μj→[i,j]andμ[i,j]→iare natural image prior based messages propagate from latent node j to node i, whileν[j]→jis the deviation penalty term between latent node j and observed node j.With L+1 candidate HR patches in hand, the sparse derivative prior based post-processing is summarized in Algorithm 1.Algorithm 1(1)Run BP algorithm X times using the three message-passing equations defined in (23).For each variable node zj, select the candidate HR patch with the highest belief.Insert the selected candidate HR patches into the corresponding position to form the final output HR image.In this section, we first discuss how to construct the coupled HR and LR dictionaries, and then propose a new SR algorithm to reconstruct a HR image from a single LR MR image.In this paper, we use a modified version of the method presented in [15,21] to construct the coupled two dictionariesΨhandΨl(as illustrated inFig. 4). Each HR training image in the training set {Zj, j=1,2,…, N} is first blurred and down-sampled by a factor of q to produce the corresponding LR image set {Yj, j=1,2,…, N} (i.e., Yj=WZj, where W is the degradation operator defined in (1)). Then a upsampled set {YjU,j=1,2,…, N} is obtained by scaling each image in {Yj} by the same factor q via bicubic interpolation (i.e.,YjU=UqYj, whereUqis the bicubic interpolator with a magnification factor of q). Since we want dictionaryΨhcontains useful discriminative high-frequency information, the original HR training set {Zj} is further processed to obtain an updated HR training set {ZjU,j=1,2,…, N} viaZjU=Zj−YjU. For dictionaryΨl, many previous work demonstrated that building it in feature space is more suitable than in image space [15,16,21]. Considering the fact that the high-frequency information of the LR image is critical for predicting the lost high-frequency information in the target HR image, people often choose the feature space as some kind of high-pass filtered image. For example, Yang et al. [15] used the first- and second-order derivatives as the feature due to their simplicity and effectiveness, Rueda et al. [21] applied a multi-scale edge analysis, where a series of 6 different filters (Sobel kernels, size 3×3×3 and 5×5×5, in x, y and z directions) are used. To combine the merits of both multi-scale analysis and the first- and second-order derivatives, in this paper, we use a multi-scale (size 3×3 and 5×5) first- and second-order derivative analysis to extract features from the upsampled image set {YjU}.The eight 1-D filters used to extract multi-scale first- and second-order derivatives are(24)F11=[−1,0,1];F21=[−1,0,1]T;F31=[−1,−2,0,2,1];F41=[−1,−2,0,2,1]TF12=[1,−2,1];F22=[1,−2,1]T;F32=[1,0,−2,0,1];F42=[1,0,−2,0,1]TwhereFi1andFi2(i=1 to 4) are the first- and second-order derivative filters, respectively. For each image in the upsampled image set {YjU}, applying these eight filters we obtain eight different filtered images {FirYjU, r=1,2 and i=1 to 4}.Following the preprocessing steps described hereinbefore, for each updated HR training imageZjU, we now have eight different filtered LR images {FirYjU}. The procedure for constructing dictionariesΨhandΨlare thus summarized as follows:1.At each location d of the updated HR training imageZjU, extract a patchpZdof size m×m.Extract the corresponding LR patches of the same size from the eight filtered images {FirYjU, r=1,2 and i=1 to 4} at the same location. Then concatenate all the eight LR patches to form a single vectorpYd¯of length 8m2.Construct the HR dictionaryΨhand a temporary LR dictionaryΨl⁎by gathering all patches {pZd} and {pYd¯}, respectively.Apply Principal Component Analysis (PCA) toΨl⁎, build the corresponding orthogonal transformation matrix Q by collecting the eigenvectors of the covariance matrix that represents at least 90% of the original variance.Construct the LR dictionaryΨlvia QΨl⁎.The reason why we useΨlinstead ofΨl⁎as the final LR dictionary is the redundancy of multi-scale first- and second-order derivative analysis, since eight different filters are applied to the same image, resulting in complementary but redundant information.Since LR dictionaryΨlis not constructed in the original LR image space, thus the original fidelity constraint‖y−Ψlα‖22in the image space must be replaced by a corresponding constraint in the feature space, which does not demand exact equality between the LR patch y and its estimationΨlα. On the other hand, because no continuity conditions are imposed along the boundaries between patches, the reconstructed HR imageZ∧should thus be further refined to satisfy the SR model (1). To this end, we simply projectZ∧onto the solution space (i.e.,Y=WZ[15,21]), computing(25)Z⁎=argminZ{‖Y−WZ‖22+ξ||Z−Z^||22}whereξis a controlling parameter. Instead of using standard gradient descent method to solve (25), we can iteratively calculate the differenceY−WZ, convolve it with a back-projection kernel, then warp back into the HR image space to update the estimated HR image. This process can be written as [15,21,48,49](26)Zt+1=Zt+(Uq(Y−WZt))⁎gwhereZtis the estimate of the HR image after the tth iteration,Uqthe bicubic interpolator with a magnification factor of q, g is the back-projection filter and ⁎ is the convolution operator. This updating process is iteratively repeated until the difference between two consecutive images is less than a given threshold.With dictionariesΨhandΨl, to reconstruct a HR image Z from a given LR image Y, our proposed SR image reconstruction algorithm (as depicted inFig. 5) is outlined in Algorithm 2.Algorithm 21)Upsample the LR image Y usingYU=UqYPerform multi-scale first- and second-order derivative analysis (i.e., apply the eight 1-D filters defined in (24) to YUto get eight different filtered images {FirYU, r=1,2 and i=1 to 4})Divide YUinto a grid of nonoverlapping patches with size of m×m. For each patch y in the image YU, do•Concatenate the patches of the eight filtered images {FirYU} that correspond to the same location of y to form a patch vectorpYd¯Reduce the dimensionality ofpYd¯viapYd=QpYd¯SubstitutepYdfor y in (18) and solve the optimization problem defined in (19)Generate the HR patch z viaz=Ψhα^Insert patch z into the corresponding location of the HR imageZ∧UpdateZ^usingZ^=Z^+YUUse Algorithm 1 to updateZ^Use (26), find the image Z⁎, which is the closest image toZ^that satisfies the global reconstruction constraint (25)Output Z⁎ as the final result of SR image reconstruction

@&#CONCLUSIONS@&#
