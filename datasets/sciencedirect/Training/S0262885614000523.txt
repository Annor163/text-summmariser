@&#MAIN-TITLE@&#
Iterative Grassmannian optimization for robust image alignment

@&#HIGHLIGHTS@&#
Propose an online algorithm t-GRASTA for the transformed robust PCA problem.Use a union of subspaces to approximate the nonlinear subspace learning process.Demonstrate the fully online mode of t-GRASTA with videos with camera jitter.

@&#KEYPHRASES@&#
Robust subspace learning,Grassmannian optimization,Image alignment,ADMM (alternating direction method of multipliers),

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
With the explosion of image and video capture, both for surveillance and personal enjoyment, and the ease of putting these data online, we are seeing photo databases grow at unprecedented rates. On record we know that in July 2010, Facebook had 100million photo uploads per day [1] and Instagram had a database of 400million photos as of the end of 2011, with 60 uploads per second [2]; since then both of these databases have certainly grown immensely. In 2010, there were an estimated minimum 10,000 surveillance cameras in the city of Chicago and in 2002 an estimated 500,000 in London [3,4].These enormous collections pose both an opportunity and a challenge for image processing and face recognition: The opportunity is that with so much data, it should be possible to assist users in tagging photos, searching the image database, and detecting unusual activity or anomalies. The challenge is that the data are not controlled in any way so as to ensure data quality and consistency across photos, and the massiveness of the data poses a serious computational challenge.In video surveillance, many recently proposed algorithms model the foreground and background separation problem as one of “robust PCA” — decomposing the scene as the sum of a low-rank matrix of background, which represents the global appearance and illumination of the scene, and a sparse matrix of moving foreground objects [5–9]. These popular algorithms and models work very well for a stationary camera. However, in the case of camera jitter, the background is no longer low-rank, and this is problematic for robust PCA methods [10–12]. Robustly and efficiently detecting moving objects from an unstable camera is a challenging problem, since we need to accurately estimate both the background and the transformation of each frame. Fig. 1shows that for a video sequence generated by a simulated unstable camera, GRASTA [13,6] (Grassmannian robust adaptive subspace tracking algorithm) fails to do the separation, but the approach we propose here, t-GRASTA, can successfully separate the background and moving objects despite camera jitter.Further recent work has extended the robust PCA model to that of the “transformed low-rank+sparse” model for face images with occlusions that have come under transformations such as translations and rotations [14–17]. Without the transformations, this can be posed as a convex optimization problem and therefore convex programming methods can be used to tackle such a problem. In RASL [15] (robust alignment by sparse and low-rank decomposition), the authors posed the problem with transformations as well, and though it is no longer convex it can be linearized in each iteration and proven to reach a local minimum.Though the convex programming methods used in [15] are polynomial in the size of the problem, that complexity can still be too demanding for very large databases of images. We propose transformed GRASTA, or t-GRASTA for short, to tackle this optimization with an incremental or online optimization technique. The benefit of this approach is three-fold: First, it will improve speeds of image alignment both in batch mode or in online mode, as we show in Section 3. Second, the memory requirement is small, which makes alignment for very large databases realistic, since t-GRASTA only needs to maintain low-rank subspaces throughout the alignment process. Finally, the proposed online version of t-GRASTA allows for alignment and occlusion removal on images as they are uploaded to the database, which is especially useful in video processing scenarios.The problem of robust image alignment arises regularly in real data, as large illumination variations and gross pixel corruptions or partial occlusions often occur, such as sunglasses or a scarf for a human subject. The classic batch image alignment approaches, such as congealing [18,19] or least squares congealing algorithms [20,21] cannot simultaneously handle such severe conditions, causing the alignment task to fail.With the breakthrough of convex relaxation theory applied to decomposing matrices into a sum of low-rank and sparse matrices [22,5], the recently proposed algorithm “robust alignment by sparse and low-rank decomposition,” or RASL [15], poses the robust image alignment problem as a transformed version of robust PCA. The transformed batch of images can be decomposed as the sum of a low-rank matrix of recovered aligned images and a sparse matrix of errors. RASL seeks the optimal domain transformations while trying to minimize the rank of the matrix of the vectorized and stacked aligned images and while keeping the gross errors sparse. While the rank minimization and ℓ0 minimization can be relaxed to their convex surrogates – minimize the corresponding nuclear norm ∥∥∗ and ℓ1 norm ∥∥1 – the relaxed problem (1) is still highly non-linear due to the complicated domain transformation.(1)minA,E,τA*+λE1s.t.D∘τ=A+EHere, D∈ℝn×Nrepresents the data (n pixels per each of N images), A∈ℝn×Nis the low-rank component, E∈ℝn×Nis the sparse additive component, and τ are the transformations. RASL proposes to tackle this difficult optimization problem by iteratively locally linearizing the non-linear image transformation D∘(τ+Δτ)≈D∘τ+∑i=1nJiΔτiϵiT, where Jiis the Jacobian of image i with respect to transformation i; then in each iteration the linearized problem is convex. The authors have shown that RASL works perfectly well for batch aligning the linearly correlated images despite large illumination variations and occlusions.In order to improve the scalability of robust image alignment for massive image datasets, [23] proposes an efficient ALM-based (augmented Lagrange multiplier-based) iterative convex optimization algorithm ORIA (online robust image alignment) for online alignment of the input images. Though the proposed approach can scale to large image datasets, it requires the subspace of the aligned images as a prior, and for this it uses RASL to train the initial aligned subspace. Once the input images cannot be well aligned by the current subspace, the authors use a heuristic method to update the basis. In contrast, with t-GRASTA we include the subspace in the cost function, and update the subspace using a gradient geodesic step on the Grassmannian, as in [6,24]. We discuss this in more detail in the next Section.Subspace learning has been an area important to signal processing for a few decades. There are many applications in which one must track signal and noise subspaces, from computer vision to communications and radar, and a survey of the related work can be found in [25,26].The GROUSE algorithm, or “Grassmannian rank-one update subspace estimation,” is an online subspace estimation algorithm that can track changing subspaces in the presence of Gaussian noise and missing entries [24]. GROUSE was developed as an online variant of low-rank matrix completion algorithms. It uses incremental gradient methods that have been receiving extensive attention in the optimization community [27]. However, GROUSE is not robust to gross outliers, and the follow-up algorithm GRASTA [13,6], can estimate a changing low-rank subspace as well as identify and subtract outliers. Still problematic is that, as we showed in Fig. 1, even GRASTA cannot handle camera jitter. Our algorithm includes the estimation of transformations in order to align frames first before separating foreground and background.In order to robustly align the set of linearly correlated images despite sparse outliers, we consider the following matrix factorization model (2) where the low-rank matrix U has orthonormal columns that span the low-dimensional subspace of the well-aligned images.(2)minU,W,E,τ∥E∥1s.t.D∘τ=UW+EU∈GdnWe have replaced the variable A with the product of two smaller matrices UW, and the orthonormal columns of U∈ℝn×dspan the low-rank subspace of the images. The set of all subspaces of ℝnof fixed dimension d is called the Grassmannian, which is a compact Riemannian manifold and is denoted byGdn. In this optimization model, U is constrained to the GrassmannianGdn. Though problem (2) cannot be directly solved [15] due to the nonlinearity of image transformation, if the misalignments are not too large, by locally linearly approximating the image transformation D∘(τ+△τ)≈D∘τ+∑i=1NJi△τiϵiT, the iterative model (3) can work well as a practical approach.(3)minUk,W,E,△τ∥E∥1s.t.D∘τk+∑i=1NJik△τiϵiT=UkW+EUk∈GdknAt algorithm iteration k, τk≐[τ1k|,…,|τNk] are the current estimated transformations at iteration k, Jikis the Jacobian of the i-th image with respect to the transformation τik, and {ϵi} denotes the standard basis for ℝn. Note, at different iterations the subspace may have different dimensions, i.e. Ukis constrained on different GrassmannianGdkn.At each iteration of the iterative model (3), we consider this optimization problem as the subspace learning problem. That is, our goal is to robustly estimate the low-dimensional subspace Ukwhich best represents the locally transformed images D∘τk+∑i=1NJikΔτidespite sparse outliers E. In order to solve this subspace learning problem both efficiently with regards to both computation and memory, we propose to learn Ukat each iteration k in model (3) via the online robust subspace learning approach [6].In order to perform online video processing tasks, for example video stabilization, it is desirable to design an efficient approach that can handle image misalignment frame by frame. As in the previous discussion regarding batch mode processing, for each video frame I, we may model the ℓ1 minimization problem as follows:(4)minU,w,e,τ∥e∥1s.t.I∘τ=Uw+eU∈Gdn.Note that with the constraint I∘τ=Uw+e in the above minimization problem, we suppose for each frame the transformed image is well aligned to the low-rank subspace U. However, due to the nonlinear geometric transform I∘τ, directly exploiting online subspace learning techniques [24,6] is not possible.Here we approach this as a manifold learning problem, supposing that the low-dimensional image subspace under nonlinear transformations forms a nonlinear manifold. We propose to learn the manifold approximately using a union of subspaces model Uℓ, ℓ=1,…,L. The basic idea is illustrated in Fig. 2, and the locally linearized model for the nonlinear problem (4) is as follows:(5)minw,e,△τ∥e∥1s.t.I∘τℓ+Jℓ△τ=Uℓw+e.Uℓ∈Gdℓn.Intuitively, from Fig. 2, it is reasonable to think that the initial misaligned image sequence should be high rank; then after iteratively approximating the nonlinear transform with a locally linear approximation, the rank of the new subspaces Uℓ, ℓ=1,…,L, should be decreasing as the images become more and more aligned. Then for each misaligned image I and the unknown transformation τ, we iteratively update the union of subspaces Uℓ, ℓ=1,…,L, and estimate the transformation τ. Details of the online mode of t-GRASTA will be discussed in Section 2.4.2.The use of a union of subspaces Uℓ, ℓ=1,…,L, to approximate the nonlinear manifold is a crucial innovation for this fully online mode. Though we use the symbols Ukand Uℓin both the batch mode and the online mode, they have two different interpretations. For batch mode, Ukis the iteratively learned aligned subspace in each iteration; while for online mode, Uℓ, ℓ=1,…,L, is a collection of subspaces which are used for approximating the nonlinear transform, and they are updated iteratively for each video frame.Whether operating in batch mode or online mode, the key problem is how to quantify the subspace error robustly for the locally linearized problem. Considering batch mode, at iteration k, given the i-th image Ii, its estimate of transformation τik, the Jacobian Jik, and the current estimate of Utk, we use the ℓ1 norm as follows:(6)FStk=minw,△τ∥Utkw−Ii∘τik+Jik△τ∥1.With Utkknown (or estimated, but fixed), this ℓ1 minimization problem is a variation of the least absolute deviations problem, which can be solved efficiently by ADMM (alternating direction method of multipliers) [28]. We rewrite the right hand of Eq. (6) as the equivalent constrained problem by introducing a sparse outlier vector e:(7)minw,e,△τ∥e∥1s.t.Ii∘τik+Jik△τ=Utkw+e.The augmented Lagrangian of problem (7) is(8)LUtk,w,e,△τ,λ=∥e∥1+λThw,e,△τ+μ2∥hw,e,△τ∥22where h(w, e, △τ)=Utkw+e−Ii∘τik−Jik△τ, and λ∈ℝnis the Lagrange multiplier or dual vector.Given the current estimated subspace Utk, transformation parameter τik, and the Jacobian matrix Jikwith respect to the i-th image Ii, the optimal (w∗, e∗, △τ∗, λ∗) can be computed by the ADMM approach as follows:(9)△τp+1=JikJikT−1JikTUtkwp+ep−Ii∘τik+1μλpwp+1=UtkUtkT−1UtkTIi∘τik+Jik△τp+1−ep−1μpλpep+1=S1μIi∘τik+Jik△τp+1−Utkwp+1−1μpλpλp+1=λp+μphwp+1,ep+1,△τp+1μp+1=ρμpwhereS1μis the elementwise soft thresholding operator [29], and ρ>1 is the ADMM penalty constant enforcing {μp} to be a monotonically increasing positive sequence. The iteration (9) indeed converges to the optimal solution of the problem (7)[30]. We summarize this ADMM solver as Algorithm 2 in Section 2.4.Whether identifying the best Uk∗ in the batch mode (3) or estimating the union of subspaces Uℓ, ℓ=1,…,L, in the online mode (5), optimizing the orthonormal matrix U along the geodesic of the Grassmannian is our key technique. For clarity of exposition in this Section, we remove the superscript k or ℓ from U, as the core gradient step along the geodesic of the Grassmannian for both batch mode and online mode is the same. We seek a sequenceUt∈Gdnsuch that Ut→U∗ (as t→∞). We now face the choice of an effective subspace loss function. Regarding U as the variable, the loss function (6) is not differentiable everywhere. Therefore, we choose to instead use the augmented Lagrangian (8) as the subspace loss function once we have estimated (w∗, e∗, △τ∗, λ∗) by ADMM (9) from the previous Ut[13,6].In order to take a gradient step along the geodesic of the Grassmannian, according to [26], we first need to derive the gradient formula of the real-valued loss function (8)L:Gdn→ℝ. The gradient ▽Lcan be determined from the derivative ofLwith respect to the components of U:(10)dLdU=λ∗+μhw∗,e∗,△τ∗w∗T.Then the gradient is▽L=I−UUTdLdU[26]. From Step 6 of Algorithm 1, we have ▽L=maw∗T(see the definition of Γ in Alg. 1). It is easy to verify that ▽Lis rank one since Γ is an n×1 vector and w∗ is a d×1 weight vector. The following derivation of the geodesic gradient step is similar to GROUSE [24] and GRASTA [13,6]. We rewrite the important steps of the derivation here for completeness.The sole non-zero singular value is σ=∥Γ∥∥w∗∥, and the corresponding left and right singular vectors areΓ∥Γ∥andw∗∥w∗∥respectively. Then we can write the SVD of the gradient explicitly by adding the orthonormal set x2,…,xdorthogonal to Γ as left singular vectors and the orthonormal set y2,…,ydorthogonal to w∗ as right singular vectors as follows:∇L=ΓΓx2…xd×diagσ0…0×w*w*y2…ydT.Finally, following Equation (2.65) in [26], a geodesic gradient step of length η in the direction −▽Lis given by(11)Uη=U+cosησ−1Uwt∗∥wt∗∥wt∗T∥wt∗∥−sinησΓ∥Γ∥wt∗T∥wt∗∥.From the discussion of Sections 2.2 and 2.3, given the batch of unaligned images D, their estimate of transformation τkand their Jacobian Jkat iteration k, we can robustly identify the subspace Uk∗ by incrementally updating Utkalong the geodesic of GrassmannianGdkn(11). When Utk→Uk∗ (as t→∞), the estimate of △tauifor each initially aligned image Ii∘τikalso approaches its optimal value △τi∗. Once the subspace Ukis accurately learned, we will update the estimate of the transformation for each image using τik+1=τik+△τi∗. Then in the next iteration, the new subspace Uk+1 can also be learned from D∘τk+1, and the algorithm iterates until we reach the stopping criterion, e.g. if∥△τ∥2∥τk∥2<ϵor we reach the maximum iteration K.We summarize our algorithms as follows. Algorithm 1 is the batch image alignment approach via iterative online robust subspace learning. For Step 7, there are many ways to pick the step-size. For some examples, you may consider the diminishing and constant step-sizes adopted in GROUSE [24], or the multi-level adaptive step-size used for fast convergence in GRASTA [13].Algorithm 2 is the ADMM solver for the locally linearized problem (7). From our extensive experiments, if we set the ADMM penalty parameter ρ=2 and the tolerance ϵtol=10−7, Algorithm 2 has always converged in fewer than 20 iterations.In Section 2.1.2, we propose to tackle the difficult nonlinear online subspace learning problem by iteratively learning online a union of subspaces Uℓ, ℓ=1,…,L. For a sequence of video frames Ii, i=1,…,N, the union of subspaces Uℓare updated iteratively as illustrated in Fig. 3.Specifically, at i-th frame Ii, for the locally approximated subspace Ui1 at the first iteration, given the initial roughly estimated transformation τi0, the ADMM solver Algorithm 2 gives us the locally estimated △τi1, and the updated subspace Ui+11 is obtained by taking a gradient step along the geodesic of the GrassmannianGd1nas discussed in Section 2.3. The transformation ui1 of the next iteration is updated by τi1=τi0+△τi1. Then for the next locally approximated subspace Ui2, we also estimate △τi2 and update the subspace along the geodesic of the GrassmannianGd2nto Ui+12. Repeatedly, we will update Uiℓin the same way to get Ui+1ℓand the new transformation τiℓ=τiℓ−1+△τiℓ. After completing the update for all L subspaces, the union of subspaces Ui+1ℓ(ℓ=1,…,L) will be used for approximating the nonlinear transform of the next video frame Ii+1.We summarize the above statements as Algorithm 3, and we call this approach the fully online mode of t-GRASTA.Algorithm 1Transformed GRASTA — batch modeRequire: An initial n×d0 orthogonal matrices U0. A sequence of unaligned images Iiand the corresponding initial transformation parameters τi0, i=1,…,N. The maximum iteration K.Return: The estimated well-aligned subspace Uk∗ for the well-aligned images. The transformation parameters τikfor each well-aligned image.1:while not converged andk<KdoUpdate the Jacobian matrix of each image:Jik=∂Ii∘ζ∂ζ|ζ=τiki=1…NUpdate the wrapped and normalized images:Ii∘τik=vecIi∘τik∥vecIi∘τik∥2forj=1→N,…,untilconvergeddoEstimate the weight vector wjk, the sparse outliers ejk, the locally linearized transformation parameters △τjk, and the dual vector λjkvia the ADMM Algorithm 2 from Ii∘τik, Jik, and the current estimated subspace Utkwjk,ejk,△τjk,λjk=argminw,e,△τ,λLUtkweλCompute the gradient ▽Las follows:Γ1=λjk+μhwjk,ejk,△τjk,Γ=I−UtkUtkTΓ1,▽L=ΓwjkTCompute step-size ηt.Update subspace:Ut+1k=Utk+cosηtσ−1Utwjk∥wjk∥−sinηtσΓ∥Γ∥wjkT∥wjk∥,whereσ=∥Γ∥∥wjk∥.end forUpdate the transformation parameters:τik+1=τik+△τik,i=1…Nend whileADMM Solver for the locally linearized problem (7)Require: An n×d orthogonal matrix U, a wrapped and normalized image I∘τ∈ℝn, the corresponding Jacobian matrix J, and a structure OPTS which holds four parameters for ADMM: ADMM penalty constant ρ, the tolerance ϵtol, and ADMM maximum iteration K.Return: weight vector w∗∈ℝd; sparse outliers e∗∈ℝn; locally linearized transformation parameters △τ∗; and dual vector λ∗∈ℝn.1:Initialize w, e, Δτ, λ, andμ: e1=0, w1=0, △τ1=0, λ1=0, μ=1Cache P=(UTU)−1UTand F=(JTJ)−1JTfork=1→KdoUpdate △τ:△τk+1=FUwk+ek−I∘τ+1μλkUpdate weights:wk+1=PI∘τ+J△τk+1−ek−1μλkUpdate sparse outliers:ek+1=S1μI∘τ+J△τk+1−Uwk+1−1μλkUpdate dual: λk+1=λk+μh(wk+1, ek+1, △τk+1)Update μ: μ=ρμif ∥h(wk+1, ek+1, △τk+1)∥2≤ϵtolthenConverge and break the loop.end ifend forw∗=wk+1, e∗=ek+1, △τ∗=△τk+1, λ∗=yk+1Transformed GRASTA — fully online modeRequire: The initial L n×dℓorthonormal matrices Uℓspanning the corresponding subspace Sℓ, ℓ=1,…,L. A sequence of unaligned images Iiand the corresponding initial transformation parameters τi0, i=1,…,N.Return: The estimated iteratively approximated subspaces Uiℓ, ℓ=1,…,L, after processing image Ii. The transformation parameters τiLfor each well-aligned image.1:for unaligned image Ii, i=1,…,Ndofor the iterative approximated subspace Uℓ, ℓ=1,…,LdoUpdate the Jacobian matrix of image Ii:Jiℓ=∂Ii∘ζ∂ζ|ζ=τiℓUpdate the wrapped and normalized images:Ii∘τiℓ=vecIi∘τiℓ∥vecIi∘τiℓ∥2Estimate the weight vector wiℓ, the sparse outliers eiℓ, the locally linearized transformation parameters △τiℓ, and the dual vector λiℓvia the ADMM Algorithm 2 from Ii∘τiℓ, Jiℓ, and the current estimated subspace Uiℓwiℓ,eiℓ,△τiℓ,λiℓ=argminw,e,△τ,λLUiℓweλCompute the gradient ▽Las follows:Γ1=λiℓ+μhwiℓ,eiℓ,△τiℓ,Γ=I−UtℓUtℓTΓ1,▽L=ΓwiℓTCompute step-size ηiℓ.Update subspace:Ui+1ℓ=Uiℓ+cosηiℓσ−1Utwiℓ∥wiℓ∥−sinηiℓσΓ∥Γ∥wiℓT∥wiℓ∥,where σ=∥Γ∥∥wiℓ∥.Update the transformation parameters:τiℓ+1=τiℓ+△τiℓend forend forIf the subspace Ukof the well-aligned images is known as a prior, for example if Ukis trained by Algorithm 1 from a “well selected” dataset of one category, we can simply use Ukto align the rest of the unaligned images of the same category. Here “well selected” means that the training dataset should cover enough of the global appearance of the object, such as different illuminations, which can be represented by the low-dimensional subspace structure. By category, we mean a particular object of interest or a particular background scene in the video surveillance data.For massive image processing tasks, it is easy to collect such good training datasets by simply randomly sampling a small fraction of the whole image set. Once Ukis learned from the training set, we can use a variation of Algorithm 1 to align each unaligned image I without updating the subspace, since we have the assumption that the remaining images also lie in the trained subspace. We call Algorithm 4 the trained online mode.However, we note that for a very large streaming dataset such as is typical in real-time video processing, the trained online mode may be less well-defined, as the subspace of the streaming video data may change over time. For this scenario, our fully online mode for t-GRASTA could gradually adapt to the changing subspace and then accurately estimate the transformation τ.We compare the memory usage of our fully online mode of t-GRASTA to that of RASL. RASL requires storage of A, E, a Lagrange multiplier matrix Y, the data D, and D○τ, each of which requires storage of the size nN. To compare fairly to t-GRASTA, which assumes a d-dimensional model, we suppose RASL uses a thin singular value decomposition of size d, which requires nd+Nd+d2 memory elements. Finally for the Jacobian per image, RASL needs nNp, and for τ RASL needs Np, but we will assume that p is a small constant independent of dimension and ignore it. Therefore RASL's total memory usage is 6nN+nd+Nd+d2+N.t-GRASTA must also store the Jacobian, τ, and the data as well as the data with transformation, using memory size 3nN+N. Otherwise, t-GRASTA needs to store the union of subspaces Uℓ, ℓ=1,…,L matrices of size Lnd(L≪N), and the vectors e, λ, Γ, and w for 3n+d memory elements. Thus t-GRASTA's memory total is 3nN+Lnd+3n+d+N.For a problem size of 100 images, each with 100×100pixels, and assuming d=10, L=10, t-GRASTA uses 66.1% of the memory of RASL. For 10,000 mega-pixel images, t-GRASTA uses 50.1% of the memory of RASL. The scaling remains about half throughout mid-range to large problem sizes.Algorithm 4Trained online mode of image alignmentRequire: A well-trained n×d orthogonal matrix U. An unaligned image I and the corresponding initial transformation parameters τ0. The maximum iteration K.Return: The transformation parameters τkfor the well-aligned image.1:while not converged andk<KdoUpdate the Jacobian matrix:Jk=∂I∘ζ∂ζ|ζ=τkUpdate the wrapped and normalized image:I∘τk=vecI∘τk∥vecI∘τk∥2Estimate the weight vector wk, the sparse outliers ek, the locally linearized transformation parameters △τk, and the dual vector λkvia the ADMM Algorithm 2 from I∘τk, Jk, and the well-trained subspace Uwk,ek,△τk,λk=argminw,e,△τ,λℒUweλUpdate the transformation parameters:τk+1=τk+△τkend while

@&#CONCLUSIONS@&#
In this paper we have presented an iterative Grassmannian optimization approach to simultaneously identify an optimal set of image domain transformations for image alignment and the low-rank subspace matching the aligned images. These are such that the vector of each transformed image can be decomposed as the sum of a low-rank part of the recovered aligned image and a sparse part of errors. This approach can be regarded as an extension of GRASTA and RASL: We extend GRASTA to transformations, and extend RASL to the incremental gradient optimization framework. Our approach is faster than RASL and more robust to alignment than GRASTA. We can effectively and computationally efficiently learn the low-rank subspace from misaligned images, which is very practical for computer vision applications.