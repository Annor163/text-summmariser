@&#MAIN-TITLE@&#
Local configuration pattern features for age-related macular degeneration characterization and classification

@&#HIGHLIGHTS@&#
Automated detection of age-related macular degeneration (AMD) using fundus images.Features are extracted using local configuration pattern (LCP) method.Ranked features are subjected to various classifiers.Proposed method classifies two classes with 97.80% accuracy

@&#KEYPHRASES@&#
Retina,Age-related macular degeneration,Fundus imaging,Local configuration pattern,Support vector machine,

@&#ABSTRACT@&#
Age-related Macular Degeneration (AMD) is an irreversible and chronic medical condition characterized by drusen, Choroidal Neovascularization (CNV) and Geographic Atrophy (GA). AMD is one of the major causes of visual loss among elderly people. It is caused by the degeneration of cells in the macula which is responsible for central vision. AMD can be dry or wet type, however dry AMD is most common. It is classified into early, intermediate and late AMD. The early detection and treatment may help one to stop the progression of the disease. Automated AMD diagnosis may reduce the screening time of the clinicians. In this work, we have introduced LCP to characterize normal and AMD classes using fundus images. Linear Configuration Coefficients (CC) and Pattern Occurrence (PO) features are extracted from fundus images. These extracted features are ranked using p-value of the t-test and fed to various supervised classifiers viz. Decision Tree (DT), Nearest Neighbour (k-NN), Naive Bayes (NB), Probabilistic Neural Network (PNN) and Support Vector Machine (SVM) to classify normal and AMD classes. The performance of the system is evaluated using both private (Kasturba Medical Hospital, Manipal, India) and public domain datasets viz. Automated Retinal Image Analysis (ARIA) and STructured Analysis of the Retina (STARE) using ten-fold cross validation. The proposed approach yielded best performance with a highest average accuracy of 97.78%, sensitivity of 98.00% and specificity of 97.50% for STARE dataset using 22 significant features. Hence, this system can be used as an aiding tool to the clinicians during mass eye screening programs to diagnose AMD.

@&#INTRODUCTION@&#
AMD is a multi-factorial ocular disease caused by deterioration of cells in the macula (See Fig. 1b) [1]. It is one of the leading causes of central vision loss [2] in people aged over 50 years [3]. AMD is characterized by drusen, retinal pigmentation, CNV and atrophy of photoreceptors [4]. It has several risk factors viz. age, smoking, hypertension and family history [5–7]. Recent World Health Organization (WHO) report reveals that 8 million people are affected with severe blindness due to AMD [8]. Globally, United Nations (UN) estimates that 20–25 million people are having AMD [9] and this figure may increase to 196 million in 2020 and 288 million in 2040 [10]. According to the presence of clinical features, AMD is mainly classified into three stages viz. early, intermediate and late[1]. They are briefly explained below.(i)Early AMD is characterized by the presence of drusen with a size of≥15μmand<63μmin diameter. Also, it has abnormal lesions viz. hyperpigmentations or hypopigmentations [1,11].Intermediate AMD is graded due to the presence of medium sized i.e.,≥63μmand<125μmdrusen and pigment abnormalities [1,4]. The lesion is present around the macula (not in the centre) [1,11].Late AMD is characterized with GA and CNV. It is categorized into two types viz. dry and wet[1] which are described below:(a)Dry AMD or non-neovascular AMD is characterized by the presence of drusen and GA in the centre of the macula (See Fig. 1b) [1,11]. Almost 90% of the vision loss is caused due to dry AMD [2]. There is no specific treatment method that may reduce the progression of late AMD [12].Wet AMD is also known as neovascular AMD characterized by CNV [5]. Eyes affected with CNV may leak blood (See Fig. 1c) and the leakage is expressed as classic or occult [5]. The leakage can be diagnosed using fluorescein angiography and indocyanine green dyes [5]. Wet AMD is found in 10% of total macular degeneration cases [2]. Neovascular AMD can be treated using thermal laser photo-coagulation [5].AMD can be diagnosed by identifying drusen from the retinal fundus images [13]. Automatic segmentation of drusen and its measurement is needed to automate the diagnostic process [14]. Hence, several authors have proposed AMD detection using automated drusen segmentation [15–27].Brandon et al. [15] proposed multi-level analysis to isolate drusen from the retinal images. Their method obtained correct detection rate of 87.00%. But this method is susceptible to Optic Disc (OD) and blood vessel variations. Sbeh et al. [16] used mathematical morphology to segment bright spots. Shape, contrast and area criterion are used to segregate the drusen from these spots. However, performance measures of their method are not reported. Adaptive Local Thresholding (HALT) operator is used in [17] to segment drusen with vague boundary as well as small drusen and reported a sensitivity of 98.00%. Gaussian derivative filters and k-NN classifier is used in [18] to identify drusen and obtained a sensitivity and a specificity of 77.00% and 88.00% respectively. Their method is not effective to identify all drusen spots. Soliz et al. [19] used Independent Component Analysis (ICA) to detect drusen phenotypes and their method obtained an accuracy of 100% using only 12 fundus images. Amplitude Modulation (AM)–Frequency Modulation (FM) based multi-scale features is used in [20] to identify drusen and reported an Area Under receiver operator characteristics Curve (AUC) of 1. Their method is able to characterize slow varying intensities in the fundus images. Mexican hat wavelet and Support Vector Data Description (SVDD) are used to detect drusen from normal and AMD images. Their method is tested using seven images and reported 100% accuracy [21]. Liang et al. [22] proposed intensity based drusen segmentation approach and reported a sensitivity and specificity of 75.00%. Removal of blood vessel and location of macula are needed in their approach. Multi-resolution locally-adaptive segmentation method is proposed to segment drusen spots. Their method obtained a sensitivity of 95.00% and a specificity of 96.00% by selecting threshold manually [23]. Statistical modelling based drusen segmentation approach is used in [24] and reported an Area Under receiver operator characteristics Curve (AUC) of 0.99 and false positives are removed using post processing. Sobel operator and Gaussian function are used in [25] to segment drusen. Their method obtained a kappa agreement of 0.60. This thresholding method produced a large number of false positives. Optimal filter bank is developed in [26] to differentiate drusen and flecks. Their method obtained an AUC of 0.85. Cheng et al. [27] proposed BIF to detect drusen in the fundus images. Their method used Gabor functions to develop BIF and reported a sensitivity and a specificity of 86.30% and 91.90% respectively. The reported works in the literatures perform only drusen segmentation. They did not extend their method to detect AMD, except in [17,26]. Authors [17,26] segmented the drusen first and then detected the AMD class.Further, inverse anomaly segmentation is proposed in [28] to identify AMD lesions and reported a segmentation accuracy of 90.00%. Case Based Reasoning (CBR) and Dynamic TimeWarping (DTW) methods are proposed in [13] to discriminate normal and AMD classes with a sensitivity of 86.00%. Inverse segmentation using statistical texture features is used in [29] to identify healthy and unhealthy areas from AMD images and reported an accuracy of 92.76% and 96–100% respectively. Spatial histogram and hierarchical image decomposition methods are developed to classify normal and AMD classes [11]. Their techniques obtained an accuracy of 74.00% and 100% using spatial histogram and hierarchical decomposition [11] respectively. Wavelet, GLCM, color, histogram based features and Weighted Frequent Sub-Graph Mining (WFSM) are used in [30] to classify normal and AMD classes. Their method achieved an accuracy of 99.90%. Zheng et al. [31] used tree based hierarchical decomposition and WFSM for automated detection of AMD and reported an accuracy of 99.60%. AM-FM based decomposition and statistical moments and histogram percentiles are used as features in [32] to discriminate Diabetic Retinopathy (DR) and AMD classes. Their method reported an AUC of 0.84 and 0.77 using RIST and UTHSCSA respectively. Texture and DWT based features are used in [14,33] to discriminate normal and AMD classes. Their method yielded an accuracy of 93.70% and 95.07% respectively.Important limitations of the aforementioned methods except [14,33] requires removal of OD, blood vessel and macula detection, before feature extraction. The difference between the reported works in the literature and proposed work in this paper is (a) anomaly and normal anatomy of fundus images such as drusen, OD and blood vessel segmentation are not needed, and (b) this work uses a less number of features to obtain highest performance measures compare to all reported works [11,14,30,33].The proposed work (See Fig. 2) starts with preprocessing using Contrast Limited Adaptive Histogram Equalization CLAHE [34] to enhance the image contrast. Then LCP [35] based features are extracted from normal and AMD classes. Further, the statistical significance of the extracted features are evaluated using t-test. Finally, the selected significant features are ranked and fed to the DT, k-NN, NB, PNN and SVM classifier with various kernel functions. The performance of the classifiers is evaluated using 10-fold cross validation strategy.Dataset description, preprocessing, feature extraction, ranking and selection are explained in Section 2. Various supervised classifiers are discussed briefly in Section 3. Obtained results are reported and presented in Section 4. The advantages and limitations of the proposed method are discussed in Section 5. Finally, the paper concludes in Section 6.Three datasets viz. (i) Private, (ii) ARIA and (iii) STARE are used to evaluate the proposed method. The details of these dataset are briefly described below.Privatedataset: The normal (n=270) and AMD (n=270) fundus images are collected from Ophthalmology Department, Kasturba Medical College, Manipal, India . The images are acquired by the clinicians using Zeiss FF450 plus mydriatic retinal camera with a 50°field of view. Acquired images are stored with 480×364 pixels resolution and a bit rate of 24. Patient׳s consent was taken to use the images for research purpose. Experienced clinicians reviewed and graded the images (See Fig. 3) into normal, Early AMD, Intermediate AMD and Late AMD as per AREDS [36] classification.ARIAdataset: These images are acquired by the clinicians of St Pauls Eye Unit and University of Liverpool, UK using Zeiss FF450+ fundus camera with a 50°field of view. Acquired images are stored with 768×576 pixels resolution and a bit rate of 24. ARIA has 101 normal and 60 AMD images. These images are available in the following link: http://www.eyecharity.com/aria_online.STAREdataset: This dataset has 36 normal and 47 AMD images which are collected from the Shiley Eye Centre at the University of California and the Veterans Administration Medical Centre, USA using TOPCON fundus camera with a 35°field of view. STARE images has a resolution of 700×605 pixels and a bit rate of 24. These images can be accessible in the following link: http://www.ces.clemson.edu/~ahoover/stare.The collected fundus images from three datasets viz. private, ARIA and STARE are subjected to preprocessing to enhance the contrast using CLAHE [34]. It is applied on the green channel of the Red Green Blue (RGB) color fundus image. CLAHE splits the images into different blocks and applies adaptive histogram equalization. Hence, this method stretches color distribution of an image using the most frequent intensity values [34,37], and yields a contrast improved image. In CLAHE two key parameters viz. block size and clip limit are used to tune the contrast of an image [38,39]. However, larger block size and high clip limit increase the noise in the fundus image [38,39]. Hence, in this work we have used a block size of 8×8 and a clip limit of 0.01 to enhance the image contrast [38]. Thus, visible anomalies viz. drusen, CNV and normal structures viz. Optic Disc (OD), blood vessels and macula are enhanced [40].Fundus image of normal and AMD exhibit texture properties due to the presence of drusen, CNV and normal structures. Several methods are proposed to extract texture features from fundus images to detect AMD [14,30], glaucoma [41], Diabetic Macular Edema (DME) [42] and DR [43]. Among various texture measures local texture descriptor viz. LBP is widely used to extract features from medical images, since it has low computational complexity, invariance to rotation and illumination changes [44]. It compares the pixel gray level with its neighbouring pixels and forms a binary pattern [45]. Its limitation is that estimates the intensity information by taking average and variance of neighbouring pixels [35]. Hence, Guo et al. [35] proposed LCP that combines local structural and microscopic configuration information. Local information is extracted using LBP, microscopic configuration provides image configuration and pixel-wise interaction which is named as Microscopic Configuration Modelling (MiC). Block diagram of the LCP feature extraction is shown in Fig. 4.LBP computed using circular symmetric operator (See Fig. 5) which compares centre pixels with its neighbouring pixels using the following equation:(1)LBPP,R=∑p=0P−1s(gp−gc)wheres(x)={1,x≥00,x<0where P and R denote the number of neighbouring pixels and radius of the neighbourhood, respectively (See Fig. 5), p represents neighbouring pixel intensity values, gcis the centre pixel intensity values and s(x) denotes a step function.Rotation invariant LBP (LBPP,Rrin2) is obtained with uniformity measure U and it can be defined as(2)LBPP,Rrin2={∑P=0P−1s(gp−gc),U(LBPP,R≤2)P+1OtherwiseIn this work LBP is computed using various scales (R=2, 3 and 4) and pixel counts (P=8, 10 and 12) [35].MiC is designed to extract microscopic features from fundus images which reflects the texture patterns. Image configuration is modelled by estimating the optimal weights of the neighbouring pixel intensities which helps one to reconstruct central pixel intensity linearly [35]. It is defined by(3)E(w0,…,wP−1)=|gc−∑p=0P−1wpgp|where gpand gcdenote the intensity values of neighbouring pixels and centre pixels, respectively,wp(p=0,…,P−1)are weighting parameters associated with neighbouring pixel gpandE(w0,…,wP−1)denotes the reconstruction error [35]. Reduction of reconstruction error and optimal parameter selections are decided by least square estimation [46]. Optimal parameter WLis computed using the following equation:(4)WL=(VLTVL)−1VLTCLwhere CLis the least square problem and VLis the neighbouring pixel intensities [35].Rotation invariant features are obtained by applying 1D Fourier transform to the optimal parameter WLand can be written as [35](5)HL(k)=∑p=0P−1WL(i)·e−j2πkp/PMagnitude of HLis considered as MiC feature and is defined as [35](6)|HL|=[|HL(0)|;|HL(1)|;…;|HL(P−1)|]|HL|encodes the pixel-wise interaction relationships and local contrast of each pattern produces discriminative information jointly with pattern occurrences of LBP. Thus, LCP provides both microscopic configuration and local shape information [35]. It can be written as(7)LCP=[[|Hp|;Op];[|H1|;O1];…;[|Hl−1|;Ol−1]]where|Hp|is computed using Eq. (6), Oprepresents occurrence of the pth local pattern of interest obtained using LBP and l is the total number of patterns of interest [35].LCP method generates 81, 121 and 169 features for different neighbours P=8, 10 and 12 and radius R=2, 3 and 4 respectively. During LCP computation, use of large neighbours may under-determine the LCP technique during the estimation of reconstruction coefficients [35]. Hence, in this work small neighbours viz. P=8, 10 and 12 and radius R=2, 3 and 4 are chosen to extract LCP features. LCP is implemented using the method available in the following link: http://www.cse.oulu.fi/CMV/Downloads/LBPMatlab.Feature selection discard the non-significant features to improve the classifier performance [47,48]. Initially, the data is evaluated to test for normal distribution using chi-square goodness-of-fit test [49]. The test results reveal that the data is normally distributed. Hence, in this work we have chosen t-test to evaluate statistical significance [49]. It compares the population means between the groups, if the difference is large it rejects the following null hypothesis:Null hypothesis H0: The data between groups has normal distributions with equal means[49].Alternative hypothesis H1: The means of the data are not equal between groups [49].The significant features are ranked using p-value and sequentially fed to the different supervised classifiers to obtain the highest classifier performance.AMD classification is performed using DT, k-NN, NB, PNN and SVM with RBF, linear, quadratic and polynomial kernel functions.DT is a predictive model which derives the decision from the training data [50]. It has three nodes viz. root node, internal nodes and leaf nodes. These nodes split the complex decision into several simpler decision to obtain the final result [50,51]. k-NN classifier is also known as memory-based classification, since the training sample are required during run-time [52]. The unknown samples are classified according to the class of their nearest neighbours by calculating the distance between the neighbours [52]. In this work, we have used k=1 to obtain highest performance. NB is a probabilistic classifier and works on the principle of Bayes theorem [53]. It makes the conditional independence assumption to reduce the learning complexity during classifier modelling. Maximum likelihood estimation is used to estimate the classifier parameters [53]. PNN is a feed forward neural network with four layers viz. input, pattern, summation and output [54]. It classifies patterns using Parzen window probability density function estimator. The compete transfer function of summation layer determines the output [54]. In this work, the sigma (σ) value of the summation layer varied from 0.01 to 1 using bootstrap [55] method to obtain highest classification performance [33]. SVM is a statistical learning approach developed by Vapnik [56]. It uses structural risk minimization principle to construct optimal hyperplane and support vectors for best possible discrimination [53,57] of normal and AMD classes. It can be applied for both linearly separable and non-separable data. However, kernel functions viz. quadratic, polynomial and RBF are used to convert non-separable data into separable one in the high dimensional feature space [53,58]. The RBF kernel width (σ) is varied from 0.01 to 5 using bootstrap method [55] to obtain highest classifier performance [33].

@&#CONCLUSIONS@&#
