@&#MAIN-TITLE@&#
A simple augmented ∊-constraint method for multi-objective mathematical integer programming problems

@&#HIGHLIGHTS@&#
Our new method efficiently generates all non-dominated solutions of multi-objective integer programming problems.A numerical example is presented to illustrate the workings of our method.Our method is compared with two recent state-of-the-art approaches on an extensive set of benchmark problem instances.

@&#KEYPHRASES@&#
Multi-objective programming,∊-Constraint method,AUGMECON method,SAUGMECON method,

@&#ABSTRACT@&#
A simple augmented ∊-constraint (SAUGMECON) method is put forward to generate all non-dominated solutions of multi-objective integer programming (MOIP) problems. The SAUGMECON method is a variant of the augmented ∊-constraint (AUGMECON) method proposed in 2009 and improved in 2013 by Mavrotas et al. However, with the SAUGMECON method, all non-dominated solutions can be found much more efficiently thanks to our innovations to algorithm acceleration. These innovative acceleration mechanisms include: (1) an extension to the acceleration algorithm with early exit and (2) an addition of an acceleration algorithm with bouncing steps. The same numerical example in Lokman and Köksalan (2012) is used to illustrate workings of the method. Then comparisons of computational performance among the method proposed by Özlen and Azizogˇlu (2009), Özlen et al. (2012), the method developed by Lokman and Köksalan (2012) and the SAUGMECON method are made by solving randomly generated general MOIP problem instances as well as special MOIP problem instances such as the MOKP and MOSP problem instances presented in Table 4 in Lokman and Köksalan (2012). The experimental results show that the SAUGMECON method performs the best among these methods. More importantly, the advantage of the SAUGMECON method over the method proposed by Lokman and Köksalan (2012) turns out to be increasingly more prominent as the number of objectives increases.

@&#INTRODUCTION@&#
Since multi-objective optimization problems are ubiquitous in real life, practitioners and researchers are very interested in this area and numerous various approaches to multi-objective optimization problems have been proposed (see e.g. Alves & Clímaco (2009), Branke, Deb, Miettinen, & Słowiński (2008), Chankong & Haimes (2008), Chinchuluun & Pardalos (2007), Clímaco, Ferreira, & Eugénia Captivo (1997), Coello Coello, Lamont, & Van Veldhuizen (2007), Cohon (1978), Collette & Siarry (2003), Deb (2001), Ehrgott (2005), Evans (1984), Figueira, Greco, & Ehrgott (2005), Kaliszewski (2006), Korhonen, Moskowitz, & Wallenius (1992), Liu, Yang, & Whidborne (2003), Miettinen (1999), Pappalardo (2008), Roy & Vincke (1981), Sawaragi, Nakayama, & Tanino (1985), Steuer (1986), Teghem (2009), Zeleny (1982), Zopounidis & Pardalos (2010)). Identifying all non-dominated solutions may be desirable since it maximizes a decision maker’s knowledge about the trade-offs among different objectives for convenience of optimal decision making. Unfortunately, to date we are still unable to generate the entire set of non-dominated solutions in many cases (Abdelaziz, 2007). Studies on multi-objective integer optimization problems, especially on exact methods solving general multi-objective integer programming (MOIP) problems, are still very scarce (Blanco (2011), Ehrgott & Gandibleux (2002), Özlen & Azizogˇlu (2009)). To the best of our knowledge, there are only very few papers on generating all non-dominated solutions to MOIP problems.A method for sequential generation of all non-dominated solutions was proposed by Klein and Hannan (1982) where a series of single objective integer programming models with a sequence of progressively more constraints to eliminate solutions dominated by previously generated non-dominated solutions were solved. On the basis of this method, two variants were put forward by Sylva and Crema (2004, 2007). Instead of optimizing a single objective function, a positive combination of all objective functions was optimized with the first variant (Sylva & Crema, 2004). However, vectors that maximized the infinity-norm distance from the region dominated by previously found non-dominated vectors were generated with the second variant (Sylva & Crema, 2007) for obtaining a well-dispersed set of non-dominated solutions. Unfortunately, as declared by Sylva and Crema (2004, 2007), a complete enumeration of non-dominated solutions was out of the question or expensive in practice because the number of non-dominated solutions is generally very large. Two algorithms which iteratively generate non-dominated solutions in the regions non-dominated by the previously generated non-dominated points were developed by Lokman and Köksalan (2012). The first algorithm developed by Lokman and Köksalan (2012) is a variant of the algorithm proposed by Sylva and Crema (2004) through decreasing the number of additional constraints and binary variables. Still, as mentioned by Lokman and Köksalan (2012), the improved algorithm still required substantial computational efforts as the number of non-dominated solutions increased. Instead of adding additional constraints or binary variables, the second algorithm developed by Lokman and Köksalan (2012) solved a series of models where bounds of objectives were imposed. Again, as declared by Lokman and Köksalan (2012), computational time increased considerably as the problem size and the number of conflicting objectives increased because of a substantial increase of the number of non-dominated solutions. A theoretical approach aiming at determining the set of all non-dominated solutions to multi-objective integer linear programming problems with non-negative integer coefficients was presented by Schweigert and Neumayer (1997). However, it is difficult to implement (Schweigert & Neumayer, 1997; Sylva & Crema, 2004). A general approach for yielding all non-dominated solutions to MOIP problems by solving simpler problems with fewer objectives was put forward by Özlen and Azizogˇlu (2009) and later, by using information of solution process, was improved by Özlen et al. (2013). For more general discussion of MOIP problems, we refer interested readers to Alves and Clímaco (2007), Clímaco et al. (1997), Ehrgott (2006) and Teghem and Kunsch (1986).Another commonly used method for MOIP problems is the ∊-constraint method. The ∊-constraint method, originally presented by Haimes, Lasdon, and Wismer (1971), operates by optimizing one objective and restricting the others with specified values. As is well known, one main drawback of the traditional ∊-constraint method is about production of weak efficient solutions. In order to overcome this drawback, an augmented ∊-constraint (AUGMECON) method by augmenting the objective function with the weighted sum of extra slack variables or surplus variables was brought forth by Mavrotas (2009). This method was improved later in the AUGMECON2 method by introducing a bypass coefficient of the innermost loop which resulted in less subproblems solved (Mavrotas & Florios, 2013). A variant of the AUGMECON method, named as a simple augmented ∊-constraint (SAUGMECON) method, was developed by Zhang and Reimann (2013). However, that research is an interdisciplinary research and mainly focuses on the application of the approach. Thanks to a newly proposed acceleration algorithm with bouncing steps and an innovative extension to the acceleration algorithm with early exit, computational efficiency of generating all non-dominated solutions to MOIP problems has been significantly improved. In this paper, we improve this approach further by utilizing information of solution process in order to avoid solving unnecessary subproblems. Furthermore, we conduct experiments on both general and special MOIP problem instances for deeply exploring computational efficiency of the SAUGMECON method. The results of comparing with two other state-of-the-art approaches show that the SAUGMECON method works the best.The remainder of this paper is organized as follows: the traditional ∊-constraint method and the AUGMECON method are respectively reviewed in Sections 2 and 3. Then the newly proposed SAUGMECON method is presented in detail and a numerical example is given to illustrate workings of this method in Section 4. Thereafter, Section 5 demonstrates computational efficiency of the SAUGMECON method by comparing it with state-of-the-art approaches through solving randomly generated general MOIP problem instances as well as special MOIP problem instances such as the MOKP and MOSP instances presented in Table 4 in Lokman and Köksalan (2012). Finally, we conclude the study in Section 6.A brief review of the traditional ∊-constraint method is presented here. More information on this method can be found in Cohon (1978), Deb (2001) and Ehrgott (2005). Without loss of generality, we consider the following MOIP problem with maximized objectives in this paper:(1)“max”{f1(x),f2(x),…,fp(x)}s.t.x∈S,wherefi(x)is the ith objective function, p is the number of objective functions, S is the solution space, x is the decision vector, n is the number of decision variables andxj∈Zfor allj∈1,2,…,n. A feasible solution x is said to be efficient and the corresponding objective vector is said to be non-dominated, if there is no other feasible solution x′ satisfyingfi(x′)⩾fi(x)for everyi=1,2,…,pwith at least one strict inequality.With the traditional ∊-constraint method, one objective is optimized and the other objectives are added into constraint space for guaranteeing that basic requirements are satisfied. As a result, the aforementioned model can be reestablished as follows:(2)maxfp(x)s.t.f1(x)⩾e1f2(x)⩾e2…fp-1(x)⩾ep-1x∈S,wheree1,e2,…,ep-1is the vector of satisfaction levels which stipulates the minimum requirements on the constrained objectives. Solutions can be obtained by parametrical variations of satisfaction levelse1,e2,…,ep-1in the right side of constraints. However, when these series of models are solved with an optimization software, solutions obtained are usually not efficient (Mavrotas, 2009). In order to circumvent the defect of the traditional ∊-constraint method, the AUGMECON method was put forward by Mavrotas (2009) where efficiency of the obtained solutions was guaranteed.The AUGMECON method transforms inequality constraints of constrained objectives into equality constraints by introducing non-negative slack variables or surplus variables and then augments the objective function with the weighted sum of these slack variables or surplus variables. With this method, the above problem can be reformulated as the following:(3)maxfp(x)+δ(s1/r1+s2/r2+…+sp-1/rp-1)s.t.f1(x)-s1=e1f2(x)-s2=e2…fp-1(x)-sp-1=ep-1x∈Sandsi∈Z+,i∈[1,p-1],where δ is an adequately small number usually between 10−3 and10-6andri,i∈[1,p-1], is the range of the ith objective. It has been proven that the AUGMECON method only generates efficient solutions (Mavrotas, 2009).Through exploiting the information from the slack variables or the surplus variables, an improved version of the AUGMECON method, named as AUGMECON2, was put forward by Mavrotas and Florios (2013). The AUGMECON2 method introduces a bypass coefficient so that the innermost loop-control variable can bounce forward. As a result, the number of subproblems solved with the AUGMECON2 method is reduced.In this section we will put forth our SAUGMECON method mainly aiming at improving computational efficiency of the above-mentioned methods with the following two acceleration mechanisms:•an acceleration algorithm with early exitan acceleration algorithm with bouncing stepsThe SAUGMECON model combines features of the traditional ∊-constraint method and those of the AUGMECON model. As in the traditional ∊-constraint method we use inequalities for the objectives added to the constraint space. On the other hand, similar to the AUGMECON model we incorporate the sum of weighted constrained objectives into the objective function. With the SAUGMECON method, the above model can be rewritten as the following:(4)maxfp(x)+δ(f1(x)/r1+f2(x)/r2+…+fp-1(x)/rp-1)s.t.f1(x)⩾e1f2(x)⩾e2…fp-1(x)⩾ep-1x∈S.Obviously, the models (3) and (4) are the same except that the surplus variablessi,i∈[1,p-1]are not used in the model (4). More importantly, the objective function in the model (4) is more intuitional as the main objective is optimized and the other objectives are made as optimal as possible. Note that constraints about the constrained objectives in the models (2)–(4) must have, or at least can be transformed to have, integer coefficients in order to be able to produce all non-dominated solutions.Similar to other ∊-constraint methods, loop-control variables vary between their corresponding pessimistic nadir values and optimal values. The optimal values of objectives are easily attainable by respectively solving their corresponding single objective optimization problems. Analogously, the pessimistic nadir values can be obtained by individually optimizing the corresponding inverse objectives. The model can be solved with standard LP solvers. The whole SAUGMECON algorithm is illustrated by the flowchart in Fig. 1. We utilize two mechanisms to accelerate the process of searching for all non-dominated solutions.(1)The acceleration algorithm with early exitThe first mechanism is exiting from loops early when the problem becomes infeasible. This algorithm was first proposed by Mavrotas (2009). In order to implement this acceleration algorithm, the constrained objectives must start with the less restricted values and gradually move to the more restricted values. That is to say,e1,e2,…andep-1must start at their corresponding pessimistic nadir values and move towards their corresponding optimal values. Once the problem becomes infeasible, it is meaningless to continue the innermost loop in that the problem is undoubtedly infeasible when constraints are further tightened. Therefore, the algorithm should exit from the innermost loop and proceed with the next waiting grid point in the nearest outer loop.Our SAUGMECON method utilizes and extends this approach in the following way. When several successive inner loop-control variables, including the innermost loop-control variable, reach their corresponding pessimistic nadir values and the SAUGMECON model is infeasible, it is obvious that the SAUGMECON model is still infeasible when the loop-control variable in the outer loop nearest to these inner loop-control variables moves from a less restricted value to a more restricted value. Thus the algorithm should also exit from the outer loop nearest to these nested inner loops. Fig. 2delineates the process of exiting from loops at length when the SAUGMECON model is infeasible.The acceleration algorithm with bouncing stepsOur innovative addition to algorithm acceleration is implementing bouncing steps in loops. It is easy to see that in the situation of feasibility the optimal solution will keep unchanged when a loop-control variable moves from its current value to the relatively worst value of its associated objective. Note that the relatively worst value here means the worst value of the associated objective obtained when its corresponding loop-control variable’s successive inner loop-control variables, including the innermost loop-control variable, move from their corresponding pessimistic nadir values to their corresponding optimal values. Based on this principle, loop-control variables can bounce forward. Specifically, the innermost loop-control variable directly moves to the value of the associated objective from which it is subsequently increased to search for new non-dominated solutions. Similarly, any other loop-control variable directly moves to the next grid point near to the relatively worst value of its associated objective where the algorithm continues to search for new non-dominated solutions. The detailed process of bouncing loop-control variables forward is described in Fig. 1 while the process of exploring the new relatively worst values of objectives is illustrated in Fig. 3. Note that in Fig. 1ef1is the innermost loop-control variable andefp-1is the outermost loop-control variable. After a feasible subproblem is solved, the innermost loop-control variableef1is set to bef1∗. As a result, a same subproblem except for the constraint off1⩾f1∗+1will be solved ifef1has not reached its maximal value, or the algorithm will exit from the innermost loop ifef1has reached its maximal value. In the latter situation,ef1is set to bef1min-1which prepares for the new iteration of the innermost loop. Then a new subproblem with constraints off2⩾f2rwv+1andf1⩾f1minis solved ifef2has not reached its maximal value after it is reset with the relatively worst value off2, i.e.f2rwv. Otherwise, ifef2has reached its maximal value, no matter whether before resetting withf2rwvor after resetting withf2rwv, the algorithm will exit from the second inner loop. In other words, the algorithm will exit from the loop which is controlled by the loop-control variableef2. Analogously, other loops can be executed.Thanks to the above two innovative acceleration mechanisms, computational efficiency can be significantly improved. Generally, we have the following theorem:Theorem 1Compared with the AUGMECON method, the SAUGMECON method solves less or at MOST the same number of single objective optimization models without missing any non-dominated solutions.The proof can be found in Appendix A. Obviously, the above-mentioned innovative extension and addition to algorithm acceleration can also be applied to both the traditional ∊-constraint method and the AUGMECON method. Furthermore, as mentioned by Mavrotas and Florios (2013), the true nadir points of the Pareto set must be known when the AUGMECON2 method is used to generate the exact Pareto set. As is well known, it is not easy to meet this requirement in reality. Of course, one may also argue to use an estimated lower bounds (or higher bounds for minimization MOIP problems) of true nadir values instead of the true nadir values. However, the further the estimated lower bounds (or higher bounds for minimization MOIP problems) are to the corresponding true nadir values, the more computational efforts are needed with the AUGMECON2 method. Obviously, this is not the case for the SAUGMECON method and as a result the pessimistic nadir values obtained by inversely optimizing single objectives individually can be used. In other words, the computational efforts with the true nadir values and the computational efforts with the pessimistic nadir values are the same.In addition to the two aforesaid acceleration mechanisms, another possible improvement is exploiting information of solution process to avoid solving unnecessary subproblems. The following two lemmas show the principle of the improvement. Since both results are very straightforward, we omit the proofs.Lemma 1Suppose subproblem 1 is a relaxation of subproblem2 and the optimal solution of subproblem1 is also feasible for subproblem2. Then the optimal solution of subproblem 1 is also an optimal solution of subproblem 2.Suppose subproblem1 is a relaxation of subproblem2 and subproblem1 is infeasible. Obviously, subproblem2 is infeasible.Fig. 4illustrates the process of exploiting solution-process information in detail. Specifically, before solving a model, the algorithm will search information of solution process to decide whether it is necessary to solve the model. If necessary, the model is solved and information of the model is recorded. We will not explain the other parts of this figure since they are similar to those at the bottom of Fig. 1.In this section we illustrate the workings of our SAUGMECON method with the following example which is the same as that used by Lokman and Köksalan (2012) for convenience of comparing computational performance:(5)“max”{Px}s.t.Wx⩽qx∈{0,1}10,whereP=546446373162523387355265586346667295422956903413713366748871W=525228239569136132688898492843985352846657308650979659946714q=[246329325]Tx=[x1x2x3x4x5x6x7x8x9x10]TSimilarly, in this paperf3, as the main objective, is optimized whilef1andf2are added to the constraint space as constrained objectives. By maximizingf1andf2individually the optimal value off1and that off2are 286 and 353 respectively. Both the pessimistic nadir value off1and that off2are 0 whenf1andf2are minimized respectively. Details of the solution process of the SAUGMECON method are presented in Table 1.As mentioned before, both loop-control variablesef2andef1start with their corresponding pessimistic nadir values. So the subproblem with constraints off2⩾0andf1⩾0is solved first and its non-dominated solution isf1=256,f2=294and f3=336. Because f1=256, the subproblem with constraints off2⩾0andf1⩾257is then solved according to the acceleration algorithm with bouncing steps. For the same reason, the subproblem with constraints off2⩾0andf1⩾274and the subproblem with constraints off2⩾0andf1⩾276are solved in sequence. After that, the algorithm exits from the innermost loop because f1=286 which is the maximal value of f1. The relatively worst value of f2 obtained by solving the series of subproblems with the constraint off2⩾0is 271, the minimum among 294, 337, 271 and 300. As a result, the subproblem with constraints off2⩾272andf1⩾0is the next one to be solved. Finally, with the SAUGMECON method without information of solution process, a total of 23 subproblems are solved to obtain 8 non-dominated solutions.Furthermore, it is plain to see that the subproblem with constraints off2⩾0andf1⩾0is a relaxation of the subproblem with constraints off2⩾272andf1⩾0and the optimal solution of the former,f1=256andf2=294, satisfies constraints of the latter. As a result, the subproblem with constraints off2⩾272andf1⩾0can be ignored according to Lemma 1. Obviously, there are a total of seven feasible subproblems that can be ignored when information of solution process is utilized. Moreover, the subproblem with constraints off2⩾301andf1⩾274is a relaxation of the subproblem with constraints off2⩾320andf1⩾274. Since the former is infeasible, on the basis of Lemma 2 the latter is also infeasible without doubt. Eventually 8 subproblems can be omitted and 15 subproblems are solved in total with the SAUGMECON method with information of solution process.Compared with the method proposed by Lokman and Köksalan (2012), thereafter named as the L–K method, where a total of 45 subproblems are solved without utilizing information of solution process while a total of 18 subproblems are solved with utilizing information of solution process, the SAUGMECON method has improved computational efficiency by 48.9% when information of solution process is not utilized and by 16.7% when information of solution process is utilized. Here the ratio of efficiency improvement is defined as the ratio of the difference between the number of subproblems solved with the L–K method and the number of subproblems solved with the SAUGMECON method to the number of subproblems solved with the L–K method.We further investigate computational performance of the SAUGMECON method deeply by performing experiments on randomly generated general MOIP problem instances as well as special MOIP problem instances. It can be obviously observed from Özlen and Azizogˇlu (2009), Özlen and Burton (2011), Özlen et al. (2013), Lokman and Köksalan (2012) as well as the SAUGMECON model established in Section 4.1 that for each problem instance all of the three methods solve the same scale of subproblems. That is to say, they solve the models with the same constraints including original problem constraints as well as constraints specifying satisfaction levels of constrained objectives. So the average number of integer programming problems (IPs) solved per non-dominated solution is employed as an ideal criterion for performance comparisons. Note that, besides susceptibility to some random factors, computational time is very sensitive to computer configuration and parameter settings of an optimization solver. Therefore, we ignore comparisons of computational time among these three methods. The algorithms are coded using Visual Studio Express 2012 for Windows Desktop and CPLEX 12.5 is used as an optimization solver. All experiments are performed on an Intel (R) Pentium Core (TM) i5-2520M CPU @ 2.50Gigahertz computer with 4.00Gigabyte RAM running Windows 8.In this section, we explore computational performance of the SAUGMECON method for randomly generated general MOIP problems by comparing it with the L–K method with and without information of solution process, with the method proposed by Özlen and Azizogˇlu (2009) (hereinafter referred to as the Ö–A method) and with the method put forward by Özlen et al. (2013) (therefore, called the Ö–B–M method), respectively. Note that, as mentioned above, the difference between the Ö–A method and the Ö–B–M method is that information of solution process is utilized in the latter but not in the former. Similar to the setting of experiments in Özlen and Burton (2011), in order to examine effects of various factors in problem design, we do experiments on randomly generated tri-objective and four-objective integer programming problem instances. For both classes of instances we run experiments with three different sizes such as 10 columns×5 rows, 25 columns×7 rows and 50 columns×10 rows. Further, variable coefficients are drawn from two different kinds of uniform distributions, specifically U[1,10] and U[1,20]. As the size of MOIP problems increases, time spent in generating all non-dominated solutions will go up because of increased time needed to solve each integer programming problem. Especially, the total time goes up sharply for the L–K method without information of solution process when the number of non-dominated solutions also rises. As a result, the solution process of MOIP problems with the L–K method without information of solution process turns out to be extremely time-consuming. So we only solve small-sized general MOIP problems. Fortunately, as it is seen from Lokman and Köksalan (2012), Özlen and Burton (2011) and the following experimental results, it does not affect analysis of computational performances very much because the average number of IPs solved in order to identify each non-dominated solution is not very sensitive to the problem size but substantially rises with increasing number of objectives. For each setting 30 problem instances are randomly generated and finally a total of 360 problem instances are solved for studying computational performances of these three methods.A summary of the experimental results is presented in Table 2. For each setting columns 4–9 list in sequence the average of the average number of IPs solved per non-dominated solution for 30 randomly generated problem instances with the L–K method without and with information of solution process, with the Ö–A method without information of solution process, with the Ö–B–M method with information of solution process, and with the SAUGMECON method without and with information of solution process, respectively. The last four columns illustrate the average of performance improvement ratio in terms of the average number of IPs solved per non-dominated solution for 30 randomly generated problem instances by respectively comparing the SAUGMECON method with the other two methods without information of solution process as well as with information of solution process. The performance improvement ratio, when the SAUGMECON method is compared with the L–K/Ö–A/Ö–B–M method, is defined as the ratio of the difference between the average number of IPs solved per non-dominated solution with the L–K/Ö–A/Ö–B–M method and the average number of IPs solved per non-dominated solution with the SAUGMECON method to the average number of IPs solved per non-dominated solution with the L–K/Ö–A/Ö–B–M method. Similar to the conclusion drawn by Özlen and Burton (2011) and Lokman and Köksalan (2012), Table 2 also indicates that the average number of IPs solved per non-dominated solution is generally not very sensitive to the problem size but very sensitive to the number of objectives. Furthermore, by utilizing information of solution process, the number of IPs solved per non-dominated solution is enormously cut down. More importantly, the SAUGMECON method outperforms the other two methods no matter whether information of solution process is utilized or not. Details of the results can be obtained from the authors upon request.In order to obtain robust information about performance comparisons between the SAUGMECON method and the other two methods, a non-parametric statistical test such as two-related-samples Wilcoxon Signed Ranks test is carried out on 30 randomly generated problem instances for each setting between the L–K method and the SAUGMECON method with and without information of solution process, between the Ö–A method and the SAUGMECON method without information of solution process, between the Ö–B–M method and the SAUGMECON method with information of solution process. The results of Wilcoxon Signed Ranks tests are reported in Table 3.We observe from Table 3 that the sig. values of the tests are almost zero. This means that we should reject the null hypothesis indicating that there are no differences between two compared methods. Therefore, the SAUGMECON method performs significantly better than its competing methods. Specifically, it solves fewer IPs than its competitors for 178 out of the 180 tri-objective problem instances and each of the 180 four-objective problem instances tested. More importantly, the advantage turns out to be more and more prominent with the increase of the number of objectives.In this section, we continue to explore computational performance of the SAUGMECON method with information of solution process for special MOIP problems by respectively comparing it with the L–K method and with the Ö–B–M method. For convenience of comparing computational performance, we perform numerical experiments on the same three and four objective knapsack problems and shortest path problems presented by Lokman and Köksalan (2012). Specifically, we carry out the following numerical experiments: three-objective knapsack problems with 25 items, 50 items as well as 100 items; four-objective knapsack problems with 25 items; three-objective shortest path problems with 25 nodes, 50 nodes, 100 nodes, 150 nodes as well as 200 nodes; and four-objective shortest path problems with 25 nodes as well as 50 nodes. For each setting 5 problem instances are solved in total. The concrete problems and their corresponding non-dominated solutions given by Lokman and Köksalan (2012) are available at: http://www.ie.metu.edu.tr/personalpages/murat/files.html.Table 4illustrates performance improvement ratio of the SAUGMECON method in terms of the average number of IPs solved per non-dominated solution by respectively comparing the SAUGMECON method with the L–K method and with the Ö–B–M method. Again, the SAUGMECON method is identified as the best method of the three methods because it solves the fewest number of IPs among these three methods. It is worth noting the statistically significant superiority of our SAUGMECON approach which outperforms all of the competing approaches on each kind of the special MOIP problems. Furthermore, the larger the number of objectives is, the more the computational performance of the SAUGMECON method, compared with the L–K method, improves. Concretely, we see a 12.09% average performance improvement ratio for the special three-objective integer programming problem instances and a 44.76% average performance improvement ratio for the special four-objective integer programming problem instances. The advantage of the SAUGMECON method over the L–K method for the special four-objective integer programming problem instances is much more obvious than that for the general four-objective integer programming problem instances. Detailed summaries of computational performances of the SAUGMECON method and the Ö–B–M method can be obtained from the authors upon request.Both the computational experiment on general MOIP problems and the computational experiment on special MOIP problems show that the SAUGMECON method performs the best among the three methods. This is expected for the following reasons:(1)Comparison between the L–K method and the SAUGMECON methodAs is well known, the number of non-dominated solutions increases considerably with the number of objectives. From the solution procedure of the L–K method, it is not difficult to see that the number of IPs solved in order to obtain a new non-dominated solution goes up rapidly with the number of non-dominated solutions already obtained. As a result, the total number of IPs solved in order to obtain all non-dominated solutions grows significantly. However, this is not the case, not very obvious at least, for the SAUGMECON method by observing its solution process. Since the number of IPs solved per non-dominated solution sharply increases with the number of objectives, the improvement of computational performance with the SAUGMECON method turns out to be much more remarkable.Comparison between the Ö–A/Ö–B–M method and the SAUGMECON methodThere is no doubt that the SAUGMECON method is better than the Ö–B–M method (the Ö–A method) in the scenario of using (not using) information of solution process and the advantages are very obvious: first, the SAUGMECON algorithm will exit from loops whenever loop-control variables touch their corresponding optimal-value boundaries while the Ö–A/Ö–B–M algorithm, as seen from its solution procedure, does not exit from loops until the problem is infeasible where the loop-control variables may exceed their corresponding optimal-value boundaries. For example, in the numerical example presented by Özlen and Azizogˇlu (2009), the minimum of f2 is 128. However, the Ö–A algorithm still solves the integer programming problem with the constraint ofl2⩽127. Of course, the problem is infeasible. Second, when several consecutive inner loop-control variables, including the innermost loop-control variable, touch their corresponding nadir values and the integer programming problem is infeasible, the SAUGMECON algorithm will exit from the outer loop which is nearest to these inner loops. However, this improvement is not included in the Ö–A/Ö–B–M algorithm.

@&#CONCLUSIONS@&#
