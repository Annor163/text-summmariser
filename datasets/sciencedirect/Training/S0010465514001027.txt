@&#MAIN-TITLE@&#
GPU-based simulation of the long-range Potts model via parallel tempering

@&#HIGHLIGHTS@&#
Simulation of the Potts model with long-range interactions on GPUs.Parallel tempering algorithm implemented on graphical processing units using CUDA.Shared memory implementation.GPU accelerated approach provides performance speedups of up to 35.

@&#KEYPHRASES@&#
Potts model,Long-range interactions,Parallel tempering,GPU computing,CUDA,

@&#ABSTRACT@&#
We discuss the efficiency of parallelization on graphical processing units (GPUs) for the simulation of the one-dimensional Potts model with long-range interactions via parallel tempering. We investigate the behavior of some thermodynamic properties, such as equilibrium energy and magnetization, critical temperatures as well as the separation between the first- and second-order regimes. By implementing multispin coding techniques and an efficient parallelization of the interaction energy computation among threads, the GPU-accelerated approach reached speedup factors of up to 37.

@&#INTRODUCTION@&#
Increased computing capabilities over the last years have changed substantially the landscape of scientific computing. High performance graphical processing units (GPUs) have become an important part of computational clusters. High level programming languages, e.g. CUDA or OpenCL, have unlocked the computational power of GPUs and made it accessible to scientists.Particularly the implementation of Monte Carlo simulations on GPUs can lead to increased performance due to the fact that the majority of these algorithms can be parallelized. Regrading spin systems the studies published in scientific journals were focused especially on systems with nearest neighbor interactions  [1,2].Macromolecules exhibiting long-range interactions have been simulated already on GPUs using molecular dynamics  [3] and the smooth particle mesh Ewald summation method  [4]. In the present paper we simulate the one-dimensional Potts model with long-range interactions decaying as1/r1+σusing a parallel tempering algorithm implemented on GPUs. It is known from both classical  [5] and nonextensive statistics  [6] that the Potts model has a very rich thermodynamic behavior.The paper is structured as follows. In the first part we review some theoretical aspects regarding the Potts model and the parallel tempering algorithm. Section  4 deals with the implementation details in CUDA. In Section  5 we present the principal results and benchmarks comparing the performance of the code with traditional CPU implementation. Finally in Section  6 we draw some conclusions and final remarks.The main result of this paper is the possibility of a good speedup on GPU for spin models with long-range interactions. By exploiting the shared memory architecture of the GPU and using an efficient multispin coding scheme for the Metropolis step and the energy computation we were able to obtain a speedup factor of 37 compared with CPU implementations.The standard Potts model is a straightforward generalization of the well-known Ising model. The one-dimensionalq-state Potts model is a lattice where the spinssican take the following values:(1)si=1,2,…,q.The interaction Hamiltonian is given by the relation:(2)H=−∑i,ji≠jJijδ(si,sj)whereJijis a coupling constant andδ(si,sj)is the Kronecker delta:(3)δ(si,sj)={1ifsi=sj0ifsi≠sj.If we consider the long-range model, we must take into account the interactions between all spin pairs. The interaction is decaying with distance as1/r1+σ(rbeing the distance between spinsiandj), so the coupling constant has the form [7](4)Jij=1|i−j|1+σ.For simulation purposes one usually resort to periodic boundary conditions. This can be approached by considering the interactions between all the spins in the original lattice of sizeLand replacing the coupling constantsJijwith(5)J∗(r)=∑n=−∞∞J(r+nL).This lead to the following expression for the coupling constants:(6)J∗(r)=1r1+σ+1L1+σ[ζ(1+σ,1+rL)+ζ(1+σ,1−rL)]whereζ(s,α)is the Hurwitz zeta function [8].(7)ζ(s,α)=∑k=0∞(k+α)−s.The short-range Potts model undergoes a first-order phase transition whenq>qcand a second-order phase transition whenq<qc, where the threshold valueqcdepends on the dimensionality of the latticed(i.e.qc=4ford=2). The long-range Potts model exhibits an interesting behavior: there is a so-called tricritical point atσc, depending on the value ofq. Forσ<σcwe have a first-order transition, whereas forσ>σcthe transition is continuous.Parallel tempering (a.k.a. replica exchange) is an algorithm which has been proposed to accelerate Monte Carlo simulations in systems with complex energy landscapes  [9,10].In this method we simulate in parallel multiple copies of the system, at different temperatures. For this stage we use the single spin-flip technique, based on the standard Metropolis algorithm, where the flips are accepted with probability(8)p=min(1,e−βΔE)whereΔErepresents the energy difference between the states. In the above relationβ=1/kBT(Tdenotes the temperature andkBstands for the Boltzmann constant).After a certain number of Monte Carlo steps we attempt to exchange the states between neighboring temperatures, based on the Metropolis criterion with probability(9)p=min(1,e(Ei−Ej)(βi−βj))whereEiandEjare the energies of the neighboring states,βi=1/kBTiandβj=1/kBTj.Parallel tempering is a powerful computational method, which is suitable for implementations on GPUs because different replicas can be run in parallel.CUDA brings a new approach to parallel computing. It uses the Graphical Processing Unit (GPU) for scientific computing. The computing power of GPUs has increased rapidly in the last years and today they are faster than the CPU if we exploit their massively parallel nature.From the software point of view CUDA is an extension of the C language, as well as a runtime library, which facilitates the general-purpose programming of NVIDIA GPUs. The parallel computation is organized using the abstractions of grids, blocks and threads. An entire grid is handled by a single GPU chip. Each multiprocessor on the GPU handles one or more blocks in a grid. Each multiprocessor is divided into a number of stream processors, each of them handling one or more threads in a block  [11,12].Threads may only safely communicate with each other only if they are in the same thread block. The fastest communication between threads is done using shared memory. Shared memory is limited, usually 16 kB per multiprocessor on GT200-based chips or 48 kB on Fermi cards  [13]. Often shared memory is simply not enough to store all the data that needs to be shared among the threads. In these cases we need to access global memory. Any thread in any block can read or write to any location in the global memory. Global memory is much larger than shared memory; however it is much slower.

@&#CONCLUSIONS@&#
