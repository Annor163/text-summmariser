@&#MAIN-TITLE@&#
Multi-Kernel Appearance Model

@&#HIGHLIGHTS@&#
Multi-Kernel Appearance Model is a new facial point detector.Multi-Kernel SVM combines multi-resolution features.A SVM cascade combines increasingly complex kernels to reduce the computational time.A shape model fitting introduces constraints between SVM detections.

@&#KEYPHRASES@&#
Facial feature localization,Multiple-kernel learning,Two-stage classifiers,SIFT descriptor,Deformable model alignment,Gauss–Newton optimization,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Automatic salient point localization is a fundamental building block in many computer vision-based applications. In facial analysis, these salient points (e.g., eye and mouth corners, nose and chin tips) are called fiducial points or landmarks. Their appearance and spatial arrangement are important for most facial analysis tasks, including face recognition, expression recognition or face animation. In human spontaneous behavior analysis, facial landmark configurations are indicative of deformations caused by expressions. Whatever the application, automatic facial landmarking is the second step (after face detection) of a larger face processing task.Many methods have been introduced over the last decade to solve this problem. Locating facial landmarks remains challenging for applications that must operate under a wide range of conditions, including illumination variations, occlusions, poses or expressions. In general, related methods use two types of information, both essential. One is facial landmark appearance, also called texture information. The other is the spatial relationship among different facial landmarks, also called shape information. By looking at the latter and the degree of spatial constraint it introduces during the search, we can consider three main streams.First, we consider methods that independently detect each facial feature point using any shape information. [50] detects 20 facial points using the GentleBoost classifier trained on Gabor magnitude images. The lack of constraint in such frameworks may often lead to senseless localizations and badly damage the system robustness.The second category proceeds to a joint detection of all points. Here, the spatial relation between points is not directly formulated: the classifier implicitly learns the constraints [12,20,40]. These methods suffer from overly strong relations between points and are limited to some common assumptions, e.g., a nearly frontal view face and moderate facial expression changes, and tend to fail under large pose variations or facial deformations in real-world applications.Finally, we consider methods that explicitly formulate constraints between points using different processes. Some methods independently detect each point and apply spatial restrictions on their locations using graph-based methods [15,46,27,54]. In a recent work, [37] first detects each landmark using multi-scale gray-level features and multi-kernel Support Vector Machines. A time-consuming combinatory process is tasked with finding the optimal point constellation according to its likelihood. This category also includes fitting-based methods, usually called Parameterized Appearance Models (PAMs), widely used in face analysis. They align a previously learned model within a new face image. The main component of these approaches is the statistical model. It is characterized by parameters that describe the possible model configurations in position, pose, shape and texture. During the fitting process, PAMs try to find correspondences between the model and an image containing the face by minimizing a cost function w.r.t these parameters. Among these approaches, we find Active Appearance Models (AAM) and Active Shape Models (ASM), introduced by [4,7] and more recently the Constrained Local Models (CLM) introduced by [9]. For computational time issues, these methods are generally based on simple features, derived from gray levels, and use some simple similarity measures during the fitting process. This strategy can lead to ambiguities: several image areas may be similar to the searched point, making the optimization function non-convex. In consequence, these systems may be prone to local minima and strongly dependent on the initialization step.In this paper, we propose the Multi-Kernel Appearance Model (MuKAM), a novel and efficient approach that tries to overcome PAM weaknesses without damaging the computational time. MuKAM employs a two-stage classifier designed to achieve fast and efficient detections. The first stage is based on low-level features and a fast linear kernel. It aims to select a subset of candidates without excluding the right location. The second stage employs higher level features and a non-linear kernel to estimate the candidate likelihoods. These two-stage present two main advantages: during the training step, the bootstrap process provides relevant samples to train the second stage, and the detector can quickly estimate the likelihood of each candidate pixel during the evaluation step. Moreover, we improve system robustness by introducing constraints between points. To introduce these constraints, we propose an alignment process step relying on a deformable model fitting: according to the sparse response maps obtained at the end of the second stage, we want to find the set of parameters that best fit the model on the face. This parameter optimization is performed using an iterative Gauss Newton process applied to a cost function especially designed for our problem. As the optimization employs sparse response maps, the optimal solution is found after a few iterations.The proposed approach is based on three main contributions: (i) an accurate point detector based on multiple scale features and multiple kernel learning algorithms, (ii) a fast and well suited two-stage classifier involving increasingly complex kernels and (iii) a robust system relying on a deformable model fitting strategy.The remainder of this paper is organized as follows. In Section 2, we briefly review the literature. In Section 3, we provide an overview of the proposed method. In Section 4, we describe the detector and detail the two-stage training process. In Section 5, we present the objective function and optimization process. In Section 6, we present an extensive evaluation of different key aspects of our method. Finally, Section 7 presents our closing remarks.

@&#CONCLUSIONS@&#
