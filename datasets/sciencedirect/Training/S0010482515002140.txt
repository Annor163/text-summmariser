@&#MAIN-TITLE@&#
Topology adaptive vessel network skeleton extraction with novel medialness measuring function

@&#HIGHLIGHTS@&#
A robust, topology adaptive tree-like structure skeleton extraction framework is proposed.A novel medialness measuring function is proposed to reduce the adjacent interferences.A wave propagation procedure is built to identify important topological nodes.The extracted curve skeletons are modeled by active contour models.

@&#KEYPHRASES@&#
Skeleton extraction,Topology adaptive,Vessel images,Curvilinear networks,Medialness measuring function,

@&#ABSTRACT@&#
Vessel tree skeleton extraction is widely applied in vascular structure segmentation, however, conventional approaches often suffer from the adjacent interferences and poor topological adaptability. To avoid these problems, a robust, topology adaptive tree-like structure skeleton extraction framework is proposed in this paper. Specifically, to avoid the adjacent interferences, a local message passing procedure called Gaussian affinity voting (GAV) is proposed to realize adaptive scale-growing of vessel voxels. Then the medialness measuring function (MMF) based on GAV, namely GAV–MMF, is constructed to extract medialness patterns robustly. In order to improve topological adaptability, a level-set graph embedded with GAV–MMF is employed to build initial curve skeletons without any user interaction. Furthermore, the GAV–MMF is embedded in stretching open active contours (SOAC) to drive the initial curves to the expected location, maintaining smoothness and continuity. In addition, to provide an accurate and smooth final skeleton tree topology, topological checks and skeleton network reconfiguration is proposed. The continuity and scalability of this method is validated experimentally on synthetic and clinical images for multi-scale vessels. Experimental results show that the proposed method achieves acceptable topological adaptability for skeleton extraction of vessel trees.

@&#INTRODUCTION@&#
Vessel stenosis is a common vascular pathological change, characterized by the clinical feature of the narrowing or blockage along the vessel path, eventually leading to insufficient blood supply or abnormal deformation. As the demands increase, it becomes more essential to provide an accurate and robust measurement of vascular morphology in the analysis of vascular lesion. However, the geometrical complexity is a major determinant of the computational analysis failure. Manual lumen segmentation and stenosis quantification are laborious and often suffer from inter- and intra-rate variabilities, in respond of this challenge, much research has been devoted to automatic and semi-automatic [1]. Without loss of generality, the curve skeleton is a subset of the object, consisting only of the union of curves, symmetrically placed within the object and characterized by the same topology as the original object [2]. The extracted skeleton not only represents a set of essential geometrical parameters for clinical purposes, but also serves in subsequent computations such as shape representation, pathological analysis of vascular network [3]. As a result, the quantitative approach of vessel shape abnormalities based on skeleton extraction and local width estimation achieves satisfactory results [4].In recent years, various skeletonization algorithms and implementations have been proposed in the literature. Research on a selection of representative methods can be broadly classified into five groups: distance transform [2,5], topology preserving thinning [6], path tracking based on the minimal path [7] or ridge computation [8] and curve tracing [9,10].Most methods based on distance transform use the Manhattan metric instead of the Euclidean metric to guarantee low complexity [11]. However, these methods are highly sensitive to the boundary noise, consequently small errors in the object boundary can drastically change the derived skeleton and yield spurious skeleton branches [12,13].The parallel thinning algorithms proposed by Palágyi and Ma were widely used [14]. The accuracy of the result was reliable through a ‘thinning’ process like peeling onions. However, all algorithms involve a large amount of template matching operations, which are inappropriate for medical application due to the unacceptable computation cost. Though some fast variants based on Look-Up Table (LUT) were proposed, these improvements only made positive effects in processing binary templates and hardly accelerated three-color templates matching [15].Most methods based on path tracking employ an iterative scheme where the intermediate computation determines the next search direction [16]. Some researchers trend to develop a directional growth strategy along the search path, which is designed based on local properties, such as the spatial continuity of vessel׳s centerline points, curvature, diameter, and intensity [3,17]. However, most tracking algorithms are considered to have low robustness due to indetermined image noise disturbance on edge. Furthermore, these approaches often depend on many parameters and increase the complexity due to the estimation of the next direction vector, which makes them more prone to failure especially for strongly curved structures, bifurcations or vessel with shape abnormalities [18].The methods based on curve tracing often involve three main steps: initialization, curve construction and curve optimization. Yan [19] used a fuzzy C-means (FCM) clustering procedure to locate cluster centers as initial key skeleton points and employed relational graph analysis to build initial active curve. Finally, it produced the final smooth curve by a modified snake model, which incorporated a FCM-based medialness energy term [19]. Similarly, Spuhler and Harders proposed a skeleton extraction method using a scattered-snakelet approach [20], and Xu proposed another one using stretching open active contour [10]. Though, these methods have acceptable skeleton extraction accuracy and elegant topological adaptability, the problems of massive calculation cost for curve constructing, overlap checks and network reconfiguration are obvious.To summarize, existing curve skeleton extraction techniques suffer from at least one of the following limitations: (1) they require manual interaction to select the starting point of each curve skeleton; (2) they have poor topological adaptability for complex vessel network; (3) in order to guide the extraction process, they require huge performance consumption to locate and classify skeletal junction nodes, which is not a trivial task and (4) finally, they are sensitive to boundary noise and adjacent interferences.Considering the limitations above, the adjacent interferences and poor topological adaptability deteriorate the result of skeleton tree extraction seriously. To address these drawbacks, a robust, topology adaptive tree-like structure skeleton extraction framework is proposed to the segmented images. Firstly, the novel medialness measuring function, which is called GAV–MMF, is constructed based on Gaussian affinity voting to locate skeleton points precisely. The procedure can be considered as an adaptive scale-growing scheme, which can avoid usage of inappropriate scale settings as shown in Section 3.1. The GAV–MMF has superior performance on the adjacent interferences suppression, compared to other convolutional MMFs as discussed in Section 4.2.1; Secondly, during the construction of initial curve skeleton, the level-set map (LSM) and level-set graph (LSG) are built to identify important topological nodes and link relationship between them to improve topological adaptability; Thirdly, each skeleton is modeled as an active curve by stretching open active contour to meet the conditions of smoothness and medialness (Section 3.3). Some topological checks and skeleton tree reconfiguration are proposed to address the problems of spurious branches and artificial corners. Finally, the improvements of our proposed method are discussed in Section 4.The rest of the manuscript is organized as follows. In Section 2, it starts with a general description of the proposed vessel skeleton extraction framework, and then provides exquisite motivation analysis in further sections. In Section 3, the proposed method gives details about the performed validation and experiments to evaluate robustness and accuracy of skeleton extraction framework in synthetic and clinical images. Some implementation issues and those complexity are discussed in Section 4. Finally, we draw some conclusions in Section 5.

@&#CONCLUSIONS@&#
