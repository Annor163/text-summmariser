@&#MAIN-TITLE@&#
Optimization of decentralized random field estimation networks under communication constraints through Monte Carlo methods

@&#HIGHLIGHTS@&#
We propose a new methodology for designing decentralized random field estimation strategies for sensor networks.We take the trade-off between the estimation accuracy and the cost of communications into account.A multi-objective Bayesian risk is used and feasible strategies are constrained by the communication link topology.Our solution is a message-passing algorithm based on a team decision theoretic approach and Monte Carlo methods.We demonstrate graceful degradation of the estimation accuracy as the communication becomes more costly.

@&#KEYPHRASES@&#
Decentralized estimation,Communication constrained inference,Random fields,Message passing algorithms,Monte Carlo methods,Wireless sensor networks,

@&#ABSTRACT@&#
We propose a new methodology for designing decentralized random field estimation schemes that takes the tradeoff between the estimation accuracy and the cost of communications into account. We consider a sensor network in which nodes perform bandwidth limited two-way communications with other nodes located in a certain range. The in-network processing starts with each node measuring its local variable and sending messages to its immediate neighbors followed by evaluating its local estimation rule based on the received messages and measurements. Local rule design for this two-stage strategy can be cast as a constrained optimization problem with a Bayesian risk capturing the cost of transmissions and penalty for the estimation errors. A similar problem has been previously studied for decentralized detection. We adopt that framework for estimation, however, the corresponding optimization schemes involve integral operators that are impossible to evaluate exactly, in general. We employ an approximation framework using Monte Carlo methods and obtain an optimization procedure based on particle representations and approximate computations. The procedure operates in a message-passing fashion and generates results for any distributions if samples can be produced from, e.g., the marginals. We demonstrate graceful degradation of the estimation accuracy as communication becomes more costly.

@&#INTRODUCTION@&#
Wireless sensor networks have been a promising technology for deploying a large number of sensor platforms over a region to gather dense spatial samples of a physical phenomenon [1]. Applications including environmental monitoring, structural monitoring [2] and precision agriculture [3] benefit from wirelessly networking these platforms in an ad-hoc fashion which can also collect measurements in possibly multiple modes induced by multiple quantities of interest. There are challenges in design because the sensor platforms have limited computational and energy resources and the links over which they can communicate are bandwidth (BW) limited. The dispersed nature of the system necessitates some communications for processing the measurements, however, the energy cost of transmitting bits is usually greater than that for computing them [4]. Therefore, it is crucial for the feasibility of a sensor network to take the estimation–communication trade-offs into account while performing collaborative “online” (or, in-network) processing of the measurements in the network [5].In this context, we are concerned with designing decentralized processing schemes for random field estimation under a set of communication constraints. In the network structure we consider, the platforms perform local communication with their neighbors located within a certain range and form a connected ad-hoc network with BW limited links. We are particularly interested in the tradeoff between the estimation accuracy and the cost of transmissions given the link topology. Transmission costs might include the energy cost of communications through, e.g., an energy dissipation model for transmitting and receiving k bits at a distance of d meters [6].Subject to estimation is a set of spatial random variables that exhibit a correlation structure. Examples of physical phenomena that can be modeled with such random fields include turbulent flow (Chp. 12 of [7]) and geostatistical data [8] such as temperature measurements over a field (Chp. 1 of [9]). There is a variety of lines of investigation on random field estimation with sensor networks. In-network processing schemes based on adaptive hierarchies (e.g., [10]), a designated fusion center (FC) receiving quantized measurements (e.g., [11]), and iterations involving FC feedback [12] have been considered. These treatments cannot pose an in-network strategy design problem that explicitly takes the tradeoffs into account and are not decentralized in that not all of the nodes contribute to the estimation task but only one or more FCs. Estimation of dynamic random fields through Kalman–Bucy filtering (KBF) is considered in [13] and [14]. In particular, [14] introduces a distributed realization of the KBF, whereas [13] considers an FC that collects measurements from sensors after finding a reduced model whereby a subset of the sensors are queried based on a surrogate communication costs and an estimation penalty. Our problem setting differs in that we are concerned with completely decentralized strategies and, on a static problem, consider the trade-off between the estimation accuracy and the communication load of the network.Decentralized estimation in sensor networks has also been studied using probabilistic graphical models (see, e.g., [15] and the references therein). In this approach, a probabilistic dependency graph of the random field is mapped onto the communication topology. The in-network processing strategy then becomes a message passing algorithm which communicates probability distributions. However, model approximations together with message coding and censoring to facilitate low-energy digital transmissions complicate the performance analysis [16]. As a result, it is not straightforward to state a design problem that takes the network topology and the communication cost into account using this perspective [17].We consider a class of in-network processing strategies which operate over an undirected communication topology and yield a rigorous communication constrained design problem through a tractable Bayesian risk. In particular, the platforms specify the vertex set and the undirected edges represent bi-directional communication links with finite alphabets sizes of which are related to the BWs. The nodes estimate a (set of) random variable(s) possibly related to a random field model based on the platform locations through a two-stage procedure: In the first stage, each node makes a measurement and produces messages to its neighbors using its communication rule. In the second stage nodes estimate their associated random variable(s), based on both the incoming messages and their measurements. The design problem involves finding the communication and estimation rules for the nodes and it is in the form of a constrained optimization problem in which the objective function is a Bayesian risk that penalizes both estimation errors and the transmissions, and the feasible set of strategies is constrained by the corresponding graph representation that captures the availability and the capacity of the links.A similar problem has been recently studied in the context of decentralized detection[18] based upon the results for another class of strategies – those over directed acyclic graphs (DAGs) (see also [19]). One appealing feature of this approach is that the solution to the design problem can be realized as a message passing algorithm which fits well into the distributed system requirements of a sensor network. We have considered the design of decentralized estimation strategies over DAGs in [20], and introduced an approximation framework through Monte Carlo (MC) methods in order to overcome the difficulties arising from the fact that the variables of concern take values from nondenumerable sets in the estimation case. This paper differs from recent work taking a similar distributed inference perspective in that we consider estimation problems (rather than detection problems as in [18,19,21]) over undirected graphs (UGs) (rather than DAGs as in [20]).The contribution of this paper is an adoption of the aforementioned approximation framework for the class of (decentralized) two-stage estimation strategies over UGs which we believe is a good match for random field estimation scenarios. Doing that, we transform a Team Decision Theoretic (TDT) iterative strategy optimization to a computationally feasible MC optimization algorithm which employs nonparametric representations of the underlying distributions. We also maintain the benefits of the TDT solution and, as a result, our approach features the following: First, this framework enables us to consider a broad range of communication and computation structures for the design of decentralized estimation networks. Second, in the case that a dual objective is selected as a weighted-sum of the estimation performance and the cost of communications, a graceful degradation of the estimation accuracy is achieved as communication becomes more costly. The resulting pareto-optimal curve enables a quantification of the tradeoff of concern. Under reasonable assumptions, the optimization procedure scales with the number of platforms as well as the number of variables involved. Moreover, it can be realized as a message passing algorithm which is an appropriate computational structure for network self-organization. The MC optimization scheme we propose features scalability with the cardinality of the sample sets required and can produce results for any set of distributions provided that independent samples can be generated from, e.g., the marginals.In Section 2, we introduce the design problem in a constrained optimization setting, and then we describe the Team Decision Theoretic investigation of its solution in Section 3. We present our MC optimization framework for two-stage in-network processing strategies over UGs in Section 4. Then, we demonstrate the aforementioned features through several examples in Section 5.22The preliminary results of the proposed scheme appear in [22].Finally, we provide concluding remarks in Section 6.In this section, we start introducing the problem setting with some basic definitions. Then, in Section 2.1 we present the two-stage in-network processing scheme over an undirected communication topology. In Section 2.2, we state the strategy design problem as a constrained optimization problem taking into account the communication constraints. This problem is to be solved offline, i.e., before processing the observations.We consider N sensor platforms dispersed over a region. Each node can establish communication links with some of the other nodes within its communication range. These links are bi-directional and the communications structure can be represented by an undirected graphG=(V,E)in which each platform is associated with a nodev∈V. An edge(i,j)∈Ecorresponds to a finite capacity one-way link from platform i to j. The bi-directionality is captured by using a UG representation in which(i,j)∈E⇔(j,i)∈E. A particular example of such a network can be seen in Fig. 5(a) in Section 5.3.On the edge(i,j), node i transmits a symbolui→jfrom the set of admissible symbolsUi→j. For example, in order to model a link with capacitylog2⁡dijbits, one can selectUi→jsuch that|Ui→j|=dij. In order to represent the “no transmission” event in censoring or selective communication schemes, one can insert an additional symbol intoUi→jsuch as 0. We note that, as both(i,j)and(j,i)∈E, the variablesuj→iandui→jare symbols in opposite directions over the same link.Associated with each sensor platform is a set of variables modeling, e.g., the temperature, humidity, or the flow vector at possibly the position of the platform. Let us denote a concatenation of variables associated with node j byXjand the set it takes values from byXj. In principle, there is no restriction on the dimensionality ofXj, i.e.,dim⁡(Xj)≥1. All random variables to be estimated can be represented with a concatenationX=(X1,X2,...,XN)which takes values fromX=X1×X2×...×XN. For example, for real valued random variables,Xj=RandX=RN. It is worth reminding that, in the detection setting,Xjs areM<∞element sets for M-ary detection.Node j collects measurementsYjusing its onboard sensors.Yj∈YjwhereYjis nondenumerable, as well. All observations collected by the network is denoted byY=(Y1,Y2,...,YN)and resides inY=Y1×Y2×...×YN.The probabilistic model underlying the estimation problem is represented by the random variable pair(X,Y). It is characterized by the joint cumulative distribution functionPX,Y(x,y)with the densitypX,Y(x,y)for a realization(x,y)=(x1,...,xN,y1,...,yN).Suppose we are given a UG communication topologyG=(V,E). The neighbors of node j is given byne(j)≜{i|(i,j)∈E∧(j,i)∈E}. Let us denote the set of outgoing messages from node j to its neighbors byu→j≜{uj→i|i∈ne(j)}. Then,u→jtakes values fromU→j=⨂i∈ne(j)Uj→iwhere ⊗ denotes consecutive Cartesian products.33In other words, e.g.,X=X1×X2×X3andX=⨂i∈{1,2,3}Xiare synonymous.Being at the receiving end of the links from its neighbors, node j collects the incoming messages denoted byu←j≜{ui→j|i∈ne(j)}and take values fromU←j=⨂i∈ne(j)Ui→j. The messages across the network are similarly given byu≜{ui→j|(i,j)∈E}and reside inU≜⨂(i,j)∈EUi→j.At this point, it is worthwhile to point out that we implicitly assume the links inGare error free so that the symbols transmitted (or lack thereof) from neighbors are exactly restored at the receiving end. This is for the sake of simplicity throughout the article and it is indeed possible to accommodate an unreliable channel model capturing link errors and packet losses possibly due to noise and interference in this network model [18].44In particular, [18] introduces an additional variablezjas the channel output to node j. This variable can be treated as a function of the messages sent from the neighborsne(j)and characterised by a conditional distributionp(zj|u←j). Examples in which this distribution is specified for modeling binary erasure channels and broadcast channels with interference can be found in [19].We continue our discussion by specifying a two-stage operation that ensures a causal online processing without deadlocks: In the first stage, having observedyj∈Yj, node j evaluates its local communication rule defined byμj:Yj→U→jand produces outgoing messages to its neighbors.55Note that a variety of transmission schemes can be represented byμjsuch as “broadcast” and “peer-to-peer”. In order to model the former,U→jcan be replaced with its subset which contains identical messages for all neighbors. Our setting falls into the peer-to-peer type communication in this perspective.After receiving all the messages from its neighbors, node j performs the second stage in which it evaluates its estimation rule given byνj:Yj×U←j→Xjto draw an inference on the valueXjtakes based on the observationyjand the incoming messagesu←jfrom neighboring nodes. Hence, the local rule of node j is a pair given byγj=(μj,νj). The objective of designingγjis the topic of Section 2.2.Based on the previous definitions, the space of all first-stage (communication) rules is defined asMjG≜{μj|μj:Yj→U→j}and the second-stage (estimation) rule space is given byNjG≜{νj|νj:Yj×U←j→Xj}. Consequently, the space of rules local to node j is given byΓjG≜MjG×NjG. The process from node j's point of view is illustrated in Fig. 1(a).We define strategies over the entire network by aggregating local rules: A first-stage communication and second-stage estimation strategy pairγ=(μ,ν)is defined asμ=(μ1,μ2,...,μN)andν=(ν1,ν2,...,νN), respectively. We refer toγ=(γ1,γ2,...,γN)as a two-stage strategy. The space of two-stage strategies overGis given byΓG=⨂v∈VΓvG. It can be seen thatΓG={γ|γ:Y→X×U}. Here,γ∈ΓGis restricted to the strategies which produceu∈Uin accordance with the networkG. Consider the set of strategiesγ:Y→X×Uwhich do not take u into account. For example, the centralized estimator which operates over the joint posterior is such a strategy. If we denote the set of u unrestricted strategies by Γ, then,ΓG⊂Γ. The global view of the strategy is illustrated in Fig. 1(b).The networked constrained online processing model above provides an abstraction of the subtleties related to the physical, network and other lower layers of the communication architecture. There has been a considerable amount of work on networking sensors including connectivity control [23], Medium Access Control [24] and multi-hop routing protocols enabling transmission between any two nodes (see, e.g., [23,25,26]). Therefore, a higher level architecture underpinning the two-stage strategy can be designed using an adequate combination of these results in consideration of the application specific requirements [27,28]. For the cases that the transmission errors and packet losses cannot be ignored, channel models characterizing these possibilities can be used in the online model as discussed previously.Given an arbitrary UGG, the selection of a two-stage strategy fromΓGis based on a Bayesian risk functionJ(γ)whereγ=(μ,ν)∈ΓG, is constructed as follows: One can select a cost c such that an estimation error penalty for the pair(x,xˆ)and a cost due to the corresponding set of messages in the network u are assigned, i.e.,c:U×X×X→R. For an arbitrary strategyγ∈ΓG, the corresponding Bayesian risk is given by(1)J(γ)≜E{c(U,X,Xˆ);γ}=E{E{c(μ(Y),X,ν(Y,μ(Y)))|Y}}.Selection of the best two-stage strategy for estimation under communication constraints is, hence, equivalent to solving the constrained optimization problem given by(2)(P):min⁡J(γ)subject toγ∈ΓGThe distribution underlying the expectation in (1) is specified by γ through the densityp(u,xˆ|y;γ)and the equation(3)p(u,xˆ,x;γ)=∫Ydyp(u,xˆ|y;γ)p(y,x),which can be shown after realizing that the tuple(U,Xˆ)=γ(Y)is a random vector conditionally independent of X given Y (denoted by(U,Xˆ)⫫X|Y) provided thatγ=(γ1,...,γN)∈ΓGis known. Then, the densityp(u,xˆ|y)is specified by γ and denoted byp(u,xˆ|y;γ).Let us consider how local communication and computation rules take part in this density: Once the local rule pairγj=(μj,νj)is fixed, the conditional density of the outcomesp(u→j,xˆj|yj,u←j;γj)becomes specified. By the two stage mechanism, this density decomposes further asp(u→j,xˆj|yj,u←j;γj)=p(u→j|yj;μj)p(xˆj|yj,u←j;νj).The distributionp(u,xˆ|y;γ), then, builds upon the local rule pairs following the causal processing provided by γ and the following factorization holds:(4)p(u,xˆ|y;γ)=∏j∈Vp(u→j|yj;μj)p(xˆj|yj,u←j;νj).In Problem (P), it can be shown that if there exists an optimal strategy, then there exists an optimal deterministic strategy [29]. Therefore it suffices to consider the deterministic local rule spaces for which case the local first and second stage rules specify the densities involved in Eq. (4) as follows:(5)p(u→j|yj;μj)=δμj(yj)(u→j)(6)p(xˆj|yj,u←j;νj)=δ(xˆj−νj(yj,u←j))whereδm(n)is the Kronecker delta and δ is the Dirac delta distribution. After substituting Eqs. (5) and (6) into Eq. (4) and Eq. (3), the distribution underlying the Bayesian risk is specified.We provide a table of symbols introduced in this section in Table 1for helping the reader throughout the rest of the article.Problem (P) in (2) is a typical team decision problem [30]. It is often not possible to find solutions with global optimality guarantees (see, e.g., [29]). A convenient solution approach which has been used in a variety of similar contexts including quantizer design for minimum distortion [31,32] and distributed estimation [33,34] is to use necessary (but not sufficient) conditions of optimality to achieve nonlinear Gauss–Seidel iterations converging to a person-by-person (pbp) optimal strategy [29,18]: At the pbp optimal pointγ⁎∈ΓG, it holds thatJ(γj⁎,γ∖j⁎)≤J(γj,γ∖j⁎)for allγj∈ΓjGwhere ∖j denotesV∖jandγ∖j⁎={γ1⁎,γ2⁎,...,γj−1⁎,γj+1⁎,...,γN⁎}.66When it is clear from the context, we denote{xi|i∈I}byxIwhere I is an index set for the collection of variables{x1,x2,...,xN}.In other words, no improvement toJ(γ⁎)can be obtained by varying only a single local ruleγj⁎. The strategies that satisfy this equilibrium condition are solutions to a relaxation of (P) in which one is interested in findingγ⁎=(γ1⁎,...,γn⁎)such that(7)γj⁎=arg⁡minγj∈Γj⁡J(γj,γ∖j⁎)for allj∈{1,2,...,N}. The strategyγ⁎is referred to as a pbp optimal strategy. The iterations given by Algorithm 1converge to such a solution starting with an arbitrary set of local rules.It is useful to note that the converged strategy depends on the initialization, in general. Therefore, it is a good practice to start the iterations with a reasonable selection of initial rules and use Algorithm 1 to improve upon them. For the example scenarios presented in Section 5, the iterative approach delivers a consistent performance with different initializations.For the detection problem, an extensive study of pbp optimal solutions for a number of strategy classes can be found in [18]. One of these classes exhibits directed acyclic communication and computation structures and can equivalently be represented by DAGs [19]. It has been shown that in the case of two-stage strategies over undirected communication topologies, pbp optimal set of local rules lie in a finitely parameterized subspace ofΓG, and hence errors involved in their computation is mainly due to finite machine precision. This is partly becauseXjs of a detection problem, contrary to the estimation setting, take values from finite sets. The communication and computation structure of a two-stage strategy can equivalently be represented through a bipartite graph (Chp. 4 of [18]). Such graphs are directed and acyclic structures and, hence, two-stage rules can be investigated using the results for the detection problem over a DAG (provided that certain assumptions hold).In our estimation setting over an undirected graph, we follow a similar approach and exploit the pbp optimality condition for decentralized estimation strategies over DAGs [20].77In principle, it is possible to obtain the estimation results presented in this section starting from the detection results in [18] and performing the marginalizations in the variablesXjs andXˆjs through appropriate integrations (as opposed to summations) under error-free and “peer-to-peer” transmission assumptions. In part becauseXjs are nondenumerable, our problem, contrary to the detection setting, does not lead to pbp optimal local rules that can be characterized with a finite set of parameters, in general.,88In the case of a dynamic problem in whichp(x)varies over time, the strategies can be updated accordingly. Investigation of efficient methods for updating strategies in dynamic problems is left beyond the scope of this work.We start by unwrapping the communication and computation structure of two-stage strategies over undirected communication topologies onto directed acyclic bipartite graphs. The two-stage operation enables us to represent the same platform with two nodes of different types. The nodes of the bipartite graphB=((V,V′),F)are identified by considering the set of nodes in the undirected graphG, i.e.,V, and its replicateV′≜{j′|j∈V}as a pair and assigning the communication rules and the estimation rules toVandV′, respectively. The edges of the bipartite graph connect communication nodes inVto the estimation rules of the neighbor nodes inV′. In other words,(j,i′)∈Fifi∈ne(j)inG. For example, consider the undirected communication topology given in Fig. 2(a). The two-stage strategy over this UG is explicitly shown in Fig. 2(b). The unwrapped directed acyclic communication and computation structure of the two-stage strategy which is a bipartite graph is shown in Fig. 2(c). Nodes 1–4 inVperform only the communication rules, i.e.,μjs. Likewise, nodes1′–4′inV′are associated only with the estimation rules, i.e.,νjs. Node j andj′correspond to the same physical platform but different processing tasks, in this respect.At this point, it is useful to contrast the two-stage strategy design problem with that for an FC estimator in a star-topology [33]. In the conventional setting, the design goal is to find an estimation rule for the FC and quantizers for the peripheral sensors which minimize the expected cost of estimation errors. The FC receives messages from all of the other sensors, however, communication is not penalized. The two-stage strategy we consider decentralizes the estimation task in a way that each node can be viewed as a local FC with its neighbors as peripherals (e.g., the estimation nodes1′–4′in Fig. 2(c) can be viewed as FCs of their local networks) and the communication rules are not restricted to quantizers. These star networks are coupled in the two-stage strategy design as all the estimation and communication rules that constitute the strategy are considered jointly through the cost functionc(xˆ,x,u).Next, we make a set of assumptions:Assumption 1The global cost function is the sum of costs due to the communication rules and the decision rules, which are in turn additive over the nodes:(8)c(u,xˆ,x)=cd(xˆ,x)+λcc(u,x)cd(xˆ,x)=∑i∈Vcid(xˆi,xi)cc(u,x)=∑i∈Vcic(u→i,x)Here, λ appears as a unit conversion constant and can be interpreted as the equivalent estimation penalty per unit communication cost [18]. HenceJ(γ)=Jd(γ)+λJc(γ)whereJd(γ)=E{cd(xˆ,x);γ}andJc(γ)=E{cc(u,x);γ}respectively.99Note that convex combinations of dual objectives, i.e.,J′(γ)=αJd(γ)+(1−α)Jc(γ), yield pareto-optimal curves parameterized by α. This setting preserves the pareto-optimal front sinceλ=(1−α)/αandJ(γ)∝J′(γ)yielding a graceful degradation of the estimation performance as λ is increased.Assumption 2Conditional independenceThe noise processes of the sensors are mutually independent and hence given the state of X, the observations are conditionally independent, i.e.,p(x,y)=p(x)∏i=1Np(yi|x).Assumption 3Measurement localityEvery node j observesyjdue to onlyxj, i.e.,p(yj|x)=p(yj|xj).Under these conditions, it is possible to apply Corollary 3.4 in [20], which reveals the structure of the pbp optimal local communication and estimation rules in strategies over DAGs, to the bipartite representation of the two-stage strategies. Before stating this result, let us define two-step neighbors of j byne2(j)≜⋃i∈ne(j)ne(i)∖j.Proposition 3.1Adaptation of Proposition 4.3 in [18] for estimationSuppose thatAssumptions 1–3hold and suppose we are given a pbp optimal two-stage strategyγ⁎=(γ1⁎,...,γN⁎)over an undirected graph. If all the local rules other than the jth are fixed at the optimum point, the jth optimal rule can be characterized as follows: The communication rule (evaluated at stage-one) is given by(9)μj⁎(yj)=argminu→j∈U→j⁡∫Xjdxjp(yj|xj)αj(u→j,xj;νne(j)⁎,μne2(j)⁎)for allyj∈Yjwith nonzero probability, where(10)αj(u→j,xj;νne(j)⁎,μne2(j)⁎)∝p(xj)[λcjc(u→j,xj)+Cj(u→j,xj;νne(j)⁎,μne2(j)⁎)].The estimation rule (evaluated at stage-two) is given by(11)νj⁎(yj,u←j)=argminxˆj∈Xj⁡∫Xjdxjp(yj|xj)βj(xj,xˆj,u←j;μne(j)⁎)for allyj∈Yjand for allu←j∈U←jwith nonzero probability where(12)βj(xj,xˆj,u←j;μne(j)⁎)∝p(xj)Pj(u←j|xj;μne(j)⁎)cjd(xˆj,xj).The termPj(u←j|xj;μne(j)⁎)in Eq.(12)is the (incoming) message likelihood and given by(13)Pj(u←j|xj;μne(j)⁎)=∫Xne(j)dxne(j)p(xne(j)|xj)∏i∈ne(j)Pi→j(ui→j|xi;μne(j)⁎)with terms capturing the influence ofi∈ne(j)on j given by(14)Pi→j(ui→j|xi;μi⁎)=∑u→i\ui→jp(u→i|xi;μi⁎)for allui→j∈Ui→jwhere(15)p(u→i|xi;μi⁎)=∫Yidyip(yi|xi)p(u→i|yi;μi⁎).The termCj(u→j,xj;νne(j)⁎,μne2(j)⁎)in Eq.(10)is the total expected cost and given by(16)Cj(u→j,xj;νne(j)⁎,μne2(j)⁎)=∑i∈ne(j)Ci→j(uj→i,xj;νi⁎,μne(i)⁎)for allu→j∈U→jwith terms capturing the influence of j oni∈ne(j)given by(17)Ci→j(uj→i,xj;νi⁎,μne(i)⁎)=∫Xne(i)\jdxne(i)\j∫Xidxip(xne(i)\j,xi|xj)∑une(i)\j∏j′∈ne(i)\jPj′→i(uj′→i|xj′;μj′⁎)Ii(u←i,xi;νi⁎)such that(18)Ii(u←i,xi;νi⁎)=∫Yidyi∫Xidxˆicid(xˆi,xi)p(xˆi|yi,u←i;νi⁎)p(yi|xi).As discussed at the beginning of this section, two-stage strategies over undirected graphs can equivalently be represented by strategies over DAGs. Under Assumptions 1–2, Corollary 3.4 in [20] is valid over the bipartite directed acyclic model associated with the two-stage strategies over the undirected graphG. Consider the bipartite DAGB=((V,V′),F)associated with the undirected graphG. Proposition 3.1 is obtained after applying Corollary 3.4 in [20] onBand then refolding it back toGby substituting j for allj′∈V′.  □Proposition 3.1 provides a variational characterization of the jth communication and estimation rules, given a pbp optimal two-stage strategy.1010The integrals overXjandYjshould be interpreted in accordance with the dimensionality of their domains.Let us use a simpler notation for the terms on the left hand side (LHS) of Eqs. (13) and (16) and denote them byPj(u←j|xj)andCj(u→j,xj), respectively. Considering Eqs. (13) and (14),Pj(u←j|xj)is a likelihood function forxjinducingu←j. Eqs. (16)–(18) reveal thatCj(u→j,xj)is the total expected cost induced on the neighbors by transmittingu→j, i.e.,E{cd(xˆne(j),xne(j))|u→j,xj;νne(j)⁎,μne2(j)⁎}. Sincep(xj)p(yj|xj)×P(u←j|xj)∝p(xj|yj,u←j)holds under Assumptions 2–3, the jth optimal communication rule selects the message that results with a minimum contribution to the overall cost and the optimal estimation rule selectsxˆjthat yields the minimum expected penalty givenyjandu←j. For example, ifcjd(xˆj,xj)=(xˆj−xj)2as in the conventional mean squared error (MSE) estimator, then the estimation rule in Eq. (11) can be expressed in closed form as(19)xˆj=νj⁎(yj,u←j)=∫Xjdxjxjp(xj)p(yj|xj)Pj(u←j|xj)∫Xjdxjp(xj)p(yj|xj)Pj(u←j|xj).SincePj(u←j|xj)=p(u←j|xj;μne(j)⁎)is the likelihood of the incoming messages and the conditional independence relationU←j⫫Yj|Xjholds, thenp(xj,yj,u←j)=p(xj)p(yj|xj)p(u←j|xj)and the denominator in Eq. (19) is nothing butp(yj,u←j)=p(yj,u←j;μne(j)⁎). Consequently, the local estimation rule is the expected value of the posterior given the local measurement and incoming messages given byxˆj=νj⁎(yj,u←j)=∫Xjdxjxjp(xj|yj,u←j;μne(j)⁎).Based on Proposition 3.1, it is possible to tailor the Update step of Algorithm 1 to obtain an iterative scheme for finding a pbp optimal two-stage strategy. The treatment of the terms in Eqs. (10), (12)–(18) as operators that can act on any set of local rules, not necessarily optimal, results with Algorithm 2. Note that, these steps can be carried out in a message passing fashion. In the first pass (Update Step 1), all nodes compute and send node-to-node likelihood terms to their neighbors. In the second pass (Update Step 2), upon reception of these messages, all nodes update their (incoming) message likelihoods and estimation rules. Then, they compute and send expected cost messages to their neighbors. After receiving cost messages from neighbors, each node updates its communication rule (Update Step 3). Owing to the message passing structure, the complexity of optimization is bounded by the node with the highest degree rather than the number of nodes. Such a structure is also advantageous in the case of a network self-organization requirement.Finally, the value of the Bayesian risk function at the lth iteration is easily found in terms of the expressions discussed above as(20)J(γl)=∑i∈VGid(νil)+λ∑i∈VGic(μil),where the per node costs are given by(21)Gid(νil)=∑u←i∫Xidxip(xi)Pil+1(u←i|xi)Ii(u←i,xi;νil),(22)Gic(μil)=∑u→i∫Xidxicic(u→i,xi)p(xi)p(u→i|xi;μil).In this section, we develop Monte Carlo (MC) methods to realize Algorithm 2 introduced in Section 3. Algorithm 2 results with a pbp optimal processing strategy whose structure is captured by the operators in Proposition 3.1. It is not possible to evaluate these operators for arbitrary selections of, e.g., priorsp(xj)s, likelihoodsp(yj|xj)s orγ∖j∈Γ∖jG, in general. Instead, we consider a fixed set of particles at each node and approximate the aforementioned operators using MC methods such as Importance Sampling (IS) [35,36]. The resulting algorithm which is detailed in this section carries out strategy optimization through passing messages represented by weighted particles.1111Similar decentralized algorithms based on transmissions of weighted particles include particle Belief Propagation algorithms (see, e.g., [37,38]) for estimation.We use IS with independent samples generated from two proposal distributionssj(xj)andqj(yj)overXjandYj, respectively for node j:(23)Sj≜{xj(1),xj(2),...,xj(Mj)}such thatxj(m)∼sj(xj)form=1,2,...,Mj,and,(24)Qj≜{yj(1),yj(2),...,yj(Pj)}such thatyj(p)∼qj(yj)forp=1,2,...,Pj.These proposal distributions can be selected as the local marginalsp(xj)andp(yj). This sampling strategy has been previously used in similar message passing algorithms (see, for example, [38] and the references therein). Use of heavy tailed distributions would improve the small sample size variance of IS [36]. Although the sizes ofSjandQjmight vary, we assume thatMj=MandPj=Pforj∈Vfor the simplicity of the discussion throughout.We fix these particle sets in order to reduce the communication load of the optimization by not having to transmit particles at every iteration but transmit them only once and communicate the weights for the rest of the iterations. This approach is similar to that proposed in [38] for particle BP algorithms, and, has also been used in [20] for optimizing decentralized strategies over DAGs.Using these sample sets, we make successive approximations to the expressions constituting the jth pbp optimal local rule given in Proposition 3.1. First, we approximate to the local rule pair in Section 4.1. Then, we apply the IS rule to the incoming message likelihood (Section 4.2). In Section 4.3, we tackle computations regarding the expected cost term. Finally, in Section 4.4, we employ all the previous steps simultaneously in Algorithm 2 and obtain a Monte Carlo optimization scheme such that the message passing structure is preserved.Let us consider Proposition 3.1 for the variational form of the jth communication and estimation rules in the case of an arbitraryγ∖jnot necessarily optimal. We approximate Eqs. (9) and (11) since it is often not possible to compute these integrals, exactly, for arbitrary selections of the factors that constructαjandβj(given in Eqs. (10) and (12), respectively).We simplify our notation by hiding the dependence of the operators in Proposition 3.1 to the local rules inγ∖j. For example, we denote the incoming message likelihood in Eq. (13) and the total expected cost in Eq. (16) byPj(u←j|xj)andCj(u→j,xj), respectively, where the underlying rules are obvious from the context.We use the sample setSjin Eq. (23) for finding an IS approximation to the communication rule in Eq. (9) and obtain(25)μj(yj)≈arg⁡minu→j∈U→j⁡1∑m′=1Mωj(m′)∑m=1Mωj(m)p(yj|xj(m))[λcjc(u→j,xj(m))+Cj(u→j,xj(m))],(26)ωjm=p(xj(m))/sj(xj(m)),for allyj∈Yjwith non-zero probability.For the local estimation rule given in (11), a similar approximation is given by(27)νj(yj,u←j)≈arg⁡minxˆj∈Xj⁡1∑m′=1Mωj(m′)∑m=1Mωjmp(yj|xj(m))Pj(u←j|xj(m))cjd(xˆj,xj(m)),for allyj∈Yjandu←j∈U←jwith non-zero probability, using the IS weights in Eq. (26).Example 4.1Consider the squared error penalty for the estimation error, i.e.,cjd(xˆj,xj)=(xˆj−xj)2. Then the pbp optimal estimation rule local to node j as given in the variational form by Eq. (27) yieldsνj(yj,u←j)≈∑m=1Mωj(m)xj(m)p(yj|xj(m))Pj(u←j|xj(m))∑m=1Mωj(m)p(yj|xj(m))Pj(u←j|xj(m)).We consider the message likelihood functionPj(u←j|xj)in the right hand side of (27) given by Eq. (13) together with the recursion involving Eqs. (14) and (15). We find an IS approximation for evaluations ofPj(u←j|xj)atxj∈Sjandu←j∈U←jas follows: We first considerp(u→i|xi;μi)in (15). We use the IS rule with the sample setQjgenerated from the local proposal densityqi(yi):(28)p˜(u→i|xi(m);μi)≜1∑p=1Pωi(m)(p)∑p=1Pωi(m)(p)δμi(yi(p))(u→i)ωi(m)(p)=p(yi(p)|xi(m))qi(yi(p))foru→i∈Uiandxi(m)∈Si.Note that the node-to-node likelihoodPi→jin (14) is a marginalization ofp(u→i|xi;μi)and can be estimated by substitutingp˜in (14). Let us denote this term byP˜i→j.Second, we considerPj(u←j|xj)in (13) and construct a sample set at node j by using the particle setsSis local to the neighbors. The mth element in this set is a vector obtained by concatenating the mth elements fromSis, i.e., we constructSne(j)≜{xne(j)(m)|xne(j)(m)=(xi(m))i∈ne(j)}. Note that these points are generated from the product of proposals, i.e.,xne(j)(m)∼∏i∈ne(j)si(xi). We consider using this sample set with the IS method and equivalently the proposal density∏i∈ne(j)si(xi). Then, the integral in the RHS of Eq. (13) can be approximated with(29)Pj˜(u←j|xj(m))≜1∑m′=1Mωj(m)(m′)∑m′=1Mωj(m)(m′)∏i∈ne(j)P˜i→j(ui→j|xi(m′)),ωj(m)(m′)=p(xne(j)(m′)|xj(m))∏i∈ne(j)si(xi(m′)).We replace thePjterm in the RHS of Eq. (27) byPj˜and obtain an approximately pbp optimal estimation rule through these successive IS approximations.We consider the expected cost termCjin the RHS of the communication rule approximation in (25). This term is given by Eqs. (16)–(18) and we begin with approximating to the conditional estimation riskIi(u←i,xi;νi). After substituting from (6) into (18), we obtainIi(u←i,xi;νi)=∫Yidyicid(νi(yi,u←i),xi)p(yi|xi).For the RHS of the expression above, we useqi(xi)as the proposal distribution of the IS rule and utilize the sample setQi(Eq. (24)). Then, the conditional expected risk is estimated by(30)I˜i(u←i,xi(m);νi)≜1∑p=1Pωi(m)(p)∑p=1Pωi(m)(p)cid(νi(yi(p),u←i),xi(m))ωi(m)(p)=p(yi(p)|xi(m))qi(yi(p))for allu←i∈U←iandxi(m)∈Si.Now, let us consider the approximate evaluation of the node-to-node cost messagesCi→jgiven by Eq. (17). We employ IS for approximately evaluating the RHS of Eq. (17) at all possible(uj→i,xj(m))pairs such thatuj→i∈Uj→iandxj(m)∈Sj. Similar to the discussion on approximating the message likelihood term, we consider a sample set constructed by concatenating the mth elements from the usual sets local to neighbors of i other than j, i.e.,Sxne(i)∖j≜{xne(i)∖j(m)|xne(i)∖j(m)=(xj′(m))j′∈ne(i)∖j}This set can equivalently be treated as points generated from∏j′∈ne(i)∖jsj′(xj′). Together withSi, we use the IS approximation to RHS of Eq. (17) and obtain(31)C˜i→j(uj→i,xj(m))≜∑une(i)∖j1∑m′=1Mωi(m)(m′)∑m′=1Mωi(m)(m′)∏j′∈ne(i)∖jP˜j′→i(uj′→i|xj′(m′))I˜i(u←i,xi(m′);νi),ωi(m)(m′)=p(xne(i)∖j(m′),xi(m′)|xj(m))p(xi(m′))∏j′∈ne(i)∖jsj′(xj′(m′)).After replacingCi→jwithC˜i→jin the total estimation risk in Eq. (16) and the approximate local communication rule in Eq. (25), a further approximation denoted byμj˜is obtained.In Sections 4.1–4.3, based on Proposition 3.1, we provided a Monte Carlo framework for approximating the jth local rule in the pbp optimal form given an arbitraryγ∖j. In particular, we obtained(μj˜,νj˜)using the IS rule with proposal distributions which might be selected simply as local marginals.Once the RHSs of all the expressions in the MC framework are considered as operators, we can approximate all local rules in a strategy simultaneously and plug them into Algorithm 2. The procedure we obtain with this approach is given in Algorithm 3. Note that, the message passing structure of the computations is maintained: Before proceeding with the iterations, the nodes exchangeSis with their neighbors. In the first stage of the iterations, the IS weights of the node-to-node likelihoods are transmitted to the neighbors. It suffices to transmit these sets as arrays of weights for each admissible link symbol sinceSis are already known to neighbors. In the second stage of the iterations, the cost messages are exchanged, again, as ordered real arrays for each symbol. The node-to-node likelihood from node i to j is, then, of lengthMi|Ui→j|, whereas that of the cost message isMj|Ui→j|. In the examples we present in Section 5, convergence is achieved after only a few iterations.Finally, the value of the Bayesian risk function corresponding to the strategy at the lth iteration, i.e.,J(γl)=Jd(γl)+λJc(γl)given by Eqs. (20)–(22), can be computed approximately by(32)J˜(γ˜l)=∑i∈VG˜id(ν˜il)+λ∑i∈VG˜ic(μ˜il)where(33)G˜id(ν˜il)=∑u←i,mP˜il+1(u←i|xi(m))I˜il(u←i,xi(m);ν˜il),(34)G˜ic(μ˜il)=∑u→i,mcic(u→i,xi(m))p˜(u→i|xi(m);μ˜il).In contrary to{J(γl)}, the sequence of approximated objectives, i.e.,{J˜(γ˜l)}, is not necessarily non-increasing. Nevertheless, note that the error sequenceerr[l]≜J(γl)−J˜(γ˜l)will be identically zero with probability one asM,P→∞. Investigation of an operator τ (Check step of Algorithm 3) that would yield a non-increasing error sequence with high probability for finiteM,Pcould be a topic for future work.In this section, we demonstrate our MC-based decentralized estimation framework in various scenarios including Gaussian priors, non-Gaussian priors, and large random graphs. We use local marginals as IS proposal distributions and compare the performances of the optimized strategies with those of the centralized and the myopic estimators. The centralized estimator provides the best accuracy achievable with the communication cost of collecting the network-wide measurements at a designated center. In the myopic estimation strategy, all variables are estimated locally using only the local measurements and no communication resources are utilized.We first consider a small network composed of four platforms. A Gaussian random fieldX=(X1,X2,X3,X4)is of concern and platform j is associated withXj. We consider two-stage strategies over the undirected graph given in Fig. 3(a). The BW constraints are captured by specifying the set of admissible symbolsUi→j={0,1,2}for all(i,j)∈E.The online processing, as described in Section 2.1, starts with each node evaluating its communication function on its measurement, i.e., nodes 1–4 simultaneously evaluateu1→3=μ1(y1),u2→3=μ2(y2),(u3→1,u3→2,u3→4)=μ3(y3),u4→3=μ4(y4)respectively. As soon as all the messages from the neighbors are received, estimation rules are run, i.e., nodes 1–4 evaluatexˆ1=ν1(y1,u3→1),xˆ2=ν2(y2,u3→2),xˆ3=ν3(y3,u1→3,u2→3,u4→3),xˆ4=ν4(y4,u3→4)respectively. We design the strategyγ=(γ1,...,γ4)whereγj=(μj,νj)using Algorithm 3.We select the communication cost local to node j ascjc(uj→ne(j),xj)=∑k∈ne(j)cj→kc(uj→k,xj)which satisfies Assumption 1. Here,cj→kc(uj→k)is the cost of transmitting the symboluj→kon the link(j,k)∈Eand given bycj→kc(uj→k,xj)={0,ifuj→k=01,otherwise.Hence,Uj→ktogether withcj→kcdefines a selective communication scheme whereuj→k=0indicates no communications anduj→k≠0indicates transmission of a one bit message. We call this a 1-bit selective communication scheme and also discuss a 2-bit scheme later in this section. The estimation error is penalized bycjd(xj,xˆj)=(xj−xˆj)2. Hence the total cost of a strategy isJ(γ)=Jd(γ)+λJc(γ)whereJdis the MSE andJcis the total link use rate.The random field prior is a multivariate Gaussian, i.e.,x∼N(x;0,CX)whereNdenotes a multivariate Gaussian with mean 0 and covarianceCX. This distribution is Markov with respect to the graphGXin Fig. 3(b). The covariance matrix is given by(35)CX=[21.1251.51.1251.12521.51.1251.51.521.51.1251.1251.52].Note that Algorithm 3 is valid for any arbitrary selection of the undirected communication topology that is not necessarily identical to the Markov random field representation of X. Here, for the sake of simplicity we select the UG topology in Fig. 3(a) to have the same structure as the MRF in Fig. 3(b).For the noise processesnjforj∈V, Assumptions 2 and 3 hold withp(yj|xj)=N(yj;xj,0.5). ConsideringCX, each sensor has an SNR of 6 dB.The initial local estimation rule is the myopic minimum MSE estimator which is based only onyj, i.e.,νj0(yj,u←j)=∫−∞∞dxjxjp(xj|yj), and the initial communication rule is a threshold rule quantizingyjgiven by(36)μj0(yj)={1,yj<−2σn0,−2σn⩽yj⩽2σn2,yj>2σn.Suppose that we use Algorithm 2 and achieve the performance points(Jc(γ⁎),Jd(γ⁎))for the converged strategies as we vary λ. There exists aλ⁎value such that forλ≥λ⁎, the communication costλJcwill increase to a level that prevents the decrease in the decision costJdachieved by the transmitted information among nodes to further cause a decrease in J. In this regime, not sending any messages (selecting the symbol 0) and using the myopic estimation rule will be the pbp optimal strategy. Hence, it is possible to interpretλ⁎as the maximum price per bit that the system affords to decrease the expected estimation error. As we use Algorithm 3 and increase λ from 0 we approximate samples from the corresponding pareto-optimal curve which enables us to quantify the tradeoff between the cost of estimation errors and communication.In Fig. 4(a), we present the approximate MSE-total link use rate pairs of the converged strategiesγ˜⁎obtained by using Algorithm 3 for varying λ from 0 with 0.001 steps (black ‘+’s). These points demonstrate graceful degradation of the estimation accuracy with decreasing communication load in the network. Specifically, we generate 2000 and 30 000 samples fromp(xi)andp(yi), respectively for obtainingSxiandSyi. The upper and lower bounds are MSEs corresponding to the myopic rule and the centralized optimal rule respectively. For the squared error cost, the optimal centralized rule given byE{X|Y=y}yields a communication cost ofJc=3Qwhere Q is the number of bits used to represent a real number, i.e.,yj, before transmitting to the fusion center. Let us consider(J˜c,J˜d)pairs for the 1-bit selective communication scheme, forλ=0(the transmission has no cost). The link use rate is approximately 3.2 bits, which is far less than the total capacity of 6 bits for the bi-directional topology given in Fig. 3(a). Nevertheless, the MSE achieved by using the strategy designed using Algorithm 3 is significantly close to that for the centralized rule. The communication stops across the network for the strategy designed usingλ⁎≈0.3and the nodes proceed with the myopic estimators for larger values of λ.At this point, it is worth mentioning that the converged strategies for different threshold selections in the initial communication rule given by Eq. (36) yield the same performance with a slight variation due to Monte Carlo approximations. This indicates that the proposed scheme performs fairly consistently with different initializations, in this example.We repeat the same scenario with a different BW constraint: Specifically, we selectUi→js corresponding to a 2-bit selective communication scheme. The initial communication rules are appropriately modified versions of that given by Eq. (36) and the approximate performance points obtained are presented in Fig. 4(a) as well.1212For these experiments, we use the condition||J˜(γ˜l−1)−J˜(γ˜l)|−|J˜(γ˜l−2)−J˜(γ˜l−1)||<1.0e−2in the Check step of Algorithm 3. The minimum number of iterations for convergence is 3 for both the 1- and 2-bit schemes and the resulting averages (standard deviations) are3.24(0.43)and3.11(0.31)for the 1- and 2-bit schemes, respectively.The tradeoff curves show that, as we increase the link capacities and for small enough λ values, the pbp optimal strategies for the 2-bit case achieve fair improvements in the estimation accuracy for the same total communication load.In this example, we demonstrate that the MC framework applies for arbitrary distributions provided that samples can be generated from their marginals. This can be an important advantage in certain problem settings in which it is not possible to obtain closed form expressions even for the centralized rule. We consider such a scenario in which X is distributed by a heavy tailed priorp(x), specifically a multivariate-symmetric Laplacian (MSL) given by(37)p(x)=2(2π)d/2|Cx|1/2(xTCx−1x2)1−d/2K1−d/2(2xTCx−1x)where d is the dimension of x,Cxis a covariance matrix, andKη(u)is the Bessel function of the second kind of order η (see, e.g., [39]). Let us denote this density bySLd(CX). Unlike the Gaussian case, uncorrelatedness does not imply independence and not being a member of the exponential family,SLd(CX)does not admit a Markov random field representation. On the other hand, it is possible to generate samples from an MSL utilizing samples generated from a multivariate Gaussian of zero mean and the desired covariance matrix together with samples drawn from the unit univariate exponential distribution, i.e., givenx′∼N(x′;0,CX)andz∼e−z, generate samples of X byx=zx′, thenx∼SLd(Cx).Similar to that in the previous section, we assume the underlying communication structure described byG=(V,E)in Fig. 3(a) together with a 1-bit selective communication scheme, and similar cost functions, observation likelihoods, and initial local rules. To the best knowledge of the authors, for an MSL prior and Gaussian likelihoods, even the centralized paradigm fails to provide a solution without employing numerical approximations.We considerX=(X1,X2,X3,X4)such thatpX(x)=SL4(CX)whereCXis given by Eq. (35) and we exploit the fact that the jth marginal density ofSLd(CX)is given bySL1([CX]j,j). It is straightforward to generate samples from these marginals [40]. Sample sets from the observation distributions are obtained using the scheme in [20].In this example, we also demonstrate the variation of the results over different sample sets, so, we generate 10 different sample sets such that|Sj|=3000and|Qj|=45000. Using these sets, we run Algorithm 3 for different choices of λ (as opposed to using a single sample set and small increments of λ as in Section 5.1). In Fig. 4(b), approximate performance points for the converged strategies are presented. The upper and lower bounds are the MSEs corresponding to the myopic and the centralized rules, respectively.1313In the MSL prior-Gaussian likelihoods problem, the evaluation of the myopic and centralized strategies and the corresponding MSEs require numerical approximations for which we utilize MC methods as well.For each value of λ, collective results based on the 10 sample sets provide a sample-based approximation to the performance point(Jd(γ⁎),Jc(γ⁎))on the tradeoff curve.1414Note that,(Jd(γ⁎),Jc(γ⁎))is the performance of the pbp optimal strategyγ⁎for the Bayesian risk corresponding to λ, i.e.,J(γ⁎)=Jd(γ⁎)+λJc(γ⁎).These sample-based results form clusters with reasonable variability which can be interpreted as an indication of their approximation quality. It is reasonable to expect this level of variability since heavy tailed distributions require utilization of larger sample sets. Nevertheless, the proposed MC framework provides distributed solutions in problem settings which do not admit straightforward solutions even in the centralized case.In this section, we demonstrate Algorithm 3 in relatively large scale random field estimation problems. Specifically, we consider problems set up by randomly deploying 50 platforms over an area of 100 unit squares. Each sensor locationsj∈R2is associated with a scalar random variable,Xj. We assume that the random fieldX=(X1,X2,...,X50)is Gaussian with zero mean, i.e.,x∼N(x;0,Cx)andCx=[Ci,j]is selected as the Matérn covariance with nugget effect given by [41](38)Ci,j={(σ2/2(η−1)Γ(η))(2ηh/ϕ)η2Kη(2ηh/ϕ),h>0τ2+σ2,h=0whereh≜‖si−sj‖is the distance between sensors i and j,Kηis a modified Bessel function of the second kind of order η,τ2is the nugget effect, ϕ is the effective covariance range andσ2is referred to as the partial sill.1515Various forms of Matérn covariances are commonly used in spatial data modeling [8].The covariance function for the particular set of parameter values we use in our experiments can be seen in Fig. 5(b). The variances ofXjs are given by the covariance function evaluated ath=0which is unity. The covariance matrixCxfor the deployment in Fig. 5(a) is given in Fig. 5(c). The inverse ofCxcontains no zeros and, hence, this model cannot be exactly represented by a sparse Markov Random Field.The undirected communication topology in Fig. 5(a) is found by sparsifying the Gabriel graph of the deployment. We consider a one-bit selective bi-directional communication scheme which yields 128 bits total capacity with this UG. We initialize the nodes with quantization rules for communications and myopic estimators. We select a communication cost similar to that we have used in the previous examples and squared error as the estimation cost. We use|Sj|=2000and|Qj|=30000samples from local marginals in Algorithm 3.The measurement noise for each sensor is Gaussian with varianceσnj2=0.25leading to 6.02 dB signal-to-noise ratio (SNR) given bySNR=10log10⁡σj2/σnj2. The myopic MSE is given byMSE=σj2σnj2/(σj2+σnj2)which equals to 0.2. In order to demonstrate the efficacy of the optimized two-stage strategies in comparison with the myopic estimator and the centralized estimator, we define an MSE equivalent SNR asSNR=10log10⁡(σj2−MSE)/MSE. This quantity, in a sense, is the SNR of a sensor which would yield the given MSE value when it is used with a myopic estimator. From this viewpoint, a two-stage estimation strategy can be viewed as being equivalent to replacing each sensor with its SNR-improved version in a myopic strategy.We consider sensors 17–23 in Fig. 5(a). In Fig. 5(d) we present the benefits of the two-stage strategies designed using Algorithm 3 in terms of the improvement in the MSE equivalent SNRs for different values of λ. The upper bounds are achieved by the centralized estimator. Nodes 18–23 have closely located neighbors with highly correlated local variables. As λ is decreased, communication is utilized more, and, consequently an improvement as much as more than half of the myopic-centralized SNR gap is achieved. Node 17 is more distant to its neighbors and benefits less from the incoming information.The overall estimation and communication costs of this network are given in Fig. 6(a) for different values of λ and five different sample sets for each. Note that, the cost of communication for the improvement upon the myopic MSE is on the scale of tens of bits which is extremely small as compared to the cost of collecting network wide measurements at a designated node for centralized estimation. The performance points for different sample sets form clusters around the points from the pareto-optimal curve they approximate in a way similar to the example in Section 5.2 and the results given in Fig. 4(b). The variations of the clusters indicate a fairly good quality of approximation. We verify the consistency of our algorithm in the performance of the designs by using four additional deployments. For each deployment, the diagonal ofCx, and, hence, the myopic performances are the same with that of the other three networks. The MSEs of the centralized rules, on the other hand, differ as well as the total network capacities.1616The capacities corresponding to the deployment instances UG 1–4 are 132, 130, 134, and 140 bits, respectively.We present the approximate MSE-total link use rate points forλ=0.005and 0.05 and for 5 different sample sets in Fig. 6(b).1717The number of iterations for convergence has a minimum value of 3, a mean value 4, and a standard deviation of 1.1.It can be observed that, the converged strategy improves the MSE performance in comparison with the myopic rule for all of the UGs with a fair amount of variability in the results. This suggests that our algorithm performs consistently across a variety of random network structures. The gains in the estimation accuracy in this example are fairly significant considering that only 1-bit transmissions are used. Our experiments also show that λ effectively controls the trade-off between estimation accuracy measured with MSE and the communications load in bits in large scale problems as well.

@&#CONCLUSIONS@&#
