@&#MAIN-TITLE@&#
A parameter control method of evolutionary algorithms using exploration and exploitation measures with a practical application for fitting Sovova's mass transfer model

@&#HIGHLIGHTS@&#
We apply exploration and exploitation measures into adaptive parameter control.We experiment with the chemical engineering problem of fitting Sovova's model.Our approach is competitive to five other approaches.

@&#KEYPHRASES@&#
Exploration,Exploitation,Parameter control,Sovova model,

@&#ABSTRACT@&#
Exploration and exploitation are omnipresent terms in evolutionary computation community that have been broadly utilized to explain how evolutionary algorithms perform search. However, only recently exploration and exploitation measures were presented in a quantitative way enabling to measure amounts of exploration and exploitation. To move a step further, this paper introduces a parameter control approach that utilizes such measures as feedback to adaptively control evolution processes. The paper shows that with new exploration and exploitation measures, the evolution process generates relatively well results in terms of fitness and/or convergence rate when applying to a practical chemical engineering problem of fitting Sovova's model. We also conducted an objective statistical analysis using Bonferroni–Dunn test and sensitivity analysis on the experimental results. The statistical analysis results again proved that the parameter control strategy using exploration and exploitation measures is competitive to the other approaches presented in the paper. The sensitivity analysis results also showed that different initial values may affect output in different magnitude.

@&#INTRODUCTION@&#
Exploration and exploitation [10,14] are two essential cornerstones of evolutionary algorithms (EAs) [4,17,22,38] that drive an evolution process toward optimization and/or convergence. In fact, these two processes are essential for search processes when using any metaheuristic approach [6,7]. Exploration is defined as visiting entirely new regions of a search space, while exploitation is defined as visiting those regions of a search space within the neighborhood of previously visited points [10]. However, to our best knowledge, not until exploration and exploitation measures using an ancestry tree approach were recently introduced by Črepinšek et al. [9], there had not been a quantitative way to measure exploration and exploitation and analyze how these essential cornerstones influence and balance the inner work of an evolution process. Our previous work in Ref. [9] primarily focused on introducing exploration and exploitation measures. In Ref. [33] we further applied such measures to investigate and explain the inner work of VEGA [43] and SPEA2 [49].Given the usefulness on investigating the inner work of EAs using exploration and exploitation measures, this paper attempts to validate a hypothesis: by using finer-grained exploration and exploitation measures as feedback, an evolution process adapted by parameter control approaches [15] may perform relatively competitive or generate even better results in terms of optimization and/or convergence on a selected practical chemical engineering problem. To validate the hypothesis, this paper extends the implementation of an existing domain-specific language [37], called PPCea (Programmable Parameter Control for Evolutionary Algorithms) introduced by Liu et al. [31,32], so that all exploration and exploitation measures from Črepinšek et al. [9] can be computed by the PPCea interpreter on-the-fly. With such, users may introduce PPCea programs to adaptively control evolution processes using the measures as feedback.The paper is organized as follows. Section 2 reviews the ancestor-tree approach. Section 3 presents how PPCea can be used to (re)produce the parameter tuning and four parameter control algorithms, including the one controlled by exploration and exploitation measures. A practical Chemical Engineering problem is shown in Section 4. The experimental results of the four parameter control strategies and two parameter tuning approaches are presented in Section 5, followed by the conclusion in Section 6.Exploration and exploitation are fundamental concepts of any search algorithm. Despite this fact, exploration and exploitation are still not well understood by practitioners and researchers [14]. To remedy this situation Črepinšek et al. [10] introduced a fresh treatment of exploration and exploitation in EAs discussing:•what parts of EAs contribute to exploration and exploitation: selection, variation operators, population size, and representation;how balance between exploration and exploitation is achieved: implicitly by parameter tuning and parameter control using uni-process or multi-processes driven approaches;when balance between exploration and exploitation should be controlled: online using deterministic, adaptive, or self-adaptive approaches; andhow balance between exploration and exploitation can be controlled: by diversity maintaining, by diversity control, by diversity learning, or by other direct approaches.Although numerous measures and means were summarized and classified in Ref. [10], direct measures to analyze exploration and exploitation barely exist. Hence, controlling exploration and exploitation is up to now mostly indirect in EAs (e.g., by varying different control parameters or by maintaining diversity without explicitly measuring exploration and exploitation). To the best of our knowledge, the only direct measures for exploration and exploitation is our own work: an ancestry-based approach presented in Ref. [9]. We have used such measures (e.g., exploreRatio, exploreGap) defined in Ref. [9] to directly measure exploration and exploitation ability of a few EAs. Particularly, in Ref. [33] the analysis and comparison between Vector Evaluated Genetic Algorithm (VEGA) [43] and Strength Pareto Evolutionary Algorithm 2 (SPEA2) [49] were performed using the recently introduced exploration and exploitation measures, where it was shown that the inner work of both multi-objective algorithms can be observed and explained in a refined way in terms of exploration and exploitation. However, in this case exploration and exploitation measures were computed off-line from data collected during the run of the algorithms. To be able to perform adaptive parameter control with the proposed exploration and exploitation measures they need to be computed on-line during the run of algorithms. Preliminary results of on-line computation of exploration and exploitation measures and adaptive parameter control with exploration and exploitation measures has been presented by Liu et al. [34], where the results were shown only on functions f2 and f14 from the benchmark test suite in Yao et al. [48]. This paper is an extension of the paper [34], where adaptive parameter control with exploration and exploitation measures has been now applied to a practical chemical engineering problem. With newly proposed adaptive parameter control using exploration and exploitation measures, the performance of Differential Evolution (DE) [45] for fitting Sovova's model [44] has been improved. But, before showing the results (see Section 5) the ancestry tree based approach for directly measuring exploration and exploitation is briefly introduced for self-contained purpose. For more information, readers are directed to [9,10]. In this paper the following notation is used. An ancestry tree originated from ith individual from initial population is denoted as τi, where i∈[0, …, pop_size−1]. The entire ancestry trees are denoted with τ, where τ={τ0, …, τpop_size−1}. A jth exploitation tree originated from ith individual from initial population is denoted with τi,j. An exploration tree originated from ith individual from initial population is denoted as exploreTree(τi), where i∈[0, …, pop_size−1]. When threshold value X, important for splitting an ancestry tree, is also mentioned an ancestry tree, exploitation tree, and exploration tree are denoted asτi(X),τi,j(X),exploreTree(τi(X)), respectively.The ancestry tree approach borrows the ideas from genealogy. Ancestry trees describe the history of all individuals that were created during an evolution process: an individual's parent, its representation (genome), as well as how (e.g., by mutation, by crossover) and when (generation) the individual was created are all stored during the construction of ancestry trees. For example, in Fig. 1(left), τ2 represents the ancestry tree originated from the 2nd individual generated at the initial stage. During each generation, if a candidate child (generated by mutation (T=m), crossover (T=c), random creation (T=rnd), repair (T=r), or cloning (T=cln), etc.) survives after selection, the ancestry tree will be expanded to further depth until no more offspring survives. Note that building such an ancestry tree is similar to the approach presented by Davis [11], where whenever a new member was added to the population, a pointer was established to its parents, as well as another pointer was established to the operator that had created the new member. Davis [11] used such a structure to adaptively compute operator probabilities. While in our approach an ancestry tree is used to compute an amount of exploration/exploitation. But, how can we see which node is a result of exploration or exploitation? In Ref. [9], a threshold variable X is introduced to delimit exploration from exploitation and can be seen as identification of an individual's neighborhood. Because X is problem dependent, various diversity measures (e.g., hamming distance and Euclidian distance) can be used for this purpose. When the selected diversity measure is larger than X, the splitting process will split an ancestry tree τiinto several subtrees (see Fig. 1(middle)). Each particular subtree is called exploitation tree τi,j, because all nodes, except the root node, are obtained by exploitation of neighborhood regions. Such a process can be observed in Fig. 1: There are six exploitation trees (τ2,0, …, τ2,5, in Fig. 1(middle)). For each exploitation tree, gray colored nodes represent exploitation nodes (obtained by exploiting within the individual's neighborhood) and black root node represents exploration node (obtained by exploring outside the neighborhood). As for exploration tree exploreTree(τi), it is constructed by linking all the black root nodes together (see Fig. 1(right)). With such, a number of exploration and exploitation measures can be defined based on the characteristics of exploration and exploitation trees.Careful readers might notice that we did a slight simplification, as every individual in ancestry tree τi, except in initial generation, has exactly one parent called a dominant parent. A dominant parent of individual indiis an individual selected from τithat passes a genetic material to its offspring. In the case when more parents contribute genetic materials to an individual (e.g., as a result of crossover), a parent with most similarities to the individual is selected as dominant parent. Every individual that has not been selected as dominant parent is represented as a leaf in an ancestry tree. It is also clear from Fig. 1 that fitter individuals, those who are selected for next generations, contribute to growth of an ancestry tree. From now, let size() represent the number of nodes of an ancestry/exploitation/exploration tree. The number of exploitation trees obtained from all ancestry trees using the threshold X is:(1)count(X)=∑i=0pop_size−1splits(τi(X))wheresplits(τi(X))represents the number of the splitting processes triggered by the threshold X in ancestry treeτi(X), as can be seen in Fig. 1(middle). Now we are ready to explain some interesting direct measures for exploration and exploitation.Exploration ratio (exploreRatio) can be defined as the percentage of nodes obtained by exploration (black nodes) over all nodes in all ancestry trees. The latter is calculated as pop_size+pop_size·G (in the case that population size is constant during evolution) or as all exploitation trees obtained by using the threshold X=0 (always splitting). Exploration nodes are root nodes of exploitation trees. Hence, the number of exploration nodes is the same as the number of exploitation trees count(X). The exploration ratio (exploreRatio) is defined as:(2)exploreRatio(X)=count(X)pop_size+pop_size·G=count(X)count(0)Exploitation ratio (exploitRatio), can be defined as:(3)exploitRatio(X)=1−exploreRatio(X)Two measures on exploration trees were defined. The first measure, exploreGap, calculates the average (avr) number of generations that was needed to change neighborhood. Namely, how many generations in average are needed to identify new and unexplored parts of the search space. Measure exploreGap is defined as:(4)exploreGap(X)=avr(gen(getRoot(τi,j(X)))−gen(parent(getRoot(τi,j(X)))))wheregetRoot(τi,j(x))returns the root (black) node ofτi,j(X)(the jth exploitation tree splitting from ancestry tree τiwith threshold X) and function parent() returns parent of a node (in this case from an exploration tree). While gen() returns the generation of a node or individual.The second measure, exploreProgressiveness, calculates the average depth of exploration trees (depth() is a standard depth function on trees). Namely, it measures the progressiveness of exploration.(5)exploreProgressiveness(X)=avr(depth(exploreTree(τi(X))))Measure exploitProgressiveness is similar to exploreProgressiveness, but this metric is defined on an exploitation tree:(6)exploitProgressiveness(X)=avr(depth(τi,j(X)))On the other hand, from exploration and exploitation trees’ wideness (numberOfLeafs), we can describe the influence of selection on exploration and exploitation (exploreSelectionPressure and exploitSelectionPressure). If same individual was selected more than once, an ancestry tree becomes wider. Measure for exploreSelectionPressure is defined as:(7)exploreSelectionPressure(x)=avr(numberofleafs(exploreTree(τi(X)))size(exploreTree(τi(X))))where i∈[0, …, pop_size−1]. Measure exploitSelectionPressure is similarly defined as:(8)exploitSelectionPressure(X)=avr(numberofleafs(τi,j(X))size(τi,j(X)))where i∈[0, …, pop_size−1] andj∈[0,…,splits(τi(X))].The following sections present how aforementioned exploration and exploration measures can be used to control and analyze EAs for a practical chemical engineering problem, where the following distance d between individuals a and b has been defined and applied:(9)d(a,b)=∑i=0n−1(|genea,i−geneb,i|)/(max(genei)−min(genei))nwhere genea,irepresents the ith gene (i=0, …, n−1) of individual a, while max(genei) and min(genei) return the upper and lower bounds of genei, respectively. The above distance is a variation of Manhattan distance, where normalization is performed on each gene. With such, no gene will outweigh any other [23]. Note that distance is a problem-specific measure, this paper defined the aforementioned distance measure due to the nature of the chemical engineering problem. Users may choose different kinds of distance measures depending on the problem to be solved [10] (e.g., Črepinšek et al. [9] used Hamming distance and Liu et al. [34] adapted Euclidean distance). With distance properly defined, if distance between dominant parent and offspring is larger than a predefined value, called splitting process threshold X, the offspring is exploring a new region. Conversely, the offspring is exploiting a region visited previously if the distance to its dominant parent is less than the predefined splitting process threshold X. Such definition of exploration and exploitation is just one of the possible classification defined by Črepinšek et al. [10], where exploration and exploitation is defined as:(10)SCN(indnew,P)>X(exploration)(11)SCN(indnew,P)≤X(exploitation)where similarity to the closest neighborSCNof newly created individual indnewin the population P can be defined as:•a similarity to its parent(s), indparent,(12)SCN(indnew,P)=d(indnew,indparent),whereindparent∈Pa similarity to the most similar individual within the whole population P,(13)SCN(indnew,P)=mind(indnew,ind)ind∈Pindnew≠inda similarity to the most similar individual in the sub-population P′∧(P′⊂P) (e.g., only to individuals which belong to the same niche),(14)SCN(indnew,P′)=mind(indnew,ind)ind∈P′∧(P′⊂P)indnew≠inda similarity to the most similar individual throughout the history of populations {Pt| t=0, …, current_gen}, where Ptdenotes a population within a generation t.(15)SCN(indnew,Pt)=mind(indnew,ind)ind∈Pt,t=0,…,current_genindnew≠indHence, in this paper the least conservative approach to identifying exploration zones is used since newly created individual is always compared only to its dominant parent.This section reviews PPCea [31,32], which is a domain-specific language [37] for EAs. The language comprises statements for general purposes (e.g., conditions, loop, and assignment statements) as well as statements and parameters specific for EAs (e.g., initialization, mutation, crossover, selection, resize, evaluation, population size, mutation and crossover rates). PPCea has been used in Ref. [32] to reproduce a number of parameter tuning, deterministic [15] and adaptive parameter control EAs (e.g., DGEA [46], PROFIGA [16] and GAVaPS [2]). The exploration and exploitation measures from Ref. [9] are newly implemented and integrated in PPCea interpreter and can be computed on-the-fly during an evolution process. An example of PPCea pseudocode to control EAs using exploration and exploitation measures (i.e., EE-driven approach) can be seen in the following code snippet (Algorithm 1). The programmable fashion of PPCea actually enables users to introduce much more complex adaptive algorithms using exploration and exploitation measures. We leave such potentials as our future work.Algorithm 1EE-driven approach using PPCea.Initialize all variables; //(F = 0.9, CR = 0.9, Round = 30, Generation = 5000, Epoch = 100)while not reaching Maximum Round doinit; //initialize populationwhile not reaching Maximum Generation docallDE; //invoke a Differential Evolution for one EpochifexploreRatio > 0.1 thenF:=F*1.22; //F is scaling factorCR:=CR*1.22; //CR is for crossoverelseF:=F*0.82;CR:=CR*0.82;end ifIncrement to Epoch generation(s), a user-defined strideend whileIncrement to next Roundend whileThe pseudocode (Algorithm 1) expresses that when DE is performing more exploration during an evolution process (i.e., exploreRatio>0.1) PPCea, after number of iterations (Epoch stride), increases the scaling factor F and control parameter for crossover CR to further explore unvisited regions of the search space. The rationale for such a control parameter strategy is as follows: Due to selection, better individuals survive (always true for DE) and if these individuals are the results of exploration then we increase F and CR to explore even more (and vice verse for exploitation). Note that value 0.1 in Algorithm 1 is set arbitrary. For the eleven problems (see Section 5) we experimented with a number of different values in order to find the best results.By using PPCea a parameter control strategy is specified in an algorithmic manner and is more flexible than current approaches to parameter control. There is no need for invasive change of EA code. As such it is more appealing for EA practitioners who want to experiment with customized parameter control strategies but do not have enough knowledge on how to change original EA code. In the sequel, several different examples for various parameter tuning and parameter control approaches using PPCea are presented.Algorithm 2Parameter tuning approach using PPCea.Initialize all variables; //(F = 0.9, CR = 0.9, Round=30, Epoch=Generation=5000)while not reaching Maximum Round doinit; //initialize populationwhile not reaching Maximum Generation docallDE; //invoke a Differential Evolution; Genetic Algorithms and Evolution Strategies also availableend whileIncrement to next Round;end whileParameter tuning approach is shown in Algorithm 2. It fixes the rates of F=0.9 and CR=0.9 during an entire evolution process. Several authors (e.g., Liu and Lampinen [30]) suggested such a setting for F and CR and we also used them for fitting Sovova's model in Ref. [24].Algorithm 3Deterministic approach using PPCea.Initialize all variables; // (F = 0.9, CR = 0.9, temp = 1.0, Round = 30, Generation = 5000, Epoch = 100)while not reaching Maximum Round doinit; //initialize populationwhile not reaching Maximum Generation docallDE; //invoke a Differential Evolution for one EpochF:= (1 / 240) + (0.11375 / temp); // Fogarty formulaCR:= (1 / 240) + (0.11375 / temp); // Fogarty formulatemp:= temp * 2.0;Increment to Epoch generation(s), a user-defined stride;end whileIncrement to next Round;end whileIn the deterministic parameter control [15], the values of control parameters are changed deterministically during an evolution process. An example of deterministic parameter control is the approach by Fogarty [20], where a formula gradually decreases scaling factor and crossover rate when the generation is incremented. An example of deterministic parameter control of DE using PPCea is shown in Algorithm 3.Algorithm 41/5 Success rule approach using PPCea.Initialize all variables; // (F = 0.9, CR = 0.9, Round = 30, Generation = 5000, Epoch = 100)while not reaching Maximum Round doinit; //initialize populationwhile not reaching Maximum Generation docallDE; //invoke a Differential Evolution for one EpochifratioM > 0.2 thenF:= F * 1.22; //ratioM above is success mutation ratio computed on-the-flyelseF:= F * 0.82;end ififratioC > 0.2 thenCR:= CR * 1.22; //ratioC above is success crossover ratio computed on-the-flyelseCR:= CR * 0.82;end ifIncrement to Epoch generation(s), a user-defined stride;end whileIncrement to next Round;end whileFor adaptive parameter control [15] the change of control parameter values depends on the status of evolution. Several measures of an evolution process can be taken into an account (e.g., percentage of individuals with above average fitness, number of successful mutations, amount of population diversity). A well known example of adaptive parameter control is 1/5 success rule presented in Bäck et al. [3], which states that when the ratio of successful mutations is above 1/5, mutation rate will become 1.22 times larger. Conversely, if the ratio of successful mutations is smaller than 1/5, mutation rate will be 0.82 times smaller than before. An example of 1/5 rule using PPCea is shown in Algorithm 4.Another successful example of adaptive parameter control is entropy-driven approach by Liu et al. [31], which outperformed other parameter control strategies on the benchmark functions from Yao et al. [48]. The entropy-driven approach presented in Ref. [31] employs the following rule: when entropy measure (representing diversity of a population [39,42]) is above a certain user-defined threshold, mutation rate is decremented to decrease diversity and encourage exploitation. Conversely, when the entropy measure is below the threshold, mutation rate is incremented to increase diversity and encourage exploration. An example of entropy-driven adaptive parameter control using PPCea is shown in Algorithm 5.Algorithm 5Entropy-driven approach using PPCea.Initialize all variables; // (F = 0.9, CR = 0.9, Round = 30, Generation = 5000, Epoch = 100)while not reaching Maximum Round doinit; //initialize populationwhile not reaching Maximum Generation docallDE; //invoke a Differential Evolution for one Epochifentropy > 0.2 thenF:= F * 0.82;CR:= CR * 0.82;elseF:= F * 1.22;CR:= CR * 1.22;end ifIncrement to Epoch generation(s), a user-defined stride;end whileIncrement to next Round;end whileIn this work we would like to promote yet another adaptive parameter control approach (EE-driven approach), which takes into account our newly developed exploration and exploitation measures, namely exploreRatio and exploitRatio (see Section 2). An example of EE-driven adaptive parameter control using PPCea is shown in Algorithm 1. It expresses the idea that when exploration is successful (above some threshold) let the process extend exploration even more; and vice verse, when exploration is not successful, let the process concentrate on exploitation more.In Chemical Engineering, reliable models are necessary to reduce the cost of process design. For this purpose EAs [4,17,22,38] turn out to be helpful because they are robust, give optimal or semi-optimal solutions, and can easily be adapted for different problems. They do not require any additional information about objective functions such as differentiability or continuity. Therefore, several applications of EAs in chemical processes for parameter estimation can be found in literature (e.g., [5,18,40,47]), as well for solving various problems in chemistry and chemical engineering [8,13,29,41]. In our previous work [24], parameter estimation of Sovova's mass transfer model [44], to describe extraction kinetics curve of vegetable oils, with EAs was presented and compared to a global optimization algorithm [35]. The global optimization algorithm by Martinez et al. [35] applies lexicographical grid method with local variation algorithm to obtain the near global optimum point on which the Nelder–Mead method was used to find the global optimum. Comparison of EAs to the global optimization technique [24] proved that EAs are more robust, efficient, and significantly better than the global optimizer [35] in regards to the deviation of the model from experimental data. Two different EAs have been used in Ref. [24]. The first version of EA may be classified as (μ+λ)-ES (Evolution Strategies), where λ, number of offspring, is not fixed but variable during an evolution process. The other differences from classic ES were in using one-point crossover and tournament selection, which are also not standard features of ES. While the second version of EA was DE invented by Storn et al. [45]. It was shown in Hrnčič et al. [24] that the proposed EA performed better than DE. The aim of this paper is to show that the behavior of DE can be improved by the proposed EE-driven parameter control technique. But, let us first briefly introduce the Chemical Engineering problem.Supercritical Fluid Extractions (SFEs) [27,36] have been applied in food and flavoring industry (e.g., decaffeination of tea and coffee [26]), petrochemical industry, pharmaceutical industry and lately also in environment protection processes for elimination of residual solvents from wastes and for purification of contaminated soil and water. They are used because of their environmental, health, safety and chemical benefits [27]. In SFE the feed material is contacted with a supercritical fluid (SCF) as solvent. SCFs (e.g., SC CO2 and SC H2O) are solvents at or above a critical temperature and/or pressure. The material extracted in SFE can be either in liquid or solid state. This work takes a closer look into extractions of solid-SCF, where the soluble components are separated from the solid material with SCF as a solvent. For design of apparatus, for SFE, the data from phase equilibrium, energy balances and mass transfer is required. From the phase equilibrium data, the solubility of compounds in SCF at different process conditions (pressure and temperature) is obtained, therefore the operating conditions, the type and quantity of the solvent can be determined. Energy balances are the basis for determining the energy consumption of the process. From mass transfer data, which has an enormous influence on the economy of extraction process, the time used for high pressure process run is determined. The flow sheet of the extraction process is shown in Fig. 2. The CO2 is compressed and heated to the operating conditions (supercritical state). The extraction step follows, and the soluble compounds are separated from the material. In this step the solubility of compound or mixture of compounds has to be the highest, while in the next separation step the solubility of compound in SCF has to be the lowest.The phase equilibrium and mass transfer data are usually obtained with research and measurements, which takes a lot of time and money. One of the major activities is kinetic modeling, whose goal is to reduce the time used for measurements and to cut the experimental cost. Mass transfer data are obtained from the extraction curve that shows a plot of total mass of oil extracted vs. the time or total mass of solvent used. The Sovova's model is used to describe extraction kinetics curve for SFE of substances for plant materials [44]. It separates the extraction curve into three periods (Fig. 3). In the first period the easily accessible solute is linear with a slope close to the value of oil solubility in solvent. In the second period, rate of extraction drops rapidly and continues with a third period where the extraction is almost linear but with much smaller extraction rate than in the first period.Sovova's model is described with the following equations, where extraction curve is defined as a function of time (y(t)).(16)y(t)=QCO2yr[1−exp(−Z)]t,if0≤t≤tCER(17)y(t)=QCO2yr[t−tCERexp(zw−Z)],iftCER<t≤tFER(18)y(t)=mSI[x0−yrWln1+expWx0yr−1expWQCO2mSI(tCER−t)]xkx0,ift>tFERwhereQCO2represents solvent flow rate, yrrepresents solubility of compounds at operating conditions, mSIrepresents mass of non-extractable material (extract-free), x0 represents the initial mass of extractable material (relative to mass of non-extractable material), and xkrepresents initial mass of extractable material in intact cell (relative to mass of non-extractable material). The axial coordinatezw, in the second extraction period, is calculated using Eq. (19).(19)zw=ZyrWx0lnx0exp[WQCO2(t−tCER)/mSI]−xkx0−xkTimes tCERand tFERrepresent the transition between the fast- and slow-extraction periods and are calculated using Eqs. (20) and (21).(20)tCER=(x0−xk)mSIyrZQCO2(21)tFER=tCER+mSIWQCO2lnxk+(x0−xk)exp(Wx0/yr)x0Parameters Z and W are directly proportional to mass transfer coefficients by Eqs. (22) and (23).(22)Z=kfa0ρQCO2(1−ϵ)ρs=FQCO2(23)W=ksa0QCO2(1−ϵ)=SQCO2The kfand ksare mass transfer coefficients in CO2 and solid phase, respectively. Value a0 represents a specific interfacial area, ρ is density of the solvent phase, ρsis density of the material and ϵ represents void fraction in bed. In the paper by Hrnčič et al. [24], parameters Z, W and xkwere chosen to be optimized with EA and DE, similar to parameters F, S and xkfitted by Sovova [44]. To solve the parameter fitting problem, the EA has been designed in Hrnčič et al. [24] where the individual of population was represented with a vector of float values [Z, W, xk], which represent estimating parameters of the model. Individual fitness value is calculated using Eq. (24)(24)ϕ(y,yobs)=100m∑i=1m|y(ti)−yobs(ti)|yobs(ti)where y(ti) represents the calculated amount of extract at time tiand is calculated using Eqs. (16)–(18)), while yobs(ti) represents the experimentally obtained amount of extract. Eq. (24) measures the percentage of average absolute relative deviation (AARD) from experimentally obtained data. In Fig. 3 the experimentally obtained data is shown as dots, while the curve represents Sovova's fitting model. For parameters Z and W the minimum value was 0 and the maximum was 10, while the boundaries for parameter xkwere between 0 and x0 (which fits with the description of xk). The same boundaries of model parameters were used in DE algorithm. In the work by Hrnčič et al. [24] the most often used DE scheme, known as DE/rand/1/bin[45], was used. In the comparison, Hrnčič et al. [24] had used six problems for SFE with CO2 of vetiver roots at 40°C and 200 bars, described and used also by Martinez et al. [35]. The values equal for all problems are initial mass of extractable material x0 = 0.0619 and extract solubility yr= 0.06. While other conditions specific to particular problems are:•Problem 1:QCO2=0.85kg/s, mtotal=3.53kgProblem 2:QCO2=0.85kg/s, mtotal=3.53kgProblem 3:QCO2=6.3kg/s, mtotal=26.2kgProblem 4:QCO2=17kg/s, mtotal=71.68kgProblem 5:QCO2=17kg/s, mtotal=72.26kgProblem 6:QCO2=6.3kg/s, mtotal=73.1kgNote that Sovova's model is a general model to describe extraction kinetics curves of vegetable oils. With different parameter settings as seen in Problems 1–6 above and Problems 7–11 shown in Section 5.2, each setting becomes a unique extraction kinetics problem along with specific characteristics such as flow rate, solubility, and initial mass, among others. Hence, these 11 different parameter settings are considered as 11 different extraction problems rather than a general huge problem with 11 different parameter settings.

@&#CONCLUSIONS@&#
A main objective of this paper is to validate a hypothesis: “By using finer-grained exploration and exploitation measures as feedback, an evolution process adapted by parameter control approaches [15] may perform relatively competitive or generate even better results in terms of average solutions and/or convergence on a selected practical chemical engineering problem.″ The aforementioned hypothesis was statistically test by the Bonferroni-Dunn test, which shows the superiority of the EE-driven approach over the Fogarty and parameter tuning (F=0.5, CR=0.9) approaches, while the EE-driven approach is relatively competitive to the parameter tuning (F=0.9, CR=0.9), 1/5 success rule, and entropy-driven approaches. Additionally, the competence and usefulness of using exploration and exploitation measures as “tools″ to analyze an evolution process in a finer-grained way is also demonstrated. By applying exploration and exploitation measures on the problem of fitting Sovova's model we can conclude that those algorithms which achieved lower exploreGap (frequently changing to new unexplored regions), higher exploreProgressiveness (exploration is sustainable), lower exploreSelectionPressure (exploration is performed widely through different individuals), higher exploitProgressiveness (exploitation is sustainable), and higher exploitSelectionPressure (exploitation is performed selectively on the best individuals) obtain better results in term of optimization and/or convergence.All of the above shows the capability of PPCea (with exploration and exploitation measures) toward optimization and/or convergence as well as its potentials to further inspirit more open and imaginable parameter control strategies by including also other exploration and exploitation measures (e.g., exploreSelectionPressure, exploitSelectionPressure). To the best of our knowledge this is the first adaptive parameter control approach based on exploration and exploitation measures. As such it needs additional validation on standard benchmark functions and on other real world problems. Our future work is inline with these goals.