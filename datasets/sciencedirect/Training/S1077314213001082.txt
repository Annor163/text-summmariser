@&#MAIN-TITLE@&#
Camera and light calibration from reflections on a sphere

@&#HIGHLIGHTS@&#
Estimation of multiple light directions from a single image of a specular sphere with unknown radius.Closed form recovery of position and orientation of multiple cameras observing the sphere.Estimation of camera intrinsics using an iterative approach.

@&#KEYPHRASES@&#
Light estimation,Camera calibration,Specular reflection,

@&#ABSTRACT@&#
This paper introduces a novel method for recovering light directions and camera parameters using a single sphere. Traditional methods for estimating light directions using spheres either assume both the radius and center of the sphere being known precisely, or they depend on multiple calibrated views to recover these parameters. In this paper, it will be shown that light directions can be uniquely determined from specular highlights observed in a single view of a sphere without knowing or recovering the exact radius and center of the sphere. Besides, given multiple views of the sphere, it will be shown that the focal length and the relative positions and orientations of the cameras can be determined using the recovered sphere and light directions. Closed form solutions for estimation of light directions and camera poses are presented, and an optimization procedure for estimation of the focal length is introduced. Experimental results on synthetic and real data demonstrates both the accuracy and robustness of the proposed method.

@&#INTRODUCTION@&#
The recovery of light directions is crucial in many computer vision and graphics applications. For instance, light directions can be used to infer the shape of an object using shape-from-shading [1], shape-from-shadows [2], shape-from-specularities [3] or photometric stereo [4]. Augmented reality and image based rendering techniques use the precise locations of light sources to render virtual objects into a scene realistically [5]. In medical applications, light estimates are used for quantification of skin cancer and burn scars [6]. Other applications use light sources in controlled setups for gaze estimation [7] and recognition [8]. In humanities, scholars analyze light in realistic paintings to address a number of technical problems in the history of art [9].In this paper, we describe how multiple light directions and camera parameters can be recovered from specular highlights observed on a sphere. The simultaneous calibration of both light and camera parameters from just a single calibration object results in a simple setup and an efficient solution. Neither the camera intrinsics nor the radius and location of the sphere are assumed to be known. In contrast, existing methods for estimating light directions using spheres either assume both the radii and centers of the spheres being known precisely, or depend on multiple calibrated views to recover these parameters. It will be shown in this paper that, for a given focal length, light directions can be uniquely determined from specular highlights observed in a single view of a sphere without knowing or recovering the exact radius and center of the sphere. The focal length can then be determined by an optimization procedure that employs a consistency measure on light directions estimated from images captured from at least two distinct viewpoints. It will be shown that the relative orientations and positions of the cameras can be recovered using two or more light directions estimated in each view.Preliminary results of this research have been published in [10]. This paper further extends [10] in the following aspects:•Internal camera parameters are not assumed to be known but estimated using an iterative optimization procedure.Additional theoretical details for the estimation of light direction, camera pose and sphere center are presented.The shape of specular reflection produced by a non-infinitesimal light source is studied. The error introduced by using the center of a fitted ellipse for estimation of light directions is analyzed.New experiments on real and synthetic data are presented. In particular, an augmented reality application with a detailed error analysis, an experiment for estimating different focal lengths, and an experiment for estimating the symmetric transfer error are presented.Throughout the paper, we make certain assumptions. Firstly, we assume that the outline of the sphere and the specular highlights can be extracted, and that these features are elliptical. The latter makes the former trivial as there exists a plethora of work dealing with robust extraction of ellipses [11–13]. Secondly, we assume that specular highlights can be matched between different views. In practice, we perform matching using temporal information. Thirdly, since it is difficult or impossible to estimate camera intrinsics from just a single image of a single sphere, we assume that the camera intrinsics remain constant for at least two consecutive frames in the image sequence.The rest of this paper is organized as follows. Section 2 discusses previous work on light direction estimation and camera calibration. Section 3 addresses the problem of sphere reconstruction from a single image. It will be shown that with unknown radius, a one-parameter family of solutions will be obtained with all the sphere centers lying on the line joining the camera center and the true sphere center. Section 4 briefly reviews the standard technique for recovering light directions from observed highlights on a sphere with known radius and location. It then proves that any sphere from the family of solutions recovered from a single image can be used to estimate the light directions. In Section 5.1, an iterative optimization method is proposed for recovering the camera calibration matrix; and in Section 5.2, a method for recovering the relative positions and orientations of the cameras is presented. In Section 6 the shape of specular reflections on a sphere is studied. Finally, experimental results on both synthetic and real images are presented in Section 7, followed by conclusions in Section 8.

@&#CONCLUSIONS@&#
In this paper we have described how light directions and both camera intrinsic and extrinsic parameters can be recovered from specular highlights observed on a sphere. The main contributions of this paper are.1.a closed form solution for recovering light directions from the specular highlights observed in a single image of a sphere with unknown size and location,an iterative solution to recover the focal length from multiple views of the sphere, anda closed form solution for recovering the relative camera poses using the estimated sphere, focal length and light directions.The estimation quality of both light directions and camera parameters depends on the quality of the extracted silhouettes and specular highlights. As we have shown in synthetic experiments, if the sphere silhouettes and the specular highlights cannot be accurately extracted, the camera poses and light directions would be inaccurate. Sophisticated methods for sphere silhouette and specular highlight extractions, e.g., based on temporal tracking information, should therefore be employed to ensure accurate estimations.We represent quaternions with a four vector(A.1)q̇=wxyzT,or alternatively by a sum of a real number w and three imaginary numbers x, y and z as(A.2)q̇=w+ix+jy+kz,where i2=j2=k2=ijk=−1. Note that the purely imaginary quaternionq̇=0+ix+jy+kzrepresents the vectorq=xyzT. The conjugate of a quaternion negates its imaginary partq̇∗=w-ix-jy-kz.Products of quaternions can be expressed as a multiplication between an orthogonal 4×4 quaternion matrix and a quaternionq̇ṙ=Qṙ=w-x-y-zxw-zyyzw-xz-yxwṙ,or(A.3)ṙq̇=Q∼ṙ=w-x-y-zxwz-yy-zwxzy-xwṙ.A rotation(A.4)x′=Rxcan be represented using unit quaternions (i.e.,‖q̇‖=1) as(A.5)ẋ′=q̇ẋq̇∗,whereẋis the quaternion representation of the vector x. The rotation representation using unit quaternions in (A.5) follows fromq̇ẋq̇∗=Qẋq̇∗=Q∼TQẋ, whereQ∼TQ=q̇·q̇0000(w2+x2-y2-z2)2(xy-wz)2(xz+wy)02(yx+wz)(w2-x2+y2-z2)2(yz-wx)02(zx-wy)2(zy+wx)(w2-x2-y2+z2).Ifq̇is a unit quaternion,q̇·q̇=1and the lower-right-hand submatrix ofQ∼TQis an orthonormal matrix representing the rotation. Therefore, ifq̇is a unit quaternions, (A.5) can be used to represent a rotation.