@&#MAIN-TITLE@&#
Automated detection and segmentation of drusen in retinal fundus images

@&#HIGHLIGHTS@&#
Designed a new drusen detection and segmentation method finding meaningful drusen boundaries.To find true edges of drusen, a gradient based segmentation procedure is described.Connected component labeling is applied to remove suspicious pixels from drusen region.Edge linking is used to connect all labeled pixels into a meaningful boundary to detect drusen.The performance of proposed method is evaluated by (i) statistical measures and (ii) quantification of drusen to grade severity of age-related macular degradation.The proposed work characterizes the detected drusen in small, intermediate, and large/soft to show its ability to grade age-related macular degradation severity level, helpful in early age-related macular degradation diagnosis.

@&#KEYPHRASES@&#
Drusen,Age-related macular degeneration,Segmentation,Boundary extraction,Retinal fundus images,Grading,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
Age-related macular degeneration is a chronic irreversible medical condition characterized by drusen. Worldwide, AMD is the third most leading cause of irreversible vision loss in persons over the age of 50 [1]. If it is not detected and treated in time, it may cause total blindness. There are mainly two types of AMD: dry and wet. Most of the people, around 90%, with macular degeneration are affected by dry AMD, which causes lack of functioning of visual cells due to the presence of drusen on retina [2, 3]. An increase in number of drusen is a prominent symptom of dry AMD and used as a marker to detect the risk of AMD [4]. Therefore, a new methodology for more accurate detection of drusen has been proposed in the presented work.Drusen are fatty deposits that appear as yellowish, cloudy bright blobs in retinal fundus images. They exhibit no specific size or shape [2, 5]. The modification in the size of individual drusen and their confluence indicates the development of macular degeneration disease. The severity level of macular degeneration is judged on the basis of the size of drusen and visibility of its boundaries in Wisconsin AMD grading system. The literature survey reveals that drusen can be classified as hard or soft [6] as shown in Fig. 1(a) and (b), respectively. Soft drusen are further classified as distinguishable and indistinguishable [4–6]. Hard drusen appear smaller in size with sharper definition as compared to soft drusen that have fuzzy boundaries. Therefore, the accurate identification of boundary of drusen is a challenging task.Drusen and their boundaries can be detected in retinal fundus images by trained clinicians with manual evaluation procedures [4] whereas biomedical researchers use automatic/semiautomatic methods to detect them. The automatic/semiautomatic methods proposed by several researchers to detect drusen are briefly summarized in Table 1. Mora et al. proposed drusen modeling and a gradient based segmentation approach to detect drusen [10]. They validated their method with twenty-two images and achieved a sensitivity of 68%. Bhuiyan et al. developed a drusen detection method using local intensity distribution, adaptive intensity thresholding and edge information [15]. They validated their method with twelve images and achieved a sensitivity of 74.94%. Grinsven et al. proposed a machine learning based method for AMD diagnosis. They achieved a sensitivity of 85% [16]. Prasath and Ramya proposed a method for drusen detection and validated with the dataset of forty images showing achieved results with only one performance measure. [19]. Kumari and Mittal validated their drusen detection method with thirty six images showing 95% sensitivity [20]. In a nutshell, the major limitations of existing works on drusen detection are the validation of methods on limited dataset with moderate performances in terms of sensitivity/accuracy, inaccurate drusen detection and insufficient information regarding quantification of drusen. Therefore, in the present work, a new method for drusen detection is proposed by (i) finding true edges of drusen using gradient based segmentation, (ii) removing suspicious pixels from drusen regions using connected component labeling and (iii) connecting detected edge pixels into a meaningful boundary using edge linking. The major highlights of the method are its validation on larger datasets resulting in comparatively higher sensitivity/accuracy than other methods, accurate detection of drusen boundaries with 99% specificity and categorization of detected drusen on the basis of size, area and number of drusen present in an image, contributing in early diagnosis of AMD especially through telemedicine for the people in rural areas.The method comprises of three phases: in the first phase bright regions are enhanced followed by the noise removal in the retinal fundus images; in the second phase, regions of drusen are detected by suppressing the spurious regions; in the third phase boundary of drusen is detected by the edge linking procedure. In the last, the performance of proposed method is evaluated by (i) statistical measures and (ii) quantification of drusen to grade severity of AMD.The rest of the paper is organized as follows: experiment materials for this paper are introduced, the proposed method are described in details and statistical measures to evaluate the proposed method are presented in Section 2, experimental results are showed, described and compared with other algorithms in Section 3, while conclusion is drawn in Section 4.Materials:The retinal fundus images for the present study have been taken from open-source benchmark databases that are available online. The databases used in the study are (i) Structured Analysis of Retina (STARE) [21] and (ii) Automated Retinal Image Analysis (ARIA) [22]. The STARE database comprises of 400 images and they have been acquired using Topcon fundus camera at 35 degree field of view with resolution of 700×605 pixels. The ARIA database comprises of 450 images and they have been acquired using Carl Zeiss Meditec fundus camera at 50 degree field of view with resolution of 768×576 pixels. The images containing drusen were sorted out from these databases. Thus a total of 48 images comprising of 37 images from STARE database and 11 images from ARIA database have been used in the present work.Method:The proposed method as shown in Fig. 2consists of three phases, namely (i) retinal image preprocessing, (ii) drusen candidate edge detection and (iii) boundary extraction of drusen. The steps followed in these three phases of method are explained in this section. The performance evaluation parameters and grading criterion of AMD are also explained in the later stage of this section.The retinal fundus images contain artifacts that occur during retinal image acquisition process. Retinal image preprocessing is necessary to remove these artifacts in order to improve quality of an image for easy detection of drusen. There are several factors responsible for the presence of artifacts in the image. One of them is non-uniform illumination which is responsible for the presence of intensity homogeneities and the shading artifacts in an image. Also, camera dependent factors like pixel noise and compression artifacts further degrade the image. The noise in the image may get amplified during contrast enhancement and impart a visible graininess to the image. This is highly undesirable especially in cases where the lesion characteristics are comparable to those of the artifacts produced due to noise amplification. Hence, retinal image preprocessing is essential to improve the quality of an image for easy detection of lesions. The steps involved in preprocessing are: (i) homomorphic filtering for removing artifact due to non-uniform illumination, (ii) green channel selection to have better contrast, (iii) Gaussian smoothing for noise removal.Retinal images are acquired by a digital fundus camera that captures the intensity of light reflected from the retinal surface. Several patient dependent and camera dependent factors such as the retina convex surface, the lower reflectance from macula as compared from other parts of the retina, insufficient pupil dilation, poor patient collaboration and ocular media opacities, i.e., cataract etc. add non-uniform illumination led artifacts in the image [10]. These factors responsible for non-uniform illumination across an image contribute to variation in color and result in different contrast among different regions of the same image. Therefore, homomorphic filtering is used to normalize the image background to have uniform illumination. Homomorphic filtering also enhances the image by compressing brightness range and enhancing contrast simultaneously [23]. In this approach, the image is considered as a function of the product of the illumination and reflectance which is represented as:(1)g(x,y)≈i(x,y).r(x,y)where g(x, y), i(x, y) and r(x, y) represent the image intensity sensed by camera, illumination multiplicative factor and reflectance multiplicative factor, respectively in terms of Cartesian coordinates (x, y) of the image. Both of these factors are separated by taking the logarithm on both the sides of Eq. (1) as given below in Eq. (2).(2)ln{g(x,y)}=ln{i(x,y)}+ln{r(x,y)}Since illumination varies smoothly throughout the image, therefore it is reflected in low frequency component of the Fourier transform of an image. On the other hand reflectance is associated with high frequency component of the image. Therefore in order to resolve the image into low and high frequency component, the Fourier transformation is applied on Eq. (2) as given in Eq. (3).(3)ℑ[ln{g(x,y)}=ℑ[ln{i(x,y)}+ℑ[ln{r(x,y)}=Fi(u,v)+Fr(u,v)where Fi(u, v) and Fr(u, v) are the Fourier transforms of ln {i(x, y)} and ln {r(x, y)}, respectively. The transformed image is then passed through a modified Butterworth high pass filter H(u, v) for homomorphic filtering as represented by Eq. (4).(4)H(u,v)=1−11+(u2+v2/a)nwhereu2+v2adetermines the steepness of transition slope. Hence a filtered image G(u, v)is obtained as given by Eq. (5),(5)G(u,v)={H(u,v)Fi(u,v)}+{H(u,v)Fr(u,v)}The spatial domain representation of filtered image is obtained by taking inverse Fourier transform of G(u, v) as shown in Eq. (6).(6)gHF(x,y)=ℑ−1{g(u,v)}gHF(x, y)is further enhanced by boosting the higher frequency values relative to low frequency values resulting in an enhanced image  gE(x, y).The processed color retinal fundus image  gE(x, y) consists of three channels; green, red, and blue. Amongst them, green channel is selected which is more informative and has a better contrast than the other two channels.As discussed earlier, noise at the pixel level is a major problem as it gets amplified during contrast enhancement operation. Since this noise has Gaussian distribution therefore it can be removed by using a smoothing filter such as Gaussian filter which is expressed as follows:(7)gF(x,y)=12πσ3e−(x2+y2/2σ2)Where gF(x, y) is Gaussian operator and σ is the standard deviation of Gaussian function that controls the degree of smoothening. Smoothed image gGF(x, y), as represented by Eq. (8), is obtained by the application of Gaussian filter.(8)gGF(x,y)=gHF(x,y)⊗gF(x,y)Detection of the candidate edges of drusen plays an important role in tracing the boundary of drusen. The following steps are followed for edge detection of drusen.The smoothed image  gGF(x, y), as obtained by Eq. (8), is filtered with a sobel kernel in both horizontal and vertical directions to get the first derivative of image intensity in horizontal direction (Gx) and vertical direction (Gy). From these two images, an edge gradient in terms of its magnitude, gf(x, y), and direction θ(x, y) at each pixel are found as follows:(9)∇gGF=[GxGy]=[∂gGF∂x∂gGF∂y](10)gf(x,y)=Gx2(x,y)+Gy2(x,y)(11)θ(x,y)=tan−1(GyGx)After obtaining gradient magnitude and direction, a full scan of image is performed to remove unwanted pixels which may not constitute the edge. For this purpose, every pixel is checked to ascertain whether it is a local maxima in its neighborhood in the direction of gradient or not. This is done in two steps as given below:Step 1 – The edge strength of the current pixel is compared with the edge strength of the pixels in both the positive and negative gradient directions.Step 2 – If the edge strength of current pixel is the largest, preserve the value of the edge strength else suppress the value.The application of non-maxima suppression gives the edge pixels in which many of them would probably be actual edges in the image, but some may be not due to noise and color variation across the image. In order to filter out the wrong pixels, the Canny edge detection algorithm is used. In this method, two threshold values are set to distinguish the right and wrong edge pixels. One of them is called high threshold value and the other is called low threshold value. If the gradient magnitude of edge pixels is higher than the high threshold value, they are marked as strong edge pixels. If the gradient magnitude of edge pixels is lower than high threshold value and higher than low threshold value, they are marked as weak edge pixels. If the pixel value is smaller than the low threshold value they will be suppressed. Gradient magnitude thresholding is mathematically expressed as given below:(12)T={∥∇gGF(x,y)∥≥t1definitelyanedget0≤∥∇gGF(x,y)∥<t1maybeanedge,dependoncontext∥∇gGF(x,y)∥<t0definitelynotanedgewhere t1 is a high threshold value and t0 is low threshold value. Finally, the edge obtained after thresholding is represented as:(13)E(x,y)={1,if∥∇gGF(x,y)∥>TforsomethresholdT0,otherwiseAny edge will always have varying gradient strength, i.e., edge consists of both the strong and weak edge pixels. Strong edge pixels would certainly be a part of final edge image. However weak edge pixels can be a part of true edge or they may be due to noise and color variations. To achieve an accurate result, the weak edge pixels caused from noise and color variations are required to be removed. These unwanted weak edge pixels are removed on the basis of 8-connected neighborhood pixel check. If they are connected to strong edge pixels they are considered to be a part of the edge otherwise they are discarded.The previous phase, i.e., edge detection phase is used to extract all candidate edges of drusen. Out of these candidate edges, few may be because of noise in the image. Therefore, after removal of such noisy component, remaining edges are required to be linked suitably to extract boundary of drusen. The procedure of boundary extraction of drusen is explained in this section.The detected candidate edges may be of several pixels wide due to multiple edge responses. These multiple edge responses may create incorrect edge linking. In addition, a small candidate edge component may be a true edge component or an isolated component because of noise. Therefore in this work, the unnecessary edge responses and the isolated components are removed. It has been accomplished in the following two steps:Step 1 – Image containing candidate edges is converted into binary image using global thresholding [22].Step 2 – Morphological thinning algorithm is applied on the binary image to (i) get single-pixel-wide edges and (ii) remove the isolated pixels.(14)E(x,y)⊖S=E(x,y)−(E(x,y)⊗S).The end points of edges in the edge map, obtained after edge thinning, seldom form closed connected boundaries of drusen. The required boundaries can be obtained only by proper linking of end points of edges. Therefore, the assessment of end points is required for linking the edges. This recovery of end points is performed with a set of 3×3 masks, as given below. These masks are applied to the edge map to find out possible edge links in all eight directions. The pixel, a candidate for end point, is center pixel in these masks. The mask entries indicated by ‘x’ can take any value (0 or 1) but at least one of them has a value 1 for end point recovery.[xxx010000][00x01x00x][000010xxx][x00x10x00]The endpoints of edges after recovery are labeled to minimize the incorrect linking decisions. A common label is assigned to the group of pixels that have similar features and in this way a local edge structure is assessed. The gaps in unconnected edge structures are bridged in agreement with the directionality of the endpoints.Finally, the boundary of drusen is extracted by linking the edge components using a local processing [24]. Algorithm used in local processing is as follows:Step 1 - Analyze the characteristics of pixel in small neighborhood for every point that has undergone edge detection.Step 2 – All points that are similar are linked, forming a boundary of pixels that share some common property.Step 3 – Two principle properties for establishing similarity are as follows:Edge pixels with coordinates (x0,y0) in the neighborhood of (x, y) are similar in magnitude to pixel at (x, y) if(15)|∇f(x,y)−∇f(x0,y0)|≤EEdge pixel with coordinates (x0,y0) in neighborhood of (x, y) has an angle similar to pixel at (x, y) if(16)|α(x,y)−α(x0,y0)|<AEdge pixel (x0,y0) is linked with (x, y) if both criteria are satisfied.Once the links are established, linked pixels are used as boundary of detected drusen.Performance of the proposed method is evaluated by the medically important statistical measures. These measures are briefly described below:Sensitivity is the measure of probability by which a method can detect to a dursen pixel correctly among dursen pixels. Mathematically it can be expressed as:(17)Sensitivity=TP(TP+FN)where TPrepresents the number of drusen pixels correctly classified by the method as drusen pixels and FNrepresents the number of drusen pixels which are falsely classified by the method as non-drusen pixels.Specificity is the measure of probability by which a method can detect to a non-dursen pixel correctly among non-dursen pixels and it can be expressed as:(18)Specificity=TN(TN+FP)where TNrepresents the number of non-drusen pixels correctly classified by the method as non-drusen pixels and FPrepresents the number of non-drusen pixels which are falsely classified by the method as drusen pixels.Accuracy of a method is the proportion of correctly detected drusen and non-drusen pixels among total examined pixels. Mathematically, it can be expressed as:(19)Accuracy=(TN+TP)(TN+TP+FN+FP)It is the probability to detect correct drusen pixels out of all detected drusen pixels by the method and it can be expressed as:(20)PPV=TP(TP+FP)It is the measure to evaluate a method by assessing the correlation in between the ground truth and the correct detected pixels by the method.(21)MCC=TN*TP−FN*FP(TP+FP)(TP+FN)(TN+FP)(TN+FN)A number of grading systems have been established to provide standards for ophthalmologists and researchers in reliable diagnosis and management of AMD using color fundus images [25]. These systems grade the severity of AMD by objective quantification of principle abnormalities. Among these grading systems, age-related eye disease study (AREDS) grading system is used in this work to grade the severity of AMD by quantification of drusen detected by the proposed method.Ophthalmologists usually identify and grade AMD using color fundus images by manually determining the size, number and extension of drusen, which is a tedious and time consuming task and usually prone to human error. In this work, severity level of AMD is graded by providing a reliable and accurate quantification of drusen by automated measuring the size, area and number of drusen.

@&#CONCLUSIONS@&#
