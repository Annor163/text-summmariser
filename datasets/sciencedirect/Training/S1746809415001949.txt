@&#MAIN-TITLE@&#
An advanced Kalman filter for gaze tracking signal

@&#HIGHLIGHTS@&#
A Kalman filter is used for denoising a gaze tracking signal.The location and velocity of gaze are treated as independent parameters of the model.Two alternative velocity estimators are presented.The covariance matrix of the measurement noise distribution is modified real-time.

@&#KEYPHRASES@&#
Gaze tracking,Kalman filter,Principal component analysis,Image analysis,

@&#ABSTRACT@&#
This paper considers the problem of removing unwanted noise from a gaze tracking signal real-time. The proposed remedy is a linear dynamic model for the gaze and a Kalman filter for estimating its optimal solution in closed form. The location and velocity of gaze are treated as independent parameters of the model. Two alternative methods for estimating the velocity are presented; the first is based on the difference in the subsequent eye images and the second on the PCA model and an affine mapping from the principal component space to the gaze space. The covariance matrix of the measurement noise distribution is modified real-time based on the estimated velocity. The presented filtering algorithm can be utilized with any eye camera based gaze tracker. Here, its ability to decrease noise of two published gaze tracking methods is demonstrated.

@&#INTRODUCTION@&#
As human's gaze reveals a person's focus of (visual) attention and interest, gaze tracking has a number of potential usages. Example fields include market research (e.g., how a person observes certain package), education (e.g., an expert can demonstrate where she looks while performing a professional operation), safety (e.g., how well a bus driver observes traffic while driving), and human–computer interaction (e.g., replacing a computer mouse with gaze). Gaze tracking systems usually use eye camera(s) for assessing the gaze. A reliable and well-performing gaze tracking system should have high accuracy and precision. Accuracy is defined as the average distance between the gaze point, estimated by the gaze tracking system, and the actual gaze point whereas precision is defined as the amount of fluctuation around the mean value, usually in terms of root-mean-square (RMS) value of subsequent distances [1].11In this paper, increased accuracy and precision means lower error and RMS.For instance, if gaze is used as an input for activating symbols on a display, such as entering passwords [2], a too noisy gaze signal will make the usage impractical.Various methods for improving the precision, i.e., decreasing the fluctuation have been presented. For instance, Kumar et al. [3] try to improve precision real-time by detecting saccades, using a threshold for the derivative of the signal, and smoothing fixations separately – this kind of approach is prone to errors with small saccades and smooth pursuits which are defined as the slow motion that eye makes when following a moving object [1]. Other similar methods, with differing filtering shapes, were reviewed in [4]. The Kalman filter has also been used; Ji and Yang [5] use a Kalman filter for tracking the pupil and Komogortsev and Khan [6] use a Kalman filtering directly on the gaze signal. These works, however, had no observation model for the velocity of the pupil or gaze point which leads to problems if the gaze signal contains severe noise. The method of Komogortsev and Khan [6] was outperformed by other methods in the comparison of Špakov [4] in terms of accuracy and precision.This paper presents a well-founded Kalman filter based solution for smoothing the gaze signal, recorded with any (video-based) gaze tracking device. The model has observation models for both location and velocity of the gaze point. For best performance, the location and velocity measurements should be independent. Here, two methods for estimating the gaze velocity are presented. The simpler one uses the pixel-wise difference between subsequent eye images as the amount of change. The other method constructs a principal component based model between the eye image and gaze point; this method can also be used as such for a coarse but lightweight robust gaze estimator. The covariance matrix of the measurement noise is modified real-time so that there would be less filtering during saccades than during fixations. The results show that the presented solution gives a manyfold increase in the precision when applied to the signal of two published gaze tracking methods.

@&#CONCLUSIONS@&#
