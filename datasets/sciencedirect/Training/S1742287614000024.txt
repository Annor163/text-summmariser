@&#MAIN-TITLE@&#
Blind Image Steganalysis of JPEG images using feature extraction through the process of dilation

@&#HIGHLIGHTS@&#
Focuses on Blind Steganalysis of JPEG images through the process of dilation.The process of dilation includes splitting of given image into RGB components.It is followed by transformation of each component into three image domains.The proposed process of dilation was tested on the trained SVM classifier.Overall Success Rate (OSR) was chosen as the metrics for performance evaluation.

@&#KEYPHRASES@&#
Blind Image Steganalysis,Dilation,Steganography,Feature extraction,Frequency,Spatial,Wavelet,

@&#ABSTRACT@&#
The detection of stego images, used as a carrier for secret messages for nefarious activities, forms the basis for Blind Image Steganalysis. The main issue in Blind Steganalysis is the non-availability of knowledge about the Steganographic technique applied to the image. Feature extraction approaches best suited for Blind Steganalysis, either dealt with only a few features or single domain of an image. Moreover, these approaches lead to low detection percentage. The main objective of this paper is to improve the detection percentage. In this paper, the focus is on Blind Steganalysis of JPEG images through the process of dilation that includes splitting of given image into RGB components followed by transformation of each component into three domains, viz., frequency, spatial, and wavelet. Extracted features from each domain are given to the Support Vector Machine (SVM) classifier that classified the image as steg or clean. The proposed process of dilation was tested by experiments with varying embedded text sizes and varying number of extracted features on the trained SVM classifier. Overall Success Rate (OSR) was chosen as the performance metric of the proposed solution and is found to be effective, compared with existing solutions, in detecting higher percentage of steg images.

@&#INTRODUCTION@&#
Steganography is the art of hiding a message in a carrier. Earlier this technique was used by kings for sending any private message by embedding it in the messenger's body parts. Today, this art of hiding has turned digital, hence the term digital image steganography. Various algorithms have been developed over the years for hiding the message into the digital image (The resultant image is then called as Steg Image.) This art has also become a challenge for the human as it could be used for illegal activities such as terrorism. Terrorists use this art for sending their messages to various parts of the world through internet without being noticed. Hence a dire need arises for a counter technique to detect such steg images which is known as Digital Image Steganalysis.Digital Image Steganalysis is the technique only for the detection of any message in a digital image. Extraction of message is a part of Cryptanalysis. There are two types of Steganalysis: (a) Targeted or Specific and (b) Blind or Universal. Targeted Steganalysis refers to the technique of identifying the Steg image where the Steganography algorithm used for hiding the message is known, whereas, in case of Blind Steganalysis, the steganography algorithm is unknown. Hence it becomes most difficult to identify. JPEG images have been the most commonly exchanged image format over internet. This paper focuses on the Blind Image Steganalysis and proposes a technique for identification of any JPEG image as steg or clean image.The rest of the paper is organized as follows: Section 2 discusses the existing solutions. Motivation is discussed in Section 3. Section 4 discusses the proposed technique, experiments conducted, and their results. Finally, the paper is concluded in Section 5.In Fridrich et al. (2000), LSB embedding is detected by the presence of many close pairs. Detection of gray scale steg images was proposed in Fridrich et al. (2001). Further, the message length was derived by forming three groups, viz., regular, singular, and unusable. Detection of audio steganography was proposed in Dumitrescu et al. (2003) based on some statistical measures of sample pairs that are highly sensitive to LSB embedding operations. Steganography algorithm, F5 (Westfeld, 2001), was attacked in Fridrich et al. (2003a) and message length was determined using distinguished statistical quantities, such as T, that correlate with the number of modified DCT coefficients. F5 with very low embedding in gray scale images was detected in Cai et al. (2005).The detection of EzStego (Machado) steganography technique in palette images (GIF image), using pair analysis was done in Fridrich et al. (2003b).All these algorithms assumed that the steganography algorithm was already known. The image format used in most of these techniques was bmp.Detection of a steganography along with watermarking was done in Avcıbas et al. (2003) by identifying the image quality metrics with the help of Analysis of Variance (ANOVA) (Rencher, 1995) technique and building a feature set which is passed to multivariate regression classifier used to classify the images as steg and clean. Training and testing has been done on bmp images with known LSB steganography techniques such as Steganos (Steganos II Security Suite), Stools (Brown) and Jsteg (Korejwa). The steganalysis technique works only on LSB embedding steganography techniques.In Shi et al. (2005), steganalysis technique was proposed in which features from gray scale bmp images were extracted using the moments of characteristic functions in subbands of the wavelet transformation of image which was then trained and tested using a neural network classifier. These images used for training and testing were embedded with five known steganography techniques, viz., non-blind SS (Cox et al., 1997), blind SS (Piva et al.), block SS (Huang and Shi, 1998), generic QIM (Chen and Wornell, 1998), and generic LSB. This work was extended in Zhang and Zhong (2009) which measured all the 78-dimensional features with the help of F-score feature selection method, selected one threshold value, and dropped those features which have F-scores below that value. Choosing of suitable threshold is a difficult task as the results may vary for different steganography algorithms.A technique for detecting additive steganography or LSB matching (Holotyak et al., 2005) with features extracted from an estimated stego signal, obtained in wavelet domain, using model based approximation of stego image pdf was proposed in Mielikainen (2006). The features from gray scale images were then trained and tested with linear classifier.The steganalysis methodology in Luo et al. (2011) provides a comparison between two most commonly used statistical features, viz., Characteristic Function (CF) and Probability Density Function (PDF) moments, in Blind Steganalysis and gives a theoretical and practical analysis on feature selection and extraction.Though a very good effort has been made in this field of steganalysis, still there are some areas unexplored. The above algorithms, in spite of their advantages, have some flaws. The proposed algorithm is an attempt to cover the less explored area of combining RGB with feature extraction in three domains of JPEG image.The concept of image calibration to obtain the statistics of the DCT coefficients has been proposed in (Fridrich, 2005). This technique has been used in our dilation process after decomposing the image into RGB components. The statistics in spatial, frequency, and wavelet domains are obtained and statistical feature values are calculated. These features are extracted from various sets of images, each set being prepared with well known steganography algorithms. Then all the features are put together for training in SVM classifier to get a trained model. Test images are compared with the trained SVM model and get classified as steg or clean image.The block schematic of the proposed technique is given in Fig. 1. Let the JPEG image be denoted as I, spatially transformed image as STI, calibrated spatially transformed image as CSTI, calibrated JPEG image as CFTI (I′), wavelet transformed image as WTI, and the vertical, horizontal, and diagonal wavelet components as VHD.Any given JPEG image has to be first split into three RGB components and then each component passes through the following feature extraction and classification algorithm using SVM:Feature extraction and classification algorithm using SVMStep-1: Divide the given JPEG image I into 8 × 8 DCT blocksStep-2: Perform the spatial transformation over I to obtain STIStep-3: Crop the image STI by 4 × 4 from all the sides to obtain the calibrated image CSTIStep-4: Perform the 2-level wavelet transformation over STI and CSTI to obtain VHD at each level.Step-5: Perform the frequency transformation on CSTI to obtain the image I′.Step-6: Extract the frequency domain statistics from I and I′ as follows:a.Find the mean, variance, skewness, and kurtosis of I and I′Find the global histogram of AC coefficients of IFind the histogram of AC coefficient differences between adjacent DCT blocks of IFind the co-occurrence matrix of coefficients in the same location between I and I′Find the co-occurrence matrix of coefficients at all locations along the diagonals of DCT blocks between I and I′Find the global histogram of AC coefficients at all locations along the diagonals of DCT blocks of IFind the histogram of adjacent pixel differences along the boundaries of DCT blocksStep-7: Extract the spatial domain statistics from STI and CSTI as follows:a.Find the mean and variance of STI and CSTIFind the co-occurrence matrix of adjacent pixel differences in STIFind the co-occurrence matrix of pixel values in same location in STI and CSTIFind the co-occurrence matrix of adjacent pixel value differences in same location between STI and CSTIStep-8: Extract the wavelet domain features from the VHD as follows:a.Find the mean, variance, skewness and kurtosis of VHD of level-1Find the mean, variance, skewness and kurtosis of VHD of level-1Step-9: Calculate the features from the statistics obtainedStep-10: Insert these features in the trained SVM classifierStep-11: Output the result (steg or clean Image)The features are calculated from the three popular domains, spatial, frequency, and wavelet, for each image component. The statistics in each domain are obtained and then features are calculated from it.The equations of Li et al. (2010) are used for computing the co-occurrence matrices and histograms for obtaining the statistics in spatial and frequency domain. Mean, variance, skewness, and kurtosis (Flannery et al., 1986–1992) are obtained using equations (1)–(4):(1)MeanM=∑i=1M∑j=1NF(i,j)M×N(2)VarianceV=1MN−1∑i=1M∑j=1N(F(i,j)−M)2(3)SkewnessS=1MN∑i=1M∑j=1N[F(i,j)−MV]3(4)KurtosisK={1MN∑i=1M∑j=1N[F(i,j)−MV]4}−3where, F is the particular image statistics matrix and (M, N) gives the size of the matrix FThe statistics in Frequency domain or DCT domain are obtained by dividing DCT coefficient matrix of images I and I′ into 8 × 8 DCT blocks. A DCT block is filled along the diagonal and the values after the half of the center diagonal are null or zero. All the values above the center diagonal are considered. The locations other than the shaded part in Fig. 2are to be considered as one of the statistics along with other statistics as described in Table 1.A total of 36 × 3 = 108 statistics are obtained from frequency domain.For extracting the statistics in spatial domain, the decomposed image pixel values in STI and CSTI are used. Table 2shows the statistics obtained.A total of 7 × 3 = 21 statistics has been obtained from Spatial domain.Two-level wavelet decomposition for each of the RGB image components is performed as shown in Fig. 3. V, H, and D are the vertical, horizontal, and diagonal wavelet components respectively. The first order statistics obtained from each wavelet component in each level of the wavelet decomposition are given in Table 3.Finally, there are 4 (number of statistics) × 3 (number of wavelet components) × 2 (number. of levels) = 24 wavelet statistics from the wavelet decomposition of STI. Similarly from the calibrated image CSTI, the same 24 statistics are obtained. Totally, 24 + 24 = 48 wavelet statistics have been obtained. Considering the RGB color components a total of 48 × 3 = 144 wavelet statistics are used in this paper.Center of Mass (COM) is calculated as a feature using the equation (5) for statistics with histograms and co-occurrence matrices:(5)COM(I)=∑i=1M2∑j=1N2F(i,j)*fft2(F(i,j))fft2(F)where, F is the particular image statistics matrix, (M, N) gives the size of the matrix F, and fft2 gives the discrete fourier transform (DFT) for a two dimension vector.For other statistics, the statistic obtained itself is taken as a feature.A COM value should provide the uniform distribution of values over a particular matrix. When a particular image statistic value is multiplied by its Fourier transform and divided by overall Fourier transform, it yields a value which is uniformly spread over a matrix. Thus, this equation helps us to reduce the 2-dimensional matrix to a single value without disturbing its characteristic. As DFT is central symmetric, for a DFT sequence with length N, the value of COM needed to be calculated in the range [1, N/2]. Thus, a 103 × 3 = 309-dimensional feature vector has been formed in this paper.

@&#CONCLUSIONS@&#
