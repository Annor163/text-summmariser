@&#MAIN-TITLE@&#
Analysis of fraudulent behavior strategies in online auctions for detecting latent fraudsters

@&#HIGHLIGHTS@&#
A systematic method is developed to discover the fraudulent strategies in online auctions.A strategy is represented by a series of status transitions to provide better insights.Four types of fraud and 29 strategies are discovered.Status identification improves understanding the insights of auction fraud.A two-way status monitoring method is proposed to detect well-camouflaged fraudsters.

@&#KEYPHRASES@&#
Early fraud detection,Behavior fluctuation,Clustering,Online auction,E-commerce,

@&#ABSTRACT@&#
Online auction fraudsters constantly monitor the contextual situations of the auction and change their behavior strategies accordingly to distract the attention of their targets. This flipping of behavior makes it difficult to identify fraudsters. Thus, legitimate traders need appropriate countermeasures to avoid becoming victimized. To help online auction users detect fraudsters as early as possible, this study develops a systematic method to discover the fraudulent strategies from proven cases of online auction fraud. First, according to the results of cluster analysis on the proven fraudsters, four typical types of fraud are identified, which are Aggressive, Classical, Luxury and Low-profiled. To provide better insight, a strategy is further represented by a series of status transitions. Hidden statuses of latent fraudsters are discovered by applying X-means clustering to the phased profiles of their transaction histories. As a result, various strategies can be extracted by such a systematic method and interesting characteristics are found in these strategies. For example, about 80% fraudsters in the Yahoo!Taiwan auction site flip their behavior no more than two times, which is not as complicated as expected originally. Based on these discovered fraudulent statuses, a high-resolution fraud detection method is performed to classify suspects into legitimate users or fraudsters in different statuses, potentially improving overall detection accuracy. A two-way monitoring procedure is then proposed to successively examine the statuses of a suspicious account. Analysis shows that the two-way monitoring method is promising for better detection of well-camouflaged fraudsters.

@&#INTRODUCTION@&#
Online auctions have become more profitable over the years, largely because such activities are not constrained by limited business hours and physical store locations. Moreover, the trading volume of online auctions increases as new trading opportunities emerge. For example, eBay, the largest worldwide auction site, posted US$ 11,651,654 in revenue for 2011 (eBay Inc. 2011), which significantly demonstrates the success of online auction business model. However, more trading disputes are inevitable with this higher trading volume, with fraud being the most threatening for users. With the anonymity and convenience that are part of the Internet environment, online auction fraudsters do not need to face target victims in person to complete their schemes. In addition, fraudsters often adjust their tricks as markets and situations change (Kaszuba et al. 2010, pp. 31–37), making it difficult for legitimate users to avoid fraudulent schemes. According to statistics of National White Collar Crime Center (NW3C) (2009, 2010), Internet auction fraud accounted for 25.5% of referred complaints in 2008, showing the seriousness of online auction fraud. While the number of reported complaints has declined in recent years, cases of online auction fraud are still listed among the top ten Internet complaints reported (NW3C 2011, 2012). The statistics imply that fraudsters now use fewer cases of schemes while increasing the dollar amount of the schemes and their success rate.Fraudsters change their behavior statuses to perform specific tricks at particular moments to defraud innocent traders in online auctions. For example, a fraudster posing as a seller generally sells a large number of low-priced items in order to earn positive feedback at a minimal cost. After accumulating a high feedback score, he begins shelving high priced items. Once he sells one or more high-priced items and receives the transferred funds, the fraudster disappears immediately and never delivers the items. Obviously, online auction fraud is not a one-time act, resulting from a sequence of actions across the lifespan of a fraudster. In fact, after performing a given sequence of events, a fraudster may camouflage himself, staying in a particular status. For instance, a fraudster could complete a series of low-priced transactions to put himself in a status which contains high feedback scores, high trading density, and low average prices. In such a state, it may be easier to attract other members to trade with him. More complicated fraudulent behavior can be formulated by a series of statuses, which is achieved through the use of a series of camouflaged actions. Obviously, legitimate traders would have more difficulty recognizing these cunning tricks.To prevent fraud, most online auction houses implement simple reputation systems so that participants can evaluate potential trading partners. The reputation system used by eBay and Yahoo! Taiwan is a binary reputation system, which allows trading partners to leave positive rating or negative feedback ratings about the other trader after completing a transaction. The feedback received determines a member’s accumulated score and his estimated reputation (or credibility) in the virtual society of the online auction site. In addition, the auction site will periodically report the backlist or suspended list to deter dishonest traders from committing fraud. And, general guidelines for fraud prevention will be announced for inexperienced traders. To enhance the reputation system, eBay further provides an extra-detailed rating mechanism to evaluate a seller (eBay Inc. 1995), which allows the buyer to leave feedback score for the obtained services such as ‘item as described’, ‘communication’, and ‘shipping time’. In spite of these strong attempts by authorities of the auction sites, smart fraudsters constantly evolve their tricks to avoid detection.Several deficiencies exist in such a simple reputation calculation method. For example, fraudsters can use fake personal information (or simply steal others’ identities) to create multiple accounts to form a criminal syndicate. These accomplice accounts then initiate false trades and leave positive ratings for one another to accumulate high ratings during a very short period of time (Wang and Chiu 2005). In general, it is difficult to recognize a potential fraud through instinct only, especially if one is considering an account with a high reputation score. As a result, a less experienced trader can easily become a victim in spite of the reputation system. Therefore, researchers propose different methods of detecting online auction fraud to assist traders identify suspicious accounts (Pandit et al. 2007, Ku et al. 2007, Chang and Chang 2009).To develop an effective fraud detection method, an appropriate measured attribute set is needed to describe or extract the characteristics of traders’ behavior. In addition, a suitable learning method is also needed to build the detection model from the extracted data. Chau and Faloutsos (2005) proposed a set of price-related attributes and applied classification trees to construct their fraud detection method. In a different approach, Chang and Chang (2011, pp. 11251–11252)adopted several feedback-related attributes and incorporated them with classification and instance-based learning methods to improve fraud detection accuracy. To consider early fraud detection, Chang and Chang (2009, pp. 744–745) also proposed a hybrid-phased modeling method to detect latent fraudsters. In the case of organized fraud, social network analysis can be applied to extract the relationships among traders and help identify accomplices (Wang and Chiu 2005, Ku et al. 2007). Kobayashi and Ito (2007a, 2007b, 2008) visualized the networking relations using graphs theory to help users identify unusual partner relationships.Even though these proposed fraud detection methods provide some degree of satisfaction, problems still remain. First, these detection methods produce a binary result, fraudulent or legitimate. However, fraud detection systems are often prone to misjudgment and may miss schemed and camouflaged fraudsters. This is because fraud is not just a result but a process. Examining the final (accumulated) status of a suspicious trader at a particular moment is not enough to detect a well-camouflaged fraudster. The behavior flipping of suspicious traders needs to be carefully investigated to identify these cunning fraudsters and increase the overall accuracy of detection processes. Second, behavior granularity and resolution also need to be improved in fraud detection outcomes. At present, when cases are erroneously classified (i.e., a legitimate trader is misjudged as a fraudster and vice versa), the developers of detection methods do not have enough information to deal with these missed targets. Finally, for the purpose of fraud prevention, it is more important to discover a latent fraudster before the fraud is activated. That is, it would be better to report potential fraud before legitimate traders are victimized. For this purpose, the suspect could be continuously monitored and not just looked at as part of a one-time detection process.Based on the above discussions, it can be seen that a more elaborate and effective mechanism is needed to uncover fraudulent strategies and detect online auction fraudsters as early as possible. To this end, this study identifies four typical types of fraudsters by applying cluster analysis to the proven fraudsters, which are Aggressive, Classical, Luxury and Low-profiled. To provide better insight, the fraudulent strategies are extracted by examining the transaction histories of proven fraudsters.1These proven fraudsters in this study were gathered from the official announcement, known as the blacklist, of the online auction site of Yahoo!Taiwan.1A fraudulent strategy is defined by a series of status transitions, in which hidden statuses of latent fraudsters are induced by applying X-means clustering to their phased profiles. This process extracts 29 sequences and identifies several interesting characteristics. For example, about 80% fraudsters in the Yahoo!Taiwan flip their behavior no more than two times, which is not as complicated as expected originally. Furthermore, most fraudsters will keep their initial status at the end of their frauds, even after flipping their behavior several times. Based on these discovered fraudulent statuses, a higher-resolution fraud detection method can be performed, which classifies latent fraudsters into different groups and potentially improves the detection of specific types of fraudsters. Subsequently, for well-camouflaged fraudsters, a two-way status monitoring procedure is proposed to successively examine the statuses of a suspicious account. Analysis shows that the monitoring method is promising for better detecting well-camouflaged fraudsters.The rest of this paper is organized as follows: preliminary information and a literature review are presented in the second section. The third section presents how to observe fraudulent flipping behavior using clustering techniques. Analyses of fraudulent behavior are discussed in the fourth section. The fifth section presents the experimental results of a new early fraud detection method using behavior statuses identification. The final section offers conclusions and suggestions for future work.The concepts and techniques related to this study are introduced in this section. First, the features of online auction fraud are depicted. Next, the measured attributes of fraudulent behavior identification applied are discussed. Subsequently, the phased profiling technique is introduced to simplify the discussions in the rest of the article. Finally, we introduce the X-means clustering technique used in this study.To handle transaction disputes and prevent fraud, the online auction sites have developed their own reputation systems to assist their members in selecting proper trading partners. In general, these reputation systems can provide some degree of protection for trading partners. However, cunning fraudsters can always find various ways to attack the reputation systems. Jøsang and Golbeck (2009) summarized nine different types of attacks and stressed the necessarity of designing a robust reputation system. Hoffman et al. (2009) provided a survey for attack and defense techniques for reputation systems. Five classes of attacks are identified and possible defense strategies are discussed as well. More specifically, their work contributes to an understanding about which components of a reputation system are most vulnerable and how to integrate the proper defense techniques into the existing reputation systems. When discussing the robustness of existing reputation systems, Jøsang (2012) found two interesting phenomenons: albeit not robust, a reputation system might provide an incentive for good behavior if the participants believe that it works. In addition, the reputation system may work effectively if it can react to the bad behavior swiftly. However, malicious manipulations of a reputation system should be prevented with proper technical mechanisms which can detect and block these attempts.Chua and Wareham (2004, p. 32) categorized Internet auction fraud into eleven types. Although the exact features of each type of fraud are not defined (Goes et al. 2009), the summary description of these frauds is given in their work. For example, a fraudster may never send the goods after he receives remittance from the buyer. He may also exaggerate the description of an item under bid or place fake photos to bias the buyer’s decision. Furthermore, some sellers can collude and execute shilling or bid shielding to raise the selling price while increasing their feedback scores. Gavish and Tucci (2008, pp. 89–97) investigated the methods that swindlers use to appear legitimate, such as selling cheap items, taking advantage of pooled mutual feedback ratings, changing seller ID, changing terms, changing location, and phishing. In fact, from the observations on the uncovered frauds in the recent years, smart fraudsters even can set complicated traps after obtaining a buyer’s private information. In addition, these tricks evolve year by year as fraudsters try to avoid discovery.Fortunately, all online auction activities are recorded in transaction histories, which include a sequence of events and behavioral reactions for each account such as mutual ratings, starting-bids, bid increases and setting bidding prices. Transaction histories record not only the results of both legitimate deals and frauds; they can also provide additional information, such as when a deal is not started but not completed. Since aggressive and unusual behavior happens before a fraud occurs, experienced traders scrutinize transaction histories to look for clues of unusual behavior prior to making trading decisions (Chau and Faloutsos 2005). Feedback comments, in particular, can influence the transaction probability and the price materially (Pavlou and Dimoka 2006). Meanings between lines from text feedback comments are helpful in making judgments. However, positive feedback comments of a fraudster could be fabricated. It is difficult for naïve users to avoid misjudgment. Furthermore, because fraudsters vary their behavior and invent new tricks as circumstances change, it is more difficult to recognize fraudulent behavior simply by looking at transaction histories. Most fraudsters react to the behavior of their target; as a result, each fraudster activates his scheme at the specific point that is most suitable for him. Intuitively, behavior before the break point would be significantly different than the activities after the fraud is activated; however, real world fraudulent activities can be quite sophisticated. Aggressive activities from fraudsters will make trading counterpart retreat, so fraudsters have to suspend their attack events to distract their targets. Therefore, the timing of a fraudster flipping his behavior will fluctuate, depending on the situation. This is especially true when a fraudster is about to activate a fraud.As a matter of fact, most trading participants do not inspect the entire transactional histories of potential trading partners. When trading participants only scan partial histories, fraudsters do not need to make much effort to disguise their past notorious behavior; they can focus instead on raising the most recent transaction details. If an automatic detection system could collect all proven fraudulent features, it could assist trading participants in filtering fraudsters. However, shrewd fraudsters are aware of the existence of fraud detection systems, so they constantly modify their behaviors to avoid detection. For example, a fraudster can create several fake accounts and fool the legitimate users through role playing. If a fraudster sees any sign of being detected, he can immediately change the style of role playing to camouflage his intention. When cases of fraud are committed by a group of accomplices, the transaction histories still can hold many clues. Unfortunately, most of those recorded trails are difficult for users to recognize. Thus, interpreting clues in the transaction histories of online auctions is a major method of detecting fraudulent behavior.Abstracting the details of the transaction histories to characterize target accounts is one of the most important steps in fraud detection. It is helpful to devise a measured attribute set to describe the features of transaction histories. Given an attribute set A={a1, a2,…,am}, the transaction history of account U can be summarized as a vector V(U, A)=(v1, v2,…,vm), where viis the value related to the ith attribute that is extracted from the transaction history. For example, if A={Count_Negative_Rating, Average_Selling_Price, Buy_to_Sell_Ratio}, then V(U, A) could be (2, $65, 8%) which indicates that, in the transaction history of U, there are two negative feedback ratings, the average prices of U’s sold items are $65, and the ratio of number of buying to selling is 0.08 (implies U could be a seller). If exist another instance being represent by (3, $77, 9%), the distance to the point of (2, $65, 8%) can be calculated in vector form. The use of more attributes can deal with multiple dimensional problems in a vector (Han and Kamber 2007). Intuitively, not all measured attributes have similar effectiveness in fraud detection. For example, Ratio of Positive Ratings would be more effective than Count of Positive Ratings in discovering fraudsters. Because fraudsters use sophisticated camouflage skills, various combinations of multiple measured attributes are needed to help distinguish fraudsters from legitimate users.For this purpose, a variety of measured attributes sets for fraud detection have been proposed in previous work (Wang and Chiu 2005, Kobayashi and Ito 2007a, Chandola et al. 2009, Chau and Faloutsos 2005). Chau and Faloutsos (2005) proposed 16 priced-related attributes to figure out the abnormal behaviors of fraudsters by examining items’ close-price. Price-related attributes are obvious but are not sufficient to capture all types of fraud. Moreover, some quasi-fraudulent behavior could be misidentified as fraud when applying only price-related attributes. For example, some legitimate traders always set the concluding prices unrealistically low to save surcharges, which could be identified as abnormal. Using a different approach, Chang and Chang (2009; p. 746; 2012; p. 355) devised a set of feedback-related attributes to stress the importance of how the feedback scores were obtained. To detect organized crime, network-related attributes were also proposed to discover unusual structures in the trading network (Wang and Chiu 2005), using network analysis to identify reputation inflation.A combination of individual high-performing attributes might not result in superior performance (Peng et al. 2005), which suggests that a larger attribute set is not always beneficial for fraud detection. In fact, too many measured attributes could result in misleading the search process of the learning algorithm. Therefore, removing the fuzzy and noisy attributes from the measured attributes set is helpful in making rule analysis and justification simpler (Dash and Liu 1997, Hall and Smith 1999, Zhong and Dong 2001, Yu and Liu 2004). More attributes imply more effort on data collection and information extraction (i.e., computation effort). It would be better to use one single measured attribute to differentiate legitimate traders from fraudsters. However, it is hardly practical to apply in real applications because existent fraudulent tricks are getting complicated. To decrease the number of measured attributes while maintaining a high level of accuracy in fraud detection, Chang and Chang (2012, p. 355) selected ten most appropriate attributes for early online fraud detection based on using several evaluators to test a variety of integrated attribute sets (see Table 1). Appendix A contains the definitions of the ten measured attributes and information about how they are calculated. Seven of the ten attributes are rating-related attributes that focus on describing contextual relationships among attributes instead of individual features in the transaction history. Experiments show that these attributes could be as effective as a large attribute set in detecting fraud. Thus, the ten selected attributes will be applied in the experiments of our work. And, the behavior status of a trader will be represented by a vector containing corresponding attribute values.The lifespan of a fraudster consists of a latent period followed by an execution period. The break point divides the transaction history of a fraudster into two periods at which the fraudster officially activates his attack resulting in account suspension. In the latent period, fraudsters camouflage themselves through various tricks, e.g., buying a large number of low-price commodities. In the execution period, fraud is executed by setting traps to attract legitimate traders. It is not easy to detect a latent and well-camouflaged fraudster by investigating his current state, because his behavior status may change. Fortunately, even though a fraudster always remains quasi-legitimate status in the latency period, sometimes, there are some features of unusual activities occurred in his transaction history. Thus, if someone was able to carefully examine the behavior change of a suspicious account in his lifespan, the chance of discovering fraud would be greatly increased.To describe the fraudsters’ behavioral changes in their latent periods, Chang and Chang (2009; pp. 744–745; 2010; p. 187) propose a phased profiling method which partitions the transaction history of a suspected account into regular segments. The phased profile of a trader is obtained by selecting a part of his full transaction records according to the assigned phase (the details of phase profiling please see Appendix B). For example, for the 85%-phased profile of the trader is gathered from the transaction records in his 0–85% of lifespan. As a result, an r% fraud detection model (such as decision trees) can be constructed by learning from a set of r%-phased profiles derived from the complete transaction records (Chang and Chang 2010, pp. 58–59). In addition, profiles in different phases can be mixed and used to generate hybrid phased models for more effective detection for latent fraudsters (Chang and Chang 2011, p. 11251).In phased profiling, the cutoff point of the partitioning of transaction histories determines the features and effectiveness of the resultant phased model for fraud detection. In practice, we never know in which phase a suspect is stepping, so we can apply all possible phased r% models (e.g., 50%-, 51%-, 52%-…model) to examine this suspect until an appropriate model occurs. However, such an enumeration is not cost-effective for fraud detection. In addition, fraudulent behaviors can overlap (Chang and Chang 2010). Every fraudster activates his scheme in terms of individual situations, resulting in different break out points. As a result, a fraudster staying in his 80% of lifespan could be identified by a 90% phased-model and vice versa. Therefore, hybrid phased models are proposed by Chang and Chang (2011) instead of a fixed cutoff point for building a detection model. It has been observed that most fraudsters activate their schemes after stepping into phase 95%, which indicates that features occurring in prior phases are more important when identifying potential fraudsters (Chang and Chang 2012). That does not imply that we need more prior data to build detection models. For the purpose of camouflage, fraudsters usually have clean records in the early stages of his lifespan. Thus, transaction records in prior early-phase (say 80%) would be not helpful for identifying fraudsters in real applications. In addition, the value of each measured attribute is a result of accumulation. That is, if r1⩾r2, then the r1% phased profile will accumulate all the features embedded in all the r2% phased profile. For example, the 85% phased profile of a trader would contain the features exhibited in his 1%, 2%,…, 84% phased profiles.Ideally, cutoffs and increments can be set at any point and at any length. According to the research of Chang and Chang (2011), fraudsters seldom exhibit their intentions before they’ve reached the 80% point of lifespan. Thus, we choose 80% as the starting points of phased profiling to reduce the computation complexity. Certainly, since phased profiling is extracted in a cumulative way, 80% phased profile will contain the features in the earlier phase (such as 79% and 78%). In phased profiles, a small increment of only 1% or 2%) would not be enough to observe a significant change in a fraudster’s behavior. According to the experimental results presented in the previous work, models built with 5%-increment phased profiles can detect fraudsters accurately while maintaining a reasonable computation effort. Thus, we also choose 5% as the increment. In fact, such a decision is also informally inspired by the level of significance used in statistics, which is generally set to be 0.05 in many applications.Based on phased profiling, Chang and Chang (2009, 2010, 2012) suggest that the behavior of proven fraudsters can be depicted by statuses in successive phases such as phase—80%, 85%, 90%, 95% and 100%. Next, for a given set of accounts US, the multiple- or mixed-phased behavior models can be constructed by applying various learning algorithms (such as classification trees) to profile US. For instance, a phase-85% behavioral model, M(US, 85%), is constructed by using the transaction histories {H(U, 85%)|U∊US} as input. If hybrid phased modeling is considered, then the input of learning would be {M(US, r%)|r∊{80, 85, 90, 95, 100}} for detecting possible behavior statuses (Chang and Chang 2011). According to reported experimental results, the phased profiling method is actually helpful to understand and simulate the contextual situations of a fraud from an earlier period.Fig. 1shows possible patterns of behavior changes in successive phases for different fraudsters. For the sake of simplicity, only one attribute (ex. AvgSellPrice) is used to describe the behavioral status in this example. It can be seen that Fraudster A increases the degree of the attribute (i.e., the attribute value) continuously before reaching 85% of lifespan (see green line). When stepping into the last 15% lifespan, his average selling price remains the same. Such a phased behavior change could result from the need to raise success rate. Similarly, the other three fraudsters show various kinds of status change in different phases. It is worth noting that if only the final status (phase 100%) is examined, there is no difference among the four fraudsters. However, when changes in phased behavior are considered, we can clearly identify the diversity of behavior patterns, which will be beneficial in developing proper methods to cope with different kinds of fraudsters. In the following sections, we will use phased profiling to help analyze and discover types of fraud.To help understand how behavior changes over a fraudster’s lifespan, the phased profiles of known fraudsters are analyzed by using X-means clustering (Pelleg and Moore 2000, pp. 727–734) to find representative behavioral patterns. Clustering is an unsupervised technique used to partition the instances of a given data set into groups, with each group containing instances that exhibit similar characteristics. For some applications, this approach offers some advantages over supervised learning approaches (Witten et al. 2009; Panda and Patra 2009). One of the main benefits is the ability to identify the connections that are grouped to form a new cluster. Therefore, the unsupervised learning capability of clustering techniques can be used to discover patterns that might otherwise be missed and is particularly useful in extracting information from various multi-dimensional datasets (Kumar and Wasan 2010, pp. 314–318).In clustering, an arbitrary instance x is described by a feature vector 〈a1(x), a2(x),…,an(x)〉 where n is the number of attributes (variables) used to describe an instance and ar(x) denotes the rth attribute value of instance x. As a result, all instances can be matched to points in the n-dimensional space Rn. And, the similarity of two instances, d(xi, xj), can be defined in terms of the standard Euclidean distance, whered(xi,xj)≡∑r=1n(ar(xi)-ar(xj))2(Michelle 1997, p. 232). Obviously, the larger the distance is, the lower the similarity between the two instances.Clustering can be performed in different ways with different criterions. K-means (MacQueen 1967) is one of the classic clustering techniques that uses an iterative distance-based algorithm. For a given cluster number (i.e. K), K centroid (i.e., the group center) is arbitrarily chosen and each instance is assigned to its closest center. Then, new centroids of each group are re-calculated according to these characteristics of group members. Iteration is continued until the same points are assigned and each cluster center has stabilized (Peng et al. 2005). Although K-means clustering is a popular technique in data mining, it has problems that need to be resolved. First, users have to determine the K parameter prior to clustering, as cluster centers for the algorithm are prone to the problem of local minima (Pelleg and Moore 2000, pp. 723–725). Unfortunately, prior knowledge about the number of clusters is often unavailable in many applications (Moser et al. 2007), so choosing an optimal K is a problem. In addition, K-means suffers a shortcoming of poorly-scaled computation.To alleviate the problems involved with using the K-means approach, an X-means algorithm (a variant of K-means) was developed to automatically figure out the optimum number of clusters to fit the dataset (Karahoca et al. 2008). The user does not need to assign a fixed K, but rather a range of K to search, in which the lower bound and upper bound of K are defined. X-means starts with an initial clustering with a K equal to the lower bound and continues to add centroids where needed until the upper bound is reached. During this process, the centroid set that achieves the best score is recorded and used in the final output (Pelleg and Moore 2000, pp. 729–730). The score of a clustering structure (say dividing the data set into three groups with three specific centroids) is evaluated using the value of Bayesian Information Criterion (BIC), which helps determine whether the new cluster structure is proper. X-means compares the BIC-values of the two structures between the children of each center and itself to make decisions (Kass and Wasserman 1995). In other words, the method merges the clusters that a K-means iteration has made to avoid unsuitable division caused by the division order (Ishioka 2005, p. 91). Basically, the BIC formula globally is applied when X-means finally chooses the best model it encountered by posterior possibility, Pr[Mj|D], and is also used locally in all the centroid split tests (Pelleg and Moore 2000). To approximate the posteriors up to normalization, X-means appliesBIC(Mj)=Lj(D)-Pj2·logR(Kass and Wasserman 1995), where Lj(D) is the likelihood of the data according to the jth model and taken at maximum likelihood point, and Pjis the number of parameters in Mj(Pelleg and Moore 2000). An example for explaining the basic idea of X-means clustering is illustrated in Fig. 2. For the more details about X-means and the BIC-value calculations, please refer to Appendix C.The X-means clustering method resolves the problem of significant differences among clusters. We do not need to initiate a very large K to have the iterations reach convergence. While the K-means method requires a specific value for K prior to the calculation, the X-means method does not need a K value in advance of performing the calculations. The method also avoids making a smaller K which arbitrarily clusters fewer instances into adjacent clusters. X-means is used in a variety of research areas, because it improves the computation by searching the space between cluster locations and the number of clusters to optimize the Bayesian Information Criterion (BIC) measure (Pelleg and Moore 2000, pp. 727–734; Ishioka 2005, pp. 91–96). Sinapov and Stoytchev (2008, pp. 91–96) use X-means to deal with the number of clusters for detecting functional similarities, while Panda and Patra (2009, pp. 1–6) apply X-means for an anomaly-based network intrusion detection system. In a comparison between X-means and several algorithms based on K-means, Kumar and Wasan (2010, pp. 314–318) find that in a multi-dimensional problem using colon and leukemia gene datasets, X-means outperforms the original K-means.In online auctions, analyzing the flipping of fraudsters’ behavior is also a multi-dimensional problem.2Fraudster identification is determined by the calculated value of a vector consisting of a set of measured attributes. In fact, a fraudster usually fabricates certain features to disguise his schemes. Therefore, it is hardly to identify a fraudster with a single feature. In computation, vector calculation is classified into a multi-dimensional problem, because it results in a synthetic output with many different features.2Therefore, the use of clustering techniques to categorize and investigate changes in behavior is a reasonable approach. Since identifying patterns that have already occurred does not help users detect the latest tricks developed by fraudsters, X-means could be used to deal with the variants of existing patterns in applications (Xing and Stroulia 2004, Vaucher et al. 2008). This study intends to extend the detection capability to the variants of existing fraudulent behavior patterns; therefore, X-means is used in following experiments.Early fraud detection is important for crime prevention in online auctions. Ideally, if someone can predict the break point of a fraudster, then fraud can be stopped before anyone is victimized. However, different behavior fluctuation sequences may result in different fraud activation points. Furthermore, a fraudster can hide his intension at any moment he feels noticed. If we do not understand the existing fraudulent behavior patterns, it would be difficult to develop an effective early fraud detection method. Thus, various types of fraud will be introduced in this section. Next, the patterns of behavior fluctuation sequences camouflaging their fraudulent schemes are discussed. Finally, behavioral statuses of fraudsters are formulated using clustered phased profiles, which will be used to explain behavioral changes.To understand general fraudulent schemes, this study applies the X-means clustering algorithm to categorize the transaction histories of 645 proven fraudsters into groups for analysis. The transaction data of these proven fraudsters3All transaction histories of Yahoo!Taiwan have been set expiration dates, so we cannot gather earlier data from the auction site.3are gathered from Yahoo!Taiwan and proven by the auction site. The X-means is conducted by setting the range of K (i.e., the number of clusters) to [1645] for search, where 1 is the minimum and 645 is the maximum. With the guidance of BIC value, X-means found that, when K=4, the result of clustering is most well-fitted to the original structure of the data set. Thus, the 645 proven fraudsters are categorized into four clusters. The centroid of each cluster presents the averaged behavior characteristics of the clustered instances, which is represented by a set of values of the measured attributes. Table 2shows how many fraudsters have been uncovered by year, with most of them being caught after 2008.Categories of online fraud can be classified using different perspectives. Chua and Wareham (2004, pp. 31–37) defined 14 types of online auction fraud by major tricks from victim’s viewpoint. This study attempts to observe fraudsters’ reactions in terms of their original intention. This study pays more attention to a fraudster’s main focus in a fraud. From our observations, it is clear that online auction fraudsters target specific types of victims. The following four categories of online auction fraud genres can explain different attitudes.(1)Aggressive: Aggressive fraudsters apply straight tricks obtain fewer positive ratings than others. They are eager to attack directly with less care regarding the high number of positive ratings. This kind of fraudster is almost extinct in recent years, because both users and auction houses have aroused trading security awareness against them. Therefore, they have not survived as easily as they did in the past. It is easy to identify this kind of fraudsters based only on the number of accumulated negative ratings. The high negative feedback scores indicate that a number of traders have become victims of such frauds. This behavior also indicates that a fraud is complete or very close to completion. If an account with many negative ratings has not been suspended, only a beginner lacking experience would trade with him.Classical: Classical fraudsters are short of patience when it comes to waiting and hooking. Classical fraudsters intend to profit as soon as possible in order to reduce the risk of being discovered. They often obtain positive ratings in very short duration. It is too fast for legitimate users to stop the trade by the time the fraud is detected. This is particularly true when the occurrence of the last negative rating is very close to the time a potential trader inspecting the fraudster’s transaction history. When examining a classic fraudster’s behavior during the earlier period, there would be no significant differences from a legitimate trader.Luxury: The kind of fraudsters only pays attention to high-priced commodities. They are patient and keep as calm as legitimate users. They will not activate their scheme until reach the break point. They maintain an image of high priced dealers, and then raise the price tag to increase the odds of higher profits. The situation implies that a buyer intending to buy a high-priced product has to pay more attention to price changes. Under these conditions, both averaged buying price and selling price are higher than other types of frauds throughout the entire lifecycle.Low-profiled: The standard deviations of the price-related attributes can represent the features of targets. Since this kind of fraud focuses on lower-priced products, users are less disturbed by their losses. Once a fraud occurs, many victims keep silent and tend not to report. The ratings from other sellers are quite numerous, because they create multiple accounts for fabricating transaction records and ratings. In general, most fraudsters use fake transactions for earning positive feedback scores to distract traders from their occurrences with high negative ratings.Even though all fraudsters obtain positive feedback scores to raise their reputations, patterns of behavior fluctuation often vary in terms of the category of fraud. Some fraudsters prefer using simple tricks to disguise their malicious intentions rather than more complicated ones. In real online auctions, most participants only check the feedback score and the number of positive ratings when choosing trading partners. This study categorized the profiles of 645 proven fraudsters with their entire transaction histories into the four groups which result in the final statuses of fraudsters. The distinctive characteristics of the four groups are shown in Table 3. According to their major characteristics, 9% of fraudsters are aggressive, 27% apply classical tricks, 37% of fraudsters target high priced commodities only, and 25% of fraudsters pay attention to low-priced goods.The above results only explain the type of fraudsters. For early fraud detection and crime prevention, it is more important to discover a latent fraudster before anyone is victimized. That is, more fine-grained analysis of the latent behaviors of fraudsters is needed to detect fraud as early as possible and prevent its occurrence. In the following sections, the details of fraudulent behavior fluctuation sequences will be investigated by examining temporal actions and statuses of fraudsters. Based on these findings, more effective early fraud detection methods can be developed.It is impractical to construct all behavior sequence patterns for each fraud. However, a sequence of movements leading to a status transition could be treated as a major event. Therefore, we observe the status transitions involving fraudulent behavior during a specific duration, rather than looking at a detailed sequence of events. If the sequences of status transitions can be identified, the capability of a fraud detection system can be improved.In this paper, a sequence of fraudulent behavior fluctuation is defined as a series of status transitions. That is, a sequence SEQ can be denoted as a vector of statuses (S1, S2,…,Sn), which implies a status transition of S1→S2→…→Snand n is the number of statuses presented in the sequence. A status Sicontained in SEQ can be denoted by a vector of attribute values, Si=(v1, v2,…,vm), where m is size of attribute set. At present, the ten attributes introduced in Section 2.2 are used as the attribute set. We will investigate the fluctuation sequences of fraudsters by first formulating the behavioral statuses of fraudsters and then mining the hidden temporal actions.To formulate these status transitions more thoroughly, a systematic method is developed to discover typical latent behaviors of proven fraudsters. Given a set of fraudsters, FS={fs1, fs2,…,fsp}, H(FS) represents the set of transaction histories of members in FS. That is, H(FS)={H(fs1), H(fs2),…,H(fsp)}. To discover possible statuses in the fraudsters’ lifespans, we further partition the transaction history of each element in FS into phased profiles according to predetermined cut points in their lifespans. As a result, we have a set of hybrid phased profiles Hhybrid(FS)={H(fs, r%)|fs∊FS, r∊P}, where P is the set of cut-points. At present, a P={80, 85, 90, 95, 100} is used to generate the hybrid profiles. Then, for a given attribute set A={a1, a2,…,am}, we have a set of vectors of attribute values FV(Hhybrid(FS))={FV(h, A)|h∊Hhybrid(FS)}. Based on FV(Hhybrid(FS)), an unsupervised learning algorithm such as clustering is applied to find and formulate the type of status transition that could identify a latent fraudster before his scheme is actually activated.For example, assume that FS={F1, F2, F3} and the transaction histories of the three proven fraudsters are partitioned into five different phased profiles, i.e., P={80%, 85%, 90%, 95%, 100%}. After performing clustering algorithm on FV(Hhybrid(FS)), four groups (statuses) of these phased profiles are generated. As seen in Fig. 3, different fraudsters can exhibit same behaviors at different points of their lifespans. For example, in Group 1, F1 in phase 90-95% shows characteristics similar to F2 in phase 80–85%. In Group 2, the behavior of Fraudster 1 during his phase 80–85% is similar to the behavior of Fraudster 3 during his phase 80–90%. As a result, the four groups can be used to represent typical statuses of these three fraudsters, regardless of when the statuses occur in their lifespans. As a result, the status transition of each fraudster can be denoted by these identified statuses.Each clustered phased profile represents the same schemed movement. The number of members in a cluster indicates the level of popularity for a certain trick. The highest number of instances in a cluster implies a trend in the type of tricks. Such a trend could also imply that a weakness in the current situation in online auctions contributes to the high popularity of that type of trick. Undoubtedly, fraudsters are adaptive; as auction houses find methods to stop their fraudulent activity, fraudsters switch their tricks as needed. Therefore, the type of fraudulent behavior identification used is helpful in explaining the rules of fraudulent scheme development.To devise the possible statuses of latent fraudsters, the transaction histories of 645 proven fraudsters collected from Yahoo!Taiwan are used for analysis (as shown in Table 3). First, an X-means clustering algorithm is applied to cluster each phased profile of collected proven fraudsters by year. As indicated in Table 4, the phased profiles are categorized into no more than four groups.4Four groups obtained from clustered phased profiles of fraudsters happen to be the same as the number of type of fraudsters shown in Section 3.1.4Fraudsters who were identified by 2007 are categorized into only two groups. In 2008, there are four clusters in every phase. In 2009, fraudsters are classified into four clusters except those instances in the 90% phase. In 2010, fraudsters by phase 90% are categorized into two groups, and all of them turned into three groups after entering phase 90%. However, the same number of groups in different years that does not mean the nature of each group for different years is same. Whereas, a decrease in the number of groups can imply that some tricks were phased out.To understand the behaviors of latent fraudsters in detail, hybrid profiling is applied to trace the flips in their behavior. The hybrid profile of a fraudster consists of five phased profiles as mentioned in Section 2; thus, every phased behavior change of a specific fraudster during his entire lifespan is recorded. In total, 3225 phased profiles generated from the 645 fraudsters are fed into clustering. As seen in Table 5, all phased behavior profiles are categorized into four different clusters. Profiles with similar fraudulent behavior (described by the attributes shown in Table 1) are gathered in the same cluster. The four clusters are named as Status-0, Status-1, Status-2 and Status-3 respectively. The five phased profiles of a fraudster may belong to the same cluster or different clusters. The different behavioral status combinations represent different tricks for attracting buyers, as well as the different timing used by fraudsters to capture profits. Each cluster is treated as a type of fraudulent behavior. Status-1 behavior reaches 39.78%, which means the odds of facing Status-1 behavior is 39.78% that you are going to trade with a fraudster.For early fraud detection, it is important to understand the typical behaviors of latent fraudsters during each particular period of lifespan. Because the centroid of a cluster is the mean of the values of a particular measured attribute that represents all members in this cluster, we can use the centroid to represent the typical behaviors statuses of fraudsters belonging to this cluster (group). Table 6shows the centroids of the four clusters (statuses) obtained from clustering phased profiles of fraudsters. Based on the attribute set chosen for characterizing the online auction traders, the centroid is a ten-tuple vector. All statuses are fraudulent tricks in essence. In a fencing or sword fighting, a fencer can use different ways to attack his opponents. The fencer might continuously thrust straight forwards several times and then steps backward to defend and cover his torso from opponent’s slashing. Because not all opponents are passive traders, fraudsters need to wait an appropriate timing to activate next attack. Conservative traders always wait and see to prevent frauds from schemes, which make schemes more complicated. Namely, the process of performing a fraud is like a dance of negotiation that is rarely completed successfully with a one-shot attack.According to Table 6, Status-0 and Status-1 behavior inclines to directly inflate positive ratings directly in a very short time (high DensityOfPos). Both Status-0 and Status-1 are camouflaged tricks for baiting. This trend is in contrast to Status-2 and Status-3, where the ratio of positive ratings for Status-0 is lower than in Status-1. Status-1 fraudsters tend to sell more goods in the last period to obtain more positive ratings (high SellingNumberLast30). A high density of positive ratings implies a collective anomaly resulting from excessive positive ratings from accomplices.Status-0 behavior focuses on raising one’s reputation to offset a large number of negative ratings. Status-0 behavior seems to be simple and straightforward. When Status-0 fraudsters do not perform too many other tricks to disguise their malicious intentions, they do not pay much attention to the value of measured attribute 8 (SellingNegtiveNumberLast30). Instead, they use simpler methods that do not require lengthy preparations to inflate reputations.Status-2 and Status-3 fraudsters do not leave any Easypay Ratings in the specific payment mechanism of Yahoo!Taiwan. The two statuses reflect different kinds of attacks under different conditions. However, another obvious feature of Status-2 behavior is that even as a seller, the fraudster receives a lot of ratings from other sellers. Previous results show that using only the original feedback score could mislead users’ decisions. In fact, every correct judgment has been generated from the combination of the indicators and indices, based on contextual situations.Table 6 also shows that most fraudulent behavior has a high ratio of positive to negative ratings except in Status-0 behavior. Status-0 behavior is activated when the ratio of negative ratings is rising, and to compensate, more commodities are sold. Status-0 and Status-1 behaviors are more conservative tricks that are mainly used while waiting for another chance to reactivate. In contrast, Status-2 and Status-3 fraudsters aggressively attack their targets with different tricks. Status-3 behavior emphasizes increased sales within a specific timeframe. As mentioned earlier, fraud consists of a sequence of ordered actions. Because fraudsters use careful camouflage, detection is more effective when the fluctuations in fraudsters’ statuses are examined rather than simply characterizing a single break-out symptom. For example, fraudsters can attract buyers with fake reputation scores, and then use a successive set of aggressive tricks to make profits. As his target perceives something irregular, a fraudster often retreats immediately to disguise his next movement. After the fraudster breaks out and is discovered, we can see that he stayed in different statuses for varying lengths of time, and that the movements correspond to successive attacks and retreats. More importantly, different fraudsters can use the same tricks to defraud after breaking out; however, different camouflaged actions may be applied in their latent period. Therefore, to understand the online auction fraudsters’ behaviors, the fluctuations of these behaviors will be investigated by various analysis methods in the next section.In this section, a systematic method is proposed to examine fluctuations in fraudulent behavior in transaction histories in order to discover the most commonly used strategies. In addition, the importance and features of these discovered strategies will be discussed.To understand the sequence of behavior fluctuations, it is indispensable to analyze transaction histories. Afterwards, we examine the status transitions in the phased behavior of proven fraudsters, which are associated with fraudulent behavior fluctuations. For a given account acc, if the set of cut points of phased profiles is {80, 85, 90, 95, 100},5The cutoff point and increments can be adjusted as needed. This study suggests 80% as starting point and 5% increments, according to our previous experimental experience. Smaller increments such as 1% were not helpful in raising accuracy; most fraudsters activate their direct attack after 90% of their lifespans.5then the phased behavior can be represented by a status vector,PhasedBehavioracc=(S80%,S85%,S90%,S95%,S100%).Initial status in the phased behavior might indicate the original intent and habitual tricks of a fraudster. However, fraudsters do not rely consistently on their initial behavior status when executing a fraud. Table 7lists 34 possible fluctuations in phased behavior. Obviously, the final status of a proven fraudster is indicated by his phased 100% profile. It can be seen that seventy percent of fraudsters are cunning about flipping their behavior. Only 198 (30%) fraudsters kept their original status until they are discovered; this number includes 42 fraudsters who followed Status-0 behavior and 156 fraudsters who were classified as Status-1.Obviously, flipping behavior is in vogue with schemed fraudsters. The results also imply that their behavior is difficult to identify at first glance. Conversely, it is not difficult for users to identify something irregular when a fraudster steps past his break point. A reasonable speculation is that it is too late for users stop a trade by the time they perceive the abnormal behavior of their counterparts.Based on the phased behavior of proven fraudsters, strategies can be formulated by investigating meaningful patterns of status transitions. In fact, phased profiling is an artificial technique to understand the temporal behavior of fraudsters. Even a fraudster cannot identify the current point of his lifespan, such as phase 80%, 90%, or 100%. Obviously, the length of time in which fraudsters stay in a particular status is varied, making it difficult to predict. For example, a phased status pattern (S0, S1, S1, S1, S1) will be simplified to (S0, S1) to represent a sequence consisting of only one transition. In addition, phased patterns (S0, S1, S1, S1, S1) and (S0, S0, S0, S1, S1) will be recognized as the same sequence, because both of them can be compressed to (S0, S1).Based on the discussion above, we turn the patterns of phased behavior (see Table 7) into patterns for flipping behavior (see Table 8). Consequently, there are 29 strategies in total. Two of them contain no flipping, while four flip behavior once, and eight flip behavior two times. On average, 80% fraudsters flip their behavior no more than two times. This implies that flipping behavior is not as complicated as we expected originally. It may result from a simple survival principle; fewer status changes will leave fewer clues in the transaction history. Traders will be less likely to notice fraudulent behavior if fraudsters flip their behavior less frequently. In addition, the result also implies many fraudsters are impatient about waiting for all their targets to get hooked. As long as they are successful in defrauding some victims, fraudsters may disappear from the auction site quickly; as a result, no further behavior change happens.The processes of a fraud are decomposed into identifiable status transition steps to help explain the trend of fraudulent behavior in online auctions. First, status identification in a fraud detection application can refine the granularity of fraudulent behavior, which also enhances the capability to predict adjacent moves. Second, understanding the sequence of behavior flipping reduces the error rate of fraud detection. In general, adjacent status identification compensates for the drawback of traditional detection systems that provide only binary outcomes. The actual situation is more complicated than a simple prediction of “yes” or “no.” Therefore, this study develops a two-way detection procedure, including both backward and forward detection procedures, to extend the capability of early fraud detection.For general users, however, it is not easy to understand and observe the meanings of status transitions. In some case, it is possible le for an experienced trader to recognize some patterns of fraudulent behavior, even without an automatic detection system. To clarify the above findings, we can identify the discovered behavioral sequences with more illustrative ways. Status-0 and Status-1 can be treated as Camouflaged attacks, and Status-2 and Status-3 as direct Attacks according to the meanings of the centroids. And then we concatenate adjacent phases in the same statuses to simplify the discovered sequences into 7 patterns (see Table 9). Using a table tennis match as a metaphor, Status-0 and Status-1 are like forehand push and chop; Status-2 and Status-3 are similar forehand swing and backhand swing. Conservative players preferring defending oriented moves first to score, some other players use direct attack first. Players can apply different combination of moves to score in terms of preferences and situations. Whenever applying Camouflage→Attack or Attack→Camouflage first, a fraud is a process of flip-flops with camouflage and attack successively. There are very few fraudsters sonly attack without camouflage can be successful in real cases of fraud. That results in 16(24) flipping combinations in total four phases at most. However, successive statuses could be concatenated into one status, the remaining 7 sequence patterns as those shown in Table 9. The simplified status transition is easier to observe with the naked eyes. The analysis of results explains how behavior flips in a fraud.Since remaining in a status after arousing suspicion could result in detection, fraudsters will sometimes switch behavior into another status to distract the users’ attention; however, the fraudsters will still ultimately follow their originally prepared schemes. This phenomenon implies that early fraud detection is possible. Therefore, it is helpful in observing the details of a fraud by investigating the initial and ending statuses of a fraud. The upper part of Table 10shows the relationships between the initial and ending statuses of fraudsters who use fraudulent flipping behavior. Interestingly, 83% of fraudsters will keep their initial status at the end of their frauds, even after flipping their behavior several times. When considering the ending status of fraudsters, 175(27.13%) used Status-1 behavior, 219 (33.95%) fraudsters used Status-2 behavior, and 192 (29.77%) used Status-3 behavior; however, only 59 (9.15%) used Status-0 behavior. This finding results from the centroid of Status-0 cluster, which (as seen in Table 6) functions by obtaining some positive feedback followed by a higher volume of negative feedbacks. As online traders become more cautious and online auction sites alert potentially unsafe trades, few users would be likely to trade with a seller who has a large number of negative ratings.The originally produced status matrix in four statuses is converted into a matrix of habitual moves, attack or camouflage, shown in the lower part of Table 10. Sixty-four percent of fraudsters will keep their initial status at the end of their frauds when in the status of direct attack, while the other 36% will use camouflage instead. The attack-oriented statuses (64%) account for the influence of negative ratings. The camouflage-oriented statuses (36%) pay more attention to raising one’s reputation directly through the use of positive ratings. The camouflage-oriented sequences are performed by higher-price oriented fraudsters, who focus more attention on disguising their tricks. Therefore, this kind of fraudster is more difficult for naïve traders to identify. To achieve higher profits while avoiding detection, they devise more delicate tricks (more status transitions), and otherwise shorten their lifecycles. However, their investments are quite reasonable based on the rate of return (e.g., selling expensive items). In contrast, fraudsters using camouflage-oriented sequences attempt to raise their reputations quickly rather than investing in long-term preparation to set traps (i.e., less status transitions). They focus more on making a large volume of quick, but not necessarily high, profits. Table 11summarizes these main findings, the corresponding comments and implications of the results obtained by fraudulent behavior analysis.Identity theft is classified as camouflage-oriented behavior, because the first part of the transaction is perfectly normal when compared to legitimate accounts. In addition, most fraudsters prefer to save time by stealing other accounts rather than cultivating conspiracies with other fraudsters. As a result, fraudsters tend to shorten the time it takes to process a fraud in order to gain money quickly and reduce the chances of being discovered. Apparently, the type of camouflage-oriented and type attack-oriented strategies represent habitual usages of camouflage and direct attack respectively.In this section, the applications of our findings in fraudulent statuses and strategies will be introduced. First, based on formulated fraudulent statuses, existent fraud detection methods can be incorporated with status identification to improve granularity and resolution in behavior detection. Second, for fraudsters who stay in hard-to-detected statuses, a two-way status monitoring method is proposed to increase the possibility of detecting them as early as possible. The strategies discovered in the patterns of status transitions will be used as the basis of the proposed monitoring method.In the following experiments for fraud detection, the data set contains both fraudsters and legitimate traders. These accounts are gathered from the records of Yahoo!Taiwan auction site from 2007 to 2010. Online auctions in Taiwan have been prosperous since Yahoo!Taiwan launched the first online auction service in 20016Yahoo!Taiwan was established in 1999, afterwards it merged the biggest Taiwanese portal site, Kimo, in 2001. Yahoo!Taiwan has been providing online auction service since then.6and has been the top auction site in Taiwan in both revenue and in the number of registered. E-commerce development in Taiwan is quite similar to the worldwide markets in many aspects, including Internet fraud. According to the National Police Agency of Taiwan, online auction fraud has been top two of reported frauds in terms of both the number of cases and the amount of monetary loss7The top 10 fraud types and cases of monetary loss rankings are updated monthly by National Police Agency, Taiwan. http://165.gov.tw/fraud_rank.aspx (in Chinese). Unfortunately, this site does not provide detailed statistics publicly.7during these years.For this study, the proportion of the minority class (fraudsters) and the majority class (legitimate) is set at 1:2. To keep a 1: to 2 ratio between fraudulent and legitimate profiles, each test includes 215 fraudsters and 430 legitimate traders randomly selected from collected data (645 fraudsters and 2493 legitimate users).8Candidates for testing include the transaction histories of 2493 legitimate users randomly downloaded from Yahoo!Taiwan. For each test, 430 users were randomly selected from the candidate pool. From Yahoo!Taiwan’s officially announced blacklist, 645 proven fraudsters were collected. Since fraudsters are outliers in reality, it is impossible to collect fraudster data with random sampling.8To sample various behavior statuses, all accounts in each test are profiled by five phases. In total, there are 1075 fraudulent phased profiles; therefore, 2250 legitimate profiles are randomly chosen from the collected transaction histories for each test. The fraudster accounts used for analysis are gathered from the blacklist (or the suspended list) reported by the auction site. Manual reviews are then preformed to filter out those who are not really fraudsters (such as those suspended due to trade disputes) by examining their transaction histories (including the obtained textual feedbacks). Those who are not reported on the blacklist are treated as legitimate traders even if they have received one or more negative feedback comments. Ideally, the data set would contain all reported fraudsters in Yahoo!Taiwan during the data collection period.Various metrics are used to evaluate the performance of the following experimental results, including true positives (TP), false positives (FP), true negatives (TN), false negatives (FN), and F-Measure, respectively (for details, please see Appendix E). In practice, misclassifying a minority class instance, fraudsters, is usually more serious than misclassifying a majority class one (Liu and Zhou 2006). To verify the capability of status identification, C4.5 decision trees (Quinlan 1993) are applied (implemented by J4.8 classifier in Weka 3.6.6) with ten-fold cross validation for classification. Ten-fold cross validation is a standard way to predict the error rate of a learning technique (Witten et al. 2009, pp. 152–154). The data is divided randomly into ten parts in which the class is represented in approximately the same proportions as it exists in the full dataset. Each part is held out in turn, and the learning scheme trained on the remaining nine-tenths; the error rate is calculated on the holdout set. Thus the learning procedure is executed a total of ten times on different trainings. Finally, the ten error estimates are averaged to yield an overall error estimate for explaining the effectiveness of results.Before presenting the capability of early fraud detection with these clustered fraudulent statuses, we first show the appropriateness of categorizing the fraudsters’ behavior into the four statuses (see Table 5 in Section 3.3). At first, the 645 collected proven fraudsters were partitioned into five phased profiles. In total, 3225 statuses were generated to test using J4.8 decision trees with 10 times 10-fold cross validation. The results are presented in Table 12. The results demonstrate that the status identification of proven fraudsters has a high success rate. In this experiment, the phased profiles of all collected fraudsters are categorized into four hidden statuses. The results of Table 12 identify the four hidden statuses, but do not evaluate the process of identifying fraudsters. This process was only used to identify the hidden statuses, and as a result does not contain profiles of legitimate traders.In the real world, the number of fraudsters is low when compared with legitimate traders; therefore, fraudsters are able to hide themselves in the online auction society. Thus, a practical early fraud detection method should focus on how to distinguish legitimate traders from fraudsters. Table 13shows the result of applying C4.5 classification technique to these test data. It is worth noting that there are five categories, four for fraudsters and one for legitimate traders. In related auction fraud detection work, each instance in the data set is usually labeled as either fraudulent or legitimate. In this study, the ‘Fraudulent’ class is further divided into Status-0, Status-1, Status-2, and Status-3. In practical terms, an instance classified into one of the four artificial classes can be simply treated as a fraudster.To show whether detection accuracy can be improved by using the proposed status identification methods, a comparison with previous related work (Chang and Chang 2011) is shown in Table 13. The main difference between the proposed method (Status Identification) and the previous work (Hybrid Method) is that the proposed method identifies the hidden statuses prior to the construction of the detection model. In addition, the detection model is built with more detailed classes (but not just Fraudulent/Legitimate) which enhances the existent methodologies for fraud detection. Referring to Table 13, the first six rows and the last three rows show the results of applying the status identification method and the hybrid phased modeling method (Chang and Chang 2011) respectively. The two methods use the same measured attributes to identify fraudsters. It can be seen that the proposed method (the Status Identification method) can obtain better detection precision and recall rate than the hybrid method. Using a t-test with significance below .05, the status identification method outperforms the conventional detection model significantly.By applying the proposed status identification method, additional information for fraud detection can be observed from the results shown Table 13. It can be seen that, except for Status-1 and Status-3 fraud, there are high precision and recall (over 90%) on the members of other classes. In particular, for Status-0, the precision and recall are higher than 99%. In total, even though normal traders are mixed in the data set, the average F-measure of classification is up to 88%. The result is much higher than 67%, which is the rate obtained by a naïve classifier. However, in terms of the F-measure, the detection performance of Status-1 seems unsatisfactory. The recall rates of fraudulent behavior for Status-1 are 66%, which suggests that approximately 35% of camouflage fraudsters could be misidentified as legitimate users. The result suggests that fraudsters who stay at Status-1 use more sophisticated camouflage in order to appear legitimate. Obviously, the low recall rate and precision for Status-1 fraudsters in the above experimental results would affect the effectiveness of early fraud detection. Similar observation can be found in the detection for Status-3 fraudsters. If we can overcome this problem, the detection accuracy will be further improved. The above comparison demonstrates that the proposed method does enhance the granularity and resolution of fraudulent behavior observation.To further explore the usage of the proposed status identification method, we divide the current data set into two different time intervals, where the earlier one (from 2007 to 2008) is considered as training set while the relatively newer one (from 2009 to 2010) is test set. The ratio of legitimate accounts to fraudsters is also set to 2:1 for both training and test sets. The training set consists of 500 legitimate accounts and 250 proven fraudsters. And, the test set contains 250 legitimate accounts and 125 fraudsters. Referring to the results shown in Table 14, the recall (TP Rate) for identifying the four fraud statuses is similar to those in Table 13. It implies that the evolvement of fraudulent behavioral statuses might be gradual but not abrupt from 2007–2008 to 2009–2010. In addition, the recall for legitimate traders is slightly lower than that in Table 13, and the precisions for detecting fraudsters in both Status-1 and Stuats-3 are also low. Because some legitimate traders in 2009 and later behave like fraudsters in Status-1 and Status-3, which results in misjudging them as Status-1 or Status-3 fraudulent behavior. The above results show that not only the fraudsters but also the legitimate traders may make their trading behavior evolve over time. This could be another clue to build a more effective fraud detection system for online auctions.In the previous section, a fraud detection problem was identified in situations where Staus-1 or Status-3 fraudsters could be easily misidentified as legitimate traders. To resolve these misjudgments, a two-way monitoring method that combines forward status monitoring and backward status monitoring is introduced to re-examine these claimed legitimate traders.Because a case of fraud consists of a sequence of actions, the behavior status of a fraudster could change with different actions or events over time. Thus, if the suspicious account acc is now identified as a legitimate trader, someone can continuously monitor any flipping in his behavior to see whether he is actually an unidentified fraudster in Status-1 or Status-3. Once the account shows a change in behavior and is identified as Status-0 or Status-2, we can claim that he is quite likely a fraudster. However, such a procedure needs to be watched continually. For example, while waiting for a detection report, a desired item owned by an uncertain legitimate trader could be sold out. To avoid this drawback, a backward status monitoring is developed to provide more proactive detection.The backward status monitoring procedure examines the previous transaction history of the account under test to determine whether any suspicious clue is left. In contrast to the forward status monitoring approach, no waiting time is needed; thus, the user can obtain instantaneous information. When the backward status identification detection starts, the transaction history of a suspected account is curtailed to the last 5%, 10%, 15%, 20% of his lifespan to simulate earlier parts of the lifespan, which can then be compared to existing phased status profiles. While status identification is performed, we assume that the current status of the suspected fraudster is in his final phase. If the partitioned phases match the existing one, the system will move to earlier phases to continue the inspection. When the behavior is identified as either Status-0 or Status-2, the system will send a warning message to suggest that the trade stop. Otherwise, the system will keep inspecting characteristics of behavior to generate a possible flipping behavior sequence. The generated sequence is then compared with the patterns of flipping behavior (see Table 8) for prediction. The detailed steps of this procedure are presented in List 1.After presenting the two-way status monitoring, we will analyze the performance of the proposed method. For a suspicious account (facc) that is a fraudster but identified as legitimate, there are two possible results of applying the two-way method to inspect the account:(1)The fraudster account will always stay in Status-0 and Status-2: in this case, because the high accuracy of detecting fraudsters in Status-0 and Status-2, this account could be a fraudster with high confidence. That is, the user should stop trading with this account immediately.The fraudster account never stays in Status-0 or Status-2 in his lifespan: in this case, the probability of continuously misjudging the fraudster as legitimate isList 1. Backward status monitoring procedure in pseudo code1ProcedureBackwardStateMonitoringbegin2inputacc: the account to be tested3inputendPhase: the end phase of H(acc) in the backward procedure4variablePH: store the current cut point of phased profiling5variableH_cur: store the transaction history of acc in the current‘6phase7PH = 100%8while(PH⩾endPhase)begin9H_cur = H(acc, PH)10if(State(H_cur) = S0 or S2)then11send out warning message of possible fraud;12end if13PH = PH–5%;14end while15List behavior from the earliest status to the current state;16Match the behavior flipping strategies;Calculate likelihood and probability for the worst case;end procedure

@&#CONCLUSIONS@&#
Identifying a suspect as soon as possible is the first priority when developing an early fraud countermeasure for online auctions, so that users can stop trading before becoming a victim. Flipping behavior, in which fraudsters often vary the type of strategy they use, is one of the most common tricks used by schemed fraudsters. In this way, they disguise their malicious intent, making it impossible for users to identify them using a single measured attribute, such as high positive feedback rate. Therefore, this study proposes the concept of behavior status identification to enhance the capability of early fraud detection over previous binary detection outcomes. Thus, the proposed method not only identifies whether an account is fraudulent or legitimate, but also the behaviors statuses. Once an account is judged as having one of the fraudulent behavior statuses, the user can observe his next move to check for fraudulent flipping behavior strategies before making a final trading decision.In this study, we applied ten selected measured attributes (Chang and Chang 2012) using X-means clustering technique to explain fraudulent behavior by status transition. The results of analysis demonstrate there are four major fraudulent behavior statuses to compose different schemes. A decrease in the number of behavior clusters implies that fraudsters are inclined to gradually adjust their schemes against users’ countermeasures. In recent years, fraudsters tend to use much faster tricks (flipping sequences) for quick profits. This study attempts to use the flipping of behavior status instead of complex network graphs to explain the relationships among traders. Since the graph of trading networks can become quite complicated, users might be distracted by the outcome generated by these trading networks, such as the number of cliques. Using fraudulent behavior status transitions (or the number of behavior flips) turns abstract networking graphs into a simple classification system, which makes fraudster identification more precise for general users. This study adopts the same measured attributes and the concept of phase profiling as in our previous research (Chang and Chang 2011, 2012); however, it is now integrated with a new way of observation and a different classification algorithm which focus on discovering the tricks of schemed camouflaged behavior along with time in details. By identifying the patterns of behavior flipping that depict how fraudsters react to their potential trading counterparts, it is easier to define new fraudulent tricks and to improve the existing detection mechanisms during negotiations.In fact, developing techniques to identify meaningful behavioral changes of fraudsters would be one of the most important tasks in our feature work. Existing auction sites, such as eBay and Yahoo!Taiwan, have constantly evolved their reputation systems to increase trust and decrease fraud. Those adoptions indeed how improve fraud detection to some degree. However, smart fraudsters adjust their tricks. Therefore, the identified status transition patterns should be updated periodically according to new transaction data from the auction sites. In addition, it is possible that modern fraudsters could discover novel sequence patterns and invent new tricks by combining known fraudulent status sequence. Thus, even if these behavior patterns are identified within Yahoo!Taiwan, it is possible that they cannot be applied to other auction sites directly; however, the proposed systematic method could be readily performed to obtain the behavior patterns for sites other than Yahoo!Taiwan. The comparisons of behavior difference among different auction sites would be another important topic in our future studies.The methodology proposed in the research can be generalized and applied in different areas, such as identifying and monitoring illegal short selling in the stock markets or blocking network intrusion initiated by potentially hostile users. For the former case, the procedure could start with collecting data from the stock exchange website. The data could be arranged by phased profiling for clustering, which could discover hidden statuses of abnormal behaviors. According to the discovered statuses, the retrieved records could be transformed into status transition sequences. Subsequently, frequent patterns could be mined from these transition sequences. With these results, authorities could monitor the latent illegal short selling in a more proactive way and identify abnormal attempts as early as possible.One of limitations in identifying sequential behavior patterns is caused by the absence of strict time constraints. Users want to specify a minimum or maximum time period between adjacent elements of the sequential pattern. In many applications, each element of the pattern can be contained in the union of the items bought in a set of transactions, as long as the difference between the maximum and minimum transaction times is less than the size of a sliding time window (Agrawal and Srikant 1996, pp. 3–17). In this study, we use phase partitioning instead of precise time slicing; however, it can be difficult to raise the accuracy of distinguishing among Status-1, Status-3 and legitimate behavior. The two-way status monitoring procedure we proposed can compensate for the weakness involved with misjudgment of Status-1 and Status-3 behavior. In fact, to detect well-camouflaged fraudsters, it is indispensable to identify the moment of their behavior changes. The phased-profiling used in this study is viable, but it is not the most effective way. Adjusting these techniques to detect fraudsters on other auction sites applicable, such as eBay, would be one of the most important tasks in our future work. In addition, the strategies and statuses should be updated periodically according to the newly transaction data revealed by the auction sites to discover novel strategies and tricks as they evolve. These projects will help keep detection accuracy as stable and complete as possible.The values of ten selected measured attribute are combined with a method of phased profiling to construct fraud detection models. A phased profile is determined by its corresponding cutoff point. The cutoff point of a phase confines the length of transaction history for the purpose of calculating the values of a measured attribute in a profile during a specified range of lifespan. The values of each individual measured attribute occurring in other phases of the same account represent the magnitude of change over time in the form of a vector. It is helpful in calculating similarity and clustering for advanced behavior observation. Since Yahoo!Taiwan was established in 19999Yahoo!Taiwan was established in1999 http://zh.wikipedia.org/wiki/%E9%9B%85%E8%99%8E%E5%8F%B0%E7%81%A3.9and launched online auction service in 2001,10http://zh.wikipedia.org/wiki/Yahoo!%E5%A5%87%E6%91%A9.10there have been about 4380 transaction days as the 12years until 2013. It is hard to compare values that are disproportionate, such as differences of a millionth. In addition, this study adopts transaction day as measuring unit for partition collected transaction histories, because it is easier for users to understand. The first six of the ten selected measured attributes are defined by Chang and Chang (2009, p. 746). The remaining four measured attributes are statistics within a specified phase. The calculation of the ten selected measured attributes is explained in details as follows:(1)Density of obtaining positive ratings (DensityOfPos)Most schemed fraudsters prefer fabricating numbers of transaction records rapidly instead of making a real trade, resulting in a large number of positive ratings occur over a very short period. Therefore, the density of obtaining positive ratings becomes extraordinary high compared with legitimate users. The density is defined by the ratio of count of obtaining positive ratings to total transaction days in a specific duration. Refer to Fig. A1, k denotes the kth day in a transaction history and blue arrow stands for a positive rating. For instance, the density of obtaining positive ratings during the range of kday to k+1 is higher than the range of k+3 to k+4. Since the count of positive ratings denotes trader credibility level in a binary reputation system, a fraudster uses this method to appeal to his targeted victims. Usually, a legitimate trader will not obtain consecutive positive ratings within the same day if without any appropriate reasons.(2)Average time to obtain positive rating after closing bid (EndCloseToPos)Average time of obtaining positive rating after closing bid occurred in a specific phase could be a feature. If the time interval between the time of closing an auction and obtaining corresponding positive rating is very close, it is likely that someone is purposely trying to enhance his reputation. Due to commodity delivery and verification of authenticity of the goods in a regular transaction, positive ratings should not be left until after concluding a transaction.(3)Ratio of positive ratings to total feedback count (RatioOfPos)This ratio is calculated by P/(P+C+N) where P is the count of positive ratings, C represents neutral ratings, and N is the count of negative ratings. This ratio evaluates the credibility level in a binary reputation system directly.(4)For a seller, the ratio of positive ratings from other sellers to all positive ratings (RatioOfSToS)In normal situations, the ratings of a seller should come from other buyers. If most positive ratings were left by other sellers, this would be highly unusual. Most fraudsters play the role of a seller to deceive buyers in a typical type of online auction fraud. They often collude with other fraudsters or members of their accomplice syndicate to fabricate transactions to accumulate positive ratings. The value is calculated as described above.(5)Time difference from the last negative rating to the current time (LastNegCloseToCur)If the last occurrence of a negative rating is very close to the current time, the credibility of his reputation is declining (Refer to Fig. A2).(6)Ratio of negative ratings to total feedback count (RatioOfNeg)The RatioOfPos is widely applied in conventional binary reputation systems. The ratio is calculated by the count of negative ratings to the count of all feedback that equals N/(P+C+N).(7)Number of sold items in the last 30days (SellingNumberLast30)According to the predetermined cutoff point, the number of sold items in the last 30days of a specified phase is counted as a feature.(8)Number of negative ratings from selling in the Last 30days (SellingNegtiveNumberLast30)According to the predetermined cutoff point, the number of selling items in the last 30days of a specified phase.(9)Number of Positive ratings (NumberOfPostive)The count of positive ratings occurred in a specified phase. For instance, the difference of the values of NumberOfPositive between phase 80% and phase 85% indicate the trend of credibility development.(10)Numerical rating from Easy Pay System (EasypayRating)Easy Pay System is a dedicated (not compulsory) payment system for the users of Yahoo!Taiwan. The easy pay system provides virtual accounts to deal with payment processes instead of using actual banking accounts. An easy pay user can transfer funds with a physical automatic teller machine, web ATM or credit card into his account for delivering payment, so the user can pay or receive money in a secured channel for reducing the odds of deception. The easy pay system provides an extra rating system which is also a binary reputation system to their users for evaluating the satisfaction of payment process. The feedback score of easy pay rating system can be part of the total feedback score but is calculated separately. However, it allows users to leave a rating for payment process.Chang and Chang (2011) propose the method of phased profiling to describe the features that occur in the specified partial transaction history of an account in a vector form. The length of a transaction can be measured by trading days or by the count of obtained ratings. For a given account ACC, the complete transaction history can be represented as H(ACC)=(tr1, tr2,…,trn) where n is number of transaction completed by ACC and tridenotes the ith transaction. Based on H(ACC), the lifespan of ACC, TACC, is represented by the difference of days between the dates of the final transaction and the creation of the account ACC; that is, TACC=date(trn)−t0. The percentage of transaction history that is used is the same as the partitioned unit that represents the phase an account has already passed through. For instance, the phase 82% profile of ACC will describe the features that occurred in the first 82% of ACC’s transaction history, while the last 18% is curtailed. More formally, the r%-phased profile of M is represented by H(ACC, r%)={tri|date(tri)⩽TACC*r%}. If account ACC were created 1352days ago, then H(ACC, 82%) would include all transactions from the first day to the 1108.64th (=1352*0.82) day of his lifespan. Detection model M(r%) represents the behavior model of a specific phase r%; it would seem that more M(r%) would ensure that the detection system can identify a suspect at any r% of his lifespan. Intuitively, a detection system containing all partitioned models (1–100%) could handle all the features of the entire lifespan of a suspected fraudster; however, this is not actually the case.Pelleg and Moore (2000, pp. 728–730) proposed X-means algorithm consists of two operations repeated until completion. The first operation is the Improve-Params: it consists of running conventional K-means to convergence. The second operation is the Improve-Structure operation to find out if and where new centroids should appear. This process is achieved by following pseudo code:X-means:1.Improve-paramsImprove-structureIf K>Kmax stop and report the best scoring model found during the search. Else Goto 1.Ishioka (2000) summarized BIC-value calculation as follows: Prepare p-dimensional data whose sample size is then calculate the BIC asBIC=-2logL(θˆi;xi∈C)+2plogni, whereθˆi=[uˆi,V^]is the maximum likelihood estimate of the p-dimensional normal distribution; μiis the p-dimensional means vector, and Vi is the p×p dimensional variance–covariance matrix; The total number of the parameters is 2p. xiis the p-dimensional data contained in Ci; niis the number of elements contained in Ci. L is the likelihood function which indicates L(⋅)=Πf(⋅).Table A1shows the clustering results for types of fraudsters by year (2007–2010), in which the data set is consisted of 645 Fraudsters in total. It can be seen that the number of clusters are 2, 4, 4 and 2 in 2007, 2008, 2009, and 2010 respectively. In addition, it demonstrates that the types of fraudsters do evolve over time and that various fraudulent behaviors are exhibited by fraudsters reported in different years.The measure metric definitions TP, FP, TN, and FN are used in this study, and they indicate the number of true positives, false positives, true negatives, and false negatives, respectively.Precisionrate=TP/(TP+FP)Recallrate=TP/(TP+FN)Success rate=TP+FP/(TP+FP+TN+FN)F-Measure=(2×Recall×Precision)/(Recall+Precision),Precision and recall are statistical measures of the performance of a binary classification test. TP rate (also called Sensitivity or recall rate in some fields) measures the proportion of actual positives which are correctly identified as such. Specificity measures the proportion of negatives which are correctly identified. A perfect predictor would be described as 100% recall and 100% precision. These two measures are closely related to the concepts of type I (false positive) and type II (false negative) errors (Witten and Frank 2005, pp. 172–173).SymbolExplanationA={a1, a2,…,am}An attribute set with m measured attributes(U, A)The transaction history of account U is described by the attributes in AV(U, A)=(v1, v2,…,vm)A vector comprising the values related to the each attribute in A, where these vi(1⩽i⩽m) are calculated by examining the transaction history of UUSThe transaction histories of a given user account setM(US, x%)A detection model is constructed by using x% phased profiles of US{H(U, r%)|U∊US}A hybrid phased profiles constructed by {M(US, r%)|r∊{80, 85, 90, 95, 100}}〈a1(x), a2(x),…,an(x)〉ar(x) denotes the rth attribute value of instance x in the n-dimensional space Rnd(xi, xj)The similarity of two instances xiand xjPr[Mj|D]Given data D, the posterior possibility of choosing MjSnThe nth status presented in the status set→Direct the next status or behavior in a given sequenceS1→S2→…→SnAn ordered sequence of status transitionCamouflage→AttackFlip camouflaged behavior into attackSEQA vector of statuses=(S1, S2,…,Sn)fspThe pth fraudsterFS=(fs1, fs2,…,fsp)A set of fraudsters consisted of fs1, fs2,…,fspH(FS)A set of transaction histories of members in FS. That is, H(FS)={H(fs1), H(fs2),…,H(fsp)}Hhybrid(FS)A set of hybrid phased profiles is defined as {H(fs, r%)|fs∊FS, r∊P}, where P is the set of cut-pointsPmissThe probability of continuously misjudging a fraudster as a legitimate user