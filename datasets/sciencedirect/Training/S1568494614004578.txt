@&#MAIN-TITLE@&#
Automatic offloading of mobile applications into the cloud by means of genetic programming

@&#HIGHLIGHTS@&#
This work defines a taxonomy of the main properties of a mobile application useful for the task of offloading, divided into four categories: user, network, data and application.The paper describes the design of an automatic framework that drives the process of offloading, by building and validating models for that process.The system permits the analysis of the behavior of our algorithm for different categories of mobile applications, presenting different distributions of the main properties.A GP-based tool for building the decision tree-based model, which will decide whether it is convenient to perform the offloading of a mobile application, is adopted.Experimental evaluation permitted the analysis of the behavior of our algorithm for different categories of mobile applications.

@&#KEYPHRASES@&#
Mobile computing,Cloud computing,Genetic programming,Data mining,

@&#ABSTRACT@&#
The limited battery life of modern mobile devices is one of the key problems limiting their use. Even if the offloading of computation onto cloud computing platforms can considerably extend battery duration, it is really hard not only to evaluate the cases where offloading guarantees real advantages on the basis of the requirements of the application in terms of data transfer, computing power needed, etc., but also to evaluate whether user requirements (i.e. the costs of using the cloud services, a determined QoS required, etc.) are satisfied. To this aim, this paper presents a framework for generating models to make automatic decisions on the offloading of mobile applications using a genetic programming (GP) approach. The GP system is designed using a taxonomy of the properties useful to the offloading process concerning the user, the network, the data and the application. The fitness function adopted permits different weights to be given to the four categories considered during the process of building the model. Experimental results, conducted on datasets representing different categories of mobile applications, permit the analysis of the behavior of our algorithm in different applicative contexts. Finally, a comparison with the state of the art of the classification algorithm establishes the goodness of the approach in modeling the offloading process.

@&#INTRODUCTION@&#
Modern smartphones boosted their capabilities due to the increasing coverage of mobile broadband networks, to the new high-performance processors, to the large-volume storage and to new different types of sensors. All these capabilities together make it possible for mobile devices to handle much more complex tasks and to execute modern mobile applications; however that consumes a lot more computing and networking resources and therefore demands much more energy, while the battery technology has not developed as fast as mobile computing technology and has not been able to satisfy the increasing energy demand. In addition, in the last few years, the introduction of larger screens further reduces the battery life of the mobile devices.Therefore, owing to these problems and to the proliferations of mobile devices (i.e. tablets and smartphones), the interest in trying to improve the limited life of their batteries is greatly increased. A possible solution to alleviate this problem is to offload part of the application or the whole computation to remote servers, as explained in [11], where software-based techniques for reducing program power consumption are analyzed, considering both static and dynamic information in order to move the computation to remote servers.In the last few years, the emergence of cloud computing technology and the consequent wide availability of cloud servers [3], has encouraged research into the use of offloading techniques on cloud computing platforms. A number of papers were published trying to cope with the main issues of the process of offloading, mainly oriented toward a particular problem area, i.e. wifi issues [14], network behavior [18] and network bandwidth [22], the tradeoff between privacy and quality [15] and the effect of the context [1].However, to the best of our knowledge, the works concerning this theme do not consider a model taking into account both the hardware/software issues and the user requirements, neither is there reference to an automatic and adaptive model to take the decision of performing the offloading. Indeed, the offloading technique potentially could improve both performance and energy consumption; however, it is an NP-hard problem to establish whether it is convenient to perform the migration, especially considering all the correlated problems such as network disconnections and variability, privacy and security of the data, variations of load in the server, etc.This paper presents a framework for modeling the automatic offloading of mobile applications using a genetic programming approach, which attempts to address the issues listed above; furthermore, it can be used to simulate different kinds of mobile applications and to generate rules for the offloading process in form of decision trees that can be analyzed by the user. The framework, originally introduced in [6], is made up of two parts: a module that simulates the entire offloading process, and an inference engine that builds an automatic decision model to handle the offloading process. The simulator and the inference engine both apply a taxonomy that defines four main categories concerning the offloading process: user, network, data and application. The simulator evaluates the performance of the offloading process of mobile applications on the basis of user requirements, of the conditions of the network, of the hardware/software features of the mobile device and of the characteristics of the application. The inference engine is used to generate decision tree-based models that take decisions concerning the offloading process on the basis of the parameters contained in the categories defined by the taxonomy. This is based on a GP-based tool that generates the models using the parameters defined by the taxonomy and driven by a function of fitness, giving different weights to the costs, time, energy according to the priorities assigned.The main contribution of the framework can be summarized as follows:•The proposal of a taxonomy of the main properties of a mobile application useful for the task of offloading, divided into four categories: user, network, data and application.The design of an automatic framework that drives the process of offloading, by building and validating models for that process.A GP-based tool for building the decision tree-based model, which will decide whether it is convenient to perform the offloading of a mobile application, is adopted.The system permits the analysis of the behavior of our algorithm for different categories of mobile applications, presenting different distributions of the main properties.A simulation tool integrating both the cloud and the mobile part.The rest of the paper is structured as follow: Section 2 surveys existing works; Section 3 describes the software architecture of the system and the different modules composing the framework; Section 4 presents the results of the method using different experimental setups; Section 5, finally, concludes this paper by giving a discussion of the approach and some final considerations.All the issues involved in the offloading decision, such as network disconnections and variability, data privacy and security, variations in load of the server, etc. need to be evaluated carefully and that makes it difficult to design an automatic system for this purpose. In fact, analyzing the works in the literature concerning the offloading of mobile applications, the problem of finding an automatic methodology to perform offloading is not much explored.A paper introducing general arguments on the process of offloading was written by Kumar and Lee [13]. The authors analyze the main problems derived from offloading mobile applications onto the cloud such as privacy, costs, energy consumption and show which applications can benefit from this approach. They introduce a simple model for deciding whether it is convenient to perform the offloading and they try to apply the technique only to computationally expensive functions while computing other tasks locally.Other papers are devoted to the utility of performing offloading, basing their considerations on some criteria, i.e. energy consumption, costs, network use, etc. For instance, in [16] the decision to perform the offloading is based on the difference between the energy used when the task was executed locally on the mobile device or remotely on the cloud servers. The power consumption of the local execution is estimated by counting the CPU cycles while, as for the remote execution, it is calculated only considering the network use (data transfer). Our model is more sophisticated, as it considers also the hardware components that are used during computation and the issues concerning the transfer of the data (i.e. CPU, wifi, 3g, display, system, etc.).In [11] a two-step method is used. First, a database of application power use is built through standard profiling techniques. Then, the authors exploit the property stated in the paper that, for a limited class of applications (i.e. applications in which the cost depends only on the scale of the input), the algorithmic complexity combined with the profiling can be used to predict the energy cost of the execution of the application itself. Unfortunately, real-world applications can be hardly modeled considering only their input.Many papers are devoted to techniques and strategies to alleviate the process of offloading analyzing the code of the application or optimizing some energy-consuming processes, i.e. the acquisition of the GPS signal. For instance, Saarinen et al. [20] analyze the application source code and identify methods presenting hardware and/or software constraints, which do not permit the offloading. In addition, they also consider traffic patterns and power saving modes. However, the work does not consider network conditions and user requirements. Note that these approaches are orthogonal to our work and can be adopted in order to optimize some phases of the offloading process.Spectra [5] is a remote execution system that monitors application resource use and the availability of the resources on the device and dynamically chooses how and where to execute application tasks. The framework provides APIs to developers to build application suitable to the defined architecture. X-ray [19] is an automatic system, which profiles an application and decides what offloading computation is useful and when. The X-ray profiling stage observes application and system events (Gui, sensor, GPS, memory, CPU) and identifies “remotable” methods. If a method does not use local resources then it is remotable. Differently from these two systems, our framework is not method-based, but considers the entire application and the decision to perform the offloading is based not only on the application characteristics (size of data, privacy concern) but also on the system status (battery, 3g or wifi connection) and on some constraints requested by the user.Gu et al. [10] extend an offloading system with an offloading inference engine (OLIE), mainly used to overcome the memory limitations of a mobile device. OLIE solves two problems: first, it decides when to trigger the offloading action; second, it selects a partitioning policy that decides which objects should be offloaded and which pulled back during an offloading action. The decision of performing the offload is based on the available memory and on the network conditions (i.e. bandwidth, delay). To achieve a more powerful triggering system, OLIE uses a fuzzy control-based model with rules specified by the system and by the application developers. For instance, a simple rule for making adaptive offloading triggering decisions can be specified as follows: “if (AvailMem is low) and (AvailBW is high) then NewMemSize is low” and the fuzzy system simply uses a linguistic approach to assign a specific value to the linguist value of low (i.e. 500k). In comparison to simple threshold-based offloading triggering, the fuzzy control model allows OLIE to implement more expressive and configurable triggering conditions. This approach is orthogonal to our and could be used to improve the thresholds decided by our tool, but our decision tree-based model is more expressive and powerful, as it considers also issues related to the user requirements and not only the hardware/software characteristics of the application and of the device.The main idea behind our system is using genetic programming to evolve models, in the form of decision trees, which will decide whether it is convenient to perform the offloading of a mobile application on the basis of the parameters and the properties typical of the application, of the user and of the environment, with the support of a tool for simulating both cloud and mobile environments. The overall software architecture of the system, illustrated in Fig. 1, will be helpful in understanding how the framework works.On the top of the architecture, there are the modules containing the data, which will be used by the other components of the system. These different modules will contain a set of data for each of the four different categories considered. We refer the reader to Section 4.1 for a detailed description of these categories. It is out of the scope of this paper to describe the techniques used to estimate these components; we just would like to mention that in the case of the parameters describing the mobile devices, they can be found in the literature for some models and can be estimated using appropriate applications, such as PowerTutor, available in the Google Play store for android-based mobile devices. The process to estimate the energy consumption for various types of applications and for multiple classes of devices is analogous to that presented in [17].Afterwards, the sampler module will generate the training and the validation dataset, by randomly combing the data estimated by the above-mentioned models. These two datasets will be used respectively to generate and validate the decision models.Analyzing the rest of the software architecture, we find the two main modules, used respectively for the simulation and for the inference of the mobile offloading module. The inference part of the designed system consists of a genetic programming module, developing a population of models, suitable to decide the possible offloading of a mobile application. Indeed, each single model of the GP population represents a decision tree able to decide a strategy for the offloading and must be evaluated using the simulation module.BoostCGPC is used to generate the models by randomly combining the function and terminal nodes, then each model is sent for the evaluation to the simulation module (the entire block, now named simulator module, comprising the mobile and the GreenCloud simulator).The simulation module consists of the GreenCloud simulator (simulating the cloud part of the offloading process) and of a mobile simulator designed in order to model the mobile device behavior. In practice, each model generated by the GP module is passed to the simulator module, which performs the fitness evaluation directly on the basis of the results obtained simulating the model using the training dataset.At the end of the process, the best model (or the best models) will form the rules adopted by the offloading engine, which will decide whether an application must be offloaded, considering the defined conditions (user requirements, bandwidth, characteristic of the mobile device and so on). The evaluation set could be used to decide if it is convenient to maintain all or part of the generated models in the repository for future use. In fact, the user can choose, as parameter of the system, the maximum number of models (or in alternative an error-based threshold) and consequently, when the maximum number of models is reached, the models with the worst accuracy is eliminated or, in alternative, other pruning criteria can be adopted.Note that the entire system is adaptive; in fact, in the case of changes in the data modules, it is not necessary to run again all the components from scratch. For instance, if we have new data, they can be added to the training data, then, the BoostCGPC algorithm will run for a number of rounds and the weights of the ensemble will be consequently adjusted. In addition, just in the case of drastic changes in the data (i.e. concept drifts), the GP module must run entirely and it will generate new models that will replace parts of the old models in accordance to some pruning criteria (i.e. by replacing the oldest or the worst performing classifiers).In this section, the GP system and its design are described.The rules used to perform the offloading process are generated using a genetic programming tool, named BoostCGPC Boost Cellular Genetic Programming Classifier[8]. One of the advantages of the chosen GP-based module is that it can run on parallel/distributed architectures, permitting time-saving in the most expensive phase of the training process. Furthermore, the use of GP supplies the characteristic of adaptivity and the possibility of working with little knowledge of the domain, which is really useful to this particular aim. As usual, in order to use GP for a particular domain, it is sufficient to choose an appropriate terminal and function set and to define a fitness function. We chose a typical approach to GP for generating decision trees, choosing as terminals simply the two answers, yes and no, to the question “Is the process offloadable?”. As nodes, the main parameters/properties that will drive the offloading process are used. More details about functions and terminals will be given in Section 3.1.2.The Boost Cellular Genetic Programming Classifier[8] algorithm builds GP ensembles using a hybrid variation of the classical GP distributed island model. GP ensembles offer several advantages over a monolithic GP, i.e. the possibility of coping with very large data sets, more simple and understandable models, robustness and obviously the advantages related to a distributed implementation.BoostCGPC adopts the AdaBoost.M2 version of the well-known boosting algorithm introduced by Schapire and Freund [9] for “boosting” the performance of any weak learner, i.e. an algorithm that “generates classifiers which need only be a little better than random guessing”. Therefore, in this section, first the original boosting algorithm is described, then BoostCGPC and the distributed variant of boosting used are illustrated.The boosting algorithm adaptively changes the distribution of the training set depending on how difficult each example is to classify. Given the number T of trials (rounds) to execute, T weighted training sets S1, S2, …, STare sequentially generated and T classifiers C1, …, CTare built to compute a weak hypothesis ht. The value 1 is assigned to the weak hypothesis ht(xi, yi) if the hypothesis classifies the example xito the class yi, else the value 0 is assigned to it.Letwitdenote the weight of the example xiat trial t. At the beginningwi1=1/nfor each xi, where n is the number of tuples of the training set. At each round t=1, …, T, a weak learner Ct, whose error ϵtis bounded to a value strictly less than 1/2, is built and the weights of the next trial are obtained by multiplying the weight of the correctly classified examples by βt=ϵt/(1−ϵt) and re-normalizing the weights so thatΣiwit+1=1.In this way, it focuses on examples that are hardest to classify, as “easy” examples get a lower weight, while “hard” examples, which tend to be misclassified, get higher weights. The boosted classifier gives the class label y that maximizes the sum of the weights of the weak hypotheses predicting that label, where the weight is defined as log(1/βt). The final classifier hfis defined as follows:(1)hf=argmaxy∈Y∑tTlog1βtht(x,y)In practice, BoostCGPC is an ensemble-based algorithm, in which each GP classifier forming the ensemble is built using a cellular GP algorithm (cGP)[7], enhanced with the boosting technique, which runs on each node. cGP runs for T rounds; for every round it generates a classifier per node, exchanges it with the other nodes, and updates the weights of the samples for the next round, according to the boosting algorithm. The selection rule, the replacement rule and the asynchronous migration strategy are specified in the cGP algorithm. Each node generates the GP classifier by running for a fixed number of generations. During the boosting rounds, each classifier maintains the local vector of the weights that directly reflect the prediction accuracy. At each boosting round the hypotheses generated by each classifier are exchanged among all the processors in order to produce the ensemble of predictors. In this way, each node maintains the entire ensemble, which can be used to recalculate the new vector of weights. After the execution of the fixed number of boosting rounds, the classifiers are updated.The distributed variant of AdaBoost.M2 used in BoostCGPC is illustrated in the pseudocode reported in Fig. 2and described shortly in the following (we refer the reader to [8] for a detailed description of the algorithm).Given the training set S={(x1, y1), …, (xN, yN)}, containing N samples, where xirepresents the feature vector of the ith sample and yithe corresponding label (assigned among the possible K classes), and given the number p of processors to be used to run the algorithm, we partition the population of classifiers in p subpopulations, one for each processor, and draw p sets of samples of sizen=Np, by uniformly sampling instances from S with replacement. Each subpopulation is evolved for g generations and trained on its local sample by running cGP. After g generations, the individual with the best fitness is selected for participating to vote. The fitness is weighted using the distributionwi,yt, which represents the weight of the tuple i, when it is assigned to the class y. Note that each processor maintains a local vector of the weights, so that the distributionwi,yton processor 1 is different from the distributionwi,yton processor 2 and so on. Then, the p individuals, one for each subpopulation, with the best fitness are exchanged among the p subpopulations and make up the ensemble of predictors that will determine the weights of the examples for the next round. After the execution of the fixed number T of boosting rounds, the overall classifiers composing the ensemble (the overall number will be p·T), collected during the different rounds, are used to evaluate the accuracy of the classification algorithm.This section describes the fitness function used in the GP inference engine and the function and terminal nodes used.For this particular domain, in order to design an appropriate fitness function, it is necessary to take into account three objectives: the energy wasted, the cost supplied to use the Cloud and the time saved (or wasted) in performing the offload process. In practice, it is a multi-objective optimization problem and clearly there does not exist a single solution that simultaneously optimizes each objective. In fact, it is evident that there is no way to improve on one objective without degrading at least another one (i.e. reducing the time without increasing the cost in using the Cloud platform). Different taxonomies were proposed for classifying multi-objective problems in the context of evolutionary algorithms [4]. From the point of view of the user preferences (decision maker), we can distinguish the case of no-preferences, a-priori and a-posteriori, indicating that, respectively, the user does not indicate any preferences or makes his choice before or after the optimization process. In our case, we are interested in defining the preferences before the process begins. A different classification concerning evolutionary algorithms distinguishes aggregation-based, criterion-based and dominance-based fitness assignment strategies. In the first case, the objectives are parameterized in a single-objective function, i.e. a weighted sum can be used. The second case affects the selection of the individuals, which switches among the different objectives, i.e. different portions of individuals are chosen in accordance to different objectives. The latter uses some criteria based on the Pareto dominance in order to compute the fitness. In our case, we are mostly interested in defining the fitness in accordance to the user's preferences that can be also drastically oriented towards one or two objectives. Therefore, we decided to choice an aggregation-based (weighted sum) strategy, as differently from the other two strategies, it permits to directly choose the weights to give to the different criteria used (i.e. the energy, the time and the cost saved by performing the offloading process); therefore, it is more appropriate in the cases in which the different criteria can be really unbalanced. By using the other two techniques, it would not be easy to define the relative importance of the different criteria.In the following, we described more in details as the fitness function is defined.First of all, we define three normalized functions, representing respectively the energy saved, the time saved and the cost saved during the process of offloading (actually the latter is a negative value, as it is a cost not a saving): Senergy, Stime and Scost.Senergy=Elocal−Eoffloadmax(Eoffload,Elocal), i.e. the ratio between the energy saved executing the process on remote servers and the energy necessary to perform the offloading. The energy is computed in accordance with the analysis defined in [13] and the methodology is better detailed in Section 3.2 together with the costs derived from using the cloud resources.Stime=Tlocal−Toffloadmax(Toffload,Tlocal), i.e. the ratio between the time saved executing the process on remote servers and the time necessary to perform the offloading.Differently, the cost function is computed asScost=−CoffloadCsup, i.e. the ratio between the cost due to the remote execution and a parameter Csup defining a threshold of cost (if the cost overcomes Csup, Scost becomes −1).Finally, the fitness is computed as the weighted sum of the three equations described above, using three positive parameters (penergy, ptime, pcost), modeling the importance we want to give respectively to the energy saving, to the time saving and to the cost saving.Considering an element Ti(representing an application running on a determined device) of the training set T composed of n tuples, the fitness of this element is computed as: f(Ti)=penergy*Senergy+ptime*Stime+pcost*Scost and consequently the total fitness is given byftot=∑i=1i=nf(Ti).As for the functions and terminals, they were chosen following the typical approach to GP for generating decision trees. In practice, decision trees can be interpreted as composition of functions where the function set is the set of attribute tests and the terminal set are the classes. The function set can be obtained by converting each attribute into an attribute–test function. Thus, there are as many functions as attributes. For each attribute X, if X1, X2, …, Xnare the possible values X can assume, the corresponding attribute–test function fxhas arity n, and if the value of X is Xi, then fx(X1, X2, …, Xn)=Xi. When a tuple has to be evaluated, the function at the root of the tree tests the corresponding attribute and then executes the argument that outcomes from the test. If the argument is a terminal, then the class name for that tuple is returned that, in our case, represent the decision of taking (or not taking) the offloading decision; otherwise the new function is executed. A detailed description of the function set together with the set of possible values will be given in Section 4.1.The mobile simulator is written in java and its architecture comprises two sub-modules. The first computes the (time, energy and cost) models that specify hardware characteristics of the mobile devices and the costs of the cloud services. The second sub-module computes the fitness for all the tasks and interacts with the GreenCloud simulator in order to obtain the estimated values concerning the cloud environment (cost, execution time memory used, etc.).The main aim of the simulator is to estimate the three important components, which will be used to estimate the goodness (fitness) of a determined model built by the GP system: the time, the energy and the cost associated with that model. The equations used to estimate these three functions are based on the model developed by Kumar [13]. The first element is function of the time required to perform the task entirely on the mobile device and of the time required to perform the same task (or at least part of the task) on the cloud server considering also the overhead associated with the communication; the second element is determined by the energy wasted on the mobile device and the energy consumed performing the offload; finally, the third module represents the cost of the cloud computing services.The time component is the difference between the time to perform the task locally or remotely. The time of local computation mainly depends on three factors: the average execution time, the probability of interruption and the available memory. A higher probability of interruption corresponds to a large amount of time to complete the task. The available memory has effects on the computation time because the mobile OS performs a time-consuming swapping operation when memory is not sufficient.In the case of the offload, the time depends on the computation time on the server (obtained from the GreenCloud simulator) that corresponds to the waiting time of the mobile device and the time required to perform the migration of the data (and of part of the application). These delays depend on the type of network, on the latency and on the bandwidth available.The energy component is obtained from the difference of the energy consumed when the task is executed on the mobile device (EM) and the energy consumed when the task runs on the cloud servers (EC). The energy wasted on the mobile system is given by the product between the average energy consumption of the system for unity of time (Pm) and the execution time (Tm). Obviously, the energy depends on the CPU usage and on the system resources used (GPS, camera, etc.) that are correlated to complexity of the task, to the available battery and to the system load.Using the model proposed by Kumar, we indicate with C, the number of instructions required by the computation, with S the speed (in number of instructions for second) of the cloud server and with M the speed of the mobile device. If the data to be transferred between the mobile and the cloud system are D (bytes) and B is the network bandwidth, it takesDBseconds to transmit and to receive the data. In addition, the mobile consumes (watts) are indicated with Pc(computing), Pi(idle), and Ptr(sending and receiving data). So, the following equations represents respectively, (2) the energy consumed on the mobile system, (3) the energy consumed for the offloading process and for waiting the end of the computation on the cloud server and (4) the effective saving (ES), if positive of the complete offloading process.(2)EM=Pc*CM(3)EC=Pi*CS+Ptr*DB(4)ES=Pc*CM−Pi*CS−Ptr*DBThe GreenCloud simulator11http://greencloud.gforge.uni.lu/.[12], is a simulation environment for energy-aware cloud computing datacenters. It is derived from NS2 (network simulator) and tracks the power use of all the components involved in a datacenter: hosts, communication switches, etc. Datacenter power analysis is focused about three core objects: server, rack and switch. Servers are responsible for the task execution and they are described by computational limits (MIPS, million instructions per second), storage limits and memory limits. A rack is a group of servers linked together by a Top-of-Rack switch that connects these servers to the main network. Each switch, and consequently the underlying servers, can be disabled to save energy.In order to model the server load, the GreenCloud simulator uses the workloads. The workloads are the objects designed for universal modeling of various cloud user services, such as social networking, instant messaging, and content delivery. Indeed, only three workload types are provided: CIWs (Computation Intensive Workloads) model high performance applications that have high-computing load with very few data to transfer; DIWs (Data Intensive Workloads) are designed to simulate tasks with very heavy data transfers. BWs (Balanced Workloads) model applications with both data and computing requirements. Using these three types of jobs, GreenCloud is able to simulate different datacenter configurations and to report detailed energy consumption of all the components.In our framework, the GreenCloud simulator is used to evaluate the execution times of the part of the application offloaded on the servers and consequently the costs necessary to use the servers and the energy wasted. Although the main interest of this paper is on the mobile side, on the datacenter side, we need to simulate the processing delays, the submitting task rates, the impact of mobile data size in the overall performance in order to identify classes of applications that benefits from the computation offloading.In this section, we describe the taxonomy of the parameters and of the properties, which the GP module will use to build the model that will decide the offloading strategy and the way in which the data modules are related to the taxonomy.Unfortunately, there is no comprehensive taxonomy concerning the different aspects of the offloading process. Therefore, in this section, we define a taxonomy that divides the main parameters considered in the analysis of a mobile environment into four different categories: Application (i.e. the parameters associated with the application itself); User (the parameters desired and imposed by the user's needs); Network (i.e. parameters concerning the type and the state of the network); Device (i.e. the parameters depending only on the hardware/software features of the devices). In practice, the decision model, built by the GP module of our architecture, will perform the decision of offloading or not on the basis of the different parameters associated to these categories. It is worth noticing that many parameters could be more detailed and complex and other could be added; however, our taxonomy does not claim to be exhaustive, but we tried to simplify the model and did not consider particular aspects, which should not influence the offloading process.In the following, we will give a short description of the parameters chosen for each defined category. Where not differently specified, the values of the parameters have been discretized in ranges, using discrete values such as low, moderate, high, etc.The parameters associated with this category consider features, which are typical of the application to be executed on the mobile devices, in an attempt to characterize all the aspects useful to take a decision on the offloading process.The average execution time of the application measured for different typical dimensions of the input.The size of the data, which eventually should be transferred during the offloading process.A value expressing whether the application devotes most of its execution time to the execution of the local computation or to using the network (0 indicates an application performing only local computation, 1 an application continuously interacting with the network).A mobile application could be interrupted for different reasons: system crash, user interruption, no availability of a necessary resource (network, GPS, etc.). This parameter represents the probability the application is interrupted before the end of the process.This class of parameters considers the needs and the behavior of the user of the mobile device, modeling the different categories of users with their different styles.Every user has different behaviors and habits in terms of mobility. Some users spend most of the time in the same place (typically at home and at work), while others move frequently in different places and this should be considered in the process of offloading for the continuous changes in the network used, the need for a better duration of battery and so on. This parameter models the probability of mobility of the user.This parameter models the urgency or the priority with which the user wants to obtain the partial/final results of the application. If the user is too impatient to get results, he could prefer a greater battery consumption to a longer waiting time.People are understandably sensitive about how the application captures their data and how the data are used. However, different users can present different sensibility, from the paranoiac to the too confident user. In our context, choosing privacy-preserving solutions can degrade the performance of the offloading process, owing to the difficulty of moving the data or to the additional cost of adding protection.The cost a user can/wants to pay is a fundamental parameter in order to perform the offloading. In fact, the cost of the cloud platform is usually correlated to the time and the resources used.The network plays a fundamental role in the process of offloading, as it determines the velocity of the process and limits the possibility of exchanging data in real time. In fact, it is not convenient to perform the offloading of an application needing to exchange a large stream of data when the efficiency of the network does not permit a fast transfer of the data itself.As quality of service of the network we consider a parameter estimating the reliability and stability of the network.The bandwidth of the network is an important parameter to establish whether the offloading of large applications/data can be quickly executed.The latency of the network is useful when small quantities of data must be exchanged during the offloading process.This parameter models the type of network available, i.e. Wifi, 3G, 2G, etc. The type of the network is crucial for saving energy, as for instance, a device transmitting data using wifi consumes less battery than using 3G.The last class of parameters we consider is pertinent to the mobile device. Analyzing the state and the characteristics of the mobile device is essential in order to drive the process of offloading. On the following we list the most important parameters to be considered.The battery charge level is of fundamental importance, as, when it is low, the process of offloading can be encouraged.The load of the CPU and the available memory are two important parameters, which can influence the choice of the offloading rather than the execution on local resources.This parameter represents the strength of the network signal detected by the mobile device (obviously it depends both on the device and on the quality of the network).In this section, a description of the datasets modeling the offloading process and of the distributions used to generate them is supplied.We remember that the first four modules of the software architecture contain the sets of data for each of the four categories considered (user, device, network and application), which will be used by the sampler module in order to generate the training and validation datasets, simply by randomly combing the data. These two datasets will be used to generate and validate the decision models. Each dataset consists of a number of tuples and each feature composing the tuple is associated with a property described in the previous section and it is associated with a set of values. For each tuple, each feature (corresponding to a property of the taxonomy) is selected randomly by following a probability distribution. This is done to ensure that the dataset represents a realistic scenario. As, for many properties, the distributions are determined by the particular class of application, we choose to generate the datasets using different distributions in order to model the different types of behavior. In the experimental section, more details will be given on the chosen distributions.It is out of the scope of this paper to describe the techniques used to estimate parameters (mean value, etc.) used in the distributions; we just would like to mention that in the case of the parameters describing the mobile devices, they can be found in the literature for some models and can be estimated using appropriate applications, such as PowerTutor, available in the Google Play store for the android-based mobile devices. The process we conduct to estimate the energy consumption for various types of applications and for multiple classes of devices is analogous to that presented in [17], conducted on some modern android-based mobile devices. The other parameters of the distributions were taken from the literature [14,18,21,2]. In the following, we just cite some specific cases useful to justify our choices.The probability of interruption specifies a probability and the value is defined in [0,1] range. A mobile application could be interrupted for different reasons: system crash, user interruption, not availability of a necessary resource (network, GPS, etc.). This parameter represents the probability that an application is interrupted before the end of its process.As for the properties concerning the category of user requirement, most of them are subjective (i.e. mobility, urgency and privacy sensitivity) and are modeled using discrete values as very low, low, medium, high and very high. The network category also needs some explanations. The property named Quality of Service of the network estimates the reliability and stability of the network. The bandwidth of the network is another important parameter to establish whether the offloading of large applications/data can be quickly executed. The latency of the network is useful when small quantities of data must be exchanged during the offloading process. All these three properties are modeled using discrete values (very low, low, medium, high and very high). The last property of this category is the type of the network. This parameter models the type of network available and consequently affects the speed of transmission of the data (i.e. LTE is considerably faster than a 2G network). The feasible values are: wifi, 3G, 2G, LTE.Table 1synthesizes the discretization used for the different properties of the taxonomy; some properties need a finer level of discretization and we choose to use 6 values (D1), while for others using 3 values (D2) is sufficient to model their behavior.Finally, it is common that some of properties may present missing values (i.e. unknown or not specified, wrong or other) and that is handled with the possibility of having the value “undefined” (indicated with the symbol ?) in most of the features.

@&#CONCLUSIONS@&#
This work presents an automatic approach to generating decision-taking models for the offloading of mobile applications on the basis of user requirements, conditions of the network, the hardware/software features of the mobile device and the characteristics of the application. The system is made up of a general framework for testing offloading algorithms and includes a mobile simulator, which computes the energy wasted in the process of offloading and an inference engine that generates the models performing the automatic offloading process. The latter is based on a distributed GP module, in which the functions are the parameters of a ad-hoc designed taxonomy, and the fitness function is parametrically defined in a way that permits one to give a different weight to the cost, the time, the energy and the quality of service depending on what interests more.Experimental evaluation of our framework permitted the analysis of the behavior of our algorithm for different categories of mobile applications, when the distributions of the main properties of the systems and the parameters weighting the energy, the cost and the time are varied. We also compared our system with a boosted version of the C4.5 algorithm in order to establish the goodness of our approach in modeling the offloading process. Finally, we validate the framework on a real case concerning an OCR application. Ongoing and future activities involve testing the framework with other real-world datasets in order to verify whether the obtained models improve battery performance in real environments and to perform an analysis of the sensitivity of the system when the main parameters change.