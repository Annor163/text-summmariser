@&#MAIN-TITLE@&#
Robust fuzzy clustering algorithms in analyzing high-dimensional cancer databases

@&#HIGHLIGHTS@&#
Effective clustering techniques in selecting the relevant gene expression of cancer subtypes.Uncertain objects in high dimensional gene expression cancer database.Prototype initialization algorithm.

@&#KEYPHRASES@&#
Fuzzy C-means,Kernel distances,Uncertain objects,Cancer databases,

@&#ABSTRACT@&#
Due to uncertainty value of objects in microarray gene expression high dimensional cancer database, finding available subtypes of cancers is considered as challenging task. Researchers have invented mathematical assisted clustering techniques in clustering relevant gene expression of cancer subtypes, but the techniques have failed to provide proper outcome results with less error. Hence, it is an essential one in finding efficient computational clustering techniques to cluster the high dimensional gene expression cancer database for perfect diagnosis of cancer subtypes. This paper presents robust clustering techniques to identify perfect similarity between the uncertain objects of high dimensional cancer database. In order to obtain the robust clustering techniques, this paper incorporates both membership functions of fuzzy c-means and possibilistic c-means. In addition, this paper presents prototype initialization algorithm to avoid random initialization of initial prototypes. Benchmarks datasets were used to show the effectiveness of the proposed methods. The proposed methods were successfully implemented with microarray high dimensional gene expression cancer databases to separate available subtypes of cancer regions. The clustering accuracies of proposed and existed clustering methods indicate that the proposed methods are superior to the existed methods.

@&#INTRODUCTION@&#
The goal of this paper is to cluster the available subtypes of cancers in high dimensional microarray gene expression cancer database. The technology of microarray high dimensional database has significant impact on cancer research [14,40,44] in finding different types of tissues. A microarray gene expression database consisting of genes and tissue samples is typically organized in a 2D matrix. Each element in the 2D matrix gives the expression level of the gene for the tissue sample. The original gene expression database obtained from a scanning process which is contaminated by noise, and missing values. A major problem in microarray cancer database analysis is the large number of dimensions, and therefore the intensity between the tissue samples is almost similar [23]. Hence, researchers have introduced many clustering techniques to capture the available subgroups of genes in microarray high dimensional database [13,27,33,40,41]. But the prediction of subgroups in cancer database has not reached the expected percentage of confidence. Recently the unsupervised [9,17,19,36,38,39], and supervised [6,12,18] clustering techniques play an important role in clustering functionally related genes together for predicting the unlabelled gene expression about their classes of tissues. However the existing methods were not robust in finding subgroups of genes in high dimensional microarray cancer database with similar intensity tissue samples [21]. Very recently fuzzy set based fuzzy clustering [3,15,20,22,29,31] has been implemented to obtain appropriate subtypes of cancer classes in cancer database. The fuzzy set based fuzzy clustering allows gradual memberships to the data points to place an object in all clusters. The memberships offer a much finer degree of detail of the data model to cluster it into several groups and memberships can also express how ambiguously or definitely a data point should belong to a cluster [11]. Even though there are lots of benefits using fuzzy c-means algorithms, it has considerable drawbacks such as the result of clustering process deteriorates while uncertainty exists in the high dimensional medical database [25,46]. Our previous works in [22,31] have worked well in clustering low dimensional databases, but the methods are unsuitable for analyzing microarray gene expression high dimensional database. Therefore this paper attempts to provide robust fuzzy clustering techniques to capture the similar gene expression of cancer subtypes from high dimensional cancer database. This paper tries to obtain the robust kernel based fuzzy clustering algorithms in the combination of both fuzzy membership function and typicality of possibilistic c-means. Possibilistic approach has been shown to be advantageous in noisy environments, the algorithm helps to find valid clusters, and in finding a robust estimate of the cluster prototypes. Typicality-based fuzzy memberships automatically reduce the effect of noise points, and improve the accuracy of the results considerably. In order to obtain high degree of memberships for the data points that are equidistant from the prototype of the clusters, this paper obtained the possibilistic c-means based objective function of fuzzy c-means. The performance of obtaining membership to the noisy object is improved by relaxing the membership constraints using the typicality of the possibilistic c-means [28,45]. To overcome the undesirable effects of similar gene expression in updating reliable prototypes the penalized constraints of typicality is used with the proposed algorithms. Here the typicality values are constrained and the sum of the overall data points of typicalities to a cluster is equal to one. The proposed objective functions are enhanced by introducing new kernel induced distance called hyper tangent kernel Bray Curtis distance to evaluate the relations between cluster prototypes and data objects. Tangent kernel induced distance of proposed clustering techniques overcomes the difficulties in clustering the uncertain objects [37]. The neighborhood information of this paper effectively finds the difference between cluster prototypes and data points. The random selection of initial prototypes of fuzzy c-means leads more number of iteration to converge the termination condition [24,34], therefore this paper presents a mathematical prototype initialization method to reduce the number of iterations.The rest of the paper is organized as follows. In Section 2, this paper gives terminology of clustering techniques and workflow of the paper. Section 3 contains the proposed algorithms. Section 4 presents prototypes initialization method. Section 5 gives the method for clustering accuracy. The experimental results on Synthetic Dataset, Checkerboard Dataset, Wine dataset, IRIS Dataset, and High Dimensional Cancer Databases of the proposed clustering methods are reported in Section 6. Section 7 provides conclusion of this paper.Consider the data which contains N objects, and p attributes. Hence we have N×p dimension of the dataset. Let the data set G, which contains n data points say x1, x2,…,xn. Assume we have to find c clusters in G, where 2≤c≤N. In crisp clustering, the goal would be to partition G into the disjoint non-empty partitionsG=∑k=1CGk, and k∈{1, 2, 3, …, c}. The objective function is given byJcm(G,V)=∑i=1n∑k=1cD(xi,vk), wherevkis a prototypes of kth cluster. In fuzzy clustering, the goal would be to find the partition matrix U. The partition matrix is a real N×c matrix that defines membership degrees for each feature vector. u is defined by u∈RNxC=[uik], whereuik∈0,1,∀i,k. The objective function of fuzzy c-means [4] is as(1)Jfcm(G,V)=∑i=1n∑k=1cuikmD(xi,vk),(m>1)In fuzzy clustering the results of a given clustering method is dependent on the similarity measure. The smaller value of distance between two objects represents the larger similarity between objects; conversely, the larger value of distance between the objects represents the dissimilarity of the objects. The fuzzy clustering method uses the concept of prototype or center from members of cluster. Thus, the clustering problem becomes finding a set of c prototypes. The challenging to researchers in clustering is no single capable clustering technique for identifying clusters in all of real world problems, because of complicated structure of dataset and various noises in the dataset.Recently kernel function is considered as an effective similarity measure in clustering methods and kernel based clustering techniques have been successfully implemented with many real life applications [7]. The common ground of Kernel based clustering is to map the input data element into a feature space with higher dimension via a nonlinear transformation. Generally, the kernel function is defined in term of inner product space as(2)H(x,y)=φ(x),φ(y)=φ(x)Tφ(y)where φ:x↦φ(x) is a linear transformation and x∈X. Here, φ(x) is considered as higher dimensional feature space. The functionH(x,v)is called a kernel function, and assumed as known. Now the kernel induced distance function can be expanded using inner product space as:(3)ϕ(xn)−ϕ(vk)2=ϕ(xn)−ϕ(vk),ϕ(xn)−ϕ(vk)ϕ(xn)−ϕ(vk)2=ϕ(xn),ϕ(xn)+ϕ(vk),ϕ(vk)−2ϕ(xn),ϕ(vk)Therefore we have the new kernel induced distance function from Eq. (3) as:ϕ(xn)−ϕ(vk)2=H(xn,xn)+H(vk,vk)−2H(xn,vk),whereH(xn,vk)=ϕ(xn),ϕ(vk)If H(xn, xn)=1 andH(vk,vk)=1, then the distance function can be rewritten [45] as(4)ϕ(xn)−ϕ(vk)2=2(1−H(xn,vk))The above distance function is known as hyper tangent based distance measure.The derivation of the prototypes depends on the specific selection of the kernel function. If we consider the tangent kernel, thenH(vk,vk)=1(k=1,…, c) and the objective function of the Fuzzy C-Means[FCM] can be expressed asJFCM(U,V)=2∑k=1n∑i=1c(uikm)(1−H(xn,vk))The aim of this paper is to find robust fuzzy clustering techniques to find subtypes of cancers in high dimensional microarray cancer databases. To reduce the iterations of clustering algorithms in finding available subtypes of cancers the prototype initialization method is introduced. The proposed algorithms are implemented with artificial datasets and real benchmark datasets for evaluating the performance of the algorithms. The clustering validity methods are used to evaluate the clustering accuracy of the proposed algorithms. The working procedure in clustering cancer database into subtypes is stipulated in Fig. 1.This subsection introduces an effective fuzzy clustering technique to find the similar patterns or subtypes of cancers in high – dimensional cancer database which is corrupted by similar intensities between the objects, missing values and other noises by scanning process of gene expression. This paper incorporates fuzziness weighting exponent, the expression of possibilistic typical weighting exponent (τ) and tangent kernel induced distance with the objective of proposed fuzzy c-means to capture the meaningful information from cancer database. The proposed objective function of Tangent Fuzzy Possibilistic C-Means is given by(5)JTFPCM(U,V)=2∑k=1n∑i=1c(uikm+τikη)(1−TB(xk,vi))whereTB(xk,vi)=1−tanh−B(xk,vi)σ2,B(xk,vi)=xk−vi2xk+vi2, and the TBrepresents tangent Bray Curtis kernel induced distance.The proposed partition matrix satisfies the following conditions:(6)0≤uik≤1,for1=i=c,1=k=n,0<∑k=1nuik<n,for1=i=c,∑i=1cuik=1,k=1,...,n∑k=1nτik=1,i=1,...,cm & η in (5) are weighting exponents. The weighting exponents compute the amount of fuzziness in the resulting classification in order to obtain proper center of cluster from the database which has similar gene expression. By minimizing Eq. (5) we have obtained the degrees of membership, typicality and the cluster centers. To minimize Eq. (5) subject to the conditions, the Lagrangian multiplier rule is used. Together Lagrangian multiplier Eq. (5) is as:(7)LTFPCM(U,V)=2∑k=1n∑i=1c(uikm+τikη)(1−TB(xk,vi))−λk∑i=1cuik−1−δi∑k=1nτik−1where λ=(λ1, λ2, …, λn) subject to the constraints∑i=1cuik=1∑k=1nτik=1Minimizing the TFPCM in Eq. (7) with respect to uikand τik, we have obtain a generalized Membership equations uikand typicality τikfor the iterative solution of an objective function.∂LTFPCM∂uik=2muikm−11−TBxk,vi−λk⇒uik=λk2m1m−111−TBxk,vi1m−1λk2m1m−1=1∑j=1c11−TBxk,vj1m−1The general iterative center updating equation is as:(8)⇒uik=11−TBxk,vi1m−1∑j=1c11−TBxk,vj1m−1∂LTFPCM∂τik=2ητikη−11−TBxk,vi−δi⇒τik=δi2η1η−111−TBxk,vi1η−1δi2η1η−1=1∑l=1n11−TBxl,vi1η−1The typicality τikis as:(9)⇒τik=11−TBxk,vi1η−1∑l=1n11−TBxl,vi1η−1By minimizing the following objective functionJTFPCMU,V=2∑k=1n∑i=1cuikm+τikη1−TBxk,viwith respect tovithis paper obtains the equations for updating the cluster center or prototypes of TFPCM.∂JTFPCM∂vi=∑K=1nμikm+τikηTBxk,vi.T′Bxk,vixk+vi2+xk−vi2xk−xk+vi2−xk−vi2vixk+vi22whereT′Bxk,vi=1+tanh−xk−vi2xk+vi2σ2The general center updating equation is as:(10)vit=∑K=1nμikm+τikηTBxk,vit−1.T′Bxk,vit−1B′dxk,vit−1xk∑K=1nμikm+τikηTBxk,vit−1.T′Bxk,vit−1Bdxk,vit−1Where t represents the iteration count,TBxk,vi=1−tanh−Bxk,viσ2,Bxk,vi=xk−vi2xk+vi2, andBdxk,vi=xk+vi2−xk−vi2xk+vi22,B′dxk,vi=xk+vi2+xk−vi2xk+vi22To avoid high similarity score to a pair of dissimilar patterns of gene expressions, this subsection introduces neighborhood tangent fuzzy possibilistic c-means [NTFPCM] by incorporating the neighborhood information, kernel functions, and possibilistic c-means.The objective function of NTFPCM is defined by(11)JNTFPCMU,V=2∑k=1n∑i=1cuikm+τikη1−TBxk,vi+1−TBχk,viHereχk=hxk+Antilog∑xh∈NklogxhNk.Together with Lagrangian multipliers and the constraint∑i=1cuik=1and∑k=1nτik=1, the proposed effective NTFPCM reads as(12)LNTFPCMU,V=2∑k=1n∑i=1cuikm+τikη1−TBxk,vi+1−TBχk,vi−λk∑i=1cuik−1−δi∑k=1nτik−1Whereχk=hxk+Antilog∑xh∈NklogxhNkTBxk,vi=1−tanh−Bxk,viσ2andBxk,vi=xk−vi2xk+vi2This subsection obtains the optimal solution of uikand τikby solving the objective function of NTFPCM. Subject to the constraints∑i=1cuik=1and∑k=1nτik=1the objective functionJNTFPCMU,V=2∑k=1n∑i=1cuikm+τikη1−TBxk,vi+1−TBχk,viis minimized with respect to uikand τikusing the necessary condition of Lagrangian method, we have(13)∂LNTFPCM∂uik=2muikm−11−TBxk,vi+1−TBχk,vi−λk⇒uik=11−TBxk,vi+1−TBχk,vi1m−1∑j=1c11−TBxk,vj+1−TBχk,vj1m−1(14)∂JNTFPCM∂τik=2ητikη−11−TBxk,vi+1−TBχk,vi−δiτik=11−TBxk,vi+1−TBχk,vi1η−1∑l=1n11−TBxl,vi+1−TBχl,vi1η−1By minimizing the objective functionJNTFPCMU,V=2∑k=1n∑i=1cuikm+τikη1−TBxk,vi+1−TBχk,vi, with respect tovithis subsection is obtained the center. The cluster center is given by(15)∂JNTPFCM∂vi=2∑K=1nμikm+τikη1−tanh2−xk−vi2xk+vi2σ2−1σ2xk+vi2−2xk−vi−xk−vi22xk+vixk+vi22+1−tanh2−χk−vi2χk+vi2σ2−1σ2χk+vi2−2χk−vi−χk−vi22χk+viχk+vi22vit=∑K=1nuikm+τikηTBxk,vit−1T′Bxk,vit−1B′dxk,vit−1xk+TBχk,vit−1T′Bχk,vit−1B′dχk,vit−1χk∑K=1nuikm+τikηTBxk,vit−1T′Bxk,vit−1Bdxk,vit−1+TBχk,vit−1T′Bχk,vit−1.Bdχk,vit−1where t represents the iteration count andBdxk,vi=xk+vi2−xk−vi2xk+vi22,B′dxk,vi=xk+vi2+xk−vi2xk+vi22The random choice of initial prototypes of clustering techniques causes the resulting clusters and leads more number of iterations. Hence this subsection presents a mathematical approach to select the initial cluster prototypes of the proposed algorithm to avoid the random choice of inappropriate initial prototypes.The mathematical method is organized with the following steps:Step 1:Consider the data matrix,X=x11,x12,……x1Nx21,x22,……x2Nx31,x32,……x3N............................................................xn1,xn2,……xnN, where N-Dimension, n- number of elementsLetm1=x11+x12+.....+x1NNm2=x21+x22+.....+x2NN⋮mn=xn1+xn2+.....+xnNNIn generalmi=xi1+xi2+.....+xiNN,i=1,2,…nStep 2:Arranging these m1, m2,….,mnvalues in ascending order and relabeling the suffix asM=m1,m2,....,mnStep 3:Finds=nc, where c represents number of clusters and n represents no. of elements in the dataset.Case 1.Suppose s is an integer, then s elements exist in each clusterCase 2.Suppose s is not an integer.Consider s=s.d, where d is decimal point.If the decimal d <0.5, then s.d has been rounded as sIf the decimal d >=0.5, then s.d has been rounded as s+1Step 4:Rearrange the data matrix in respect of its relabelling mean value.(i.e)X′=x11,x21,……xN1x12,x22,……xN2x13,x23,……xN3..................................................x1n,x2n,……xNnPartitioning the data into groupsFirst group contains first s data of X’Second group contains second s data of X’⋮cth group contains cth s s data of X’.Last n-s data keeps in separate group.Step 5Find the median of each group. Let it be median1, median2,…, medianc.Fix this median as a cluster Prototype.(OR)Group1=x11,x21,……xN1x12,x22,……xN2.................................................x1s,x2s,……xNsGroup2=x1s+1,x2s+1,……xNs+1x1s+2,x2s+2,……xNs+2.................................................x12s,x22s,……xN2s⋮Groupc=x1(c−1)s+1,x2(c−1)s+1,……xN(c−1)s+1x1(c−1)s+2,x2(c−1)s+2,……xN(c−1)s+2...........................................................................................x1cs,x2cs,…….............xNcsPrototype1=(median(1st column of group1), median(2nd column of group1),……,median (Nth column of group1))Prototype2=(median (1st column of group2), median(2nd column of group2),……,median (Nth column of group2)).⋮Prototype c=(median (1st column of group c), median(2nd column of group c),……,median (Nth column of group c))The cluster accuracy is defined using silhouette width [30,32]. The proposed fuzzy clustering based methods assign each point to all clusters with membership values. Assume two classes we have namely A and B. From the partition membership matrix, take the ith object in the cluster A, and compute the silhouette value say a(i)a(i)=1/|A|−1∑j∈A,j≠id(i,j),where a(i) is a average dissimilarity of i to all objects of A.Consider a second cluster B different from A and putd(i,B)=1/|B|∑j∈Cd(i,j)=average dissimilarity of i to all objects of B, clusters B≠A. Computing b(i)=minB≠Ad(i, B). Computing the silhouette width of the ith object as Silhouette width (i)=(b(i)−a(i))/max (a(i), b(i)). The silhouette width is obtained for each object of the cluster and the average of the silhouette of all the objects is considered as clustering accuracy of the particular cluster. These silhouette accuracy measures the degree of confidence in the clustering assignment of a particular observation, with perfect observations which has values nearly 1 and poor observations which has values nearly −1. The observations are helped in deciding the obtained substructure of dataset is meaningful. In the context of clustering validation, it is clear that when the resulted cluster has clustering accuracy below the value 0.50, the algorithm is not finding an appropriate cluster and the cluster contains inappropriate objects. If the resulted cluster has obtained the clustering accuracy between the values 0.51–0.75, then the cluster structure is considered as reliable structure. In case the accuracy of resulted cluster reaches 0.76 and above, the cluster is considered as well structured cluster.

@&#CONCLUSIONS@&#
