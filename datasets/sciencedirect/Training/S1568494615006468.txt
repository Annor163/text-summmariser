@&#MAIN-TITLE@&#
Studying the effect of population size in distributed evolutionary algorithms on heterogeneous clusters

@&#HIGHLIGHTS@&#
We present a study on the adaptation of the island sizes of a distributed Evolutionary Algorithm to the computational power of the nodes of an heterogeneous cluster.Three problems with different characteristics and computational demands (MMDP, OneMax and Rosenbrock Shifted Function), have been used to give an insight of the effects of this proposal and tested in two different hardware systems (homogeneous and heterogeneous cluster).As a first step, we have adapted (offline) population sizes proportionally to the attained generations to obtain the optimum with the same population size in all islands.We also have adapted the population size during runtime (online) comparing with the current number of generations of the neighbours of the topology.Results show that adapting (online and offline) the population sizes to the computational power of the nodes of a heterogeneous cluster can decrease time to obtain the optimum solution.

@&#KEYPHRASES@&#
Evolutionary Algorithms,Genetic algorithms,Distributed computing,Parameter tuning,Parameter control,

@&#ABSTRACT@&#
Distributed Evolutionary Algorithms are traditionally executed on homogeneous dedicated clusters, despite most scientists have access mainly to networks of heterogeneous nodes (e.g., desktop PCs in a lab). Fitting this kind of algorithms to these environments, so that they can take advantage of their heterogeneity to save running time, is still an open problem. The different computational power of the nodes affects the performance of the algorithm, and tuning or fitting it to each node properly could reduce execution time.Since the distributed Evolutionary Algorithms include a whole range of parameters that influence the performance, this paper proposes a study on the population size. This parameter is one of the most important, since it has a direct relationship with the number of iterations needed to find the solution, as it affects the exploration factor of the algorithm. The aim of this paper consists in validating the following hypothesis: fitting the sub-population size to the computational power of the heterogeneous cluster node can lead to an improvement in running time with respect to the use of the same population size in every node.Two parameter size schemes have been tested, an offline and an online parameter setting, and three problems with different characteristics and computational demands have been used.Results show that setting the population size according to the computational power of each node in the heterogeneous cluster improves the time required to obtain the optimal solution. Meanwhile, the same set of different size values could not improve the running time to reach the optimum in a homogeneous cluster with respect to the same size in all nodes, indicating that the improvement is due to the interaction of the different hardware resources with the algorithm. In addition, a study on the influence of the different population sizes on each stage of the algorithm is presented. This opens a new research line on the fitting (offline or online) of parameters of the distributed Evolutionary Algorithms to the computational power of the devices.

@&#INTRODUCTION@&#
Evolutionary Algorithms (EAs) are a general method for solving optimization and search problems inspired by the evolution of species and its underlying mechanism, natural selection. These algorithms work on a population of encoded possible solutions, called individuals, every one competing with others according to their fitness (quality or cost of the solution they encode). The population evolves, with iterations of the algorithm (or generations), by means of selection and recombination/mutation operators, creating a new set of candidates. This goes on until a stopping criterion (e.g. number of generations) is met. The fitness function, which describes the target problem, expresses the quality of the solution, giving the grade of adaptation of an individual.The performance of an EA can be measured by the running time required to find the optimal value and/or by the quality of the solution attained in a fixed time. The performance is affected by a set of parameters, such as the crossover rate, or population size, among others. Population size has been studied as a fixed [27] or adaptive [19,29] value, as it has a significant impact on the efficiency of an EA [28].Performance can also be improved using Distributed EAs (dEAs) [6], where the algorithm is run on a set of nodes simultaneously, working with different sub-populations (or islands) at the same time. One or more individuals are interchanged (migrated) periodically between sub-populations, which are connected following a specific topology. Fig. 1shows the island model with a ring topology.Cantú-Paz, in [8], published a theoretical study about population size, migration rate and the degree of the topology. This kind of algorithms has been usually executed on homogeneous clusters [6,42], being used with the same parameters in all nodes (homogeneous dEAs), or with different parameters (heterogeneous dEAs) [40,38,24].As previously said, population size is a key factor for the performance of dEAs [28], so this paper investigates whether adapting the sub-population size of each node in a distributed Evolutionary Algorithm can leverage the computational capabilities of a heterogeneous cluster.This is motivated by new trends in distributed computing, such as Cloud Computing [11], GRID [5] or Service Oriented Science [20], which are leading to heterogeneous computational devices, such as laptops, virtual machine instances, GPUs [1], tablets or desktop PCs, working in the same environment. Thus, many laboratories, which do not include classic clusters but the usual desktop and laptop computers, should be able to leverage this motley set as a heterogeneous cluster.It has been shown that [3] asynchronous dEAs with the same parameter configuration are even more efficient in time and the number of evaluations in reaching the optimal solution on this kind of environments than on clusters with homogeneous devices. This can be explained by different reasons, such as different memory access times, cache sizes, or even implementation languages or compilers in each machine, leading to a different exploitation/exploration rate of the search space [3].These facts have motivated the study of a combination of both ideas in this paper: asynchronous dEAs on a heterogeneous set of nodes with different parameter values fitted to each node. The concept parameter fitting is proposed in this work to distinguish with respect the term parameter adaptation defined by Eiben in [15]. Our concept specifies that the parameter values are set (online or offline) taking into account the computational power of the nodes, while the parameter adaptation implies a modification (online) of the parameters taking into account the information provided by the algorithm itself (for example, a variation in the average fitness value).In this case, the parameter to be fitted to the computational power of each node has been the sub-population size of each island. The population size is of capital importance in the accuracy and convergence speed of an EA. The population is a repository of the building-blocks that an evolutionary computational process recombines and mutates in order to improve the average fitness of the population and, eventually, find the optimal solution to the target-problem. If the supply of building-blocks is insufficient, selection and genetic drift will probably guide the search towards premature convergence to a local optimum (or the EA becomes too dependent on the randomness of the mutation operator). Larger populations guarantee a more diverse supply of building-blocks (higher genetic diversity) and are more likely to overcome premature convergence. However, in large populations, convergence speed is the payoff for accuracy: in general, when the population size of an EA grows, the convergence speed is reduced [9]. When having different processors with different computational power computing sub-populations of an EA, it may be a good policy to distribute the individuals in a way that less efficient nodes are assigned with smaller populations, having smaller diversity. This solution not only integrates within an EA two different types of evolutionary search (fast, with the smaller populations, and accurate, with the larger), but also puts on the most efficient nodes the burden of computing larger sub-populations. This combination can reduce computation time as slower nodes can exploit solutions without premature convergence and, at the same time, benefit from the diversity of the faster ones.In this work, a heterogeneous distributed system has been used to answer the following research questions:•Can an asynchronous distributed EA be fitted to leverage the capability of a heterogeneous cluster?How does the fitting of the sub-population size to the computational power affect the running time and number of evaluations?Is there any difference between using the same sub-population sizes on a homogeneous and a heterogeneous cluster?How is each stage of the algorithm (selection, recombination, mutation, replacement and migration) affected by the different configurations?The rest of the work is structured as follows: after a background in the algorithm parameter fitting to computational substrate in dEAs, the developed algorithms and experimental setting (Section 3) are presented. Then, the results of the experiments are shown (Section 4), followed by conclusions and suggestions for future work lines.Fitting algorithm parameters to available heterogeneous computational resources usually leads to improved performance [36]. An easy way to take advantage of the available resources is balancing the load [21,30] so that workloads are distributed across multiple elements. However, assigning equal tasks to each node in heterogeneous clusters may result in suboptimal performance [7].One of the problems in parameter tuning and adaptation on heterogeneous clusters is the computational load representation. It depends on the algorithm, size of the problem, language, compiler or hardware characteristics, so the results obtained from artificial benchmarks, such as Linpack [18], should not be extolled as identificative of the system performance [14]. For example, in the work of Garamendi et al. [21], a small benchmark was executed on all nodes at the beginning of the algorithm in order to distribute individuals of an Evolutionary Strategy (ES), following a master-slave model. The computational load by artificial benchmarks may not represent the correct load of the algorithm accurately, so, as proposed in this paper, information about the algorithm itself should be used for calibration.Besides, dEAs are not usually based in the master–slave paradigm for load balancing (unlike the Global Parallel EAs [4]), so setting different sub-population sizes may affect the algorithmic performance if used on heterogeneous environments.In other works, there is no direct relation between the algorithm parameters and the computational resources of the nodes. For example, Domínguez et al. [13] divided the available devices in “faster” and “slower” nodes to create a distributed hybrid meta-heuristic that combines two different methods: Genetic Algorithms (GAs) and Simulated Annealing (SA). Their system executes the GAs, heavier in computational terms, in the faster nodes, and simpler meta-heuristics (SA) in the slower ones, obtaining better results than other configurations. Gong et al. in [25] also ordered the nodes by their computational power to test different topology configurations in a distributed EA. Besides from ordering the nodes taking into account only their previously known computational resources, the results of previous works were not compared in a homogeneous cluster to validate if the fitting takes advantage of the heterogeneity of the cluster, as proposed in this paper.The heterogeneous computational performance of nodes or network speed can affect the performance of an algorithm. In [3], Alba et al. compared a dGA, on homogeneous and heterogeneous clusters. Super-linear performance in terms of number of iterations to find the optimum was obtained on the heterogeneous ones, being more efficient than the same algorithm running on homogeneous machines. However, the parameter setting was the same in both clusters and the authors did not fit the parameters to the machines used.Fitting algorithm parameters to computational nodes derives on heterogeneous parameter sets. These sets can improve the results on homogeneous hardware, for example, setting a random set of parameters in each homogeneous node can also increase the performance of a dGA, as explained by Gong and Fukunaga in [24]. That model outperformed a tuned canonical dGA with the same parameter values in all islands. Other approaches [10,39] optimise sets of heterogeneous parameters using meta-GAs. Single parameter fitting has also been studied. For example, adapting the migration rate produced better results than homogeneous periods, as explained by Salto and Alba in [32]. This indicates that heterogeneous parameters may lead to an increase of performance, so it is necessary to validate if the performance is due to the parameter set or by the heterogeneous devices combination.This work is focused on the sub-population sizes, as this parameter has been previously studied in different works due to its huge impact on the results. In the work of Weber et al. [43] two different sub-population sizes are used: higher size value for exploration, and a variable lower size value for exploitation. Schlierkamp-Voosen et al. [35] proposed a quality measure to be used in each sub-population to adapt the size, also taking into account the migration and crossover mechanisms. However, these works are based on the competition of sub-populations, taking into account only the information provided by the fitness of the population, and not by the machines that are executing the distributed EAs.In this work, the sizes of the sub-populations of a dEA are fitted (offline and online) to the computational power of each machine, using the information obtained from the algorithm itself, and compared on different hardware systems. To the best of our knowledge, there are no works that modify parameters of the EA, such as the size, depending on the node where the island is being executed, while taking into account information provided by the execution of the algorithm.In this section two different parameter setting schemes are proposed to test if fitting the sub-population sizes of an asynchronous dEA to the nodes of a heterogeneous cluster leads to time reduction. In the field of Evolutionary Computation (EC) there are two different approaches about the algorithm parameter setting: parameter tuning and parameter control[16]. The former consists in establishing a good set of parameters before the run (offline), that do not change during the execution. Parameter control refers to setting up a number of the EA parameters and changing these values in running time (online).In this study, a dEA with the same sub-population sizes has been executed in the heterogeneous cluster until the optimal solution is found, as a baseline. Then, the obtained number of generations has been used, to distribute the number of individuals proportionally among the nodes, that is, offline. The same set of sizes is used in a homogeneous cluster (as control system) to validate if the changes in performance are due to the parameters or the fitting to the nodes. Finally, an online parameter setting that extracts relative information about the performance of the nodes has been tested to validate our approach.The experimentation is focused on a distributed GA, one of the most extended EAs [17]. Algorithm 1 shows the pseudo-code of the used algorithm. It is a steady-state approach, i.e. in every generation the offspring is mixed with the parents and the worst individuals are removed. Also, each pair of parents selected during crossover generates two new individuals for offspring. That is, in each generation, a crossover with a rate of 0.5 selects half of population for crossover and generates an equal number of offspring. The selected neighbourhood topology for migration between islands (nodes) is a ring (see Fig. 1). The best individual is sent to the neighbour in the ring, after a fixed number of generations in each island. The algorithm stops when the optimum (the solution to the problem) is found.Algorithm 1Pseudo-code of the used dEA: a distributed Genetic Algorithm (dGA).population ← initialisePopulation()while stopping criterion not met doparents ← selection(population)offspring ← recombination(parents)   offspring ← mutation(offspring)O ← offspring.size //O is also equal to the number of parents selectedpopulation ← population + offspringif time to migrate thenmigrants ← selectMigrants(population)remoteBuffer.send(migrants)end ifif localBuffer.size ≠ zero thenimmigrants ← localBuffer.read()I ← immigrants.size()population ← population + immigrantsend ifif localBuffer.size ≠ zero thenpopulation ← population + localBuffer.read()end ifpopulation ← population - population.getTheWorst(O + I)end whileAlthough results may be independent of the problem, as an adaptive algorithm cannot replace a specific problem adaptation [10], different types of problems that cover different characteristics and computational demands have been used in this work.In these experiments, the Massively Multimodal Deceptive Problem (MMDP) [23], the OneMax problem [34], and the Rosenbrock Function [37] have been used. Each one requires different actions/abilities by the GA at the level of population sizing, individual selection and building-blocks mixing. Also, these problems have been used previously in other parameter adaptation algorithms, such as [39] (MMDP and OneMax) and [43,35] (Rosenbrock).The MMDP is designed to be difficult for an EA, due to its multimodality and deceptiveness. Deceptive problems are functions where low-order building-blocks do not combine to form higher order building-blocks. Instead, low-order building-blocks may mislead the search towards local optima, thus challenging search mechanisms. MMDP is composed of k sub-problems of 6 bits each one (si). Depending on the number of ones (unitation) sitakes the values shown in Table 1.The fitness value is defined as the sum of the sisub-problems with an optimum of k (Eq. (1)). The search space is composed of 26kcombinations from which there are only 2kglobal solutions with 2kdeceptive attractors. Hence, a search method has to find a global solution out of 25kadditionally to deceptiveness. In this work, three different problem sizes have been used: k=25 (150 bits), k=40 (240 bits) and k=50 (300 bits).(1)fMMDP(s→)=∑i=1kfitnesssiOneMax is a simple linear problem that consists in maximising the number of ones in a binary string. That is, maximise the expression specified in Eq. (2).(2)fOneMax(x→)=∑i=1NxiIn this case, three different string sizes have been used: 5000, 10000 and 15000.Finally, the Shifted Rosenbrock function is defined in Eq. (3).(3)fRosenbrock(x→)=∑i=1D−1[100(zi+1−zi2)2+(zi−1)2]+fbiasWith z=x−o+1 andx→=[x1,x2,…,xD], and considering D as the number of dimensions, and o=[o1, o2, …, oD] as the shifted global optimum.This is a multi-modal shifted function, which is non-separable and scalable and it presents a very narrow valley from local optimum to global optimum. It is part of the CEC 2005 Benchmark [37], and the optimum is set to the value 390 (with an error of 0.001). Three different chromosome lengths have been used: 10, 30 and 50.The main objective of this work is testing parameter fitting to hardware. Thus, different configurations should be used to compare and validate if the change in the parameters depends on the parameters, the hardware heterogeneity, or a combination of both. Therefore, the same parameters are used in a homogeneous cluster as a control system for the experiments. Five configurations of hardware and parameter settings were tested:•HoSi/HeHW: Homogeneous Size/Heterogeneous Hardware. The same sub-population size in each island on a heterogeneous cluster.HeSi/HeHW: Heterogeneous Size/Heterogeneous Hardware. Different sub-population sizes in each island on a heterogeneous cluster.HoSi/HoHW: Homogeneous Size/Homogeneous Hardware. The same sub-population size in each island on a homogeneous cluster.HeSi/HoHW: Heterogeneous Size/Homogeneous Hardware. Different sub-population sizes (the obtained for HeSi/HeHW) in each island on a homogeneous cluster.AdSi/HeHW: Adaptive Size/Heterogeneous Hardware. Online fitting of sub-population sizes in each island on a heterogeneous cluster.Two different computational systems were used: a heterogeneous cluster and a homogeneous cluster. The first one is formed by different computers of our lab with different processors, operating systems and memory size. The latter is a dedicated scientific cluster formed by homogeneous nodes. Table 2shows the features of every system and the name of the nodes.To study the scalability, two different numbers of nodes were used in each problem and configuration: 4 nodes (from HeN1/HoN1 to HeN4/HoN4, referred as 4X configuration for the rest of the paper) and 8 nodes (from HeN1/HoN1 to HeN8/HoN8, referred as 8X configuration). The same amount of nodes has been used previously in other works on dEAs on heterogeneous environments [3,13,33].The global population size was set to 1024 individuals. Other researchers who investigate in dEAs on heterogeneous environments have used 512 individuals (see the works [13,12,33]). However, as using 512 individuals in preliminary runs obtained extremely low sub-population sizes, a larger value was used. A population of 1024 is large enough to test different sub-population sizes in different number of computational nodes (4 and 8), allowing a better distribution among them. The stopping criterion for all approaches used in this work is to find the optimum of the problem, so that all runs have always finished when the optimum has been found in one of the nodes. This stopping criterion has been considered as Alba et al. did in [2], since it offers a fair way to compare the running time and behaviour of the tested configurations. Two-point crossover was used, as it has been used previously in studies on parallel GAs for binary problems [8], and BLX-0.5 for real coded dEAs [31].In this configuration, each node has the same number of individuals, so the total amount is 1024. The algorithm was run 40 times per problem instance on the homogeneous (HoHW) and heterogeneous clusters (HeHW). The average number of generations in each node of the HeHW cluster is shown in Tables 3(for 4X) and 4(for 8X). Note how the generations attained and their proportion in every node to reach the optimum depend on the problem considered, besides the hardware.Our aim consists in validating the following hypothesis: fitting the sub-population size to the computational power of the heterogeneous cluster nodes presents an improvement in running time.In this work, for a possible offline method to calculate the computational performance of each node, the average number of generations obtained in the HoSi/HeHW configuration for the three problems is used in order to determine the computational power of the heterogeneous machines. This comparison takes into account all the evolutionary process in a fair manner (proportionally to memory, processor and network usage), instead of a traditional benchmark that usually relies only on the CPU speed. Although this is not obviously the ideal way, it is a possible way to establish the computational power for the experiments of this work, and to determine if changing the sub-population size according to the computational power reduces the computing time of the whole approach. It should be considered that the contribution of this work is not the method to compute these sizes, but the comparison and analysis of the algorithm with parameters fitted to the computational power of the heterogeneous nodes.Thus, the obtained average number of generations in the previous sub-section, in Tables 3 and 4, is used to set the sizes proportionally in the HeSi/HeHW and HeSi/HoHW configurations. This has been done by dividing the total number of individuals (1024) proportionally to the number of generations spent by each node in HoSi/HeHW to solve the same problem. Note that, even having two nodes with the same processors and memory, HeN1 and HeN2, they might have different computational power: this may be produced by different operating systems, virtual machine versions, or number of processes being executed inside a node. The same heterogeneous parameter set will be tested in the control system (HoHW) to do a fair comparison and study the performance of both systems properly.Finally, in order to validate the hypothesis that fitting the sub-population sizes to computational resources of a heterogeneous cluster reduces the computational time required to find the solution, a third configuration is proposed. In this approach, the fitting of the sub-population size to the computational power of the islands (nodes) is performed during runtime (online). Each time a node (N) receives an individual, it compares its current number of generations (GenN) with the generations in the node that sent the individual (node N−1 in the ring). Then, the sub-population size is adapted proportionally to the difference in the number of generations, as described by the following equation:(4)sizeN′=GenNGenN−1sizeNIf the new size is larger than the current size, new individuals are added to the sub-population, cloning existing ones randomly. Otherwise, the sub-population must be reduced and thus, the worst are removed. Algorithm 1 is now updated as shown in Algorithm 2.Algorithm 2Pseudo-code of the used dEA: a distributed Genetic Algorithm (dGA) with automatic size adaptation mechanism.N ← initialPopulationSizepopulation ← initialisePopulation(N)while stopping criterion not met doG ← G + 1parents ← selection(population)offspring ← recombination(parents)offspring ← mutation(offspring)population ← population + offspringO ← offspring.size //O is also equal to the number of parents selectedif time to migrate thenmigrants ← selectMigrants(population)remoteBuffer.send(migrants)end ifI ← 0if localBuffer.size ≠ zero thenimmigrants ← localBuffer.read()iG ← immigrants.getGeneration()I ← immigrants.size()population ← population + immigrantsend ifpopulation ← population - population.getTheWorst(O + I)newSize ← calculateNewSize(iG, G, N)if newSize > N thenpopulation ← population + population.getRandomClones(newSize - N)elsepopulation ← population - population.getTheWorst(N - newSize)end ifN ← newSizeend whileUsing this possible online fitting scheme, each node only requires information from one of the neighbours and not from the whole system. Thus, each node tends to have a number of individuals proportional to its computational power with respect to the other nodes. Experiments on homogeneous cluster do not affect the sub-population sizes, as the number of current generations is equal in all nodes during runtime.Table 5summarises the parameter set used in the experiments.In order to deal with the operating system and architecture heterogeneity (different operating systems and versions, processors, compilers, etc.), the OSGiLiath framework [22], based on Java, has been used in this work. This is a service-oriented evolutionary framework that configures the services to be used in a local network automatically. In this case, each node offers a migration buffer to accept foreign individuals. Also, in order to reduce bottlenecks in distributed runs, asynchronous communication has been provided to avoid idle time. That is, the algorithm continues evolving the sub-population while individuals are being received, although the buffers cannot be used for communication until the reception is done. This kind of communication offers an excellent performance when working with different nodes and operating systems, as proved in [3,26]. The transmission mechanism is based on ECF Generic server (over TCP).11http://www.eclipse.org/ecf/.The source code of the algorithms used in this work is available at http://www.osgiliath.org under a LGPL V3 License.

@&#CONCLUSIONS@&#
The main question addressed in this work was: Is it worth fitting the sub-populations sizes of a dEA to the computational power of each node in a heterogeneous cluster? To answer this question properly a set of experiments was designed with several characteristics in mind. First, the separate study of two parameter settings: offline and online. Also, the usage of three problems with different characteristics and computational demands with different lengths. Finally, two different hardware systems (homogeneous and heterogeneous clusters), each one with different number of nodes (4 and 8).A base configuration with the same sub-population sizes was used on a heterogeneous cluster. The results were used to calculate offline the computational power of each node, comparing the average number of generations to find the optimal solution. These proportions were used to set the new sub-population sizes. Also, a possible way to fit online the sub-population sizes was performed comparing the current generation number between each node and its previous neighbour in the topology.Results showed that online or offline fitting the sub-population size to the computational power of each node in a heterogeneous cluster can reduce significantly the running time of an algorithm with respect to keeping the same size for all nodes. The sub-population size fitting was also affected by the problem being solved. Also, to answer the question about the difference of using these same sub-populations sizes in a homogeneous cluster, a control system was also used for comparison. In this case, the same parameter sets used in a homogeneous cluster did not improve the running time in multi-modal problems, as the average fitness of the population remained close to the average best fitness during all the evolution, and therefore, fitness diversity was not as well maintained as in the heterogeneous cluster.Furthermore, the answer to the question about the influence of the sub-population size effect on the stages of the algorithm was that, in fact, there existed an effect on stages that are independent of this parameter, such as the migration. These results are a promising start for fitting EAs to the performance of each node, using more suitable benchmarks or even in a dynamic way.In a future work, new online adaptation methods for sub-population sizes will take into account the nature of the problem at hand. For example, measuring the population diversity along with the generation number. Also, parameters such as migration rate or crossover probability could be fitted to the node's execution characteristics. Other appropriate benchmarks to analyse the algorithm will be used to get an online automatic parameter fitting while nodes enter or exit the topology net, or fitting the parameters to the current system load.