@&#MAIN-TITLE@&#
A visualization framework for team sports captured using multiple static cameras

@&#HIGHLIGHTS@&#
K-partite graph is a useful model for multi-source matching problems.It is useful to have mid-level representations to fuse data from multiple sources.Alternate background models can help characterize the background scenes accurately.Shadow pixels can be accurately removed by using their planner view-invariance.Appearance based Bhattacharyya distance is a robust blob-similarity measure.

@&#KEYPHRASES@&#
Perceptual reasoning,Video analysis,Sports visualization,Multi-camera tracking,Data fusion,Computer vision,

@&#ABSTRACT@&#
We present a novel approach for robust localization of multiple people observed using a set of static cameras. We use this location information to generate a visualization of the virtual offside line in soccer games. To compute the position of the offside line, we need to localize players’ positions, and identify their team roles. We solve the problem of fusing corresponding players’ positional information by finding minimum weight K-length cycles in a complete K-partite graph. Each partite of the graph corresponds to one of the K cameras, whereas each node of a partite encodes the position and appearance of a player observed from a particular camera. To find the minimum weight cycles in this graph, we use a dynamic programming based approach that varies over a continuum from maximally to minimally greedy in terms of the number of graph-paths explored at each iteration. We present proofs for the efficiency and performance bounds of our algorithms. Finally, we demonstrate the robustness of our framework by testing it on 82,000 frames of soccer footage captured over eight different illumination conditions, play types, and team attire. Our framework runs in near-real time, and processes video from 3 full HD cameras in about 0.4s for each set of corresponding 3 frames.

@&#INTRODUCTION@&#
Recent sports analysis and visualization systems have transformed viewers’ understanding and appreciation of the game, and have created a new industry [1,20]. However, many analysis techniques and graphical additions require significant human input. Automatically inferring the state of a multi-player game remains an open challenge, especially when the context of the game changes dynamically without discrete plays (e.g., soccer, field hockey, basketball). Our work targets this particular subset of sports.A key technical challenge for sports visualization systems is to infer accurate player positions despite visual occlusions and clutter. One solution for this problem is to use multiple overlapping cameras [23,10], provided the observations from these cameras can be fused reliably. Our work explores this question of efficient and robust fusion of visual data observed from multiple synchronized cameras.The main theoretical contribution of our work is a novel class of algorithms that fuse the location of players observed from multiple cameras by iteratively finding minimum weight K-length cycles in a complete K-partite graph. Each partite of the graph corresponds to one of the K cameras, whereas each node of a partite encodes the position and appearance of a player observed from a particular camera. The edge-weights in the graph are a function of similarity between the detected players in different camera-pairs, and their corresponding ground plane distances (see Section 3.5). We model the correspondence between a player’s blobs observed in different cameras as a K-length cycle in this graph (see Fig. 1for illustration).Another important challenge in sports visualization is the use of player positions to generate visualizations that might be informative for the viewers, coaches, and players. While there has been a lot of work in this regard (see e.g.[22,27,28,37,17], and the references therein), here we propose an end-to-end visualization framework that is different from previous works in a few important ways.First, our goal is to generate sports visualizations, and not to develop a decision making system [15,17]. Second, the design principle of our system is to use off-the-shelf cameras in a framework that is readily deployable to different playing locations. Current pan-tilt-zoom (PTZ) camera based visualization systems (as used in American Football for instance) employ non-vision based technology, that is expensive and not readily available. On the other hand, using a purely vision based PTZ camera system would require maintaining full camera calibration throughout a game, which is still an open research problem [39,2]. We therefore focus on using only static cameras, which requires only planer homographies that can be readily computed at the start of a game. Finally, we are interested in generating visualizations with minimal human supervision. This approach is different from previous visualization systems [26,9] that usually work off-line, and require significant manual supervision.The particular visualizations we have developed include displaying a virtual offside line in soccer games, highlighting players in passive offside positions, and showing players’ motion patterns accumulated over time. To demonstrate the robustness of our framework, we present results on 82,000 frames of soccer footage captured over eight different illumination conditions, play types, and team uniform colors. The variation in the illumination conditions we tested include naturally lit (morning, afternoon, evening, sunny, cloudy) and artificially lit (night time) fields. The play types we considered include drills and regular games. The teams we considered in our testing include different combinations of red, green, yellow, white, and blue team-uniforms. More details about these experimental variations can be found in Section 4.Data fusion using multiple information sources is a thoroughly studied problem [13]. Broadly speaking, most of the previous work in data fusion may be categorized into low-level (sensor-level) fusion [12,38], mid-level fusion [31], and high-level (decision-level) fusion [35,5].Some of the recent work on fusing data from multiple cameras in order to localize and track multiple people has focused on combining low-level sensor data to achieve robust inference [24,29,8]. In this work, however, we focus on mid-level fusion that combines local inference from each camera to reach a coherent global inference.The problem of finding multi-object multi-frame correspondence has previously been viewed from a variety of different perspectives, including constraint optimization [19], greedy randomized search [36], and graph based approaches [33]. The particular graph structure that has been most frequently used is the bi-partite graph [34]. The techniques for optimization for this particular graph structure are well studied [16]. However, using a bi-partite graph structure to model correspondences across more than two information sources is a greedy approximation which naturally results in sub-optimal result. To overcome the constraints posed by the bi-partite structure, there have been some recent attempts to use complete K-partite graphs [18,32].Our approach is different from these existing methods in two important ways. First, given the temporal constraints of previous problems, they have used graphs with directed edges, which restricts their search space, and makes the solution dependent on the order of individual graph partites. As we fuse data at a per-frame level, our problem does not pose temporal constraints, requiring us to use undirected graphs. Therefore our solution is more general in that it explores a larger search space, while being independent of the order of individual graph-partites. Second, most previous approaches have used an acyclic graph structure, however the graph structure we use involve loops.In the remaining part of this section, we provide details regarding the modeling and analysis of our problem.Given a complete K-partite graph G, find the minimum weight cycle c∈G, such that c passes through each k∈K once and only once.A complete K-partite graph and a node-cycle are shown in Fig. 2a and c respectively.1The terms partite and tier will be used interchangeably from hereon.1Each partite of G corresponds to one of the K cameras, whereas each node of a partite encodes the position and appearance of a player observed from a particular camera. A cycle c in G represents a correspondence among observations of a player in different cameras. The goodness of a correspondence is ranked based on the weight of its cycle – smaller weight cycles imply better correspondence.As the number of players at any given instant of time is not known, we use the greedy heuristic of iteratively finding the longest (length K), and most cohesive (least weight) cycle, and remove it from our original graph G. This operation is repeated until there are no more K-length cycles that are also more cohesive than a pre-defined threshold. We repeat this procedure to iteratively find and remove all the K length cycles. This process continues until there are no more non-trivial cycles in the graph.A naive solution to our problem would be to first enumerate all K-length cycles in the graph, and then search for the minimum weight cycle in a brute force manner. With n nodes in each of the K tiers, the total number of cycles would be O(nKK!). Recall that here K represents the number of cameras and n denotes the number of players observed in each of the K cameras. Even for relatively small values of n and K, this solution is expensive,2For example, a setup with 5 cameras observing 15 players would require searching through 91,125,000 cycles at each time-step.2and a more efficient solution is therefore needed.Our problem exhibits two key characteristics that can be exploited to create a more efficient solution.1 – Optimal sub-structure: The property of optimal sub-structure implies that an optimal solution of a problem can be constructed from optimal solutions of its sub-problems. More specifically, in our case:Lemma 1A sub-path p between nodes {u, v}∈c is the shortest path between u and v[7].2 – Overlapping sub-problems: The property of overlapping sub-problems implies that a problem can be divided into sub-problems which can be re-used several times. More specifically, in our case:Lemma 2A shortest path between nodes u and v is less than or equal to the shortest path between u and an intermediate node w, and the shortest path between w and v[7].These properties enable us to use dynamic programming approach of updating of the solution-set from one step to the next in an incremental manner. This observation allows us to have solutions that range from maximally to minimally greedy in terms of the number of graph-paths explored at each iteration. The globally optimal solution of our problem is NP-hard for k⩾3 [32]. Therefore, the ability to choose an approximate solution given the application requirements of search efficiency versus optimality can be quite useful in practice.As our problem is cyclic in nature, the paths we find must start and end at the same node. With traditional dynamic programming, there is no guarantee that the shortest path returned by the algorithm would necessarily end at the source node. We therefore need to modify our graph representation such that we satisfy the cyclic constraint of our problem, while still using a dynamic programming based scheme.Assume the size of all nodes V∈G is n. For each node v∈V, we can construct a subgraph Gvwith K+1 tiers, such that the only node in the 1st and the (K+1)st tier of Gvis v. Besides the 1st and the (K+1)st tiers of Gv, its topology is the same as that of G (see Fig. 2b). Note that the shortest cycle in G involving node v is equivalent to the shortest path in Gvthat has v as its source and destination (see Fig. 2c). Our problem can now be re-stated as:Modified problem statement:Given G, construct Gv, ∀v∈V. Find the shortest K length paths P={pv∈Gv∀v, ∈V} that span each tier once and only once. Find the shortest cycle in G by searching for the shortest path in P.We now present a class of algorithms for finding the shortest path pv∈Gv. The overall shortest cycle in G can then be found by repeating this process ∀v∈V.Let T be the set of all tiers ∈G, and tvbe the tier of a node v∈V. Let P{v, k−1} denote the shortest k−1 length path from source to v, and let T{v, k−1} denote the set of tiers covered by P{v, k−1}. Let C{v, k−1} denote the cost of P{v, k−1}. Similarly, letP{v,k-1,tu}denote the best k−1 length path from the source to v that does not pass through tu, and letT{v,k-1,tu}denote the set of tiers covered byP{v,k-1,tu}. LetC{v,k-1,tu}denote the cost ofP{v,k-1,tu}. We define the neighborhood of u as:(1)v∈N(u,k)ifftu∉T{v,k-1}tu≠tvThe notion of N(u, k) for a node u∈G is illustrated in Fig. 3a. Each node with a cross is included in a best path that spans the tier of u, and can therefore not be further used by u. Nodes with checks are best paths of length two that do not span the tier of u, and can therefore be used by u. Note that in Fig. 3, the lines with blocks at the end highlight the path stored in a particular node.Algorithm 1Maximally Greedy Approachfork=2, 3, …, Kdofor allu∈VdoS={ϕ}, Q={ϕ}for allv∈N(u, k) doS=S∪{C{v, k−1}+w(v, u)}//Set of costsQ=Q∪{P{v, k−1}+(v, tv)}//Set of pathsend fori=index (min (S)); S{u, k}=S[i]; Q{u, k}=Q[i];end forend forfor allv∈VdoS=S∪{C{v, K}+w(v, s)}Q=Q∪{P{v, K}+(v, s)}end fori=index (min (S)); Cbest=S[i]; Pbest=Q[i];Algorithm 1 considers the best k−1 length path stored in each of the neighbors of a node u in order to compute the best k length path from the source to u. An illustrative example of the flow of Algorithm 1 is given in Fig. 3b.Algorithm complexity: The complexity of Algorithm 1 for finding shortest path in Gvis O(n2K) because finding the best length l path to a particular node requires searching over O(n) paths of lengths l−1 in the neighborhood of the node being considered. Finding a shortest path of length K would therefore require O(nK) operations, because this requires K operations of complexity O(n), one for each path length from 1 to K. As this process is done for each of the n nodes in Gv, the complexity of finding the overall shortest path in Gvis O(n2K). Furthermore, since there are n sub-graphs Gvin G, the complexity for finding the shortest cycle in G is O(n3K).Bottleneck cases: We need to find paths in Gvthat span each tier once and only once because Algorithm 1 proceeds in a maximally greedy manner. There can be cases where Algorithm 1 cannot query a certain node v anymore, as the best k−1 length path at v already passes through tu(Fig. 4a). If best paths at {∀v∈V⧹u} already span tu, Algorithm 1 cannot converge further. We can therefore state the convergence condition as:(2)|{N(u,k)}|>0∀(u,k)Here convergence does not necessarily imply optimality. i.e., the state where the solution returned by an algorithm is the same as that of exhaustive search (Section 2.2). Because of the greedy search policy of Algorithm 1, the invariant of Lemma 1 does not always hold. Algorithm 1 therefore greedily attempts to find the best solution that it can, and as often as it can.In Algorithm 1, if P{v, k−1} spans tk, then the subset of nodes {u∣tu=tk} cannot use this path anymore. We therefore need alternate paths ending at v that do not pass through tksuch that nodes {u∣tu=tk} could use these paths in later iterations. Algorithm 2 attempts to achieve this goal by keeping the minimal set of best k−1 length paths that exclude each tier at least once (a routine denoted as “Rank” in Algorithm 2). Fig. 4b shows how Algorithm 2 keeps alternate paths to allow u to have a larger set of neighbors than that of Algorithm 1.Algorithm 2Leave Each Tier Out At least Oncefork=2, 3, …, Kdofor allu∈VdoS={ϕ}, Q={ϕ}for allv∈N(u, k) doS=S∪{C{v,k-1,tu}+w(v,u)}Q=Q∪{P{v,k-1,tu}+(v,tv)}end forSort (S); Rank (Q); T′={T⧹tu}for allti∈T′ doFindP{v,k,ti}∈QFindC{v,k,ti}=Cost(P{v,k,ti})end forend forend forfor allv∈VdoS=S∪{C{v, K, ϕ}+w(v, s)}Q=Q∪{P{v, K, ϕ}+(v, s)}end forAlgorithm complexity: The complexity of Algorithm 2 for finding pv∈Gvis O(n2K2log (nK)+n2K3). Note that the outer two loops of Algorithm 2 are of O(nK) complexity. For each iteration of the inner loop, the two key procedures that need to be performed are (i) sorting the neighborhood paths based on their costs, and (ii) finding the path and cost-set for each tier in T except for the tier of the current node. The complexity of the sorting procedure is O(nK.log (nK)), while that of finding the new path and cost-set is O(n.K2). Therefore the overall complexity of Algorithm 2 for finding pv∈Gvis O(n2K2log (nK)+n2K3). Furthermore, because there are n sub-graphs Gvin G, the complexity for finding the shortest cycle in G using Algorithm 2 is O(n3K2log (nK)+n3K3).Bottleneck cases: If all the paths available to a node u have a particular tier (say tc) in common, Algorithm 2 may still not always be able to exclude each tier at least once. In the next iteration, the nodes in tcwould not be able to query u (see Fig. 4c for illustration). If this is true ∀u, Algorithm 2 would terminate prematurely.Algorithm 3 maintains the best k−1-length paths for all combinations of tiers such that nodes in all tiers can always query their neighbors. Fig. 4d shows how this approach avoids a bottleneck case for Algorithm 2. Algorithm 3 is guaranteed to have ∣{N(u, k)}∣=∣{V⧹{v∣tv=tu}}∣∀{u, k}, and always satisfies Lemma 1. It therefore guarantees both convergence and optimality. We now provide a proof for these claims.We first prove that the convergence condition (as defined in Eq. (2)) for Algorithm 3 would always be satisfied.TheoremAlgorithm 3never returns a NULL solution.∀u∈G, the set N(u, k) satisfies the constraint:A node v∈N(u, k), iff ∃ a path of length k−1 that ends at v and does not include tu. The total number of k−1 length paths stored at v that do not include tuisK−2Ck−2. Therefore, Eq. (3) would hold if:(4)K-2Ck-2⩾1∀kEq. (4) holds if k⩽K, which is always true. □Combinatorial Approachfork=2, 3, …, Kdofor allu∈VdoS={ϕ}, Q={ϕ}for allv∈N(u, k) dofor alli∈ψ{v, k−1}doS=S∪{C{v,k-1,ψ{v,k-1,i}}+w(v,u)}Q=Q∪{P{v,k-1,ψ{v,k-1,i}}+(v,tv)}end forend forSort (S); Rank (Q); T′={T⧹tu};ψ{u, k}≡Set of all (k−1) size subsets of T′for alli∈ψ{v, k}doComputeP{u,k,ψ{u,k,i}}∈QComputeC{u,k,ψ{u,k,i}}end forend forend forfor allv∈VS=S∪{C{v,K,ψ{v,K,1}}+w(v,s)}Q=Q∪{P{v,K,ψ{v,K,1}}+(v,s)}end forWe now prove the optimality of Algorithm 3.TheoremAlgorithm 3always returns the optimal solution.The optimality of Algorithm 3 can be proved if it could be shown that:•A sub-path of a shortest path is a shortest path itself, andShortest sub-paths for any path length are available.If s−(v1, t1), −(v2, t2), …, −(vk, tk) is the shortest k-length path that ends at vkand involves tiers {t1, t2, …, tk−1}, then s−(v1, t1), −(v2, t2), …, −(vk−1, tk−1) is the shortest path that ends at vt−1and involves tiers {t1, t2, …, tk−2}.Since G=(V, E, w) has non-negative weights, w: E→R+, the triangular inequality implies that the sub-path of a shortest path is the shortest sub-path itself [7].The best k−1 length path ending at v, ∀v∈V that includes any subset of k−2 tiers is always available.Proof by induction: Assume Lemma 2 is true for paths of length k−2. We define Tk−3 as the set of all subsets of length k−3 tiers, and assume that Tk−3 is available at every node. Now, consider a set of length k−2 tiers Tk−2. Let tk∈Tk−2, then Tk−2⧹tk∈Tk−3. Any node in tkwill have the best path of length k−2 that includes Tk−2⧹tk. Algorithm 3 accumulates all best paths including Tk−2⧹tktiers, and sorts them to find the best overall path involving Tk−2.Algorithm complexity: The number of K-length paths maintained at each node by Algorithm 3 is 2K−1. Recall that at each node, Algorithm 3 maintains the best k−1 length paths for all combinations of tiers in order to compute k-length paths. The number of paths maintained at each node by Algorithm 3 can therefore be given as:(5)K-1C0+K-1C1+⋯+K-1CK-1According to the Binomial theorem [6],(6)(x+y)n=∑knnCkxn-kykEq. (5) can be written in terms of the Binomial theorem (Eq. (6)) if we choose x=y=1. Therefore, summing up Eq. (5) results in 2K−1. The complexity of Algorithm 3 for finding the shortest path in Gvis O(n2K−1), and its overall complexity for finding the shortest cycle in G is O(n22K−1).To predict the behavior of our algorithms for applications with different number of cameras, we now present simulation experiments using a complete K-partite graph with 5 nodes in each tier, and the number of tiers varying from 3 to 12.3Recall that here a node represents an observation in one of the cameras, while a tier corresponds to a particular camera.3For each set of tiers, we generated 1000 random graphs by sampling edge weights from a normal distributionN(0,1). Fig. 5a shows that Algorithm 1 and Algorithm 2 always return an optimal solution for tiers ⩽4 and ⩽6 respectively. Fig. 5b shows that bottleneck occurs for Algorithm 1 quite rapidly, while Algorithm 2 converges more than half the time for tiers ⩽8. Fig. 5c highlights the greedy nature of Algorithm 1 and 2 which do not guarantee optimality even when they converge. Algorithm 3 however consistently shows convergence and optimality, but costs a reduction in efficiency (Fig. 5d).As an application of our proposed algorithms, we present a computational framework for localization of multiple soccer players captured using three synchronized overlapping static cameras. We captured two soccer data-sets on different soccer fields in order to maximize the data variability, and to test the generalizability of our framework more rigorously. We now summarize the main attributes of these data-sets:Data-set 1: For the first data-set, we erected 40 feet high scaffolds, and mounted synchronized 1080P-HD cameras on them. The soccer field dimensions for this setup were 204×121 feet. We used three static cameras to capture one half of this field. The camera positions with respect to the field are shown in Fig. 1a. We captured different colors for the team jerseys (red, yellow, blue, green, and white), types of soccer plays (matches, drills), and lighting conditions (morning, afternoon, and evening, all in natural lighting).Data-set 2: For the second data-set, we used scissor lifts with adjustable heights to mount synchronized 720P-HD cameras on them. The soccer field dimensions for this setup were 344×225 feet. Similar to the first data-set, we used three static cameras to capture one half of this field. We collected two games with heights of the lifts set to 60 feet. One of these two games was recorded at night under flood lights. We captured a third game with the lifts set at about 25 feet. Furthermore, for a third game, the position of camera 3 was changed such that it was on the end line opposite to camera 2.The main steps of our computational framework are illustrated in Fig. 6, and are explained below.We begin by adaptively learning per-pixel Gaussian mixture models for scene background. The probability of a background pixel having value xnis given as:(7)p(xn|background)=∑j=1Jwjζjwhere ζjis the jth Gaussian component, and wjis its weight. The term ζjis given as:(8)ζj(xn;μj,Σj)=1(2π)D/2|Σj|1/2e-12(x-μj)JΣj-1(x-μj)where μjand Σjare the mean and covariance of jth component. These models are used for foreground extraction by thresholding appearance likelihoods of scene pixels [21].Note that there exists a trade-off between how often the background appearance model is updated, and how often a slowly or occasionally moving object is incorrectly assigned to be part of the background. This tradeoff is particularly important to us because players move with variable speeds – in fact some players (especially the goalie) could remain stationary for a few seconds, introducing error in our inference regarding who is the second last defence player. To solve this challenge, we maintain two background models – the first to learn the appearance of the background over the next t seconds, while the second (the one we learned over the last t seconds) to discriminate between the background and foreground objects. We swap these two background models every t seconds. This mechanism allows us to maintain a relatively current model of what the background looks like, without misclassifying the slow-moving objects.While there are numerous appearance-based methods for shadow removal [30], they work best for relatively soft shadows. In soccer games however, shadows can be quite strong. We therefore rely on geometric constraints of our multi-camera setup for robust shadow removal.Consider Fig. 7, which illustrates that the shadow pixels of the player are view invariant. Here invariance is brought about by the fact that the shadow pixels are projected on the common ground plane viewed by multiple cameras. Given the homographies between the field image seen from multiple views, we can transform the pixels of the soccer field as viewed by one camera to other cameras.4For K cameras observing a soccer field, we require K2 homographies.4We use these homographies to remove shadows by warping the extracted foreground in one view onto another, and filtering out the overlapping pixels [23,24,10].For our setup, we begin by finding 3×3 planer homographiesHπa,πbbetween each pair of views πaand πb, such that for any point pair paand pbin πaand πb, the following holds:(9)pa=Hπa,πb·pbRecall that 2-D homographies have 8 degrees of freedom (9 entries in theHπa,πbwith common scale factor). To determine eachHπa,πbwe require at least 4 pairs of corresponding points in respective view pairs [14]. In practice we use a 15 point correspondence across the three cameras to estimate the mapping between their field regions. These points are shown in Fig. 8, and were manually marked.When a player’s blob in a particular view is occluded by the projection of the blob of another player, or their shadow in a different view, relying simply on these geometric constraints might result in losing image regions belonging to the occluded parts of the player in the considered view. To avoid this challenge, we apply chromatic similarity constraints of original and projected pixels before classifying them as shadow versus non-shadow. The intuition here is that the appearance similarity of shadow pixels across multiple views is more than the similarity for non-shadow pixels.We track the player blobs using a particle filter based blob tracker [25]. We represent the state of each player using a multi-modal distribution, which is sampled by a set of particles. To propagate the previous particle set to the next, three steps are performed at each time-step:Selection: A particle setst′n:n=[1→N]is sampled from prior density p(xt−1—zt−1) [25]. Here x and z are object-state and observation vectors.Prediction: Predicted states of particlesstn:n=[1→N]are generated fromst′n:n=[1→N]using the dynamical model. The dynamics are applied to state parameters as:(10)stn=st′n+A·vt-1+B·wtwherewt∼N(0,Σ)Here vt−1 is the velocity vector obtained from the previous steps, while A and B are matrices representing the deterministic and stochastic components of the dynamical model.Measurement: We compute the probability of the statep(stn=zt|xt)and normalize the probabilities of all particles so that they sum to one:(11)πtn=p(zt|xt=stn)Σi=1Np(zt|xt=sti).These weights are used in the next frame for particle selection. Based on the discrete approximation ofp(zt|xt=stn), different estimates of the best state at time t can be devised. We use the maximum likelihood state(12)xtˆ=argmaxstnp(zt|xt=stn)as the tracker output at time t (for more details, see [25]).We classify the tracked blobs on a per-frame and per-view basis. We pre-compute the hue and saturation histograms of a few (10–15) player-templates of both teams as observed from each view. During testing, we compute the hue and saturation histograms for the detected blobs, and find their Bhattacharyya distances from the player-templates of the corresponding view [3]. We classify each blob into offense or defense based on the label of their nearest neighbor templates. The pipeline of blob-classification for one particular view is shown in Fig. 9.Ideally, one would expect that the homographies between pairs of image planes, and between the image plane and the ground to be precise enough to localize players’ positions accurately. In practice however, this is not the case because when players in one view are occluded by the projections of other players or by their shadows in another view, parts of the players might be removed. This problem is illustrated in Fig. 10. We consider the bottom point of a blob as the location of a player in the image plane, and the removal of players’ legs can create significant error, particularly when players are gathered close to each other. One way to solve this problem is to use information from multiple cameras.To use multiple cameras, we first need to transform players’ location observed in different views into a shared coordinate system. We do this by projecting the base-point of all blobs observed from each camera into the real-world coordinates of the field (Fig. 6). These projected blobs are nodes in our K-partite graph (Fig. 2a). Edge-weights on node-pairs are computed according to Eq. (13).(13)w(nb1,nb2)=0ifd(b1,b2)>dth1-B(b1,b2)OtherwiseHerenb1is the node for a particular blob b1, while B(b1, b2) is the Bhattacharyya distance [3] between b1 and b2. The distance threshold, dth is manually selected. For each cycle in this graph (Section 2.1), we infer the player location by averaging the strongest node-pair in the cycle.As our three proposed algorithms perform equally for 3-tiered graphs, each of them is applicable for our current setup. In sports broadcast however, the number of cameras maybe 16 or more [11], making the analysis of how our algorithms performs for larger numbers of cameras crucial.

@&#CONCLUSIONS@&#
We have presented a novel modeling and search framework for fusing evidence from multiple information sources as finding minimum weight K-length cycles in complete K-partite graphs. As an application of the proposed algorithm-class, we have presented a framework for soccer player localization using multiple synchronized static cameras. We have used this fused information to generate sports visualizations, including the virtual offside line, highlighting players in passive offside state, and showing players’ accumulated motion patterns. We have demonstrated the robustness of our framework by testing it on a large data-set of approximately 82,000 frames of soccer footage captured over eight different illumination conditions, play types, team attire, field sizes, and camera positions.Some of our conclusions based on our results are given below.•Representing correspondence among different observations of a particular player as a weighted cycle in a complete K-partite graph is sufficient to accurately fuse information from multiple sources. Note that there exist more strict representations of correspondence (e.g., a clique), and a cycle is a somewhat greedy correspondence representation. For our setting however, our empirical results show that representing correspondence in a greedy manner still results in accurate data fusion overcoming the challenges of occlusions and varying illumination.Utilizing a mid-level data representation (player locations in each view) to fuse information from multiple sources (cameras) works reasonably accurately for overcoming the problem of player occlusion in tracking.In this work have assumed that the playing field is a plane. This assumption should be made with caution, and it might be useful to treat larger fields in a by-part manner, considering each part as a separate planer surface.Maintaining alternate background appearance models can help characterize the background scenes accurately, particularly if the illumination conditions in the scene change rapidly, or if different foreground objects move at significantly different speeds.Using the view invariance property of shadow pixels to remove them can work quite well, particularly when the shadows are hard and cannot be removed using purely illumination based methods.Employing Bhattacharyya distance over hue and saturation values as a similarity measure for player blob classification can result in quite accurate blob classification.There are a few research directions we would like to pursue in the future.•Currently we perform search for each frame independent of the results from previous frames. In future work, we want to explore incorporating temporal dependency between observations over time to initialize our search procedure in each frame. This would help us improve the search efficiency and accuracy of our framework.We are currently modeling correspondences as cycles in complete K-partite graphs. In the future we would like to explore alternate models of correspondence (e.g., paths, and cliques) to see what impact do they have on the search optimality versus efficiency tradeoff.We want to test our framework using a larger number of cameras. This experiment would give us a better sense of how many cameras are sufficient for our framework to perform well for different sized fields.An important question to explore is the required number of cameras as a function of camera height, and the impact this number has on the processing speed of our framework.We also want to perform a thorough quantitative analysis of the efficiency gain for using GPUs instead of CPUs.A qualitative factor for the usability of our framework is to analyze how frequently is our system able to actually perform correctly in cases where an expert believes there is something interesting taking place. This would provide a better understanding of the usefulness of our framework in situations that really matter to the viewers.We would like to use our framework for a variety of sports where the context of the game usually changes continuously without discrete plays. Other examples of such sports besides soccer include ice/field hockey, and basketball.Finally, as our proposed set of algorithms are quite general, we want to apply them on a wider set of correspondence finding problems. In particular, we would like to test our algorithms on the problems of feature matching for depth estimation, trajectory matching using multiple cameras, and motion capture reconstruction.