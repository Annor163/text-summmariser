@&#MAIN-TITLE@&#
SAMAR: Subjectivity and sentiment analysis for Arabic social media

@&#HIGHLIGHTS@&#
We present a system for subjectivity and sentiment analysis (SSA) for Arabic social media data.Individual settings are required per genre and task.Using either lemmas or lexemes improves SSA results.Using a POS tagset leads improved results, as do standard features.Processing dialects does not improve when it is know which sentences are in dialect.Genre specific features tend to be helpful for sentiment analysis, but not for subjectivity.

@&#KEYPHRASES@&#
Subjectivity and sentiment analysis,Morphologically rich language,Arabic,Social media data,

@&#ABSTRACT@&#
SAMAR is a system for subjectivity and sentiment analysis (SSA) for Arabic social media genres. Arabic is a morphologically rich language, which presents significant complexities for standard approaches to building SSA systems designed for the English language. Apart from the difficulties presented by the social media genres processing, the Arabic language inherently has a high number of variable word forms leading to data sparsity. In this context, we address the following 4 pertinent issues: how to best represent lexical information; whether standard features used for English are useful for Arabic; how to handle Arabic dialects; and, whether genre specific features have a measurable impact on performance. Our results show that using either lemma or lexeme information is helpful, as well as using the two part of speech tagsets (RTS and ERTS). However, the results show that we need individualized solutions for each genre and task, but that lemmatization and the ERTS POS tagset are present in a majority of the settings.

@&#INTRODUCTION@&#
In natural language, subjectivity refers to aspects of language used to express opinions, feelings, evaluations, and speculations (Banfield, 1982) and, as such, it incorporates sentiment. The process of subjectivity classification refers to the task of classifying texts as either objective (e.g., The new iPhone was released.) or subjective. Subjective text can further be classified with sentiment or polarity. For sentiment classification, the task consists of identifying whether a subjective text is positive (e.g., The Syrians continue to inspire the world with their courage!), negative (e.g., The bloodbaths in Syria are horrifying!), neutral (e.g., Obama may sign the bill.), or, sometimes, mixed (e.g., The iPad is cool, but way too expensive.).In this work, we address two main issues in subjectivity and sentiment analysis (SSA): First, SSA has mainly been conducted on a small number of genres such as newspaper text, customer reports, and blogs. This excludes, for example, social media genres, such as Wikipedia Talk Pages. Second, despite increased interest in the area of SSA, only few attempts have been made to build SSA systems for morphologically-rich languages, i.e., languages in which a significant amount of information concerning syntactic units and relations is expressed at the word-level (Tsarfaty et al., 2010), such as Finnish or Arabic, cf. (Abbasi et al., 2008; Abdul-Mageed et al., 2011a; Mihalcea et al., 2007). Thus, we aim at partially bridging these two gaps in research by presenting an SSA system for Arabic social media genres as Arabic is one of the most morphologically complex languages (Diab et al., 2007; Habash et al., 2009). We present SAMAR, a sentence-level SSA system for Arabic social media texts. We explore the SSA task for four different genres: Synchronous chat, Twitter, Web discussion fora, and Wikipedia Talk Pages. These genres vary considerably in terms of their functions and the language variety employed. While the chat genre is mostly in dialectal Arabic, the other genres are mixed between Modern Standard Arabic (MSA) and dialectal Arabic to varying degrees.In the current work, we focus on investigating four main research questions:•RQ1: How can morphological richness be treated in the context of Arabic SSA? To date most robust SSA systems have been developed for English, which has relatively little morphological variation. In such systems most of the features are highly lexicalized, hence a direct application of these methods would not be quite as successful for Arabic since a lemma in Arabic may be associated with hundreds if not thousands of variant surface forms. Accordingly, we need to investigate how to avoid data sparseness resulting from using lexical features without losing information that is important for SSA. More specifically, we characterize our problem in two spaces: the lexical space comparing simple lexeme tokenization with full lemmatization (lexemes vs. lemmas); abstracting away from the lexical form to the part of speech class, we investigate using two different POS tag sets for Arabic that encode a significant amount of morphological information.RQ2: Can standard features be effective for SSA when handling social media despite the inherently short texts typically used in these genres? In this prong of the research we investigate the impact of using two standard features frequently employed in SSA studies (Wiebe et al., 2004; Turney, 2002) on social media data that employes dialectal Arabic usage and the text inherently varying in length (i.e., the text being very short, e.g., in Twitter data). First, we investigate the utility of applying a UNIQUE feature (Wiebe et al., 2004) where low frequency words, below a certain threshold, are replaced with the token “UNIQUE”. Given that our data includes very short posts (e.g., twitter data has a limit of only 140 characters per tweet), it is questionable whether the UNIQUE feature will be useful or whether it replaces too many content words. Moreover, it should be noted that dialectal Arabic, to date, does not have a standardized orthography, therefore low frequency content words will be pervasive in social media genres since most of these genres employ dialectal Arabic. Second, we test whether a polarity lexicon that was extracted from a standard Modern Standard Arabic (MSA) newswire domain is useful for processing SSA for social media data.RQ3: How do we handle dialects in an SSA system for Arabic? For Arabic, there are significant differences between dialects on all levels of linguistic representation: morphology, lexical, phonology, syntax, semantics, and pragmatics. This difference is even more pronounced between the dialects and MSA. However, existing robust Arabic NLP tools such as tokenizers, Part of speech (POS) taggers, and syntactic parsers are exclusively trained on and for MSA newswire genres. Therefore we would like to measure the impact on SSA performance of explicitly modeling for dialectal usage.RQ4: Which features specific to social media can we leverage? We are interested in investigating the impact of using information that is typically present in social media (meta) data such as gender, author and document id information on SSA performance.The remainder of the paper is organized as follows: In Section 2, we give an overview of the linguistic characteristics of Arabic that are important for our work; Section 3 describes the social media corpora and the polarity lexicon used in the experiments; In Section 4, we review related work; Section 5 describes the SSA system, SAMAR, used for the current research, as well as the features used in the experiments; Section 6 describes the experiments and discusses the results; In Section 7, we give an overview of the best settings for the different corpora, followed by a conclusion in Section 8.Arabic is a Semitic language known for its rich morphology. For our purposes, we define a word to be a space delimited token in naturally occurring written Arabic text. A typical word in Semitic languages packs more information than a typical word in a language such as English. A word in Arabic exhibits several morphological aspects: derivation, inflection, and agglutination.Morphemes. New words can be derived from existing words or morphemes. A morpheme is the basic, minimal linguistic unit that bears meaning, regardless of whether it can stand alone as a word. For example, the inflectional plural marker suffix -s, the lexical prefix anti-, or the word table are all morphemes in English; the word tables is comprised of two morphemes: table + -s. There are four ways to combine morphemes, where typically one morpheme (called the base) bears the core meaning of the word: before the base (prefix or proclitic; e.g., Al+11We use the Buckwalter transliteration scheme for rendering romanized Arabic script (Buckwalter, 2002) http://www.qamus.org.‘the’), after the base (suffix or enclitic; e.g., +At feminine plural form), or both before and after (circumfix; e.g., ta+ …+ uwA present tense second person masculine plural, or ma+ …+$ negation in some Arabic dialects).Semitic languages are largely templatic. Most derived words are comprised of a root and a pattern/template. However the semantics of the word is not always predictable due to some arbitrary idiosyncratic features due to semantic drift in its meaning, with usage over time.The derivational mechanism typically takes two morphemes and creates a new word with a part of speech possibly different from that of any of the participating morphemes. For example, speak (verb) + -er → speaker (noun) in English. Derivational morphology in Arabic, like most Semitic languages, is made up of roots and patterns.Roots. The root is an ordered tuple of consonants, a.k.a. radicals, most often a triplet (but could be a pair or quadruple). For example, the three radicalsk t b are a root related to ‘writing’ in Arabic. Roots are not necessarily monosemic, i.e., a root could have multiple meanings. Typically a root is unpronounceable. It is meant to be an abstract concept around which words cluster. The vowels are added by merging with a pattern/template. Roots and patterns are inherent parts of Semitic languages and unique to them.Pattern/wazn/template. The template/pattern is a fixed sequence of vowels and interleaved place-holders for the root's consonants. For example 1a2a3 is a perfective verb, where the digits correspond to the root radicals. A pattern may also contain additional consonants. Like the root, the pattern/template is not necessarily monosemic. Roots and patterns are each morphemes in their own right. The root carries a basic meaning of an action or an object (in our example above,k t b are a root related to writing), while the template reflects a modifying meaning over the root's basic meaning, as in conveying a verb/action or a noun/object, mutual or reflexive action, etc. For examplekAtab ‘corresponded’,kat ab ‘dictated’, andkitAb ‘book (noun)’ – each having a different pattern, merged with the same rootk t b.Arabic inflects for various features: number, gender, grammatical aspect, syntactic case, mood, definiteness, person, voice, and tense. The set of words sharing meaning but varying over these features is called a lexeme class. It is typically represented as a citation form by one of the set members – called the lemma. The lemma is used for linguistic purposes, e.g., as the citation/head form in a dictionary, or as a feature in parsing or semantic processing. The lemma form is typically the masculine singular active perfective verb form for verbs and the masculine singular for nouns. Lemmas are typically fully diacritized where the vowels and gemination forms are present. The lexeme can inflect with certain combinations of these features depending on the part of speech (noun, verb, adjective, etc.) Table 1illustrates some examples of words. It should be noted that lemmas are also inflected words.In many cases the meaning of the resulting word is compositional, i.e., it can be constructed from the meaning of the participating morphemes.In the example in Table 1, we note two types of plurals: soundmakotabAt and brokenmakAtib. The sound plurals are typically predictable, hence their underlying lemma is the same as the singular form of the word. Conversely the broken plurals are unpredictable, different from the general (sound) affixational case, hence their underlying lemma is often represented as the same as the broken form.Lexeme members (including lemmas) could further agglutinate to certain closed class words (clitics), forming complex surface words in naturally occurring written Arabic texts (where in English, these would typically be space-delimited tokens). These agglutinative clitics may be particles (such as negation particles), prepositions, and grammatical markers of various sorts, such as aspectual and future marker morphemes, conjunctions, and pronouns, some of which occur as enclitics (suffixes) and others as proclitics (prefixes). It is worth noting that agglutinative morphology is more complex in dialects of Arabic than they are in MSA, thereby rendering the tokenization of Arabic dialects much more complex as a process. For example, the Arabic wordwabi. Hasanathim, ‘and by their virtue (sing.)’, comprises the morphemes illustrated in Table 2.In Table 2, the stem is simply the base word without handling of morphotactics: namely in this case the conversion of thet word finally to ap once separating the clitichim from the stem. The lexeme is by definition inflectional. In this case the lemma and the lexeme are the same form. Agglutinative morphology is different from derivational and inflectional morphology in that the resulting word retains a complex meaning, as in the example above: conjunction+preposition+the stem+possessive pronoun (equivalent to an English conjunction of a prepositional phrase), and may reach a complexity equivalent to a whole sentence in English. The tokenization process typically handles clitic segmentation and morphotactic normalization.To our knowledge, to date, no gold-labeled social media SSA data exist for Arabic. For this reason, we create annotated data comprising a variety of data sets: DARDASHA (DAR): (Arabic for ‘chat’) comprises the first 2798 chat turns collected from a randomly selected chat session of ‘Egypt's room’ in Maktoob chat http://chat.mymaktoob.com. Maktoob is a popular Arabic portal. DAR is an Egyptian Arabic subset of a larger chat corpus that was harvested between December 2008 and February 2010. The language variety in this collection is mostly dialectal Arabic (DA).TAGREED (TGRD): (‘tweeting’) is a corpus of 3015 Arabic tweets collected during May 2010. TGRD has a mixture of MSA and dialectal Arabic. The MSA part (TGRD-MSA) comprises 1466 tweets, and the dialectal part (TGRD-DIA) comprises 1549 tweets.TAHRIR (THR): (‘editing’) is a corpus of 3008 sentences sampled from a larger pool of 30 MSA Wikipedia Talk Pages posts that we harvested.MONTADA (MONT): (‘forum’) comprises 3097 Web forum sentences collected from a larger pool of threaded conversations pertaining to different varieties of Arabic, including both MSA and DA, from the COLABA data set (Diab et al., 2010). The discussion topics covered in the forums are hand selected to be in the domains of social issues, religion, and/or politics. The sentences are automatically filtered to exclude non-MSA threads. It is worth noting that over 20% of the data used in this corpus is classical Arabic since some of it was drawn from literary criticism writings.Each of the data sets is labeled at the sentence level by two college-educated native speakers of Arabic. For each sentence, the annotators assigned one of 4 possible labels: (1) objective (OBJ), (2) subjective-positive (S-POS), (3) subjective-negative (S-NEG), and (4) subjective-mixed (S-MIXED). Following Wiebe et al. (1999), if the primary goal of a sentence is judged to be the objective reporting of information, it is labeled OBJ. Otherwise, a sentence is a candidate for one of the three SUBJ classes. We also label the data with a number of other metadata tags.22We use the term ‘metadata’ as an approximation, as some features are more related to social interaction phenomena.Metadata labels included the user gender (GEN), the user identity (UID) (e.g., the user could be a person or an organization), and the source document ID (DID). We also mark the language variety (LV) (i.e., MSA or dialect) used, tagged at the level of each unit of analysis (i.e., sentence, tweet). Annotators are instructed to label a tweet as MSA if it mainly employs MSA words and adheres syntactically to MSA rules, otherwise it should be labeled DA.Table 3shows the types of annotations available for each data set. Data statistics, such as the distribution of classes, are provided in Table 4, and inter-annotator agreement in terms of Kappa (K) is shown in Table 5. For evaluation purposes, we chose the labels assigned by one of the annotators for each data set.Polarity lexicon: We manually created a lexicon of 3982 adjectives labeled with one of the following tags {positive, negative, neutral}, (c.f. Abdul-Mageed et al., 2011a). We focus on adjectives since they are primary sentiment bearers. However, the adjectives pertain to the newswire domain: they were extracted from the first four parts of the Penn Arabic Treebank (Maamouri et al., 2004). Consequently, they are out of domain for all the corpora studied here.

@&#CONCLUSIONS@&#
