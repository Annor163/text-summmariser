@&#MAIN-TITLE@&#
A multimodal temporal panorama approach for moving vehicle detection, reconstruction and classification

@&#HIGHLIGHTS@&#
An effective multimodal temporal panorama approach for moving vehicle detection and classification using a novel sensing system.A new audio-visual vehicle (AVV) dataset, which features audio-visual alignment, vehicle detection and reconstruction.Multimodal audio-visual feature extraction and selection with systematically study for multimodal feature integration.

@&#KEYPHRASES@&#
Laser-Doppler vibrometry,Multimodal,Panoramic imaging,Audio-visual integration,

@&#ABSTRACT@&#
Moving vehicle detection and classification using multimodal data is a challenging task in data collection, audio-visual alignment, data labeling and feature selection under uncontrolled environments with occlusions, motion blurs, varying image resolutions and perspective distortions. In this work, we propose an effective multimodal temporal panorama approach for moving vehicle detection and classification using a novel long-range audio-visual sensing system. A new audio-visual vehicle (AVV) dataset is created, which features automatic vehicle detection and audio-visual alignment, accurate vehicle extraction and reconstruction, and efficient data labeling. In particular, vehicles’ visual images are reconstructed once detected in order to remove most of the occlusions, motion blurs, and variations of perspective views. Multimodal audio-visual features are extracted, including global geometric features (aspect ratios, profiles), local structure features (HOGs), as well various audio features (MFCCs, etc.). Using radial-based SVMs, the effectiveness of the integration of these multimodal features is thoroughly and systematically studied. The concept of MTP may not be only limited to visual, motion and audio modalities; it could also be applicable to other sensing modalities that can obtain data in the temporal domain.

@&#INTRODUCTION@&#
Moving vehicle detection and classification, in applications such as traffic monitoring [11,12,29], surveillance [24,25], and checkpoint inspection [7], can be very challenging if the data are noisy, especially from a sensor system at a large standoff distance. Occlusions, motion blurs and variations of perspective views always make the task difficult in both feature extraction and object classification. Using visual-only sensors may not be sufficient; audio information can provide complementary acoustic signatures, such as loudness and sharpness, for distinguishing different types of vehicles [15]. Typical acoustic sensors are microphones or microphone arrays; however, laser Doppler vibrometers (LDVs) [30,16] have started to show promise in long-range acoustic detection. Microphones or microphone arrays need to be placed at fixed location and near to the target, otherwise all sounds in between are captured. An LDV can be used to listen to the target at very long distance when the laser beam is reflected from a good vibration surface, and only sounds close to the vibration surface are captured. For example, using a Polytec LDV with a<1mW red laser, we have found that the distance can be as far as 300m [30]; using a newly available Polytec LDV with a 10mW infrared laser, the distance could be much larger than that. In this work, we use a novel integrated audio-visual sensor system with a pair of PTZ cameras and a LDV for automatically acquiring video, range and audio information of moving vehicles at a large distance.Using the multimodal sensor platform, new audio-visual vehicle (AVV) datasets are collected in both local road and highway scenarios. Multimodal data are then represented in a multimodal temporal panorama (MTP) interface for audio-visual alignment, real-time automatic vehicle detection, vehicle speed estimation, accurate vehicle image reconstruction, and efficient vehicle labeling. Vehicle detection using multimodalities reduces some false target detection with online data alignment so that the feature combination and classification can be more efficient. With the detection results, we further apply a visual image reconstruction technique on moving vehicles so that the images of extracted vehicles are invariant to perspective views, and free from occlusions from static objects as well as motion blurs. Since vehicles’ images are reconstructed with the same side-views, many local and global features can be applied more efficiently for classification. Along with audio features, the classification performance can further be improved. We analyze various types of visual features and audio features individually; then integrate them systematically. The visual features include aspect ratio and size (ARS), histograms of oriented gradients (HOG), and shape profiles (SP), representing simple global geometric features, statistical features, and global structure features, respectively. The audio features include short time energy (STE), spectral energy, entropy, flux and centroid feature, and Mel-frequency cepstral coefficients (MFCC), which are grouped into three types: temporal feature (STE), spectral feature (SPEC) and perceptual feature (PERC). We provide a thorough study on the selection and combinations of features for vehicle classification using support vector machines (SVMs). This research can find applications in traffic monitoring, check point security inspection, and transportation management. The general idea can also be applied to other applications with multimodal sensing and target detection and classification.There are three main contributions of this work. First, a new audio-visual vehicle dataset is created, and a multimodal temporal panorama approach is proposed for real-time detection and fast data labeling. Second, a novel method for vehicle image reconstruction is designed using multiple images, and the reconstructed images are both view-invariant and occlusion and motion-blur free. Third, we show the effectiveness of multimodal feature selection and combination through an empirical approach, particularly of the importance of audio-visual integration. We also provide detailed observations for future research.The rest of paper is organized as follows. Section 2 discusses some related work. Section 3 presents the AVV dataset. Section 4 describes the multimodal temporal panorama representation and the visual reconstruction method. Section 5 describes multimodal feature extraction. Section 6 provides the experiment results of multimodal vehicle classification and analyzes the multimodal integration issues based on the experiments. Conclusions and discussions are provided in Section 7.

@&#CONCLUSIONS@&#
