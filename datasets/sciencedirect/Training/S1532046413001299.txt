@&#MAIN-TITLE@&#
Extraction of events and temporal expressions from clinical narratives

@&#HIGHLIGHTS@&#
Standard approaches for event extraction consider each event in isolation.We design a sentence-level inference strategy for event extraction.We use MeSH and SNOMED CT to design clinical descriptors.We give a robust algorithm for date extraction.Several rules were developed to extract and normalize complex temporal expressions.

@&#KEYPHRASES@&#
Natural language processing,Named entity recognition,Electronic health records,Information extraction,Temporal extraction,Integer quadratic programmming,

@&#ABSTRACT@&#
This paper addresses an important task of event and timex extraction from clinical narratives in context of the i2b2 2012 challenge. State-of-the-art approaches for event extraction use a multi-class classifier for finding the event types. However, such approaches consider each event in isolation. In this paper, we present a sentence-level inference strategy which enforces consistency constraints on attributes of those events which appear close to one another. Our approach is general and can be used for other tasks as well. We also design novel features like clinical descriptors (from medical ontologies) which encode a lot of useful information about the concepts. For timex extraction, we adapt a state-of-the-art system, HeidelTime, for use in clinical narratives and also develop several rules which complement HeidelTime. We also give a robust algorithm for date extraction. For the event extraction task, we achieved an overall F1 score of 0.71 for determining span of the events along with their attributes. For the timex extraction task, we achieved an F1 score of 0.79 for determining span of the temporal expressions. We present detailed error analysis of our system and also point out some factors which can help to improve its accuracy.

@&#INTRODUCTION@&#
The i2b2 2012 challenge [1] was focussed on temporal information extraction from clinical narratives. This challenge consisted of three tasks: (a) event extraction, (b) temporal expression (or timex) extraction and (c) extraction of temporal relations. We participated in the first two tasks, namely, event and timex extraction. This paper describes our approach to extracting events and temporal expressions from clinical narratives. Input for these tasks consists of clinical narratives (in plain text format) and goal is to automatically annotate the clinical narratives with events and timexes information. Along with finding text spans of events and timexes, these tasks also involve finding their attributes.A sub-task of event extraction (i.e. concept extraction) for clinical narratives has been previously addressed in some of the works [2–7]. Uzuner et al. [8] give a survey of systems that participated in the 2010 i2b2 NLP challenge. Best systems for this task used machine learning approaches to find concept boundaries and types. Most of the systems used some sequence prediction model in conjunction with a multi-class classifier (like Support Vector Machines (SVMs)) for finding concept boundaries and types. Sequence prediction models that are typically used are first-order models so that the inference remains tractable. Such models cannot account for expressive (long-range) dependencies between different events. In this paper, we present a general inference strategy which can easily account for such expressive dependencies.For timex extraction, best available systems (like HeidelTime [9] and SUTime [10]) are rule-based. HeidelTime is a multilingual cross-domain temporal tagger and was the best system for extraction and normalization of English temporal expressions in the TempEval-2 [11] challenge. SUTIME is another temporal tagger and is available as part of the Stanford CoreNLP pipeline. Testing on the TempEval-2 evaluation corpus shows that this system gives results comparable to HeidelTime. Angeli et al. [12] present a probabilistic approach (using a Probabilistic Context Free Grammar (PCFG)) for learning to interpret temporal phrases. However, this system does not perform as well as HeidelTime and SUTime on TempEval-2 task. Both HeidelTime and SUTime have been designed for general English text and are not sufficient for extracting clinical timexes. We developed rules specific to clinical narratives which complement HeidelTime for the task of clinical timex extraction. Sun et al. [13] provide comprehensive overview of systems which perform clinical timex extraction.The primary contributions of this paper are the following:1.Novel Features: We designed novel features for event extraction. One of our features is to construct a clinical descriptor for any concept using medical ontologies (like MeSH and SNOMED CT). The clinical descriptors designed by us encode important information about concepts and would benefit several other Information Extraction tasks. For example, clinical descriptor of the concept “Myocardial Infarction” (or Heart Attack) consists of the following terms: Disease, Traumatic Injury, Disease affecting entire cardiovascular system, Myocardial Ischemia, Heart Disease, etc.Sentence-Level Inference: Attributes of events which appear close to one another are sometimes related. To use such information, we developed an inference strategy which ensures that the attributes of related events are consistent with one another. Our approach advances the current state-of-the-art for event extraction where events are considered in isolation while determining their attributes. Moreover, our approach is general and can also be used for other cases where one is jointly solving several Information Extraction tasks which constrain one another.Date-extraction algorithm and rules for timex extraction: We give a simple but robust algorithm for date extraction using the JodaTime [14] Library. We adapted a state-of-the-art system for timex extraction in the news domain (namely, HeidelTime) for using it in clinical narratives. We also developed our own rules for timex extraction to complement the HeidelTime and show that our rules give substantial performance improvement for this task.Task Description:In this task, we need to extract medical events from the clinical text. The i2b2 2012 challenge guidelines [1] defined a medical event as anything that is clinically important and that can also be mapped to a timeline. In addition to finding the text-spans referring to the events, we also need to identify these 3 attributes of the events: Type, Modality and Polarity. There are 6 possible values for the Type attribute: (1) laboratory tests, etc. (TEST), (2) treatments, medications, surgeries, etc. (TRE), (3) symptoms, diseases, complaints, etc. (PROB), (4) clinical departments like ICU (CDEPT), (5) evidential events like reporting a pain (EVID) and (6) any event which does not belong to first 5 types is referred to as Occurrence event (OCCU). The polarity attribute marks whether an event is positive (POS) or negative (NEG). For example, in the sentence “the patient reports headache, and denies chills”, the event [headache] is positive in its polarity, and the event [chills] is negative in its polarity. The modality attribute is used to describe whether an event actually occurred or not. It can take four possible values: Factual (FACT), Conditional (COND), Possible (POS) and Proposed (PROP).Approach Used:We used a pipeline approach for event extraction as illustrated in Fig. 1. In this approach, we first identify the spans of the events. These spans are given as input to the type classifier which finds the probability associated with any event taking a particular type. Then the event spans and type probability vectors serve as input for the modality and polarity classifiers which output the probabilities associated with any event taking particular modality and polarity values. The probability outputs of different classifiers are then given as input to the inference procedure which computes the final assignment of values to different event attributes. The different stages of this pipeline are described in more detail in the following subsections:We used a simple high-recall strategy for finding the spans of the events. Here, we take all the constituents1Constituents refer to the chunks output by shallow parser.1output by a state-of-the-art shallow parser2http://cogcomp.cs.illinois.edu/page/software_view/Chunker.2as candidate events. This list of candidates is then filtered in the following way:1.The constituents which do not contain any letter (a–z) (e.g. 09/01/2011) are discarded.Constituents which correspond to names of persons (e.g. Dr. Barber) are discarded.Constituents corresponding to pronouns (e.g. he, she, etc.) are discarded.Constituents which only consist of stopwords are discarded.It is to be noted that a constituent which passes all the tests of this stage can still be rejected later on by assigning the type “NULL” to it. This justifies the use of high-recall strategy in this stage.To find the types of events, we employed a multi-class SVM classifier as provided in the LIBSVM package [15]. Many of the constituents returned by the filtering process described above are still not events. So, we added a NULL type to the classifier to identify the constituents which are not events. Following features were used in the classifier design:1.Normalized string: We normalized the surface form of the constituent by converting it to lowercase and removing the stopwords from it.Unigrams: We split the surface form of the constituent to get the white-space delimited tokens. These tokens (other than those which correspond to stopwords) were used as the features.Semantic Type: We processed the constituent using MetaMap which gives the UMLS concepts corresponding to the constituent. We used 2012AA USA-strict model in the MetaMap. Semantic types of these concepts were used as features.Occurrence in MeSH: This is a binary feature which is active only if at least 1 of the concepts returned by MetaMap also occurs in the MeSH3http://www.nlm.nih.gov/mesh/meshhome.html.3Vocabulary.Occurrence in SNOMED CT: This is a binary feature which is active only if at least 1 of the concepts returned by MetaMap also occurs in SNOMED CT4http://www.ihtsdo.org/snomed-ct/.4vocabulary.MeSH Descriptor: MeSH Descriptor for a concept is found in the following way:(a)First of all, we construct the path from the concept to the root of the MeSH hierarchy. In general, there can be more than 1 paths. Fig. 2a and b show the different paths in MeSH and SNOMED CT parent trees for the same concept “Myocardial Infarction”.For each path found in Step (a), we retain the top 4 concepts5Let ‘x’ be the number of concepts to retain. This number was determined empirically. We were guided by the consideration that the retained concepts should neither be too general nor too specific. We experimented with different values of x. By manual observation, x=4 gave the best results.5(starting from the root of MeSH hierarchy). For example, for the two paths shown in Fig. 2a, we get the following 2 lists:•(Diseases, Cardiovascular Diseases, Vascular Diseases, Myocardial Ischemia) for first path and(Diseases, Cardiovascular Diseases, Heart Diseases, Myocardial Ischemia) for second path.It is to be noted that these lists differ in only the third member. Please also note that while making these lists, we did not include the following concepts: (MeSH, MeSH Descriptors, Topical Descriptor). This is because of the fact that these concepts appear at the top of almost all the paths and thus, do not provide any specific information.The lists obtained in previous step are then merged into a single list. For example, by merging the 2 lists mentioned in Step (b) above, we will get a single list with 8 members (some of which are duplicates). The duplicates are then removed but we keep track of the frequency with which each concept appeared in the list.The list obtained in step (c) is then sorted by concept frequency.Finally, we retain only the first 3 members of the list mentioned in Step (d). If there is a tie, preference is given to those concepts which are lower in the hierarchy because they often contain more useful information.The final list thus obtained in previous step gives us the MeSH descriptor of the concept.MeSH descriptor of the full constituent is formed by taking the union of the MeSH descriptors of all the concepts occurring in the constituent as returned by MetaMap.SNOMED CT Descriptor: SNOMED CT descriptor of the constituent is formed by a similar method as described for the MeSH descriptor.Most of the features described above are lexical features which leads to a large number of total number of features. We get a total of 25,284 features and 31,291 training examples for our type classifier. SVM is able to effectively learn from such large number of features.To find the polarity of events, we designed a binary classifier with the following features:1.Negex: We use output of a publicly available implementation of Negex [16] algorithm as one of our features. Negex is a rule-based classifier for negation detection and the rules are specially designed for medical domain.Unigrams from the constituent.Four tokens from both left and right sides of the constituent.Event type with the maximum probability as output by the type classifier previously.To find the modality of the events, we used a multi-class classifier using LIBSVM package. It used the same features as those in the polarity classifier except the NegEx feature.In this section, we describe our inference strategy for event extraction. The basic principle behind this strategy is: “Attributes of events which appear close to one another are sometimes closely related. For some events, attributes can be determined with more confidence. And relations between events’ attributes guide the inference procedure to determine the attributes of other events.” We will now explain it in more detail with the help of examples. Fig. 3shows two sentences in which the events are shown in brackets and correct (gold) attributes of events are shown adjacent to them. Event attributes are shown in the following order: Event Type/Event Polarity/Event Modality.Now, consider first and third events in Fig. 3a. These events follow the pattern: [Event1] showed [Event2]. Let us call this pattern P1. In clinical narratives, such a pattern strongly suggests that Event1 is some kind of test and Event2 is some kind of problem (or symptom). So, we can impose a constraint on the output of classifiers that whenever it sees that two events follow pattern P1, then Event1 should be assigned the type TEST and Event2 should be assigned the type PROB.Next, consider different events in Fig. 3b. All these events are separated by commas and hence, form a list. It is highly likely that all the events which appear in a list should have the same type. The advantage of such a constraint can be explained as follows: Suppose that type classifier is not sure about the type of second event “hematemesis” (which means that it does not give a high probability to any of the event types). But the type classifier is confident that first and third events (“hemoptysis” and “abdominal pain”) are both problems. Based on the constraint that all the elements in a list should have the same type, type classifier can correctly infer that “hematemesis” should also be of type PROB.It is also to be noted that each constraint can either be coded as a hard-constraint or a soft-constraint. If a constraint is generally not violated in the training data, then it is formulated as a hard-constraint. Otherwise, the constraint is made soft with a penalty parameter which is inversely proportional to the probability of violation of constraint in the training data.In this section, we explain how to implement the inference procedure outlined in the previous section. We implement the inference procedure by writing it in terms of an optimization problem (specifically, Integer Quadratic Program (IQP)) as shown below in Eqs. (1)–(7). In this optimization problem, we basically try to assign those values to the events’ attributes which get maximum probability according to the classifiers subject to several hard and soft constraints. To solve the IQP, we used Gurobi Optimizer 5.0 [17]. Previously, Roth and Yih [18] also suggested a formalism that combines constraints with linear models. However, unlike us, they restricted themselves to hard constraints.(1)max∑i=1d∑k=17xtype,i,k·ptype,i,k+∑k=14xmod,i,k·pmod,i,k+∑k=12xpol,i,k·ppol,i,k-∑(i,j)∈Lρtype·1{ztype,i≠ztype,j}-∑(i,j)∈Lρmod·1{zmod,i≠zmod,j}-∑(i,j)∈Lρpol·1{zpol,i≠zpol,j}(2)s.t.∀c∈C1:∀i∈Sc:⋁k∈Lcxtype,i,k(3)∀c∈C2:∀(i,j)∈Sc:⋁k∈L1cxtype,i,k∧⋁k∈L2cxtype,j,k(4)∀c∈C3:∀(i,j)∈Sc:∀k:xtype,i,k==xtype,j,k(5)∑k=17xtype,i,k=1,∑k=14xmod,i,k=1,∑k=12xpol,i,k=1∀i(6)ztype,i=k⇔xtype,i,k=1,zmod,i=k⇔xmod,i,k=1,zpol,i=k⇔xpol,i,k=1∀i(7)xtype,i,k∈{0,1},xmod,i,k∈{0,1},xpol,i,k∈{0,1}∀i,kEq. (1) describes the objective function of IQP. In this equation, xtype,i,kdenotes the indicator variable (as shown in Eq. (7)) which is equal to 1 (active) iff event i has type k. ztype,iis another variable which takes an integer value (from 1 to 7) corresponding to the type of event i as shown in Eq. (6). xmod,i,k, xpol,i,k, zmod,iand zpol,iare similarly defined. ptype,i,kis the probability of event i having the type k as output by the type classifier. pmod,i,kand ppol,i,kare similarly defined.Next, we describe the different constraints used in the optimization problem:1.The last 3 summation terms in Eq. (1) correspond to three soft constraints with penalty parameters given by ρtype, ρmodand ρpol. Here, L is the set of 2-tuples where each tuple contains ids of 2 events which appear adjacent to one another in a list. Thus, these constraints penalize those assignments where the events which appear in a list get different attributes.C1 in Eq. (2) refers to the set of those constraints which act only on a single event. Here, Scis the set of events which satisfy constraint c and Lcis the set which contains the possible event types for any event in Sc.C2 in Eq. (3) is a set of binary constraints (constraints which take 2 events as arguments). Scis the set of event tuples which satisfy constraint c. L1cand L2care the sets of possible event types for the first and second element of event tuples in Sc. An example of this constraint is a pattern “[Event1] showed [Event2]” as shown in Fig. 3a.C3 in Eq. (4) is another set of binary constraints which enforce the events in every tuple of Scto have the same type. For example, any two events which are separated by a comma and are part of the same list should have same type.Eq. (5) imposes the constraint that every event has a unique type, modality and polarity.It is to be noted that the inference procedure as described above is very general and allows for several other types of constraints. For example, there can be constraints which relate the values of different attributes of the same (or even different) event(s). However, we have not yet experimented with such constraints and we will address this issue in future work.Task Description:In the Timex extraction task, a system is supposed to identify the spans and attributes of the temporal expressions in the text. The i2b2 2012 challenge guidelines [1] defined three attributes associated with each temporal expression, namely type (TYPE), value (VAL) and modifier (MOD). The TYPE attribute can have 4 possible values: DATE, TIME, Duration (DUR) and Frequency (FREQ). The VAL attribute gives the time (value) associated with the temporal expression. Finally, a temporal expression can have one of the following 7 modes: NA, APPROX, MORE, LESS, START, MIDDLE, END.Approach Used:Our overall approach for timex extraction is rule-based as rule-based methods have been shown to give the best results to date for this task [11]. For the timex extraction task, first of all we determine the “Admission Date” and “Discharge Date” as given in the clinical narrative. Then we use a publicly available temporal extraction system, namely HeidelTime, as our basic building block. And finally, we use our own rules which are specifically designed for clinical narratives to complement the output of HeidelTime. We explain each of these components of our temporal extraction system in the following subsections.In this subsection, we describe the method used by us to determine “Admission Date” and “Discharge Date” in the clinical narrative.1.Clinical narratives in the i2b2 datasets typically have 4 sections: Admission Date, Discharge Date, History of Present Illness and Hospital Course. A new section is determined by the fact that the line ends with a semicolon.After we determine the first line where “Admission Date” and “Discharge Date” sections begin, we use a regular expression to find out whether the following line has a date in it.Now, a date can be written in several different formats. For example, we can write the same date Sep 14, 1999 in the following ways: 1999-09-14, 99/09/14, 09/14/99, 09/14/1999, 09-14, etc. Clinical reports list the dates in all such formats. Correctly determining the date requires consideration of the constraints on the date fields, namely day, month and year. For example,(a)Since the narratives were all taken from US hospitals, they put month before date.Month takes value between 1-12 and day takes value between 1-31.Year can appear either as a first field or a last field.Year can either be in 2 digit format or in 4 digit format.It is possible that year may not be there at all (as it can be determined from context). But since we are dealing with clinical reports, the day field will generally be there.Both “-” and “/” can act as separators between various fields of date expression.Considering the above things, we designed the following 10 regular expressions using JodaTime Library: yy-MM-dd, MM-dd-yy, yyyy-MM-dd, MM-dd-yyyy, yy/MM/dd, MM/dd/yy, yyyy/MM/dd, MM/dd/yyyy, MM-dd, MM/dd. The given date expression was made to match with each of these regular expressions. JodaTime itself takes care of consistency checks on the date fields. First regular expression which matched the date expression was used to determine the date fields. This algorithm gave us an accuracy6Here, accuracy refers to the fraction with which our system correctly identifies the date associated with a date pattern. For example, the pattern “7/12/99” represents the date “July 12, 1999”.6of 97% on test portion of the i2b2 2012 dataset.The above procedure was also used to determine dates in other sections of the clinical narrative.1.We used HeidelTime as a basic building block to obtain the temporal expressions. For the temporal expressions that HeidelTime identifies, it also gives the TYPE, VAL and MOD attributes. HeidelTime also expects the “Document (Section) Creation Time (DCT)” as one of the inputs which serves to resolve the ambiguity while determining the value of some temporal expressions. For “History of Present Illness” section, DCT is given to be the Admission date and for “Hospital course” section, DCT is given to be the Discharge Date.HeidelTime assigns the type SET to timexes of type FREQ. So, we replace the SET type in HeidelTime with FREQ while outputting the result. Also, in the VAL attribute for timexes of type FREQ, HeidelTime does not prefix the value with R. So, we ourselves prefix the value of FREQ timexes with “R”. In some cases, the VAL attribute given by HeidelTime is not formatted according to the i2b2 guidelines. So, we do a post-processing step to properly format the HeidelTime results. For example, for the phrase “several months”, HeidelTime gives the value PXM.7Here, “X” represents an unknown value.7We change it to P3M and set the modifier attribute to APPROX as specified in the i2b2 guidelines.Next, the MOD attribute produced by HeidelTime is mapped to the i2b2 MOD attribute. For example, “more_than” of HeidelTime is same as “more” of i2b2.Although HeidelTime is good in identifying timexes written in general English, it is not able to identify the clinical timexes. So, we added the following rules in our system to identify the clinical timexes.1.Some timexes are of the form “POD#n”.8“POD” stands for “postoperative day”.8For such timexes, first we identify the temporal expression corresponding to the “operation date”. If we do not find such an expression, then we set the operation date to be same as admission date. Next, we set the value of “POD#n” to n days after the operation date. We also capture other variations of “POD#n” like “postoperative day n”, etc.A similar procedure as described above is also followed for the expressions like “hospital day n” or “HD n”. Reference date for computing the value of such timexes is the admission date.We identify clinical expressions of the type “x n” or “xn” or “times n”, etc. Such expressions are of type frequency and identify only the number of times for which an event is repeated but do not specify the interval for such repetition. A value of “Rn” is given to these expressions.If year value is not specified for some of the dates mentioned within the document, then we set the year based on admission date or discharge date.Several timexes contain the word “day” in them. Expressions like “per day” are assigned the type FREQ with a period of 1day. For expressions like “2days after admission (discharge)”, we calculate the value based on admission (discharge) date and assign the type DATE to such expressions.Expressions like “tid” or “t.i.d.”, etc. are of type FREQ with period of 8h. Similar rules are also developed for expressions of type “bid”. These expressions have the period of 12h.Several timexes start with the letter “q”. We developed rules for all such expressions. For example, our rules cover the following expressions: qid (Period: 6h), qad (Period: 48h), qd (Period: 24h), qds (Period: 6h), qAM or qPM (Period: 24h), qn or qnoc (“every night”, Period: 24h), qmt (“every month”, Period: 1month), qw (“every week”, Period: 1week), etc. Please note that our rules also cover variations of such expressions as well. Expressions of type “qnh” have the period of n hours where n is a number.

@&#CONCLUSIONS@&#
