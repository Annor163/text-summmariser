@&#MAIN-TITLE@&#
Exploiting multi-expression dependences for implicit multi-emotion video tagging

@&#HIGHLIGHTS@&#
We propose a novel multiple emotional tagging method based on multi-expressions.We propose a novel multi-expression recognition by exploring dependencies among expressions.We model the relationships between expressions and emotions using a Bayesian Network.

@&#KEYPHRASES@&#
Implicit video tagging,Multi-emotion,Multi-expression,

@&#ABSTRACT@&#
In this paper, a novel approach of implicit multiple emotional video tagging is proposed, which considers the relations between the users' facial expressions and emotions as well as the relations among multiple expressions. First, the audiences' expressions are inferred through a multi-expression recognition model, which consists of an image-driven expression measurement recognition and a Bayesian network representing the co-existence and mutual exclusion relations among multi-expressions. Second, the videos' multi-emotion tags are obtained from the recognized expressions by another Bayesian Network, capturing the relations between expressions and emotions. Results of the experiments conducted on the JAFFE and NVIE databases demonstrate that the performance of expression recognition is improved by considering the relations among multiple expressions. Furthermore, the relations between expressions and emotions help improve emotional tagging, as our approach outperforms the traditional expression-based or image-driven implicit tagging methods.

@&#INTRODUCTION@&#
Recent years have seen a rapid increase in the size of digital video collections. Because emotion is an important component in the personalized classification and retrieval of digital videos, assigning emotional tags to videos has been an active research area in recent decades [1]. This tagging work is usually divided into two categories: explicit and implicit tagging [2]. Explicit tagging involves a user manually labeling a video's emotional content based on his/her visual examination of the video. Implicit tagging, on the other hand, refers to assigning tags to videos based on an automatic analysis of a user's spontaneous response while consuming the videos [2]. Although explicit tagging is a major method at present, it is time-consuming and brings users extra work. Implicit emotion tagging can overcome the above limitations of the explicit tagging.The manifestations of human emotion are various, including physiological signals and visual behaviors, which are adopted as users' spontaneous nonverbal responses in implicit emotion tagging research. Physiological signals reflect subtle unconscious variations during emotion experience in bodily functions, which are controlled by the Sympathetic Nervous System (SNS). Most of these functions cannot be easily captured by other sensory channels or observation methods. However, to capture physiological responses, users are required to wear complex apparatuses, which may make some users feel uncomfortable. In contrast, when obtaining an implicit tag by visual behavior, no complex apparatus other than one standard visible camera is needed. Thus video-based approach is more easily applied outside the laboratory.Facial expression analysis is one of the most feasible visual behaviors for implicit video tagging. Six basic expression categories proposed by Paul Ekman are the widely adopted descriptors, including anger, disgust, fear, happiness, sadness, and surprise [3]. Present expression-based video tagging research however assumes human's expression as a singular category. It means that only one particular category of expression appears at a time. This assumption may be challenged by psychology studies, which demonstrate that some expression manifestations are the combination of some specific basic expression categories [4] because of the underlying facial anatomy. In addition, some expressions may rarely appear together, such as happiness and sadness. These co-existent and mutual exclusive phenomenon of basic expressions should be considered in expression recognition. In this paper, multi-expression recognition is conducted. The relationships among expressions are taken into consideration by a Bayesian Network (BN).Even though facial expression is the major visual manifestation of emotions, they are still different [5–8]. Thus, we cannot treat them totally similarly [9]. However, the relationships between them are rarely analyzed or considered [10]. In the video emotion tagging, the facial expressions are typically regarded as the emotions. Similar to expressions, multiple emotions may appear while subjects watch stimuli videos [11] or during our daily communications. Therefore, it is reasonable to tag a video's emotion with multi-emotion categories and to consider their relationships. In this paper, we use a BN to capture the relations between multiple emotions and multiple expressions.In this paper, a multi-emotion tagging method is proposed. First, the multi-expressions of the user are recognized through a novel expression recognition model, which contains an image-driven expression recognition and a BN model exploiting the relations among multi-expressions. Then, the video's multi-emotion tags are obtained from recognized multi-expressions through another BN model considering the relations between the expressions and emotions. Expression recognition results on both JAFFE [12] and NVIE [13] databases demonstrate the importance of modeling multi-expression relations. Emotional tagging results on NVIE database validate the effectiveness of our approach.

@&#CONCLUSIONS@&#
