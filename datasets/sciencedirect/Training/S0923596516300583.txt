@&#MAIN-TITLE@&#
Identifying deficits of visual security metrics for images

@&#HIGHLIGHTS@&#
Introduction of a formal method to evaluate security metrics.An evaluation of state-of-the-art image and security metrics.Currently there are not security metrics without deficits.

@&#KEYPHRASES@&#
Confidence,Image metrics,Partial encryption,Security metrics,Selective encryption,Sufficient encryption,Transparent encryption,

@&#ABSTRACT@&#
Visual security metrics are deterministic measures with the (claimed) ability to assess whether an encryption method for visual data does achieve its defined goal. These metrics are usually developed together with a particular encryption method in order to provide an evaluation of said method based on its visual output. However, visual security metrics themselves are rarely evaluated and the claim to perform as a visual security metric is not tied to the specific encryption method for which they were developed. In this paper, we introduce a methodology for assessing the performance of security metrics based on common media encryption scenarios. We systematically evaluate visual security metrics proposed in the literature, along with conventional image metrics which are frequently used for the same task. We show that they are generally not suitable to perform their claimed task.

@&#INTRODUCTION@&#
The claim of visual security metrics (security metrics for brevity) is usually the ability to assess the functionality of an encryption method based on the output of the encryption of visual data. In particular, the evaluation of an encryption method is only based on the visual output (i.e., the ciphertext), which is either an image or video. While such metrics are often created in conjunction with a specific encryption method and tested, if at all, only for this encryption method, the claim to perform as a security metric is usually universal. Furthermore, regular image quality metrics, such as the frequently used PSNR and SSIM, are also utilized in the literature to evaluate encryption methods [1–4].The problem with the evaluation of security metrics is the fact that there is no established testing methodology. Thus, even if security metrics are tested, the test is usually based on the evaluation procedures for regular image metrics, which are not sufficient to establish whether a method is applicable in the context of encryption.Regarding cryptographic security, Shannon's work [5] shows that the highest level of security is reached when applying a secure cipher to a redundancy free plain text. Current image/video codecs exploit redundancy for compression and thus we can consider a bit stream to be an almost redundancy free plain text in the sense of Shannon. Consequently, for maximal security, the encryption of the entire bit stream with a state-of-the-art cipher, such as AES, would suffice (“conventional encryption”). Lookabaugh and Sicker [6] showed that selective encryption is sound and demonstrated its relation to Shannon's work. However, [7] showed that side information can compromise security.However, there are application scenarios which make it necessary to move away from full encryption. Methods which do not utilize full encryption of the underlying data are called Lightweight/Soft/Partial/Selective Encryption. Specifically, selective encryption is the application of an assumed secure encryption method to a selected part of the plain text. In selective encryption the encryption part is assumed to be secure, e.g., by using AES. The final security of the selective encryption comes then from the selection part. What is evaluated in order to gauge the final security of the selective encryption is, to what extent the information left in plain text can be used to reconstruct an image or video.Furthermore, an attack on the selective encryption method does not come from attacking the encryption, but from attacking the selection. This is usually done by using knowledge about the original format of the image/video. An attack is usually based on removing the negative impact on quality by the, essentially random, signal introduced by the encryption. This is typically done by replacing the random signal by a signal which introduces the least amount of error into the final decoding. In order to do so, very specific knowledge about the containing format has to be exploited, and there is usually only a single method to go about this, i.e., the attack.Another, (implicit) assumption about the selective encryption method under test is the format compliance. Format compliance requires an encrypted bitstream to be decodable by a standards compliant decoder. In other words, format errors may not be introduced by the encryption. Thus, in the following, when we refer to an encrypted image/video we mean the image or video that results from decoding an unattacked encrypted bitstream.The notion of security in selective encryption is different from the traditional notion of security: First, we knowingly leave information in plain text to retain format compliance; second, the focus is on content security not information security, i.e., the content should be secure (to some defined extent), while information about the content might be allowed to leak. In order to be able to discuss the exact notion of security in such non-conventional encryption schemes, we need to distinguish distinct application scenarios of encryption schemes for visual data:Confidentiality encryption:Means MP security (message privacy). The formal notion is that if a system is MP-secure an attacker cannot efficiently compute any property of the plain text from the cipher text [8]. This can only be achieved by the conventional encryption approach.This is a relaxation of confidential encryption. Side channel information may be reconstructed or left in plaintext, e.g., header information, packet length, but the visual content must be secure in the sense that it must not be intelligible/discernible [9].Means we do not require full security, just enough security to prevent abuse of the data. The content must not be consumable due to high distortion (e.g., for DRM systems) by destroying visual quality to a degree which prevents a pleasant viewing experience or destroys the commercial value. This implicitly refers to message quality security (MQ), which requires that an adversary cannot reconstruct a higher quality version of the encrypted material than specified for the application scenario [10].Means we want consumers to be able to view a preview version of the video but in a lower quality while preventing them from seeing a full version. As an example: this can be used in a pay per view scheme where a lower quality preview version is available from the outset to attract the viewers interest, q.v., [11]. The difference between sufficient and transparent is the fact that there is no minimum quality requirement for sufficient encryption. Encryption schemes which can do sufficient encryption cannot necessarily ensure a certain quality and are thus unable to provide transparent encryption.Given these different application scenarios it is clear that depending on the goal, a security metric has to fulfill different roles. For example, under the assumption of sufficient encryption, a given security metric would have to evaluate which quality is low enough to prevent a pleasant viewing experience. In contrast, for the transparent encryption case, a metric not only has to assess whether the quality of an image or video is low enough, but also whether the quality is high enough to be useful to attract interest. When it comes to content confidentiality the question of quality is no longer applicable. Content confidentiality requires that image content must not be identified by human or automated recognition. This requirement also has to be maintained for any part of the image. Image metrics, in general, do not deal with such questions but rate the overall image quality, the question of intelligibility is usually not covered at all. A drastic example would be an image where only a small part of the image is partly visible. Classical metrics would judge the whole image and consequently would attribute a high security, even though a part of the image is still recognizable which contradicts content confidentiality. Still, it has to be pointed out that content confidentiality can have different forms. To prevent a face recognition scheme from working properly it is sufficient to protect any facial information in a surveillance video, while humans could still be identified in such a video by using gait recognition. Furthermore, if the appearance of a person has to be concealed entirely, a much stronger extent of protection (i.e., higher security) is required. Finally, confidential encryption cannot be solely assessed with security metrics since the scope goes beyond assessing security based on the visual appearance only. Furthermore, we should note that the application of security metrics on video is performed at a frame by frame basis in the literature. We will adopt this model but should note that for the discussion of confidential encryption motion data is of importance, e.g., in [12] it was shown that a replacement attack combined with motion information can reveal the content of a scene even though the visual content of every frame is encrypted.Consequently, depending on a given application scenario different properties are required from a security metric and different approaches to construct such a metric might perform better or worse for some applications scenarios. This dependence on the evaluation goal of a security metric is hardly ever discussed in the papers introducing a metric. Sufficient and transparent encryption scenarios have a clear and distinct link to the traditional notion of (low) visual quality, while it is highly questionable or at least doubtful if content confidentiality can be assessed by the classical quality notion. While the lack of relation to spatial areas of most security metrics could be compensated in the design to provide locally varying results, the lack of relation to intelligibility in general can probably not be easily resolved.For both, security metrics and regular image metrics, in the literature we do not find any evaluation whether a given metric can perform the claimed function or how such an evaluation correlates to actual security. However, for regular image metrics it is well known that the correlation with human observations over the full range of possible quality (from high to low quality) does not imply a good performance on a given subset. More specifically, it was pointed out recently that most image metrics perform very poorly for the low quality range ([13]–using the low quality end of the LIVE database). For security metrics, not even this question has been covered so far.In this paper, we will try to remedy this situation by giving an overview of requirements regarding security goals and formulating these requirements into a testing methodology. Based on this methodology we will evaluate the various security metrics in the literature as well as applicable conventional image metrics. However, we will not deal with every application scenario equally explicitly. We will only make a first step to cover the content confidentiality scenario. The main reason for this is a lack of ground truth. It is not obvious how to generate ground truth for this scenario since there is a disparity between how an image metric works and what is necessary to evaluate content confidentiality. Image metrics, and as an extension security metrics, measure the quality of an image respective to human judgement. This works well for high quality images but suffers for low quality images where human observers can have difficulties differentiating between the severity of an impairment. Thus the methodology to systematically generate ground truth based on human observation needs to be changed for content confidentiality which is not in the scope of this paper. On the other hand, for the image quality-related scenarios (sufficient and transparent encryption), ground truth data is available, in the form of image impairment databases with mean opinion scores (MOS) based on a number of human observations.In the following we will motivate and introduce a methodology which allows to measure desirable traits of a security metric. This methodology can, and should, be used to asses newly developed metrics.To motivate this, we will give an overview of security metrics used in the literature in Section 2. We will not analyse why metrics fail and the presented counterexamples should be seen as a proof by contradiction rather than a exhaustive list of failings. Note that this is a question of generality, we do not dispute that certain metrics are a good fit for specific encryption types.In Section 3 we will describe what is expected of security metrics and the methodology how security metrics can be evaluated. This is done by providing certain desirable traits of a security metric, a motivation for the traits and a formal description of the traits to allow measuring them.In Section 4 we will present the evaluation of state-of-the-art metrics and measure their ability to perform as security metrics. This is done based on the traits introduced in Section 3 and shows the usefulness of these traits to find shortcomings of current metrics and to prevent the same shortcomings in future metrics.Section 5 will conclude the paper and give a list of state-of-the-art reference metrics and their usability as security metrics.In this section a brief overview of security metrics will be given. The metrics discussed are taken from the recent literature and are specifically designed to ascertain whether the image quality after encryption is sufficiently reduced. The metrics given in this section are discussed as general security metrics, i.e., not limited to the specific method with which they were designed together. References to the original work will be given for each security metric as well as some examples where the metric fails to assess given example images as would be expected from a general security metric. The SSIM and PSNR are also included in this overview. Even though they were not designed to be security metrics, they are frequently used as such, e.g., [3,14–16] (SSIM), [4,17–19] (PSNR) and [1,2] (SSIM and PSNR).Peak Signal to Noise Ratio (PSNR): The peak signal-to-noise ratio (PSNR) is still widely used because it is unrivaled in speed and ease of use. The PSNR is a quality metric, meaning a high metric score reflects a high quality, which gives a score in the range[0,∞]. However, it is also well known that the correlation to human judgement is somewhat lacking even for high and medium quality [20]. Fig. 1illustrates the performance of the PSNR metric on samples from the IVC-SelectEncrypt [21] database (see Section 3).Structural Similarity Index Measure (SSIM): The structural similarity index measure (SSIM) [22] extracts three separate scores from the image and combines them into the final score. First the visual influence is calculated locally then luminance, contrast and structural scores are calculated globally. These separate scores are then combined with equal weight to form the SSIM score. The SSIM is a quality metric, a high metric score reflects a high quality, which gives a score in the range[0,1]. Fig. 2illustrates the performance of the SSIM metric on samples from the IVC-SelectEncrypt database.Edge Similarity Score (ESS): The edge similarity score (ESS) was introduced in [23] and uses localized edge direction information to compare two images. The ESS is a quality metric, a high metric score reflects a high quality, which gives a score in the range[0:1]. Fig. 3illustrates the performance of the ESS metric on the foreman sequence when encryption according to [24] is applied in comparison to white noise.Luminance Similarity Score (LSS): The luminance similarity score (LSS) was introduced in [23] and uses localized luminosity information to compare two images. The LSS is a quality metric, a high metric score reflects a high quality, which gives a score in the range[−8.5:1]. Fig. 4illustrates the performance of the LSS metric on the foreman sequence when encryption according to [25] is applied in comparison to noise.Neighborhood Similarity Degree (NSD): The neighborhood similarity degree metric (NSD), introduced in [26], uses local pixel similarity correlation between original and impaired image. The NSD depends on two parameters, one to define the region for pixel similarity correlation (d) and one to define the similarity threshold (m). The parameters m and d were set to the same values as in the experiments in [26], i.e., m=5, d=3, border extension is done by repeating the last border pixel. The NSD is an impairment metric, a high metric score reflects a low quality, which gives a score in the range[0:1]. Fig. 5illustrates the performance of the NSD metric on samples from the IVC-SelectEncrypt database.Local Entropy (LE): The local entropy metric was introduced in [27] (LE), it is a no reference metric operating only on an impaired image. The LE metric uses the average of normalized localized entropy scores, on 8×8 blocks, as image quality predictor. The LE is an impairment metric, a high metric score reflects a low quality, which gives a score in the range[0:1]. Fig. 6illustrates the performance of the LE metric on samples from the IVC-SelectEncrypt database.Local Feature Based Visual Security (LFBVS): The local feature based visual security metric (LFBVS) was introduced in [28] and utilizes localized edge and luminance features which are combined and weighted according to error magnitude, i.e., error pooling. The LFBVS is an impairment metric, a high metric score reflects a low quality, which gives a score in the range[0:1]. Fig. 7illustrates the performance of the LFBVS metric on the silent sequence when encryption according to [24] is applied in comparison to white noise.All the given image metrics, with the exception of the local entropy metric (LE), are full reference metrics, meaning they utilize information from the original and comparison (encrypted) image to calculate an assessment of the visual similarity. The local entropy metric by Sun et al. is a no reference metric, i.e., it utilizes only the impaired image to judge the resulting quality. By measuring entropy, LE can also be interpreted to assess the encrypted image compared to random noise (which exhibits maximal LE). Since all of the given security metrics are proposed to be general we will not differentiate between full- and non-reference metrics in the following but compare them solely on the task they are supposed to solve.From the description of the various security metrics it can be seen that a wide range of approaches exist, from metrics targeting signal properties, e.g., PSNR which targets noise, to LE which targets local entropy, metrics which use higher level information, e.g., NSD or ESS which use a form of object detection (mostly based on edges), to metrics which use information about the HVS to improve their performance, e.g., SSIM or LFBS which use simulation of the fovea centralis and error pooling respectively. However, for every security metric the accompanying figure demonstrates an obvious fault in the performance of the given metric. Such examples can be found for every metric of course, the question we will try to answer in the following sections is whether the demonstrated fault is singular or systemic.In order to gauge the effectiveness of a dedicated security metric it is useful to compare them to regular metrics. To facilitate a fair comparison, three recent metrics, in addition to PSNR and SSIM, are chosen and included in the evaluation. The local edge gradient image metric (LEG) [29] shows a good correlation with human judgement and is reasonably fast to compute such that it can be used even under time constraints. The visual information fidelity (VIF) [30] and CPA1 [31] outperform the SSIM and LEG in regard to correlation with human judgement but are a lot slower to compute [29]. A second reason to include those metrics is to gauge whether they can be used as security metrics. The LEG and VIF are quality metrics with a score in the range[0,1], and the CPA1 is an impairment metric with a score in[0,∞].In this section we outline (1) our evaluation methodology, (2) the reason to use this methodology, and (3) the application scenario(s) which can be assessed by employing a certain methodology. A discussion of the desired outcome from these tests for security metrics is also provided. This section is the guideline of how security metrics and image metrics are evaluated for the use as security metrics in Section 4.Selective encryption methods, in a majority of cases, aim at format-compliant encryption, i.e., encryption in such a way that the media can be decoded by a standards compliant decoder without error. Frequently, security metrics are applied on a direct decoding of the encrypted bitstream. This can have adverse effects since encryption introduces noise which can hide plain text data and consequently a security metric might judge that an encryption method is more secure then it actually is. There are a number of options how a security metric can be applied, as illustrated in Fig. 8. All security metrics under evaluation are applied on a direct decoding of the encrypted bitstream (which we will denote as the encrypted domain) by the authors in the corresponding original papers. Other options would be to attack the encryption method in a way which does not break it but reduces the obfuscation of the plain text data in the encrypted domain (denoted extracted in the figure). Such attacks usually utilize knowledge about the bitstream rather than the encryption method (other than location). Typical attacks would be error concealment and replacement attacks against selective encryption schemes [32]. In general, such attacks replace the encrypted content with bitstream elements that are statistically known to introduce less noise than the random elements produced by encryption. Another possibility would be to utilize post processing to further help the metric detect residual information (denoted processed in the figure).In the evaluation we only handle the difference between security metrics applied directly in the encrypted domain versus application in the extracted domain. The post processing step is only provided to better highlight the remaining information in an image. It cannot be directly used as an application domain since the post processing step is either specific to the encryption, in which case it should be included in the attack, or specific to the metric, in which case it should be included in the security metric. Post processing, in general, can influence different metrics in various ways, an example of this is given in Fig. 9where post processing increases ESS and, at the same time, decreases the SSIM. This means that it is never actually possible to determine an optimal postprocessing method which would be required in a sensible assessment.In order to test whether a security metric can operate in the encrypted domain a number of well known video sequences have been encrypted for three target qualities, utilizing EZBC encryption methods described in [24]. To generate the different target qualities the selective encryption was applied to either all I-frames (low quality), low frequency bands of all frames (medium quality), and high frequency bands of all frames (high quality). Fig. 10illustrates the quality targets of the encryption process. The targets where chosen to contain high, medium and low residual information. Under the assumption that a security metric can operate in the encrypted domain it should be able to reliably order the encrypted frames of each sequence for every sequence from highest to lowest quality.We generate two sets of ground truth, one for the high-medium and one for the medium-low quality comparison, containing ordered (based on quality) tuples for each frame. For a sequence S containing framess1,…,sNSand high (SH), medium (SM) and low (SL) quality versions we generate two sets of ordered (by quality) tuplesDHM(S)={(sH1,sM1),…,(sHNS,sMNS)},and likewise for DML.Then a tested metric should also generate two sets with ordered tuples based on the estimated quality provided by the metricM(o,c)↦R:QHM(S,M)={q(M,s1,sH1,sM1),…,q(M,sNS,sHNS,sMNS)}, whereq(M,o,c1,c2)={(c1,c2)ifM(o,c1)≥M(o,c2),(c2,c1)otherwise,and likewise forQML(S,M).Based on these four sets the ability of a metric to order in a given domain can be estimated by(1)OM(S)=12|QHM(S,M)∩DHM(S)||DHM(S)|+12|QML(S,M)∩DML(S)||DML(S)|.values of 1 (100% correct ordering) or 0 (0% correct orderings, i.e., 100% correct reverse ordering) show a high ability of the metric to order correctly in the given domain. The difference between 1 and 0 is that image metrics can either measure similarity of images, i.e., quality metrics, resulting in a normal ordering or the difference between images, i.e., impairment metrics, resulting in a reverse ordering. Results around 0.5 are akin to random decisions and reflect the inability of the tested metric to perform in this domain.Furthermore, since the low quality range chosen is in (or at least close to) the domain of content confidentiality, i.e., the rightmost column in Fig. 10 does not exhibit intelligible visual content, this setting also serves as an indication whether an image metric might be useful for content confidentiality. While a good performance on this evaluation does not necessarily mean a image metric is qualified for content confidentiality, a low performance is a strong indicator that the metric is unfit for this task. Based on the information which parts of the data have been encrypted and the entirely evident differences in visual appearance, ground truth is out of question here.Note also that this is a proof by contradiction. That is, if a metric claims to be able to generally work in the encrypted domain and we can demonstrate that there are cases where it does not, then this claim has been falsified.Besides the encryption application scenarios where a certain quality is required (sufficient and transparent encryption), further examples for the importance of the quality notion are watermarking where the resulting quality should not be below a certain threshold, and of course, lossy compression. However, the notion of quality in this cases is not as straightforward as it seems. On the one hand we use the term quality in the context of the human visual system (HVS), i.e., how a person consuming the content would judge the quality. On the other hand, the term quality can refer to the score returned by a (security) metric which is tied to the quality in the HVS sense. This relation is not exact and it is not inherently clear how to choose a metric which correlates to the HVS quality which is targeted, although in practice Algorithm 1 is usually applied.Algorithm 1Method for finding a target metric score based on a target HVS quality.1: Chose a source image.2: Alter the image until it fits the perceived target quality.3: Apply the security metric on the altered and original image, the resulting metric score is the target quality.While this results in a target quality which can be used, we know nothing about how well this score actually reflects the human judgement, since it is well known that the correlation between human judgement and image metrics is not perfect. In other words, how confident can we be in the choice of image metric score in relation to the perceived quality?In order to evaluate this, well known databases which contain impaired and encrypted images and the perceived quality, in the form of mean opinion scores (MOS), will be used. The databases contain a set of points p representing impaired images with associated values pvfor metric value and pdfor MOS value, ordered from lowest to highest quality. Based on a target MOS quality score D two values can be calculated, Fig. 11illustrates this.Zero false negative: Vmin(D) refers to the metric value for which the following holds:pd>D⇒pv>Vmin(D). That is if the metric score is below Vmin(D) we are sure that the perceived quality is below the MOS quality score (D).Zero false positives: Vmax(D) refers to the metric value for which the following holds:pv>Vmax(D)⇒pd>D.That is if the metric score is above Vmax(D) we are sure that the perceived quality is above the MOS quality score (D).This also means that if a target metric quality score pvtis obtained as given by Algorithm 1 we are assured thatVmin(D)≥pvt≥Vmax(D).Thus we can define the confidenceCDfor a metric score based on a given perceived quality D asCD≔|Vmax(D)−Vmin(D)|. A confidence score over the full perceived quality range can be given asC=1#S∑D∈SCD,where S is the set of distinct MOS samples from the database.Also note that we can interpretCas the average overCD,μD∈S(CD), and consequently we can also calculate the standard deviation,σD∈S(CD). The reason for calculating σ is to estimate how stable the confidence range is over the whole range of visual quality. This has to be taken into account since it is well known that image metrics exhibit different correlation to human judgement depending on the quality range, e.g., [13].For security metrics, and image metrics in general, the lowerμ(CD)andσ(CD)the better Algorithm 1 can be used to estimate a target image quality metric score.Furthermore, since the signal is reduced to statistical components it is also of interest which shape the signal takes in conjunction withμ(CD)andσ(CD). The shape, together with the monotonicity (see Section 3.3), can be used to indicate a possible application scenario for a security metric, essentially whether the security metric can be used for all quality ranges or only on high/low quality applications.By shape of the signal we mean the distribution of outliers, where we define outlier based on the z score11NIST/SEMATECH e-Handbook of Statistical Methods, http://www.itl.nist.gov/div898/handbook/, October 2013.of a data point D aszD=CD−μ(CD)σ(CD).we will define high outliers as outliers withzD<−1and likewise low outliers as outliers withzD>1, indicating a higher and lower confidence respectively. Based on the distribution of high and low outliers we can specify the shape of the signal as follows.•A signal is stable if there are no outliers. That is, if−1≥zD≥1holds for allD∈S.A signal is biased if it consist of two clearly separable parts, where one exhibits a good confidence score (CDsmall) and the other a bad confidence score (CDlarge). We say the signal is biased towards the quality where the good confidence score is located, i.e., where the metric is performing well.That is, A signal is biased if there exists a Dtsuch thatzD<−1⇒D<DtandzD>1⇒D>DtorzD<−1⇒D>DtandzD>1⇒D<Dt. If a low D indicates a high quality we specify the shape to be biased towards high quality ifzD<−1⇒D<Dtor biased towards low quality ifzD>1⇒D<Dt. If a low D indicates low quality the definition is switched accordingly.A signal which is neither stable nor biased is considered unstable.What is required from image metrics in general is monotonicity with regard to human observations. That is, if an image metric decides that image A is of better quality than image B a human observer should also prefer image A over image B. This is akin to correlation but since the human visual system is not a linear system regular linear correlation is meaningless. Thus in order to ascertain the correlation of an image metric and human observations the notion of monotonicity is utilized. Rank order correlation, which essentially judges the monotonicity of the signals, is most often used, usually in the form of Spearman's rank order coefficient (SROC) [33] or Kendall Tau (τ) [34].Hofbauer and Uhl [13] pointed out that the correlation of an image metric over the full quality range does not imply that a high correlation is achieved for the low quality range. This is especially important for security metrics since certain application scenarios specifically target the low quality range of images, e.g., sufficient encryption. We cannot confine the evaluation to the low quality range since there are also applications for higher quality, i.e., transparent encryption. Also note that this is a dual property to the confidence in the sense that for the confidence we evaluate the relation of choosing a MOS value and evaluating the range of metric scores which can potentially fall onto this MOS value. Monotonicity is evaluated on specific sets of impairment and looks at how well an increase in metrics score reflects an increase in the MOS.To properly evaluate security metrics for all encryption scenarios we will evaluate them using a high quality, a low quality and a full quality range dataset. The reason to also include the high quality range is to be inclusive in terms of possible application scenarios. For example the upgrade to high definition quality from PAL/NTSC quality is just as valid in terms of application scenarios as from hand held quality to PAL/NTSC quality. As basis for the evaluation we will use well known databases which contain mean opinion score of human judgement over different impairments. The SROC will be used for evaluation purpose, as is current best practice for metric evaluation.From security metrics we would expect a high correlation with human judgement for the low quality range. While the low quality range is often the target of encryption some transparent encryption schemes could target a higher quality, consequently, a good correlation with human judgement on the high quality range is also desirable.

@&#CONCLUSIONS@&#
