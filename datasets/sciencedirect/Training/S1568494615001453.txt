@&#MAIN-TITLE@&#
DNA computer based algorithm for recyclable waste paper segregation

@&#HIGHLIGHTS@&#
DNA computer based algorithm is developed and evaluated for recyclable waste paper segregation.The concepts of replication and massive parallelism operations are used.The matching stage consists of Copy, Extract, Detect and Merge or Union operations.Gel electrophoresis operation is used to identify the candidate paper object grade.Success rate are 92% for WP, 90% for ONP and 93% for OCC with template size 5×5.

@&#KEYPHRASES@&#
Waste paper sorting,Paper grade,Template matching,DNA computing,

@&#ABSTRACT@&#
This article explores the application of DNA computing in recyclable waste paper sorting. The primary challenge in paper recycling is to obtain raw materials with the highest purity. In recycling, waste papers are segregated according to their various grades, and these are subjected to different recycling processes. Highly sorted paper streams facilitate high quality end products, while saving on processing chemicals and energy. In the industry, different sensors are used in paper sorting systems, namely, ultrasonic, lignin, gloss, stiffness, infra-red, mid-infra red, and color sensors. Different mechanical and optical paper sorting systems have been developed based on the different sensors. However, due to inadequate throughput and some major drawbacks related to mechanical paper sorting systems, the popularity of optical paper sorting systems has increased. The automated paper sorting systems offer significant advantages over the manual systems in terms of human fatigue, throughput, speed, and accuracy. This research has two objectives: (1) to use a web camera as an image sensor for the vision system in lieu of different sensors; and (2) to develop a new DNA computing algorithm based on the theme of template matching techniques for segregating recyclable waste papers according to paper grades. Using the concepts of replication and massive parallelism operations, the DNA computing algorithm can efficiently reduce the computational time of the template matching method. This is the main strength of the DNA computing algorithm in actual inspections. The algorithm is implemented by using a silicon-based computer to verify the success rate in paper grade identification.

@&#INTRODUCTION@&#
Although the technology for it is still underdeveloped, DNA computing presents a completely novel paradigm. Other bioinspired methods, such as genetic algorithm, artificial neural network and ant colony, are essentially different from DNA computing, since the concept of DNA computing is based on the DNA computer; nevertheless, the concept of bio-inspired methods is used in solving real world problems using a silicon computer [1–3]. Adleman's successful lab experiment for the Hamiltonian Path Problem (HPP) explored the new field of DNA computing [1,3] and found that molecular computers have many attractive properties. While modern supercomputers perform 1012 operations per second, Adleman estimates that the realistic rate for molecular manipulations is 1020 operations per second. Similarly, its energy consumption and memory capacity are quite impressive. Whereas a supercomputer needs one joule for 109 operations, the same energy is sufficient to perform 2×1019 ligation operations. When storing a videotape, each bit requires 1012 cubic nanometers of storage; DNA stores information with a density of one bit per cubic nanometer [4]. Although the execution time for DNA molecular reactions are slower than conventional computers, the overall performance of DNA computers is better that those of conventional electronic computers. In line with this, numerous studies on the shortest part problems, cryptography [5–7], scheduling [8–14], clustering [15,16], encryption [17–19], forecasting [20], and DNA algorithm employment in information security technology [21] have been made in recent years. Nonetheless, due to the limitation in the numerical values that DNA computing represents, extant studies so far have only considered small- or medium-sized scheduling problems to illustrate their proposed solutions. In order to overcome this problem, some researchers proposed a numeric number representation for logic and arithmetic operations using DNA strands [22,23]. Recently, Boukerche et al. employed DNA in an intrusion detection model for computer and telecommunication systems by [24]; it has also been used in n signal and image processing applications [25–27]. The application of DNA certification is the most widely used and developed [21] among all DNA computing models proposed in this field.In the current paper, an algorithm for recyclable waste paper sorting is proposed using DNA molecular operations which is the extension of these [28,29] in terms theoretical and experimental point of views. An efficient DNA algorithm is designed based on the template matching for recyclable waste paper grade identification. Using the replication and massive parallelism operations of DNA molecules, the DNA computing algorithm can efficiently reduce the computational time of the template matching method [29], which is the main obstacle in using the template matching method in actual inspections. The remainder of this paper is organized into sections. Section 2 briefly describes the necessity of the waste paper sorting system. Section 3 briefly describes the abstract model for DNA computing and the rationale behind the development of the DNA computing algorithm for recyclable waste paper sorting. Section 4 describes the proposed DNA computing algorithm for recyclable waste paper sorting. Section 5 discusses the experimental results, relative comparison and discussion. Finally, Section 6 draws the conclusions.The primary challenge in paper recycling is to obtain raw materials with the highest purity. In recycling, waste papers are segregated according to their various grades, because these are subjected to different recycling processes. Efficiently sorted paper streams will result in a high quality end product, saving processing chemicals and energy. The grade refers to the quality of paper or pulp based on its weight, color, usage, raw material, surface treatment, finish, or a combination of these factors [30]. The waste paper sorting systems are classified into manual and automated systems, with the latter offering significant advantages over the former in terms of human fatigue, throughput, speed, and accuracy. Automated paper sorting systems are classified further into mechanical and optical systems. From 1932 to 2009, different mechanical [31–37] and optical [38–43] paper sorting methods have been developed to address the demand for paper sorting. However, mechanical paper sorting cannot achieve commercially viable throughputs and accuracy. The greatest advantages of optical paper sorting systems include consistent and reliable production efficiency with a relatively high hit rate and purity as well as low operational cost, which are due to fewer manual workers on the production line.Faibish et al. [31] proposed an automated paper recycling system where ultrasound is used to separate different grades of papers. However, the system has been found to be too slow (80ms/sub-frame) for industrial applications due to the contact manipulation and sensing involved in the process. Meanwhile, Ramasubramanian et al. [32] developed lignin sensors that work well in separating newsprint samples from others. Such lignin sensors are influenced by the sensor distance from the sample and color.Hottenstein et al. [33] proposed a sensor-based sorting approach, in which a brightness sensor (with a reflected light intensity of 457nm) is used to sort papers into three primary categories, namely, white papers containing optical brighteners, white papers without optical brighteners, and other types of papers. Venditti et al. [34] developed a stiffness sensor that is used to group recovered paper into paperboard and others; however, it failed to distinguish a stack of newsprint from a single paperboard. Sandberg [35] patented a sorting device to separate paper objects from contaminants. The sensor-based sorting methods proposed by Bialski et al. [36] and Grubbs et al. [37] are not successful mainly due to the absence of a reliable sensing systems to distinguish between grades. In 2002, Khalfan et al. [38] introduced an optical paper sorting method using diffuse reflectance to identify whether a sheet of paper is white or non-white. Their proposed paper sorting system segregated papers into white and ground wood paper according to the amount of its lignin content. Eixelberger et al. [39] proposed an optical paper sorting method to segregate waste paper according to the radiation reflected from the surface of the paper. Bruner et al. [40] likewise proposed an optical paper sorting method to separate waste papers into bright white paper and others based on the amount the fluorescence present on the surface of paper objects. Doak et al. [41] also an optical paper sorting method that separates different grades of paper based on at least one of the following characteristics: color, glossiness and the presence of printed matter. Heinz [42] developed a paper sorting method using visible light, ultraviolet light, X-rays and/or infrared light, which illuminates the paper for sorting. However, they utilized mechanical pickers that caused the system to operate at relatively slower speeds.Although this represents great development in the large-volume, automated sorting technology, the implementations of the methods abovementioned are complex, expensive, and sometimes offer limited reliability. These systems segregate only two types of papers at a time; moreover, no image processing or intelligent techniques are used to identify the characteristics of the paper objects.Rahman et al. proposed six electronic image-based waste paper sorting techniques [43–48] to overcome the drawbacks of the existing optical methods. The first technique [43] focused on four points along the periphery of a paper object. The features surrounding those four points are then extracted. Given that the method does not consider the textural features of the entire paper object, it may obtain inaccurate information regarding paper grade. In addition, this method requires a significant amount of time to preprocess the paper object image, which results in slow system operation. The other four methods discussed by Rahman include template matching [44], co-occurrence features [45], case base reasoning (CBR) approach [46] and window features [47], all of which are efficient in identifying paper grade rate. However, actual applications of all the above mentioned methods are slowed down by the significant computing time they require. Similarly, the final method mentioned, which is the dominant-color-based method [48], is also slow due to the preprocessing and the required time to conduct an analysis of the entire paper object image for feature extraction. Moreover, the template size is large; for example, this method considers 24 features. Finally, all of the methods utilize a manual enrollment system.Therefore, the main goal of this study is to develop a smart vision sensing system that can segregate the different grades of paper using DNA computing algorithm. In this proposed system, the RGB color components of the entire paper object are considered to synthesize single-stranded DNA molecules or oligonucleotides. The algorithm provides quick and accurate results, because it filters unexpected color regions of the paper object during the feature extraction process.This section consists of two subsections, namely in the first Section 3.1 briefly describes the model for DNA computing and next Section 3.2 describes the rationale behind the development of the DNA computing algorithm for recyclable waste paper sorting.All the genetic information in cellular organisms is stored in the DNA, which consists of polymer chains, commonly referred to as DNA strands; these strands contain four simple nucleic acid units, called deoxyribonucleotides or simply nucleotides [2] (Fig. 1). Each nucleotide is composed of three parts, namely, a base module, a sugar (deoxyribose in DNA), and a phosphate group. The four bases are adenine (A), thymine (T), guanine (G) and cytosine (C). Each of these forms a specific complementary base pairing called the Watson–Crick complementarity [2,49], where A bonds only with T, and C bonds only with G. The set of DNA strands is a key component of DNA computing [23]. In summary, a single-strand DNA is defined as a string of four different base nucleotides. Two single strands form a double strand if and only if the single strands complement each other [23].Many theoretical and practical computational models of DNA computing have been proposed [3,50–57]. In this paper, most of the DNA manipulations are integrated from different previous models, which are widely used in DNA computing.(1)Denaturation: Given a test tube T, Denaturation (T) dissociates each double strand in T into two single strands [23,57].Annealing: Given a test tube T, Annealing (T) produces all feasible double strands from single strands in T[23,57]; the produced double strands are still stored in T after Annealing.Synthesis: creating single-strand DNA molecules, oligonucleotides or oligos [2].Extraction (T, S, T+, T−): With the test tube represented as T and the DNA strand as s, the operation is performed to extract all strands containing s from the original tube T to yield a new tube T+. The remaining strands in tube T are poured into another tube T−. The extraction operation is implemented as follows [3]: OligosS¯, whose sequence is the reverse complement of s, are prepared with a biotin residue extending from each oligo. Then, a bead matrix whose surface is coated with covalently attached avidin protein molecules (which bind biotin very strongly) is used as a solid support, to which the biotinylatedS¯oligos are attached. Tube T is first heated to ensure that all of the DNA strands in it are single stranded. Next, the strands that contain s are removed by passing the contents of T through a separation column containing the bead matrix and immobilizedS¯oligos described above. The column is then washed to transfer into a new tube T− all of the strands in T that do not contain s. This leaves only those strands that contain s on the column, which can then be recovered from the separation column into a new tube T+[2,3,56] via Denaturation.Copy (T1, T2). Given a test tube T1, Copy (T1, T2) produces a test tube T2 with the same contents as T1[23,57].Copy (T, T1, T2,…, Tn). In parallel, this operation produces copies T1, T2,…, Tnof tube T[56,58].Merge (T1, T2). Given two test tubes T1, T2. Through the Merge operation (T1, T2) the union T1∪T2 is stored in T1[23,57].Union (T0, T1, T2,…, Tn). Union operation is performed by mixing the DNA strands from n tubes, T1,…, and Tnand putting them into one tube T0. This process empties tubes T1, T2,…, Tn[56,58].Separation (T, s, k, Ton, Toff). This operation separates strands into Ton and Toff. If the strands in tube T contain s, which represents nucleotides of length l, starting from position k, they are poured into Ton; otherwise, they are poured into Toff[56,59].Separation (T1, X, T2). Given a test tube T1 and a set of strings X, Separation (T1, X, T2) removes all single strands containing a string in X from T1, and produces a test tube T2 with the removed strands [23,57].Selection (T1, L, T2). Given a test tube T1 and an integer L, Selection (T1, L, T2) removes all strands with length L from T1, and produces a test tube T2 with the removed strands [23,57]. The length of a strand is the number of symbols in the strand.Cleavage (T, xy) [23,57]: Given a test tube T and a string of two symbols xy, Cleavage (T, xy) cuts each double strand containingxyxy¯in T into two double strands as follows:p0xyq0p1xy¯q1⇒p0xp1x¯,yq0y¯q1.Insert or delete short subsequences [2].Polymerase chain reaction, PCR, amplification multiplies DNA molecules [2].Sorting or Gel electrophoresis [2].Reading T. This operation describes every DNA strand in tube T[56,60].Removing T. A test tube is denoted as T. The Remove operation discards all strands in tube T and empties tube T[56,60].Detecting T. Given a test tube T, Detection is performed to check whether tube T contains at least one DNA strand. It returns Y if it contains DNA strands; otherwise, it returns N[23,56,57,60].DNA computing is a rapidly growing interdisciplinary research field. It provides high speed computation due to massive parallelism, energy efficiency due to its ultra-low power consumption, and economical information storage in computational processes with the use of DNA molecules [1,2,61]. Hence, a novel DNA computing algorithm is developed for future DNA computers using DNA molecular operations. In the present study, DNA molecular operations are simulated using silicon-based computers, a task which involves a huge amount of computational time.A DNA strand is a string composed of four different base nucleotides. The template or primer [2] consists of start and end DNA strand subsequences that are used to identify the sequence. The basic strategy used in DNA computing is almost always the same: first, a large number of potential solutions to a problem is assembled, with each solution encoded using a DNA strand; second, non-solutions are filtered out using DNA manipulation techniques; and finally, the method checks for the existence of a solution [2].Fig. 2illustrates the basic block diagram of the recyclable waste paper grade identification system employing DNA computing. The proposed system operates in two phases, namely, enrollment and identification, which have some common components. The enrollment phase consists of image acquisition, preprocessing, feature extraction, single-strand DNA molecules synthesis for template images, and creation of the reference database storing into test tube. During the enrollment phase, the feature extraction process generates the RGB string for template images, while the sequence of test tube provides the paper grade ID. The identification phase consists of image acquisition, preprocessing, feature extraction, matching, and decision. The grade of the candidate paper object is identified in this phase. In the proposed system, 320×240 RGB images are taken from an inspection zone on the conveyor belt using a commercially available webcam. After the necessary preprocessing, the search image is divided into N-cells while the RGB strings are generated for the N-cell images. The single-strand DNA molecules are synthesized using RGB strings from the N-cell images. The matching process is implemented in the combination of the Copy, Extract, Detect, and Merge DNA operations. The decision regarding paper grade is then made based on the outcome of the Gel electrophoresis operation.The process of acquiring the initial raw data from a particular sensing device (scanner, camera, etc.) is called image acquisition [62]. This is the basis of all subsequent computations given that the quality of the raw data can strongly influence the performance of the system as a whole. In the SVS system, the images are captured from the conveyor belt using a Logitech QuickCam Pro 4000 Web Camera. The image acquisition setup consists of several steps, which are discussed below.The non-reflective, oil-free conveyor belt is considered for good quality images. The maximum speed of the conveyor belt is 7.112cm/s (14ft/min) with 60Hz. The width of the conveyor belt is 18″ or 457.2mm.Two types of camera are widely used in real life applications, namely, an area camera and a line camera [63,64]. The appropriate camera selection is determined by the nature inspection task, the required accuracy and speed of the inspection. In this experiment, an area camera (Logitech QuickCam Pro 4000 Web Camera) is utilized for the following reasons: (i) line scan camera is recommended for long components, continues reel materials or cylindrical objects which can be rotated, namely, line scan cameras inspect a fast-moving continuous production line of material such as fabrics or paper, often called a web as well as any defects can be precisely located on the web according to the time they passed the imaging line. On the other hand, single product units are inspected by area scan camera. Here the paper objects like single product unit arrive individually in the inspection zone which are captured using area scan camera [74,75]; (ii) setting up an area camera is easier than a line scan camera because triggering the former does not require detailed attention unlike in the case of a line scan camera, (iii) area cameras and frame grabbers are cheaper than line scan cameras [64], (iv) area scan cameras can image a defined area quickly, whereas a line scan camera must be moved over the area to produce a similar image, (v) greater flexibility can be had with area scan cameras, as a single image can be segmented into multiple regions-of-interest to look for specific objects rather than having to process the entire image [74,75]. In addition, an area camera, Logitech QuickCam Pro 4000 Web Camera is selected in lieu of a standard industrial camera because the proposed system is a prototype system; hence, cost-effective camera is considered as well as any time, low specification camera is easily replaced with high specification camera with maintained at least equal or high quality image.The specifications and features of the Logitech QuickCam Pro 4000 Web Camera are as follows: CCD optical sensor, color camera, a CCD image sensor lens construction that supports manual focus adjustment, and 4 pin USB Type A Interface for USB expansion and connectivity with a computer interface [65]. The webcam settings for brightness, contrast, and saturation are adjusted to 50, 50 and 100% of their scales, respectively. The webcam is installed 60cm above the conveyor belt, and the focal length is adjusted using the variable focal length of the webcam.The white balance setting is required to ensure that uniform RGB distribution is maintained for every experiment, because it is a key factor in obtaining high quality images. The performance of the vision system is influenced by the lighting arrangement, as observed in this experiment. To calibrate and adjust the lighting, three different lighting techniques, namely, front lighting-directional bright field illumination, front lighting-directional dark field illumination, and diffused front lighting [62], are considered in this study (Fig. 3). In both diffused front lighting (Fig. 4(a)) and front lighting-directional-bright field illumination (Fig. 4(b) and (c)), the images from the inspection zone show some problems with the reflection due to the oily reflective conveyor belt, such that the paper object on the conveyor belt seems to disappear and the system gives false signal for the presence of object on the conveyor belt as shown in Fig. 4(a) and (b). Moreover, the reflection from the paper object's surface is not uniform. It is important that the paper objects’ texture is analyzed. Even a single paper object with a uniform color throughout the body showed different color combinations in the histogram analysis of the segmented portions of the paper image, which is due to the non-uniform lighting. In front lighting-directional-dark field illumination, the image from the inspection zone is distinctive enough for texture analysis, and the paper object surface is properly illuminated as illustrated in Fig. 4(d). Moreover, the front lighting-directional-dark field illumination technique is widely used in analyzing surface scratches or texture [63,66]. Thus, this particular illumination technique is adopted for this experiment.The FOV is determined by four parameters, namely, (1) the maximum size of the object under inspection, (2) the maximum spaces for the object in different orientation and translation, (3) margin as an offset to the object size, and (4) the aspect ratio of the camera sensor [64].Fig. 5shows the FOV along with other parameters. The maximum paper object size is displayed using label 1, while label 2 represents the paper object with a different orientation. As can be seen, the paper object can exceed the maximum variation as shown with the labeled-2 due to its positioning. The summation of the maximum paper object size and the maximum positioning tolerance is represented by label 3. The additional need for a margin between the paper object and the image is represented by label 4. For the image processing, it is essential to maintain a good space between the image edges and the paper object. Consequently, it is convenient to give a specific allowance in positioning for the purpose of camera installation and maintenance [64].Although the desired FOV is represented by label 4, the calculated FOV is adapted using the sensor resolution of the camera. The aspect ratio is 4:3 for most area cameras. As a result, the FOV is calculated for every direction using Eq. (1) as follows:(1)FOV=(ps+tp+m)×ar,whereps: maximum paper object size,tp: allowance in positioning of the paper object,m: margin between the paper object and the image edges, andar: adaption to the aspect ratio of the camera sensor (the value of ar depends on the direction, that is, ar=1 for vertical direction and ar=4/3 for horizontal direction).In calculating the FOV for the SVS system, the following values are specified manually over the conveyor belt using mm scale and visualized image on the screen:ps=335mm,tp=2mm,m=2mm, andar=4:3 for horizontal direction.According to Eq. (1), the vertical FOV for this SVS system is calculated as follows:FOVver=335mm+2mm+2mm=339mm.Given that the aspect ratio of the QuickCam Pro 4000 Web Camera sensor is 4:3, the FOV in the horizontal direction is adapted accordingly as follows:FOVhor=339mm⋅43=452mm.In this experiment, the vertical and horizontal FOV are 339 and 452mm, respectively. Hence, the FOV is 452mm×339mm.In the FOV, the camera sensor resolution and spatial resolution are related to one another. Camera sensor resolution is defined as the number of columns and rows that a camera provides, which is specified by its internal sensor [64]. The measurement unit of the camera sensor resolution is the pixel. The direct mapping of real world objects to the image sensor, done by the lens, is defined as the spatial resolution of the camera [64], which is measured in mm/pixel. Meanwhile, the spatial resolution depends on the camera sensor and the FOV. The ratio of the distance between the object and camera to the focal length of the camera will provide the magnification ratio that indirectly determines the resolution. Sometimes, the resulting spatial resolution is not equal in its horizontal and vertical directions because some area cameras do not provide square pixels. The camera sensor and spatial resolutions are evaluated using Eqs. (2)–(5) as follows(2)Rs=FOVRc(3)Rc=FOVRs(4)Rs=SfNf(5)Rc=FOVRs=FOV⋅NfSfwhere, Rcrefers to the camera resolution in pixels, Rsrefers to the spatial resolution in mm/pixels, FOV refers to the field of view in mm, Sfrefers to the size of the smallest feature in mm, and Nfrefers to the number of pixels to map the smallest feature.Here, the measurement of the vertical FOV or the height of the FOV is 339mm, and the measurement of the horizontal FOV or the width of the FOV is 452mm.In calculation, FOVver=339mm, and FOVhor=(4/3)×339mm=452mm.The size of the captured image or the camera resolution (Rc) is 320×240 pixels.Spatial resolution,Rs-hor=FOVhor/Rc-hor=452mm/320pixels=1.4125mm/pixelSpatial resolution,Rs-ver=FOVver/Rc-ver=339mm/240pixels=1.4125mm/pixelIf the size of the smallest feature, Sfis defined as 4mm, then we have the following:Nf=SfRs=4mm1.4125mm/pixel≈3pixels.Thus, the spatial resolution Rsis 1.4125mm/pixel, and the number of pixels required to map the smallest feature is 3 pixels.The real-time scanning process produces two types of signals, namely, the presence of object (PObj) and the absence of object (AObj). The system always performs scanning operations to detect the presence of an object. The system captures the images from the inspection zone based on these two signals. If the AObj signal is detected after the signal PObj, then the system captures the image of the paper object from the inspection zone. This technique distinguishes individual paper objects from a series of paper objects. The detailed process is shown in Fig. 6and procedure describe below.Procedure for real time paper object image acquisition processStep 1.Initialize PObj and AObj with 0 for FALSEStep 2.IF scanning line detect paper object THENStep 3.PObj set to 1 for TRUEStep 4.IF paper object passed the scanning line THENStep 5.Set AObj to 1 for TRUEStep 6.ELSEStep 7.Continue from Step 4 until paper object pass the scanning lineStep 8.ENDIFStep 9.IF PObj=TRUE AND AObj=TRUE THENStep10.Capture paper object image from inspection zoneStep 11.Set PObj=0 for FALSE and PObj=0 for FALSEStep 12.ENDIFStep 13.ELSEStep 14.Continue from Step 2 until paper object is comingStep 15.ENDIFStep 16.Repeat Step 2 to Step 15 until the system is runningStep 17.ENDThe first step in the preprocessing block is to take the image from the inspection zone after trimming the unnecessary boundary portion of the image. Thereafter, the background noise is eliminated from the image through a combination of threshold and morphological operation erosion [63] with 3×3 minimum convolution filter.Here, the gray/red/green/blue level histogram corresponds to an image composed of light objects on a dark background, such that the object and background pixels have gray levels grouped into two dominant modes. One easy way to extract the objects from the background is to select a threshold (T) that separates these modes. Then, any point (x, y) on which the gray/red/green/blue level of point (x, y), f(x, y)>T is called an object point; otherwise, the point is called a background point. The entire process is called single thresholding [67].Thresholding is regarded as an operation that involves tests against a function T of the following form:T=T[x,y,p(x,y),f(x,y)],where f(x, y) is the gray level of point (x, y), and p(x, y) denotes a local property of this point, for example, the average gray level of a neighborhood centered on (x, y).A threshold image g(x, y) is defined as follows:(6)g(x,y)=f(x,y)iff(x,y)>T0iff(x,y)≤T.Thus, pixels labeled f(x, y) remain unchanged (or any other convenient intensity level) and correspond to objects, whereas pixels labeled 0 correspond to the background.Morphological operation erosion is a reduction operation, which is implemented with a 3×3 minimum convolution filter. This filter replaces the gray/red/green/blue level of a pixel with the lowest gray/red/green/blue level in the 3×3 neighborhood. A pixel in an image becomes black if any (required number) of its neighboring pixels are black or less than the threshold, T.The single threshold method is applied to eliminate background noise. In this case, the gray/red/green/blue level value of brightness threshold, T is 60. Any point (x, y) is converted into deep black if the gray level or red/green/blue level values of at least five neighbors are less than T.In Fig. 7, the images (a), (b) and (c) represent the original images of white paper (WP), old newsprint paper (ONP) and old corrugated cardboard (OCC) with background noise as well as the images (d), (e) and (f) represent preprocessed images of WP, ONP and OCC, respectively [48].The paper image consists of three components red, green and blue. Because the DNA strand consists of four different bases ‘A’, ‘G’, ‘C’ and ‘T’, the four components ‘R’ (red), ‘G’ (green), ‘B’ (blue) and ‘I’ (intensity) are considered for the paper images. “I’ is obtained from the average value of the red, green, and blue components of the original RGB image. The basic strategies followed in the construction of RGB string is that the first color component corresponds to the one with the highest value then the second, third and finally fourth color is the intensity component, “I”. The repetition of the color components depend on the values because the ranges of the color component values are different for various types of paper grades as shown in Table 1[43]. It is observed that the RGB component values are less than 63 for background and hence no repetition for less than 63 shown in the color repeat procedure.For template construction, the system generates the RGB string for template images after obtaining the value of the template width (TW) and template height (TH) for template image and information pertaining to the focal region of the preprocessed image.The search image is divided into N-cells (Fig. 8), and each cell size must be equal to the template image. The RGB strings for the N-cells are obtained using the RGBStringForSearchImage, RGBString, and ColorRepeat procedures. The RGBString for the N-cells is used to synthesize the single-strand DNA molecules for the N-cells. The unnecessary cells are filtered during the calculation of the RGB string.Procedure: RGBStringForSearchImageProcedure: RGBStringProcedure: ColorRepeat (ColorValue as Integer)The ColorRepeat procedure takes the color values of Red, Green, Blue, along with the intensity level value, and return the integer number for repeating the R, G, B, and I in the RGB string for each pixel value as follows:Single-strand molecules, called oligonucleotides (or simply, oligos), are chemically synthesized using a particular machine. The synthesizer is supplied with the four nucleotide bases A, G, C, and T in the solution, and nucleotides are added following the R, G, B, and I sequence in the RGB strings of the respective cells.Procedure: RGBString to single-stranded DNA molecules or oligonucleotidesThe DNA single-strand molecules are synthesized from the RGBString by using the following mapping rules:The matching between the template image and the candidate search image, as well as the decision about the paper grade identification are implemented through the DNA operations shown in Fig. 9. The matching stage consists of the Copy, Extract, Detect, and Merge or Union operations [29]. Finally, the Gel electrophoresis operation is applied to identify the grade of the candidate paper object.In parallel, the variables tm and t1 stand for the maximum number of templates and the starting value of the template, respectively. The value of t1 is 1. The variable cn stands for the maximum number of cells in the search image, and c1 stands for 1. For parallel computation, the copy operation produces cn copies Tt1c1, Tt1c2, …, Tt1cnof tube Tt1; Tt2c1, Tt2c2, …, Tt2cn of tube Tt2; … and Ttmc1, Ttmc2, …, Ttmcnof tube Ttm. The respective DNA operations are as follows:Copy(Tt1,Tt1c1,Tt1c2,…,Tt1cn)Copy(Tt2,Tt2c1,Tt2c2,…,Tt2cn)…Copy(Ttm,Ttmc1,Ttmc2,…,Ttmcn)Pseudocode: copy of template imageProcedure: copy of cell images of the search imageThe variable cn stands for the maximum number of cells in search image, and c1 stands for 1. The variable tm stands for the maximum number of templates, and t1 stands for the starting value of the template (the value of t1 is 1). For parallel computation, the copy operation produces tm copies Tc1t1, Tc1t2, …, Tc1tmof tube Tc1; Tc2t1, Tc2t2, …, Tc2tmof tube Tc2; … and Tcnt1, Tcnt2, …, Tcntmof tube Tcn. The DNA operations are as follows:Copy(Tc1,Tc1t1,Tc1t2,…,Tc1tm)Copy(Tc2,Tc2t1,Tc2t2,…,Tc2tm)…Copy(Tcn,Tcnt1,Tcnt2,…,Tcntm)Pseudocode: copy of N-cells of the search imageLet us assume that the Xt1, Xt2, …, Xtmsingle-strand DNA are contained in the Tt1, Tt2, … and Ttmtest tubes, respectively. After the Copy operation, the Tt1c1, Tt1c2, …, and Tt1cntest tubes contain the single-strand Xt1; the Tt2c1, Tt2c2, …, Tt2cn test tubes contain the single-strand Xt2; … and the Ttmc1, Ttmc2, …, and Ttmcntest tubes contain the single-strand Xtm. Through the Extract operation, we can then identify the number of existing template images in the search image. All search image cells are compared with each template image. Let us suppose that we obtain positive results from theTc1t1t1c1+,Tc2t1t1c2+, … and theTcnt1t1cn+test tubes after applying the Extract operation on the first template image. Then, we apply the Detect operation on theTc1t1t1c1+,Tc2t1t1c2+, … andTcnt1t1cn+test tubes to confirm the existence of template images in the search image cells. If the Detect operation responds “Yes,” then the contents of the test tube are poured into T1. Finally, T1 shall refer to the union of theTc1t1t1c1+,Tc2t1t1c2+, … andTcnt1t1cn+test tubes except when the Detect operation responds “No,” in which case the process is repeated for all the other template images (t2, t3, …, tm).Basically, the Union operations are as follows:Union(T1,Tc1t1t1c1+,Tc2t1t1c2+,…,Tcnt1t1cn+)Union(T2,Tc1t2t2c1+,Tc2t2t2c2+,…,Tcnt2t2cn+)…Union(Tm,Tc1tmtmc1+,Tc2tmtmc2+,…,Tcntmtmcn+).Pseudocode: extract and merge operationsGenerally, the DNA molecules are sorted via PCR and gel electrophoresis [2,26,27]. These sorting methods are also used in the current study because they have the merits of sorting operation in each tube in parallel. Prior to the gel electrophoresis operation, we apply the Detect operation on the T1, T2, … Tmtest tubes whether or not the Gel electrophoresis operation is essential. If the result of the Detect operation is “Yes” for more than one test tube, then we should apply the Gel electrophoresis operation using the DNA strands of the T1, T2, … Tmtest tubes to identify the maximum length of the DNA strand and confirm which test tube content is the maximum. Finally, the position of the test tube indicates the paper grade ID of the candidate paper object as follows:Detect(T1)Detect(T2)…Detect(Tm)Pseudocode: gel electrophoresis operationThe proposed system performance analysis is based on the success rate, average success rate, error rate, and failure rate. The success rate and average success rate are calculated based on the respective equations given as follows:(7)Success rate=Number of paper object correctly identifiedTotal number of paper object×100%(8)Average success rate=WPS+ONPS+OCCSWPT+ONPT+OCCT×100%where, WPS refers to the number of white paper (WP) objects correctly identified, ONPS: refers to the number of old newsprint paper (ONP) objects correctly identified, OCCS: refers to the number of old corrugated cardboard (OCC) objects correctly identified, WPT: refers to the total number of WP objects examined, ONPT: refers to the total number of ONP objects examined, and OCCT: refers to total number of OCC objects examined.Meanwhile, error rate and failure rate are calculated using the following equations:(9)Error rate=Number of paper object incorrectly identifiedTotal number of paper object×100%(10)Failure rate=Total incorrectly identified paper object+Total unknown paper objectTotal number of paper object×100%The correct identification rate or success rate is calculated based on the percentage of the number of paper objects classified into their respective paper grades, as shown in Eq. (7). False grading means that the wrong paper grade, such as WP, is identified as ONP. The error rate refers to the percentage of the false grading shown in Eq. (9), while failure rate refers to the percentage of the total number of non-identified paper objects or the percentage of the sum of the false grading and unknown paper objects, as shown in Eq. (10).The experimental results and discussion section is divided into three subsections, namely experimental results, performance analysis and discussion.

@&#CONCLUSIONS@&#
