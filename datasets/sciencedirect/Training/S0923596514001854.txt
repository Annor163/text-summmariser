@&#MAIN-TITLE@&#
Wavelet based volumetric medical image compression

@&#HIGHLIGHTS@&#
We investigated how to optimally compress volumetric medical images with JP3D.We extend JP3D with directional wavelets and intra-band prediction.Volumetric wavelets and entropy-coding improve the compression performance.Compression gains for medical images with directional wavelets are often minimal.We recommend further adoption of JP3D for volumetric medical image compression.

@&#KEYPHRASES@&#
JPEG 2000,Directional wavelets,JP3D,H.265/MPEG-H HEVC,JPEG-LS,Subjective evaluation,

@&#ABSTRACT@&#
The amount of image data generated each day in health care is ever increasing, especially in combination with the improved scanning resolutions and the importance of volumetric image data sets. Handling these images raises the requirement for efficient compression, archival and transmission techniques. Currently, JPEG 2000׳s core coding system, defined in Part 1, is the default choice for medical images as it is the DICOM-supported compression technique offering the best available performance for this type of data. Yet, JPEG 2000 provides many options that allow for further improving compression performance for which DICOM offers no guidelines. Moreover, over the last years, various studies seem to indicate that performance improvements in wavelet-based image coding are possible when employing directional transforms. In this paper, we thoroughly investigate techniques allowing for improving the performance of JPEG 2000 for volumetric medical image compression. For this purpose, we make use of a newly developed generic codec framework that supports JPEG 2000 with its volumetric extension (JP3D), various directional wavelet transforms as well as a generic intra-band prediction mode. A thorough objective investigation of the performance-complexity trade-offs offered by these techniques on medical data is carried out. Moreover, we provide a comparison of the presented techniques to H.265/MPEG-H HEVC, which is currently the most state-of-the-art video codec available. Additionally, we present results of a first time study on the subjective visual performance when using the aforementioned techniques. This enables us to provide a set of guidelines and settings on how to optimally compress medical volumetric images at an acceptable complexity level.

@&#INTRODUCTION@&#
Today, all modern hospitals heavily rely on digital medical imaging as an important and well-established part of the full chain of patient care handling. In fact, the completely digitized medical workflow, the improved imaging scanner technologies and the importance of volumetric image data sets have all raised the requirements for more efficient compression techniques. Currently image slice resolutions of 512×512 are considered to be the minimum standard. However, more recent scanning systems are able to output image slices with spatial resolutions of 1024×1024 or more at increasing pixel bit-depths [1]. Additionally, volumetric and time-lapse capable scanning technologies are both increasing the amount of output data even more. With thin-slice Computed Tomography (CT) scanning, the number of slices in volumetric datasets exploded as the inter-slice distance decreased from typically 5mm to 0.6mm over the years [2,3]. As such, efficient compression and improved transmission techniques for handling medical images are of utmost importance. Moreover, the ubiquity of Internet usage for e-Health platforms also mandates adequate support for features such as region-of-interest (ROI) coding and progressive quality and resolution scalability more than ever before.Yet, a large variety of image coding techniques exist, ranging from transform based techniques utilizing Discrete Cosine Transform (DCT) [4,5], Discrete Wavelet Transforms (DWT) [6] or Karhunen-Loève Transforms (KLT) [7–9] to prediction-based techniques, such as CALIC [10] or LOCO-I [11] (as used in JPEG-LS [12]). Some proposals investigated using video coding methodologies such as H.264/MPEG-4 AVC [13] or the very recent H.265/MPEG-H HEVC [14,15] to compress 3D and 4D medical image datasets [16–20]. All of the aforementioned techniques have their strengths and weaknesses. For the compression of volumetric medical datasets it is shown that 3D wavelet based codecs outperform the DCT-based solutions while providing required functionalities such as quality and resolution scalability, random access and ROI coding [21]. In contrast, prediction-based techniques (like CALIC [10] and LOCO-I [11]), typically deliver competitive (near-)lossless compression performance, at the cost of not supporting these functionality constraints.Most, if not all, medical informatics systems rely on the Digital Imaging and Communications in Medicine (DICOM) standard [22], which in turn relies on major ISO/IEC and ITU-T standards such as JPEG [5], JPEG-LS [12] and JPEG 2000 [6] for encoding of medical image datasets. From this set of adopted coding standards, the wavelet based JPEG 2000 is still the best-suited coding technique. It provides excellent rate-distortion performance for volumetric medical datasets [21,23–25], it supports lossy-to-lossless coding, resolution scalability, region of interest access at varying degrees of granularity, flexible file formats and resilience against transmission errors [6].The JPEG 2000 [26,27] standard is subdivided in multiple parts of which Part 1 [6] defines the core image coding technology. The other parts specify optional extensions that add extra functionality to JPEG 2000. As such, Part 2 [28] – providing the Multi-Component Transform (MCT) extension – and Part 10 [29] – known as JP3D, providing volumetric extensions – are also relevant for this work.To compress an image, the JPEG 2000 encoder decomposes the input into wavelet sub-bands (see Section 2) and consecutively quantizes and encodes the resulting wavelet coefficients by use of the Embedded Block Coding by Optimized Truncation (EBCOT) [30] paradigm. EBCOT is a two-tiered entropy coder. Tier-1 represents a context-based adaptive binary arithmetic coding unit that processes the various sub-bands as smaller independent units or so-called code-blocks. Tier-2 then packetizes the resulting code-block bit-streams to generate the final output JPEG 2000 code-stream that optionally meets given rate and/or distortion requirements. The decoding process, on the other side, can be coarsely considered as the inverse of the encoding process without an EBCOT Tier-2 module.Currently, two methodologies exist for the compression of volumetric medical image data using JPEG 2000. The first is used by DICOM and employs the Multi Component Transform (MCT) feature, as defined in JPEG 2000 Part 2, to perform an axial DWT step with the image slices interpreted by the codec as separate image components. However, this has the minor drawback of causing an inherent ambiguity between actual component information and slice information. The second methodology involves JP3D to handle compression of volumetric image data by properly extending the required portions of JPEG 2000 Part 1. JP3D redefines the DWT to enable support for three dimensions (3D-DWT) [27]. Additionally, JP3D allows the number of decomposition steps and the applied wavelet kernels along theX,YandZdimensions to mutually differ. This offers extra flexibility to easily adapt the wavelet transform to specific characteristics of the data at hand. For the purpose of this work, our presented framework will support both of these methodologies. We would like to point out that both the MCT and JP3D extensions allow fall-back to a 2D-DWT setting when opportune, guaranteeing that the worst-case performance of these extensions is equal to the best-case performance of JPEG 2000 Part 1.Finally, JP3D also introduces volumetric ROI and volumetric code-block support, which are both unavailable in Part 1 or Part 2. The impact of volumetric ROI coding on the lossless compression performance is known and largely depends on the size of the ROI [31,27]. The max-shift ROI method is further enhanced by JPEG 2000 Part 2 to support variable shifts, allowing to balance the ROI overhead and the coding performance more precise. It was observed that with the max-shift method the impact on the lossless bit-rate for small ROIs - spanning less than 1% of the volume – is negligible, though for larger ROIs can increase up to 10%. Alternatively, JPEG 2000 also supports another type of ROI coding, that is block-based and involves rearranging the code-block data in the code-stream into quality layers, and can be done, unlike the shift-based ROI, after encoding. The impact for this type of ROI on the lossless compression performance, caused by the overhead to signal the extra layers and packets within the code-stream, is negligible (typically less than 0.5% overhead) and depends on the precinct sizes. These overhead figures were obtained for the most likely case that the code-blocks are smaller or equal to their containing precinct. When precincts sizes are chosen to be smaller than the code-block size to support very small ROIs, the overhead will significantly increase. Nonetheless, practice demonstrates that this type of ROI encoding is rarely required.The classical wavelet transform employed in JPEG 2000 has the drawback of not being able to optimally represent curvilinear discontinuities in images. The origin of this problem stems from the fact that the n-dimensional DWT is assumed to be a separable transform, given by the tensor product of individual 1D-DWTs along their respective orthogonal dimensions. As such, the classical DWT is limited to efficiently representing point-singularities, and it is unable to sparsely capture more complex, higher-order discontinuities such as lines and curves. Directional transforms on the other hand can efficiently adapt and sparsely represent such geometric structures. Significant research regarding different types of directional wavelet transforms has been proposed in the past, for 2D image data [32–35]. To our knowledge a directional discrete wavelet has never been deployed in the context of volumetric image coding. This paper extends directional wavelet transforms to allow support for volumetric image data sets. We note that finding optimized directional wavelets in the axial direction relies on similar concepts as those of motion-compensated temporal filtering, which was very popular in wavelet-based coding of video [36–40]. The state-of-the-art in video compression, which is the recently developed High Efficiency Video Coding (H.265/MPEG-H HEVC) standard [41] is used as benchmark in the experimental section. We note that employing and optimizing video coding techniques for the compression of volumetric medical data calls for thorough investigations and possibly algorithmic modifications, which goes beyond the scope of this paper. This paper shows how the JPEG 2000 standard can be further extended while also maintaining backward compatibility with its current specification, and provides a thorough evaluation of the resulting performance for volumetric medical data. With this respect, our paper analyses the impact on the compression efficiency by examining various compression settings, such as the employed wavelet kernel, the applied decomposition structure, the directional transform and the related entropy-coding settings. Subsequently, it investigates the possibility of exploiting symmetries that are typically present in medical images by additionally de-correlating the wavelet coefficients before the entropy-coding step. This is achieved based upon the work of [42], through the use of a generic block-based intra-band prediction scheme.Alternatively, it is also possible to replace the axial DWT with an axial KLT for the compression of volumetric medical image data, which is supported through the Multi-Component Transform (MCT) extension of JPEG 2000 Part 2. The KLT is able to optimally remove existing correlations from the image data, but it has two serious drawbacks that make it less suitable for the compression of volumetric medical image data. First of all, the KLT has very high computational complexity and memory usage. Secondly, it comes with the inability to access individual slices, without decoding all slices of the volumetric image. Promising work was done in the context of compression of hyper-spectral image data to (1) provide a reversible KLT implementation [43] that allows scalable lossy-to-lossless compression, and (2) reduce the computational and memory complexities of the KLT by applying a divide-and-conquer strategy [8,9]. However, for the compression of volumetric medical image data with a slice-based 2D-DWT, it was shown that the axial KLT does not maximize the coding gain and consequently performs less or equal to an axial DWT [7]. Combined with the fact that the axial DWT does not suffer from the drawbacks that the KLT brings, we decided to not include it in this study.Summarizing, this paper provides a comprehensive and unified study on the efficient compression of volumetric medical image data, in both lossy – with rate-distortion optimization – and lossless modes. We present a novel, JPEG 2000 based volumetric image codec, enhanced with additional coding modes based on the aforementioned state-of-the-art techniques, that is, directional wavelet transforms, block-based intra-band prediction and arbitrary decomposition structures. Though these individual coding techniques have been presented in literature before, it is the first time that they are jointly integrated in a volumetric coding system and that directional wavelet transforms are deployed in a volumetric context. Subsequently, the paper provides thorough experimental results, comparing existing coding techniques, such as JPEG 2000 Part 1, JPEG 2000 Part 2 MCT (as supported by DICOM), JPEG 2000 Part 10 (JP3D), JPEG-LS and H.265/MPEG-H HEVC, and the proposed volumetric coding system. The results are obtained using both objective and subjective metrics.The paper is structured as follows. Section 2 provides a formal definition of the lifting-based Discrete Wavelet Transform as used in this work, along with the various tested extensions to make it directional. Section 3.1 explains how these directional wavelet transforms can be applied on volumetric images, and Section 3.2 describes the tested intra-band prediction methodology. Finally, Section 4 gives a description of the implemented codec that was used for this work, with the results in Section 5 and conclusions in Section 6.This section introduces a general formulation of the discrete wavelet transform (DWT) based on the lifting scheme as applied for JPEG 2000. It is similar to the formulations used in [32–34], but extended for volumetric data. This notation is used as the basis to present extensions to the DWT in subsequent sections.A forward 1D-DWT separates a given discrete signal into a low-pass L and a high-pass H signal [44] by means of a dyadic wavelet filter bank and down-sampling operations. The resulting low-pass output signal is a scaled version of the original signal with half the number of samples. The high-pass signal contains the missing high-frequency information needed to allow reconstruction with an inverse 1D-DWT. It is important to note that the DWT is critically sampled.LetS=s[l]|l∈Π, withs[l]=s[lx,ly,lz]andl=(lx,ly,lz), denote a signal defined on a 3D orthogonal sampling gridΠ=(lx,ly,lz)∈Z3. Let the gridΠbe divided into eight distinct sub-grids, where(1)Πpqr=(lx,ly,lz)∈Π|p=lxmod2,q=lymod2,r=lzmod2The division of the sampling gridΠinto the eight sub-gridsΠpqrfacilitates defining three instantiations of a 1D-DWT. Each instance filters samples along one of the three possible dimensions ofΠ, labeled as 1D-DWTH, 1D-DWTVand 1D-DWTA, for the horizontal (along the X-axis), vertical (along the Y-axis) and axial (along the Z-axis) dimensions respectively. Then, based on the just created sub-gridsΠpqr, we introduce the following six grid-unions:(2)ΠϕH=⋃q,r∈BΠϕqr,ΠϕV=⋃p,r∈BΠpϕr,ΠϕA=⋃p,q∈BΠpqϕ|ϕ∈B,B={0;1}More precisely, the six sub-grid-mergers divideΠinto three pairs of odd and even poly-phase components, with respect to a given dimension. Introducing these odd and even poly-phase sub-grids, avoids using ambiguous terminology like rows or columns in the volumetric context.In [45] it is shown that any biorthogonal 1D-DWT can be expressed as a finite sequence of prediction and update steps, jointly called lifting steps. Given that D indicates either H, V or A, the input signalSis first decomposed into even (S0(0)={S[l0]|l0∈Π0D}) and odd (S1(0)={S[l1]|l1∈Π1D}) components respectively. Then, in the subsequent stage, a finite sequence of successive prediction and update steps take place, grouped as pairs of lifting steps. Let M be the total number of required lifting steps, then the ithpredict and update steps are respectively defined as(3a)S1(i)[l1]=S1(i−1)[l1]−Pl1d,(i)(S0(i−1)),∀l1∈Π1D(3b)S0(i)[l0]=S0(i−1)[l0]+Ul0d,(i)(S1(i)),∀l0∈Π0DThe prediction functionPl1d,(i)(·)and the update functionUl0d,(i)(·)are functions operating on the sample values of the previous and current lifting steps respectively and returning a scalar output. The variable d represents a constant vector depending on D being H, V or A as respectivelyd=dH=(1,0,0),d=dV=(0,1,0)ord=dA=(0,0,1). Finally, after M pairs of lifting steps, the even and odd poly-phase values represent the result as respective low-pass (LD) and high-pass (HD) coefficients, up to scaling factors GLand GH:(4a)HD[l1]=GHS1(M)[l1],∀l1∈Π1D(4b)LD[l0]=GLS0(M)[l0],∀l0∈Π0DThe applied prediction and update functions are defined by:(5a)Pl1d,(i)(S0(i−1))=∑k=−KPKP−1cP,i,kS0(i−1)[l1−(2k+1)d](5b)Ul0d,(i)(S1(i))=∑k=−KUKU−1cU,i,kS1(i)[l0−(2k+1)d]where KP,cP,i,k, KUandCU,i,k, as well as GL, GHand M, are constants determined by the applied DWT kernel. The scaling factors GLand GHhandle the normalization of the transform to make it unitary, which is important in order to achieve good lossy coding performances. The normalization factors are computed from the synthesis wavelet filters such that for one decomposition level, the total noise energy is preserved in the reconstructed image, when quantizing the coefficients with very high-rate scalar uniform quantizers and assuming that the quantization noise on the wavelet coefficients is white. Wavelet coefficients in JPEG 2000 can be quantized due to either an explicit but optional uniform with dead-zone quantization step, or implicitly as the consequence of bit-stream truncation during the Embedded Block Coding by Optimized Truncation (EBCOT) process. In both cases, quantization is considered to be uniform.Typically, the kernel׳s predict- and update filter coefficients and the scaling factors are rational, or even irrational, numbers, approximated as floating point numbers. Hence, even if the input is given by integer numbers, the output of the filtering operations is no longer guaranteed to be integer. Moreover, due to its limited representation precision, floating point arithmetic is not exact and thus inherently introduces approximation errors, meaning that both the prediction and the update functions are irreversible in practice. In order to ensure perfect reversibility of the transform, one needs to define specialized prediction and update functions that rely on integer calculus alone to prevent rounding errors. The integer-based prediction and update functions are defined by(6a)P^l1d,(i)(S0(i−1))=⌊∑k=−KPKP−1cP,i,kS0(i−1)[l1−(2k+1)d]⌋(6b)U^l0d,(i)(S1(i))=⌊∑k=−KUKU−1cU,i,kS1(i)[l0−(2k+1)d]+0.5⌋where⌊⋯⌋represents the mathematical floor operator. The loss of accuracy by applying rounding inP^l1d,(i)(·)andU^l0d,(i)(·)depends on the kernel coefficient values and causes a loss in the energy compaction efficiency of the transform. This means that certain kernels are inherently more usable in a lossless compression fashion than other kernels, depending on their respective kernel constants and the ability to maintain a minimal reduction of accuracy due to rounding.As stated before, the lifting-based forward 1D-DWTDdescribed above is able to filter a discrete sampled signal into a low-pass (LD) and a high-pass (HD) sub-band, along dimension D. Assuming that the two-dimensional DWT (2D-DWT) is separable, it can be written as the tensor product of two separated one-dimensional DWTs (1D-DWT). As such, applying the forward 1D-DWTVon an input signalS, followed by application of a 1D-DWTHon the resulting LVand HVis equivalent to the forward 2D-DWT as used by JPEG 2000 Part 1 to perform a single level of decomposition, yielding four sub-bandsLHLV,LHHV,HHLVandHHHH(the H and V sub-indices will be omitted from now on). As specified in JPEG 2000 Part 1, the complete forward DWT step performs a multi-resolution wavelet analysis, as introduced by Mallat in [46]. The full decomposition then represents an iteration of consecutive 2D-DWT operations on the LL sub-bands generated at different resolution levels (see Fig. 1(a)).The 3D-DWT (see Fig. 1(b) and (c)) is similarly defined as the tensor product of the independent horizontal, vertical and axial 1D-DWTs. That is, for volumetric instances of a given signalS, the 3D-DWTHVAcan be defined as the application of the 1D-DWTA, followed by the 1D-DWTVand finally the 1D-DWTH, effectively decomposingSinto eight wavelet subbands. With volumetric Mallat (see Fig. 1(c)), only the resulting low-pass (LLL) sub-band is further analyzed in order to generate a new decomposition level.JPEG 2000 supports two built-in wavelet filter banks, labeled 5×3 and 9×7, both originating from the same family of biorthogonal Cohen-Daubechies-Feauveau (CDF) wavelets [47]. With the minimum support requirement, both of these wavelets can be constructed by factorizing a maximally flat Daubechies or Dubuc–Deslaurier half-band filter [48]. This means that the 5×3 kernel is in fact constructed from the CDF 5/3, which is the shortest symmetrical biorthogonal CDF wavelet with two vanishing moments. Its synthesis scaling function or low-pass filter is a linear B-spline. The 5×3 kernel is extremely useful for supporting lossless compression because all of its filters have rational coefficients with the dividends being powers of two. Due to this property, achieving perfect reversibility is possible without loss of performance, as rounding errors can be perfectly controlled.The 9×7 kernel, on the other hand, is a variation on the CDF biorthogonal cubic B-spline construction, using the shortest scaling of order four. It is a variation, because the vanishing moments (6 and 2) are divided up equally on both analysis and synthesis sides in a way that makes the resulting basis functions almost orthogonal [48]. As such, the 9×7 kernel has four vanishing moments per wavelet filter. Moreover, this kernel is nearly orthogonal and has a higher factorization-order that the 5×3 kernel. As such, it also offers an improved energy compaction performance for lossy compression compared to the 5×3 kernel.An exhaustive study on the performance of various types of wavelet kernels [49] drove the JPEG committee to select the 5×3 kernel for lossless and the 9×7 kernel for lossy compression for JPEG 2000. One notes also that in literature, most new advancements utilize also the 5×3 and 9×7 kernels [32,35,42]. Consequently, we will also investigate these kernels in the context of volumetric image coding.Some proposals in the literature focus on directional transforms [33,34], making use of the so-called (6, 6) interpolation wavelet kernel [45] as an alternative to the 9×7 wavelet kernel. For some data sets, the (6, 6) kernel is found to offer higher energy compaction efficiency than the 9×7 kernel. Complexity-wise, the 9×7 and the (6, 6) kernels are notably different, both with benefits and drawbacks depending on the implementation architecture. On one hand, the (6, 6) filter-bank can be implemented through a single lifting step per filter, unlike the 9×7 kernel that requires two lifting steps per filter, which might complicate efficient memory access implementations. On the other hand, the (6, 6) kernel requires more operations per calculated coefficient than the 9×7 kernel due to it׳s large support length of 21 samples. Still, a complexity study of the kernels is beyond the scope of this work and given the good overall performance of the (6, 6) kernel, we decided to also investigate this kernel.Finally, and in light of the fact that the study is being performed in a volumetric imaging context, we also opted to include results using the Haar filter. This wavelet kernel has the shortest possible support length of one and basically performs a linear prediction to generate the high-pass coefficients. Therefore, it might prove beneficial for the compression of volumetric medical image data sets for which the axial sampling pitch (i.e. intra slice distance) is much larger than the intra slice sampling pitch, as it is often the case with modalities such as CT or Magnetic Resonance Imaging (MRI).As shown in literature [32–35], it is possible to improve transform efficiency by making use of directional wavelet transforms. Modifying the previously defined classic or non-directional 1D-DWTDto make it directional requires the prediction function (5a) and the update function (5b) to accept more generic direction vectors thand=dD(recall that D can be H, V or A). As such, d now represents the direction vector and is confined only by(7a)l1−(2k+1)d∈Π0D,∀l1∈Π1D∧k∈[−KP;KP[(7b)l0−(2k+1)d∈Π1D,∀l0∈Π0D∧k∈[−KU;KU[This restriction implies thatd∈Z3(i.e. no interpolation will be required) and that depending on D one of its coordinates is always odd. Moreover,dis further restricted so that the line segment between the grid origin(0,0,0)andddoes not intersect with any other point inΠto avoid using linear dependent vectors. An encoder could be made to try out all possible direction vectors within a well-defined range of angles, in order to identify the best possible direction in some rate-distortion sense. However, it is more convenient in practice to predefine a discrete set of direction vectors. This significantly limits the number of possibilities that have to be evaluated by the transform while encoding.Subsequently, it is possible to modify the prediction and update functions once more to allow direction vectors with fractional coordinates (i.e.d∈R3). This implies that the actual prediction and update values to be used by the two functions need to be sub-sampled on the gridΠ. However, in order to respect the causality constraint for the inverse directional DWT, it is required that the applied interpolation function uses only samples fromΠ0during the predict step or samples fromΠ1during the update step. The implementation used in this work makes use of a 1D Lanczos [50] interpolation filter L(X) given by(8)L(X)={sinc(x)sinc(x/a)if−a<x<a0otherwisewheresinc(x)=sin(x)/xand with a=2 in order to perform the interpolation as in [32].In practice, the directional DWT of Section 2.4 is always employed in an adaptive way, such that the direction vector d dynamically changes depending on spatial location. This adaptability allows the DA-DWT to optimize energy compaction by adjusting itself to distinct localized directionality features in the image data. Doing so, requires the inverse DA-DWT operation of the decoder to know how the forward DA-DWT was applied. Hence, the encoder must also signal the directional information (i.e. the applied direction per spatial location) in the code-stream. It is important to stress that, for a direction-adaptive DWT (DA-DWT) to be profitable, the associated rate cost for encoding this directional information should be small enough so as to not inhibit the overall rate-distortion gain brought by the directional transform itself. Thus, it is practically not possible to allow per pixel direction selection. Segmenting the image data and allowing the directional DWT to employ a suited direction per segment can, however, achieve the trade-off between adaptability and overhead. For this reason, various segmentation strategies were proposed in the past, ranging from simple block-based or tree-based segmentations [32,33,35] to fully arbitrary and content dependent segmentation [34].The most straightforward approach is the application of a block-based segmentation, where the transform segments the input into fixed-sizedNX⁎NY⁎NZblocks. Such blocks are subsequently referred to as DA-blocks (distinguishing them from EBCOT code-blocks). This requires only the signaling of the globally chosen DA-block dimensions along with a selected direction vector for each DA-block. Large DA-blocks result in fewer vectors to signal, but at the same time also cause the transform adaptability to be less granular, affecting its energy compaction performance. Making this trade-off between the adaptability of the directional transform and the associated overhead is content dependent and can be effectively solved by introducing a tree-based segmentation to generate the blocks. Using the tree enables measuring the splitting cost versus the coding gain in a rate-distortion optimal way, up to a predefined minimum DA-block size.An alternative to the block-based and tree-based approaches for segmenting the input image was presented in the work of [34] by introducing a generic segmentation driven DA-DWT (SD-DA-DWT). This work proposes an image segmentation scheme at the sample resolution, allowing for maximal directional adaptability of the transform. The so-called Edgementation [51,52] algorithm is used which performs a gradient-based segmentation followed by rate-distortion-driven segment merging with contour simplification to significantly limit the generated overhead. For the contour simplification and contour coding, the proposed algorithm uses the sophisticated algorithm from [53]. However, for the compression of volumetric medical data sets, this last approach has two hurdles. First of all, determining the optimal segmentation that captures directional features in a volumetric dataset is complex. Secondly, the actually applied segmentation description needs to be stored, which severely influences the overall performance gains due to the incurred overhead. For this reason, and given the typical slice-oriented representation of medical volumetric images, our generic segmentation implementation uses the 2D SD-DA-DWT of [34].Similar to [33,34], we use the L1-norm of the prediction (i.e. high-pass) coefficients as the metric to compare all direction vector candidates, withL1(X)=∑i|xi|. In practice, this means giving preference to those direction vectors that minimize the sum of absolute values of the generated prediction coefficients. Minimizing those coefficients tends to also minimize the bit-rate contributions of the high-pass sub-bands after quantization and entropy coding.To encode the selected direction vector information, we employ a rather conventional signaling methodology that is independent of the employed segmentation technique. More precisely, direction vectors are coded as indexes to the actual vectors in modulus NDfor each of 1D-DWTDsteps independently, where NDrepresents the number of possible direction vectors in the respective set for a given D. The direction vectors each represent an angle and as such their respective indexes are ordered in a circular way to support predictive coding. The implementation predicts each direction index from its respective causal neighborhood and the resulting prediction error value is simply sent to a ND-symbol arithmetic coder.More advanced coding strategies, such as a tree-based coding approach, can be useful to drive the direction search in a rate-distortion optimized way. However, in practice we found that for volumetric medical images, the bit-rate spent on directionality coding ranges from 0.001 to 0.05 bits per pixel (bpp) depending on the chosen DA-block dimensions. This is extremely low, rendering any potential gains from more advanced techniques from small to negligible.It is observed that resulting wavelet coefficients generated by a forward wavelet transform of medical images still contain anatomical symmetry related correlations. As shown in [42], such remaining correlations can be effectively exploited by applying a block-based intra-band prediction scheme to further reduce the energy of the sub-bands. We note that the work of [42] only exploits intra-band redundancies in 2D slices, yet showing improvements of up to 15% in bit-rate reduction compared to JPEG 2000 2D for lossless compression. In light of our search to try to improve the overall compression efficiency for medical volumetric datasets, it is relevant to test the performance of such an intra-band prediction scheme in combination with and compared to the presented volumetric and directional extensions. Thus, based on [42] a generic block-based prediction step was implemented to take place just before EBCOT encodes each sub-band. With squared prediction blocks of 16×16, 8×8 or 4×4 coefficients, let bidenote the current prediction block under investigation. Then, letC={b0,b1,…,bi−1}denote the set of previously encoded blocks in raster-scan order, serving as candidates for the prediction of bi. Furthermore, let Tk(b) withk∈[0;7]represent the spatial transform operator that takes as input a prediction block b and creates as output any of the eight geometrical possible permutations through 90°-rotation and/or mirroring operations. The encoder then searches for the best prediction candidate blockbp∈Cwith a corresponding Ttfor bithat satisfiesL1(Tt(bp)−bi)=mink,b∈C(L1(Tk(b)−bi)).Once bpand Ttare found, both the prediction residualTt(bp)−biand the original block biare lossless encoded with EBCOT and the comparison of the resulting rates serves as the decision criteria to enable prediction or not for bi. Additionally, to be able to decode the predicted blocks, the prediction parameters (b,t) are encoded in the final bit-stream using Exponential Golomb (k=0) codes [54] and arithmetic coding [55].In the context of this work, a complete compression system, called JP3D+DA, was designed and implemented in C++.11The SD-DA-DWT implementation was done in MatLab as a separate module.It is in fact a JPEG 2000 Part 1 and Part 10 compliant codec extended to additionally support all of the coding techniques investigated in this paper. Moreover, it can be used to generate results matching the JPEG 2000 Part 2 MCT setup as used by DICOM by disabling the use of volumetric code-blocks. Fig. 2schematically presents the relevant parts of such a JPEG 2000 compliant codec. Fig. 3, on the other hand, shows the extended JP3D+DA codec employed in this work. Initially, the input image is sent to the transform module, where a mode switch allows to select the type of transform action to perform. This is either an Edgementation based SD-DA-DWT, a block-based DA-DWT, a non-directional DWT or no transform action. With the selection of the first three modes, the output represents the generated sub-band(s) of a single-level decomposition step, along with side-information. These sub-bands are subsequently sent back as input data to the transform module, enabling multi-level wavelet decompositions. Only in the case that no transform was selected, the input data passes through unaltered for further entropy coding in the entropy module. The entropy module contains a switch for the intra-band prediction step to allow further de-correlation of the wavelet coefficients, before encoding them with EBCOT. The module also handles coding the side-information and multiplexes all the data into the final code-stream. We would like to note that the optional interpolation for the DA-DWT occurs in the direction search and the DA-DWT blocks. The implemented wavelet filters for the experiments are the reversible Haar and 5×3 kernels and the irreversible 9×7 and (6, 6) kernels. Table 1lists for each of these four wavelet kernels their respective parameters and kernel lifting coefficients.For the DA-DWT modes, our codec implementation works with a number of direction vectors that approximate angle steps of 22.5° in theXY-plane, while for directions involving the Z-dimension, angle steps of 45° were used, as shown in Fig. 4. For the Lanczos interpolated mode, the direction vectors used represent the same direction vectors as in the non-interpolated mode, but with the coefficients normalized such that the leading dimension coordinate becomes exactly 1 (i.e. x=1 for H, y=1 for V and z=1 for A).The presented framework puts no restrictions on the search for optimal directions for the DA-DWT. Unlike in [32–34], it performs an exhaustive search, using the predefined set of vectors, to achieve transform optimality by maximizing its energy compaction into the low-pass sub-bands. Doing so guarantees that our DA-DWT implementation will deliver optimal results in MSE sense. The increase in time complexity for the exhaustive search is linearly dependent on the number of employed direction vectors, per applied directional 1D-DWT. Specifically, for our experiments we used a set of 9 directions along all three dimensions. Thus, for slice-based DA-DWT, this will lead to a time-complexity increase relative to the conventional DWT by a factor of 18 per decomposed sub-band, while for the axial DA-DWT, this factor will be 9. The encoding of the direction vectors represent a negligible computational cost compared to the other codec components.Our previous work [56] shows that it is possible to significantly reduce the computational complexity of the direction vector search by a factor of 2.75, with only a very modest penalty in the resulting rate-distortion performance. Practical implementations of the DA-DWT can and probably should make use of such complexity-reduction techniques. Nonetheless, we focus in this paper on maximizing and analyzing the rate-distortion performance, optimizing the performance-complexity trade-off being left as topic of further investigation.

@&#CONCLUSIONS@&#
First of all, in medical imaging, it is not well defined what the optimal and most efficient settings for data compression are. The actual context that determines when to use lossless versus lossy compression and the actual parameters for tweaking the compression system are left to the judgment of the implementer and the use case. Compression standards, such as JPEG or JPEG-LS, have a very limited set of options regarding their setup. However, in the case of JPEG 2000 a lot more options are available. In this work, we have spent a huge effort into testing a wide range of the possible settings for the compression of volumetric medical images. Our results show that for volumetric medical images the addition of two wavelet decompositions along the axial dimension suffices to optimize the compression efficiency in all cases for all of the tested images. This means that the (4, 4, 2) wavelet decomposition structure is in practice the advisable choice for the compression of volumetric medical images.Secondly, we also show that the addition of directional adaptive wavelet filters can improve the compression efficiency in some specific cases, but at the cost of increased time and memory complexities. However, given that the additional complexity cost is huge, and that the achieved gains are often minimal, we conclude that the use of directional wavelet transforms for the compression of volumetric CT, MRI or US image data is not worth the effort.Third, it seems that the addition of an intra-band prediction step can slightly improve the compression performance for a wavelet based coding system for some specific images, but again not without increasing the codec׳s complexity. Moreover, efficiently managing the extra overhead is not without difficulties and requires further study to avoid negating the achievable transform gains.Fourth, when comparing JPEG 2000 with H.265/HEVC we see that on most images JP3D, optionally with intra-band block prediction, outperforms H.265/HEVC for almost all images. Though, for those images where H.265/HEVC is better, the bit-rate improvement is also significant. This suggests that H.265/HEVC might not yet be well-tuned for the compression of higher bit-depth image data (12 and 15 bits per sample). We also point out that, unless the All Intra configuration is used, H.265/HEVC cannot not offer random access functionality for partial and progressive decoding of images, like JPEG 2000 inherently does. Moreover, the time-complexity experiments indicate that H.265/HEVC demands a significantly higher computational cost compared to the JPEG-2000 based coding techniques.And lastly, given the fact that JP3D uses only core technology of JPEG 2000 Part 1, we strongly recommend it as the compression standard to use on volumetric medical images. The JP3D standard does not suffer from ambiguity problems concerning the signaling of slice versus component data, it is not more complex than JPEG 2000 Part 1 and it offers significant improved compression performances through use of both volumetric wavelets and code-blocks. Compared to JPEG 2000 Part 2 MCT, JP3D offers very similar compression performance, but it also offers volumetric support for both code-blocks and region-of-interest functionality. Even at very low bit-rates where JPEG 2000 2D fails entirely regarding visual quality, the volumetric counterpart is able to deliver images at a visual quality that can still be considered useful.