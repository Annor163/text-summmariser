@&#MAIN-TITLE@&#
Automated colon cancer detection using hybrid of novel geometric features and some traditional features

@&#HIGHLIGHTS@&#
A novel colon cancer detection system has been proposed.The proposed system utilizes a hybrid of traditional and novel features for classification.Novel geometric features, which mathematically quantify the variation in the structure of normal and malignant colon tissues, have been proposed.The proposed geometric features show superior classification performance compared to traditional features.RBF kernel of SVM shows promising results for classification of colon cancer data.

@&#KEYPHRASES@&#
Colon cancer,Classification,Elliptic objects,Colon biopsy,Elliptic Fourier descriptors,SIFT,Morphological, geometric, and texture features,

@&#ABSTRACT@&#
Automatic classification of colon into normal and malignant classes is complex due to numerous factors including similar colors in different biological constituents of histopathological imagery. Therefore, such techniques, which exploit the textural and geometric properties of constituents of colon tissues, are desired. In this paper, a novel feature extraction strategy that mathematically models the geometric characteristics of constituents of colon tissues is proposed. In this study, we also show that the hybrid feature space encompassing diverse knowledge about the tissues׳ characteristics is quite promising for classification of colon biopsy images. This paper thus presents a hybrid feature space based colon classification (HFS-CC) technique, which utilizes hybrid features for differentiating normal and malignant colon samples. The hybrid feature space is formed to provide the classifier different types of discriminative features such as features having rich information about geometric structure and image texture. Along with the proposed geometric features, a few conventional features such as morphological, texture, scale invariant feature transform (SIFT), and elliptic Fourier descriptors (EFDs) are also used to develop a hybrid feature set. The SIFT features are reduced using minimum redundancy and maximum relevancy (mRMR). Various kernels of support vector machines (SVM) are employed as classifiers, and their performance is analyzed on 174 colon biopsy images. The proposed geometric features have achieved an accuracy of 92.62%, thereby showing their effectiveness. Moreover, the proposed HFS-CC technique achieves 98.07% testing and 99.18% training accuracy. The better performance of HFS-CC is largely due to the discerning ability of the proposed geometric features and the developed hybrid feature space.

@&#INTRODUCTION@&#
Medical imaging has gained much importance in the last few decades, especially in analyzing different body parts for predicting certain disorders/diseases. Microscopic imaging is one of the medical imaging techniques, wherein the images of biopsy slides are captured. Biopsy images have well-defined organization of tissues and connected components, depending upon the body part from which they are taken [1]. The same is true for colon biopsy images, which are used in our problem for cancer detection. Biologically different constituents in a colon biopsy image can be identified by looking at the spatial organization of its constituents.Microscopic analysis is the commonly practiced technique of colon cancer diagnosis, wherein histopathologists visually examine the deformation of tissues under microscope, and decide whether the geometric structure and organizational arrangement of sample tissues belong to the class of malignant or normal colon. Microscopic analysis is time consuming as well as subjective. The main reason behind subjectivity is the fact that quantitative cancer grades are assigned depending upon the observed morphology of tissues by the histopathologists. This process also leads to inter/intra-observer variability as quantitative grades assigned to the same sample by different histopathologists, or even by one histopathologist, may vary at times [2,3]. In order to alleviate such problems in diagnosis, researchers are working since long to find automatic quantitative tools, which could measure the degree of deformation and assign quantitative cancer grades to the colon samples.The research in the field of colon cancer is in various dimensions. A larger subset of the colon cancer detection techniques has been summarized in a recent survey reported by Rathore et al. [4]. Some authors have performed analysis on hyperspectral data of colon biopsies [5,6]. In these schemes, authors select one spectral band amongst several bands of hyperspectral cube, calculate image features, and then based on these features classify samples into multiple classes. Some researchers have studied thousands of human genes in parallel by using two variants of microarrays [7,8]. Their aim was to identify such genetic alterations, which were supposed to be responsible for colon cancer. Like genes, blood serum also deviates from its normal composition in case of colon cancer. Researchers have exploited this variation, and have used laser-induced fluorescence and Raman spectroscopy of blood serum for cancer detection [9,10].Some researchers have exploited the variation in the texture of normal and malignant colon biopsy images for cancer detection. In this context, Esgiar et al. analyzed distinctiveness of six texture features (angular second moment, contrast, correlation, entropy, inverse difference moment, and dissimilarity) for classification of colon biopsy images [11]. They found the combination of entropy and correlation to be the most distinctive feature set, providing an overall accuracy of 90.2%. They further extended the idea by introducing fractal dimensions into the classification process, and proved that a combination of entropy, correlation and image fractal dimensions yields classification accuracy of 94.1% [12]. Followed by their work, Masood et al. proposed a few valuable methodologies for classification of colon. In their first method, they calculated morphological features of shape, size and orientation, and gray-level co-occurrence matrix (GLCM) based features of energy, inertia, and local homogeneity from colon biopsy images [13]. They employed polynomial SVM classifier, and achieved classification accuracy of 84% and 90% using morphological and GLCM based features, respectively. Masood et al. further extended the previous work [13], and calculated circular local binary patterns in order to classify colon biopsy images [14]. They obtained an accuracy of 90% by employing Gaussian SVM for classification. Further, Rathore et al. proposed a colon biopsy image based classification technique (CBIC) [15], wherein a hybrid feature set comprising traditional histogram of oriented gradients based features, and novel variants of statistical moments and Haralick texture features has been used for classification of colon biopsy images. A majority voting based ensemble of SVM classifiers has been used for classification, and 98.85% classification accuracy has been observed.Recently, Altunbay et al. proposed a colon cancer detection technique [16], wherein they constructed a graph on different objects, obtained by using circle fitting algorithm [1] on the white, pink and purple clusters of colon biopsy image. Features of degree, average clustering coefficient, and diameter are computed from the graphs. The features are then used to classify given samples by using linear SVM kernel. In addition, Ozdemir et al. presented a method for automated colon cancer detection [17]. In this work, reference graphs of a few normal images are generated by employing previously proposed method of graph creation [18], and are stored for further referencing. Some query graphs are generated from the test images, and are searched in the reference graphs. Three most similar graphs are found in the reference images. Finally, normal or malignant class is assigned to the test sample based on the degree of similarity of the query graph with the three most similar graphs.The techniques mentioned in the previous paragraphs have a few limitations. First, graph based techniques [16,17] are computationally expensive. Second, texture features based techniques [11–15] have exploited general texture features for classification, and have not exploited the background knowledge about the morphology of colon tissues for classification. Therefore, a computer-aided diagnostic technique, which could exploit the morphology of normal and malignant colon tissues in a computationally tractable manner, is required.In this research, a novel hybrid feature space based colon classification (HFS-CC) technique has been proposed for robust and effective classification of colon biopsy images. We propose a novel feature type that mathematically quantifies the geometric structure of constituents of colon tissues. Further, we compute some other feature types such as morphological, SIFT, EFDs, and texture features, and combine those features with geometric features to form a hybrid feature set. HFS-CC differs from its previous counterparts in two aspects. First, it incorporates background knowledge about tissues organization into the classification process by introducing novel geometric features, thus leads to effective and promising results. Second, it caters different categories of features, and exploits positive aspects of each category. There are several abbreviations used in subsequent sections. These abbreviations are given inTable 1.The remainder of this paper is organized as follows. Section 2 describes the structure of normal and malignant colon tissues. Section 3 presents the proposed scheme in detail. Section 4 describes performance measures. Section 5 demonstrates experimental results, and Section 6 concludes the paper.Normal colon tissues have well-defined organizational structure. There are three constituents of a normal colon tissue, namely, epithelial cells, non-epithelial cells, and connecting tissues. The detailed structure of a normal colon tissue is shown inFig. 1(a). Lumen lies in the middle of the tissue and is surrounded by epithelial cells that form glandular structure, whereas, non-epithelial cells lie in between glandular structures and are known as stroma. Cells and connected tissues are organized and coherent in case of normal colon. But, this organizational structure deviates considerably for malignant tissues as shown in Fig. 1(b)–(d).Histopathologists analyze the samples under microscope and decide whether tissue is normal or not. Furthermore, histopathologists also assign quantitative cancer grades to the malignant colon samples. Grade of colon cancer is the differentiability level of malignant tissues from normal ones. There are three colon cancer grades: well-, moderately-, and poorly differentiable. In a well differentiable grade, tissues are slightly similar to normal ones as shown in Fig. 1(b). In this particular grade, cancer progresses at low speed. In moderately differentiable cancer grade, tissues are different from normal ones as shown in Fig. 1(c), and cancer progresses at moderate speed in this grade. In a poorly differentiable cancer grade, malignant tissues are totally different from normal tissues as shown in Fig. 1(d), and cancer progresses at very high rate in this particular grade.The proposed HSF-CC scheme comprises six main stages, namely, pre-processing, feature extraction, feature reduction, feature concatenation, training/testing data formulation, and classification of images into normal or malignant categories by using SVM classifier.Fig. 2 presents top-level architecture of the proposed scheme.In the proposed HFS-CC scheme, the hybrid features are extracted from the given dataset after a few pre-processing steps. The features are then combined for subsequent use in SVM based classification.The main purpose of this stage is to make the dataset suitable for subsequent operations. Two types of preprocessing are applied on input images depending upon the requirements of subsequent feature extraction techniques. These preprocessing methods are explained in the following text.Morphological and geometric features are extracted from image clusters. This clustering is achieved by running K-Means algorithm. K-Means is a non-parametric statistically iterative method, originally developed by Fukunaga et al. for estimation of gradients of a density function [19], and has extensive use in computer vision for image clustering [20,21]. In this study, K-Means algorithm has been applied on color intensities of pixels, and image pixels have been segregated into three clusters. The clusters depict pink region (connective tissue components), white region (luminal structures and epithelial cells), and purple region (non-epithelial cells) in the image. The clusters are then transformed to binary format using global thresholding method. Morphological features have been computed from binary clusters, whereas the binary clusters have been further dilated using Eq. (1) for geometric features.(1)f=f⊕bwhere f is the cluster and b is the square structuring element of size ‘2’.Fig. 3 shows a colon biopsy image and its corresponding white, pink, and purple clusters achieved after preprocessing.K-Means divide an image into clusters, but does not separately identifie pink, white and purple clusters. Therefore, average intensity values of the clusters are calculated for an image in order to identify the clusters. A white cluster has highest average intensity, a pink cluster has moderate value, whereas a purple cluster has lowest value of average intensity. So, the clusters of an image can be easily distinguished based on this parameter.Fig. 4 demonstrates mean gray level values for the three clusters.Second type of pre-processing is specific to the extraction of SIFT and texture features. For these features, image is converted into grayscale in the preprocessing phase.Features provide a mean to translate an image pattern into a set of discriminatory quantitative values. The ultimate aim of this stage is to formulate a feature vector for every colon biopsy image. The individual features are combined to form a composite feature vector, which is used for image classification. Feature extraction process has already been explained in Fig. 2. There are five feature extraction modules (FEM) corresponding to individual feature extraction strategies. These modules independently extract diverse features from an image with one exception of elliptic Fourier descriptors based FEM that utilizes some information supplied by geometric FEM.Morphology of tissues plays a pivotal role in determining whether tissues are normal or malignant. Morphological features provide a way to convert image morphology into a set of quantitative values. They have broadly been used in classification [22–24], segmentation [25], and so on.Morphological FEM takes binary image clusters as input, and finds connected components in the clusters. It retains those connected components having area greater than a certain threshold T (see Section 5.3.2). The number of connected components satisfying threshold criterion may vary for different clusters, and are represented by Cw, Cpand Crfor white, pink and purple clusters, respectively. Nine morphological features, namely, area (a), perimeter (p), eccentricity (y), Euler number (l), convex area (x), compactness (o), orientation (e), length of major (m1) and minor axes (m2) are computed for each connected component of a cluster.Table 2 describes these features; definitions of morphological features have been taken from Gonzalez[26].Eq. (2) presents morphological feature vectors for individual connected components.(2)qiw=[apylm1m2xoe]iTwherei=1,2,3,...,Cwqip=[apylm1m2xoe]iTwherei=1,2,3,...,Cpqir=[apylm1m2xoe]iTwherei=1,2,3,...,Crwhere qiw,qipandqirare morphological feature vectors for ith connected component of white, pink and purple clusters, respectively.Average values of the nine features obtained from connected components of a cluster constitute morphological feature vector for the corresponding cluster. The feature vectorsw,p,rfor the white, pink, and purple clusters are given in the following equation:(3)w=1Cw[∑i=1Cwqiw]p=1Cp[∑i=1Cpqip]r=1Cr[∑i=1Crqir]The vectorsw,pandrare combined to form morphological feature vectorm.(4)m=[wTpTrT]TTexture features have been quite successfully used in solving classification related problems [27–29], and especially the classification of colon biopsies [11,12]. In this work, texture features have been calculated from the GLCM matrix, which encapsulates the spatial relationship between pixels of an image. Each entry (i, j)th in the GLCM defines how many times the pixel with intensity value i co-occur in a specified relationship with pixel having intensity value j. The relationship is in terms of two parameters, which are the relative distance (d) between the pixel of interest and the neighboring pixel, and their relative orientation θ. Normally, θ is quantized in four directions (0°, 45°, 90°, 135°) [10]. In this work, texture features have been computed at four possible directions, and two distances (d=1,2), thereby resulting in a total of 8 GLCM matrices. The values of the GLCM matrices have been averaged in four directions for each distance d, thereby resulting in two GLCM matrices (for d=1 and d=2). The texture features of randomness (r), contrast (t), correlation (ρ), energy (n), and homogeneity (h) have been computed from the two GLCM matrices. The results in the experimental section correspond to the GLCM that leads to maximum classification capability, which is the four-directional average GLCM computed at d=1.The initial eight GLCM matrices have also been used separately for classification of colon image dataset. Furthermore, several combinations of these GLCMs, and a hybrid of the features computed from these GLCMs have also been investigated. But, the best results have been achieved for the average four-directional GLCM computed at d=1.Table 3 formulates definitions of texture features and mathematical formulae for their calculation, as given in Gonzalez and Woods[26].These features are computed from gray-level co-occurrence matrix G, where i and j represent indices of its rows and columns. pijis the ijth term of G divided by the sum of its elements. The terms miand mjare the mean, σiand σjare the standard deviation of ith row and jth column of G. Above mentioned features are combined to form texture feature vectort.(5)t=[rtρnh]TSIFT features, originally proposed by Lowe [30], are normally used in problems of panoramas reconstruction [31], face identification/authentication [32–34], and most importantly, visual object tracking [35]. However, its diverse and distinctive nature helps researchers to use it in other application areas. SIFT features are robust against image scaling, rotation, illumination changes, noise, and blurry effects. These properties of SIFT features make them a good choice for classification of colon samples.SIFT features are extracted through a staged filtering process. In the first step, key points are localized in an image. To this end, original image is repeatedly convolved with Gaussian to produce convolved scale-space images. Then, adjacent Gaussian convolved images are subtracted to produce difference of Gaussian images. After calculating difference at one scale, original image is down-sampled by a factor of 2, and process is repeated until reaching lowest possible scale. First step detects large number of key points, which are reduced in the next step. In the second step, each pixel is matched against 8 neighbors in its own scale and 9 neighbors in scales above and below it. The points having their value either greater or smaller compared to all the neighboring pixels retain after this step. In the third step, unstable key points i.e. the points that are poorly localized along edges or have poor contrast are discarded.Finally, orientations and descriptors are assigned to the remaining key points. Orientations are assigned based on directions of local image gradient. For calculation of descriptors, magnitude and orientation values of pixels lying in 16×16 window around a given pixel are used to compute 16 orientation histograms. These histograms contain samples from 4×4 sub-regions of the given window, and have 8 bins each. The magnitudes and orientations are further smoothed by a Gaussian function with equal to one half the width of the descriptor window. The descriptor then becomes a vector of all the values of these histograms. Since there are 16 histograms with 8 bins each, therefore, the vector has 128 elements. Descriptor vector is finally normalized to make it independent of linear and non-linear illumination changes.In this particular research study, SIFT features are calculated for the given dataset. SIFT feature vector for an image comprises orientations and descriptors of SIFT key points of that particular image. The number of SIFT key points may vary from image to image, therefore, most distinctive S key points are picked from each image to make equal sized feature vectors. The libsiftfast-1.2 library [36] has been used for feature extraction. SIFT feature vector has the following composition.(6)θ=[θ1θ2θ3...θS]qi=[q1q2q3...q128]iTwherei=1,2,3,...,Ss⁎=[θq1Tq2Tq3T...qST]TIn Eq. (6),θcontains orientations of S points, whereasqivector contains features of ith SIFT point. Finally orientations and features of S points are combined to form SIFT fetaure vectors⁎.In classification problems, huge size, imbalanced nature and high dimensionality of training dataset mainly cause the classification algorithms to suffer in accurately predicting the samples. Therefore, data must be reduced in size prior training a classifier. In our classification problem, SIFT features have quite large size. Therefore, in order to alleviate the curse of dimensionality issues, SIFT features have been reduced by using minimum redundancy and maximum relevance (mRMR) method [37].Fig. 5 demonstrates dimensionality reduction process for SIFT features. mRMR model takes original SIFT feature vectors⁎and corresponding image labels b1,b2,…,b174 as input, and returns reduced feature vectors.In a normal colon tissue, epithelial cells and lumen are nearly elliptic, whereas, in a malignant colon tissue, epithelial cells and lumen merge together, thereby resulting in irregular shaped white regions. Furthermore, the epithelial cells in a normal colon tissue are elliptic, and have symmetry in their sizes and distribution. On the other hand, the epithelial cells in a malignant colon tissue are irregular, and have no symmetry in their distribution and sizes. Normal and malignant colon tissues are shown inFig. 6 for comparison.In this research study, we speculated that this variation can be exploited to identify normal and malignant colon tissues. Therefore, geometric features have been proposed with an intention to capture geometrical differences between the structure of epithelial cells and lumen in normal and malignant colon tissues.The calculation of geometric features is a three step process. In the first step, elliptic objects (epithelial cells and lumen) are detected in colon biopsy images. In the second step, the detected objects are divided into different categories. In the third step, the information about the size and spatial distribution of these objects is exploited to calculate geometric features. These steps are explained in the following text.The first step is to locate elliptic objects in colon biopsy images. Since epithelial cells and lumen belong to white cluster, therefore, elliptic objects are detected only in the white cluster of colon biopsy images. A novel algorithm has been proposed for this purpose, which is shown inFig. 7.In the proposed algorithm, connected components are generated in white cluster of colon biopsy images. Smaller components, which have arisen due to blur in colon biopsy images and have area smaller than component area threshold (CAT), are excluded from further experimentation. Later, each connected component is processed individually, and elliptic objects are found in the component.The process of searching elliptic objects in a single component is shown in the right half of Fig. 7. Initially, four patterns of ellipses i.e. horizontal (0°), vertical (90°), diagonal (45°), and off-diagonal (135°) as shown inFig. 8 are generated starting with maximum values of semi-major (SMJA) and semi-minor axes (SMIA).Generated ellipses are in fact matrices, and their size depends upon length of semi-major and semi-minor axes. For example, for 5 units’ long semi-major axis and 3 units’ long semi-minor axis, horizontal, vertical, diagonal and off-diagonal ellipses are matrices of size 11×7, 7×11, 11×11, and 11×11, respectively. The pixels lying inside ellipse have value ‘1’, whereas outer pixels have value ‘0’ as demonstrated in Fig. 8.The four generated ellipses are found in each connected component of a cluster. For the reason, system traverses pixels of the connected component one at a time, and extracts four regions of the same size as horizontal, vertical, diagonal and off-diagonal ellipses around the pixel. The pixel values of horizontal, vertical, diagonal, and off-diagonal windows are compared with respective pixel values of the horizontal (0°), vertical (90°), diagonal (45°), and off-diagonal (135°) ellipses. If all the pixels having value ׳1׳ in an ellipse are also ׳1׳ in the extracted window, an ellipse of that particular orientation is supposed to exist at the pixel. Once the system finishes traversing all the pixels of a connected component, the object detection process is repeated with the remaining pixels (which have not been assigned to any elliptic object) of the component by decrementing the values of SMJA and SMIA by one unit. The process is continued for the same connected component provided there are some unassigned pixels, and the SMJA and SMIA have not reached minimum bounds. Otherwise, the process is started for the next connected component of the cluster in the same fashion.Fig. 9 demonstrates the elliptic objects detected in the white cluster of a colon biopsy image.The blur or noise in colon biopsy images may disturb the functioning of K-Means, and some inner pixels of epithelial cells may be 0, thereby leading to not exact but almost elliptic shapes in the clusters. Furthermore, the ellipse searching process in four orientations covers most of the ellipses, but there may be some ellipses which are slightly tilted from the four defined orientations. Therefore, a concept of membership function has been introduced in the proposed HFS-CC technique in order to find nearly elliptic shape based epithelial cells and the epithelial cells tilted from four standard orientations. The membership function defines the percentage of pixels, which have the same value in generated ellipse and the extracted window. The optimal value of membership, found through experimentation, is 95%.Fig. 10 demonstrates membership function. In Fig. 10(a), there is a horizontal ellipse that needs to be found in the image patches (b) and (c). A full match has been found in the pattern given in Fig. 10(b). Circled numbers in Fig. 10(b) represent those image pixels which have value 1, but they do not participate in matching process because they lie outside the boundary of generated ellipse. A partial match has been found in Fig. 10(c). It shows nearly elliptic shape where two circled numbers inside ellipse are 0, however membership function helps detecting such ellipses.The detected objects are further divided into two categories depending upon object area threshold (OAT). The largest object, which is lumen in case of normal images, and is either lumen or a larger part of scattered lumen in case of malignant images, is not divided into any of the categories. The objects having size larger than OAT belong to one category (object type-1), whereas, objects having size smaller than OAT belong to second category (object type-2).Fig. 11(a) shows the categorization of objects into two object types. The objects having size greater than OAT are in yellow, and the objects having size smaller than OAT are in blue.Geometric features are computed based on the information about size and spatial distribution of the detected objects. These features include:1.Object size uniformity (OSU): OSU measures the uniformity in the sizes of objects both at the local and global level. The local features are called local object size uniformity (LOSU), and global features are called global object size uniformity (GOSU).Local object size uniformity: In order to calculate LOSU features, a circular window is iterated on each image pixel, and standard deviation of areas of both the object types lying within the window is separately calculated. For instance, in window 2 inFig. 12(a), there are 2 objects of object type 1, and 4 objects of object type 2. The LOSU features are computed by calculating the standard deviation of areas for the 2 and 4 objects, respectively, for object type 1 and 2. Since both the object types have areas of different scales, therefore, LOSU features are normalized by dividing standard deviation of areas with respective mean for each particular object type. Two features per pixel are computed this way. The LOSU features will be zero for pixels, which have either no object or only one object in a circular window around them, therefore, these pixels do not contribute in the calculation of geometric features. This scenario is shown in window 1 of Fig. 12(a). In the end, we do average the non-zero values of features to compute two LOSU features per image.Since the detected objects have almost the same area in normal colon biopsy images, therefore, the value of LOSU features will be near to zero for these images. On the other hand, since the detected objects greatly differ in terms of area in malignant colon biopsy images, therefore, LOSU features will have larger values for these images. These features are calculated using smaller and larger window of radii RS and RL, respectively, and are named as LOSU1 and LOSU2 for smaller window, and LOSU3 and LOSU4 for larger window, respectively.Global object size uniformity:In order to calculate the GOSU features, standard deviation of the area of all the detected objects for a particular object type is calculated. This measure will also be small for normal colon biopsy images, and vice versa due to more uniformity in the detected objects of normal colon biopsy image. These features are named as GOSU1 and GOSU2.Object spatial distribution uniformity (OSDU): OSDU feature measures the uniformity in the spatial distribution of detected objects. It is a measure of the magnitude of sum of position vectors for all the objects other than lumen. The position vectors are calculated with reference to the centre of the lumen (largest detected object). The process of computing OSDU features from a colon biopsy image is shown in Fig. 12(b). The value of OSDU feature will be near to zero for normal colon biopsy images since the detected objects are uniformly distributed in space around the lumen. On the other hand, OSDU feature will have larger values for malignant colon biopsy images since the detected objects do not follow any standard spatial distribution. The OSDU feature is not calculated at the local level since the objects do not have any regular orientation at the local level.Eq. (7) depicts composition of geometric feature vectorg.(7)g=[LOSU1LOSU2LOSU3LOSU4GOSU1GOSU2OSDU]The optimal values of several parameter such as RS, RL, membership function, maximum and minimum bounds for SMJA and SMIA, OAT, and CAT are calculated. The process of calculating these values is given in explained in Section 5.3.2.Lumen and epithelial cells have elliptic shape, therefore, it is speculated that elliptic Fourier descriptors (EFDs) of these constituents will help in discriminating normal and malignant colon tissues. EFDs were initially introduced in 1982 by Kuhl et al. for classification of several solid objects such as windmill, tank, etc. [38]. However, later on EFDs have been extensively used in pattern recognition [39,40].The computation of EFD features is a two step process. In the first step, elliptic objects are detected in the white cluster of colon biopsy images as already discussed in Section 3.2.4.1. In the second step, elliptic objects are sorted in descending order based on their area, and EFDs of the top-most E objects are calculated up to the desired harmonic level H. Selection of optimal values for E and H is explained in Section 5.3.2. The process of extraction of EFDs is elaborated inFig. 13.EFDs are based on chain codes, which approximate the shape of a closed contour by a sequence of eight standardized line segments, and are invariant to dilation, translation, rotation and starting point of a contour. EFDs of a closed contour comprise x and y-projection of its chain codes. H harmonic levels are used for extraction of EFDs, and there are four Fourier coefficients i.e. a, b, c and d against each harmonic level. Eq. (8) presents elliptic Fourier descriptors for E elliptic primitives.(8)ai=[a1a2a3...aH]iTwherei=1,2,3,...,Ebi=[b1b2b3...bH]iTci=[c1c2c3...cH]iTdi=[d1d2d3...dH]iTwhereai,bi,ci, anddivectors contain a, b, c and d Fourier coefficients of ith primitive upto harmonic level H.ai,bi,ci, anddivectors are averaged to forma¯,b¯,c¯andd¯average vectors.(9)a¯=1E∑i=1Eai,b¯=1E∑i=1Ebi,c¯=1E∑i=1Eci,d¯=1E∑i=1EdiAverage vectors are then combined to form final elliptic feature vectore.(10)e=[a¯Tb¯Tc¯Td¯T]TIndividual features are combined to make a hybrid feature vector. The features are aligned in sequence as presented inFig. 14. Upper indices are for individual features, whereas lower indices are for hybrid features. Hybrid feature vector has 244 dimensions.In this work, Jackknife 10-fold cross-validation technique has been employed for training/testing data formulation and parameter optimization. It is a commonly practiced technique that has been successfully used in the past to validate the accuracy of prediction. In 10-fold Jackknife test, data are divided into 10 folds. 9 folds participate in training, and the classes of the samples belonging to the remaining fold are predicted based on the training performed on 9 folds. The test samples in the test fold are purely unseen for the trained model. This sampling process is repeated 10 times and the class of each sample is predicted. Finally, the predicted labels of the unseen test samples are used to determine classification accuracy. The Jack-knife process is repeated for each combination of system׳s parameters, and classification performance has been reported for the sample that leads to maximum classification accuracy on the unseen test data.Fig. 15 presents Jackknife 10-fold cross-validation process for the calculation of classification performance of morphological feature vector using linear SVM. There are two parameters involved in this task; one is the area threshold of morphological features (T), and second is the constraint violation cost (c) of linear SVM. The parameters have been varied in their potential ranges, and Jack-knife process is repeated for each combination. The classification accuracy on unseen test data is measured for each combination of parameter values, and the best achieved classification accuracy has been reported in Section 5.In recent times, SVM classifier has received noticeable attention for attaining higher classification success. SVM classifier is considered a better performer compared to other classifiers. It has been quite successfully used in different application areas of medical diagnosis [41–43]. In the training phase of SVM, it maps non-separable data to a high dimensional space where it becomes linearly separable. In high dimensional space, SVM creates a partition surface between data of two classes while trying to maximize the margin of separation between classes. Decision surface divides total feature space into two sub-spaces where each sub-space belongs to single class. In the testing phase, test data is mapped to the space and labels are assigned to the images depending upon the sub-space in which their features lie. Linear, RBF and Sigmoid kernels have been used for classification, and classification accuracy is evaluated using 10-fold cross-validation.In our experiments, we provide visual results obtained by the algorithms i.e. labels assigned to the samples during testing. Further, we quantitatively evaluate the results using well-known performance metrics such as accuracy, sensitivity, specificity, Matthews׳s correlation coefficient (MCC), F-score and receiver operating characteristics (ROC) curves. The calculation of parameters involves true positive (TP), false positive (FP), true negative (TN), and false negative (FN). True negative and true positive are the number of correctly classified negative and positive samples, whereas, false negative and false positive are the number of positive and negative samples, which are incorrectly classified.Accuracy is a measure of overall effectiveness/usefulness of the classification scheme. It can be calculated using equation given below.(11)Accuracy=TP+TNTP+FP+TN+FN×100Sensitivity is used to measure the ability of a classifier to recognize patterns of positive class. It can be obtained using the following equation.(12)Sensitivity=TPTP+FNSpecificity is calculated to measure the ability of a classifier to recognize patterns of negative class. The following equation is used to calculate specificity.(13)Specificity=TNTN+FPMCC serves as a measure of classification in binary class problems. Its value ranges from −1 to +1. +1 means classifier always predicts a right label, whereas −1 means classifier always commits a mistake. However, 0 means random prediction. MCC can be calculated using the following formula.(14)MCC=TP×TN−FP×FN((TP+FN)(TP+FP)(TN+FN)(TN+FP))F-score makes use of precision and recall to calculate accuracy of classification.Precision=TPTP+FP,Recall=TPTP+FNThe F-score can be calculated by using Eq. (15). It is weighted average of precision and recall values. Its value ranges between 0 and 1, where 0 is the worst possible score and 1 is the best possible.(15)Fscore=2×Precision×RecallPrecision+RecallAn ROC curve is a standard way for graphical representation of the classification performance of a system [44]. It characterizes the system over its entire operating range, and is created by plotting true positive rate (TPR) against false positive rate (FPR). TPR represents the number of correct positive cases divided by the total number of positive cases. FPR, on the other hand, is the number of negative cases predicted as positive cases divided by the total number of negative cases.

@&#CONCLUSIONS@&#
