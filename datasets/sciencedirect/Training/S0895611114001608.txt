@&#MAIN-TITLE@&#
3D multimodal MRI brain glioma tumor and edema segmentation: A graph cut distribution matching approach

@&#HIGHLIGHTS@&#
A new algorithm for 3D Multimodal MRI Brain Glioma Tumor and Edema Segmentation.New preprocessing algorithm to segment edema.Comprehensive evaluations/comparisons on the publicly available MICCAI-2012 challenge data set.Comprehensive evaluations/comparisons on the testing MICCAI-2012 challenge data set on virtual skeleton database website.Very competitive performance of the proposed algorithm.

@&#KEYPHRASES@&#
Graph cut distribution matching,Segmentation,MRI,Brain tumor,Edema,BraTS2012,

@&#ABSTRACT@&#
This study investigates a fast distribution-matching, data-driven algorithm for 3D multimodal MRI brain glioma tumor and edema segmentation in different modalities. We learn non-parametric model distributions which characterize the normal regions in the current data. Then, we state our segmentation problems as the optimization of several cost functions of the same form, each containing two terms: (i) a distribution matching prior, which evaluates a global similarity between distributions, and (ii) a smoothness prior to avoid the occurrence of small, isolated regions in the solution. Obtained following recent bound-relaxation results, the optima of the cost functions yield the complement of the tumor region or edema region in nearly real-time. Based on global rather than pixel wise information, the proposed algorithm does not require an external learning from a large, manually-segmented training set, as is the case of the existing methods. Therefore, the ensuing results are independent of the choice of a training set. Quantitative evaluations over the publicly available training and testing data set from the MICCAI multimodal brain tumor segmentation challenge (BraTS 2012) demonstrated that our algorithm yields a highly competitive performance for complete edema and tumor segmentation, among nine existing competing methods, with an interesting computing execution time (less than 0.5s per image).

@&#INTRODUCTION@&#
Glioma tumor could be considered as a primary malignant brain tumor that could seriously threaten an important number of patients, with a survival prognosis not exceeding one year for high-grade glioma [1,2]. Such tumors are often accompanied with peritumoral edema, which corresponds to an extensive perifocal swelling [3]. Magnetic Resonance Imaging (MRI) is the main modality for evaluating the pathological regions. Segmenting precisely the tumor and edema regions in MRI is, therefore, an essential pre-processing task towards thorough and reproducible diagnosis of brain tumors. Manual segmentation could be so prohibitively time-consuming, and could never be reproducible during clinical routines. Therefore, automatic or semi-automatic segmentation algorithms would be highly recommended in order to surmount such disadvantages. Several past research studies investigated such problem [4–6] by segmenting both the tumor and the edema regions in one or multiple modalities (T1,T1C,T2 and Flair), and this remains yet a challenging task. Most of the existing algorithms are still not fast and not flexible enough, especially for realistic clinical scenarios and needs. One could notice some difficulties inherent to the brain tumor segmentation because, in general, brain tumors have shape and intensity characteristics that may vary dramatically from one subject to another, which impedes building reliable models from training data. For instance, the brain tumor region shape may be arbitrary, and does not necessarily fall within a category (or class) of shapes that could be learned from one finite set of training subjects as is the case of most medical image segmentation problems. Furthermore, in some cases, tumors might have intensity profiles that would be so similar to the other normal regions within the considered image. The past research studies addressed different variants for this segmentation problem and several of them used multi-modal MRI [6,7]; other works used only a single modality [8,11]. Among studies, one could notice that several of them focused only on the tumor as a target region [9,10,13], whereas others addressed both the tumor and the edema segmentation [11]. Most of the existing methods require a time-consuming external learning phase, which requires building a large, manually-segmented training set [6]. In [6], the authors used three MRI modalities (T1,T1C and T2) and texture characteristics to construct a multi-dimensional feature set. Then, they learned a statistical model for tumor and normal tissues, thereby obtaining a 3D supervised segmentation of the brain tumor. Several other studies addressed both edema and tumor in order to provide richer clinical information that could be somehow useful. For instance, the authors of [11] presented a Bayesian formulation for incorporating soft model assignments so as to delimit brain tumor and edema. The study in [9] presented an unsupervised change detection method based on gray level histograms for brain tumor and edema segmentation. Comparatively to our proposed approach, various other tumor/edema segmentation algorithms were presented at the MICCAI BraTS 2012 challenge. The authors of [5] used a standard forest classification based on spatially non-local features along with initial probability estimates for individual tissue classes. The initial tissue regions probabilities were therefore based on local intensity information alone, and one parametric GMM-based model was used for the estimation step. Another competitor in the challenge [4] integrated random forest classification with hierarchical conditional random field regularization within an energy minimization scheme. The authors of [19] presented a semi-automatic tumor-cut algorithm. The user would be consequently required to provide the maximum diameter of the edema region visible on FLAIR images, and subsequently, a level set method would be then used to segment the target regions. Although effective in some cases, such mentioned training-based algorithms could be faced to one evident difficulty in extracting the substantial variations within tumor shape and intensity. The ensuing results depended on the characteristics, the variability, and the mathematical description of the training set. For instance, an unseen tumor different from all those within the training set may not be found.In this work, we propose a novel distribution-matching, data-driven algorithm for 3D multimodal MRI brain glioma tumor and edema segmentation. We estimate a non-parametric model distribution that characterizes the normal regions in the current data. Then, we state our segmentation problems as the optimization of several cost functions of the same form, each involving two terms [15] (i) a distribution matching prior, which evaluates a global similarity between distributions, and (ii) a smoothness prior to avoid the occurrence of small, isolated regions in the solution. Obtained via recent bound-relaxation results, the optima of the cost functions yield the complement of the tumor region or edema region in nearly real-time. Based on global rather than pixel wise information, the proposed algorithm does not require an external learning from a large, manually-segmented training set, as is the case of the existing methods. Therefore, the ensuing results are independent of the choice of a training set. Quantitative evaluations over the publicly available training and testing data set from the MICCAI Multimodal Brain Tumor Segmentation 2012 challenge (BraTS 2012) demonstrate that the proposed algorithm yields a competitive performance. Over the real data of the mentioned challenge, our algorithm was well ranked for complete edema and tumor segmentation among the nine competing methods [14]. Our work builds on the Bhattacharyya-similarity bound derived by our co-author in a preliminary conference paper [26]. The following lists the main contributions of this study and the differences between our work and [26]:(1) The main contribution of [26] is theoretical and focuses on the optimization aspects of the work. Specifically, it details the derivation of a bound of the Bhattacharyya measure, which allows using graph cuts. However, the proof-of-concept experiments in [26] were limited to color photographs and were based on an unrealistic assumption where the model distribution is learned from the ground truth. There are no medical imaging applications in [26]. In this work, we extend the application of the Bhattacharyya bound to the real problem of 3D Multimodal MRI Brain Glioma Tumor and Edema Segmentation.(2) We report completely novel results, including quantitative evaluations/comparisons on the publicly available training and testing data set from the MICCAI multimodal brain tumor segmentation challenge (BraTS 2012). The results demonstrate that the proposed algorithm can yield a highly competitive performance among nine other competing algorithms.(3) In this submission, we added new algorithmic components, which were designed specifically for multi-modal edema segmentation. The work in [26] cannot be applied directly to our problem; it did not consider any medical imaging application.(4) To the best of our knowledge, our work is the first to investigate the idea of distribution matching in the context of brain tumor segmentation. Furthermore, it is the first to design a distribution matching algorithm in an interactive way, where the prior model is learned interactively from the current image data. Unlike the existing brain tumor segmentation methods, our work removes the need for and dependence on extensive learning from a large, manually segmented training set. In practice, this is an important advantage over the existing brain tumor segmentation algorithms.The remainder of this paper is arranged as follows. Section 2 introduces the Multimodal Brain Tumor Segmentation Benchmark (BraTS2012 data). Section 3 describes the segmentation methodology. Section 4 reports the experimental results and contains a discussion. Finally, the conclusion's section draws several perspectives of this work.The results reported in this research were based on approved evaluations using the Multimodal Brain Tumor Segmentation Benchmark (BraTS 2012 data) [14]. This section describes in details the data sets, notations and evaluation metrics that we used in this work. The Multimodal Brain Tumor Segmentation data set was introduced in the MICCAI 2012 Challenge by B. Menze, A. Jakab, S. Bauer, M. Reyes, M. Prastawa and K. Van Leemput [14]. This large and publicly available training and testing dataset was very useful and allowed us to compare efficiently our algorithm to others participating in the challenge. In the remainder of the paper, we will refer to this dataset as BraTS2012. We followed the standard evaluation protocol used for all algorithms via an online system provided by the Virtual Skeleton Database [17].BraTS2012 aims mainly at validating various segmentation approaches by evaluating and comparing 3D MRI brain tumor and edema segmentation algorithms. Segmenting brain tumors from multi-modal imaging data is one of the most challenging tasks in medical image analysis due to their unpredictable appearance and shape. Although many different segmentation approaches have been proposed in the literature during the past few years, it would be so hard to compare the existing methods because the validation datasets that could be used could differ widely in terms of input data regarding specifically structural MRI contrasts; MRI perfusion or MRI diffusion data... Other difficulties could be related to the type of lesion as it could be primary or secondary tumors; solid lesion or infiltrated growing lesion, as well as the state of the pathology (pre- or post-treatment). In order to surmount some difficulties regarding the current state-of-the-art in automated brain tumor segmentation and assure possible comparisons between different methods, a Multimodal Brain Tumor Segmentation (BraTS2012) challenge has been organized in conjunction with the MICCAI 2012 conference. For this purpose, a large dataset of brain tumor MRI scans was hence available in which the tumor and edema regions have been manually delineated. In fact, the ground-truth segmentations for tumor and edema for training data as well as the quantitative evaluation results were seriously studied.A publicly available set of training data could be downloaded from Kitware/MIDAS [17] or from the Virtual Skeleton Database [16]. The training data regroups real and simulated data. It consists of multi-contrast MRI scans (T1, T2, FLAIR, and post-Gadolinium T1) of both low grade and high grade glioma patients with expert annotations for “active tumor” and for “edema”. The simulated images closely follow the conventions used for the real data, except that their names start with “SimBraTS”.Each MRI modality is characterized by (i) the Repetition Time (TR), which represents the time between successive applications of radiofrequency pulse sequences, and (ii) the Echo Time (TE), which represents the delay before the radiofrequency energy radiated by the tissue in question is measured. The T1-weighted modality (T1) is characterized by a short TR and a short TE. This Provides better anatomic details. The T2-weighted modality (T2) is characterized by a long TR and a short TE. It is more sensitive to water content and, as a result, more sensitive to pathology. The Fluid Attenuated Inversion Recovery (FLAIR) modality is characterized by a long TR and a short TE. It removes the signal from the cerebrospinal fluid (CSF), thereby allowing a clearer visualization of the cerebral edema. The T1-weighted with gadolinium contrast agent (T1C) modality is characterized by the enhancement of the malignant tumor due to the contrast agent.All MRI scans and ground truth segmentations are stored using unsigned 16 bit and unsigned 8 bit integers, respectively. All volumes were linearly co-registered to the T1 contrast image, skull stripped, and interpolated to 1mm isotropic resolution. The MRI scans were distributed in the ITK and VTK compatible format and stored as signed 16-bit integers, but only positive values could be used. The manual segmentations (file names ending by “truth.mha”) have only three intensity levels: 1 for edema, 2 for active tumor, and 0 for everything else.The total number of training cases is 80, including:•25 High-Grade simulated images: SimBraTS_HG. A number is further added to denote each of the cases, e.g., SimBraTS_HG0001 for the first case;25 Low-Grade simulated images: SimBraTS_LG;20 Real High-Grade images: BraTS_HG; and10 Real Low-Grade images: BraTS_LG.This testing data is similar to the training data, except that the reference segmentations are not publicly available. Automated segmentations should be uploaded directly to the evaluation page to obtain dice metric scores. The total number of testing data is 30 and could be referred as follows:•10 High-grade simulated images: BraTS Challenge Sim High Grade;5 Low-grade simulated images: BraTS Challenge Sim Low Grade;11 Real high-grade images: BraTS Challenge High Grade; and4 Real low-grade images: BraTS Challenge Low Grade.In summary, BraTS2012 is a very heterogeneous and diversified dataset and, therefore, could be considered as a very realistic testing benchmark.We performed quantitative evaluations using the well-known Dice Metric (DM) [18] by computing the affinities between ground-truth segmentations provided with BraTS2012 dataset and the obtained results. DM takes values within the interval [1], where 1 indicates a perfect match and 0 a complete mismatch. For the testing data, the ground-truth segmentations were not publicly available. However, automated segmentations should be uploaded directly to the evaluation page to obtain dice metric score [17].The challenge training data results highlight four top-ranked methods [5,4,12,19]. The authors of [5] presented an automatic algorithm based on learning a model of intensity for each patient in order to determine the initial probabilities. They used a classification forest (CF) with spatially non-local features to represent the data, and estimated tissue classes by providing the CF with initial probabilities. The study in [4] presented a fully automated algorithm using random forest classification with hierarchical conditional random field regularization in an energy minimization scheme. The method presented in [12] built on the discriminative random decision forest framework to provide a voxel-wise probabilistic classification of the volume. The authors in [19] presented a semi-automatic method, where the user should draw manually a diameter to define the foreground region and a box limiting the background region [19]. The method computes tumor and background strengths, and use a level set surface to delineate the tumor. All the results obtained on the BraTS2012 dataset were made available on the challenge website. In the rest of this paper, we will refer to the algorithms in [4,5,12,19] as Bauer et al., Zikic et al., Geremia et al. and Hamamci et al., respectively. These methods will be used in our comparisons to demonstrate the performance of the proposed method on the training dataset. For the testing data, we used the online tool provided by the Virtual Skeleton Database.Because we use multi-modal MRI, we need to denote each modality. We will use notation Ii, where i∈(T1, T2, T1C, FLAIR). IT1 denotes the T1 modality, IT2 the T2 modality, IT1C the T1C modality and IFLAIRthe FLAIR modality. The ground-truth segmentation of each case will be denoted by GT added to the case type and number, e.g., GTHG0001 (Fig. 1). Before describing the segmentation processes, let us first consider the following definitions and notations:•SRT1 is the segmentation result obtained for T1 modality image IT1;SRT2 is the segmentation result obtained for T2 modality image IT2;SRT1C is the segmentation result obtained for T1C modality image IT1C;SRFLAIRis the segmentation result obtained for FLAIR modality image IFLAIR.ISumT1CFLAIRis the summation of SRT1C and image IFLAIRas shown in Fig. 2and could be defined by:(1)ISumT1CFLAIR=SRT1C+IFLAIR‘+’ represents the normalized summation process.We can also define:•ISumT1CT1is the summation of SRT1C and image IT1ISumT1CT2is the summation of SRT1C and image IT2ISumT2T1Cis the summation of SRT2 and image IT1CISumT2T1is the summation of SRT2 and image IT1ISumT2FLAIRis the summation of SRT2 and image IFLAIRIn this section, we describe the different steps of our approach for brain tumor and edema segmentation, which is based on distribution matching and is tested and validated using BraTS2012. First of all, we present a complete and convivial flow chart that describes the process; See Fig. 3.As depicted in Fig. 3, the MRI modalities are used as follows: the T1C modality is used for high grade tumor segmentation, the T2 for low grade tumor segmentation and the FLAIR modality for edema segmentation. The latter could involve both high and low Grade tumor and would necessitate one preprocessing stage.The tumor region presents different gray level intensities compared to the normal brain tissue. Therefore, we can define two different parts:ΩI¯, which represents the normal part (Fig. 4) and ΩI, which represents the searched tumor region. From the normal part, we estimate a non-parametric model distribution of intensity MI. Such a model would be then a prior that contains all the statistical information about the image within the normal regions in the considered brain image. The main step of the algorithm consists of finding within the suspected tumor region RIa sub-region whose intensity distribution most closely matches the learned model, i.e. MI. We extract then the normal part from the infected one, and therefore the targeted tumor region. We state the problem as the optimization of an energy function containing (1) an intensity distribution matching prior that measures a global similarity between non-parametric distributions, and (2) a smoothness prior that avoids the occurrence of small, isolated regions in the solution.For high or low grade brain tumor segmentation, image I could be one of the following inputs:(2)I∈{IT1C,ISumT2T1C,ISumT1T1C,ISumFLAIRT1C}for high gradet umor(3)I∈{IT2,ISumT1CT2,ISumT1T2,ISumFLAIRT2}for low grade tumorletI:ΩI⊂DI⊂ℝn(n∈{2,3})→ZIbe an image function defined from a fixed domain ΩIto the spaceZIof intensity values. DIis the whole domain of image I. ΩIwould be a subset of the whole image domain containing the tumor. Fig. 4 shows a typical T1C example in which the blue line is used to divide the whole image domain DIinto two parts. In this example, ΩIcorresponds to the right-hand part of the image and represents the suspicious pathological part (i.e., the part that contains the suspected tumor).ΩI¯=DI\ΩIdenotes the complement of ΩIwithin DI, which represents the normal part (i.e., not including the tumor region). MI(z) would be the kernel density estimate for the gray level distribution of image I withinΩI¯.(4)∀z∈ZIMI(z)=∑p∈ΩI¯K(z)A(ΩI¯)whereA(ΩI¯)denotes the area (or volume) ofΩI¯(i.e., the number of pixels/voxels within the region), and K(z) is a kernel function, typically Gaussian:(5)K(z)=12πσ2exp−(z−μ)22σ2,where σ is the kernel width and μ is the expected value.MIis a prior model, which contains all the statistical information about image I within the normal regions. The main step of the algorithm consists of finding within ΩI(i.e., the abnormal part) a region RIwhose intensity distribution most closely matches model MI(Refer to Fig. 4 for a typical example). We obtain therefore the normal part, which represents the non-tumor region in ΩI. This yields the searched tumor region: ΩI\RI. We state the problem as the minimization of a discrete cost function with respect to a binary labelingLI:ΩI→0,1, which defines a variable partition of the image domain:RI=p∈ΩI|LI(p)=1, corresponding to the normal part, andRI¯={p∈ΩI/LI=0}=ΩI\RI, corresponding to the tumor region. The optimal labeling is obtained by minimizing a global cost function containing a non-linear distribution matching constraint based on the Bhattacharyya measure and a smoothness constraint. To introduce the cost function, let us first introduce the following notations for any binary labelingLI:ΩI→0,1:•PRIis the Kernel Density Estimate (KDE) of the distribution of image data I within RIregion.(6)∀z∈ZIPRI(z)=∑p∈RIK(z)A(RI)where A(RI) denotes the area (or volume) of RI.BZ(f,g)is the Bhattacharyya coefficient, which measures the amount of overlap between two distributions f and g defined over a set of valuesZI:(7)BZ(f,g)=∑z∈ZIf(z)g(z)The algorithm consists of finding an optimal labelingLIoptthat minimizes the following cost function:(8)LIopt=argminLI:ΩI→0,1FI(LI),with(9)FI(LI)=−BZ(PRI,MI)︸Distribution matching+λS(LI)︸SmoothnessS(LI) is a smoothness prior, which regularizes the segmentation boundary [6]:(10)S(LI)=∑{p,q}∈Nrp,qδLI(p)≠LI(q)with(11)δx≠y=1ifx≠y0ifx=y,andrp,q=1∥p−q∥N is some neighborhood system containing all pairs {p, q} neighboring elements in ΩI. The smoothness prior (or regularization) avoids the occurrence of small, isolated regions in the solution. λ is a positive constant that balances the relative contribution of the distribution matching term and the regularization term.LIoptgives an optimal boundary-smooth region,RIopt={p∈ΩI/LIopt(p)=1}, whose intensity distribution most closely matches MI. This optimal region would be expected to correspond to the non-tumor region or non-edema region in ΩI. Therefore, the tumor (or edema) region would be finally computed fromLIoptas follows:(12)SRI=ΩI\RIopt={p∈ΩI/LIopt(p)=0}The distribution matching term in (9) is a higher-order (non-linear) functional, which is difficult to optimize [20,21]. It has an analytical form that cannot be directly amenable to fast optimizers such as graph cuts [22] or convex-relaxation techniques [23]. In the segmentation literature, such non-linear terms are commonly optimized via standard gradient-descent procedures, e.g., active curves and level sets [24,25], which result in computationally intensive algorithms [26]. In this work, we use the recent bound optimization result in [26]. Rather than optimizing directly the initial functional (i.e. the Bhattacharyya coefficient in our case), one can solve a sequence of easier sub-problems, each corresponding to a bound of the functional.A(u, ui) is an auxiliary function of a cost function FI(u) if it satisfies the following conditions:(13)FI(u)≤A(u,ui),i>1(14)FI(u)=A(u,u)∀u∈0,1We optimize iteratively a sequence of instrumental functions, denoted A(u, ui),i≥1 in which i represents the iteration number and whose optimization is easier than FI(u):(15)ui+1=argminu∈0,1A(u,ui),i≥1Using the equality and inequality conditions in the definition of auxiliary function, one can easily show that the obtained sequence of solutions yields a decreasing sequence of the original function FI(u):(16)FI(ui)=A(ui,ui)≥A(ui+1,ui)≥FI(ui+1)Furthermore, the original function is lower bounded and, therefore, the sequence of solutions converges to a minimum of FI(ui).The authors of [26] derived an auxiliary functional of the Bhattacharyya measure. They further showed that such auxiliary functional is amenable to fast graph-cut optimization using the Boykov–Kolmogorov algorithm [22]. The bound-optimization process in [26] converges within a few iterations (typically less than 5).In this work, we use the auxiliary functional in [26] and the Boykov-Kolmogorov algorithm [22]. Further details on this auxiliary functional and bound optimization can be found in [26]. Also, the graph-cut algorithm of Boykov and Kolmogorov [22] is well established in the computer vision literature. Therefore, we omit the details of graph cut optimization here.Brain edema segmentation is an additional step within our developed system, where we could clearly differentiate the tumor region from the edema region, an output highly demanded in clinical practices. According to the conceived algorithm, one could design the same segmentation process but beginning with a preprocessing step necessary for FLAIR modality so as to clarify the edema shape.To segment the brain edema, we proceeded to the following preprocessing steps onIFLAIRfinalso as to create a new image (refer to Fig. 5for the details of creating imageIFLAIRfinal):1We create an intermediate imageIFLAIRinterdefined by(17)IFLAIRinter=SRT1C+IFLAIRLetIFLAIRsymVbe the image obtained from IFLAIRby vertical symmetry andIFLAIRsymHthe image obtained from IFLAIRby horizontal symmetry. We create a new imageIFLAIRmultdefined by:(18)IFLAIRmult=SRT1C·IFLAIRsymVif the tumor is within one hemisphereIFLAIRmult=SRT1C·IFLAIRsymHif the tumor is shared by the two hemispheresFinally, we defineIFLAIRfinalas follows:(19)IFLAIRfinal=IFLAIRmult+IFLAIRinterWe used the same distribution matching process to obtain an optimal regionEFLAIRedema. Finally, edema segmentations for high grade and/or low grade tumors could be obtained as follows:(20)EdemaFLAIRHG=RFLAIRedema·SRT1C(21)EdemaFLAIRLG=RFLAIRedema·SRT2In the end of this edema segmentation process, we have to define these following images in order to segment brain edema in the other image modalities (IT1C, IT1 and IT2):(22)ISumT1FLAIR=SRFLAIRfinal+IT1ISumT1CFLAIR=SRFLAIRfinal+IT1CISumT2FLAIR=SRFLAIRfinal+IT2whereSRFLAIRfinalis the tumor segmentation result obtained inIFLAIRfinal.Then, we use the same distribution matching process with the following image inputs:(23)I=ISumT1CFLAIRfor segmenting the T1C modality;ISumT1FLAIRfor segmenting the T1 modality;ISumT2FLAIRfor segmenting the T2 modality.In this section, we report quantitative evaluations of the proposed methodology over the publicly available training data set from the Multimodal Brain Tumor Segmentation 2012 challenge (BraTS 2012). Also, we report comparisons with the top ranked methods in the challenge [5,4,12,19]. This section would be further supported by several visual illustrations, which would depict typical examples of the obtained results using the different types of images in the data set. We also give plots that would detail the obtained performance for each case in the data set. The Mean Dice Metric “MDM” was chosen as a measure of such performance (see Section 2.4). The implementation results for the training data would be presented first followed by the implementation for the testing data and this would be followed by discussions on these experimental results. As an important and valuable procedure for each implementation (training as well as testing datasets), we had opted for the simulated cases first, followed by the real cases (Fig. 6).We present several segmented MRI images as visual examples, along with a detailed performance evaluation in term of DM measure obtained for the training data. Fig. 7depicts the segmentation obtained on the third case of SimBraTS_HG, and Fig. 8shows the result of case 23 in SimBraTS_LG. The blue curve illustrates the obtained tumor boundary, the red curve corresponds to the edema boundary, the yellow curve involves the tumor ground truth and the green curve corresponds to the edema ground truth boundary.For the methodology performance, we evaluated the DM measure for the simulated cases involving 25 SimBraTS_HG as well as 25 SimBraTS_LG pathologies from the training dataset. Fig. 9illustrates the mean Dice Metrics as functions of the case number for high grade tumor (blue) and edema (red). Fig. 10illustrates the Dice Metrics for the low grade cases. The proposed algorithm scored a mean Dice Metric measure for complete tumor and edema segmentation higher than 0.86 for the simulated high grade cases and higher than 0.84 for the simulated low grade cases.We present several segmented MRI images as visual examples, along with a detailed performance evaluation in term of DM measures. Fig. 11depicts the segmentation obtained on the first case of BraTS_HG, and Fig. 12depicts the result of the first case in BraTS_LG. The blue curve illustrates the obtained tumor boundary whereas the red curve corresponds to the edema boundary. The yellow curve involves the tumor ground truth and the green curve corresponds to the edema ground truth.For the methodology performance, we evaluated the DM measure for the 20 BraTS_HG real cases as well as for the 10 BraTS_LG real cases from the training dataset. Fig. 13illustrates the mean Dice metrics as functions of the case number for high grade tumor (blue) and edema (red). Fig. 14illustrates the Dice metrics for the low grade cases.For complete tumor and edema segmentation, the proposed algorithm scored a mean Dice Metric measure higher than 0.89 for simulated high grade cases and higher than 0.88 for simulated low grade cases.Tables 1 and 2report the results of our algorithm and the methods in [5,4,12,19] respectively on simulated and real training data. The mean Dice Metrics in Tables 1 and 2 demonstrate a very competitive performance of the proposed algorithm, which outperformed all top-ranked methods on both synthetic and real training data. For instance, within the set of real data, the proposed algorithm scored a mean Dice metric (DM) higher than 0.80 for all cases (edema/tumor and low grade/high grade), whereas the best performance attained before by the competing algorithms is DM =0.73.In this part, we present quantitative evaluations of the proposed algorithm over the testing dataset from the MICCAI Multimodal Brain Tumor Segmentation 2012 live challenge. We report also comparisons with several other methods competing over the challenge data. This section is further supported by several visual illustrations, which depict typical examples of the obtained results using the different types of testing images. We also give plots that detail the obtained performance for each case in the data set. We used the mean Dice Metric as a measure of performance. Such a measure is computed with the online Virtual Skeleton Database evaluation tool.We present several segmented MRI images as visual examples, along with a detailed performance evaluation in term of the obtained DM measures. Fig. 15depicts the segmentation obtained on case 168 of BraTS Challenge Sim High Grade, and Fig. 16shows the result of case 5 in BraTS Challenge Sim Low Grade. The blue curve illustrates the obtained tumor boundary and the red curve corresponds to the edema boundary.For the methodology performance, we evaluated the DM measure for the 10 BraTS Challenge Sim High Grade as well as for the 5 BraTS Challenge Sim Low Grade from the testing dataset. Fig. 17illustrates the Dice metrics as functions of the case number for high grade tumor (blue) and edema (red). Fig. 18plots the Dice metrics for the low grade cases.For complete tumor and edema segmentation, the proposed algorithm scored a mean Dice Metric measure higher than 0.91 for simulated high grade cases and higher than 0.84 for simulated low grade cases.We present several segmented MRI images as visual examples, along with a detailed performance evaluation in term of the DM measures obtained for the real testing data. Fig. 19depicts the segmentation obtained on the third case of BraTS Challenge High Grade 0119, and Fig. 20shows the result of the first case in BraTS Challenge Low Grade0109. The blue curve depicts the obtained tumor boundary and the red curve corresponds to the edema boundary.For the methodology performance, we evaluated the DM measure for the 11 BraTS Challenge High Grade as well as for the 4 BraTS Challenge Low Grade from the testing dataset. Fig. 21illustrates the Dice metrics as functions of the case number for high grade tumor (blue) and edema (red). Fig. 22plots the Dice metrics for the low grade cases. For complete tumor and edema segmentation, the proposed algorithm scored a mean Dice Metric measure higher than 0.9 for real high grade cases and higher than 0.64 for real low grade cases.Table 3reports the results of our algorithm and the other competitors. The final results can be found at the Virtual Skeleton Database BraTS 2012. We used both real (BraTS Challenge High Grade and BraTS Challenge Low Grade) and simulated (BraTS Challenge Sim High Grade and BraTS Challenge Sim Low Grade) data from the BraTS2012 testing dataset. The mean Dice metrics in Table 3 demonstrate a very competitive performance of the proposed algorithm.

@&#CONCLUSIONS@&#
