@&#MAIN-TITLE@&#
Controlling the workload of M/G/1 queues via the q-policy

@&#HIGHLIGHTS@&#
We study an M/G/1-type queue with an arrival process controlled by the q-policy.The effects of the q-policy on several performance measures are considered.We obtain the steady-state integral equation for the pdf of wait.Reducing busy period lengths via a q-policy can also lead to increased profits.A modified accumulating priority queue is also considered.

@&#KEYPHRASES@&#
Queueing,Customer blocking,Level crossing analysis,M/G/1 queue with accumulating priority,

@&#ABSTRACT@&#
We consider a single-server queueing system with Poisson arrivals and generally distributed service times. To systematically control the workload of the queue, we define for each busy period an associated timer process, {R(t), t ≥ 0}, where R(t) represents the time remaining before the system is closed to potential arrivals. The process {R(t), t ≥ 0} is similar to the well-known workload process, in that it decreases at unit rate and consists of up-jumps at the arrival instants of admitted customers. However, if X represents the service requirement of an admitted customer, then the magnitude of the up-jump for the timer process occurring at the arrival instant of this customer is (1 − q)X for a fixed q ∈ [0, 1]. Consequently, there will be an instant in time within the busy period when the timer process hits level zero, at which point the system immediately closes and will remain closed until the end of the current busy period. We refer to this particular blocking policy as the q-policy. In this paper, we employ a level crossing analysis to derive the Laplace–Stieltjes transform (LST) of the steady-state waiting time distribution of serviceable customers. We conclude the paper with a numerical example which shows that controlling arrivals in this fashion can be beneficial.

@&#INTRODUCTION@&#
We study an M/G/1-type queueing model in which the arrival process is controlled by a system manager so as to decrease the lengths of the general busy period. In some applications, for example, a system manager may be more inclined to regularly decrease the overall length of the busy period if it is the case that the server/machine becomes highly susceptible to expensive breakdowns after operating for extended periods of time. These breakdowns can be costly both in terms of the repair costs and the opportunity costs due to closures of the system. To alleviate the risk of incurring an expensive breakdown, a system manager may want to rest the server/machine during closedown periods on a regular basis. In addition, cost-effective maintenance checks can be performed during these rest periods to ensure the long-run functionality of the machine.In this paper, we present one such policy which would allow a system manager to control the busy period lengths. Specifically, during each busy period, the control is exercised by closing the system to potential customers over a constant proportion of the overall busy period. The flexibility to disallow (or to block) customers from entering the system may be desirable if, for instance, a holding cost for customers during their sojourn in the system exists. The main focus of our research is to study the effect of the new policy, which we refer to as the q-policy, on various performance measures of interest such as the length of busy periods and the wait of serviceable customers.The literature on the optimal design and control of queueing systems is quite extensive. In regards to the arrival control of queueing systems, the usual goal is to find the optimal policy which maximizes (or minimizes) a specific objective function. In the seminal paper by Naor (1969), an M/M/1-type queueing system is studied where the arrival process is controlled by the administration of a toll charge for arriving customers. In particular, customers receive a fixed reward K upon successful service but also incur a holding cost h per unit time spent in the system. Naor studies the optimal policies from two perspectives, namely: (i) individual optimization, where the objective function is the individual expected net benefit rate function, and (ii) social optimization, where the objective function is the expected overall net benefit rate function. Naor assumes that the optimal policies for both problems is of the critical number form (i.e., customers are accepted for service if the number of customers currently occupying the system is less than the critical number), and this form of optimal policy can be validated through the use of Markov decision processes (see Stidham, 2002 and references therein). Under this framework, Naor establishes a key result which states that an individually optimal policy admits more customers than its counterpart, the socially optimal policy.Naor’s work inspired several other researchers to consider various generalizations for both the model and the net benefit structure. Rosenshine and Rue (1981) considered Naor’s model and studied the effect of the arrival rate on the parameters for both kinds of optimal policies. Yechiali (1971) extended Naor’s work by relaxing the assumption of the arrival process to be merely a renewal process. The M/M/s variant was considered by Knudsen (1972) where Naor’s main result was shown to still hold true. Doshi (1977) considered the continuous-time arrival control of an M/G/1 queueing system which operated under a policy that opened and closed the system to potential arrivals depending on the level of the workload. In Johansen and Stidham (1980), the authors showed that Naor’s main result actually holds true under a set of fairly general conditions (e.g., dependent arrivals, batch arrivals, and random rewards). For excellent surveys of the literature, we refer the interested reader to Stidham (1985); 2002). To the best of our knowledge, the q-policy presented here has not been previously studied.The optimal policies found by these researchers have usually resulted in the formulation of threshold-form policies (i.e., thresholds for the number of customers in the system or for the residual workload). We emphasize, however, that our focus is not one that searches for an optimal policy which maximizes a specific objective function, but instead analyzes the effects of a given policy which aims to lessen the workload of a system. Nonetheless, we do, in Section 6, formulate an optimization problem which illustrates that, in certain situations, the reduction of the busy cycle lengths via the q-policy can result in increased profits.The rest of the paper is organized as follows. In Section 2, we introduce the queueing model and the q-policy. Section 3 is devoted to the study of the busy period as well as some fundamental steady-state probabilities associated with the system. The steady-state distribution of the waiting time of serviceable customers is analyzed in Section 4 by virtue of the level crossing methodology. In Section 5, we present a model which enables a system manager to block customers during busy periods similar to the q-policy, but has the property that it does not require knowledge of the service times upon arrival. Finally, following the numerical example in Section 6, we offer some concluding remarks and a discussion regarding potential future work in Section 7.We consider a queueing system which is of M/G/1-type. We assume that the Poisson arrival rate of customers to the system is λ > 0. If the system is open (i.e., accepting new customers) when a customer arrives, then this customer joins the queue. Otherwise, the customer is lost and unrecoverable. In Section 6 of this paper, we present an optimization problem which shows that in certain situations it may be desirable to block or prevent customers from entering the system. Let {Xi, i = 1, 2, …} denote the sequence of independent and identically distributed (iid) customer service times having common meanμ=E(Xi)and common second momentγ=E(Xi2). Similar to the model studied by Johansen and Stidham (1980), the customer service times are assumed to be known to the server (or system manager) immediately upon a customer’s entry to the system. We denote the corresponding distribution function and Laplace–Stieltjes transform (LST) by(1)B(x)=P(Xi≤x)andB˜(s)=∫0∞e−sxdB(x),respectively. Service is conducted by order of arrival (i.e., first-come-first-serve or FCFS for short). We denote the traffic intensity of the classical (i.e., unblocked) M/G/1 system, as usual, by ρ = λμ. Note that we reserve the notationB¯(x)=P(Xi>x)for the complementary distribution function of B( · ), and further that this style of notation will also be adopted for other complementary distribution functions throughout the paper.Before we formally introduce the q-policy, we recall that for an arbitrary busy period of the classical (work-conserving) M/G/1 queue, any customer who arrives during this busy period will always be admitted for service (i.e., they will eventually be served in this busy period). However, suppose that a system manager would like to restrict (or control) the arrival process during a busy period, so that the system is not obligated to serve all customers who arrive during the busy period. In such a situation, a system manager could, for intervals of time within the busy period, close the system to potential arrivals. A blocking policy provides a set of guidelines which allows a system manager to administrate the openings and closures of the system. We denote such a policy in general by π(t), where π(t) = 1 implies that the system is open at time t, and similarly π(t) = 0 implies that the system is closed at time t. An example of such a blocking policy is the q-policy, denoted by πq( · ), which we define next.Definition 2.1 (Theq-policy) Without loss of generality, assume that a customer arrives to an empty queue at time τ1 = 0, thereby initiating the start of a busy period. For all t ≥ 0 during this busy period, we define the process {R(t), t ≥ 0}, which is similar to the workload process. In particular, for 0 ≤ q ≤ 1:1.R(0) = (1 − q)X1, where X1 is initial customer’s service time.R(t) decreases at unit rate unless the process is at level 0.For the sequence of customer arrival epochs, {τi, i = 2, 3, …}, during this busy period,(2)R(τi)={R(τi−)+(1−q)XiifR(τi−)>0,0ifR(τi−)=0,whereR(t−)=limϵ→0R(t−ϵ).Then, for all t ≥ 0 during this busy period,(3)πq(t)={1ifR(t)>0,0ifR(t)=0.The process {R(t), t ≥ 0} acts as a timer for the busy period. That is, R(t) represents the time remaining, at time t, before the system is closed to potential arrivals.Fig. 1illustrates a busy period under the q-policy. Here, at some time during the servicing of the third customer, C3, the timer becomes drained (i.e., R( · ) hits level 0), at which point the system becomes closed for potential arrivals. Hence, both customers C5 and C6 are blocked from entering the system. It is important to note that, although the system is closed at this point, the server must still complete the servicing of C3 and C4. In other words, the busy period terminates when all admitted customers have been fully served. Moreover, the end of the busy period signals the reopening of the system and the commencement of the ensuing idle period which ends at the next customer arrival instant. The busy period and the subsequent idle period together form a busy cycle.Clearly, under the q-policy, the resulting busy periods are stochastically smaller than those corresponding to a system not implementing any sort of blocking policy. It is also apparent that if we set q = 0, then {R(t), t ≥ 0} exactly becomes the workload process during a busy period in the classical M/G/1 queue. In fact, a blocking proportion equal to zero simply implies that no customers are blocked from service, and thus the resulting model is equivalent to the classical M/G/1 queue. Moreover, we obtain the M/G/1/1 queue as a special case when q = 1.In this section, we first establish a functional equation for the LST corresponding to the distribution of the busy period duration operating under the q-policy. Let T be the length of such a busy period, whose distribution function and LST are denoted by G(x) andG˜(s),respectively.To derive the LST of T, we note that the order in which serviceable customers are served does not, in any way, affect the duration of the busy period. As in the classical case, this important observation leads to the derivation of a functional equation forG˜(s). We now introduce a new service discipline which we refer to as the q-restricted last-come-first-serve (q-restricted LCFS for short) discipline. First of all, recall that {R(t), t ≥ 0} consists of up-jumps at the arrival epochs of each serviceable customer, and further that the magnitude of the jump is equal to the service time of the customer multiplied by (1 − q). Let us refer to these entities simply as the unblocked portions of the service times. Now, the order of service determined by the q-restricted LCFS discipline is precisely the order of service obtained by applying the usual LCFS discipline to a system in which the unblocked portions are effectively considered as the actual service times (i.e., (1 − q)Xiinstead of Xi).Fig. 2demonstrates the q-restricted LCFS discipline in a typical busy period. Again, we determine the order of service under this discipline by effectively considering the unblocked portions as the actual service times. Specifically, in Fig. 2, one can determine the order of service by projecting the arrival epochs to the axis a* and applying the usual LCFS discipline. Moreover, under the q-restricted LCFS discipline, we see that the interval of time during which R(t) is positive (i.e., the system is open to accepting new customers) can be decomposed into smaller, well-understood sub-intervals of time. Indeed, these sub-intervals are merely the acceptance periods of their corresponding sub-busy periods. For example, in Fig. 2, C4 generates a sub-busy period in which C5 and C6 both are serviced; the length of the acceptance period for this sub-busy period is equal to (1 − q) × (X4 + X5 + X6). It is clear that these sub-busy periods are identically distributed to the overall busy period (generated by C1). However, we do note that in the intermediate sub-busy periods (i.e., sub-busy periods generated by C4 and C3 in Fig. 2), customers who fail to arrive in their acceptance periods are not blocked from the system, but instead are serviced in the next sub-busy period.Theorem 3.1If λ(q) = λ(1 − q) and ρ(q) = λ(q)μ < 1, then T has a proper (i.e., non-defective) distribution and its corresponding LST satisfies the functional equation(4)G˜(s)=B˜(s+λ(q)(1−G˜(s))).Similar to the LST derivation of the busy period duration in the classical M/G/1 queue (e.g., see Kleinrock, 1975, Section 5.8), we invoke the fact that T is independent of the service discipline, so long as it is a work-conserving one. Kleinrock’s derivation involves the usual LCFS discipline, but here, we employ the q-restricted LCFS discipline. Define N to be the number of customers who arrive during the unblocked portion of the initial customer’s service time. As discussed above, each of the N customers generates a sub-busy period of their own which is identically distributed to the overall busy period and, moreover, is mutually independent from the others.Conditioning on both N = n and the first service time X1 = x, we obtain(5)E(e−sT|X1=x,N=n)=e−sx(G˜(s))n.Given X1 = x, N is Poisson distributed with rate λ(q)x, and this leads to(6)E(e−sT|X1=x)=e−sxe−λ(q)x∑n=0∞(λ(q)xG˜(s))nn!=e−x(s+λ(q)−λ(q)G˜(s)).Lastly, removing the condition on X1 immediately yields(7)G˜(s)=E(e−sT)=B˜(s+λ(q)(1−G˜(s))),and the result is proven.□As in the classical case, we are left with an implicit expression for the LST of T. Nonetheless, we are still able to obtain the moments of T through successive differentiation. In particular, the first two moments of T are:(8)E(T)=μ1−ρ(q),(9)E(T2)=γ(1−ρ(q))3.Remark 3.1Theorem 3.1 implies that the busy period under the q-policy is distributed equivalently to the busy period of a classical M/G/1 queue with arrival rate λ(q) and service time distribution B( · ). Furthermore, the busy period is also equivalently distributed to the busy period of the following M/G/1 system with a Bernoulli-type blocking policy:(i)customers arrive according to a Poisson process with rate λ > 0;at each customer arrival epoch, the server conducts a Bernoulli experiment, where with probability (1 − q) the customer is admitted for service, and with probability q the customer is blocked.A commonality of this model with the system under the q-policy is that during busy periods, the probability that an arriving customer is blocked from entering the system is precisely q.We next establish the form of the probability generating function (pgf) for Nbp, the number of customers served in a busy period. We definem(z)=E(zNbp)to be the pgf of Nbp. Like the duration of the busy period T, the number served in a busy period is unaffected by the order of service. Hence, by implementing the q-restricted LCFS discipline, we obtain(10)E(zNbp|N=n)=E(z1+M1+M2+⋯+Mn),where N is the number of customers in the initial queue (i.e., those customers arriving during the unblocked portion of the initial customer’s service time) and Midenotes the number of customers served in the ith customer’s sub-busy period. By independence, we have(11)E(zNbp|N=n)=z(m(z))n.It immediately follows, by removing the condition on N, that(12)m(z)=zB˜(λ(q)(1−m(z))),from which the first moment of Nbp is clearly given by(13)E(Nbp)=11−ρ(q).To conclude this section, we shift our focus to the derivation of some key steady-state probabilities of the system, namely:PI≡steady-stateprobabilitytheserverisidle;PB≡steady-stateprobabilitytheserverisbusy;PB,0≡steady-stateprobabilitytheserverisbusyandthesystemisclosed;PB,1≡steady-stateprobabilitytheserverisbusyandthesystemisopen.To obtain these probabilities, we apply the theory of regenerative processes (e.g., see Kao, 1996, Section 3.6). Define a busy cycle, D, to consist of a busy period T and the ensuing idle period I (i.e., D = T + I). Clearly, the set of regeneration points associated with D are the epochs defined by busy period commencements. Thus, from elementary renewal theory, we readily obtain:(14)PI=E(I)E(D)=1−ρ(q)1+ρq,(15)[1.5mm]PB=E(T)E(D)=ρ1+ρq,(16)[1.5mm]PB,0=qPB=ρq1+ρq,(17)[1.5mm]PB,1=(1−q)PB=ρ(q)1+ρq.The motivation for our study of the virtual wait process stems from the well-known fact that for M/G/1-type queues, the distributions of virtual wait and actual wait are equivalent in steady-state. In what follows, we denote the (unfinished) workload process under a q-policy by {Uq(t), t ≥ 0}, whereas the virtual wait process is denoted by {Wq(t), t ≥ 0}.Obviously, {U0(t), t ≥ 0} and {W0(t), t ≥ 0} are the corresponding workload and virtual wait processes for the classical M/G/1 system. Now, for times t > 0 when the system is open (i.e., πq(t) = 1), one notes that Uq(t) behaves in the same manner as U0(t) in that:(i)Uq(t) decreases at unit rate, except during times of idleness;Uq(t) up-jumps at customer arrival epochs, with the magnitude of the jumps being equal to the arriving customer’s service time.On the other hand, for times t > 0 when πq(t) = 0, we have that Uq(t) decreases at unit rate. In particular, if t* > 0 is such that πq(t*) = 0 andπq(t*−)=1,then starting from time t*, the workload depletes at unit rate until it hits level 0. Now, similar to how {U0(t), t ≥ 0} and {W0(t), t ≥ 0} are equivalent processes, during times t when the system is open, the processes {Wq(t), t ≥ 0} and {Uq(t), t ≥ 0} are also equivalent. However, the virtual wait process is further complicated by the fact that during a closure period for the system, the process is essentially undefined (i.e., does not exist).Fig. 3depicts the sample paths of both processes for three consecutive busy periods of the system. The grey-shaded regions correspond to the times during which the system is closed (i.e., πq(t) = 0), and thus, also represents the times when Wq(t) is undefined. Customer arrival epochs are marked on the time axis with diamond symbols, and observe that both processes up-jump at arrivals occurring only during times when the system is open. As is also evident from Fig. 3, the instant in time at which the system becomes closed during a busy period is exactly the same instant in time that Wq(t) (or equivalently Uq(t)) hits level qTi, where Tiis the duration of the ith busy period. In what follows, we defineGq(x)=P(qT≤x)=G(x/q)as well asG˜q(s)=E(e−s(qT))=G˜(sq).In order to study the wait of admitted customers, it is clear that we must analyze the virtual wait process only during times of its existence. Hence, we introduce the censored virtual wait process{Wq(t),t≥0},as illustrated in Fig. 4. This process can be considered as {Wq(t), t ≥ 0} with the censorship (or removal) of the periods of non-existence. Indeed, by simply removing these periods, the resulting censored process will have a different time clock than the non-censored version. However, due to the memoryless property of the Poisson arrival process, the analysis of {Wq(t), t ≥ 0} during its times of existence must be equivalent to the analysis of{Wq(t),t≥0}.As is evident in Fig. 4, the sample path never continuously hits level 0 (unless q = 0), but instead always down-jumps to level 0. Furthermore, the magnitude of these down-jumps have distribution Gq( · ). This simple observation allows us to derive the steady-state integral equation for the probability density function (pdf) of the virtual wait (during times of its existence).We characterize the transient distribution of the censored virtual wait by the functions(18)Ft(x)=P(Wq(t)≤x),x≥0,t≥0;ft(x)=∂∂xFt(x),x>0,t≥0;P0(t)=P(Wq(t)=0),t≥0.}The steady-state distribution is obtained by letting t → ∞ in the functions of Eq. (18), resulting in(19)F(x)=limt→∞Ft(x),f(x)=limt→∞ft(x),andP0=limt→∞P0(t).When appropriate, we will use f(x; q) equivalently as f(x) to specify the value of q being used in the blocking policy. Also, in what follows, we extend the definition of P0(t) by defining P0(t) = 0 for all t < 0.If we consider the censored virtual wait process, letUt(x)andDt(x)denote the number of sample path up- and down-crossings of level x, respectively, during the time interval (0, t). Moreover, letDtc(x)(andDtj(x)) denote the number of continuous down-crossings (jump down-crossings) of level x in the time interval (0, t). Clearly,(20)Dt(x)=Dtc(x)+Dtj(x).Correspondingly, we remark thatUtj(x)=Ut(x)for all x ≥ 0. The ingenuity of the level crossing methodology lies in the principle of set balance (e.g., see Brill, 2008, Section 2.4.6). That is, in steady-state, the up-crossing and down-crossing rates of level x are equal:(21)limt→∞E(Dt(x))t=limt→∞E(Ut(x))t,(22)[1.5mm]limt→∞Dt(x)t=a.s.limt→∞Ut(x)t,where “a.s.” means almost surely, or with probability 1. Thus, to develop an integral equation for the steady-state pdf of the virtual wait (provided it exists), we must establish both the up- and down-crossing rates of level x. The next theorem provides the means to do so.Theorem 4.1The up- and down-crossing rates of level x are given by(23)limt→∞E(Ut(x))t=λB¯(x)P0+λ∫y=0xB¯(x−y)f(y)dy,x>0,(24)limt→∞E(Dtc(x))t=f(x),x>0,(25)limt→∞E(Dtj(x))t=λP0G¯q(x),x>0.The proof for both the up-crossing rate and the continuous down-crossing rate (i.e., Eqs. (23) and (24)) can be derived in the exact same manner as for the classical M/G/1 virtual wait process (e.g., see Brill (2008, Theorems 3.3 and 3.4)). Thus, we omit their proofs and only prove Eq. (25).To establish Eq. (25), we considerE(Dt+hj(x)−Dtj(x))for very small h. Clearly,Dt+hj(x)−Dtj(x)represents the number of jump down-crossings of level x in a small interval of size h. Thus,Dt+hj(x)−Dtj(x)can take values in the set of non-negative integers. Concerning the expectation of this quantity, we can obviously omit the case of it being equal to 0. In addition, it is not difficult to see thatP(Dt+hj(x)−Dtj(x)≥2)=o(h).Therefore, the only event we must really consider is whenDt+hj(x)−Dtj(x)=1. This event implies that a busy period initiates before time t, and also that sometime within the time interval (t, t + h), the server finishes processing all but the last qth proportion of the workload of this busy period (assume again that the system is empty at time 0). Conditioning on the length of this busy period leads to(26)P(Dt+hj(x)−Dtj(x)=1)=∫y=x/q∞λhP0(t−(1−q)y)dG(y)+o(h).The above result is obtained by recalling that the sample path immediately jumps down to level 0 as soon as the censored virtual wait process hits level qy. In particular, a jump down-crossing of level x will occur only if the busy period duration y is such that qy > x. Thus,(27)E(Dt+hj(x)−Dtj(x))=∫y=x/q∞λhP0(t−(1−q)y)dG(y)+o(h).Dividing the above equality by h and letting h → 0, we subsequently obtain(28)∂∂tE(Dtj(x))=λ∫y=x/q∞P0(t−(1−q)y)dG(y).It then follows (sinceE(D0j(x))=0) that(29)E(Dtj(x))=λ∫s=0t∫y=x/q∞P0(s−(1−q)y)dG(y)ds.Finally, Eq. (25) follows becauselims→∞∫y=x/q∞P0(s−(1−q)y)dG(y)=P0G¯q(x)via the dominated convergence theorem (e.g., see Parzen, 1962, Section 6–10).□If ρ(q) < 1, then(30)limt→∞Dtc(x)t=a.s.f(x),x≥0andlimt→∞Dtj(x)t=a.s.λP0G¯q(x),x≥0.By the memoryless property of Poisson arrivals, both{Dtj(x),t≥0}and{Dtc(x),t≥0}are (delayed) renewal processes. The desired result then follows from a well-known limiting theorem from renewal theory (e.g., see Parzen, 1962, Theorem 3A).□From Theorem 4.1, we can obtain an integral equation for the steady-state pdf of the virtual wait (provided it exists). Specifically, by using Eqs. (23)–(25) along with the balance rate equation given by Eq. (21), we end up with(31)f(x)+λP0G¯q(x)=λB¯(x)P0+λ∫y=0xB¯(x−y)f(y)dy.Remark 4.1An attractive feature of the level crossing technique is that we are able to intuitively explain each of the individual algebraic components of the resulting integral equation. We note that Eq. (31) is almost identical to that for the classical M/G/1 virtual wait, with only the addition of the second term on the left-hand side of the equality sign. This term (the jump down-crossing rate of level x) can be explained as follows: the rate that a busy period initiates is λP0, where the proportion of these busy periods that result in a jump down-crossing of level x isG¯q(x)=P(qT>x). The other terms are interpreted in the same manner as for the classical M/G/1 virtual wait.Letting x → 0 in Eq. (31) results in f(0+) = 0 where, in general, f(z+) = limε → 0f(z + ε). This result is as expected since f(x) represents the continuous down-crossing rate of level x, and under the q-policy, any sample path of{Wq(t),t≥0}never down-crosses level 0 continuously—it always jumps down to level 0.To find P0, we use the normalizing condition∫0∞f(x)dx+P0=1. Now,(32)∫0∞f(x)dx=λP0(μ−E(qT))+λ∫y=0∞∫x=y∞B¯(x−y)f(y)dxdy,which implies that∫0∞f(x)dx(1−λμ)=λP0(μ−qE(T)). Using Eq. (8), we get(33)∫0∞f(x)dx=P0ρ(1−ρ(q)−q)(1−ρ)(1−ρ(q))=P0ρ(1−q)(1−ρ)(1−ρ)(1−ρ(q))=P0ρ(q)1−ρ(q).Therefore, P0 = 1 − ρ(q). This result too is as expected, since P0 represents the long-run proportion of time that the server is idle conditional on the system being open for arrivals (i.e., conditional on the existence of the virtual wait process). From Eqs. (14) and (17), the long-run fraction of time the system accepts new customers is PI+ PB, 1 = (1 + ρq)−1. Thus, P0 = PI/(1 + ρq)−1.From Eq. (31), we can readily obtain the LST of the steady-state actual wait of serviceable customers.Theorem 4.3The LST of the steady-state waiting time of serviceable customers is(34)W˜(s)=(1−ρ(q))(s−λ+λG˜(qs))s−λ+λB˜(s).Clearly,W˜(s)≡∫0∞e−sxdF(x)=P0+∫0∞e−sxf(x)dx. Thus, the desired result is readily obtained by first multiplying both sides of Eq. (31) by e−sxand then integrating over x ∈ (0, ∞).□Alternatively, we can express the above LST as follows:(35)W˜(s)=(1−ρ(q))+ρ(q)W˜+(s),where W+ represents the stationary waiting time for those customers who are admitted for service upon their arrival but incur a positive wait time prior to entering service. We refer to W+ as the delayed waiting time whose LSTW˜+(s)is given by(36)W˜+(s)=(1−ρ(q))(G˜(qs)−B˜(s))μ(1−q)(s−λ+λB˜(s)).One can obtain the first moment of waiting time as usual by differentiatingW˜(s)and twice applying L’Hôpital’s rule. After some algebra, we acquire the following illuminating form of the mean waiting time:(37)E(W)=λ(q)γ2(1−ρ(q))×(1+σ(q)),where σ(q) = q/(1 − ρ(q)). We observe that the first term is equal to the average waiting time in the classical M/G/1 queue with arrival rate λ(q) and service time distribution B( · ). Clearly, σ(q) ≥ 0 since 0 ≤ q ≤ 1, which implies that a system under the q-policy has a greater average waiting time than a classical M/G/1 system with the aforementioned parameters.In addition, the first moment of waiting time can be rewritten as(38)E(W)=λγ2×κ(q),0≤q≤1,where(39)κ(q)=1−q1−ρ(q)(1+σ(q))=(1−q)(1−ρ(q)+q)(1−ρ(q))2.Differentiating κ(q) (with respect to q) yields(40)κ′(q)=−2q(1−ρ(q))3.Therefore, for ρ(q) < 1,E(W)is a decreasing function of q. ConsideringE(W)at the extreme values of q, we see that for q = 0,E(W)=λγ(1−ρ)−1/2which is the classical M/G/1 average waiting time without a blocking policy, and for q = 1, κ(1) = 0 so thatE(W)=0. The latter result is due to the fact that during busy periods, the system is closed to all potential arrivals, and above that, only customers who arrive to an idle server will be served (and these customers experience zero wait).Finally, we close this analysis by considering the first moment of delayed waiting time, namely:(41)E(W+)=E(W)ρ(q)=γ2μ×1−ρ(q)+q(1−ρ(q))2,0≤q≤1.It is indeed true that for q = 1, there is zero probability that an arbitrary customer will experience positive wait; however, as q → 1, we see thatE(W+)becomes(42)E(W+)|q=1=γμ.We recognize Eq. (42) as the mean of the limiting total-life random variable of a renewal process with B( · ) serving as the interarrival time distribution function (e.g., see Kao, 1996, Section 3.3).We now consider a slight variant of the M/G/1 queue operating under the q-policy. Specifically, we incorporate a closedown period, S, after each busy period. It is assumed that the sequence of successive closedown periods are iid with distribution functionA(x)=P(S≤x). The facility is closed to all potential arrivals during a closedown period. Thus, the incorporation of a closedown period will increase the proportion of customers that are blocked from the system. In addition, it is obvious that the closedown periods do not affect the waiting time distributions for serviceable customers, and so our analysis of waiting time in the previous subsections is still applicable.We view the total idle period as the durations of time when the server is not busy. Hence, similar to the partitioning of the steady-state probability of the system being busy, we define the following:PI,0≡steady-stateprobabilitytheserverisidleandthesystemisclosed;PI,1≡steady-stateprobabilitytheserverisidleandthesystemisopen.In this variation, the busy cycle remains D = T + I (note though that the closedown period is contained in I). Again, applying elementary renewal theory arguments, we obtain:(43)PI=E(I)E(D)=(1−ρ(q))(1+λE(S))(1+λE(S))(1+ρq)−λE(S)ρ,(44)[1.5mm]PI,0=E(S)E(I)PI=(1−ρ(q))λE(S)(1+λE(S))(1+ρq)−λE(S)ρ,(45)[1.5mm]PI,1=λ−1E(I)PI=1−ρ(q)(1+λE(S))(1+ρq)−λE(S)ρ,(46)[1.5mm]PB=E(T)E(D)=ρ(1+λE(S))(1+ρq)−λE(S)ρ,(47)[1.5mm]PB,0=qPB=ρq(1+λE(S))(1+ρq)−λE(S)ρ,(48)[1.5mm]PB,1=(1−q)PB=ρ(q)(1+λE(S))(1+ρq)−λE(S)ρ.Thus, the long-run fraction of time the system is accepting of new customers isPI,1+PB,1=[(1+λE(S))(1+ρq)−λE(S)ρ]−1.In order to implement the q-policy, a system manager must know the service times of the customers upon their arrival to the system. However, such knowledge may not always be available. In this section, we introduce another M/G/1-type queueing model which enables a system manager to reduce the length of busy periods, in a similar fashion as the q-policy, without the knowledge of service times upon arrival. This system is a variant of the M/G/1 queue with accumulating priority, which was recently studied by Stanford, Taylor, and Ziedins (2014).The first key aspect of the M/G/1 queue with accumulating priority has to do with how priority is accumulated for customers. Specifically, customers arrive to the system with zero initial priority and, throughout their sojourn in the system, earn priority linearly at rate ξ1 > 0. At service completion epochs, the customer with the greatest accumulated priority is serviced next. The second key feature of this model lies in the concept of an accreditation threshold, which increases linearly at rate ξ2 where 0 ≤ ξ2 ≤ ξ1. In fact, the accreditation threshold is a stochastic process which we denote as {Θ(t), t ≥ 0}. It is important to note that the accreditation threshold and its implementation does not, in any way, affect the order of service for customers. Hence, the way in which the M/G/1 queue with accumulating priority operates is actually equivalent to the classical M/G/1 queue under the FCFS discipline. However, the incorporation of the accreditation threshold does shed new light on the structuralization of the general busy period, providing a useful classification of those customers who arrive during busy periods.The above basic model was introduced by Stanford et al. (2014) in their analysis of a particular multi-class non-preemptive priority system. In order to analyze the M/G/1 queue with accumulating priority, these authors defined a new stochastic process which they called the maximal priority process. To incorporate a blocking policy into this system, we require a slight modification to their definition of the maximal priority process. We then establish the relation between our modified maximal priority process and the censored virtual wait process of the previous section. We exploit this relation to obtain the steady-state integral equation of the accumulated priority of serviceable customers.Upon arrival to the system, customers begin to accumulate priority at a linear rate. During busy periods, a customer will be admitted for service only if its priority overtakes (i.e., becomes greater than) the accreditation threshold, governed by {Θ(t), t ≥ 0}. At a service completion instant, if there are any admitted customers present in the system, the one with the greatest accumulated priority is selected next for service. The busy period ends at a service completion instant which leaves no more admitted customers in the system. Note that the busy period may end while there are still customers present in the system. In this situation, these customers depart the system without ever entering into service.Let τkdenote the arrival epoch of customer Ck, so that we may define Φk(t) to be this customer’s priority function (i.e., the amount of accumulated priority Ckhas at time t), namely:(49)Φk(t)=ξ1(t−τk),t>τk.Furthermore, let n(k) denote the arrival position of the kth customer to be serviced. The definition of the maximal priority process now follows.Definition 5.1The maximal priority process is a two-dimensional stochastic processM(t)={(M(t),Θ(t)),t≥0},satisfying the following conditions:1.M(t)=(0,0)for all t corresponding to idle periods.For all t not corresponding to service commencement/completion instants, we have(50)dM(t)dt=ξ1anddΘ(t)dt=ξ2,where 0 ≤ ξ2 ≤ ξ1.At the sequence of service completion times {δk, k = 1, 2, …},(51)M(δk)=1{Φ∨(δk−)>Θ(δk−)}·Φ∨(δk−),(52)Θ(δk+)=min{M(δk),Θ(δk−)},where(53)Φ∨(δk−)=maxm∈{n(k)+1,n(k)+2,…}Φm(δk−)and 1{A} is the indicator function of the event A.The above definition shows that {M(t), t ≥ 0} is closely related to the well-known age process (i.e., when ξ1 = 1, M(t) represents the age of the oldest admitted customer at time t). Furthermore, the accreditation threshold process increases linearly at rate ξ2 during busy periods. Stanford et al. (2014) referred to those customers who arrive during busy periods and whose priority overtakes the accreditation threshold as accredited customers.With this definition in place, we can now introduce the blocking scheme for our modified M/G/1 queue with accumulating priority. In particular, serviceable customers consist of accredited customers and customers who arrive during idle times. On the other hand, those customers whose priority fails to overtake the accreditation threshold during a busy period are blocked, thereby departing the system without ever entering into service. We refer to such customers as non-accredited customers.Fig. 5depicts a typical sample path of{M(t),t≥0}. Note that customers C4, C5, and C9 are of the non-accredited type and thus end up being blocked from service. Moreover, a notable difference between the current model and the one considered in Section 4 is that with the current system, blocked customers experience some wait before being forced to depart the system.Suppose now at the end of an arbitrary busy period, we wish to find the latest time by which a customer would have to arrive in order to be admitted for service. This can be done by simply dividing the height of the accreditation threshold at time t* (i.e., the time at which the busy period completes) by ξ1 and subsequently subtracting this quantity from t*. For a sample path such as the one shown in Fig. 5, this is equivalent to determining the t-intercept of a line with slope ξ1 which crosses the point(t*,Θ(t*−)).For each busy period, we define the accreditation interval as the duration of time within which customers must arrive in order to be admitted for service. An important observation is that the ratio of the accreditation interval to the busy period is always (1 − ξ2/ξ1). Therefore, this model is similar to the one of Section 4 in that admitted customers must arrive within the first (1 − q)th proportion of the busy period with q = ξ2/ξ1. In fact, it can be shown that the LST of the busy period is the solution to Eq. (4) with q = ξ2/ξ1 (see Stanford et al., 2014 and their discussion on accredited busy periods). In addition, using the same argument as in Brill (1988), we can show that the steady-state distribution of {M(t), t ≥ 0} when ξ1 = 1 is equivalent to the steady-state distribution of the workload process{Uξ2(t),t≥0}of Section 4.Letξ1ϕnbe the accumulated priority, immediately prior to entering service, of the nth customer to be serviced where ξ1 is the priority accumulation rate. Trivially, we have(54)ξ1ϕn=ξ1·Wn,where Wnis the waiting time of the nth serviceable customer. Furthermore, 1ϕn≡ ϕn= Wnrepresents the age of the customer prior to entering service. Letgξ1(x)denote the steady-state pdf of the accumulated priority (immediately prior to entering service) for the serviceable customers.Since waiting times for the serviceable customers in the current model are equivalently characterized by the waiting times for serviceable customers in the model of Section 4 with q = ξ2/ξ1, we have g1(x) ≡ g(x) = f(x; ξ2) for all x > 0, from which it immediately follows that(55)gξ1(x)=g(x/ξ1)ξ1,x>0.From Eq. (31), we get(56)gξ1(x)=λB¯(x/ξ1)P0−λP0G¯ξ2/ξ1(x/ξ1)ξ1+λξ1∫y=0x/ξ1B¯(x/ξ1−y)g(y)dy.Thus, multiplying both sides of Eq. (56) by e−sxand integrating over x ∈ (0, ∞), we obtain the LSTs of the steady-state accumulated priority for serviceable customers and accredited-type customers as(57)ξ1ϕ˜(s)=(1−ρ(ξ2/ξ1))(ξ1s−λ+λG˜(ξ2s))ξ1s−λ+λB˜(ξ1s),and(58)ξ1ϕ˜+(s)=(1−ρ(ξ2/ξ1))(G˜(ξ2s)−B˜(ξ1s))μ(1−ξ2/ξ1)(ξ1s−λ+λB˜(ξ1s)),respectively. Alternatively, Eqs. (57) and (58) can be obtained by substituting s = ξ1s and q = ξ2/ξ1 into Eqs. (34) and (36), respectively.We remark that Eq. (58) was first presented by Stanford et al. (2014). However, their result was obtained under a different setting, as they studied a particular multi-class non-preemptive priority system and obtained the steady-state marginal waiting time distributions of each class. We emphasize that in their model, there is no concept of customer blocking. The authors obtained their result for a random variable which they called the additional accumulated priority. We direct readers to their paper for more details. Moreover, the authors’ method of analysis differs from ours in that their proof of Eq. (58) is inspired by the Conway, Maxwell, and Miller (1967, Chapter 8-4) derivation of the flow time LST in a classical FCFS M/G/1 system.In summary, our level crossing analysis provides an alternate proof of Stanford et al.’s (2014) main result (i.e., Eq. (58)) and also yields the steady-state integral equation for the pdf of accumulated priority in Eq. (56). Furthermore, our model provides an alternate interpretation of the wait of customers in their non-preemptive priority system. Specifically, the additional wait that high priority customers serviced in an accredited busy period experience is identical to the wait experienced by delayed customers in an M/G/1 system under the q-policy.We next establish the distribution of the overall waiting time random variable. Clearly, by design of the model, customers who are blocked from service will experience a (steady-state) waiting time (or total time in the system) which follows the limiting distribution of the forward recurrence time of qT. Defining W0 to be the wait of such non-serviced customers, it readily follows that(59)W˜0(s)=1−G˜ξ2/ξ1(s)E(T)sξ2/ξ1.Since priority is accumulated linearly at rate ξ1, the LST of the waiting time for serviceable customers is obtained from Eq. (57) as(60)W˜1(s)=ξ1ϕ˜(s/ξ1)=(1−ρ(ξ2/ξ1))(s−λ+λG˜(ξ2s/ξ1))s−λ+λB˜(s).Using the steady-state probabilities given by Eqs. (14)–(17), we derive the overall LST of waiting time as(61)W˜(s)=11+ρξ2/ξ1W˜1(s)+ρξ2/ξ11+ρξ2/ξ1W˜0(s).After some elementary algebra, we obtain(62)W˜(s)=(1−ρ(ξ2/ξ1)1+ρ(ξ2/ξ1))×(s−λ+λG˜(sξ2/ξ1)s−λ+λB˜(s)+λ(1−G˜(sξ2/ξ1))s).In this section, we formulate a numerical study to demonstrate a potential usage of the q-policy. We remark that the inspiration for this study originates from a similar study considered by Kao (1996, Example 3.6.4). In what follows, we consider a queueing system with closedown periods as described in Section 4.3. For this system, suppose we have the following monetary parameters:K≡thecostofeachclosedownperiod;h≡thecostofholdingonecustomerperunittime;R≡thetollfeepaidbyeachservicedcustomer.The objective function which we seek to optimize is the long-run expected profit per unit time. Clearly, the instants of busy period commencements define a set of regeneration points. Thus, our objective function is(63)P(q)=R·E(Nbp)−K−E(Cbp)E(D),whereE(Cbp)is the expected holding cost incurred during a busy period. We remark thatE(Nbp)is given by Eq. (13) andE(D)=E(T)+E(S)+λ−1. Moreover, it can be shown, following a similar line of reasoning to Kao (1996, pp. 139–140), that for all work-conserving service disciplines (e.g., both FCFS and the q-restricted LCFS disciplines),(64)E(Cbp)=hE(Nbp)(μ+E(W)).Note that the quantityμ+E(W)represents the long-run average flow time.By recalling the form ofE(W)in Eq. (37), it is immediately clear thatE(Cbp)depends only on the first two moments of the service time distribution. Consequently, the expected profit function P(q) is also affected by the variability of the service time distribution. We use the coefficient of variation of the service time distribution, denoted byCV=γ−μ2/μ,to assess the effect of the variability of the service time distribution on the profit function. In particular, we present five numerical examples of nearly identical models, differing only in their respective coefficients of variation of the service time distribution. In Examples 1–5, we consider five service time distributions with common mean μ = 1, but with coefficients of variation 0, 0.5, 1, 1.5, and 2, respectively.Fig. 6displays the profit functions corresponding to the five examples. With the exception of the profit functions for Examples 1 and 2, we observe that the expected profit per unit time can be maximized by implementing the q-policy. Letting q* denote the optimal blocking proportion which maximizes P(q), we find q* (to 4 decimal places of accuracy) for Examples 1–5 to be 0, 0, 0.1000, 0.1710, and 0.2538, respectively. In Table 1, we calculate the expected profit function and several other quantities of interest corresponding to various values of the blocking proportion q for Examples 1–5. We note that since μ = 1, Eqs. (8) and (13) together imply thatE(T)=E(Nbp)for all values of q.Although it is indeed true that the maximum long-run expected profit per unit time is obtained without the usage of a q-policy (i.e., q* = 0) for both Examples 1 and 2, there are other viable reasons for the implementation of a q-policy. In regard to Example 2, let us defineqr*to be the relative maxima of P(q). By using standard calculus-based methods, we find thatqr*=0.0406. From Table 1 (and the rows corresponding to Example 2), we see that the resulting expected profits with q = q* = 0 andq=qr*differ only by a small amount. However, the advantage of implementing a q-policy still lies in the fact that both the cycle and busy period lengths are smaller when compared to the system without a q-policy in place. Ultimately, withq=qr*,the system is essentially earning the same expected profit as for the case with q = 0, but at the same time allowing for more frequent maintenance checks on the server/machine. Similar remarks can be made for Example 1.In these numerical examples, we showed that by reducing the cycle lengths, a system manager can significantly decrease the incurred costs and thus capture the potential profit (or, as in both Examples 1 and 2, obtain nearly maximal expected profit). It is also apparent that as CV increases, so too does the optimal blocking proportion q*, as evidenced in Fig. 7. It is interesting to note the presence of a discontinuity point in Fig. 7, which occurs for a certain value of CV residing in the interval (0.6014, 0.6015). This particular value of CV corresponds to the first instance in which a non-zero blocking proportion yields a higher expected profit.In conclusion, we have presented a queueing model which enables a system manager, through choice of which blocking proportion q to use, to effectively reduce the duration of a busy period. We have studied several performance measures of interest, including the wait of serviceable customers and the busy period duration. We have also shown that, in certain situations, the reduction of busy period lengths can be accompanied with an increase in profit. A possible avenue for future research lies in the area of server vacation models (e.g., see Takagi, 1991, Chapter 2). In particular, rather than closing the system to potential arrivals, one could consider a situation where the server goes on vacation, during which customers are still allowed to join the queue.

@&#CONCLUSIONS@&#
