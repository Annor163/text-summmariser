@&#MAIN-TITLE@&#
Histogram based perceptual quality assessment method for color images

@&#HIGHLIGHTS@&#
Common methods cannot distinguish those effects of low distortions on color images.Image histogram and Human Vision System based method are proposed.Color images should be measured taking into account Human Vision System.Frequency domain processes are more effective for image quality assessment.

@&#KEYPHRASES@&#
Image quality assessment,Histogram,Perceptual image quality,Fourier transform,

@&#ABSTRACT@&#
A histogram based perceptual quality assessment (HPQA) method for color images is presented in this paper. Basically, the HPQA combines two quality assessment approaches (color image quality assessment and histogram based image quality assessment) and it uses the fourier transform. Its range is between 0 and 1. 1 represents the best quality result, 0 represents the worst quality result for the HPQA. The HPQA results are more suitable than its counterparts in terms of the HVS and they can be obtained faster than the other methods' results. In addition, it can easily differentiate effects of low distortions on color images.

@&#INTRODUCTION@&#
After digital images are acquired, they are subjected to many processing or manipulations for various reasons (compression, data hiding, acquisition, coding, etc.). Image quality assessment (IQA) methods play a very essential role in almost all aspects of multimedia signal processing operations. An image can be used for visual browsing, for medical diagnosis or for extracting information via machine learning methods. The amount of measured distortion in an image may have rather different interpretations with respect to different applications and determines whether the given image has the required amount of quality to be useful for the application at hand. Therefore, it is important to develop application specific IQA methods [1–5]. An important issue in evaluation of digital image processing algorithms is to define reliable IQA methods to estimate quality.A diagnostic image quality assessment method measures the quality of the image for the purpose of medical diagnosis. Likewise, remote sensing imagery is used to estimate some of the relevant parameters for the analysis of its content. Unbounded errors in pixel values due to compression may lead to unacceptable estimation errors in subsequent analysis. A measure used successfully in an application may provide rather poor results in a different application. Therefore, the design of an application specific IQA method is rather important.A fundamental task in many image processing applications is the visual evaluation of a distorted image. There are many measures for examining image quality, such as Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), PSNR-HVS-Modified [1], Structural SIMilarity (SSIM) [2], MultiScale-Structural SIMilarity (MS-SSIM) [3], Universal Quality Index (UQI) [4], and so on. The simplest and the most widely used full-reference IQA method is the MSE. It is computed by averaging the squared intensity differences of distorted and original image pixels, along with the related quantity of the PSNR. Although the PSNR is mostly used in the literature, it is not very well matched with the perceived visual quality [5].The PSNR-HVS-M had been designed to improve the performance of the PSNR and the MSE. It divides the image into 8×8pixels non-overlapping blocks. Then, the Discrete Cosine Transform (DCT) based δ(i, j) is calculated. After that δ(i, j) difference between the original and the distorted blocks is weighed for every 8×8 block by the coefficients of the Contrast Sensitivity Function (CSF) [1]. The SSIM has followed a strategy of modifying the MSE measure so that errors are penalized in accordance with their visibility. It compares local patterns of pixel intensities that have been normalized for luminance and contrast [2]. The MS-SSIM is layered on the SSIM. The algorithm calculates multiple SSIM values at multiple image scales (resolutions). By running the algorithm at different scales, the quality of the image is evaluated for different viewing distances. MS-SSIM also puts less emphasis on the luminance component compared to the contrast and structure components. In total, MS-SSIM has been shown to increase the correlation between the MS-SSIM index and subjective quality tests. However, the trade-off is that the MS-SSIM takes longer to run than the straight SSIM algorithm [3]. The UQI has been designed by modeling any image distortion as a combination of three factors: loss of correlation, luminance distortion, and contrast distortion [4]. It is not based on Human Vision System (HVS).In addition to the IQA methods presented above, much attempt has gone into the development of IQA methods that take advantage of well-known characteristics of the HVS in the last decade [6]. Sparking from these facts, the proposed histogram based perceptual quality assessment (HPQA) method offers a new strategy for qualifying of the color images. The HPQA combines two image quality measurement approaches. The first one is HVS based color image quality measure approach [7] and the second one is histogram based image quality measurement approach [8]. In contrast to these approaches' classical view, the processes are realized on the Fourier Transform (FT) domain because it is seen that magnitude values of the FT coefficients present more suitable results for the HVS.The rest of the paper is organized as follows. In Section 2, YUV transformation, the Fourier Transform (FT) and image histogram are briefly introduced. The proposed method's details are explained in Section 3. Section 4 presents experimental results and comparisons with the previous works. The paper is concluded in Section 5.A classical digital color image is represented with a 3-dimensional array composed of M rows, N columns and 3 channels (R, G and B). Row and column indexes are shown as r and c. Each element of that serial is called a picture element (pixel) (Fig. 1).In general, each color image pixel is identified using 24 bits, i.e. 8 bits for each color channel of red, green, and blue. Color images are also classified into 2 categories, as compressed and uncompressed. Color transformation is usually used as a preprocess before the intracomponent coding in RGB color image compression [9]. A commonly preferred color transformation is from RGB (Fig. 2a) to YUV (Fig. 2b, c, and d).YUV was originally adopted from the JPEG and JPEG 2000 standards [10]. The forward transformation and its inverse formulas (ITU-R BT.601) are given in Eqs. (1) and (2), respectively. YUV transformation not only decorrelates the original color components, but also discards some information to get lower entropy. The discarded information cannot be recovered, and thus the transformation is lossy [11–13]. This means that it is an irreversible component transform (ICT).(1)Y=0.257R+0.504G+0.098B+16U=‐0.148R‐0.291G+0.439B+128V=0.439R‐0.368G‐0.071B+128(2)R=1.1644Y‐16+1.596V‐128G=1.164Y‐16‐0.813V‐128‐0.391U‐128B=1.164Y‐16+2.018U‐128.An approximated Reversible Component Transformation that originates from the JPEG 2000 standard and is called the RCT in the present work is given in Eq. (3)[14,15]. The proposed HPQA method preferably utilizes the RCT rather than the classical YUV, as its goal is not focused on digital image compression. Therefore, data loss never occurs when the RGB to YUV(RCT) (where the Y channel refers to the luminance, while U and V refer to the color information in an image) transformation is realized in the presented method. An important feature of the HVS is its different response to the luminance and color components directly related to the natural features of the eye [7], which are utilized and reflected into the proposed method with different ratios, as detailed in the following section.(3)Y=R+2G+B/4U=R‐GV=B‐GG=Y‐U+V/4R=U+GB=V+G.The FT basis consists of sinusoids of varying frequency and phase. Specifically, it is sought to express a periodic signal as a weighted sum of the sinusoids:(4)fx=1N∑k=0N−1ckcos2πkNx+ϕkwhere the frequency of the sinusoid is ωk=2πk/N, the phase is ϕk, and the weighting (or amplitude) of the sinusoid is ck. The sinusoids form a basis for the set of periodic signals. That is, any periodic signal can be written as a linear combination of the sinusoids. This expression is referred to as the Fourier series [16].In two dimensions, an M×N image can be expressed with respect to two-dimensional sinusoids:(5)fxy=1M×N∑k=0M−1∑l=0N−1cklcosωkx+ωly+ϕklwith:(6)ckl=∑p=0M−1∑r=0N−1fprcosωkp+ωlr+ϕkl.Examples of the 2-D FT basis are shown in Fig. 3. From left to right are bases with increasing frequency, and from top to bottom are bases with varying orientation (i.e., relative contributions of horizontal ωkand vertical ωlfrequencies) [16].The 2-D FT basis can be expressed with respect to a fixed basis as:(7)fxy=1M×N∑k=0M−1∑l=0N−1aklcosωkx+ωly+bklsinωkx+ωlywhere,(8)akl=∑p=0M−1∑r=0N−1fprcosωkp+ωlr(9)bkl=∑p=0M−1∑r=0N−1fprsinωkp+ωlr.The FT coefficients are complex valued. These complex valued coefficients can be analyzed in terms of their real and imaginary components, corresponding to the cosine and sine terms. This can be helpful when exploring the symmetry of the underlying signal f(x), as the cosine terms are symmetric about the origin and the sine terms are asymmetric about the origin. These complex valued coefficients can also be analyzed in terms of their magnitude and phase. Considering the complex value as a vector in the real-complex space, the magnitude and the phase angle are defined as [16,17]:(10)ck=ak2+bk2and(11)θ=tan−1bkak.The magnitude describes the overall contribution of a frequency in constructing a signal, and the phase describes the relative position of each frequency.In statistics, a histogram is a graphical representation showing a visual impression of the distribution of data and it is used to show the frequency distribution of a set of measurements. In digital imaging, a histogram consists of tabular frequencies, shown as neighboring rectangles, raised over discrete intervals, with an area equal to the frequency of the observations in the interval. The height of a rectangle is also equal to the frequency density of the interval, i.e., the frequency divided by the width of the interval [18]. In general, histograms are the basis for numerous spatial domain processing techniques but histograms are created using FT magnitude values of each channel in this work. This approach is a major difference from the other IQA methods.It can be seen that FT magnitude values based R, G and B histograms of the Lena images (Fig. 5) given in Fig. 4. The sub-figures have been drawn as 3-D using the Matlab® mesh() function.Although, it is believed to be that the quality of images are equal considering the PSNR values (i.e., 27.67dB), it can be seen that this is not true considering the image histograms drawn after the FT. Differences between an original image histogram and its distorted version's histogram can clearly be seen in Fig. 5. From this point of view, the HPQA method has been developed and presented in this paper.In this section, the proposed HPQA method, with the details of its four fundamental parts, i.e. the reversible YUV transformation, the FT based Histograms calculation for each YUV channel and their histograms' based quality assessment (HQA), and weighting of the HQAs considering the HVS are presented. The general structure of the HPQA method is depicted in Fig. 6.The proposed HPQA method's result is obtained in four steps as shown in Fig. 5. Each step is detailed following paragraphs.Step 1Because an important feature of the HVS is its different response to the luminance and color components directly related to the natural features of the eye, an approximated RCT given in Eq. (3) is applied on RGB image [12,13]. The RCT is usually used when RGB to YUV transformation where Y channel refers to luminance while U and V refer to the color information in an image. YUV channels' information is utilized and reflected into the proposed method with different ratios as detailed in the following steps.A histogram is a graphical representation showing a visual impression of the distribution of data and it is used to show the frequency distribution of a set of measurements. In digital imaging, a histogram consists of tabular frequencies, shown as neighboring rectangles, raised over discrete intervals, with an area equal to the frequency of the observations in the interval. The height of a rectangle is also equal to the frequency density of the interval, i.e., the frequency divided by the width of the interval [18,8]. It can be easily said that when some extraordinary situations can't be detected on the spatial domain, they can easily be detected on a frequency domain (i.e., FT domain). From this point of view, each YUV channel's FT coefficients are calculated at this step's first phase. Thus, the domain is changed from the time domain to FT frequency domain. At the second phase of this step, histograms are achieved for each YUV channel notated as H(YFT), H(UFT), H(VFT) for original image and,H•YFT,H•UFT,H•VFTfor distorted image as seen in Fig. 6.At this step, the histogram quality results (YHQA, UHQA, VHQA) for each channel are achieved. While this process is applied on the spatial domain histograms in [8], it is applied on the FT magnitude values' histograms in the presented work. The HQA is defined as:(12)HQA=ΔTCFactor×HD.The first component of the HQA is ΔTCFactor (interhistogram difference factor). Histograms (H) are obtained from the original YUV image's channel (i.e., H(YFT)) and the distorted YUV image's channel (i.e.,H•YFT) is applied to the extraction process as seen below.(13)Δ=HYFT−H•YFT.The Δ is a difference vector between the original and the distorted image histograms. Total change (ΔTC) between the original and the distorted image histograms can be calculated by summation of all indices of the Δ (Eq. (14)) and 0≤Δ≤2×M×N [8].(14)ΔTC=∑nΔn.Then, ΔTCFactor varying between 0 (worst) and 1 (best) is calculated using ΔTC as seen below:(15)ΔTCFactor=1−ΔTCΔTCmax.ΔTCmaxexpression means that the upper limit on the amount of histogram change is (2×M×N). The range of ΔTCFactor is [0, 1]. The best value 1 is achieved if and only ifHYFT=H•YFT.The second component of the HQA (Eq. (12)) is the HD (Histogram Distortion) and it refers to the correlation quality between H(YFT) andH•YFT. It is calculated by the classical correlation formula as seen below:(16)HD=∑jHYFTj×H•YFTj∑jHYFTj2.Like the ΔTCFactor, the best HD value is also 1, which is obtained whenHYFT=H•YFT. The explanations above show that the best HQA value is 1, which results when ΔTCFactor and HD values are equal to 1. The worst value of the HQA is 0, which occurs when ΔTC=ΔTCmax[8]. These operations given above are sequentially applied to the other histograms (i.e., H (UFT) and H (VFT)) and then YHQA, UHQA, and VHQAare obtained.This step is the last process of the HPQA method. The HQA results (YHQA, UHQA, and VHQA) which obtained for Y, U and V channels are weighed by considering the color image quality assessment considering the HVS specifications. These specifications are very important for perceptual property of the proposed HPQA method.There are two types of photo-receptors in the human retina, named as rods and cones. The rods are responsible for vision at especially low light levels. They do not provide color vision and have almost no effect on spatial perception [7,19,20]. Unlike the rods, the cones are active at higher light levels, responsible for color vision and spatial perception. The fovea part of the human eye hosts the cones and rods. There are approximately 7million cones and 120million rods in the fovea [7,21–23]. The rods are extremely sensitive to light. On the other hand, the cones supply the eye's color sensitivity [7,24–26]. From these main information views, the weights on the human perception of these cone and rod sensors (i.e., CWand RW) are calculated as seen below [7]:(17)CW=7,000,000/120,000,000+7,000,000=0.0551(18)RW=120,000,000/120,000,000+7,000,000=0.9449.The first term CWas seen in Eq. (17) is the weight on the human perception of the cones. And the second term RWas seen in Eq. (18) is the weight on the human perception of the rods [7].Finally, the HPQA result can be easily obtained using Eq. (19) detailed below:(19)HPQA=YHQA×RW+UHQA+VHQA2×CW.Inclusion of this new weighted approach, considering the human eye's different response to the luminance and color, leads to the superiority of the proposed HPQA method measure over the classical IQA methods.

@&#CONCLUSIONS@&#
After digital images are acquired, they are subjected to many processing or manipulations for various reasons. IQA methods presented in the literature play a very important role in almost all aspects of multimedia signal processing operations. The histogram based full-reference perceptual quality assessment (HPQA) method is presented for color images in this paper. Some of the quality aspects cannot be measured in time domain, but this situation can be opposite in the frequency domain. From this point of view, the HPQA combines the color image quality approach and the histogram based image quality approach with the help of the Fourier transform.Quality results' ranges are between 0 and 1 in most IQA methods. 1 represents the best quality result, 0 represents the worst quality result for the HPQA. Experimental studies about the applicability of the HPQA on a well-known test image under 6 different distortions (median, jpeg, blurring, speckle, etc.), both perceivable by the HVS and with the same PSNR value (i.e. 27.67dB), are presented. The HPQA results are more suitable than its counterparts in terms of the HVS and they can be obtained faster than the other IQA methods' results. In addition, the HPQA can easily differentiate the effects of low distortions on color images.