@&#MAIN-TITLE@&#
Hybrid real-coded genetic algorithm for data partitioning in multi-round load distribution and scheduling in heterogeneous systems

@&#HIGHLIGHTS@&#
Real-coded genetic algorithm approach to determine optimal order of load distribution, optimal number of processors and load partition.Distributed computing system architecture with affine communication model.Optimal load processing time for a given network.

@&#KEYPHRASES@&#
Data partitioning,Scheduling,Genetic algorithm,Divisible loads,Parallel computing,

@&#ABSTRACT@&#
Data partitioning and scheduling is one the important issues in minimizing the processing time for parallel and distributed computing system. We consider a single-level tree architecture of the system and the case of affine communication model, for a general m processor system with n rounds of load distribution. For this case, there exists an optimal activation order, optimal number of processors m* (m*≤m), and optimal rounds of load distribution n* (n*≤n), such that the processing time of the entire processing load is a minimum. This is a difficult optimization problem because for a given activation order, we have to first identify the processors that are participating (in the computation process) in every round of load distribution and then obtain the load fractions assigned to them, and the processing time. Hence, in this paper, we propose a real-coded genetic algorithm (RCGA) to solve the optimal activation order, optimal number of processors m* (m*≤m), and optimal rounds of load distribution n* (n*≤n), such that the processing time of the entire processing load is a minimum. RCGA employs a modified crossover and mutation operators such that the operators always produce a valid solution. Also, we propose different population initialization schemes to improve the convergence. Finally, we present a comparative study with simple real-coded genetic algorithm and particle swarm optimization to highlight the advantage of the proposed algorithm. The results clearly indicate the effectiveness of the proposed real-coded genetic algorithm.

@&#INTRODUCTION@&#
One of the primary objectives in the area of parallel and distributed systems is to partition and schedule the processing load among the processors, such that the processing time of the entire processing load is a minimum. Minimizing the processing time of the entire processing load involves the design of efficient data partitioning and scheduling algorithms. Design of efficient data partitioning algorithms for heterogeneous systems is more difficult because, the processors in the system may have different computation rate, and the communication links in the system may have different communication rate. One way to design efficient data partitioning algorithms is from the Divisible Load Theory[1,2] view point in 1988 and 1990. The theory is shown in [3] that “the divisible load theory offers a tractable and realistic approach to scheduling that allows integrated modelling of computation and communication in parallel and distributed computing systems”. The research work on divisible load scheduling is presented in [4,5]. Divisible load theory has served as an effective modelling tool for data-intensive application in [6] and a large amount of work has been published for various network structures, including linear networks [7,63], bus networks [8,72], single and multi-level tree networks [9–11,22,64], mesh networks [12,13], hypercubes [14], nonlinear loads [29–31], static load balancing [24] and arbitrary graphs [15] with different constraints. The theory of divisible load distribution has applications in a wide range of areas such as compute vision [16], large scale data file processing [17], data intensive applications [18], query processing in database systems [19], scientific computing [20], video and multimedia applications [21,23], numerical computing [25], biomedicine and bioinformatics [26]. Divisible load distribution has applications in filtering of radio communications, encryption for secure communications, and coding for digital communications [27]. Aerospace applications include satellite signal and image processing [28], radar and infrared tracking [29], and data reporting and aggregation and processing in wireless sensor networks [32].Divisible load scheduling problem will be more difficult, when practical issues like the communication latencies are considered. For divisible load scheduling, the affine model of communication in which the communication latencies (start-up times) are included, is studied in [33–35], for both single and multi-round load distribution in heterogeneous systems. For a heterogeneous single-level tree network (master-slave system), load scheduling strategies are discussed and is also shown the methodology leads to a band-width centric scheduling strategy in [34]. The effect of start-up delays in multi-round load distribution is studied in [35]. A linear programming formulation for the divisible load scheduling with communication latencies is given in [5]. It is pointed out in [33], that this linear programming methodology is valid only if all the processors in the system are participating in the computation process. The computational complexity of the divisible load scheduling problem is presented in [36]. The problem of scheduling divisible loads in both linear and affine communication model is considered and the open problems in multi-round load distribution are brought out [37]. In [38], various distribution strategies have been studied including, multi-installment of load distribution. Further, in [39,40], scheduling strategies without knowledge of network resources are examined.In [41], scheduling algorithms using DLT on heterogeneous systems by considering different types of variation of the perturbation parameters, larger problem sizes, and different types of application characteristics. In [42], the resource model and the job model are presented to achieve a minimum processing time. A network aware divisible load algorithm extends DLT to optimally allocate both computational and networking resource of an optical grid in [43]. In [44], an uniform framework for parallel image processing on heterogeneous network systems, Single Program Multiple Data (SPMD) tasks where each image processing task can be computed as multiple SPMD subtasks on various kinds of computing nodes. The uniform interface has been created for connect existing hardware and software resources to the user application, which makes complexity of parallel execution system transparent. In [45], GA-BT a genetic algorithm based peer selection optimization strategy for efficient content distribution in Bit-Torrent networks. GA-BT employs the divisible load theory to dynamically predict an optimal fitness value to speed up the convergence process in producing optimal or near optimal schedules in peer selection.A method of partitioning divisible loads known as “multi-installment technique” (multi-round) is presented in [46]. In [46], a homogeneous system (all the processors are identical and all the communication links are identical) and a linear model for communication and computation are used. The theoretical aspect of multi-installment scheduling algorithm for multiple loads in bus network is illustrated in [47] In practical heterogeneous systems, the communication model is not linear and communication latencies (start-up delays) are to be included. These communication latencies play a major role in data partitioning and scheduling. The effect of communication latencies (start-up time) and its influence on the processing time is first studied in [48] for a linear network architecture of the distributed computing system. In this study, it is shown that the processing load assigned to processors beyond a certain number of processors is zero. In other words, only processors up to a certain number will participate in the computation process. The effect of start-up delays in communication and computation for a bus network is presented in [49,50] and in these studies also processors beyond a certain number are not included in the load distribution process. In [51], multi-installment technique is presented for homogeneous tree network with start-up delaying computation process. In [51], the effect of result collection in multi-installment scheduling algorithm for homogeneous network is presented. Also, a closed form expression for processing time is obtained using rational expansion theorem. In [52,53], the issue of scheduling is formulated as a linear programming framework. The major benefit of using this uniform multi-installment strategy is that, we get an approximate optimal number of installments required to process the load such that the processing time is a minimum. In [54], a novel algorithm called robust uniform multi-round (RUMR) algorithm is proposed. In RUMR algorithm, the uncertainty in the communication and computation times, which can be caused by the platforms (e.g., when resources are non-dependent) are handled by increasing the chunk size (load fraction size) in the initial rounds and decreasing the chunk size towards the end. In [55], Drozdowski and Lawenda analyze multiple divisible loads on a star-connected system consisting of homogeneous processors. This work left one open question of the problem NP membership. As it is impossible to show that this problem is in NP it is necessary to prove that communication pattern can at least be recorded in polynomial time.In this paper, we consider a single-level tree (master-slave or star-shaped) architecture of the distributed computing system. We consider the case of affine communication model, for a general m processor system with n rounds of load distribution. For this case, there exists an optimal activation order, optimal number of processors m* (m*≤m), and optimal rounds of load distribution n* (n*≤n), such that the processing time of the entire processing load is a minimum. This is a difficult optimization problem because for a given activation order, we have to first identify the processors that are participating (in the computation process) in every round of load distribution and then obtain the load fractions assigned to them, and the processing time. There are 2mncombinations of participating processors for every activation order. There are m! activation orders are possible. Hence, we have to consider m!*2mnsolutions to obtain the optimal processing time.So for this problem, we propose a real-coded genetic algorithm to search the set of participating processors, and the load fractions assigned to them in every round, such that the processing time is a minimum, for a given activation order. We also show that from the load fractions obtained for any activation order, we can search for a better activation order. Real-coded genetic algorithm uses hybrid crossover and mutation operators. unlike, normal real-coded genetic algorithm, the four crossover operators proposed in this paper always satisfy the equality constraints and hence the solution are always valid. In addition, zero mutation operator helps in identifying optimal activator order effectively. Using the solutions from proposed real-coded genetic algorithm, we propose a heuristic approach to find the optimal activation order, optimal number of processors m* (m*≤m), and optimal rounds of load distribution n* (n*≤n), such that the processing time of the entire processing load is a minimum.It is known that the solution obtained from genetic algorithms cannot be guaranteed to be optimal; i.e., no formal proof of optimality. But, for a large class of difficult optimization problems, it has been shown that the genetic algorithm produces solution that are very close to the optimal or among the best available solutions.This paper is organized as follows: in Section ‘Multi-round divisible load scheduling problem’, we present the multi-round load distribution problem and present some motivating numerical examples to show the combinatorial nature of the problem. Section ‘Real-coded genetic algorithm for obtaining load fractions’, presents the real-coded genetic algorithm describing the solution representation, genetic operators and other details. In Section ‘Simulation results’, we present numerical results and show that the genetic algorithm gives the optimal number of rounds, optimal number of processors and also the optimal activation order for the root processor. Finally, we discuss and conclude in Section ‘Conclusion’.A single-level tree network with (m+1) processors and m links, is shown in Fig. 1. The processing load originates at the root processor (p0). The root processor distributes the load assigned to each child processor in n rounds (installments). The order in which the processing load is distributed (sequence of load distribution) in all rounds are the same and is {p1, p2, …, pm}. The processors in the network are equipped with communication co-processors (front-ends), so that communication and computation can be done concurrently. Here also we follow the rules of load distribution given in [4]. The objective here is to find the size of the load fractions assigned to each processor in each installment, such that the processing time of the entire processing load is a minimum. The computation and communication models used in this paper are:Computation time is linear: if αiis the load fraction assigned to processor pi, then the time to compute this load fraction by processor piis αiAi, where Aiis the processing rate (reciprocal of the speed) of the processor pi.Communication time includes latencies: if αiis the load fraction assigned to processor pi, then the time to communicate this load fraction to processor piby the root processor p0, is gi+αiGi. Here giis the communication latency, and Giis the communication rate (reciprocal of band width) of the link lito processor pi. For communications, one-port model is used. The root processor (p0) can communicate with only one child processor at a given time.Load distribution, defined as an (mn+1)-tuple {α0, α1,1, α2,1, …, αm,1, α1,2, α2,2, …, αm,2, …, α1,n, α2,n, …, αm,n}, such that 0≤αi,j≤1 andα0+∑i=1m∑j=1nαi,j=W. Here α0 is the load fraction assigned to the root processor (p0) and αi,jis the load fraction assigned to the ith processor (pi) in round j. W is the total processing load.Finish time (Ti) for processor pi, is the time difference between the time instant at which the processor pistops computing and the time instant at which the root processor p0 initiates the load distribution process.Processing time (T), is the time at which the entire load (W) is processed; it is given by the maximum of the finish time of all processors; i.e., T=max{Ti}, i=0, 1, …, m, where Tiis the finish time of processor pi.We now present some motivating numerical examples to show the combinatorial nature of this multi-round load distribution strategy with affine communication model.Example 1Affine communication model Consider a system with two child processors p1 and p2 attached to the root processor p0. The computation speed parameters of the processors are A0=A1=A2=1.0, the communication link speed parameters are G1=0.6, G2=2.0, and the communication latencies are g1=2 and g2=1. The processing load is sent to the child processors p1 and p2 in two rounds (installments). The total processing load is W (W=100). The activation order is {p1, p2} in both rounds. In this situation, we need to consider the following cases:Case 1: Use both the processors p1 and p2 in two rounds.Case 2: Use the processor p1 only in the first round and p2 in both (two) rounds.Case 3: We use the processor p1 only in the second round and p2 in both (two) rounds.Case 4: Use the processor p1 in both (two) rounds and p2 only in the first round.Case 5: We use the processor p1 in both (two) rounds and p2 only in the second round.The processing time and the load fractions assigned to the processors in each round are given in Table 1. Note here that αi,jis the load fraction assigned to processor i (pi), in jth round. We explain how we got the load fractions. In divisible load scheduling literature, timing diagram is the usual way of representing the load distribution process. It is shown in divisible load scheduling literature [4], that in order to achieve minimum processing time all the processors participating in the computation process should stop computing at the same time instant. The timing diagram for the two processor system with the start-up overheads in two rounds (two-installments) is shown in Fig. 2. From this timing diagram, the recursive load distribution equations for two-rounds are:(1)α1,2A1=g2+α2,2{G2+A2}(2)α2,1A2=g1+α1,2G1+g2+α2,2G2(3)α1,1A1=g1+α1,2G1+g2+α2,1G2(4)α0A0=g1+α1,1G1+g2+α2,1G2+g1+α1,2G1+g2+α2,2G2+α2,2A2The normalization equation is(5)α0+α1,1+α1,2+α2,1+α2,2=100By making the appropriate values of αi,jzero and removing the unnecessary equation for the cases, from the above equations, the load fractions for all the Cases 1–5 are obtained. For example, in Case 3, the load fractions are obtained by making α1,1=0 (also g1 for that round), and by removing the α1,1 equation.For this problem, there are two possible activation orders for root processor and they are {p1, p2} and {p2, p1}. The results for the activation order {p2, p1} is given in Table 2. From these Tables 1 and 2, we see that the optimal activation order is {p1, p2} for the above problem.Now, we show that this optimal activation order can be obtained from the values of load fractions obtained for any one of the activation orders. We consider the load fractions obtained from the activation order {p2, p1} to obtain the optimal activation order. Let the optimal activation order is {*, *}. Here * denotes at present the processor for this position is not known. From the load fractions obtained for the activation order {p2, p1}, we see that the processors participating in round one is p1. So the activation order now is {p1, *}. Since, there are only two processors, the optimal activation order is {p1, p2}. If we consider the load fractions of activation order {p1, p2} also we get the same optimal activation order.It is possible for both the processors to have a non-zero load in both the rounds for the processing time to be minimum. Then this above method needs to be modified by considering more number of rounds, and this will discussed later in this paper.Proposition 1In affine communication model, for a given total processing load and for a given number of rounds, the optimal activation order for the root processor can be obtained from the load fractions obtained for any activation order.This above proposition is very much useful in obtaining the optimal activation order for the root processor in a general m processor n rounds of load distribution, from the load fractions obtained for any activation order. The reason is for a m processor system there are m! activation orders are possible. So we use one activation order for n rounds of load distribution and from the load fractions, we use the above proposition to obtain the optimal activation order. This will be explained later in this paper.Example 2Linear communication model Let us consider the same problem Example 1 with g1=g2=0. The results for the above cases are shown in Table 3. From Table 3, we see that using processor p1 in both the rounds and processor p2 only in second round gives optimal processing time. Note here also from the load fractions, we can obtain the optimal activation order for root processor as in Example 1.In a recent study [37], it is shown that for the case of affine communication model in single round load distribution, the complexity of the problem is open. The difficulty is that for multi-round load distribution with affine or linear communication model, we have to first find the participating processors (resource selection [37]) in each round, and then find the load fractions assigned to the processors in each round.Proposition 2The multi-round load distribution with linear or affine communication model is a combinatorial optimization problem, because it is not necessary to use all the processors in all the rounds, to minimize the processing time of the entire processing load.Preliminary results in activation order for root processor: In the above examples, the activation order for the root processor is given. In a recent study [37] an interesting aspect about the definition of round is presented. For a single-round of load distribution it is clear. But in multi-round load distribution, the definition of round is not clear. So in every round the load distributed to child processors in the same activation order. In this study also we assume that the activation order is same in every round. The optimal ordering for linear communication model is obtained by serving the child processors in the ordering of non-decreasing link capacities [4,37].First we show that in affine communication model the optimal ordering depends on the total processing load W, even for single round strategy. We will illustrate this fact with the following numerical example.Example 3Root processor has no processing capabilityWe consider that the root processor (p0) has no processing capability. This type of system is considered in [37]. Let T{p1, p2} and T{p2, p1} be the processing time T for activation orders {p1, p2}, and T{p2, p1} respectively. For this system, the load distribution equations for activation order {p1, p2} is(6)α1=g2A1+α2G2+A2A1(7)α1+α2=WThe load distribution equations for activation order {p2, p1} is(8)α2=g1A2+α1G1+A1A2(9)α1+α2=WThe processing times for these activation orders are(10)T{p1,p2}=g1+g2A1(G1+A1)+(G1+A1)G2+A2A1W−g2A11+((G2+A2)/(A1)(11)T{p2,p1}=g2+g1A2(G2+A2)+(G2+A2)G1+A1A2W−g1A21+((G1+A1)/(A2)For the values of A1=1.3, A2=1.1, G1=0.2, G2=0.35, g1=5 and g2=1.1, the above equations reduces to(12)T{p1,p2}=5.6+(0.790909)W(13)T{p2,p1}=3.8884618+(0.8365384)WFrom the above expressions we see the following:(14)T{p1,p2}>T{p2,p1}forW<35.266638(15)T{p1,p2}<T{p2,p1}forW>35.266638(16)T{p1,p2}=T{p2,p1}forW=35.266638It is important to note that the above analysis is valid only when G1≠G2. If G1=G2 then the optimal activation order is independent of the total processing load (W). For the case G1=G2=G, T{p1, p2}≤T{p2, p1} only when g1A1≤g2A2. This is proved as Theorem 2 in [33]. Based on this example for the case G1≠G2, we state the following proposition.Proposition 3In single-round load distribution with affine communication model, the optimal activation order for the root processor depends on the total processing load.Now, we show that the optimal activation order for the root processor depends on number of rounds of load distribution.Example 4Consider a system with two child processors p1 and p2 attached to the root processor p0. The computation speed parameters are A0=15, A1=1.3, A2=1.1, the communication link speed parameters are G1=0.2, G2=0.35, and the communication latencies are g1=5 and g2=1.1. The total processing load (W) is 100.We first consider the activation order {p1, p2} for the root processor. The processing times for one round and two rounds of load distribution are 80.4491 and 69.2876 respectively. Now consider the activation order {p2, p1} for the root processor. The processing times for one round and two rounds of load distribution are 82.9180 and 68.8545 respectively.From this we can see that for the same total processing load (W=100), the optimal activation order for single round is {p1, p2}. But the optimal activation order for two rounds is {p2, p1}. Note that for obtaining the processing time T in two rounds of load distribution, all the five cases presented in Example 1 are considered, for the activation orders. Here also if G1=G2 then the optimal activation order is independent of the total processing load (W). For the case G1=G2=G, T{p1, p2}≤T{p2, p1} only when g1A1≤g2A2[33].Proposition 4In affine communication model, for a given total processing load, the optimal activation order for the root processor depends on the number of rounds used in load distribution.When we extend the above analysis to a general m processor system with n rounds (installments) of load distribution the following two important questions will arise:1.In each round, whether to use all the processors or only some of the processors and What is the load fraction assigned each processor in each round?What is the optimal number of processors, optimal number of rounds, and the optimal activation order for the root processor in a general m processor and n round system?In this paper, these above questions are addressed and is solved using a real-coded genetic algorithm. We consider a general m processor system and n rounds of load distribution. The communication model is affine. The real-coded genetic algorithm gives the load fractions assigned to every processor in every round. The load fractions assigned to some processors in some rounds of load distribution may be zero. For example, if the value of load fraction α4,5 is zero means that the processor p4 is not participating in round 5 of the load distribution. From the load fractions for every processor in every round, we obtain the optimal number of rounds, optimal number of processors and optimal activation order for the root processor, for a general m processor system and n rounds of load distribution. To the best of our knowledge, this is the first attempt to solve this multi-round load distribution problem with affine communication model in a genetic algorithm frame-work.In earlier studies [37,46], the following rules are used for multi-round load distribution.1.The front-end of the root processor is continuously engaged in distributing the load until all rounds have been communicated.The processors must be engaged continuously in computation, once they start computing, from the first round until the end of last round.All the processors stop computing at the same time instant.The timing diagram for a general m-processor system with n round (installments) load distribution is shown in Fig. 3. We see that the processors and the rounds are numbered in natural order (and not in reverse order as in [37,46]). Also note that for a general m-processor n-round load distribution, it may not be possible to satisfy Rule 2 mentioned above. The processors may have idle time after completing one round and waiting for the load assigned to it in the next round. So we modify the finish time of processor pi,i=1, …, m as(17)T0=α0A0(18)Ti=∑k=1i{gk+αk,1Gk}+Max{αi,1Ai,Ki,1}+⋯+Max{αi,nAi,Ki,n}In the above equation, the first term (∑k=1i{gi+αk,1Gi}) gives the time at which the processor pistarts computing the first round load fraction. Each Max function takes care that the processing of a load fraction in any round is started only after that load fraction is received by that processor and also takes care if the processor is idle after complete the processing of load assigned in the previous round. For example, αi,1Aiis the time at which the processor picompletes the processing of load fraction assigned to it in the first round. Ki,1 is the time at which the processing load assigned to processor piin second round is received at the processor pi. Also note in the above equation that if any load fraction (αi,j) is zero, then the corresponding giis made zero for computing the value of Ti. The value of Kp,qis(19)Kp,q=∑j=p+1m{gj+αj,qGj}+∑j=1p{gj+αj,q+1Gj}We now pose this multi-round load distribution problem as an optimization problem. Given: the speed parameters of the network (Gi, Ai), start-up delays (gi), number of rounds of load distribution (n), and the activation order for the root processor. To find: the optimal load fractions assigned to each processor in each round, such that the processing time (T) of the entire processing load is a minimum. The processing time (T) is given by(20)T=max{Ti,i=0,1,…,m}where Tiis the finish time of processor pi. One should note that the solution should satisfy the equality constraint(21)W=∑i=1m∑q=1nαi,qwhere W is total size of processing load.In this paper, we proposed an improved real-coded genetic algorithm to obtain the optimal load fractions assigned to each processor in each round, for the above problem. The real-coded genetic algorithm employs hybrid crossover and mutation operators. The operators are designed such that the solution produced by them always satisfy the equality constraint given in Eq. (21).Genetic algorithms (GA) are developed by Holland [56] in an attempt to explain the adaptive process of natural systems and to design artificial systems based upon these natural systems. In earlier studies of genetic algorithms [56,57], the solutions are coded using binary representation. It is shown in [58] that for numerical optimization problems, floating point representation of solutions performs better than binary representation because they more precise, more consistent, and lead to faster convergence. Genetic algorithms using floating point representation for solutions are called real-coded genetic algorithms. This type of representation for solutions is also known as floating-point representation, real number representation or continuous representation. Hybrid genetic algorithm with different type of genetic operators at different stages of evolution process could provide effective better solution to many practical optimization problems. In recent years for solving optimization problems many researchers are using real-coded genetic algorithms [59,60].In [61], integer-coded genetic algorithm (ICGA) and particle swarm optimization (PSO) complied with neural-network-based extreme learning machine (ELM), the algorithm performed well in accurate gene selection and sparse data classification for microarray data for multiclass cancer classification, the author compare their algorithm with algorithms in previous literatures. Ref. [62] the paper brought integrating dominance properties with genetic algorithms for parallel machine scheduling problems for minimizing the makespan, the meta-heuristic algorithm was working well for larger problem. In [67,68] the ACGA algorithm was applied in the solving of several scheduling problems. The main characteristic of ACGA is that it alternates the EDAs and genetic operators in each generation. Many extensions of ELM have been developed to improve the performance in sparse high-dimensional applications, such as cancer recognition, prediction, finance and control [65]. In [66], AGA was applied to dynamic allocation optimization problem and a simple test measures of performance (MOP). In [67], this paper describes a decomposition-based optimization approach for the design of a composite structure for stiffness requirements using an RCGA to fulfil design a composite box beam for specified stiffness requirements. More details about how genetic algorithms work for a given problem can be found in literature [56–58].In genetic algorithms, a solution to the optimization problem is represented as a string (a coded solution or solution). For our problem, the string (solution) gives the load fractions assigned to each processor in each round of load distribution. Each string (solution) is evaluated according to fitness function (related to the objective function) which is problem specific. A survival of fittest strategy is adopted to identify best strings (solutions) and subsequently genetic operators are used to create new solutions for next generation. This process of successive generations continues until the termination (convergence) criterion is satisfied. The construction of a real-coded genetic algorithm for our problem involves the following issues: string representation, population initialization, selection function, design of genetic operators, fitness function and termination criterion. Now, we will describe these issues involved in applying genetic algorithm to our multi-round divisible load scheduling problem.String representation: The string representation is the process of encoding a solution to the problem. Each string in the population represent a possible solution to the scheduling problem. The string representation scheme depends on the structure of the problem in GA framework and also depends on the genetic operators used in the algorithms. For our problem, the string consists of an array of real numbers. The value of each element in the array represents the load fraction assigned to each processor in each round. The length of the string is mn+1, representing load fractions α0 and αi,ji=1, …, m and j=1, 2, …, n. A valid string is the one in which the sum of the load fractions (sum of the elements in the array) is equal to the total processing load (W).For example, in case of a two processor (m=2) and two round (n=2) system, a string will represent the load fractions {α0, α1,1, α2,1, α1,2, α2,2}, where α0 is the load fraction assigned to the root processor (p0) and αi,jis the load fraction assigned to processor piin jth round. For example, a string {20, 20, 20, 20, 20} is a valid string, because the sum of load fractions assigned is equal to the total processing load W (100).Population initialization: One of the advantages of genetic algorithm is due to the fact that the genetic algorithm search from a population of solution points instead of a single solution point. Most frequently used technique for population initialization is random generation or based on the knowledge of the given problem. But, the initial population size, and the method of population initialization will affect the rate of convergence of the solution. For our problem, we proposed three different initial schemes such that the solution covers the search space efficiently. The population of solutions is generated in the following manner.•Equal allocation: the value of load fractions in the solution is (W/(mn+1)).Random allocation: generate mn+1 random numbers. These random numbers are normalized such that the sum is equal to W. This is the values of α0 and αi,jin the solution.Zero allocation: Select a solution using equal or random allocation. Any one element in the selected solution is assigned zero and its value is equally allocated to other elements.Selection function: We have used normalized geometric ranking method given in [69] for the selection process. In this method, the solutions (population) are arranged in descending order of their fitness value. Let q be the selection probability for selecting best solution, and rjbe the rank of jth solution in the partially ordered set. The probability of solution j being selected using normalized geometric ranking method is(22)sj=q′(1−q)rj−1where q′=(q/(1−(1−q)N)) and N is the population size. The details of this method can be found in [69].Genetic operators: Genetic operators are used to create new solutions based on the current solutions. New solutions are obtained by combining or rearranging parts of the old solutions, and a new solution obtained may be a better solution to the optimization problem. These genetic operators are analogous to those which occur in the natural world: reproduction (crossover, or recombination); mutation. One should note that the solution generated by these operator should satisfy the equality constraint given by Eq. (21). Hence, we improved the operators to produce valid solution at any given time.Crossover operator is a primary operator in GA. The role of crossover operator is to recombine information from the two selected solutions to produce two new solutions. The crossover operator improves the diversity of the solution. Now, we describe four different crossover operators used in our divisible load scheduling problem. Let C1 and C2 are the two solutions selected for crossover operations.(23)C1={c11,c21,…,ci1,ci+11,…,cj1,cj+11,…,cmn+11}(24)C2={c12,c22,…,ci2,ci+12,…,cj2,cj+12,…,cmn+12}Modified two point crossover (MTPX): This operator first select two crossover points randomly i, j and i<j. LetK1=ci1+ci+11+⋯+cj1andK2=ci2+ci+12+⋯+cj2. Here K1 and K2 are the total load between the crossover sites. Also let x1=K1/K2 and x2=K2/K1. Two new solutions H1 and H2 are obtained as(25)H1={c11,c21,…,x1ci2,x1ci+12,…,x1cj2,cj+11,…,cmn+11}(26)H2={c12,c22,…,x2ci1,x2ci+11,…,x2cj1,cj+12,…,cmn+12}For example, consider the two (m=2) processor two (n=2) round system. Let the solutions C1 and C2 are selected for crossover operation. The crossover points selected be i=2 and j=4. The load fractions between two crossover sites are represented in bold face.C1=[4020101515]C2=[3015251020]Here, K1=20+10+15=45 and K2=15+25+10=50. The two new solutions H1 and H2 obtained are:H1=[4015455025455010455015]=[4013.522.5915]H2=[3020504510504515504520]=[3022.222211.111116.666720]The MTPX ensures the sum of load fractions assigned to the processors in the network is equal to the total processing load. The operator generates two new solutions only when K1 and K2 are greater than zero.Modified simple crossover (MSCX): Here, only one crossover site i is selected randomly and the second crossover site is mn+1. LetK1=ci1+ci+11+⋯+cmn+11,K2=ci2+ci+12+⋯+cmn+12, x1=K1/K2 and x2=K2/K1. Two new solutions H1 and H2 are:(27)H1={c11,c21,…,x1ci2,x1ci+12,…,x1cmn+12}(28)H2={c12,c22,…,x2ci1,x2ci+11,…,x2cmn+11}Modified uniform crossover (MUCX): In this operator, the crossover sites are selected randomly. Suppose, i and j are the two points selected randomly for crossover operation then the sum of load fractions selected for crossover operation beK1=ci1+cj1andK2=ci2+cj2. Let factor x1=K1/K2 and x2=K2/K1. Two new solutions H1 and H2 are:(29)H1={c11,c21,…,x1ci2,ci+11,…,x1cj2,cj+11,…,cmn+11}(30)H2={c12,c22,…,x2ci1,ci+12,…,x2cj1,cj+12,…,cmn+12}Modified averaging crossover (MACX): Averaging crossover is a commonly used operator in real coded genetic algorithm and it generates new solutions by averaging the two parent. The modified Two new solutions H1 and H2 are:H1=C1+β(C1−C2)H2=C2+β(C2−C1)where β is a scalar value in the range of (0≤β≤1).Hybrid crossover (HCX): We have presented four types of crossover operators. The performance of these operators in terms of convergence to optimal solution depends on the problem. One type of crossover operator which performs well for one problem may not perform well for another problem. Hence many research works are carried out to study the effect of combining crossover operators in a genetic algorithm [70,71] for a given problem. Hybrid crossovers are a simple way of combining different crossover operators. The hybrid crossover operator use different kinds of crossover operators to produce diverse offsprings from the same parents. The hybrid crossover operator presented in this study generates eight offsprings for each pair of parents by MSCX, MTPX, MUCX and MACX crossover operators. The most promising offsprings of the eight substitute their parents in the population.Mutation operator: The mutation operator alters one solution to produce a new solution. The mutation operator is needed to ensure diversity in the population, and to overcome the premature convergence and local minima problems. Note the mutation operators are modified such that they satisfies the equality constraints given in Eq. (21). We describe different mutation operators used in this study.Swap mutation (SM): Let C1 be the solution selected for mutation operation. This operator first select two mutation points randomly i and j. The new solution (H1) is generated by swapping the values at these mutation points.(31)C1={c11,c21,…,ci1,ci+11,…,cj1,cj+11,…,cmn+11}(32)H1={c11,c21,…,cj1,ci+11,…,ci1,cj+11,…,cmn+11}Consider the two (m=2) processor two (n=2) round system. Let C1 be the solution selected for mutation operation and the mutation sites(i and j are shown in bold face.C1=[4020101515]The new solution (H1) is generated by swapping the values at these mutation points.H1=[4015102015]Random zero mutation (RZM): Let C1 be the solution selected for mutation operation. This operator first select one mutation point i randomly. The new solution (H1) is generated by making the value at this mutation point zero and distributes this value to other elements in the solution equally.(33)C1={c11,c21,…,ci1,ci+11,…,cj1,cj+11,…,cmn+11}(34)H1={x+c11,…,0,x+ci+11,…,x+cj1,…,x+cmn+11}wherex=(ci1)/(mn+1). The random zero mutation operator is useful because one element in the string is made zero. For example, if the element in the string corresponding to α3,4 is made zero means that the processor p3 is not participating in round 4 of load distribution. This operator also increases the rate of convergence of the algorithm.Fitness function: The calculation of fitness function is easy. The string gives the load fractions α0 and αi,ji=1, …, m and j=1, …, n. Once the load fractions are known, the finish time of all processors (Ti) can be easily obtained. The processing time of the entire processing load T is max(Ti, ∀i=0, 1, …, m). Since, the genetic algorithm maximizes the fitness function, the fitness is defined as negative of the processing time (T).(35)F=−TTermination criteria: In genetic algorithm, the evolution process continues until a termination criterion is satisfied. The maximum number of generations is the most widely used termination criterion and is used in our simulation studies.In general, a real-coded genetic algorithm for our problem has the following steps:1.An initial population of solutions is randomly (or based on problem knowledge) generated.For each solution the value of the objective function is calculated. (The solution gives the load fractions assigned to each processor in each round and so the finish time of each processor (Ti) can be easily calculated). The objective function is the processing time (T) of the entire processing load and is T=max{Ti}, i=0, 1, …, m). Based on the value of the objective function a fitness is assigned to each solution.New solutions are generated by examining the fitness value of the solutions and applying genetic operators on the solutions (strings).Repeat steps 2 and 3 until convergence.The real-coded genetic algorithm discussed in the earlier section was implemented in MATLAB on a Pentium-IV machine. The real-coded genetic algorithm parameters used in our simulations are: Smmutation probability is 0.15 for first 2500 generations and 0.30 after 2500 generations; Sccrossover probability is 0.6; q selection probability is 0.08; Maximum number of generations is 5000; and N population size is 50. The parameters are obtained by trail and error and are fixed for all simulations. We have conducted many numerical simulations for various values of m, n, Gi, Ai, and gi. We present a numerical example to show how this methodology works.Numerical Example 5Consider a six (m=6) processors system. The processing speed parameters are: A0=15, A1=1.5, A2=1.4, A3=1.3, A4=1.2, A5=1.1 and A6=1.0 and communication link speed parameters are: G1=0.3, G2=0.4, G3=0.2, G4=0.1, G5=0.35 and G6=0.1. The communication latencies are: g1=1, g2=2, g3=5, g4=1.5, g5=1.1 and g6=3.5. The activation order for root processor (p0) is {p1, p2, …, p6}. The total processing load (W) is 100.This example was run in real-coded genetic algorithm for 6 rounds with all the 6 processors. The load fractions assigned to each processor in each round obtained from the real-coded genetic algorithm are given in Table 4. From this Table 4, we see that the load fractions assigned to processor p3 is zero in all rounds. This implies that the processor p3 is not participating in any of the rounds and so the optimal number of processors is 5. Similarly, we see that the load fractions assigned to all the processors in round 6 is zero. This implies that this round is not used. Hence, the optimal number of rounds is 5.Now, we will explain how genetic algorithm gives the optimal number of rounds and optimal number of processors. Genetic algorithm starts with a population of solutions (load fractions to processors in each round) to the problem. Every solution in the population is used to find the processing time (T). Based on the processing time a fitness is assigned to every solution. Based on the fitness new solutions are obtained using genetic operators. Hence, genetic algorithm searches through all possible solutions to the problem. The solutions other than the one with optimal number of rounds and optimal number of processors are discarded because their processing time is more than the processing time for optimal number of rounds and processors. So genetic algorithm converges to optimal number of rounds and optimal number of processors. This is possible because the only information needed in genetic algorithm is the objective function value (processing time T). The objective function is easy to calculate once the load fractions are known. It is also easy in genetic algorithm to make any particular load fraction (αi,j) zero (by using the random zero mutation) and obtain the processing time. Any idle time for the processors in computation are included in the finish time expression. Also, we can see that the rules 2 and 3 of load distribution are automatically satisfied. This can be verified from the load fractions obtained, that there is no idle time for processors and all processors stop computing at the same instant in time.How to obtain the optimal activation order from the load fractions given in Table 4 for activation order {p1, p2, …, p6}?.For this we use Proposition 1 described in earlier section. Let the optimal activation order is {*, *, *, *, *, *}. Here * denotes at present the processor pifor this position is not known. From Table 4, the processors participating in round 1 are p4 and p6. So in the optimal activation order first activate processor p4 and then processor p6. Now the optimal activation order is {p4, p6, *, *, *, *}. The processors participating in second round are p1 and p5. After activating processor p6, activate processor p1 and then processor p5 in the optimal activation order. Now the optimal activation order is {p4, p6, p1, p5, *, *}. The processors participating in third round are p2 and p4. Of these processors p4 is already activated. So after activating processor p5 activate processor p2 in the optimal activation order. Now the optimal activation order is {p4, p6, p1, p5, p2, *}. Processor p3 is not participating in any of the rounds and so it is considered as removed from the network. So the optimal activation order is {p4, p6, p1, p5, p2}.We used this optimal activation order ({p4, p6, p1, p5, p2}) in our real-coded genetic algorithm. The load fractions and the processing time obtained for this optimal activation order in 2 rounds of load distribution is given in Table 5. We can see that the results given in Table 5 are the same as obtained for 6 rounds of load distribution for the activation order {p1, p2, p3, p4, p5, p6} given in Table 4. Hence, for this example, the optimal activation order is {p4, p6, p1, p5, p2}, optimal number of processors is 5, and optimal rounds of load distribution is 2. This example, clearly shows that the real-coded genetic algorithm gives the optimal number of processors, optimal rounds of load distribution, and the optimal activation order for a general m processor n rounds load distribution system.The processing time for the entire processing load in 2 rounds of load distribution for activation order {p1, p2, p3, p4, p5, p6} is 38.911. The processing time for the entire processing load in 2 rounds of load distribution for optimal activation order {p4, p6, p1, p5, p2} is 37.22944.Convergence study. Now, we conduct convergence study of proposed hybrid real-coded genetic algorithm (HRCGA) using the optimal activation order {p4, p6, p1, p5, p2} and optimal rounds (2 rounds) on load distribution. The proposed HRCGA is called 30 times and the mean and standard deviation of converged results with respect optimal processing time 37.22944 is reported in Table 6. Similar study has been conducted using simple real-coded genetic algorithm (RCGA) with random initialization and well-known particle swarm optimization (PSO) [73–75]. The number of solutions, number of iterations and initial populations are kept constant among these three algorithms. PSO algorithm parameters are selected as suggested in [74,75]. From the table, we can clearly see that the proposed HRCGA converges close optimum than RCGA and PSO algorithms. HRCGA shows better convergence due to the modified operators which produces valid solutions.Numerical Example 6Now, we considered a case with A0=15, A1=1.8, A2=2.4, A3=1.3, A4=1.2, G1=0.2, G2=2.05, G3=0.15, G4=0.15, g1=0.15, g2=4, g3=0.05, g4=0.1, and total processing load W is 100. The activation order for root processor (p0) is {p1, p2, p3, p4} and number of round be 2.The load fraction assigned to the processors in all rounds and total load processing time are given in Table 7. From the table, we can observe that the processor p2 is not participating in all rounds and hence it is removed the load distribution process.

@&#CONCLUSIONS@&#
