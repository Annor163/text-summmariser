@&#MAIN-TITLE@&#
Eidetic Wolf Search Algorithm with a global memory structure

@&#HIGHLIGHTS@&#
We provide an improved Wolf Search Algorithm (WSA) using a global memory structure.The algorithm is tested in several experiments based on 7 test problems.Comparisons with regular WSA, ACO, and PSO show advantages but also limitations.Further insights concern a suitable size of the global memory structure.

@&#KEYPHRASES@&#
Metaheuristics,Wolf Search Algorithm,Global memory structure,Ant Colony Optimization,Particle Swarm Optimization,

@&#ABSTRACT@&#
A recently proposed metaheuristics called Wolf Search Algorithm (WSA) has demonstrated its efficacy for various hard-to-solve optimization problems. In this paper, an improved version of WSA namely Eidetic-WSA with a global memory structure (GMS) or just eWSA is presented. eWSA makes use of GMS for improving its search for the optimal fitness value by preventing mediocre visited places in the search space to be visited again in future iterations. Inherited from swarm intelligence, search agents in eWSA and the traditional WSA merge into an optimal solution although the agents behave and make decisions autonomously. Heuristic information gathered from collective memory of the swarm search agents is stored in GMS. The heuristics eventually leads to faster convergence and improved optimal fitness. The concept is similar to a hybrid metaheuristics based on WSA and Tabu Search. eWSA is tested with seven standard optimization functions rigorously. In particular, eWSA is compared with two state-of-the-art metaheuristics, Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO). eWSA shares some similarity with both approaches with respect to directed-random search. The similarity with ACO is, however, stronger as ACO uses pheromones as global information references that allow a balance between using previous knowledge and exploring new solutions. Under comparable experimental settings (identical population size and number of generations) eWSA is shown to outperform both ACO and PSO with statistical significance. When dedicating the same computation time, only ACO can be outperformed due to a comparably long run time per iteration of eWSA.

@&#INTRODUCTION@&#
In mathematical science it is generally known that there is no efficient algorithm to solve NP-complete optimization problems, thereby motivating researchers to innovate stochastic algorithms for generating approximate instead of deterministic solutions. Also for difficult continuous optimization problems with multiple local optima, nondifferentiable objective functions, or with challenging constraints, stochastic algorithms have often shown to be superior to more traditional optimization methods. Swarm intelligence algorithms have lately emerged in computational science. These showed good results in various applications of optimization domains, such as supply chain logistics (Chiang, Che, & Cui, 2014), flowshop scheduling (Zhang & Wu, 2014) and mechanical design (Cheng & Lin, 2014) by Particle Swarm Optimization algorithms; RFID network optimization (Ma, Chen, Hu, & Zhu, 2014), image processing (Charansiriphaisan, Chiewchanwattana, & Sunat, 2013), and cast scheduling (Pan, 2016) by Artificial Bee Colony Algorithm; computer vision (Xiao, Xia, Zhu, Huang, & Xie, 2013), power channel optimization (Lin, Tsai, & Lee, 2013), routing in mobile networks (Rupérez Cañas, Sandoval Orozco, García Villalba, & Hong, 2013), industrial layout problems (Hani, Amodeo, Yalaoui, & Chen, 2007), pattern matching (Sreeja & Sankar, 2015), and vehicle routing (Schyns, 2015) by Ant Colony Optimization (ACO). One of the most prominent representatives of swarm intelligence is Particle Swarm Optimization (PSO) (Eberhart & Kennedy, 1995) which has been used successfully in a broad range of applications (Poli, Kennedy, & Blackwell, 2007), e.g. for flowshop scheduling problems (Tseng & Liao, 2008) or in neural network-based applications (Sermpinis, Theofilatos, Karathanasopoulos, Georgopoulos, & Dunis, 2013). PSO is also popular because of its simplicity and applicability to various types of optimization problems. Another very popular algorithm in this group of methods are ACO algorithms which have been shown to be quite successful for finding optimal or almost optimal solutions for difficult optimization problems (Dorigo, 2001; Liao, Stützle, de Oca, & Dorigo, 2014; Socha & Dorigo, 2008). More recently emerging swarm intelligence algorithms are, for instance, the Bat Algorithm (Yang, Deb, & Fong, 2014b), Cuckoo Search (Yang & Deb, 2013), the Krill Herd algorithm (Wang, Deb, & Cui, 2015), and Monarch Butterfly Optimization (Wang, Gandomi, Alavi, & Deb, 2015).While ACO is one of the most representative algorithms that utilize stigmergy for building new solutions stochastically, the Wolf Search Algorithm (WSA) (Tang, Fong, Yang, & Deb, 2012) can be potentially improved by stigmergy. To guide the search towards promising solutions, ACO retains the heuristic information from past generations as pheromone trails. The strength of the pheromone trail is reinforced iteratively depending on the quality of the solutions found by the ants. The ants moisten the trails which are relatively more favorable with fresh pheromones in the direction of the highest pheromone concentration. With the increased probability of the strongest pheromone trail by which the ants travel, the ants eventually will converge to the most frequently used trail as the fittest solution. Other swarm algorithms such as PSO have been enhanced by using memory from the path of visited solutions as well (Yin, Glover, Laguna, & Zhu, 2010).Using the same concept of artificial stigmergy which is a mechanism of communication among the search agents by modifying the environment, a modified version of WSA called Eidetic-WSA (eWSA) is proposed in this paper. eWSA contributes to fast convergence and possibly yields better solutions than the original WSA. The objective of this paper is to investigate the efficacy of eWSA in comparison particularly to ACO and PSO which are both popular and proven successful in many applications. The rest of the paper is organized in this way: Section 2 reviews the background of incorporating external memory into metaheuristic search agents. The principles of the proposed eWSA are described in Section 3. The experiments which are designed to validate eWSA and compare eWSA versus ACO and PSO are presented in Section 4. The results are then discussed in Section 5. Section 6 concludes the paper.

@&#CONCLUSIONS@&#
