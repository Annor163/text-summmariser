@&#MAIN-TITLE@&#
An ensemble-based data fusion approach for characterizing ultrasonic liver tissue

@&#HIGHLIGHTS@&#
We extract four feature representations for the ultrasonic liver tissue characterization and use four different classification algorithms.The proposed algorithm can form an ensemble with good generalization performance.The combination of multiple classifiers with different features is an effective approach to characterize ultrasonic liver tissue.

@&#KEYPHRASES@&#
Ensemble of classifiers,Multiple classifier systems,Wavelet transform,Gabor filter bank,Multiresolution analysis,

@&#ABSTRACT@&#
This study investigates the feasibility of an ensemble of classifiers in characterizing ultrasonic liver tissue. Texture analysis generally requires feature representation and classification algorithm. From a variety of feature representations and classification algorithms, obtaining optimal ensembles composed of any feature-classifier pairs is difficult. This paper proposes an ensemble creation algorithm that can form an ensemble with high generalization performance. The pattern recognition process comprises four main stages. The first stage utilized multiresolution analysis to extract intrinsic features of ultrasonic liver images. By utilizing spatial-frequency decomposition, a feature vector was obtained by collecting the feature representation for each subimage. In the second stage of the study, various classification algorithms with diverse feature vectors were trained. Based on the trained classifiers, an ensemble was created by using the proposed algorithm in the third stage. The last stage was concerned with the aggregation of individual classifiers. The proposed approach was applied to discriminate ultrasonic liver images from three liver states: normal liver, cirrhosis, and hepatoma. Based on the six well-known fusion schemes, the experimental results showed that the ensemble proposed in this study yields more discrimination. The results indicate that the combining multiple classifiers with different features is an effective approach for characterizing ultrasonic live r tissue. Furthermore, a clinician can use the quantitative index of the classification results when deciding whether to conduct an advanced medical examination, thus improving the quality of medical care.

@&#INTRODUCTION@&#
Ultrasonic imaging has been widely adopted in many hospitals and clinics as a safe and effective diagnostic tool for visualizing organs and soft tissues in the human abdominal cavity. By visually interpreting B-scan images, clinicians can evaluate the pathological condition of liver tissue by observing brightness and texture compared to surrounding areas [1,2]. Hence, characterizing liver tissue by using an ultrasound apparatus depends principally on the clinical experience of physicians to observe particular textural characteristics; thus, the process is prone to subjective interpretation.In previous applications of texture analysis algorithms in characterization of liver diseases, supervised classification is generally adopted. In performance of supervised classification, determining a set of efficient and meaningful features to characterize liver tissue is a vital task [3–8]. Recently, approaches based on multiresolution analysis, such as wavelet transform or Gabor filter bank have been widely used in texture classification [4,5,9–14]. One of the motivations for multiresolution analysis comes from the model of human visual system that exhibits the following properties: multichannel decomposition of retinal images, extraction of important boundaries as zero-crossings of retinal images, and spatial and spectral localization of the important properties of the retinal image [15]. Multiresolution analysis provides a precise and unifying framework for analyzing an image that can locate energy in both the spatial and frequency domain close or equal to the theoretical bound determined according to Heisenberg's uncertainty principle. Thus, multiresolution analysis based on wavelet transform or Gabor filters is an excellent tool for spatial-frequency decomposition.Considerable effort has been devoted to characterize the ultrasonic liver tissue [1–8]. The developed schemes are usually based on using one type of texture features and do not gain from the interaction of different classifiers in order to reach better recognition results. Classifiers using distinct feature sets often produce uncorrelated errors. Classification performance can be improved by obtaining a consensus on their decisions. Hence, determining how to achieve optimal recognition performance is a compelling challenge when multiple classifiers are available.Information fusion technology has developed rapidly in recent years. Three main types of fusion strategies [16] are data fusion, feature fusion, and decision fusion. Data fusion simply combines different domains of raw data to form new raw data. Feature fusion selects and combines features extracted from various domains to obtain a better feature subset [17]. Decision fusion combines multiple classifiers to provide a better result [18]. In the past decade, using multiple classifier systems has been proposed to optimize classification performance. Some of these studies have focused on melanoma diagnosis [19], protein secondary structure prediction [20] and facial recognition [13]. Usually, multiple classifiers based on different feature sets can offer complementary information on the input pattern, and combining these classifiers improves performance. When developing a multiple classifier system, two important issues should be considered. Firstly, creating a set of complementary classifiers is necessary. Secondly, a decision fusion method should be designed to effectively aggregate the output of the classifiers. Hence, to select adequate classifiers from a pool of classifiers with high performance and diversity is an important task.Diversity is a crucial condition for obtaining accurate ensembles [19–22]. However, in the classification context, no complete or undisputed theory explains why and how diversity between individual classifiers contributes to overall ensemble accuracy [20]. The main difficulty of using diversity measures is the so-called accuracy-diversity dilemma. Usually, diversity measures can be categorized into two types [19], pair-wise and non-pair-wise. The pairwise measures are used to evaluate the diversity between all possible pairings of classifiers in the ensemble, such as Q statistic, double fault, disagreement, and correlation. The non-pairwise diversity measures consider all the classifiers together and directly calculate one diversity value for the ensemble, such as entropy, variance and generalized diversity.This study presents a multiple classifier architecture combined with an evidence fusion technique for characterizing ultrasonic liver tissue. An ensemble creation algorithm is proposed to select adequate classifiers with high recognition rate and diversity. After obtaining adequate classifiers, the output of the classifiers is integrated by using a fusion scheme. Among fusion methods [23–28], the fuzzy integral method is most appropriate for solving the problem of pattern recognition, because it is a nonlinear, numeric-based approach. The fuzzy integral fuses information from multiple sources to achieve the final classification. Adopting a fuzzy integral in membership aggregation rather than a traditional aggregation operator leads to critical distinction in how fuzzy integration processes are used. In general, individual information sources could lose their respective significance in final decision-making. Instead, the properties of the fuzzy integration are emphasized, thereby providing a degree of membership for a particular class from each individual source of information. This holistic utilization of the fuzzy integral is crucial to the integration of information. Herein, the fusion scheme adopts the fuzzy integral to integrate information from diverse classifiers, and each classifier uses a multiresolution feature vector to perform classification. This scheme can provide a quantitative indicator that reveals the degree of suspected disease for each sample. Furthermore, other well-known fusion schemes are also used to evaluate the effectiveness of the ensemble created for comparison.The remainder of this paper is organized as follows: Section 2 reviews the relevant methods; Section 3 describes the proposed ensemble creation algorithm; Section 4 presents the experimental setup and the experimental results; and lastly, Section 5 offers concluding remarks.A multiple classifier system can be grouped into three main categories: sequential, parallel, and hierarchical. In sequential system architecture, the classification results generated by a classifier are often used to direct the classification processes of the successive classifiers. The problem with this type of configuration is that errors made by previous classifiers are not recoverable by the successive classifiers; therefore, the overall system error is the accumulation of the errors of individual classifiers in the system. In the parallel architecture, the classifiers generate results independently and then a decision process integrates the results from all the classifiers. If the decision process is well designed, the overall system may reach peak performance. In addition, classifiers in the parallel architecture can be implemented by parallel processors to achieve real-time performance. In a hierarchical architecture, the control strategy is a combination of sequential and parallel processing. In this study, we address the problem of decision processes in a parallel architecture, as given in Fig. 1. Herein, we focus on combining classification results obtained using N different feature sets. Each feature set is used to train a classifier; hence, there are N different classifiers.Feature computation is the first step in a pattern recognition system. In this study, the feature vector is computed based on multiresolution analysis. Multiresolution analysis facilitates the decomposition of a signal into numerous details at various resolutions where each resolution characterizes distinct physical structures within the signal. The formulation represents a signal by decomposing it into subbands, and each subband can successively be treated individually based on its characteristics. As shown in Fig. 2, feature extraction consists of multiresolution analysis and feature representation.Traditional multiresolution analysis involves using a two-channel filter bank to decompose subimages recursively in the low-frequency channel. However, significant texture information may also be found in the middle frequency channel; hence, merely decomposing subimages in the lower frequency channel may not provide information that is sufficiently discriminative for classification. General multiresolution analysis based on M-band wavelet transform can offer a more flexible tiling of the time-scale plane than the two-band multiresolution analysis can. For the background and implementation details of the M-band wavelet transform, readers may refer to [5].From the discrete-time signal processing viewpoint, a close relationship exists between M-band wavelets and M-channel filter banks. Thus, performing an M-band wavelet transform does not require precise forms of the scaling function and wavelet functions, but merely depends on the scaling filter and wavelet filters, which must meet several conditions [29]. These filters play a vital role in a given wavelet transform. Accordingly, an M-band wavelet basis can be fully specified by the choice of the scaling filter and M-1 wavelet filters. Specifically, the filter bank provides an easy means to relate the coefficients of an M-band wavelet analysis at various levels of decomposition [5].It has been shown that Gabor wavelets are optimal in that they minimize the uncertainty in space and frequency domains [30]. Gabor filters are self-similar, meaning that all filters can be generated from one filter through dilation and rotation. Each filter is in the shape of plane waves with frequency, restricted by a Gaussian envelop function with relative widths. The parameters of a Gabor filter are the central frequency, the orientation, the number of scale levels, and the relative widths of the Gaussian function. Extracting useful features from a signal normally requires a set of Gabor filters containing different frequencies and orientations that cover the appropriate spatial frequency space.Developing a set of texture features that can successfully discriminate textural pattern classes is an essential task of texture analysis. Among texture features, those based on fractal dimensions have been applied successfully to texture classification [5,10,31,32]. Moreover, energy and energy deviation values have been adopted in MPEG-7 to describe image texture [33]. This study adopted these two texture descriptors.To describe the image texture, the texture descriptor is based on a filter bank approach. The texture descriptor components are the first and second moments of energy in channels.(1)Ei,j=1W⋅H∑y=0H−1∑x=0W−1|Ii,j(x,y)|(2)σi,j=1W⋅H∑y=0H−1∑x=0W−1(|Ii,j(x,y)|−Ei,j)2where Ii,j(x,y) is the intensity of the filtered image of size W·H at scale i and in the direction j. Hence, if S scales and K orientations are considered in the implementation, then the corresponding feature vector is given as follows:(3)FV=(E0,σ0,E1,1,σ1,1,E1,2,σ1,2,…,Ei,j,σi,j,…,ES,K,σS,K)where E0 and σ0 are the first and second moments of the original image and Ei,jand σi,jare the first and second moments of the filtered image at scale i and in the direction j.The concept of fractal was first proposed by Mandelbrot to describe the shape and appearance of objects that possess repeating patterns when viewed at increasingly fine magnifications [34]. This special quality of scale invariance, which shows up in many natural patterns, can be identified and quantified by the fractal dimension (FD) that is strictly larger than the topological dimension. It provides a way to numerically measure their degree of boundary irregularity or surface roughness. Therefore, by regarding the intensity of image pixels as their height above a plane, the intensity surface can be viewed as a rugged surface, and the fractal dimension can provide a quantitative measure of the roughness of an image [35,36]. Different fractal dimension values indicate different texture structures in the image. Usually, the more complex the texture structure is the higher its FD value will be. The FD has been successfully exploited in different medical image analysis areas [5,10,31,32]. That is, the fractal dimension can provide a quantitative measure of a textured image.Box-counting approaches are popular for estimating the fractal dimension of images. Among the box-counting approaches, we use the revised differential box counting method [32] because it encompasses a high dynamic range and can be computed efficiently. The method is applied to decomposed subimages to extract a multiresolution fractal feature vector. Hence, the corresponding feature vector is given as follows.(4)FV=(FD0,FD1,1,FD1,2,…,FDm,1,…,FDm,i,…)where FD0 is the fractal dimension of the original image and FDm,idenotes the fractal dimension of the ith subimage at scale level m.Several classifiers are in common use of which the minimum distance classifier (MDC) is one of the most economical ones. In MDC, each class is estimated by a single prototype, usually a centroid. It provides classification at minimal total parameter requirement and computational demand. k-nearest neighbor (k-NN) classifier is another prominent classifier [37]. In classification, the k closest neighbors of a pattern vector are found from among all the prototypes. The class label is decided by the majority rule. However, the classification results are unable to offer the degree of membership for a particular class. Nevertheless, based on fuzzy theory, fuzzy k-NN algorithm gives not only a class to which the pattern is assigned, but also the class membership degree that provides information about the certainty of the classification decision. Additionally, neural network classifiers have shown promise in pattern classification [38]. In recent years, the support vector machine (SVM) has emerged as a successful classification method [39]. In this research, we adopted four different classification algorithms to perform classifier combination: the minimum distance classifier, fuzzy k-NN classifier, probabilistic neural network, and SVM.Let E={e1, e2,…, eL} be a set of L classification algorithms and C={ω1, ω2,…, ωK} be a set of K class labels. We assume that there are S types of feature vectors. Accordingly, we may employ L*S classifiers to learn the classification task. Each classifier receives the feature vectorxi∈Rni,1≤i≤Sas its input, where niis the cardinality of the feature vector xi, which is assigned to a class label from C. The classifier output is a K-dimensional vector with supports to the classes, i.e.(5)el(xi)=[el,1(xi)el,2(xi)…el,K(xi)]T,where el,k(xi) is the degree of support given by classification algorithm elwith ith type of feature vector to the hypothesis xithat comes from ωk. Combining classifiers means to find a fusion method,F,to obtain the support for class ωkbased on L*S classifier outputs, i.e.(6)P(ωk)=F(e1,k(x1),e1,k(x2),…e1,k(xS),e2,k(x1),e2,k(x2),…,e2,k(xS),…eL,k(x1),eL,k(x2),…eL,k(xS))Hence, the class is selected as the one with the maximum value of P(ωk):(7)c=argMaxkP(ωk)Combining classifiers is a powerful method for increasing classification rates in pattern recognition problems. The aim of the decision process is to produce more accurate results by effectively integrating classification outputs from different classifiers. In this study, we obtained quantitative classification results, instead of hard classification results, to indicate the possibility of a specific disease. Hence, we compare the different combination schemes, e.g. majority rule [23], the Borda count [40], arithmetic mean, weighted averaging [24], and the fuzzy integral [25–28], to obtain the best classification results. Herein, majority rule and the Borda count are used for comparison. A brief description for each scheme is given below.The correct class is the one most often chosen by different classifiers. If more classifiers label a sample as one class than as any other classes, then the sample is assigned to that class. The discriminant function for class ωkis given as(8)P(ωk)=∑l=1L∑i=1Sdl,kiwheredl,ki=1ifk=argMaxcel,c(xi)Hence, the class is selected by (7).For any class ωk, the Borda count is the sum of the number of classes ranked below k by each classifier. It is defined as follows:For any class ωkin a set C, let Bj(ωk) be the number of classes in C which are ranked below the class ωkby classifierej. The Borda count for class ωkis(9)P(ωk)=∑jBj(ωk)The final decision is made by selecting the class yielding the largest Borda count. Intuitively, if the class ωkis ranked near the top by more classifiers, its Borda count tends to be larger. The magnitude of the Borda count for each class measures the strength of agreement by the classifiers with the proposition that the input pattern belongs to that class. The Borda count method assumes an additive independence between the rankings. It is simple to implement, and requires no a priori knowledge of the classifier.If N classifiersej, 1≤j≤N, are available, the class ωkoutput of the combiner is:(10)P(ωk)=1N∑j=1Nej,kThe maximum of the arithmetic averaging values is chosen as the correct class. The arithmetic averaging value of the correct class indicates the degree of membership for the class.The scheme uses weights based on the classification rate of the training set for each class. Then we can obtain a weighted averaging output for each class as defined below.If N classifiersej, 1≤j≤N, are available, the class ωkoutput of the weighted averaging combiner is:(11)P(ωk)=1N∑j=1Nαkej,kwhere the weights αkare the degree of importance of the corresponding classifiers for the class ωk.The correct class is the maximum of the weighted averaging values. The weighted averaging value of the correct class indicates the degree of membership for the class. If all weights αj,kare set to 1, the combiner is simply averaging.Integrals are the most important aggregation tools in many areas, especially in decision fusion. The fuzzy integral is a nonlinear function that is more suitable to practical problems. In the model of fusion multiple classifiers based on the fuzzy integral, classifiers are the information sources, and each classifier can gain the estimation of the sample independently, then the evidence is combined by the fuzzy integral. The characteristic of this model is that both pieces of evidence and the importance of classifiers in obtaining the final results are considered in the fusion algorithm.Sugeno first proposed the theory of fuzzy measures and fuzzy integrals [41]. A fuzzy measure uses a set function that is monotone but not always additive. Based on the notion of fuzzy measure, Sugeno defined a new integral called Sugeno fuzzy integral, which can be regarded as a nonlinear weighted mean.Regarding the same fuzzy measure, Murofushi and Sugeno proposed the so-called Choquet integral [42]. The Choquet integral coincides with the Lebesque integral when the measure is additive, but this is not the case for the Sugeno integral. However, comparative results from the fusion of multiple classifiers will indicate the classification performance for both integrals in this study.Given a large pool of different classifiers there are generally several possible combining strategies to follow and it is usually not clear which one is the optimal strategy for a particular problem. The simplest strategy could be to select the single, best performing classifier based on the training data. Such an approach does not guarantee optimal performance. Moreover, there is a possibility that at least some subsets of classifiers could jointly outperform the best classifier if suitably combined. An optimal combination of classifiers should have good individual performance and at the same time a sufficient level of diversity. The aim of the ensemble creation method proposed in this paper is to create several classifiers with good recognition rates and sufficient diversity. The method provides the answers to the questions of which classifiers and how many of them should be selected to obtain improved combined performance of the selected subset.Let E={e1, e2,…, eL} be a set of L classification algorithms and C={ω1, ω2,…, ωK} be a set of K class labels. We assume that there are S types of feature vectors. Accordingly, we may employ L*S classifiers to learn the classification task. To use the performance of the classifier with the specific feature vector, the mean correct classification rate was defined as(12)P¯i,j=[P¯i,j(1)P¯i,j(2)…P¯i,j(k)]Twhere 1≤i≤L, 1≤j≤S,P¯i,j(k)is the averaged degree of support given by the ith classification algorithm with jth type of feature vector for the kth class. The total correct classification rate for each classifier was defined as(13)CRi,j=Σkni,j,kΣkNkwhere ni,j,kis the number of correctly classified samples out of a total of Nkfrom the kth class.Based on given individual performances, we can select the candidate classifiers. Their individual performances are above the average performance of the classifier pool. This criterion provides a minimum performance in the classifier pool.(14)Candidateclassifiers:ei,jifCRi,j≥1LS∑l=1L∑m=1SCRl,mwhere ei,jis the ith classification algorithm with the jth type of feature vector.Since the main reason for combining classifiers is to improve their performance, a diverse ensemble has greater potential for improved accuracy. An ensemble of diverse classifiers is characterized by the misclassification of patterns having a low correlation among the individual classifiers contained in the ensemble. Relevant literature reports various measures of diversity between base classifiers [21,43]. Diversity measures are often divided into parts: non-pairwise and pairwise. Using the non-pairwise diversity measures involves considering all the classifiers together and directly calculating one diversity value for the ensemble. These measurements are used to calculate the misclassification of patterns in the data set. The pairwise measures are used to evaluate the diversity between all possible pairings of classifiers in the ensemble.In general, the total correct classification rate for each classifier does not provide information about performance for each class. However, the mentioned measurements do not involve using information about the difference of classification performance for each class. Such information can provide an index of sensitivity or specificity in medical application.In this study, we adopted a pairwise diversity measure based on the differences in performance between the two classifiers for each class. The diversity measure is expressed as follows.(15)div=P¯i,j−P¯m,n=∑k=1K(P¯i,j(k)−P¯m,n(k))2Hence, we define a fitness function of two classifiers as follows.(16)Fitness(ei,j,em,n)=(CRi,j+CRm,n)+λP¯i,j−P¯m,nwhere (CRi,j+CRm,n) provides the performance of the two classifiers at the training stage and parameter λ>0 controls the balance between the two criteria. A suitable value of λ depends on the application. Hence, the fitness function provides trade-off information between the individual accuracies and the diversity between the classifiers. The proposed ensemble creation algorithm is listed as follows.Ensemble creation algorithm.Goal: to create a classifier ensembleInput:P¯i,j,CRi,j, in the training stageOutput: classifier ensembleEkStep (1) Find candidate classifiers ei,jifCRi,j≥1LS∑l=1L∑m=1SCRl,mStep (2) Calculating fitness for each pair of classifiers and sorting in descending order.Fitness(fi0,j0,fm0,n0)>fitness(fi1,j1,fm1,n1)>fitness(fi2,j2,fm2,n2)>⋯Step (3) Initialize ensembleE0={fi0,j0,fm0,n0},k=0Step (4)Ek+1=Ek∪{fik+1,jk+1,fmk+1,nk+1},k=k+1Step (5) If performance(Ek)>performance (Ek−1) go to Step (4)Else k=k−1The proposed algorithm generates an ensemble of classifiers yielding high classification performance and diversity which are combined by using an aggregation approach.

@&#CONCLUSIONS@&#
This paper proposes an ensemble creation algorithm that can construct an ensemble to characterize ultrasonic liver tissues effectively. The advantages of this methodology are two-fold. The first involves defining a fitness function that provides trade-off information between accuracy and diversity; and the second entails the capability of using the relative significance of the diverse classifiers. Based on the six well-known fusion schemes, we compared the created ensemble with manually constructed ensembles. The experimental results evidenced that the ensemble proposed in this study can yield superior classification accuracies.Furthermore, the obtained quantitative index can indicate the degree of suspected disease, which is especially useful when examining samples that are difficult to interpret. For example, the transformation of liver cirrhosis is progressive, and samples in early cirrhosis are generally undifferentiated from normal livers through visual interpretation. Hence, a quantitative index of classification results that shows values above a certain threshold can alert a clinician to possible liver disease in a patient. In summary, the proposed method can provide clinicians with a quantitative index of necessity for further medical examination and assist them in improving the quality of medical services.