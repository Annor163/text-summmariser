@&#MAIN-TITLE@&#
The Bisection–Artificial Bee Colony algorithm to solve Fixed point problems

@&#HIGHLIGHTS@&#
We introduce a novel iterative method to finding the fixed point of a nonlinear function.We combine ideas proposed in Artificial Bee Colony algorithm and Bisection method.Our method is new and very efficient for solving a nonlinear equation.

@&#KEYPHRASES@&#
Bisection method,Fixed point problems,Artificial Bee Colony algorithm,

@&#ABSTRACT@&#
In this paper, we introduce a novel iterative method to finding the fixed point of a nonlinear function. Therefore, we combine ideas proposed in Artificial Bee Colony algorithm (Karaboga and Basturk, 2007) and Bisection method (Burden and Douglas, 1985). This method is new and very efficient for solving a non-linear equation. We illustrate this method with four benchmark functions and compare results with others methods, such as ABC, PSO, GA and Firefly algorithms.

@&#INTRODUCTION@&#
Solving equations is one of the most important problem in engineering and science. The bisection method in mathematics, is a root-finding method that repeatedly bisects an interval and then selects a subinterval in which a root must lie for further processing so that the range of possible solutions is halved in each iteration. This is a very simple and robust method, but it is also relatively slow. Thus, it is often used to obtain a rough approximation to a solution which is then used as a starting point for more rapidly converging methods [1]. The bisection method is also called the binary search method because of its similarity to the binary search algorithm [1] in computer science.Bio-inspired algorithms are amongst the most powerful algorithms for the optimization problems [2–7,18], especially for the NP-hard problems like the traveling salesman problem and others. Particle Swarm Optimization (PSO) algorithm was developed by Kennedy and Eberhart in 1995 [8] based on the swarm behavior(/intelligence) such as that of fishes and birds schooling in nature. Though particle swarm optimization has many similarities with genetic algorithms, it is much simpler because it does not use mutation/crossover operators. Instead, it uses the real-number randomness and the global communication among the swarming particles. In this sense, it is also easier to implement. The Firefly Algorithm(FA) was introduced by X.S. Yang in 2009 [9] for multimodal optimization applications. He compared FA algorithm with other metaheuristic algorithms such as Particle swarm optimization (PSO).Motivated by the intelligent behavior of honey bees, Dervis Karaboga gave Artificial Bee Colony algorithm(ABC) [10,11] in 2005. It is as simple as Particle Swarm Optimization (PSO) and Differential evolution (DE) algorithms, Genetic algorithm (GA) [12], biogeography based optimization (BBO) algorithm, and uses only common control parameters such as colony size and maximum cycle number. ABC as an optimization tool, provides a population-based search procedure in which food positions are modified by the artificial bees with time and the bee's aim is to discover the places of food sources with high nectar amount and finally the one with the highest nectar. In ABC system, artificial bees fly around in a multidimensional search space and some (employed and onlooker bees) choose food. Development of an ABC algorithm for solving generalized assignment problem, which is known to be NP-hard, is presented in detail along with some comparisons in [13]. Sources, depending on their experience and the experience of their nest mates, adjust their positions. Some applications of the ABC algorithm to solve hard problems are presented in [14–17]. In this paper, we introduce a novel iterative method that combines the advantages of both the Bisection method and the Artificial Bee Colony algorithm to solve the hard fixed point problem.In Section 2, fixed point problem is defined and brief overview of the ABC algorithm and the Bisection method are described. In Section 3, we explain and discuss about our method. In Section 4, we compare accuracy and complexity of proposed method with other algorithms on four benchmark functions. In Section 5, we discuss about the ability of the proposed method.In this section, we define the fixed point problem and briefly explain the ABC algorithm and the Bisection method.In mathematics, a fixed point(invariant point) of a function is a point that is mapped to itself by the function. In other word, a number c is a fixed point for a given function g if g(c)=c. A set of fixed points is sometimes called a fixed set. For example, benchmark functiong3=20+e−20e−0.21/x2−e1/cos(2πx),x∈[1,21]has a fixed point (see in Section 3), but not all functions have fixed points. Function g(x)=x+1, x∈R, has no fixed points, since x is never equal to x+1 for any real number.An iterative method for solving equation g(x)=x is the recursive relation xi+1=g(xi), i=0, 1, 2, …, with some initial guess x0. The algorithm stops when one of the following stopping criterion is met:•D1: total number of iterations is N, for some N, fixed apriori.D2: |xi+1−xi|<ϵ for some ϵ, fixed apriori (Fig. 1).Theorem 1If g is continuous on [a, b] and g(x)∈[a, b] for all x∈[a, b], then g has a fixed point in [a, b].Proof(See chapter 2 of [1]).Theorem 2If g(x) and its derivatives are continuous, |g′(c)|<1 and g(c)=c, then there is an interval I=[c−δ, c+δ], δ≥0, such that the iterative scheme xk+1=g(xk) converges to c for every x0∈I. Further, if g′(c)≠0, then the convergence is linear. Alternatively, ifg′(c)=g′′(c)=...=g(p−1)(c)=0and g(p)(c)≠0, then the convergence is of order p.Proof(See theorem 2.4 of [1]).|g′(x)|<1,∀x∈(c−δ,c+δ)However, the computation of δ is sometimes very difficult to perform. In other words, finding an interval I=[c−δ, c+δ] is difficult.The Bisection method is a numerical method for estimating the roots of a real-valued function. Given a continuous function f on an interval [a, b], where f(a) and f(b) have opposite signs, the problem is to find x that satisfies f(x)=0. Fig. 2gives bisection method to compute the roots of a function.Artificial Bee Colony algorithm (ABC) is an algorithm based on the intelligent foraging behavior of honey bee swarm, purposed by Karaboga in 2005 [4]. In ABC model, the colony consists of three groups of bees: employed bees, onlookers and scouts. It is assumed that there is only one artificial employed bee for each food source. In other words, the number of employed bees in the colony is equal to the number of food sources around the hive. Employed bees go to their food source and come back to hive and dance on this area. The employed bee whose food source has been abandoned becomes a scout and starts to search for a new food source. Onlookers watch the dances of employed bees and choose food sources depending on dances. The pseudo-code of the ABC algorithm is given in Fig. 3.In ABC which is a population based algorithm, the position of a food source represents a possible solution to the optimization problem and the nectar amount of a food source corresponds to the quality (fitness) of the associated solution. The number of the employed bees is equal to the number of solutions in the population. At the first step, a randomly distributed initial population (food source positions) is generated. After initialization, the population is subjected to repeat the cycles of the search processes of the employed, onlooker, and scout bees, respectively. An employed bee produces a modification on the source position in her memory and discovers a new food source position. Provided that the nectar amount of the new one is higher than that of the previous source, the bee memorizes the new source position and forgets the old one. Otherwise she keeps the position of the one in her memory. After all employed bees complete the search process, they share the position information of the sources with the onlookers on the dance area. Each onlooker evaluates the nectar information taken from all employed bees and then chooses a food source depending on the nectar amounts of sources. As in the case of the employed bee, she produces a modification on the source position in her memory and checks its nectar amount. Providing that its nectar is higher than that of the previous one, the bee memorizes the new position and forgets the old one. The sources abandoned are determined and new sources are randomly produced to be replaced with the abandoned ones by artificial scouts.After initialization, the population is subjected to repeat the cycles of the search processes of the employed, onlooker, and scout bees, respectively. An employed bee produces a modification on the source position in her memory and discovers a new food source position. Provided that the nectar amount of the new one is higher than that of the previous source, the bee memorizes the new source position and forgets the old one. Otherwise she keeps the position of the one in her memory. After all employed bees complete the search process, they share the position information of the sources with the onlookers on the dance area. Each onlooker evaluates the nectar information taken from all employed bees and then chooses a food source depending on the nectar amounts of sources. As in the case of the employed bee, she produces a modification on the source position in her memory and checks its nectar amount. Providing that its nectar is higher than that of the previous one, the bee memorizes the new position and forgets the old one. The sources abandoned are determined and new sources are randomly produced to be replaced with the abandoned ones by artificial scouts.In this section, we introduce a novel iterative algorithm by combining the Bisection method and the ABC algorithm (BABC) to obtain the solution approximation of a fixed point problem as g(x)=x. We define a function f(x)=g(x)−x. Thus the problem of finding the fixed points of g(x) is reduced to finding the roots of f(x). We further define a function h(x)=|f(x)|. The problem of finding the roots of f(x) is further reduced to finding an x that minimizes h(x). The idea here is that instead of taking the mid point of the interval I (interval I includes the solution)to be a candidate solution, ABC algorithm is used to give a better approximation, i.e. given an interval Ik=[ak, bk] a candidate solution xkis computed using the ABC algorithm. If f(xk)=0 we are done, else we compute a new interval Ik+1⊂Ikdepending upon whether f(xk).f(ak)<0 or f(xk).f(bk)<0. The pseudo code of the proposed method is given in Fig. 4.Clearly, in Fig. 4 for each iteration we obtain randomly new approximation value xkof the solution equation by ABC algorithm on Ik, for each k∈N. So that, Ik+1 is either [ak, (xk+ak)/2] (only bkchanges) or we have [(ak+xk)/2, xk] or [xk, (xk+bk)/2] (both akand bkchange) or [(bk+xk)/2, bk] (only akchanges). So, we get(1)Ik+1⊆Ik.Thus,(2)c∈⋂Ik.Therefore, the intersection of all the Ik's is nonempty and we have(3)0≤|c−xk|≤(bk−ak)≤(l)k(b−a)for all k and 0<l<1. But this mean that(4)limk→∞(c−xk)=0and/or(5)limk→∞xk=c.Therefore, we have following theorem.Theorem 3If g is continuous on [a, b] and g(x)∈[a, b] for all x∈[a, b] then BABC method is convergent to a fixed point of the function g in [a, b].In this section, we illustrate our algorithm with some examples and compare the results with other evolutionary optimization algorithms like GA, PSO, FA and also ABC.Consider the following benchmark functions:(6)g1(x):x2/4000−cos(x)+1=x,x∈[−20,20](7)g2(x):10+x2−10cos(2πx)=x,x∈[−20,1)(8)g3(x):20+e−20e−0.2x2−ecos(2πx)=x,x∈[1,21](9)g4(x):418.9829−xsinx=x,x∈[400,500]Table 1summarizes these functions.Fixed points of the four functions g1…g4 are plotted in Fig. 5. It can be seen that the fixed points of g1 and g2 are attained at 0. g3 has a fixed point very close to 20 and g4 has a fixed point very close to 490.We show details of solving function f1(x)=0 as follow.At first step random initial value of α generated with ABC algorithm at x0∈I0=[−20, 20], and then with propose algorithm in Section 3, we obtain new approximate value x1∈I1⊆I0 for root and continue until we will reach to best value of root with arbitrary accuracy ϵ=1·e−t, t≫1.Results for the four functions are shown in Table 2and in Figs. 6–9. The table and the figures show that BABC outperforms all the algorithms on all the benchmark functions.

@&#CONCLUSIONS@&#
