@&#MAIN-TITLE@&#
Selective invocation of shape priors for deformable segmentation and morphologic classification of prostate cancer tissue microarrays

@&#HIGHLIGHTS@&#
An optimized level set segmentation scheme, which selectively leverages shape prior.A CAD system to perform automated Gleason grading on large histopathology images.

@&#KEYPHRASES@&#
Level set segmentation,Prostate cancer detection,Histology,Digital pathology,Gleason grading,Shape prior,Active contour,

@&#ABSTRACT@&#
Shape based active contours have emerged as a natural solution to overlap resolution. However, most of these shape-based methods are computationally expensive. There are instances in an image where no overlapping objects are present and applying these schemes results in significant computational overhead without any accompanying, additional benefit. In this paper we present a novel adaptive active contour scheme (AdACM) that combines boundary and region based energy terms with a shape prior in a multi level set formulation. To reduce the computational overhead, the shape prior term in the variational formulation is only invoked for those instances in the image where overlaps between objects are identified; these overlaps being identified via a contour concavity detection scheme. By not having to invoke all three terms (shape, boundary, region) for segmenting every object in the scene, the computational expense of the integrated active contour model is dramatically reduced, a particularly relevant consideration when multiple objects have to be segmented on very large histopathological images. The AdACM was employed for the task of segmenting nuclei on 80 prostate cancer tissue microarray images from 40 patient studies. Nuclear shape based, architectural and textural features extracted from these segmentations were extracted and found to able to discriminate different Gleason grade patterns with a classification accuracy of 86% via a quadratic discriminant analysis (QDA) classifier. On average the AdACM model provided 60% savings in computational times compared to a non-optimized hybrid active contour model involving a shape prior.

@&#INTRODUCTION@&#
Active Contours (AC) can be categorized as boundary-based (first generation) and region-based (second generation) schemes [20,3,5]. Most AC models are not intrinsically capable of handling object occlusion or scene clutter. Therefore, the integration of shape priors into the variational formulation represents a natural way to overcome occlusion. Third generation (hybrid) AC models involve combining a shape prior with geometric/geodesic active contours that simultaneously achieves registration and segmentation [21,26,4]. Rousson and Paragios [26] proposed a novel approach for introducing shape priors into level set representations, focused on 2D closed shapes. A limitation of most third generation AC models, however, is that only one pair of overlapping objects can be accurately resolved at a time. Further, most of these methods are sensitive to model initialization and typically require varying degrees of user intervention [20,3,5,21,26,4]. Moreover, the efficiency of these hybrid schemes are limited by the computational overhead of the non linearity of the convergence of the evolving curve. Additionally, the shape prior (the most computationally heavy term in the variational formulation) is typically invoked in segmenting every object in the scene, regardless of whether or not an overlap exists. Non-overlapping objects, in most cases, can be segmented by first and second generation AC models alone.In this paper, a variational adaptive segmentation scheme (AdACM) is presented. The original instantiation of our segmentation method Ali and Madabhushi [1] combined boundary and region based energy terms with a shape prior in a multi level set formulation to resolve overlapping and non-overlapping nuclei. However, due to the computation overhead of including shape prior energy, such a scheme is computationally expensive for large images (such as histopathology). AdACM selectively invokes the shape prior term in the variational formulation for only those instances in the image where overlaps between objects are identified; these overlaps being identified via a contour concavity detection scheme. By not having to invoke all 3 terms (shape, boundary, region) for segmenting every object in the scene, the computational expense of the integrated active contour model is dramatically reduced, a particularly relevant consideration when multiple objects have to be segmented on very large histopathological images (see Fig. 1). Furthermore, most of the shape based level set models reported in literature are only able to handle the overlap resolution of a single pair of objects per image [21,26,4]. However, AdACM segmentation scheme provides simultaneous segmentation of all overlapping and non-overlapping objects in very large images.In their seminal work, Cootes et al. [7] proposed to use principal component analysis (PCA) to capture the main shape variations of parametric AC's (active shapes) within a training set and thus to represent specific shapes. Consequently, their model is not parametrization free. Leventon et al. [21] proposed the introduction of prior shape information into AC, intrinsically represented by level set functions, the core idea being to apply PCA on the signed distance functions (SDF) of the parametric ACs. This feature allowed them to construct an intrinsic and parametrization free shape model. The shape prior is comprised of the mean level set shape and a weighted sum of the m strongest eigen modes of variation (obtained from the PCA of the SDFs). SDFs have the additional advantage that they are more robust to slight misalignments of the training sequence compared to parametric curves. Unfortunately, the shape functions resulting from PCA are not exactly SDFs, as proved by Leventon et al. [21], but they can nonetheless be used in practice since they are very close to real SDFs. Rousson et al. in a similar fashion, Rousson and Paragios [26] proposed a method where the optimal weight factors of the eigenmodes of variation are estimated by solving a linear system. Bresson et al. [2] integrated the geometric shape prior of Leventon et al. [21] into the segmentation framework based on AC as well as on a region driven term derived from the Chan and Vese energy term [4]. In [26,23], the signed distance functions of the training images are computed and the statistics of the signed distance training set is captured via PCA. This representation assumes that the probability distribution function of the training set is Gaussian.Various segmentation methods have been previously proposed that are bottom-up approaches. Supervised learning [6], multi-reference level-set [15], hierarchical partial matching [25] and various shape-based models [25,29] have been proposed for cell segementation. Recently, a new non-parametric method was proposed to tackle these three challenges in a unified framework [31]. Unlike these previously proposed approaches, our strategy instead of using any parametric model based off shape statistics, incorporates the use of shape priors on-the-fly through a sparse shape composition. However, sparse shape composition has inferior run-time efficiency, in particular when there are a large number of training datasets available for training the model.Prostate Cancer (Cap) is evidenced by profound histological, nuclear and glandular changes in the organization of the prostate. Grading of surgically removed tumor of CaP is a fundamental determinant of disease biology and prognosis. The Gleason score, the most widespread method of prostate cancer tissue grading used today, is the single most important prognostic factor in Cap strongly influencing therapeutic options [11,10]. The Gleason score is determined using the glandular and nuclear architecture and morphology within the tumor; the predominant pattern (primary) and the second most common pattern (secondary) are assigned numbers from 1 to 5. The sum of these 2 grades is referred to as the Gleason score. Scoring based on the 2 most common patterns is an attempt to factor in the considerable heterogeneity within cases of CaP. In addition, this scoring method was found to be superior for predicting disease outcomes compared with using the individual grades alone. Problems with manual Gleason grading include inter-observer and intra-observer variation and these errors can lead to variable prognosis and suboptimal treatment [28]. In recent years, computerized image analysis methods have been studied in an effort to overcome the subjectivity of conventional grading system [22,17,14]. An important prerequisite to such a computerized CaP grading scheme, however, is the ability to accurately and efficiently segment histological structures (glands and nuclei) of interest. Perviously, texture based approaches [19,18] characterized tissue patch texture via wavlet features and fractal dimension. However, a limitation of these approaches were that the image patches were manually selected to obtain region containing one tissue class on the digitized slide. Doyle et al. [9] showed that spatial graphs (eg. Voronoi, Delaunay, minimum spanning tree) built using nuclei as vertices in digitized histopathology images, yielded a set of quantitative feature that allowed for improved separation between intermediate Gleason patterns. Farjam et al. [12] employed gland morphology to identify the malignancy of biopsy tissues, while Diamond, et al. [8] used morphological and texture features to identify 100-by-100 pixel tissue regions as either stroma, epithelium, or cancerous tissue (a three-class problem). Tabesh et al. [27] developed a CAD system that employs texture, color, and morphometry on tissue microarrays to distinguish between cancer and non-cancer regions, as well as between high and low Gleason grade prostate cancers (both cases used binary classification).In this work, we leverage the AdACM scheme for automatic segmentation of all nuclei on large digitized tissue microarrays (TMAs) of CaP. Additionally, we leverage the findings of Veltri et al. [28] who demonstrated a link between nuclear morphology and Gleason grade to develop a nuclear morphology based classifier to predict Gleason grade. We complement the morphologic features extracted from segmented nuclei with (a) graph features extracted from different types of graphs, where the nuclear centers constitute the graph vertices constructed from nuclear centroids and (b) texture features to distinguish primary Grade 3 and Grade 4 prostate cancers. Since the institution of the Epstein criteria [10], there appears to be a trend in pathology grading of prostate tumors towards over-grading, the so called “Gleason drift” whereby most pathologists tend to call prostate cancer patterns starting from 3 and above (corresponding to a score of 6 and above). Consequently, there are almost no prostate cancers that are called 5 and lower, at least in the US. Because of PSA and early detection, more than 80% of the prostate cancers found are therefore a mix of primary grade 3s and 4s (score of 6, 7 and 8) [10], scores of 9 and 10 are rare due to early detection. Since most of the prevalent Gleason scores are 6–8, the patterns that are most important to distinguish between are 3 and 4. Hence, the reason for focusing on only Gleason grades 3 and 4 in this paper. Moreover, grades 3 and 4 have the most variability among pathologists and a good automated Gleason grading scheme needs to be able to accurately and reproducibly distinguish these two patterns. The accuracy of the nuclear classifier is also implicitly reflective of the performance of AdACM, since accurate nuclear segmentation is a pre-requisite for accurately quantifying nuclear morphology. Major contributions of the papers are:1.Adaptive active contour based on shape prior without user intervention.Selectively invoking shape term (computationally expensive step) in the regions of overlapping nuclei identified by concavity detection, thereby reducing computational complexity.Nuclear morphology based classifier to predict Gleason patterns.The rest of the paper is structured as follows. Our hybrid active contour method is described in Section 2., while methodologies for selectively invoking energy terms in the active contour model is discussed in Section 3. We discuss feature extraction for Gleason grading in Section 4, while Section 5 discusses feature selection and classification. We describe the experimental design, results and performance measures in Section 6. In Section 7 we present our concluding remarks.An image is defined asC=(x,fg)where x is a 2D grid representing pixels c∈x, with c=(x, y) representing the Cartesian coordinates of a pixel and fgassigns intensity values to c∈x, wherefg(c)∈ℝ(gray scale). Table 1has the description of notations and commonly used symbols in this paper.The contours that segment the nuclear-boundaries are represented using the level set method, and are evolved by minimizing the variational energy functional. Under the level set framework, the contour is represented implicitly as the zero level of a higher dimensional embedding function, and the contour propagation is performed by evolving the embedding function. This enables handling topological changes of the boundary (splitting and merging) easily.We combine the shape prior, ψ, with a Geodesic Active Contour(GAC) to create the shape functional. The shape prior, ψ, is created using the statistical methods described in [26]. Each shape in the training sample is embedded as the zero level set of a higher dimensional surface. The Signed Distance Function (SDF) is used to encode the distance between the level set (shape contour) and the grid pixels. The level set formulation of the shape functional is expressed as:(1)Fshape=∫Ω(ϕ(x)−ψ(x))2|∇ϕ|δ(ϕ)dxwhere {ϕ} is a level set function, ψ is the shape prior, δ(.) is the Dirac function, and δ(ϕ) is the contour measure on {ϕ=0}. Eq. (1) introduces a shape prior in such a way that only objects of interest similar to the shape prior can be recovered, and all unfamiliar image structures are suppressed. It evaluates the shape difference between the level set ϕ and the the shape prior ψ at each iteration of the evolution. However, this formulation only solves for a single level set consistent with the shape prior.We define a functional to drive the shape model towards a homogeneous intensity region using the shape prior. If our objects of interest have a smooth intensity surface, then the Mumford-Shah (MS) model is the most appropriate model to segment these objects [5]. Since the MS method applied on the AC will extract globally homogeneous regions and our objective is to capture an object corresponding to a particular shape space, the best solution is to apply the MS-based force on the shape prior [5]. Indeed, this new force will globally drive the shape prior towards a homogeneous intensity region based on the shape of interest. The functional Fregioncan be written with the shape function ψ and statistics of partitioned foreground and background regions, uin, uout:(2)Fregion(ψ,uin,uout)=∫ΩΘinHψdx+∫ΩΘoutH−ψdx,where ψ is the shape function, Hψis the Heaviside function [5], Θr=|I−ur|2+μ|∇ur|2 and r∈{in, out}.We define a synergistic model to address the problem of object segmentation, integrating a geometric shape prior with local and global intensity information within a variational framework:(3)F=F1+Fregion(ψ,uin,uout),(4)F1=β1Fshape(C)+β2Fboundary(ϕ,ψ),=∫Ωβ1((ϕ(x)−ψ(x))2)+β2(g(|∇fg|)|∇ϕ|δ(ϕ))dxwhere ψ is the shape function of the object of interest given by the PCA (see Section 2.1), g is an edge detecting function, δ(.) is the Dirac delta function, and δ(ϕ) is the contour measure on {ϕ=0}, and β1, β2 are arbitrary positive constants that balance the contributions of the boundary, shape, and region terms. The proposed functional F1 is an extension of the work of Chan [4] where we have integrated a new statistical shape model. Writing out Eq. (3) in its entirety we have,(5)F(Φ,Ψ,uin,uout)=∫Ωβ1((ϕ(x)−ψ(x))2)+β2(g(|∇fg|)|∇ϕ|δ(ϕ))dx︸Shape+boundaryforce+βr∫ΩΘinHψdx+∫ΩΘoutH−ψdx︸RegionforceProof of existence of solution for above model is provided in our previous method [1].The level set formulation in Eq. (5) is limited in that it allows for segmentation of only a single object at a time. In this work, we incorporate the method presented in [30] into Eq. (5). Consider a given image consisting of multiple objects {O1, O2, ⋯, Om} of the same shape. For the problems considered in this work (nuclei segmentation on histopathology images), all nuclei are assumed to be roughly elliptical in shape. Instead of partitioning the image domain into mutually exclusive regions, we allow each pixel to be associated with multiple objects or the background. Specifically, we try to find a set of characteristic functions χfsuch that:(6)χf(x)=1ifx∈Of,0if otherwise.We associate one level set per object in such a way that any Ok, Ol, k, l∈{1, 2, ⋯, m} are allowed to overlap with each other within the image. These level set components may both be positive within the area of overlap, and enforce the prior on the shapes of objects extracted from the image. We consider a specific case of segmenting two objects within an input image, which is generalizable to N independent familiar objects.The simultaneous segmentation of two familiar objects with respect to the given shape prior is solved by minimizing the following modified version of Eq. (5):(7)F(Φ,Ψ,uin,uout)=∑a=12∫Ωβ1(ϕa(x)−ψ(x))2+β2(g(|∇fg|)|∇ϕa|δ(ϕa)dx+βr∫Ω(ΘinHχ1∨χ2)dx+∫Ω(Θout−Hχ1∨χ2)dx+ω∫ΩHχ1∧χ2dx+∑a=12∫Ω(ϕa−ψa)2dx.whereHχ1∨χ2=Hψ1+Hψ2−Hψ1Hψ2,Hχ1∧χ2=Hψ1Hψ2, Φ=(ϕ1, ϕ2), andΨ=(ψ1, ψ2). The fifth term penalizes the overlapping area between the two regions being segmented, and it prevents the two evolving level set functions from becoming identical. Minimizing Eq. (7) by alternating with respective to dynamic variables, yields the associated Euler-Lagrange equations, parameterizing the descent direction by time t>0.General case ofN>2. The method described above can be generalized for simultaneous segmentation of N>2 independent objects, all of which can leverage the shape prior ψa. Following is the generalized form of Eq. (7):(8)F(Φ,Ψ,uin,uout)=∑a=1N∫Ωβ1(ϕa(x)−ψ(x))2+β2(g(|∇fg|)|∇ϕa|δ(ϕa)dx+βr∫Ω(ΘinHχ1∨χ2)dx+∫Ω(Θout−Hχ1∨χ2)dx+ω∑a≠b∫ΩHχ1∧χ2dx+∑a=1N∫Ω(ϕa−ψa)2dx.We use the popular watershed transformation to obtain the initial delineations of nuclear boundaries in the entire image. By creating the binary mask of the delineations, we obtain the estimated boundaries of the nuclei present.High concavity points are characteristic of contours that enclose multiple objects and represent junctions where object intersection occurs (Fig. 2). The areaA(s)of the closed sub-contour s is compared to predetermined area of an ideal nucleus τA. Hence a sub-contour is eligible for a split ifA(s)>τA. Since c=(x, y), the difference between any two pointscwandcw−1will represent a vector in 2D. Concavity points are detected by computing the angle between vectors defined by three consecutive points(cw−1,cw,cw+1)∈s. The degree of concavity/convexity is proportional to the angleθ(cw)as shown in Fig. 2.θ(cw)can be computed from the dot product relation (Eq. (9)):(9)θ(cw)=π−arccos(cw−cw−1)·(cw+1−cw)||(cw−cw−1)||||(cw+1−cw)||.A point is considered to be concavity point ifθ(cw)>θt, where θtis an empirically set threshold degree. Concavity points can be distinguished from convexity points by computing the cross product of the vectors(cw−cw−1)and(cw+1−cw), where a concavity point would yield a positive cross product if the point were moving in a counterclockwise direction on s (see Fig. 2). The value ofθ(cw)for an eligible concavity pointcwis constrained to be less than an empirically determined value θmax. The value of θmaxserves as a threshold for detecting meaningful concavity points and in our case it was found that θmax=(8/9)π yielded optimal results. Note that numerous false concavity points may also be detected due to noisy boundaries on the contour.The number of detected concavity points, cc≤1, indicates presence of a single non overlapping nucleus. In such cases, shape prior constraint is not necessary and we reduce the model to only employ the region term by setting β1=0. Similarly, l number of ccindicate the presence of l overlapping objects. Hence in those regions we initialize the model with the integrated hybrid model (region, boundary, shape terms) with l level sets and set N=l (in Eq. (7)). The initial contour (as defined by watershed segmentation) is defined as a circle of radius r at the center of the contour, which is also serves as the seed point for placement of the initial level set. Fig. 3illustrates the work flow from initialization to final segmentation for AdACM.We seek to develop a feature set that describes the nuclear morphological, architectural, and textural attributes of CaP from tissue microarrays are then used to describe and discriminate between the different Gleason patterns in the TMAs.From each imageCa feature vector F is created comprising the nuclear, graph, and textural based attributes. These values are calculated as described below.A total of 7 nuclear features from each of the segmented nuclei were extracted. These nuclear morphologic features include: Area Overlap Ratio, Average Radial Ratio, Compactness, Convexity, Mean Nuclear Area, Mean Nuclear Perimeter, Mean Nuclear Diameter.We calculate features that describe the spatial location of nuclei within the histological image. On each of the segmented nuclei, center of mass is calculated to represent the nuclear centroid. To analyze the nuclear architecture in greater detail, we construct a series of graphs, using the nuclear centroids as nodes of the graph. Quantifiable features are then extracted from the these graphs (see Table 2).We denote a graph asG=(V,E,W), where V are vertices, E are edges, and W are edge weights, proportional to length. The set of vertices, edges, and weights make up a unique graph onR. We construct the following graphs (illustrations are shown in Fig. 4)The Voronoi Diagram partitionsRinto a set of polygons with centroids V, where a non-centroid pixel is assigned to the polygon of the closest centroid pixel. This yields a tessellation of the image, as shown in Fig. 4(b). Pixels that are equidistant from exactly two centroids make up E (edges of the graph), while pixels equidistant from three or more centroids make up the intersections of multiple edges. The perimeter, area, and chord lengths of each polygon inGVare computed, and the average, standard deviation, disorder, and minimum to maximum ratio of each are calculated for a total of 12 Voronoi-based features perC.The Delaunay Triangulation is a triangulation of vertices V such that the circumcircle of each triangle contains no other vertices. The Delaunay and Voronoi graphs are dual to each other, meaning that two points are connected inGDif and only if their polygons inGVshare an edge. An example ofGDis given in Fig. 4(c). From this graph, we compute the area and perimeter of each triangle, and the average, standard deviation, disorder, and minimum to maximum ratio of these are calculated to yield 8 Delaunay-based features perC.A spanning tree of a set of points V is an undirected, fully connected graph on V. The weight W of the graph is the sum total of all edges E, and the Minimum Spanning Tree (MST) is the spanning tree with the lowest overall W. The MST, denotedGM, is a subgraph of the Delaunay Triangulation. An example ofGMis given in Fig. 4(d). We calculate the average, standard deviation, disorder, and minimum to maximum ratio of the weights W to yield 4 MST-based features perC.The proliferation of nuclei, difference in size and shape leads to a change in overall textural characteristics in a region of interest (ROI). To quantify this change in tissue texture characteristics, we calculate a number of low-level image statistics from each ROI. These statistics can be broadly characterized into two groups: first-order statistics, second-order co-occurrence features. Each of these is calculated in a pixel-wise fashion and are computed independently for each of the hue, saturation, and intensity channels of the original scanned image, generating a set of corresponding feature images. The average, standard deviation, and mode of each of these feature images is calculated, yielding a texture feature vector to quantify the image. In total, 253 texture features are calculated in this manner. The details of each feature type are given below.We calculate 15 different first-order statistics from each image, including average, median, standard deviation, and range of the image intensities within the sliding neighborhood, as well as the Sobel filters in the vertical, horizontal, and both diagonal axes, 3 Kirsch filter features, gradients in the vertical and horizontal axes, difference of gradients, and diagonal derivative. By calculating these 15 features for each channel in the image, and then calculating the mean, standard deviation, and mode of the feature images, we obtain a total of 135 first-order statistics forC.Co-occurrence features, also referred to as Haralick features [16], are computed by constructing a symmetric 256×256 co-occurrence matrix which describes the frequency with which two different pixel intensities appear together within a fixed neighborhood. The number of rows and columns in the matrix are determined by the maximum possible value in a channel ofC; for 8-bit images, this corresponds to 28=256. Element (a, b) in the matrix is equal to the number of times pixel value a occurs adjacent to pixel value b inC. From the co-occurrence matrix, a set of 13 Haralick features are calculated: contrast energy, contrast inverse moment, contrast average, contrast variance, contrast entropy, intensity average, intensity variance, intensity entropy, energy, correlation, entropy, and two measures of information. Extracting these values from each channel and taking the mean, standard deviation, and mode of each feature image yields a total of 117 co-occurrence features.There are many potential benefits of variable and feature selection: facilitating data visualization and data understanding, reducing the measurement and storage requirements, reducing training and utilization times, defying the curse of dimensionality to improve prediction performance. After extracting texture features, we utilized the minimum Redundancy Maximum Relevance (mRMR) feature selection scheme [24] in order to identify an ensemble of features that will allow for optimal classification of CaP primary grade 3 versus 4. The feature selection scheme is used to identify the most discriminatory attributes from among all of the textural, architectural, and nuclear morphologic features extracted.In the following description, the selected subset of featuresQis comprised of feature vectors Fi, i∈{1, …, |Q|} (note that F={F1, …, FN},Q⊂Fand|Q|<N). The mRMR scheme attempts to simultaneously optimize two distinct criteria. The first is “maximum relevance” which selects features Fithat have the maximal mutual information (MI) with respect to the corresponding label vector L. This is expressed as(10)U=1|Q|∑Fi∈QMI(Fi,L)The second is “minimum redundancy” which ensures that selected features Fi, Fj∈Q, i, j∈{1, …, |Q|}, are those which have the minimum MI with respect to each other, given as(11)V=1|Q|2∑Fi,Fj∈QMI(Fi,Fj)Under the second constraint, the selected features will be maximally dissimilar with respect to each other, while under the first, the feature selection will be directed by the similarity with respect to the class labels. There are two major variants of the mRMR scheme: the MI difference (MID, given by U−V) and the MI quotient (MIQ, given by U/V). These variants represent different techniques to optimize the conditions associated with mRMR feature selection. In this study, we evaluated the use of both MID and MIQ for feature selection as well as determined an optimal number of features by varying |Q| the mRMR algorithm.The Quadratic Discriminant Analysis (QDA) classifier aims to find a transformation of the input features that is able to optimally discriminate between the classes in the dataset. Given a set of samples C with associated feature set, F, QDA solves for Y=FTAF+BTF, where Y={Y1, Y2, …} denotes the resultant vector of QDA.Based on calculating the meansμl(C)=+1,μl(C)=−1and covariances∑lC=+1,∑lC=−1of the 2 classes in the dataset (Grade 3 and Grade 4), we can solve the equation below to calculate the following log likelihood ratio:(12)log(H)=(F−μl(C)=+1)T∑lC−1=+1(F−μl(C)=+1)(F−μl(C)=−1)T∑lC−1=−1(F−μl(C)=−1).Our dataset comprised a total of 80 images obtained from 40 patient cases, in the form of TMAs with 2 TMAs per patient study. The various CaP tissues and controls included in these TMAs were selected and reviewed by a John Hopkins Hospital pathologist. Slides from all cases selected are reviewed and mapped by a pathologist and the normal-appearing and staged and/or graded index tumor areas were identified and marked on the slide for each case. Using these template slides marked for normal-appearing (adjacent) and diagnostic CaP areas, the tissue blocks were coordinately marked using the template slides, and 0.60-mm cores were punched from the normal-appearing and CaP areas and then transferred to recipient blocks. The TMAs were prepared (both normal-appearing and cancer areas) using a Beecher MT1 manual arrayer (Beecher Instruments, Silver Spring, MD) in the Johns Hopkins Hospital TMAJ pathology core facility. Each TMA was constructed using four replicate 0.6mm core tissue samples from the normal-appearing and cancer areas of each patient who had undergone radical prostatectomy for CaP. The 40 studies (consisting of TMAs for cancer areas) comprised 13 Gleason patterns 6 (3+3), 8 pattern 7 (3+4), 7 (4+3) pattern 7, 7 pattern 8 (4+4) and 5 pattern 9 (4+5) studies where the first number in the parenthesis refers to the primary and the second number to the secondary Gleason grade.We qualitatively and quantitatively compared the segmentation performance with the GAC (Geodesic Active Contour) [3] and the Rousson shape based model (RD) [26]. The RD model is a popular region based AC model where the model is driven by the Gaussian distribution of both foreground and background and also involves a shape prior.Experiment 1 Overlap Resolution: The aim of this experiment was to demonstrate the ability of our scheme to correctly resolve the overlap between all intersecting nuclei across 80 histopathology images.Experiment 2 Comparison of our model against the GAC and Rousson-Derich (RD) models in terms of detection accuracy: The aim of this experiment was to compare the detection accuracy of our model over two state-of-the-art AC models, GAC and RD.Experiment 3 Comparison against GAC and RD model in terms of segmentation accuracy: The aim of this experiment was to compare the segmentation performance in terms of boundary and area overlap metrics compared to the GC and RD model.Experiment 4 Runtime analysis and computational efficiency: The aim of this experiment was to evaluate the computational efficiency and speed up achieved by AdACM compared against other models.Experiment 5 Classifier Accuracy: The aim of this experiment is to evaluate classifier accuracy in distinguishing grade 3 vs grade 4. Furthermore, we evaluate the optimal feature set determined by mRMR feature selection method.The metrics used to evaluate object detection include: (1) sensitivity (SN); (2) positive predictive value (PPV); and (3) overlap detection ratio (OR) (see Table 3). The detection results from three models (Chan-Vese, our model and RD) are compared to manual detection results obtained from an expert clinician. The SN and PPV values are computed from the true-positive (TP), false-positive (FP), and false negative (FN) values (TP, FN, FP are subsequently defined):(13)SN=TPTP+FN,(14)PPV=TPTP+FP.TP refers to the number of nuclei correctly identified while FP refers to the number of objects incorrectly identified as lymphocyte nuclei and FN refers to the number of nuclei missed by the model. The detection results are represented as the centroid of the region enclosed by a closed contour. TP, FP, and FN values are obtained by comparing each centroid generated by the model to manually determined object centroid. The overlap detection ratio (OR) (Table 2) is computed as follows:OR=NumberofoverlapsresolvedTotalnumberofoverlaps.An overlap is characterized by the existence of a common boundary between two objects and in our case may be between two or more nuclei.Segmentation results are compared to manual delineations performed by an expert oncologist (which serves as ground truth for segmentation evaluation) by computing boundary based metrics, namely Hausdorff distance (HD), mean absolute distance (MAD), and area overlap metrics (true positive area (TPa), false-positive area (FPa), true-negative area (TNa), and false-negative area (FNa)). The manual delineation is represented as a closed boundaryG.For each of the 8040 nuclear boundary segmentations, a corresponding value for HD and MAD were obtained. HD and MAD values close to zero correspond to better segmentation. The area overlap metrics are used to compute the sensitivity SNa, specificity SPa, positive predictive value PPVaand the overlap ratio OVaof the segmentation results for each of the three models. The area overlap metrics are computed as follows:TPa=|A(S)∩A(G)|A(G),FPa=|A(S)∪A(G)−A(G)|A(G),FNa=|A(S)∪A(G)−A(S)|A(G),andTNa=|C−A(G)|A(G).whereA(·)is the area of the closed boundary. For each image, the set of pixels lying within the manual delineations of the nuclei is denoted asA(G).A(S)is the set of pixels whose level set functions are positive, after the convergence of active contour model. The SNaand PPVavalues are computed in a similar fashion as described in (13) and (14), respectively. SPaand OVavalues are computed as follows:SPa=TNaTNa+FPa,OVa=TPaTPa+FPa+FNa.

@&#CONCLUSIONS@&#
