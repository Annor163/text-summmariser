@&#MAIN-TITLE@&#
Multiview Hessian discriminative sparse coding for image annotation

@&#HIGHLIGHTS@&#
mHDSC conducts sparse coding for multiview features.mHDSC explores the heterogeneity of diverse features.mHDSC boosts the discrimination through the label information.Hessian regularization preserves the high-order information of the local geometry.Hessian regularization steers the solution varying smoothly along the geodesic.

@&#KEYPHRASES@&#
Image annotation,Hessian,Multiview,Sparse coding,

@&#ABSTRACT@&#
Sparse coding represents a signal sparsely by using an overcomplete dictionary, and obtains promising performance in practical computer vision applications, especially for signal restoration tasks such as image denoising and image inpainting. In recent years, many discriminative sparse coding algorithms have been developed for classification problems, but they cannot naturally handle visual data represented by multiview features. In addition, existing sparse coding algorithms use graph Laplacian to model the local geometry of the data distribution. It has been identified that Laplacian regularization biases the solution towards a constant function which possibly leads to poor extrapolating power. In this paper, we present multiview Hessian discriminative sparse coding (mHDSC) which seamlessly integrates Hessian regularization with discriminative sparse coding for multiview learning problems. In particular, mHDSC exploits Hessian regularization to steer the solution which varies smoothly along geodesics in the manifold, and treats the label information as an additional view of feature for incorporating the discriminative power for image annotation. We conduct extensive experiments on PASCAL VOC’07 dataset and demonstrate the effectiveness of mHDSC for image annotation.

@&#INTRODUCTION@&#
Due to the prodigious development of sensors such as cameras and microphones, people can exploit huge amounts of high dimensional data carrying particular kinds of information. Considering the redundancy of these high dimensional data for a particular intelligent task, such as object categorization and human behaviour analytics, it is essential to properly represent the relevant information to reveal the underlying process of these observations.Sparse coding aims to learn a dictionary and simultaneously find a sparse linear combination of atoms from this dictionary to represent the observations (e.g. images and image features). It has received growing attentions because of its flexibility and promising performance for many computer vision applications, such as image denosing [1] and inpainting [4].In recent years, dozens of sparse coding algorithms have been developed and these algorithms can be grouped into the following five categories: reconstructive sparse coding, supervised sparse coding, discriminative sparse coding, structured sparse coding and graph regularized sparse coding.(1)Reconstructive sparse coding: Reconstructive sparse coding methods learn the optimal dictionary and find the corresponding sparse representation by minimizing the data reconstruction error. The representative optimization methods for sparse representation include matching pursuit [16], orthogonal matching pursuit [19] and basis pursuit [3].Supervised sparse coding: Supervised sparse coding methods exploit the label information to learn an over-completed dictionary and the corresponding sparse representation for classification tasks. Pham and Venkatesh [20] considered the class label and the linear predictive classification error and proposed a joint framework of dictionary construction and classification. Zhang and Li [29] incorporated the labels directly into the sparse coding stage and proposed a discriminative K-SVD (D-KSVD) method to retain the separability. Jiang et al. [13] extended D-KSVD by integrating both labels and classification error.Discriminative sparse coding: Discriminant analysis [38,39] plays an important role for classification problems. In contrast to supervised sparse coding which straightforwardly exploit the class label information, discriminative sparse coding methods incorporate class separability criterion into the objective function. Popular class separability criteria include softmax function [15], Fisher discrimination criterion [24], and hinge loss [18]. Mairal et al. [15] used the classical softmax discriminative cost function to leverage the sparse coding. Yang et al. [24] introduced Fisher’s discriminative criterion to sparse coding to ensure the sparse representations have large between-class scatter but small within-class scatter. Lian et al. [18] proposed a max-margin sparse coding method which combined the hinge loss function with sparse coding.Structured sparse coding: Structured sparse coding methods naturally extend reconstructive sparse coding by exploiting the structure sparsity such as group sparsity [28] and hierarchical sparsity [11]. Yuan and Lin [28] extended Lasso to group Lasso which considered group/block structured dependencies among the sparse coefficients. Jenatton et al. [11] employed hierarchical sparsity-inducing norms to learn a hierarchical dictionary which solved tree-structured sparse decomposition problems. Jia and Salzmann [12] exploited structured sparsity to learning a latent space of multiview data.Graph regularized sparse coding: Graph regularized sparse coding methods use graph regularization to exploit the local geometry of the data distribution. Graph Laplacian is a representative graph regularization. Zheng et al. [30] used graph Laplacian to exploit the local geometry of the data distribution by adding a Laplacian regularization (LR) to the sparse coding framework. Gao et al. [8] proposed hypergraph Laplacian regularized sparse coding to preserve the local consistence in the feature space.Although the aforementioned sparse coding algorithms have obtained promising performance for various applications such as clustering, classification, and dimensional reduction, they share some of the following two major problems for image annotation:(1)Since it is expensive to label a large number of images for training a robust model, manifold assumption based semi-supervised learning (SSL) has been introduced to integrate both a small number of labelled images and a large number of unlabelled images to improve the performance of image annotation. LR is one of the most representative works in which the geometry of the underlying manifold is determined by the graph Laplacian. Although LR achieved top level performance for image annotation, it suffers from lacking of extrapolating power. It has been identified that LR biases the solution towards a constant function due to its constant null space, which possibly leads to poor extrapolation capability [14].The aforementioned sparse coding methods are only applicable to images that are represented by single view features. However, in image annotation, images are often described by multiview features. Different views (or equivalently visual features), such as colour histogram, edge sketch and local binary patterns (LBP), characterize different properties of an image [7,17,21]. Each view of a feature describes a specific property of the image, and the weaknesses of a particular view can be reduced by the strengths of others. Although we can concatenate different features into a long vector, this concatenation strategy cannot efficiently explore the complementary of different features because it improperly treats different features carrying different physical characteristics. Therefore, compared to single view feature, multiview features provide more characteristics of images and can significantly leverage the performance especially when features for different views are complementary to one another [37,40–43].To address these problems, we present multiview Hessian discriminative sparse coding (mHDSC) in this paper. Particularly, mHDSC can well leverage multiview sparse coding by seamless integrating Hessian regularization with discrimination. According to proposition 1 in [14], the geodesic function in null space of Laplacian is no other than a const, which implicates that LR biases the solution towards a constant function and then leads to poor extrapolation capability. In contrast to Laplacian, Hessian has richer null space and drives the solution varying smoothly along the manifold. Hessian regularization (HR) is more preferable for exploiting the local geometry than LR. Kim et al. [14,36,37] has demonstrated the excellent performance of HR in regression and classification problems. The proposed mHDSC has the following advantages: (1) mHDSC incorporates multiview features into sparse coding, which effectively explores the complementation of different features from different views; (2) mHDSC treats the label information as an additional view of feature, which well boosts the discrimination without adding more computing complexity; and (3) mHDSC exploits Hessian regularization to preserve local similarity, which steers the solution varying smoothly along geodesics in the manifold.We carefully implement mHDSC for image annotation and conduct experiments on the PASCAL VOC’07 dataset [6]. To evaluate the performance of mHDSC, we also compare mHDSC with several baseline algorithms including discriminative sparse coding (DSC), Laplacian discriminative sparse coding (LDSC), Hessian discriminative sparse coding (HDSC), multiview sparse coding (mSC), multiview discriminative sparse coding (mDSC) and multiview Laplacian discriminative sparse coding (mLDSC). The experimental results demonstrate the effectiveness of mHDSC by comparison with the baseline algorithms.The rest of this paper is arranged as follows. Section 2 presents the proposed mHDSC framework. Section 3 details the implementation of mHDSC. Section 4 discusses some related work. And Section 5 demonstrates experimental results followed by the conclusion in Section 6.In multiview sparse coding (mSC), we are given a multiview dataset of N observations from V views including l labelled data i.e.SL={xi(1),xi(2),…,xi(V),yi}i=1land u unlabelled data i.e.SU={xi(1),xi(2),…,xi(V)}i=l+1N, whereyi∈RPcis the class labels of theithexample (Pcis the number of class). In the following section of this paper, we useXL(v)∈RPv×lto denote thevthview feature vectors of labelled data (Pvis the dimension of the vthview feature),Y∈RPc×lto denote the label vectors, andXU(v)∈RPv×(N-l)to denote the vthview feature vectors of unlabelled data.By incorporating an additional regularization term to control the sparsity and exploit the local geometry, mSC aims to find an integrated sparse representation (code)W∈RNd×Nof the multiview data and a multiview dictionary D={D(1),D(2),…,D(V)}, whereD(v)∈RPv×Ndcontains Nddictionary atoms for the view v. Thus, mSC is written as follows(1)minD,W12N∑v=1V‖X(v)-D(v)W‖F2+φ(W),s.t.‖Di(v)‖⩽1,1⩽i⩽Nd,X(v)={XL(v),XU(v)}where φ(W)=γ1φ1(W)+γ2φ2(W)+γ3φ3(W), φ1(W)=||W||1,∞ is a regularizer that controls the sparsity over W,φ2(W)=∑v=1V‖(D(v))T‖1,∞is a regularizer that controls the structure of dictionary, φ3(W) is a regularizer to preserve the local similarity, and γ1, γ2 and γ3 are parameters that balance the loss function and regularizations φ1(W), φ2(W) and φ3(W), respectively.Although there are different choices for φ2(W) to exploit the local geometry, Laplacian regularization (LR) [30,8] is promising to preserve the local similarity. It is crucial to accurately explore the local geometry in semi-supervised image annotation, because images share similar semantic concepts should be close in the representation w.r.t. the new bases (i.e. the multiview dictionary). Thus, the corresponding sparse codes of the images which share common labels are close to each other. However, LR biases the solution towards a constant function [14], so it is not the best choice for encoding the local geometry for semi-supervised image annotation.In this paper, we propose multiview Hessian discriminant sparse coding (mHDSC) for image annotation. Fig. 1describes the framework of mHDSC. Particularly, mHDSC employs Hessian regularization (HR) to encode the local geometry. And it is applied to multiview features. In addition, mHDSC treats the label information as an additional view of feature to boost the discrimination of the dictionary. Thus mHDSC can be expressed as follows according to (1)(2)minD,W,α12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ1‖W‖1,∞+γ2∑v=1V+1‖(D(v))T‖1,∞+γ3trW∑v=1V+1(αvHv)WTs.t.‖Di(v)‖2⩽1,1⩽i⩽Nd,∑v=1V+1αv=1,αv⩾0,W={WL,WU}whereXL(V+1)=Yis the label information, WLis the sparse representation of labelled data, WUis the sparse representation of unlabelled data, and Hvis the Hessian regularization computed from the vthview feature. It has been shown by Kim et al. [14] that Hessian regularization improves the performance of LR and steers the solution varying smoothly along the coordinate system.Although there are several ways to define the loss function in (2), we use the traditional least squares loss of sparse coding due to its efficiency and simplicity. This loss has been widely adopted in practice, such as [31].The proposed mHDSC treats Y as the additional view feature, so it can infer the label information from the sparse code without using classifiers. In particular, given a test image represented by multiview features x(v), 1⩽v⩽V, mHDSC can estimate the label y, i.e. the (v+1)thview feature by conducting the following two steps. It first obtains w by solving a convex problem(3)minw12∑v=1V‖x(v)-D(v)w‖F2+γ1‖w‖1.Then the label y, i.e. the (v+1)thview feature, is given byy=x(V+1)=D(V+1)w.In contrast to existing works [32–35] that exploit either sparse learning-based feature selection or multi-feature fusion for image annotation and video retrieval, the proposed mHDSC learns a dictionary while finding the sparse linear combination of atoms from this dictionary to represent the multiple observations. Especially, the proposed mHDSC has the following advantages: (1) it naturally encodes the discrimination by treating labels as an additional view feature; (2) it exploits the complementary property of different visual features by incorporating multiview features into the sparse coding framework; (3) it precisely captures the second order information of the local geometry by exploiting Hessian regularization to preserve local geometry; and (4) it can infer the label information from the sparse code without using classifiers.The objective function in (2) is convex w.r.t. D, W or α separately, but not jointly convex w.r.t. D, W and α. In this paper, we iteratively solve the problem by using alternating optimization [2] which optimizes over one variable with others fixed. Generally, the solution of (2) can be divided into three parts: sparse coding, dictionary updating and graph coefficients updating. In Section 3, we detail the optimization algorithm of (2).The optimization of mHDSC contains three steps: (1) learning sparse codes W given fixed dictionary D and graph coefficients α; (2) updating dictionary D given fixed sparse codes W and graph coefficients α ; (3) learning optimal graph coefficients α given fixed sparse codes W and dictionary D. In the following, we first provide a brief description of the alternating optimization of mHDSC, and then present the optimization of each subproblem in detail. For convenience, Table 1lists the important notations used in this paper.Given fixed D and α, the problem (2) can be simplified to:(4)minW12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ1‖W‖1,∞+γ3tr(WHWT),whereH=∑v=1V+1(αvHv),∑v=1V+1αv=1,αv⩾0.Given fixed W and α, the problem (2) can be simplified to:(5)minD12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ2∑v=1V+1‖(D(v))T‖1,∞,s.t.‖Di(v)‖2⩽1,1⩽i⩽NdAnd given fixed D and W, the problem (2) can be simplified to:(6)minαγ3trW∑v=1V+1(αvHv)WT,s.t.∑v=1V+1αv=1,αv⩾0Algorithm 1 summarizes the overall procedure of the alternating optimization.Algorithm 1. Alternating optimization method for (2).Input: XL, XU, Y, γ1, γ2, γ3Output: D,W,α1:Initialize D, W, α, e.g., with random entries.2:repeat3:Update W asW←argminW12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ1‖W‖1,∞+γ3tr(WHWT).4:Update D asD←argminD12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ2∑v=1V+1‖(D(v))T‖1,∞.5:Update α asα←argminαγ3tr(W(∑v=1V+1(αvHv))WT).6: until convergenceThe subproblem (4) can be written as the following general form:(7)minWf(W)+g(W)wheref(W)=12l∑v=1V+1‖XL(v)-D(v)WL‖F2+12(N-l)∑v=1V‖XU(v)-D(v)WU‖F2+γ3tr(WHWT),g(W)=γ1‖W‖1,∞. Both f(W) and g(W) are convex functions. Furthermore, f(W) is differentiable and ∇f(W) is Lipschitz continuous. Hence we can adopt an efficient convex optimization method for subproblem (4). Algorithm 2 shows a variant of Nesterov’s first order method which can solve (4).Algorithm 2. A convex optimization method for (4).Input:XL,XU,Y,D={D1,D2},D2∈RPc×Nd,H,γ1,γ3.Output: W1:ChooseW(0),W∼(0)and let τ(0)=1 andL1=1lσmax(DTD),L2=1N-lσmax(D1TD1),L3=γ3σmax(H).2: fork=0,1,2,…,until convergence do3:Z(k)={ZL(k),ZU(k)}←τ(k)W(k)+(1-τ(k))W∼(k)4:Update(8)WL(k+1)←argminWL‖WL-UL(k)‖F2+γ1τ(k)(L1+L3)‖WL‖1,∞,WU(k+1)←argminWU‖WU-UU(k)‖F2+γ1τ(k)(L2+L3)‖WU‖1,∞,whereUL(k)=WL(k)-1τ(k)(L1+L3)(1l(DTDZL(k)-DTXL)+γ3(WH)L)andUU(k)=WU(k)-1τ(k)(L2+L3)1N-l(D1TD1ZU(k)-D1TXU)+γ3(WH)U.5:W∼(k+1)=τ(k)W(k+1)+(1-τ(k))W∼(k)6:Find τ(k+1)>0 such that(τ(k+1))-2-(τ(k+1))-1=(τ(k))-27: end for8: returnW∼(k)Subproblem (8) can be separated w.r.t. each row of W and efficiently solved using l1 projection [5].Similarly, the subproblem (5) can be separated to (V+1) parts w.r.t. each view. And each part also can be written as the general form of (7) withf(W)=12l‖XL(v)-D(v)WL‖F2+12(N-l)‖XU(v)-D(v)WU‖F2andg(W)=γ2‖(D(v))T‖1,∞.Therefore we can also adopt the framework of Algorithm 2 to solve the subproblem (5). We brief the optimization of (5) in Algorithm 3.Algorithm 3. A convex optimization method for (5).Input: XL, XU, Y, W, γ2Output: D={D(1),D(2),…,D(V+1)}For each v, denote(D(v))Tas B1:ChooseB(0),B∼(0)and let τ(0)=1 andL1=1lσmax(WLWLT),L2=1N-lσmax(WUWUT).2:fork=0,1,2,…,until convergence do3:Z(k)={ZL(k),ZU(k)}←τ(k)B(k)+(1-τ(k))B∼(k)4:Updatecase: v=1,…,VB(k+1)←argminB‖B-U(k)‖F2+γ1τ(k)(L1+L2)‖B‖1,∞,whereU(k)=B(k)-1τ(k)(L1+L2)(1l(WLWLTZL(k)-WLXLT)+1N-l(WUWUTZU(k)-WUXUT)).case: v=V+1B(k+1)←argminB‖B-U(k)‖F2+γ1τ(k)L1‖B‖1,∞,whereU(k)=B(k)-1τ(k)L1(1l(WLWLTZL(k)-WLXLT)).5:B∼(k+1)=τ(k)B(k+1)+(1-τ(k))B∼(k)6:Find τ(k+1)>0 such that(τ(k+1))−2−(τ(k+1))−1=(τ(k))−27:end for8:(D(v))T←B∼(k)9: return DThe subproblem (6) can be equally rewritten as(9)minα∑v=1V+1αvtr(WHvWT),s.t.∑v=1V+1αv=1,αv⩾0The solution w.r.t. α is αi=1 when tr(WHiWT) is the minimum one over different views, and αk=1 otherwise. This means that only one view is selected and this method cannot explore the complementary property of multiple views.In this paper, we employ a trick [22,23] to avoid this phenomenon, i.e. we replace αiwithαir,r>1. Under this setting, each view has a particular contribution to the final sparse coding. And therefore, the new objective function of (9) is expressed as:(10)minα∑v=1V+1αvrtr(WHvWT),s.t.∑v=1V+1αv=1,αv⩾0To solve (10), letλbe a Lagrange multiplier and consider the constraint∑v=1V+1αv=1,and then we get the Lagrange function(11)L(α,λ)=∑v=1V+1αvrtr(WHvWT)-λ∑v=1V+1αv-1.By setting the derivative ofL(α,λ)w.r.t. αvandλto zero, we have(12)∂L(α,λ)∂αv=rαvr-1tr(WHvWT)-λ=0,v=1,…,V+1∂L(α,λ)∂λ=∑v=1V+1αv-1=0.Therefore, a closed form solution αvcan be obtained(13)αv=(1/tr(WHvWT))1/(r-1)∑v=1V+1(1/tr(WHvWT))1/(r-1).The Hessian matrix Hvis semi-definite positive, and thus we always have αv⩾0. When W is fixed, (13) gives the global optimal α.Suppose we are given n samples, v view features. Denote the number of dictionary D atoms as d, the sum dimension of all view features as p, and the number of iteration as k for subproblem (4) and (5), we optimize W and D with the time complexity kO(d2(n+p)+dpn+dn2) and kO(d2(n+p)+dpn), respectively. And the time cost for subproblem (6) is O((v+d)×n2). Denote the number of alternating iterations as η, and the number of candidate parameters that need the m-fold cross-validation as r. Therefore, the total cost of the proposed method is O(mηr(2kd2(n+p)+2kdpn+(kd+v+d)n2)). Since the view number v and dictionary atom number d is generally much smaller than the product of d and iteration number k, the time cost is approximately O(mη r(2kd2(n+p)+2kdpn+kdn2)). When d is much smaller than n and p, the time cost is around O(mη r(2kdpn+kdn2)). When the image set becomes larger (i.e. n≫p), the time cost can be approximate as O(mη r(kdn2)). Since matrix product cost most of the computational time in the proposed method, parallelization (e.g. MapReduce and GPU computing) can be employed to efficiently reduce the time cost.

@&#CONCLUSIONS@&#
