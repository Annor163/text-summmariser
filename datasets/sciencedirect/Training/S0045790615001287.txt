@&#MAIN-TITLE@&#
Non-negative Matrix Factorization on Low-Power Architectures and Accelerators: A Comparative Study

@&#HIGHLIGHTS@&#
Performance and energy consumption study of NMF is performed on different systems.General-purpose CPUs yield better execution times at the cost of high energy rates.Low-power architectures offer better trace-off in energy and performance.

@&#KEYPHRASES@&#
NMF,Low-power processors,GPU,DSP,Accelerators,

@&#ABSTRACT@&#
Power consumption is emerging as one of the main concerns in the High Performance Computing (HPC) field. As a growing number of bioinformatics applications require HPC techniques and parallel architectures to meet performance requirements, power consumption arises as an additional limitation when accelerating them. In this paper, we present a comparative study of optimized implementations of the Non-negative Matrix Factorization (NMF), that is widely used in many fields of bioinformatics, taking into account both performance and power consumption. We target a wide range of state-of-the-art parallel architectures, including general-purpose, low-power processors and specific-purpose accelerators like GPUs, DSPs or the Intel Xeon Phi. From our study, we gain insights in both performance and energy consumption for each one of them under a number of experimental conditions, and conclude that the most appropriate architecture is usually a trade-off between performance and energy consumption for a given experimental setup and dataset.

@&#INTRODUCTION@&#
Recent technological advances in the areas of genetics and molecular biology are the result of interdisciplinary research between diverse fields such as medicine, biology, chemistry and computer science. One of the main challenges these areas will need to face today and in the near future is the ability to process, analyze and interpret massive amounts of data generated in biological experiments.Different data mining methods have proven to be powerful tools to obtain biological patterns. Two of the most extended techniques in large dataset analysis are clustering algorithms and matrix factorization techniques. These methods facilitate multidimensional analysis, that allows dimensionality reduction, or discovering certain patterns that dramatically reduce the burden towards biological interpretation. Dimensionality reduction is a key step for the effective analysis of high-dimension datasets. In this area, Principal Component Analysis (PCA) [1] or Singular Value Decomposition (SVD) [2] are two of the most popular methods. Non-negative matrix factorization (NMF) is also considered as one of the most efficient methods in the biological disclosure due to its ability to establish relevant relationships between experimental datasets.NMF was proposed by Brunet et al. [3] as a powerful tool for gene expression data. They applied it to cancer micro-array data to extract molecular patterns in leukemia, medulloblastoma and central nervous system tumor datasets based on consensus clustering. NMF is nowadays widely used in computational biology for molecular pattern discovery [4], supervised learning frameworks as class comparison and prediction [5], or text-mining [6]. However, the importance of NMF is not limited to computational biology but also to other areas such as image processing for image classification [7] or face recognition [8], information retrieval to extract semantic recognition or hidden meaning in text [9], web-based logs [10], or hyperspectral image processing [11], among others. However, both NMF primitives and applications based on them pose two big challenges from the computational perspective that are closely related:Performance requirements. Factorization of large biological datasets makes NMF a very demanding task from the computational point of view that may make this processing unfeasible in practice, unless high-end distributed memory architectures are used. Due to this fact, parallel implementations of NMF have been previously proposed and successfully applied. In particular, previous works have targeted parallel implementations in shared-memory multi-core processors using the OpenMP paradigm [12], distributed-memory clusters based on Message Passing Interface (MPI) [13], and also exploiting modern Graphics Processing Units (GPUs) [14].Power constraints. Many of the scenarios and applications in which NMF is typically used can be strictly limited by the maximum power that can be supplied to the computing platform (for example, on hand-held devices in biological in-place analysis scenarios), or maximum energy consumed (for example, in on-board hyperspectral image analysis on airborne or spaceborne missions). In such cases, a correct selection of the computing platform and its performance/power ratio is crucial to meet the application requirements in terms of power consumption.Processor manufacturers are nowadays concerned about concepts such as Green Computing and Power-aware HPC. Their goal is to develop efficient processors not only in terms of peak performance rates, but also energy consumption and peak power draw. Besides modern and efficient multi-core CPUs, hardware accelerators such as GPUs or the recently introduced Intel Xeon Phi, specific-purpose architectures such as Digital Signal Processors (DSPs), or ultra-low power processors like ARM-based architectures or hybrid architectures using low-power ARM CPUs and programmable GPUs have been recently introduced in the High Performance Computing field in order to meet at the same time performance and power consumption requirements.The suitability of this type of architectures is primarily dictated by the specific characteristics of the target application, and more precisely, by the efficiency of the underlying software building blocks (e.g. scientific libraries) on top of which those applications are built. As an example, for many biological applications based on NMF, the performance and power efficiency attained on different architectures for this specific operation will dramatically determine the behavior of the overall application. In this paper, we perform a comparative study of several state-of-the-art parallel architectures in terms of performance and power efficiency for a well-known NMF implementation proposed by Brunet et al. [3]. This choice is motivated by the high acceptance of these implementations, but does not exclude the extension to other implementations as Least Squares NMF [15] or Chih-Jen Li approach [16]. To the best of the authors’ knowledge, there does not exist either any viability study of NMF under power consumption constraints in the literature or optimized implementations for novel architectures like multi-core DSPs, low-power ARM or Intel Xeon Phi. This paper extends the insights already extracted in [17], with the following new contributions:•We target novel, state-of-the-art architectures not covered in [17], including ARM Cortex A7 and A15, Nvidia Kepler and Intel Xeon Phi, to adapt the study to new architectures recently emerged in the HPC arena.We extend the pmlib framework to gather actual power measurements from the most representative architectures among the evaluated ones.For these architectures, we extend the power efficiency study already presented in [17] with actual power consumption measurements, describing the measurement environment used in the evaluation process and discussing the suitability of each platform for this specific problem based on realistic considerations.We propose new experimental results for single and double precision arithmetic, and discuss the feasibility of each architecture depending on the desired accuracy.The rest of the paper is organized as follows. Section 2 presents an overview of the selected architectures that are employed to evaluate the performance and power efficiency of our approach. Section 3 introduces the basic concepts of the NMF factorization, together with the specific optimization techniques applied to adapt them to each platform. Section 4 reports detailed performance and power efficiency results and discusses the feasibility of each target architecture for a given experimental condition. Section 5 moves through the description of the power measurement environment used to evaluate the power efficiency of the solutions using realistic power data. Finally, Section 6 closes the paper with some general concluding remarks and future work proposals.In this section, we present the main features of the architectures used in the evaluation of performance and power efficiency of the selected NMF implementations. Four of them (ARM Cortex-A7/A15, CARMA board and DSP) are inherently low-power architectures; two of them are designed as high-end hardware accelerators (Intel Xeon Phi and Nvidia Kepler); the last one (Intel Xeon) is a general-purpose processor that will be evaluated as a baseline for our performance and power consumption measurements and conclusions.Table 1gives an overview of the capabilities of each architecture in terms of theoretical peak performance-measured in GFLOPS (1 GFLOP=1billion floating point operations per second) – and energy efficiency (in terms of GFLOPS per Watt, considering the TDP – Thermal Design Power – as a measure of power consumption for each one of them). We also add information regarding the capability of each architecture to report accurate on-board energy consumption readings; this feature will be leveraged in our empirical energy consumption study in Section 5. Table 2reports the key architectural features of each platform. Finally, Table 3shows the compiler versions, optimization flags and BLAS implementations used in our experimental evaluation. In the rest of the study, we will refer to each architecture using the name reported in Table 1.The increasing processing demands of the mobile market, together with the necessity of designing highly-efficient architectures, have contributed to the development of processing platforms in which Performance per Watt is the primary design concern. This type of systems, often based on the ARM architecture with some accelerating platform attached – low power GPUs or DSPs – has attracted the attention of the HPC community, and has emerged as an appealing alternative for scenarios in which high performance is needed, but power efficiency or maximum available power is a critical restriction. We report next the low-power architectures employed in our study.The ARM Cortex is a line of RISC processors that implements a dual-issue superscalar, out-of-order pipeline. In our case, we use an Odroid XU+E board, featuring a Samsung Exynos 5410 heterogeneous SoC that implements the ARM big.LITTLE hybrid architecture: it presents two independent processing clusters, the first with four ARM Cortex A7 ultra-low power cores and the second with four ARM Cortex A15 cores. Each cluster owns an independent cache hierarchy, while main DDR memory is shared between both. The selection of the specific processing cluster can be modified at runtime depending on the experimental necessities.This type of processors is the base of many current mobile devices (including phones, tablets, hand-held devices and even low-power desktop systems), hence the interest in studying its feasibility for biomedical applications such as those using NMF, in which both mobility and power consumption can be a concern. Their low TDP make them a perfect platform for those applications and scenarios severely limited by the maximum power draw that can be sourced to the computing platform.The CARMA board was introduced in late 2012 to demonstrate the capabilities of ARM and GPU architectures combined in terms of performance and power efficiency. It exhibits a quad-core ARM Cortex A9 CPU with a Quadro 1000M GPU to support the increasing demand for energy-efficient computing, combining a general-purpose programming model on the CPU side and CUDA on the GPU side. The CARMA board combines a theoretical peak performance of 270 GFLOPs with a power consumption of 45W. While not directly designed neither for mobile devices nor for high performance computing, some projects such as the Mont-Blanc project try to deliver Exascale performance with 15–30 times energy saving using this type of low-power hybrid architecture [21].While exhibiting a higher peak power consumption than homogeneous ARM-based architectures, this type of heterogeneous platforms are a trade-off between performance and power consumption for those types of applications that exhibit considerable degrees of data-parallel sections in the code, which can efficiently exploit the potential of the attached GPU.One of novel additions to the energy-aware HPC field is the C6678 multi-core Digital Signal Processor (DSP) from Texas Instruments (TI) [22,23], that implements eight C66x VLIW cores running at 1GHz, and combines a theoretical peak performance of 128 GFLOPs with a power consumption of roughly 10W per chip. Besides, one of its most appealing features is programmability, combining support for general-purpose languages (e.g. C/C++) with well-known parallel programming models such as OpenMP. DSP-based architectures are already present and widely spread in medical equipment and devices specifically designed for biologic analysis, hence the interest in porting routines like NMF for biomedical analysis.This specific-purpose architecture will be even more attractive in novel hybrid SoCs such as the TI Keystone-II architecture, based on ARM technology accelerated by one or more Digital Signal Processors [24]. However, the DSP is unique as it can be a standalone processor, or act as a classical accelerator, using a low-power host processor.As of today, the usage of massively parallel hardware accelerators is playing a key role in the HPC arena. Many of the most powerful supercomputers are today equipped with one or more accelerators per computing node. In some cases, even low-end desktop computers exhibit relatively powerful graphics hardware, that can be exploited to accelerate critical applications. Even though specific-purpose GPUs have been historically the chosen accelerating platform for many scientific applications, the appearance of the Intel Xeon Phi as a general-purpose, highly programmable accelerator is attracting the HPC community to evaluate its efficiency, both in terms of performance and power consumption.The Nvidia Tesla K20 is a high-end GPU that implements the modern Kepler GK110 microarchitecture, featuring 2496 CUDA cores, with a peak performance of 3.52 GFLOPS operating in single precision. Together with the de facto standard in GPGPU programming –CUDA–, these platforms are able to easily exploit the inherent data parallelism available in some applications with a relatively small programming effort. In our case, the evaluated card is equipped with 5 Gbytes of GDDR5 memory, and is attached to a node powered by an Intel Xeon E5 2670 through a PCI-e Gen3 bus.Opposite to graphics processors, the cores in the Intel Xeon Phi microarchitecture are based on the x86 general-purpose architecture, with wide (512-bit) vector units to support heavy data-parallel applications. Together with high-level language constructions to support a host-accelerator model, this makes the porting of existing codes for x86 architectures straightforward. For our evaluation purposes, we will use an Intel Xeon Phi 5110P card, attached to an Intel Xeon E5 2670 through a PCI-e Gen3 bus.We will also evaluate the efficiency of our implementations both in terms of performance and power consumption for a general-purpose Intel Xeon processor, using it as a baseline. More specifically, we use an Intel Xeon E5 2670 featuring two quad-core sockets and running at 2.6Ghz, with 16 Gbytes of DDR3 RAM. We consider this processor to be representative of common modern multi-core architectures for desktop and server environments. In addition, as our accelerator-based architectures are attached to this exact processor model, and its power consumption cannot be ignored in heterogeneous platforms, it is necessary to carry out a detailed evaluation also for this architecture.Non-negative factorization (NMF) was first introduced by Paataro and Tapper in 1994 [15] under the name positive matrix factorization, and popularized by Lee and Seung [8]. The NMF decomposition can be described as(1)V≈WH,whereV∈Rm×nis a positive matrix with m variables and n objects,W∈Rm×kis the reduced k factor, andH∈Rk×ncontains the coefficients of linear combinations of the basis vectors. For the sake of dimensional reduction of NMF, it is assumed thatk≪min(n,m). In particular, for gene expression, the matrix V expresses an experimental biological matrix with m genes and n experimental conditions. For a particular rankk,Hand W represent metagenes (semantic feature) and metagenes expression patterns (gene semantic profile), respectively.In Lee and Seung’s approach, NMF iteratively modifies W and H until their product approximates V. Such modifications are derived from minimizing a cost function that describes the distance between the product WH and V. For this work we consider the well-known NMF factorization reformulated by Brunet et al. [3] with the following update rules:(2)Hαμ←Hαμ∑iWiαViμ/(WHiμ)∑kWkα(3)Wiα←Wiα∑μHαμViμ/(WHiμ)∑νHανH and W are randomly generated, so this approach does not always converge to the same solution. To solve this issue, a consensus matrix assignment is calculated to establish a convergence condition that mitigates probability dispersion in the final solution. Algorithm 1 shows an excerpt of the main NMF code for each iteration of the refinement process; in the algorithm, we only report the necessary operations to update H according to Eq. 2, but similar operations hold for the update of W1The ./ operator stands by element-wise division.1.In this work we have also considered the study of other NMF variants related to sparseness of both the basis and encoding vectors. This method is referred as Nonsmooth Non-negative Matrix Factorization (nsNMF) [25], and it is defined as:(4)V≈WSHwhere V, W, and H are the same as in the original NMF model. The positive symmetric matrixS∈Rk×kknown as “smoothing” matrix is defined as:(5)S=(1-θ)I+θk11Twhere I is the identity matrix, 1 is a vector of ones, and the parameterθ(0<θ<1) controls sparseness of the model.As both NMF approaches are similar from the algorithmic perspective and the type of operations performed, we will take the Lee and Seung’s approach to describe our NMF implementation and optimizations in the following subsections, and for our experimental study. However, we have observed similar qualitative performance and energy consumption results for nsNMF, and thus many of the insights and conclusions extracted can be directly applied also to this method.As can be observed in Algorithm 1, the updates of W and H are mainly based on general matrix–matrix multiplications and other fine grained matrix and vector operations. Hence, the most convenient method for optimizing NMF is to cast these matrix operations in terms of BLAS2http://www.netlib.org/blas.2(Basic Linear Algebra Subprograms) routine calls. This enables the use of highly tuned BLAS implementations specific for each architecture, provided such exists, and thus removes the major part of the optimization task from the developer’s shoulders. As the major part of BLAS implementations provide support multi-threaded execution, this also facilitates the parallelization task of the original sequential code. In our case, the first optimization from the basic sequential code consists of casting the updates of W and H in terms of the corresponding high performance parallel BLAS routine implementation, mainly using xGEMM3From now on, in BLAS calls, x can be replaced by s when using single precision floating-point arithmetic, or d for double precision.3for general matrix–matrix multiplication in (▷(1)) and (▷(4)) and a sequence of xAXPY for the reduction of W to one column (▷(3)).Algorithm 1NMF(Vn×m,Wn×k,Hk×m,niters)1: foriter⩽nitersdo2:3:▷H=H.∗(W′∗(V./(W∗H)))./x14:5:wh=W∗H▷(1)6:wh=V./wh▷(2)7:8:▷Reduce to one column (x1)9:x1=repmat(sum(W,1)′,1,m)▷(3)10:11:Haux=W∗wh▷(4)12:H=(H.∗Haux)./x1▷(5)13:14:▷W=W.∗((V./(W∗H))∗H′)./x215:▷…16:17: end forIntensively using BLAS kernels is the approach taken to optimize the NMF implementation on general-purpose architectures (Arm7, Arm15 and Xeon). We describe next the particularities of the NMF implementations on GPU-based architectures (Carma and Kepler), DSP, and XeonPhi.To port the NMF algorithm to the CUDA programming model, matrix operations must be rewritten into CUDA kernels. This process is enhanced by the possibility of using the BLAS implementation from Nvidia (CUBLAS) which incorporates xAXPY and xGEMM matrix operations. Algorithm 2 shows the pseudo-code for the NMF implementation in a CUDA-enabled GPU, where each line indicates a kernel invocation. Kernels denoted as k__W_mult_H and k__Wt_mult_WH are wrappers to the corresponding invocation to CUBLAS, while k__mult_M_div_vect has been developed specifically for this platform using CUDA. Although the matrix reduction in (▷(3)) is based on a sequence of xAXPY calls, we have observed a performance degradation when using the CUBLAS_xAXPY for the specific matrix dimensions (and shapes) in NMF, and it has been replaced by a specific CUDA kernel with the same functionality.Algorithm 2NMF_GPU(d_V,d_W,d_H,niters)1: foriter⩽nitersdo2:3:▷H=H.∗(W′∗(V./(W∗H)))./x14:5:d_WH←k__W_mult_H(d_W,d_H)▷(1)6:d_WHaux←k__V_div_WH(d_V,d_WH)▷(2)7:x1←k__accum(d_W)▷(3)8:d_Haux←k__Wt_mult_WH(d_W,d_WHaux)▷(4)9:d_H←k__mult_M_div_vect(h,d_Haux,x1)▷(5)10:11:▷W=W.∗((V./(W∗H))∗H′)./x212:…13:14: end forAdditionally, a new kernel is built in order to adjust small values to avoid underflow in W and H. The construction of the connectivity matrix and the convergence criterion is performed on CPU due to low impact in the overall execution time.In Algorithm 2, matricesV,Wand H are replaced by their equivalentsd_V,d_Wandd_H, that have been previously allocated and transferred to GPU memory. After computation, the resulting factors are transferred back to main memory. Pinned memory has been used on the host side to optimize data transfers from and to W and H, which are updated regularly in host in order to compute connectivity matrix and the convergence criteria. Padding has also been applied in the dimension k in order to adjust memory alignment to the CUDA warp size for this architecture, which reports a reduction in computing time between 10% and 15%.Unlike GPU-based architectures, the TI DSP is a standalone processor, running its own real-time operating system, and thus no data transfers between memory spaces are necessary. From this perspective, it is more similar to general-purpose architectures such as ARM or Intel x86. The BLAS implementation from TI [20,26] has been extensively used in our implementation when possible. In general, both inside the TI BLAS implementation and in the rest of the code, three different levels of parallelism are exploited:Instruction-level parallelism. We have performed a deep exploration of loop-related parameters (unrolling factor and bounds, use of restrict keywords to disambiguate pointers, and compiler optimizations) in order to find an optimal combination for NMF and help the compiler in the process of obtaining optimized code for the VLIW architecture.Data-level parallelism. SIMD instructions are supported in the C66x through the use of intrinsics and vector datatypes. While this is exploited heavily in the TI BLAS implementation, we have also leveraged these capabilities in those parts of the code in which BLAS cannot be applied.Thread-level parallelism. To exploit parallelism across multiple cores, we have used the multi-threaded version of TI BLAS; the recently introduced OpenMP support from TI has been applied on those loops that cannot be cast in terms of this (multi-threaded) BLAS implementation.The implementation of NMF on the Intel Xeon Phi accelerator is carried out using the native Intel MKL library (Intel Math Kernel Library), which provides highly optimized (vectorized and multi-threaded) implementations of the required BLAS routines.The simplest and most direct way to port NMF algorithm to the XeonPhi accelerator is by using the Automatic Offload (AO) model. It enables the use of the Xeon-Phi co-processor automatically and transparently without modifying the source code, by the use of the corresponding environment variable. In this naive way, selected BLAS operations (including xGEMM in (▷(1)) and (▷(4)) and the reduction to a column by means of xAXPY (▷(3)) mentioned in Algorithm 1) can be automatically executed in the accelerator, without any intervention from the developer. However, according our own experience, it is not easy to control the workload distribution between the host and accelerator performed by the AO scheduler in the MKL library. Moreover, for the matrix sizes involved in NMF, the AO scheduler rarely and randomly decides to perform matrix operations on the accelerator, regardless of forcing the whole task to be downloaded to the accelerator by using the corresponding MKL environment variable (MKL_MIC_WORKDIVISION).Because of this handicap, we have decided to manually specify which parts of the NMF algorithm are performed on the co-processor. This task only implied the incorporation of a few #pragma offload constructions to identify the parts of the algorithm that will be executed on the accelerator. In order to reduce multiple memory copies for each xAXPY and xGEMM operation between host and accelerator, the offloaded region has been specified only once. Thus, the complete algorithm is performed in the accelerator, with only an initial and final data transfer. The BLAS calls in the offloaded region will be, thus, executed in the co-processor, as the rest of the updating rules; those parts of the code that can be potentially executed in parallel by all the cores in the co-processor have been marked with the corresponding #pragma omp parallel annotation. As thread-to-core affinity is also a critical factor when pursuing high performance in the Xeon Phi, we have explored a number of different configurations; for our NMF configuration, a compact affinity policy, in which consecutive threads are mapped to consecutive hardware threads in the architecture, turns out to be the optimal configuration.

@&#CONCLUSIONS@&#
In this paper, we have presented a detailed performance and energy consumption study of the well known Brunet’s version of NMF algorithm on different architectures, including low-power, general-purpose, and accelerator-based platforms. In scenarios and applications in which performance is not the only restriction, the selection of an architecture for NMF cannot be taken attending exclusively to factors like theoretical peak performance. On the contrary, it must be a trade-off solution. We have gained insights about the strengths and weaknesses of a set of representative low-power and specific and general purpose architectures attending simultaneously performance and energy consumption considerations, for a wide range of problem conditions and datasets. We believe these contributions can be of wide appeal also for other types of numerical codes widely used in bioinformatics, as well as for other present and future computing architectures. Although not reported in the paper, the major part of the insights have also been validated for the Nonsmooth NMF [25].Future research lines will include scalability studies for different number of cores on each architecture and experimental dataset, and the deployment of power measurement mechanisms on more architectures. We plan to study other NMF methods on different architectures to gain insights about the suitability of each platform for a given NMF variant. As nearly all tested platforms support (or will support in the near future) a common parallel programming paradigm (OpenCL), we will also evaluate a third key factor when selecting a platform for acceleration of NMF: programmability. We will conduct research on the trade-off between performance, energy consumption and ease of programming using common OpenCL codes for all architectures.