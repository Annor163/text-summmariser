@&#MAIN-TITLE@&#


@&#HIGHLIGHTS@&#
Facial landmark detection using a cascade of regressorsNew regression model based on L21 normMultiple initialisations are used to improve robustness.The method is evaluated on multiple datasets and on the 300W challenge.

@&#KEYPHRASES@&#
Facial landmark detection,regression,300W challenge,

@&#ABSTRACT@&#
We propose a new methodology for facial landmark detection. Similar to other state-of-the-art methods, we rely on the use of cascaded regression to perform inference, and we use a feature representation that results from concatenating 66 HOG descriptors, one per landmark. However, we propose a novel regression method that substitutes the commonly used Least Squares regressor. This new method makes use of the L2,1 norm, and it is designed to increase the robustness of the regressor to poor initialisations (e.g., due to large out of plane head poses) or partial occlusions. Furthermore, we propose to use multiple initialisations, consisting of both spatial translation and 4 head poses corresponding to different pan rotations. These estimates are aggregated into a single prediction in a robust manner. Both strategies are designed to improve the convergence behaviour of the algorithm, so that it can cope with the challenges of in-the-wild data. We further detail some important experimental details, and show extensive performance comparisons highlighting the performance improvement attained by the method proposed here.

@&#INTRODUCTION@&#
Existing works on facial landmark detection are often divided into holistic models (e.g., AAM [1–3]), and part-based models. Traditionally, part-based models iteratively alternate between two steps: the construction of landmark-specific response maps, and the shape fitting step. The response map construction relies on the use of landmark-specific classifiers trained to fire when evaluated at the correct landmark location. A response map for a landmark is constructed by scanning a classifier with a probabilistic output over a region of interest in a sliding window manner [4]. The subsequent shape fitting step consists of finding the landmark locations maximising individual responses, but constrained to having a valid shape according to the shape model (most typically a Point Distribution Model [5]).The two most challenging aspects of part-based classifier models are (1) training classifiers that are sensitive enough to perform fine grained detection, and (2) most importantly, the extreme challenge of the shape fitting stage. The latter process is plagued with local minima and often results in a costly maximisation procedure. The most notable efforts within this group are those of Belhumeur et al. [6], and the DRMF [7]. The former used a RANSAC-type shape fitting, while the latter used a discriminative regression-based model predicting shape increments. However, obtaining reliable performance using these approaches implies a strong implementation effort and significant know-how and, even then, their performance now trails behind that of other state-of-the-art methods.An important exception both in terms of the theoretical framework and the practical performance is that of Zhu and Ramanan [29]. In this work, the authors used a discriminative classifier and part-based model consisting on an adaptation of the successful Deformable Parts Model [23] for facial landmarking. The main difference arises from the use of a tree-based graphical model to capture the face shape. Exact inference becomes possible, but multiple pose-wise experts can be used to capture different head poses, including profile faces. While their ability to perform exact inference is remarkable and very useful in practise, their precision is lower than for other methods (provided they converge), and detection can be slow despite the strong speed-up provided by a complex yet efficient implementation.Alternatively, Valstar et al. [8] proposed to drive the local search by regressors performing direct displacement prediction instead of by classifiers measuring landmark fitness. Landmark-specific regression models were trained to this end, with each regressor being tasked with predicting the displacements in the x and y direction from the test location directly to the true target location. While this resulted in promising performance, this approach still has several shortcomings, such as its lack of robustness to erroneous regressor predictions, or the effective inclusion of shape constraints, in particular for non-frontal head poses. Further improvements on regression-based landmarking was attained by combining multiple regression predictions into the equivalent of response maps [9,10]. Thus, while the response maps obtained were typically more precise than those obtained with classification approaches, the shape alignment step was still hindering practical performance.A new breakthrough was proposed by Cao et al. [11]. Firstly, they adopted the cascaded regression framework of Dollár et al. [12], which powered regression-based predictions to allow for inference being simultaneously robust and precise. Secondly, they proposed to directly estimate the shape increments as a whole. That is to say, instead of having a per-landmark model, they used a combined model, taking the whole face appearance as input, and predicting increments for the whole shape. This allowed bypassing the cumbersome shape fitting step, and shape consistency was enforced through the joint prediction. It is interesting to note that face shapes are assumed to lie in a linear subspace (once rigid parameters are eliminated).However, this approach really became the state-of-the-art due to the work of Xiong & De la Torre [13]. While the authors followed a similar approach to that of Cao et al. [11], they managed to greatly simplify the methodology by adopting HOG features and only relying on least squares for inference. The resulting algorithm attained state-of-the-art performance using only 4 matrix multiplications and ran in real time on a standard PC with minimal implementation efforts. The authors also provided an implementation of the method, including extremely well optimised pre-trained models. Furthermore, due to its simplicity, the method can be re-implemented from scratch very easily. Despite its huge advantages, the method of Xiong & De la Torre still presents some drawbacks. Firstly, there is no confidence score for each prediction step, so that there is no knowledge of whether the inference actually improved the solution. Thus, it is not possible to use multiple initialisations or mixture models, which is particularly important for largely non-frontal head poses. Secondly, the use of least squares is not robust and it is thus not ideal in the presence of partial occlusions or when a subset of the landmarks are far off from their ground truth location.Many works have since then built upon the works of Cao et al. [11] and Xiong & De la Torre [13] in different ways. For example, Ren et al. [14] and Kazemi & Sullivan[15] presented extremely fast face alignment algorithms using variants of these ideas. Several works have proposed methods for improving the robustness to partial occlusions. Specifically, Burgos-Artizzu et al. [16] proposed to train a model tasked with detection occlusions explicitly in a discriminative manner. An alternative approach was proposed in Xing et al. [17], where a sparse dictionary learning approach was followed as an alternative to the least squares regression of [13]. This thus constitutes a generative approach rather than discriminative. A specific mechanism within the construction of the dictionary was also included to tackle fitting under partial occlusions. An alternative generative variant of [13] was proposed by Tzimiropoulos [18]. It maintained the PCA-based model traditional for generative models (see e.g., [1,2]), but as novel elements it used a cascade regression approach and a novel mechanism for removing appearance variation in successive levels of the cascade. The work by Sun et al. [19] proposed instead to use a Convolutional Neural Network approach to model the inference problem at each of the cascade levels. Finally, Yan et al. [20] proposed to use a discriminative ranking model capable of selecting and combining multiple predictions, each one obtained using the SDM method and using a different initial shape hypothesis. In fact, this last work won the first 300W facial landmark challenge [21].In this work we build on the previous efforts mentioned above, aiming to tackle the problems of a lack of confidence measures of the predictions and the problem of least squares fragility inherent to [13]. The main methodological contributions of this paper are as follows: Firstly, we propose a new robust regression methodology based on the use the L2,1 norm [22]. This norm allows us to compare two shapes in a robust manner, so that sparse error patterns are primed. The details of this approach will be described in 2. Since the resulting distance is not linear, we resort to its kernelisation, and then employ a standard Support Vector Regression technique for inference. Secondly, we resort to multiple initialisations, and employ an estimate aggregation technique in order to combine the resulting estimates in a robust manner [9]. The aim of this process is to increase the robustness to large out-of-plane rotations. In particular, we use four shapes covering a range of pan head rotations, and for each head pose we create a number of initialisations by simply displacing the viewpoint-specific mean shape in a grid manner on the x and y axis. This process is explained in detail in Section 3. A depiction of the detection process is summarised in Fig. 1.While these are the two major methodological components of our method, we have performed other optimisations worth mentioning. Firstly, we use a face detector trained using the Deformable Parts Model [23]. This greatly improves both the precision and the robustness of the initial estimate respect to that of a Viola and Jones face detector. Secondly, the features we use to represent local patches result from first computing a HOG descriptor, and then computing PCA over them [23]. This serves a twofold purpose: it improves the speed of the inference evaluations and increases the precision of the predictions. These and other minor details and aspects of the algorithm will be detailed in Section 4.One of the remarkable aspects of the work presented by Xiong & De la Torre [13] is the excellent performance attained even when using Least Squares regression, a very simple machine learning method. Much of the excellent performance is due to the use of cascaded regression. We review the principle of cascaded regression in Section 2.1, both for completeness, and to define notation. Our first contribution is to change the inference algorithm used in the regression cascade of [13], substituting the Least Squares regression for a novel L2,1 norm-based approach. This change is motivated and detailed in Section 2.2.A shape contains Nptslandmarks (66 in our case), and it is represented as a 2Npts-dimensional vector. Inference starts with an initial shape estimate, say s0, typically given by the face detector.11Bold lower-case letters indicate vectors. All vectors are column vectors unless indicated otherwise. Matrices are typeset as upper-case bold letters. All other letters are scalars.The appearance corresponding to a shape s is constructed by computing a descriptor (HOG in this case) on a small patch centred at each of the Nptslandmarks defined by shape s. The resulting descriptors are then concatenated into a single vector. We use the notation f(s,I) to indicate that the appearance descriptor is computed for shape s on image I.Inference is attained by sequentially applying a set of linear regressors, so that the output of the previous regressor is the input to the next regressor. Specifically, each such linear regressor is defined in [13] asWkbkk=1:Nit, where Wkis a matrix containing the regression coefficients, bkis the bias term22It is common to simplify the notation by including the bias term within the matrix Wkand appending a 1 at the end of the input feature vector.and Nitis the total number of iterations in the cascade. Nitis fixed, and there is no convergence criterion, so that the chain of regressors is applied in full every time. Specifically, an iteration of the algorithm proceeds as follows:(1)xk=fsk−1I(2)yk=WkTxk+bk(3)sk=sk−1+ykwhere, I is the test image, andsNitis the final shape estimate.We note the images within the training set asIjj=1:Nim. For each of these images, a set of initial shapes are usedsi,j0i=1:Ninit. These multiple initialisations can be obtained by, for example, first registering the mean shape to the ground truth using scaling and translation only, and then perturbing the resulting shape. However, other strategies to generate the initial shapes exist [12,13].The first training set is defined as:(4)xi,j1yi,j1i=1:Ninit,j=1:Nimxi,j1=fsi,j0Ijyi,j1=sj*−si,j0where sj⁎ is the ground truth shape for image j.Then, the first regressor can be learnt as:(5)argminW1,b1∑i=1Ninit∑j=1Nimsj*−si,j0−W1Txi,j1−b1In the general case,(6)si,jk=si,jk−1+WkTxi,jk+bkand Wk,bkare obtained using si,jkin a similar manner as in Eqs. (4) and (5).Our approach follows the same cascaded regression scheme, but we modify the regressor of choice. That is, instead of computing a linear regressor (Wk,bk) at every step, we compute a non-linear regressorG−θk. The proposed regressor is based on the use of the L2,1 norm [22]. Specifically, we want to find a way to compare two feature vectors, say x1 and x2, in a robust manner.Remember that each feature vector x was generated by computing landmark-specific feature vectors and then concatenating them together into a single vector. We re-define the appearance feature vector, now denoted as X, as the n×Nptsmatrix that results from re-ordering the n-dimensional per-landmark appearance feature vectors corresponding to the Nptslandmarks. That is, instead of concatenating the per-landmark appearance feature descriptors vertically, we concatenate them horizontally, resulting in a matrix rather than a vector. Then, we define the distance between two appearance feature vectors as:(7)dX1X2=X1−X22,1where(8)X2,1=∑j=1:NptsX:,j2where X:,jindicates the column j of matrix X.In doing so, the comparison between two shapes is obtained by first computing the L2 distance between per-landmark representations, obtaining a 66-dimensional vector, and then computing the L1 norm over the resulting vector. It is interesting to note that the (squared) Euclidean distance used in Least Squares regression would result from simply computing the L2 norm again on the 66-dimensional per-landmark L2 distance. However, by substituting the computation of the L1 norm for the L2 norm in the second step, we enforce sparse landmark-to-landmark error patterns. These error patterns are typical in the presence of partial occlusions, so that the occluded landmarks will yield high L2 errors while the rest of the landmarks will result in low ones. A similar effect happens when there is a large head pose variation between two examples (e.g., a frontal shape is used to initialise the search for a non-frontal head pose), or when contour landmarks are poorly aligned so that the corresponding appearance patterns can be extracted from the background. This is illustrated in Fig. 2. This figure shows the test image (left-hand side) with its ground truth, and two training images with their ground truth shapes. Since the shapes are very similar, we would like to use a distance that considers the associated appearance patterns to be similar. However, the partial occlusion on the test image requires a robust comparison.The regression function is now non-linear. Thus, we resort to the use of Support Vector Regression (SVR) and use a kernelised version of this norm. Specifically, we compute:(9)KX1X2=e−γX1−X22,1We use an off-the-shelf solver for this problem [24].While the use of a robust regressor improves the algorithm performance in images with non-frontal head poses, we further combine this strategy with a multiple initialisation and aggregation strategy [9]. Specifically, for each image, we consider a set of four initial shapes corresponding to distinct head poses, noted {si0}k=1:4 (see Fig. Fig. 3). The specific four initial shapes used in here result from the face detection algorithm used ([25], see Section 4 for details on the face detector used). In particular, face detection results from applying 4 pose-wise experts, and the pose-wise expert yielding the best score is responsible for the face detector. A per-expert mean shape is constructed by using the subset of all the training faces for which the specific expert provided the detection. This is however a heuristic rule, although in our case this yields better overall performance compared to manually defining the initial shapes to be equally spaced in terms of their rotation angles.These shapes are fitted to the test image using the bounding box resulting from the face detection process. Then, each shape is perturbed at regular intervals along the x and y axis in a grid-like manner. This can be done for example defining a vector of displacements v=(−R,…,−r,0,r,…R), where r is the stride or step size, and R is the maximum displacement. Let us define Δxias a 2Npts-dimensional vector with v(i) in its first Nptsdimensions and 0 on the other dimensions, while Δyiis defined equivalently but with 0 on the first Nptsdimensions instead. We can then define set of initial shapes as:(10)sk,i,j0+Δxi+Δyjk=1:4;i,j=1:|v|accounting for a total of 4×|v|×|v| initial shapes.The first step of the regression cascade is then computed, in our case using the methodology explained in Section 2.2. This yields a set of predictions sk,i,j1. Then we aim to combine these estimates into a single prediction. This is done by using a prediction aggregation strategy, in a similar manner to Local Evidence Aggregation [9]. Specifically, we consider a 1-dimensional Gaussian distribution with fixed covariance σ0. Then, we define a response map for each landmark l, noted Rl, as follows:(11)Rlxy=∑i,j,kNx;sk,i,j1l,σ0Ny;sk,i,j1l+Npts,σ0.This process actually performs a Kernel Density Estimation using a Gaussian isotropic kernel over the regressor predictions. Each of the response maps encodes the belief of a certain image location being the true landmark location when considering all the estimates simultaneously. However, when this belief is only considered in a local manner, i.e., if we were to pick the maximum of each response map as the prediction, the resulting shape would not be anthropomorphically consistent. Thus, the aim is now to find the consistent shape that maximises the individual responses:(12)s^1=argmaxs∑l=1NptsRlsl,sl+Nptss.t.sisvalid.However, this is a very challenging optimisation (in fact, it has been one of the most pressing optimisation problems for facial landmark detection over the last decade). In order to avoid complex procedures at this stage, which is not the main focus of this work, we resort to the simple strategy of restricting the search space to the estimates sk,i,j1. That is to say, we define:(13)s^1=argmaxsi,j,k∑l=1NptsRlsi,j,k1l,si,j,k1l+Npts.This serves the purpose of improving performance in the presence of non-frontal head poses and of less precise face detections (arguably, the precision of the face detection is lower for non-frontal head poses, thus both cases often co-occur). While classification-based approaches can rely on the score of the classifier (e.g., using logistic regression [4]), regression-based approaches do not have an equivalent. Thus, we use the Local Evidence Aggregation property highlighted by Martinez et al. [9], for which the accumulation of regression predictions result from meaningful input patterns. Instead, patterns unseen during training, such as those too far from the ground truth either in terms of the head pose or of the displacement, result in random predictions which do not accumulate.We repeat this process for the second iteration of the algorithm. However, in this case we do not use 4 pose-wise shapes. Instead, we only consider ŝ1, and perturb it by translating it by a smaller amount than used in the first iteration. The remaining iterations do not include this procedure as it was shown ineffective in these cases. This is not surprising, as the algorithm converges very quickly and the last iterations only fine-tune the prediction.

@&#CONCLUSIONS@&#
In this article, we have tackled the problem of facial landmarking in the wild by focusing on augmenting the robustness of current methods to non-frontal head poses. While we build on the hugely popular SDM, we have two major contributions to differentiate this work from previous ones. Experimental results confirm that the resulting algorithm is indeed very robust. This results in particularly good performance for the most challenging datasets.