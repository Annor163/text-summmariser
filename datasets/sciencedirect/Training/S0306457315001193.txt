@&#MAIN-TITLE@&#
Genetic programming-based feature learning for question answering

@&#HIGHLIGHTS@&#
A new framework for answering definitional and factoid questions.Producing new features by combining effective features with arithmetic operators.Genetic Programming (GP) algorithm has been employed for feature learning.Three discriminant-based methods have been used for learning features weights.

@&#KEYPHRASES@&#
Question Answering (QA),Feature learning,Genetic Programming (GP) algorithm,Feature weight learning,Factoid questions,Information Extraction (IE),

@&#ABSTRACT@&#
Question Answering (QA) systems are developed to answer human questions. In this paper, we have proposed a framework for answering definitional and factoid questions, enriched by machine learning and evolutionary methods and integrated in a web-based QA system. Our main purpose is to build new features by combining state-of-the-art features with arithmetic operators. To accomplish this goal, we have presented a Genetic Programming (GP)-based approach. The exact GP duty is to find the most promising formulas, made by a set of features and operators, which can accurately rank paragraphs, sentences, and words. We have also developed a QA system in order to test the new features. The input of our system is texts of documents retrieved by a search engine. To answer definitional questions, our system performs paragraph ranking and returns the most related paragraph. Moreover, in order to answer factoid questions, the system evaluates sentences of the filtered paragraphs ranked by the previous module of our framework. After this phase, the system extracts one or more words from the ranked sentences based on a set of hand-made patterns and ranks them to find the final answer. We have used Text Retrieval Conference (TREC) QA track questions, web data, and AQUAINT and AQUAINT-2 datasets for training and testing our system. Results show that the learned features can perform a better ranking in comparison with other evaluation formulas.

@&#INTRODUCTION@&#
Question Answering systems are advanced search engines that can provide the least brief and the most complete answer to users instead of making them read a set of documents. QA systems are essential tools for dealing with the fast-growing global information. However, upgrading a search engine to a QA system is a complex and open-ended problem (Zadeh, 2003). Machine-based human-like answering has been a dream that Artificial Intelligence (AI) scientists have been trying to achieve. Based on Russell and Norvig (2010), AI field has four definition groups and one of them is based on the Turing test, which is about the ability of machines to communicate or answer like a human. Moreover, Arthur Samuel (Samuel, 1983) in his talk titled “AI: where it has been and where it is going” stated the main goal of AI and machine learning as: “to get machines to exhibit behavior, which if done by humans, would be assumed to involve the use of intelligence.”At the early years, the fundamental problem of QA was converting a natural language question to a Structured Query Language (SQL) query and retrieving answers from structured data. These convert-to-query-based systems have been called restricted-domain systems because they can only answer questions related to their already-provided structured data (Indurkhya & Damerau, 2010). However, with rapid enlargement of data in unstructured format, extracting answers from domain-independent sources became the main challenge of QA. These QA systems, which operate on sources that could be general and free of specific domain, are called open-domain QA systems. The first web-based QA system developed in 2004, named Start (Katz, Lin, & Felshin, 2002), and contemporary systems are Wolfram11www.wolframalpha.comfrom IBM, and AskHERMES (Yen et al., 2013b).The simplest form of answering for a QA system is returning a paragraph to a definitional question. However, factoid question is the most discussed question type. The answer of a factoid question is a simple fact such as name of a person or a location that can be found in a sentence (Jurafsky & Martin, 2009). In addition to these two question types, there are others such as list, hypothetical, causal, relationship, procedural, and confirmation questions. In this paper, we have worked on definitional and factoid questions with a four-phase framework including paragraph ranking, sentence ranking, word extraction, and word ranking.In order to select an answer from a set of candidates, they must be ranked. The ranking problem includes computing a score based on a set of features. Computing the sum of all feature values or∑i(featurei)formula cannot reflect the true value of an answer because each feature has a weight. Finding the weights is a supervised learning problem that can be solved by a discriminant-based classification algorithm. In this paper, we used three methods for this task including Linear Discriminant Analysis (LDA), Logistic regression, and Support Vector Machines (SVM). Taking into account the weights, the score computation formula will become∑i(featurei×weighti).Following these two formulas, one possible continuation is using other arithmetic operators such as multiplication, division, exponential, and logarithm, which is the main purpose of this paper. Here a challenging problem is finding a promising ranking formula based on a set of operators and features. In order to solve such kind of problems, evolutionary approaches can be used since they are capable of searching in large-scale search spaces effectively. Among different types of evolutionary algorithms, Genetic Programming (GP) whose individuals are trees would be the best candidate. Since our problem is finding a ranking formula, which can be modeled as a tree of operators and features, GP would be a perfect choice. The main contribution of this paper is learning efficient features via GP algorithm for a Question Answering system.The remainder of this paper is organized as follows: in Section 2, we will discuss about related works. In Section 3, the structure of our proposed QA system will be presented in detail. Sections 4 and 5 deal with answering definitional and factoid questions. The last three sections describe experimental results, discussion, and conclusions respectively.

@&#CONCLUSIONS@&#
We proposed a Genetic Programming-based approach for learning new features based on a set of features and arithmetic operators. The learned features proved that they can perform a better ranking in comparison with three types of evaluation formulas, including∑i(featurei×weighti),∑i(featurei2×weighti), and∏ifeaturei. The weights of the learned features, which have higher values than the other features, also show the importance of them.We also developed a QA framework with three hierarchical ranking phases to test the learned features. In our framework, we used result of search engine ranking as a feature in the paragraph ranking. Moreover, result of the paragraph ranking is a feature in the sentence ranking and the result of the later is a feature in the word ranking.Discriminant-based classification methods are used to learn the weights of the features and SVM has the best results for all the three phases. This result is also describable by theory; trying to maintain a margin along with separation will cause better results. The threshold of the filtering formula is also tested with different values in order to find the best result.Our system is evaluated with web data, and AQUAINT and AQUAINT-2 datasets. However, web-based answering has better accuracy because it uses redundancy in web. We used this property via the Popularity feature in the word ranking and using n-retrieved documents.Moreover, we explored the answering of factoid and definitional questions and future works can include answering other questions like list, procedural, and causal that includes investigating their features and defining new phases for them. Another possible future work for our approach can be a dynamic system that can update its evaluation formulas with respect to feedbacks from users.