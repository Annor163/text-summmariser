@&#MAIN-TITLE@&#
Time–frequency features for pattern recognition using high-resolution TFDs: A tutorial review

@&#HIGHLIGHTS@&#
A streamlined methodology for designing high resolution quadratic TFDs using separable, directional and adaptive kernels.A formulation of new (t, f) features by translation from time-domain only features or frequency-domain only features.A review of (t, f) image processing techniques for resolution enhancement, de-noising and improved classification.A review of multi-component IF estimation techniques as a performance criterion to compare time–frequency distributions.Experiments that illustrate the above points in EEG seizure detection and classification using a large medical database.

@&#KEYPHRASES@&#
Quadratic time–frequency distributions,Time–frequency image processing,Time–frequency feature extraction,Compact kernel distribution,Newborn EEG seizure abnormality,Non-stationary signals,

@&#ABSTRACT@&#
This paper presents a tutorial review of recent advances in the field of time–frequency(t,f)signal processing with focus on exploiting(t,f)image feature information using pattern recognition techniques for detection and classification applications. This is achieved by (1) revisiting and streamlining the design of high-resolution quadratic time frequency distributions (TFDs) so as to produce adequate(t,f)images, (2) using image enhancement techniques to improve the resolution of TFDs, and (3) defining new(t,f)features such as(t,f)flatness and(t,f)entropy by extending time-domain or frequency-domain features. Comparative results indicate that the new(t,f)features give better performance as compared to time-only or frequency-only features for the detection of abnormalities in newborn EEG signals. Defining high-resolution TFDs for the extraction of new(t,f)features further improves performance. The findings are corroborated by new experimental results, theoretical derivations and conceptual insights.

@&#INTRODUCTION@&#
There has been a significant effort in the past decades to develop Digital Signal Processing (DSP) methods that are more appropriate for the representation, analysis and processing of non-stationary signals [1]. The studies initially focused on the design of Spectrograms, filter-banks and quadratic methods related to the Wigner-Ville Distribution (WVD) for optimal representation of signals such as mono-component Linearly Frequency Modulated (LFM) signals used in radar [2], sonar [3], geophysics [4], and other applications [5–8]. Researchers then shifted their focus to the analysis of multi-component signals, resulting in a number of new approaches to design advanced Time-Frequency Distributions (TFDs) and related techniques [9–14,8]. Such multi-component signals provide a more precise modeling of most natural signals, including biomedical signals such as fetal movement signal, phonocardiogram (PCG), electrocardiogram (ECG), speech, electroencephalogram (EEG), heart rate variability (HRV) and many others. A typical model for such signals was originally proposed in ([15], p. 419). Following this approach, a multi-component signal of time duration T and bandwidth B can be expressed as:(1)s(t)=∑k=1Ncsk(t)=∑k=1Ncak(t)cos⁡(ϕk(t)),whereNcis the total number of components,sk(t)is the kth signal component,ak(t)andϕk(t)are the instantaneous amplitude (IA) and instantaneous phase (IP) of the kth signal component. The IAak(t)is a low-frequency amplitude whose spectrum is assumed not to overlap with the spectrum of the higher-frequency signalcos⁡(ϕk(t))[16,17]. The derivative of the IPfk(t)=12πdϕk(t)dtdefines the instantaneous frequency (IF) of the kth signal component. The above defines the AM-FM model of the signal where the IA is the AM law and the IF is the FM law of the signal. The time support ofak(t)is T and the frequency support offk(t)is B.Using the above model, a multi-component signal is completely characterized by the number of componentsNc, the IA and IF of each component; residual noise could be added in certain situations when there are interferences. The time–frequency(t,f)approach is a preferred method to represent such multi-component signals as it allows solving the problem of estimating the characteristics of the components constituting the signal in Eq. (1). For example, it can provide a measure of the energy leakage that takes place around the components due to slow variation of their IAs, and a measure of the relative energy distribution throughout the(t,f)plane. Such information can then be used to refine a number of advanced techniques and methodologies in applications such as detection and classification using selected(t,f)features for pattern recognition. An important generic application of such methods is diagnosis, which is related to condition monitoring and fault detection. This applies to both machines and humans. For the sake of illustration, we will use physiological signals in this paper, although the method can be applied to all fields where decisions need to be made on the basis of information collected from non-stationary signals.The basic idea is to find and recognize patterns in the signal that would indicate the presence of a fault, an abnormality or otherwise would indicate a normal condition for the process generating the signals. If there is an abnormality, then one needs to identify and classify the abnormality. Although the approach is general, this paper illustrates it by focusing on some particular physiological signals such as electroencephalography (EEG) for monitoring new-born brain activity and predicting newborn health outcomes through diagnosis and prognosis.Although the methodologies presented are general, this paper considers only physiological signals for illustration, including EEG, electrocardiography (ECG), heart rate variability (HRV) and heart sounds which are routinely used by medical specialists for diagnosis in a range of situations. After acquisition, these signals are usually processed in several stages, including a pre-processing stage like amplification and filtering to suppress artifacts and noise. In some situations, multi-channel physiological signals are acquired using multiple spatially distributed sensors that provide both temporal and spatial information. The diversity given by space time information can allow a more refined analysis and better interpretation of the data in applications such as source localization, signal-to-noise ratio (SNR) enhancement, classification, and removal of artifacts [18,19]. As indicated earlier,(t,f)analysis is widely used for the representation and analysis of physiological signals because of the non-stationary and multi-component characteristics of these signals; the(t,f)image allows a refined treatment of further processing stages such as detection and classification, leading to diagnosis, condition monitoring and fault detection.Early detection of abnormalities in physiological signals can help save or improve patients' lives. Manual detection of abnormality requires a constant monitoring of the relevant physiological signal by a qualified medical expert. The development of an automatic abnormality detection technique, which can be implemented on a digital computer, would result in a major advance in medical practice. Such detection of abnormality in physiological signals can be considered as a pattern classification problem involving extraction of features from the signals and training of a classifier. Features can be extracted from the time-domain representation [20–22], the frequency-domain representation [23], a combination of both time-domain and frequency-domain representations [24], or joint time frequency representations using TFDs [7,25,5,26–30,13,31]. The performance of abnormality detection techniques depends of course on the choice of signal representation and selection of features. The abnormality detection techniques that are based on TFDs are shown to outperform time-domain or frequency-domain only approaches as TFDs are more adapted to analyze the non-stationary characteristics of physiological signals [26] and convey critical information about the signal.TFDs are normally compared in terms of their resolution and cross-term suppression properties. Previous studies have shown that high-resolution TFDs, like the Modified B-Distribution (MBD), give good classification results [25,26]. A key question is therefore whether the performance of TFD-based signal classification techniques can be related to the resolution of the TFD. This paper aims to answer this question by investigating the influence of resolution parameters on classification performance.TFDs are rich in information partly because they increase the dimensionality of the classification problem at the expense of increased computational costs. In order to avoid this problem, it is important to extract only the most relevant features from the TFD. Such features can be extracted in a number of ways. These include dividing a TFD into a number of tiles and computing the energy in each tile [6], reducing the dimension of the TFD by linear transformation methods [5,30,31], selecting relevant points from a TFD based on relevance or mutual information measure [29], translating time-domain or frequency-domain features to(t,f)domain and extracting relevant features [26], and using image processing techniques to extract features like statistical measures, texture related features, geometric features, ridges [25,28], to name just a few.This study reviews previous work on the design of high-resolution TFDs [32,10],(t,f)image processing and feature extraction methodology [25,26] with three objectives: (1) streamlining the design of high-resolution TFDs, (2) improve diagnostic applications and (3) providing the reader with an illustration on physiological signal classification techniques. The study refines, updates and extends previous studies with improved precision and illustrates the improvements using a real application: enhancing newborn health outcomes. The style of this paper is a tutorial review with scope and coverage defined by the inclusion of the following:1.A streamlined review of quadratic(t,f)distributions (QTFDs) formulations;A methodology for the design of new high-resolution QTFDs and the study of how they improve the performance of features extraction;A review of multi-component IF estimation techniques as a performance measure to compare TFDs;A review of(t,f)image processing techniques for cross-term suppression, resolution enhancement and de-noising as a pre-processing stage before classification; including the design of a(t,f)image enhancement technique based on directional filtering to improve the resolution of QTFDs;A formulation of(t,f)translated features from time-domain only and frequency-domain only features;Illustrative experiments to apply the above points to EEG seizure detection using a large medical database.Let us consider a non-stationary real signals(t)as defined in Eq. (1). The WVD is the core member of the class of QTFDs. The WVD is defined by taking the Fourier transform (FT) of an instantaneous auto-correlation functionKz(t,τ)expressed as [1]:(2)Wz(t,f)=∫RKz(t,τ)e−2jπfτdτ,whereKz(t,τ)is defined as(3)Kz(t,τ)=z(t+τ2)z⁎(t−τ2),and wherez(t)is the analytic associate of a real signals(t)obtained by the use of the Hilbert transform; expressed as(4)z(t)=s(t)+jH{s(t)}.In the above expression, the imaginary part represents the Hilbert Transform defined byH{s(t)}=1πp.v.{∫Rs(τ)t−τdτ}, where p.v. represents a principle value expressed as(5)p.v.{∫Rs(τ)t−τdτ}=limδ→0⁡[∫−∞t−δs(τ)t−τdτ+∫t+δ+∞s(τ)t−τdτ].For a real AM-FM signals(t)=a(t)cos⁡(ϕ(t)), the analytic signalz(t)can be written as:z(t)=a(t)ejϕ(t), under some conditions such as whena(t)is a low-frequency amplitude whose spectrum does not overlap with the spectrum of the high-frequency signalejϕ(t)[16,17]. For such signals with large Bandwidth–Time-duration (BT) product, then the IF provides an estimate of the FM law.The WVD defined in Eq. (2) gives ideal concentration for mono-component LFM signals, but it produces undesired cross-terms for non-linear frequency modulated (FM) or multi-component signals. Cross-terms can be reduced by convolving the WVD with a 2D(t,f)kernel, resulting in the following expression [1],(6)ρ(t,f)=γ(t,f)⁎⁎(t,f)Wz(t,f)whereγ(t,f)is the 2D(t,f)smoothing kernel. Eq. (6) represents the(t,f)formulation of QTFDs. The 2D smoothing of the WVD withγ(t,f)reduces the cross-terms, but blurs the auto-terms. For this reason, the(t,f)kernels are designed to achieve the best tradeoff between the following two conflicting objectives:a)Minimize cross-terms;Retain the resolution of auto-terms.Eq. (6) can be estimated via time–lag formulation by replacing the convolution operation along the frequency axis with the multiplication operation along the lag axis ([33], p. 67), resulting in the following expression:(7)ρ(t,f)=∫RG(t,τ)⁎tKz(t,τ)︸Rz(t,τ)e−2jπfτdτ,whereG(t,τ)is called the time–lag kernel of the TFD and is related toγ(t,f)by inverse FT. The time–lag formulation is widely used for implementing TFDs because of its conceptual simplicity and computational efficiency as it requires only one convolution along the time axis and one FT from lag domain to frequency domain [13].A Doppler–frequency based formulation of TFDs can be obtained from the(t,f)formulation by replacing the time convolution in Eq. (6) by a multiplication in Doppler after taking a FT [33]:(8)ρ(t,f)=∫RG(ν,f)⁎fkz(ν,f)e2jπνtdν,whereG(ν,f)is the kernel in the Doppler–frequency domain. The quantitykz(ν,f)is often referred to as the spectral autocorrelation function (SAF) defined as ([33], p. 70):(9)kz(ν,f)=Z(f+ν2)Z⁎(f−ν2),whereZ(f)is the FT ofz(t). The Doppler–frequency TFD formulation requires one convolution along the frequency axis and one inverse FT (from Doppler to time) to transform the SAF to the(t,f)domain representation. The computational cost of transforming the SAF to the(t,f)domain is equal to that of transforming the instantaneous auto-correlation function to the(t,f)domain, apart from the required estimation ofZ(f).A Doppler–lag formulation can be obtained by replacing the convolution operation along the time axis in Eq. (7) with the equivalent multiplication along the Doppler-axis ([33], p. 69), resulting in the following expression:(10)ρ(t,f)=∫R∫Rg(ν,τ)Az(ν,τ)︸Az(ν,τ)e−2jπfτ+2jπtνdτdν,whereAz(ν,τ)represents the ambiguity function, defined as:(11)Az(ν,τ)=∫RKz(t,τ)e−2jπtνdt,andg(ν,τ)=∫RG(t,τ)e−2jπtνdtis the Doppler–lag kernel. This formulation is often used for designing high-resolution TFDs as it allows entering filter specifications in the formulation ofg(ν,τ)[33]. The Doppler–lag formulation requires three FTs as computing the ambiguity function from the time–lag kernel needs one FT and transforming the ambiguity function to the TFD requires two FTs.These four formulations are illustrated in Fig. 3.The selection of one of the above four formulations depends on the specifications of the application and signal characteristics such as duration T, bandwidth B, and value of BT product. For example, for narrow-band signals (i.e. with small B), Eq. (8) would be preferable to use ([33], p. 70).A question asked by most beginners is which TFD to use to get started, given that the WVD has a good resolution with a problem of cross-terms, the Spectrogram has a problem of resolution, but no apparent cross-terms and other QTFDs appear more complicated. To answer this question, let us first review the Spectrogram in detail.The Spectrogram is a simple yet effective TFD in some situations. It is defined as:(12)Ssw(t,f)=|∫Rs(τ)w(t−τ)e−2jπfτdτ|2,wherew(t)is the analysis window. The Spectrogram is a QTFD as its time–lag kernel can be expressed as the instantaneous auto-correlation function of the window ([33], pp. 47–48).(13)G(t,τ)=w⁎(t+τ2)w(t−τ2).This implies that the(t,f)kernel of the Spectrogramγ(t,f)is the WVD of the windoww(t), and equivalently the ambiguity domain kernel filterg(ν,τ)is the ambiguity function of the windoww(t)([33], p. 76),(14)γ(t,f)=∫Rw⁎(t+τ2)w(t−τ2)e−2jπfτdτ.To discuss the limitations of the smoothing kernel of the Spectrogram, let's consider a Gaussian windoww(t)=(a/π)1/4e−a2t2. Using Eq. (14) results in the(t,f)kernel for this window expressed as [34]:(15)γ(t,f)=2e−at2e−4π2f2a.The above expression shows that the smoothing kernel of the Spectrogram is non-separable given that both t and f variables are parametrized by the same scale value. The smoothing along the time axis cannot be controlled independently from the one in the frequency axis and vice-versa; this makes the Spectrogram extremely sensitive to the length of the window ([33], p. 221). Attempts to mitigate this limitation of the Spectrogram include using separable kernel TFDs that have the flexibility to independently adjust the type of smoothing along the time or frequency axis as discussed in Section 2.2.In short, the Spectrogram is an easy to use QTFD that does not have a problem with cross-terms, but suffers from poor resolution as well as sensitivity to the choice of window length. On the other hand, the WVD has higher resolution for mono-component LFM signals, but has an issue of cross-terms that may be problematic for analysis and modeling.The S-method, which can be considered an optimized version of the Spectrogram, combines the advantages of the Spectrogram and WVD. It is defined as [35]:(16)SMs(t,f)=2∫RG(θ)Fs(t,f+θ)Fs⁎(t,f−θ)dθ,whereFs(t,f)is the short-time Fourier transform ofs(t), defined as:(17)Fs(t,f)=∫Rw(τ)s(t+τ)e−j2πfτdτ.In Eq. (16),G(θ)is a narrow window whose length controls the cross-term suppression and auto-term resolution properties of the TFD. Previous studies have shown that an appropriate selection of the length ofG(θ)can combine advantages of both Spectrogram and WVD. The resultant TFD can have auto-term resolution close to the WVD with a significant suppression of cross-terms [35]. The ambiguity domain kernel of the S-method is given below [13].(18)g(ν,τ)=G(ν)⁎ν∫Rw(u+τ2)w⁎(u−τ2)e−j2πuνdu=G(ν)⁎νAw(ν,τ).Eq. (16) shows that the S-method is computed using the short-time Fourier transform, which makes it more computationally efficient than other QTFDs such as the WVD. Let us now review the design of separable kernel TFDs.An attempt at simplification is to first consider(t,f)kernels that can be represented simply as the product of an independent time-only kernel with an independent frequency-only kernel; these separable(t,f)kernels ([33], pp. 213–222) are expressed as:(19)γ(t,f)=g1(t)G2(f).The meaning and significance of this simplification is that we can define and design some QTFDs simply by smoothing the WVD in t and then in f. The shape and size ofg1(t)orG2(f)determines the smoothing along the time or frequency axis respectively. In many applications, separable(t,f)kernels have shown to give good enough results in terms of cross-term suppression and auto-term resolution, making them popular as they are easy to use. Other equivalent formulations of(t,f)separable kernels are given below in other related domains.•Time–lag domain:G(t,τ)=g1(t)g2(τ)Doppler–frequency domain:G(ν,f)=G1(ν)G2(f)Doppler–lag domain:g(ν,τ)=G1(ν)g2(τ)As discussed above, high-resolution separable kernel TFDs can be designed in the four possible domains, that is:(t,f)domain, Doppler–frequency domain, time–lag domain or Doppler–lag domain; they are related to each other by FT as illustrated in Fig. 3. The ambiguity domain (lag–Doppler domain) is usually preferred for designing TFDs as filtering in the ambiguity domain is performed by a multiplication of lag and Doppler windows instead of one or two convolutions in other domains.The WVD defined in Eq. (2) is often considered as the core distribution of QTFDs; it suffers from the presence of undesired artifacts or cross-terms that prevent its straightforward interpretation as an energy distribution versus t and f. These cross-terms can be classified into two types: outer-terms and inner-terms. Outer-terms can be easily explained by considering a two component signal:z(t)=z1(t)+z2(t)for which the WVD is given by(20)Wz(t,f)=Wz1(t,f)+Wz2(t,f)+2Re{∫Rz1(t+τ2)z2⁎(t−τ2)e−2jπfτdτ}︸Wz1z2(t,f).In the above expression,Wz1(t,f)andWz2(t,f)represent auto-terms that describe an energy concentration whileWz1z2(t,f)represents outer-term artifacts that are generated by the interaction of signal componentsz1(t)andz2(t). The second type of artifacts is called inner-terms; they are generated by the non-linear FM characteristic of mono-component signals.A non-linear mono-component signal can be approximated by the summation of a number of piece-wise LFM signal components. For example, a single non-linear FM signal componentz1(t)can be written as:(21)z1(t)=z1,a(t)+z1,b(t),wherez1,a(t)andz1,b(t)represent respectively the first and the second pieces constituting the signalz1(t). Its WVD is given by:(22)Wz1(t,f)=Wz1,a(t,f)+Wz1,b(t,f)+2Re{∫Rz1,a(t+τ2)z1,b⁎(t−τ2)e−2jπfτdτ}︸Wz1,az1,b(t,f).Cross-terms are oscillatory in nature, with the same order of magnitude as that of auto-terms [36], and they lie half-way in-between two signal components in(t,f)plane as illustrated in Fig. 4(a). The direction of oscillation of outer-terms is orthogonal to the line joining the two components while the direction of oscillation of inner-terms is partly orthogonal to the IF of a non-linear FM signal ([33], p. 63).The ambiguity function is often used for designing QTFDs because it is the 2D-FT of the WVD, which then allows filtering in the(t,f)domain by a multiplication in the ambiguity domain. Specifically, Eq. (6) and Eq. (10) show that TFDs can be expressed as the result of a double convolution of(t,f)kernels with the WVD in the(t,f)domain or as the 2D-FT of the product of the Doppler–lag kernel with the ambiguity function. This leads to the following simple procedure for designing the QTFDs.In the ambiguity domain, the cross-terms seem to appear away from the origin (see Fig. 4(b)) and are separated by a distance that is approximately equal to the frequency spacing in between two signal components as illustrated by Fig. 4(b). On the other hand, the auto-terms pass through the origin and appear between two cross-terms in the ambiguity domain. We note that the energies of the auto-terms are mostly concentrated around the origin as illustrated in Fig. 4(b).QTFDs can then be defined to exploit the geometrical properties of auto-terms and cross-terms in the ambiguity domain by designing kernels using the “almost low-pass” characteristics of auto-terms and the high-pass characteristics of cross-terms in the ambiguity domain, resulting in kernels that discriminate and separate them. The cross-terms can therefore be reduced by applying a suitable 2D filter in the ambiguity domain and then transforming the ambiguity function back to the(t,f)domain.The exact specifications of a 2D filter depend on the nature of the signal being analyzed. For example, for Fig. 4(b), a 2D filter that is elongated along the lag axis with low-pass characteristics along the Doppler axis will lead to a higher-resolution TFD. The result is shown in Fig. 4(c); and for illustration of this principle, the next subsection presents simple examples of relevant separable kernels that lead to high-resolution QTFDs.To illustrate this principle in clear terms, let us consider two special cases: lag-independent TFDs and Doppler-independent TFDs. These two cases of separable kernel TFDs can be used in certain specific situations related to signal characteristics, resulting in easy designs and implementations.a)Lag-independent (LI) TFDs: Such lag-independent TFDs only perform smoothing along the time axis and are therefore characterized byG2(f)=δ(f)org2(τ)=1. This kind of kernel is suitable for signals whose IF is parallel to the time axis in the(t,f)domain. In the ambiguity domain, such signals have most of their auto-term energy concentrated along the lag axis as these signals appear as an impulse along the frequency axis in the(t,f)domain, and as a constant along the lag axis in the ambiguity domain. The MBD kernel represents such an example of LI-TFD. It is defined in the ambiguity domain by the following kernel [1]:(23)g(ν,τ)=G1(ν)=|Γ(β+jπν)|2Γ2(β),|ν|≤12,0≤β≤1where ν and β are bounded to ensure that the MBD is a low-pass filter. Some physiological signals like HRV and EEG seizure have negligible FM; the direction of oscillation of outer-terms for such signals is parallel to the time axis. The MBD, a lag-independent distribution, is naturally suited for the analysis of such signals as it only performs smoothing along the time axis, thus avoiding the blurring of auto-terms in all directions usually caused by a 2D smoothing. To illustrate, let us consider a multi-component signal composed of two tones and one LFM, and analyze it using the MBD, windowed WVD (discussed in the next subsection), and Hamming–Hanning kernel TFD [32] as shown in Fig. 5. The MBD, in Fig. 5(a), gives high energy concentration for the two tones but fails to give the same level of energy concentration for the LFM component as it performs smoothing only along the time axis. The Hamming–Hanning kernel TFD, shown in Fig. 5(b), gives a blurred representation for all the signal components due to its 2D smoothing kernel. The windowed WVD in Fig. 5(c) fails to suppress the cross-terms due to its frequency-only smoothing that is almost orthogonal to the direction of oscillation of cross-terms. Of course, for all the TFDs, further improvements can be made by optimizing window size and window shape following traditional DSP filter design criteria.Doppler-independent (DI) TFDs: Such Doppler-independent TFDs only perform smoothing along the frequency axis and are characterized byg1(t)=δ(t)orG1(ν)=1. These DI types of kernels are appropriate for signals whose auto-terms are parallel to the frequency axis in the(t,f)domain. In the ambiguity domain, such signals have most of their auto-term energy concentrated along the Doppler axis. A simple example of a DI-TFD is the WVD windowed with a Hamming window along the lag axis expressed as:(24)g(ν,τ)=g2(τ)=0.54−0.46cos⁡(2πτ),−0.5≤τ≤0.5,where τ is bounded to ensure that Hamming is a low-pass filter.The DI-TFD is suited to real-world signals that have the characteristics described above, like for instance EEG spike signals which can be modeled by a train of impulses in the time-domain. The direction of oscillation of outer-terms for such signals is parallel to the frequency axis. Methods, such as the windowed WVD defined by Eq. (24), are more suitable for the analysis of this type of signals as they perform smoothing along the frequency axis only and avoid unnecessary blurring caused by a complete 2D filter. Fig. 6shows the MBD, windowed WVD, and Hamming–Hanning kernel TFD of a signal composed of two impulses in the time domain and an LFM signal. The MBD, shown in Fig. 6(a), gives poor energy concentration for all the signal components as the direction of its smoothing kernel is orthogonal to the direction of energy concentration of the signal components. The Hamming–Hanning kernel TFD, shown in Fig. 6(b), performs 2D smoothing and therefore blurs the signal auto-terms, but its resolution is better than the MBD. The windowed WVD, shown in Fig. 6(c), results in a high-resolution(t,f)representation for the two impulses but it fails to give same resolution for the LFM component as it only performs smoothing along the frequency axis.Apart from the LI and DI TFDs, most of the other separable kernel TFDs, like the B-distribution, the extended Modified B-distribution and the Compact support kernel employ smoothing filters along both time and frequency axes [33,32,10]. Some examples of these particular kernels previously used in the literature or recently developed are given below.i.B-distribution Kernel ([33], p. 217): The B-distribution kernel is defined in the ambiguity domain as follows:(25)g(ν,τ)=g2(τ)G1(ν)=|τ|β|Γ(β+jπν)|221−2βΓ(2β),|ν|≤0.5,|τ|≤0.5,and0≤β≤1,where τ, ν and β are bounded to ensure that the B-distribution contains a low-pass filter.The B-distribution kernel is the product of a low-pass filterG1(ν)=|Γ(β+jπν)|221−2βΓ(2β)and a high-pass filterg2(τ)=|τ|β. The B-distribution gives a high-resolution TFD for selected small values of β[37]. A disadvantage is that a zero at the origin appears as a consequence of the high pass filtering performed along the lag axis i.e.g2(0)=|0|β=0. This results in a deterioration of the resolution of the B-distribution for certain types of signals [32]. This fact motivated its modification as detailed below.Modified B-distribution: As explained above, the MBD-kernel was designed to overcome some of the problems of the B-distribution, based on the following observations1The B-distribution usually gives high resolution(t,f)representation for very small values of β(0<β≪1)([33], p. 118).For small values of β, the lag window is approximately an all pass filter (except forτ=0), i.e.,g2(τ)≈1.Hamming–Hanning TFD: The corresponding Hamming–Hanning kernel is a 2D low-pass filter expressed as [32]:(26)g(ν,τ)=(0.54−0.46cos⁡(2πτ))(0.5−0.5cos⁡(πν)),−12≤ν≤12,−12≤τ≤12.This kernel results in a high-resolution TFD obtained by choosing a 2D low-pass filter along both lag and Doppler axes. This example is provided merely to show that any of the classical windows used for spectral analysis or digital filter design can be used as kernel filters, with specifications provided in the ambiguity domain.Extended modified B-distribution: As discussed earlier, previous studies have reported that the kernel of the lag-independent MBD mentioned in Eq. (25) gives optimal energy concentration for signals with negligible FM ([33], pp. 213–222), i.e., for signals whose IF is almost parallel to the time axis. The drawback of the lag-independent formulation of the MBD is that it does not allow smoothing along the frequency axis, thus limiting its scope for the analysis of signals whose auto-terms are parallel to the time axis. For example the MBD cannot be used for the analysis of a signal that is composed of a train of impulses as observed in some newborn EEG signals, as it then would give poor results [1]. The EMBD exhibits improvement in some situations as it extends the MBD by applying its kernel filter along both lag and Doppler axes, resulting in the expression [32]:(27)g(ν,τ)=|Γ(β+jπν)|2Γ2(β)|Γ(α+jπτ)|2Γ2(α),where−0.5≤ν≤0.5,−0.5≤τ≤0.5,0≤β≤1and0≤α≤1. The lengths of the Doppler and lag windows are controlled by separate parameters α and β respectively. The extra degree of freedom in the formulation of the EMBD allows to independently adjust the lengths of the windows along both lag and Doppler axes as illustrated in Fig. 7. This makes it a more useful tool for the analysis of real-life signals, such as fetal movement signals, EEG signals with seizure and EEG spike signals. However, the EMBD has only one parameter for each kernel filter or window (that is α for lag and β for Doppler) to control both shape and size. Thus the EMBD does not allow adapting both length and shape of the smoothing window of the kernel filter independently, although it is an improvement on both the BD and the MBD.Compact support kernel TFD: Such compact support kernels (CSK) are designed to vanish outside a given range in the ambiguity domain. Unlike Gaussian windows they do not have infinite length, so there is no need to truncate those using rectangular windows that may cause loss of information. These TFDs have been shown to outperform other kernel-based methods in terms of their ability to suppress cross-terms while retaining the resolution of auto-terms in some cases [10]. Such high-resolution performance is achieved by these kernels by combining their compact support with a flexibility to adjust both shape and size independently, as discussed below.In order to explain the characteristics of the CSK, let us first observe in the formulation below that its kernel includes two components [10]:(28)g(ν,τ)={e2cecD2ν2−D2+cD2τ2−D2,{ν2<D2τ2<D20,otherwiseIn the above, the two branches formed by the Doppler window and lag window of the CSK are respectively given by(29)G1(ν)={ececD2ν2−D2,|ν|<D0,otherwiseandg2(τ)={ececD2τ2−D2,|τ|<D0,otherwiseThe above equations show that the shape and size of both Doppler and lag windows are determined respectively by the parameters c and D. These parameters allow the CSK to adapt both kernel length and shape. For example, the shape of the CSK in the ambiguity domain can be adjusted from the quasi-rectangular window to the quasi-Gaussian window as shown in Fig. 8. However, the CSK definition restricts the Doppler and lag windows to be of same length, so that the smoothing along time or frequency axis cannot be adjusted independently. This limitation is overcome by a new design procedure described in Section 2.3.To illustrate the potential advantage of using separable kernel TFDs over the Spectrogram in terms of energy concentration and resolution properties, let us consider a two component signal defined as:(30)s(t)={cos⁡(2π(0.2t−0.0006t2))+cos⁡(2π(0.3t+0.0006t2)),0≤t≤127,0,otherwise,The Spectrogram and Hamming–Hanning kernel based TFD for this signal are shown in Fig. 9. The parameters of both TFDs were optimized based on visual analysis.Fig. 9 shows that the separable kernel TFD gives high energy concentration for the given signal as compared to the Spectrogram. This improved performance of the Hamming–Hanning kernel based TFD is due to additional flexibility in its formulation to independently adjust smoothing along time and frequency axes.Eq. (29) indicates that neither the shape nor the size of the Doppler and lag windows can be adjusted independently of each other. This shortcoming limits the application of the CSK TFD to the analysis of signals whose energy is homogeneously distributed in the ambiguity domain. As a consequence, the CSK TFD cannot deal optimally with signals like EEG seizure signals, whose IF is almost parallel to the time axis, or EEG spike signals, whose IF is almost parallel to the frequency axis.To illustrate the limitations of the CSK TFD, let us consider a multi-component signal composed of two LFM signals. Fig. 10(a) shows the ambiguity function modulus of this signal and a CSK with optimal parameters. The CSK, even with optimal parameters, fails to retain all the auto-term energy in the ambiguity domain, thus resulting in a blurred TFD as shown in Fig. 10(b). Fig. 10(c) illustrates the ambiguity domain filtered by a separable kernel that is elongated along the lag axis to retain all auto-term energy. The separable kernel filters cross-terms while retaining all the auto-terms, resulting in a higher-resolution TFD as shown in Fig. 10(d). The low-resolution performance of the CSK is due to the restriction in its formulation to have equal length for both Doppler and lag windows.The CSK can be extended by simply modifying the formulation of Doppler and lag windows so that their lengths can be adjusted independently. Such modified Doppler and lag windows can then be expressed as:(31)G1(ν)={ececD2ν2−D2,|ν|<D0,otherwiseandg2(τ)={ececE2τ2−E2,|τ|<E,0,otherwise.As mentioned above, the lengths of the modified Doppler and lag windows now depend on two parameters D and E. These parameters are selected on the basis of shape and orientation of auto-terms in the ambiguity domain so that the maximum energy of auto-terms is retained and cross-terms are reduced. This leads to the following formulation of the Extended Compact Kernel (ECK):(32)g(ν,τ)=G1(ν)g2(τ)={e2cecD2ν2−D2+cE2τ2−E2,|ν|<D,|τ|<E,0,otherwise.The additional degree of freedom in the formulation of the ECK to independently adjust the lengths of the Doppler and lag windows is illustrated in Fig. 11.The resulting ECK performs smoothing along both time and frequency axes. Note that, like many other TFDs, it does not rigorously fulfill mathematical properties like time support, frequency support, time and frequency marginals, and positivity ([33], p. 216). However, it satisfies the mathematical properties of realness, energy conservation and(t,f)shift invariance [10], which are sufficient and convenient for a number of applications such as classification, as justified below.1.Real TFDs decrease the dimensionality of the classification problem as compared to complex TFDs.Time-shift and frequency-shift invariance are needed to ensure the consistent performance of pattern classification algorithm.The conservation of the total energy is necessary to preserve the relative energy between features of different classes of data.The time–lag domain is often used for the discrete-time implementation of TFDs for computational efficiency ([33], pp. 268–278). The discrete-time time–lag formulation of the TFD of the analytic associatez[n]of the N-point real signals[n]can be expressed as ([33], pp. 237):(33)ρ[n,k]=2DFTm→k(G[n,m]⁎n(z[n+m]z⁎[n−m])).The discrete-time variable n and discrete-frequency variable k are related to the continuous-time and continuous-frequency variables by the following expressions ([33], pp. 232–241)(34)n=tfsandk=f2Mfs,wherefsis the sampling frequency. The resulting discrete TFD is a matrix of sizeN×M, where N is the number of time-domain signal samples, and M is the number of frequency-domain samples. Following Eq. (32), the discrete time–lag formulation of the ECK is expressed as:(35)G[n,m]=DFTl→n(ecD2(lN)2−D2)e2cecE2(mN)2−E2.Its properties are discussed in the next section with respect to performance.Let us first consider an LFM signal as:(36)s(t)=Arect[tT]cos⁡(2π(f0t+α2t2)+ψ),where A is the amplitude (assumed to be equal to 1), T is the total duration and ψ represents a phase offset (ψ is often equal to 0), andrect[tT]represents a rectangular window defined by:(37)rect[τ]={1−12≤τ≤120,otherwise.The frequency rate α is estimated by the difference between the maximal frequencyfmaxand the initial frequencyf0, divided by the total duration T:(38)α=fmax−f0T.The performance of the CKD defined above is evaluated using the following signals:a)A synthetic multi-component signal composed of two LFM components defined as:(39)s(t)=rect[t−128T](cos⁡(2π(0.1t+0.00062t2))+cos⁡(2π(0.15t+0.00062t2))).The sampling frequency is 1 Hz, the signal duration is equal toT=255s and the frequency rate α for both signals is the same and is given by:α=fmax⁡,1−f0,1T=(0.253−0.1)255=0.0006, wherefmax⁡,1andf0,1are respectively the maximal frequency and the initial frequency of the first LFM signal.An EEG seizure signal of 8-s duration sampled at 32 Hz.A fetal movement signal of 2.5-s duration sampled at 100 Hz.The resulting ‘P’ values for the TFDs of the synthetic signal are shown in Table 1. On the basis of both visual and quantitative analysis, the CKD outperforms all the other TFDs for all these signals due to a better ability to reduce cross-terms while maintaining a high resolution of auto-terms. The S-method is the second best performing TFD for synthetic, real-life EEG and fetal movement signals. Note that the performance of the MBD can be significantly improved by using a rectangular window of length smaller than the signal length, but such modification will make the MBD a lag dependent distribution, i.e., an EMBD.The CKD gives the best performance for signals whose auto-terms are nearly parallel to either time or frequency axis. However, its performance degrades for signals whose auto-terms have a specific direction away from the time axis or frequency axis in the(t,f)domain. In such cases, the optimum can be reached using directional filtering as a post-processing operation to design a high-resolution TFD as detailed in Section 4.2.For stationary signals, frequency estimation is used in a number of applications including music and speech to estimate the relative strengths of each frequency component [39]. For non-stationary signal processing, the method extends to IF estimation which represents the variation of the dominant frequency as a function of time [17]. This concept of IF is intrinsically linked to the concept of TFDs as the IF estimation capability of TFDs is often used as a criterion to evaluate their performance, including robustness against noise. The performance of the previously defined TFDs is comparatively assessed below for both simulated and real-world signals in terms of IF performance estimation. This requires first to define clearly what is being estimated and the criteria for comparison. Let us consider first the simple case of mono component signal IF estimation.In TFD based IF estimation the criteria of goodness for mono component signals are: no bias and minimum variance. These IF estimates can be defined as the peaks of TFDs or as their first moments. One aim of defining high-resolution TFDs is to also yield high concentration TFDs, resulting in efficient IF estimates.As the concept of IF was introduced to represent the spectral variations of non-stationary signals [17], a simple example is the FM signals, for which the IF is the FM law. The easiest is the LFM, which is used in various applications, such as “vertical seismic prospecting” (VSP), where it is desired to study parameters such as soil absorption and dispersion [4]. For such signals, the WVD is the optimal representation in terms of energy concentration.Let us consider a mono-component analytic signalz(t)modeled asz(t)=a(t)ejϕ(t), such thata(t)is a low-frequency signal whose spectrum does not overlap with the high-frequency signalejϕ(t)as per Eq. (1) andϕ(t)is defined byϕ(t)=arctan⁡(Im(z(t))/Re(z(t)). The IF of the mono-component signal is defined as the time derivative of its phase:(40)f(t)=12πdϕ(t)dt.A comparative review of fundamental algorithms for IF estimation appeared in [40]. More recent advances are reviewed next, setting the stage for the more difficult case in next section that is used as a test for comparing the new TFDs defined in the previous section.The main(t,f)approach to IF estimation follows the simple principle that the IF of a mono-component signal at each time instant can be estimated by detecting the location of peaks along the frequency axis in the(t,f)plane.Several algorithms are based on the above principle. For example, the WVD gives an ideal estimate for mono-component LFM signals so it can be used as an IF estimator in such cases. However, its estimate is biased for non-linearly FM signals [41], and so other methods are needed. In the general case, the bias can be overcome by estimating the IF from a windowed WVD, but windowing increases the variance of the IF estimate. An optimal window length for an optimum bias-variance tradeoff at each time instant can be estimated adaptively [41]. Following this approach, multiple WVDs can be used to obtain multiple estimates of the IF as well as the confidence interval for each estimate. Starting from the smallest window, the confidence intervals of the IF estimates of successive windows are tested for overlap till the intersection of the confidence intervals of two successive windows results in a null set. The IF estimate of the longest window fulfilling the criterion of overlapping of confidence intervals is then selected as an optimal estimate. This method is known as the ICI rule where ICI means intersection of confidence intervals [41]. A modified approach further improves the accuracy of the ICI algorithm by taking into account the amount of overlap between two successive confidence intervals. Other iterative IF estimation algorithms can obtain the initial estimate of the IF from the Spectrogram [42]. The IP, defined as the integration of the IF, is then used to demodulate the original signal. The demodulation shifts the spectrum of the original signal around the zero frequency. The IF of the demodulated signal is then estimated again and this process is iterated till there is no further change in two consecutive estimates of the IF.Most QTFDs fail to accurately estimate the IF at very low SNR. In such scenarios improvements can be obtained by taking into account the main direction in the(t,f)plane where there is most energy concentration. For example, the adaptive combination of the directionally smoothed WVDs was shown to obtain a(t,f)representation that has high concentration of signal energy along the IF of the signal even at a very low SNR [43]. Such methods need to be further extended to deal with the more general multi-component case as addressed in the next section.For a multi-component signal, the(t,f)approach follows the principle that a multi-component analytic signal may be expressed as the sum ofNcmono-component signals, i.e.,(41)z(t)=∑i=1Nczi(t)=∑i=1Ncai(t)ejϕi(t)The IF of the ith signal component is defined by the time derivative of its phase as(42)fi(t)=12πdϕi(t)dtIf the individual components of the signal are FM signals, then the multi-component signal appears as multiple ridges in the(t,f)plane. Multi-component IF estimation algorithms need then to involve both detection and linking of related peaks to estimate the IF of each signal component. The linkage stage is needed so that the IF of each component can be tracked accurately and without mix-up with the IFs of other components.Image processing techniques can be used to link all the points of each IF in the(t,f)domain [44]. The key stages involve:1.Detecting peaks in a TFD by using first and second order partial derivatives along the frequency axis.Linking the detected peaks using some neighborhood-connectivity criteria [44]. For example, using a 10-neighborhood connectivity criterion, a peak belonging to the IF of a signal component must have at least one other peak of the IF of the same signal component in its 10-neighborhood and it should not have any peak of the IF of any other signal component in this selected neighborhood. The 10-neighborhood of a peak at the location(x,y)is defined as a set of all pixels at the following locations [44].(43){(x+1,y)(x+1,y+1)(x+1,y+2)(x+1,y−1)(x+1,y−2)(x−1,y)(x−1,y+1)(x−1,y−2)(x−1,y−1)(x−1,y−2)}Let us consider for illustration another method, the ICI based IF estimation algorithm which was extended to multi-component signals by first extracting signal components using a blind source separation algorithm [45]. This algorithm iteratively extracts signal components from the(t,f)plane till the total energy of the signal falls below a certain threshold. The disadvantage of this algorithm is its dependence on prior information like total number of signal components or SNR of a signal.A comparative study has shown that the above image processing algorithm based on connected component linking is more suitable for estimating the IF of the physiological signals considered as it is computationally efficient as compared to the component extraction method [46]. Fig. 15illustrates an example of IF estimation of a multi-component EEG signal using the image processing technique described in [44]. Both ICI with blind source separation and connected component linking algorithms can only be applied to(t,f)separable signals, i.e., signals whose components do not overlap with each other in the(t,f)domain. Many of the real-world signals do not fulfill this property so these methods are not general and should be applied only to relevant classes of signals, therefore requiring a-priori knowledge.In order to design high performance multi-component IF estimation algorithms for the general case, it is important to remember that the performance of multi-component IF estimation algorithms depend on the resolution and cross-term suppression capabilities of the TFD employed. Recent studies have indicated that data-dependent high-resolution TFDs like the Adaptive Fractional Spectrogram (AFS) [47] and variable-bandwidth filter based heterogeneous TFD [9] can outperform other TFDs in terms of their ability to accurately estimate the IFs of closely spaced signal components at low SNR. The improvement is naturally obtained using an adaptive procedure so as to get a “perfect match” with the data. The previous TFDs are therefore compared below in terms of their IF estimation performance. The AFS is included in the comparison as an example of data dependent TFD.In order to evaluate the IF estimation capability of the TFDs designed above, let us consider a two-component real signal expressed as:(44)s(t)=s1(t)+s2(t),where(45)s1(t)=rect[t−128T]cos⁡(2π(0.1t+0.15Tt2)),(46)s2(t)=rect[t−128T]cos⁡(2π(0.15t+0.15Tt2)),with time durationT=256s and sampling frequencyfs=1Hz. The corresponding IFs are(47)f1(t)=0.3tT+0.1,(48)f2(t)=0.3tT+0.15.The TFDs considered are the EMBD, Spectrogram, CKD and AFS; for the latter the IF is estimated using the component extraction procedure as discussed in [47]. The mean square error (MSE) is estimated by performing 200 Monte Carlo simulations [48]. Fig. 16displays the results of the IF estimates. The results indicate that the CKD gives more accurate estimates of the IFs as compared to other non-adaptive TFDs, and naturally, the AFS does even better due to the adaptation.The above findings indicate that an accurate estimation of the IF of the signal components is directly related to the cross-term suppression and auto-term resolution properties of(t,f)methods employed. Therefore, there is a need to develop better methods for improving the resolution of TFDs. The following section will discuss image processing methods for improving the resolution of TFDs.Clarity of representation is essential for TFDs, so that their relevant features can be read, selected and extracted. As all QTFDs suffer from limitations such as inherent compromise between cross-term suppression and auto-term resolution, it may adversely affect the extraction of some relevant features from(t,f)images as well as components separation. To improve the readability, let us consider the TFD as a(t,f)image. Then, image processing techniques can be used as a processing stage to either improve the resolution of cross-term-free low-resolution TFDs (e.g., the Spectrogram) using de-blurring methods or further suppress cross-terms in high-resolution TFDs (e.g., the WVD). Section 4.1 reviews existing image processing techniques for TFD image enhancement, and Section 4.2 presents an improved novel image processing technique for improving the resolution of the class of QTFDs considered and therefore allowing improved multi-component IF estimation.Given the number of different ways to generate a high-resolution TFD and the imperfections associated with each one of them, a natural approach is to process the TFD image using image processing techniques to improve the clarity of the image. Three types of processing are reviewed in the following sections:(t,f)image de-blurring,(t,f)de-noising and(t,f)image artifact suppression.Image de-convolution techniques are used for the estimation of high resolution images from blurred ones. For example, these techniques have been applied to estimate an original high-resolution TFD from the Spectrogram, which can be interpreted as a blurred version of the true(t,f)image [34]. Another method reduces the blurring in the Spectrogram by using artificial neural networks [49]. This technique estimates the inverse of the blurring function using neural networks, which are trained using a pre-computed Spectrogram and the WVD. The trained neural networks are then applied to the Spectrogram to estimate the true high-resolution TFD. The disadvantage of this technique is that it results in a discontinuous TFD [49].One way to enhance(t,f)images is to filter out noise to improve their SNR, using image de-noising techniques. Such techniques often assume an additive white noise model to account for the distribution of noise in images. Unfortunately, this model is not valid in general for TFDs as earlier studies have shown, that apart from the WVD, noise is not uniformly distributed in(t,f)images [50]. The influence of noise is stronger in the region of support of auto-terms as noise appearing outside the region of support of the auto-terms is reduced due to the low-pass filtering applied in the ambiguity domain. So,(t,f)image de-noising algorithms should be designed by taking into account the characteristics of noise distribution in QTFDs.Some of the image de-noising algorithms that have been applied to(t,f)images are discussed below.a)Singular Value Decomposition (SVD) based methods: As signals represented in the(t,f)domain are often characterized by just a few components, then, the resulting TFDρ(n,k)can be considered as a sparse matrix. Such TFD is in general not full rank and its SVD can be expressed as [51]:(49)ρ(n,k)=UDVH,where U is an orthogonal matrix,VHis the conjugate transpose of the orthogonal matrix V, andD=diag(α1,α2,⋯,αN−r+1,⋯,αN)is a diagonal matrix in which the last r singular values are equal to 0([αN−r+1,αN−r,⋯,αN]=0rT). In the presence of white noise, the TFD matrix becomes:(50)ρ(n,k)=UDVH+N=[U1D1V1]H.The TFD matrix is now full rank with its last r singular values being non-zero.Based on this property, a simple and fast de-noising algorithm can be designed as follows [51]:–Divide the TFD matrix into sub-blocksBs.Perform SVD on each sub-blockBs=UsDsVsHand set to zero the last singular values that are smaller than a threshold ϵ.Replace the submatrixBsbyB˜s=UsD˜sVsH(D˜sis the modified diagonal matrix D).Reconstruct the denoised matrixρ(n,k).Another SVD based de-noising method reduces noise by applying low-pass filtering to singular vectors [52]. The smoothed singular vectors are then used to synthesize a de-noised TFD. Experimental results demonstrate that this method can suppress noise without deteriorating the basic structure of TFDs [52].Wavelet based methods: These image de-noising techniques for improving the SNR of(t,f)images are based on the assumption that most of the(t,f)image energy is concentrated in only few coefficients of the Wavelet Transform (WT). The WT is obtained by decomposing a TFD into several bands using a low-pass filter and a high-pass filter [53]. So, a(t,f)image is de-noised by assigning zero value to coefficients below a certain threshold and then inverting the WT. Most of the wavelet de-noising techniques use additive white noise model for noise. This model may be considered as a rough approximation of the noise in QTFDs.Morphological processing: These techniques exploit the fact that signal components appear as ridges/curves occupying large connected regions in a(t,f)plane. On the other hand, noise is randomly distributed in a(t,f)plane and appears as small objects or disconnected regions [53]. These small objects can be eliminated from(t,f)images by using the image opening operation [54]. This operation compares a predetermined template (often called the structuring element) with objects in an image; if the size of an object is smaller than that of the template, it is deleted from the image; otherwise it is retained.Anisotropic diffusion[55]: Traditional 2D low-pass filtering schemes result in blurring in all directions regardless of object boundaries. The anisotropic diffusion overcomes this limitation by performing edge-preserving image enhancement such that the smoothing is performed on all the points in the(t,f)plane except the points lying near the objects boundaries (i.e., near the boundaries of support regions of the signal components).Three separate techniques are reviewed below that use image processing techniques.a)Some techniques use morphological image reconstruction to suppress interference terms in the WVD [11]. Such techniques usually employ two images; one is a marker that contains the starting points of the transformation, while the other one is a mask that constrains the transformation. For example, the technique described in [11] processes the WVD, a marker in this case, using the characteristics of the Spectrogram to form a mask. The processing of the WVD starts at peaks. These peaks are then dilated while the thinned Spectrogram constrains the spreading of the peaks. This process continues until the marker stops changing. This technique combines the advantages of the WVD and Spectrogram so that the resulting representation has high energy concentration and is also cross-terms free.Another approach uses a non-linear center affine filter to suppress the cross-terms in the WVD [56]; such a filter is designed to exploit the local statistics of a(t,f)image to adapt its shape. In the regions of high variance it transforms itself into a low-pass filter while in the regions of low variance it adapts itself into an identity operator. Thus it aims to reduce cross-terms while retaining the shape of auto-terms [56].The limitation of the above cross-term suppression techniques [11,56] is that they fail to give optimum results when cross-terms overlap with auto-terms.A hybrid image and signal processing technique can be used to suppress cross-terms in the WVD even in scenarios when cross-terms overlap with auto-terms [12]. The key stages of this technique are shown in Fig. 18. The technique uses a blurred cross-term-free reduced-interference TFD to locate signal component in a(t,f)plane. The reduced-interference TFD is then segmented using the connectivity criterion discussed in Section 3.3; each segment corresponds to a signal component in the time domain. Fractional Fourier filtering is then applied to perform time-varying filtering so as to extract signal components from the original signal. The extracted components are analyzed separately using the masked WVDs to suppress both inner and outer interference terms. The masked WVDs of the separated signal components are added up to obtain a cross-term free high-resolution TFD. This technique can also be used for estimating the IFs of multi-component signals as the extraction of signal components reduces the problem of IF estimation of multi-component signals to the basic IF estimation of mono-component signals. This technique can be more broadly applied than the first two methods, but it is still limited to signals with non-overlapping(t,f)signal components. The step by step illustration of this third approach for a two-component signal is shown in Fig. 19.The performance that can be achieved by combining a(t,f)approach with an image processing approach can be further enhanced by using an adaptive directional filtering based(t,f)image enhancement technique. This refinement includes adapting the direction of a(t,f)kernel at each(t,f)point on the basis of the direction of energy concentration resulting, in essence, in the definition of another high-resolution TFD.Most TFDs require optimization of their parameters to obtain a clear and accurate(t,f)representation with the best possible resolution; e.g. incorrect selection of window length for the Spectrogram can result in a significantly different visual representation to the correct representation (see [33], p. 39). So, there is a need for some kind of automatic procedure for the selection of parameters in applications requiring real-time computations. Most of the existing adaptive TFDs optimize the parameters of their kernels, either globally or locally, to maximize a certain measure representing the quality of a TFD [57–60]. Some of the commonly used quantitative measures for assessing TFD quality include the Kurtosis (Ratio of norms) [61], the Renyi Entropy [60], and the energy concentration measure [57]. These and other measures are described in detail in Section 5.3. For any given quality measure, the parameters of TFDs can be optimized by either using an exhaustive search technique or employing more computationally efficient methods such as the steepest decent recursive algorithm [57].Previous studies have reported that for underspread signals, directional filtering along the major axis of the auto-terms can significantly reduce the cross-terms without affecting the resolution of the auto-terms [32,62]. These schemes naturally require prior information about the angle formed by the auto-terms and the time axis. The angle formed by the auto-terms and the time axis can be estimated from the moments of the fractional Fourier transform [63] for signals whose auto-terms have only one direction of energy concentration in a(t,f)plane. In general, there are several possible directions of energy concentration in the(t,f)domain and this would require separate filters for all these directions at a local level. Another solution is to design a post-processing technique to further improve high-resolution TFDs by adapting the direction of a smoothing kernel locally for each point in the(t,f)plane. Such adaptive kernel TFD can be expressed as an extension of Eq. (6), i.e.:(51)ρadapt(t,f)=γθ(t,f)(t,f)⁎⁎(t,f)ρ(t,f),whereρadapt(t,f)is the adaptive directional TFD (ADTFD),γθ(t,f)(t,f)is an adaptive kernel whose direction is adapted at each point in the(t,f)plane, andρ(t,f)is the QTFD used to start the process. A directional smoothing kernel should have the following properties:•The kernel should have the maximum response when aligned with ridges. This implies that the kernel should have low-pass characteristics along its major axis.The kernel output should be zero for non-ridge points as otherwise spectral leakages would be observed at(t,f)points where no signal is present.Cross-terms are oscillatory in the direction of their major axis, but auto-terms are not, as illustrated in Fig. 20.Filtering along the major axis of the auto-terms does not blur a TFD.Both auto-terms and cross-terms appear as ridges in a QTFD.Convolve a magnitude squared TFD with K directional filters such that the angle of each filter is given by:(54)θk=2πkK,k=1,⋯,K.For each(t,f)point, choose the angle that maximizes the magnitude of a directionally smoothed TFD.(55)θt,f=2πKargmaxk|γθk(t,f)⁎⁎(t,f)|ρ(t,f)|2|2.

@&#CONCLUSIONS@&#
