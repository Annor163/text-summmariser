@&#MAIN-TITLE@&#
A unified framework for translation and understanding allowing discriminative joint decoding for multilingual speech semantic interpretation

@&#HIGHLIGHTS@&#
A comparison between the methods used for speech translation and understanding.A unified framework for translation and understanding.A discriminative joint decoding for multilingual speech semantic interpretation.The proposition is competitive with state-of-the-art techniques.The framework can be generalized to other components of a dialogue system.

@&#KEYPHRASES@&#
Multilingual speech understanding,Conditional random fields,Hypothesis graphs,Statistical machine translation,Dialogue systems,

@&#ABSTRACT@&#
Probabilistic approaches are now widespread in most natural language processing applications and selection of a particular approach usually depends on the task at hand. Targeting speech semantic interpretation in a multilingual context, this paper presents a comparison between the state-of-the-art methods used for machine translation and speech understanding. This comparison justifies our proposition of a unified framework for both tasks based on a discriminative approach. We demonstrate that this framework can be used to perform a joint translation-understanding decoding which allows to combine, in the same process, translation and semantic tagging scores of a sentence. A cascade of finite-state transducers is used to compose the translation and understanding hypothesis graphs (1-bests, word graphs or confusion networks). Not only this proposition is competitive with the state-of-the-art techniques but also its framework is even more attractive as it can be generalized to other components of human–machine vocal interfaces (e.g. speech recognizer) so as to allow a richer transmission of information between them.

@&#INTRODUCTION@&#
Nowadays, probabilistic approaches are widely used in natural language processing (NLP) applications (speech recognition, machine translation, syntactic parsing, part-of-speech or semantic tagging). Many different approaches are available in the literature and their relative performances differ according to the targeted tasks. So, considering a specific task, it not always possible to know the best performing approach before evaluating most of the models. Though some important features of the various approaches may prevent us from testing all the combinations with respect to some of the task characteristics.For instance, for spoken language understanding (SLU), the task of extracting the meaning from a user's utterance, conditional random fields (CRF) (Lafferty et al., 2001) have been shown to be the most efficient approach so far (Hahn et al., 2010); whereas for statistical machine translation (SMT), the log-linear phrase-based statistical machine translation (LLPB-SMT) model (Koehn et al., 2003) is the most commonly used and has shown its potential for many language pairs and domains of application.However despite the differences in their formal descriptions, distinctions between probabilistic approaches tend to fade away when confronted with practical considerations and the numerous assumptions required for their implementations. Some works already proposed the use of discriminative approaches, such as CRF, for SMT (Och and Ney, 2002; Liang et al., 2006; Lavergne et al., 2011) while at the same time the phrase-based translation pipeline was also investigated in the context of other natural language processing tasks such as grapheme–phoneme conversion (Rama et al., 2009) or part-of-speech tagging (Gascó i Mora and Sánchez Peiró, 2007).So far, many works have considered the issue of multilingual systems for different NLP tasks such as cross-lingual information retrieval (e.g. Capstick et al., 2000; Jagarlamudi and Kumaran, 2008), cross-lingual information distillation (Singla and Hakkani-Tur, 2008), multilingual speech recognition adaptation (Schultz, 2004) and cross-lingual spoken language understanding (e.g. Minker, 1998; Lefèvre et al., 2010).In this paper, our overall objective is to develop efficient approaches for speech understanding in a multilingual context (where SMT is also involved, as explained later). In this outlook, the state-of-the-art approaches are investigated for each of the underlying issues: CRF for speech understanding and LLPB-SMT for translation. In a first step, we propose to use and optimize the LLPB-SMT approach for speech understanding, and also to integrate a CRF-based model in a machine translation module to evaluate the practical interest of each method. This preliminary study serves to highlight the specificities of each task and to evaluate the performance of the respective approaches on these tasks.Besides, we have shown in a previous work that the use of machine translation is an effective solution for the portability of an understanding system from a language to another (Jabaian et al., 2010). For one of the best performing configurations, the portability is simply obtained by cascading a translation module with an understanding system, the overall idea being to translate the user's inputs into a language for which we already have a performing SLU system. This idea is to be contrasted with this consisting in trying to build a performing system in the new language, for which we generally lack enough usable data.But, in this context, it has been stated that the best understanding output is not always generated from the best translation hypothesis. From our experience, it is often due to bad word reordering. Therefore, the selection of the best translation is not sufficient to optimize the overall system in a multilingual understanding scenario. Consequently, based on the initial comparison made between both tasks, we propose a model that can jointly decode the user's inputs in terms of translation and understanding hypotheses. This joint decoding selects a translation taking into account the semantic tagging generated for this translation. It is no longer searched for the best possible translation, but for the translation that can be semantically labelled in the best possible way.The reported experiments are carried out on the French Media man–machine dialogue corpus (Bonneau-Maynard et al., 2006). Manually transcribed and conceptually annotated data allow to train an initial CRF-based understanding system for French. In order to use this system for Italian semantic tagging, an Italian to French translation system, based on either LLPB-SMT or CRF, is trained with few manual data. This system is used during decoding to infer translations (from Italian into French) in order to provide inputs to the French understanding system. We show how these models are merged in a single decoding loop by means of hypothesis graphs and combined scores. To define the performance upper-bounds of the proposed methods, all experiments are performed using a manual transcription of the speech data.Preliminary results have already been presented in Jabaian et al. (2013b). This current version is not only a refinement of these experiments but it also provides a deeper comparison of the techniques at hand with more result analysis. For instance, we investigate more systematically the effect of the tuning mechanism used to optimize the performance of the joint models and show that all the results are noticeably improved. This optimization, based on the minimum error rate training (MERT) algorithm (Och, 2003), is first applied to each model (translation and understanding) separately, then it is generalized to perform an optimized joint decoding using both systems.The paper is organized as follows: Section 2 presents the use of the log-linear phrase-based stochastic machine translation approach for speech understanding. Then Section 3 describes the use of Conditional Random Fields for machine translation and the parameter tuning of this model. Our proposal of a joint decoding process between translation and understanding is introduced in Section 4. Section 5 gives an overview of the experimental study along with the results.The log-linear phrase-based statistical machine translation (LLPB-SMT) (Koehn et al., 2003) is amongst the most popular approaches for SMT. This approach relies upon a log-linear combination of several models, including reordering models, translation models and n-gram language models.The translation model P(s∣t) represents the probability that a source sentence s is the translation of a sentence t from all possible sentences in the target language. The probabilistic language model p(t) assigns a probability to a word sequence t by means of a probability distribution. The decoding with the LLPB-SMT model is then expressed asargmaxtP(s∣t).P(t). The reordering model introduces the possibility to modify the time sequence of the source sentence to match monotonically the target sentence. For sake of simplicity we will not detail here the implication it has during the decoding step.The model coefficients in the LLPB-SMT system are trained using the maximum class posterior criterion or using an error criterion by application of the MERT algorithm (Och, 2003) with respect to the measured translation quality.Some works already investigated to which extent statistical machine translation approaches can be ported to a task of speech understanding. For example (Macherey et al., 2001) proposed to apply an SMT system to SLU and showed that using a max-entropy SMT approach for understanding gives good performance compared to other classical understanding methods (Macherey et al., 2009). In the same line we propose to consider the understanding of a user utterance as a translation from a sequence of words (source language) to a sequence of concepts (target language).This approach assumes that the sequences of concepts are the translations of the original sequences of words and then the best sequence of concept c derived from a sequence of word s can be defined as:(1)cˆ=argmaxcP(s∣c).P(c)where P(s∣c) is a word-to-concept translation model and P(c) is a concept n-gram language model.It is important to mention that this model is somewhat a derivation of the approach devised in Pieraccini et al. (1991) where Hidden Markov Models are used for word-to-concept translation modelling.Despite the apparent similarities between the tasks, SLU has its own characteristics that must be taken into consideration in order to improve the performance which can be obtained with LLPB-SMT.The differences between a classical translation task (from a natural source language to a target one) and the use of translation for understanding (translation from a natural language into semantic tags) can be summarized as follows:•unbalanced token association. Contrary to regular translation where word-to-word alignment is on average linking a source word to a target word, concepts, seen as target words, are most of the time linked to several source words. Even considering the phrase-based approach, linking sub-sentential segments, the phrase table (translation model in this case) is still highly unbalanced in the understanding case and this questions several aspects of the system training phase;no null fertility. In a translation task, a source word can be skipped (null fertility), whereas for understanding every word must be aligned to a concept. Even though words that do not contribute to the meaning of the sentence, considering the task domain, are labelled with a specific NULL concept;no reorderings. Semantics of a sentence generally follows the order in which words occur unlike in a translation task where translated words may have a very different order between target and source sentences depending on the considered language pair and their syntactic proximity;no long-range target language model. The number of concept tokens is always very low compared to the usual target vocabulary size and the concept sequences are shorter. For these two reasons understanding can use language models with short histories;no common error measurement. Evaluation measures are different in both tasks (BLEU, Papineni et al., 2002) for translation vs. CER – concept error rate – for understanding). Therefore the tools used for optimizing translation systems should be adapted to optimize CER score instead of BLEU.A major difficulty of the translation task is that it requires automatic alignment of a word from the source language to its corresponding word in the target language. Since corpora used for training translation systems are usually aligned at the sentence level, an automatic alignment step is necessary to obtain word alignment. However, most of understanding corpora are labelled and aligned at the segment level and therefore the use of alignment information can be beneficial to help the alignment process. In this respect, the use of the BIO (begin inside outside) tagging (Ramshaw and Marcus, 1995) ensures that each word in the source sentence is aligned to its corresponding concept and therefore no additional automatic alignment is required. In that way, the extraction of the phrase table is obtained from a corpus with a perfect alignment (no alignment errors). This somehow addresses the two first points.Following the assumption of the third point that the semantics of a sentence follows the order in which words occur, we propose to introduce a constraint of monotony, which conducts the decoder to follow strictly the order of words to generate concepts.Finally, according to the last point, since we want to evaluate the hypotheses generated by this approach from an understanding perspective (evaluating the CER and not the BLEU score) we propose to modify the MERT algorithm (Och, 2003) used to optimize the system's parameters with respect to a development set so as to maximize the CER directly.Last but not least it is important to note that there is a major difference between the two tasks in the way they are dealing with out of vocabulary (OOV) words. Generally in SMT, the OOV words encountered during the decoding are copied (projected untranslated) to the output. For a translation task this projection is a good strategy when OOV words are named entities (such as people names, places) which are likely to remain unchanged in several languages.In understanding, the output vocabulary is limited to predefined concepts and thus the projection of OOV named entities in the output is not a suitable strategy. On the other hand, it is possible to anticipate the problem by enriching the training corpus with named entity lists from the target domain. For example, in the context of a hotel reservation task, a large number of OOV words comes from city names missing in the training data. Adding a list of cities to the training data may decrease the impact of the OOV words on the result.Several efficient methods have been proposed for concept tagging (He and Young, 2006; Lefèvre, 2006; Raymond and Riccardi, 2007; Wang et al., 2009; Hahn et al., 2010). Due to their good performance, Raymond and Riccardi (2007) proposed to use conditional random fields (CRFs) (Lafferty et al., 2001) for language understanding and they are now largely used as a state-of-the-art model for this task. Linear-chain CRFs represent a log-linear model, normalized at the sentence level. In this formulation concept sequences are represented in the BIO formalism, see below, so that each word has a concept associated to it with a segmental information.For a sequence of conceptsCˆ=c1,…,cNthat can be hypothesized by the SLU module from a word sequence of length NW=w1…,wN, linear-chain CRFs model the probability between concepts and words as follows:(2)P(c1N|w1N)=1Z(w1N)∏m=1NH(cm−1,cm,ϕ(w1N,n))with(3)H(cn−1,cn,ϕ(w1N,n))=∑iλihi(cn−1,cn,ϕ(w1N,n))Log-linear models are based on feature functions hirepresenting the information extracted from the training corpus, λ are estimated during the training process and Z is a normalization term.ϕ(w1N,n)represents a pattern function that will be used to define the feature functions during training.There has been a lot of research to improve the machine translation quality using alternative methods for translation, such as hierarchical translation (Chiang, 2007), hybrid approaches (phase-based and hierarchical (Dymetman and Cancedda, 2010) or n-gram-based translation models (Mari`no et al., 2006).Recently, efforts have been made in order to benefit from a good performance of the discriminative methods in machine translation. Lavergne et al. (2011) proposes a translation system based on CRF scoring while Gao and He (2013) proposes to score the translation phrase-table using a Markov Random Field model.We now envisage the use of an understanding system to address the translation task. Of course the differences listed in the previous section remain true although their influence is now in the reverse direction. The translation is viewed as a tagging of the source sequence, the possible tags being the words of the target language themselves. Training a tagger based on a CRF approach requires a corpus annotated (translated corpus) at word level. The application of the IBM models (Brown et al., 1993) provides automatic word alignments from a bilingual corpus originally aligned at the sentence level.As for the understanding task, where many words may be associated with a single concept, several source words can be aligned with only one target word. To deal with that issue, tags are handled as it is done for the understanding task using the BIO formalism. For example, the French sequence “Je voudrais” aligned to the Italian word “vorrei” can be represented as: “je, B_vorrei” “voudrais, I_vorrei”.The main difficulty for training CRF models for translation is related to the high number of tags (corresponding to the target language vocabulary size). Though some solutions exist. For instance, Riedmiller and Braun (1993) proposes to use the RPROP algorithm for feature optimization to deal with a large number of features. This algorithm reduces the memory requirements compared to other optimization algorithms (Turian et al., 2006). Another limitation to the use of CRF for translation is that it does not take into account word reordering and that the target language model is limited by the computational complexity of the decoding.So it appears that the MT task is more demanding in terms of modelling constraints than understanding (reduce to mere sequence labelling in this case). It could be profitable to benefit from the discriminative power of the CRF approach but specificities of the MT task must be handled properly.Raymond et al. (2006) proposes a composition of Weighted Finite State Transducers (WFSTs) for semantic interpretation. Furthermore, in order to obtain an efficient CRF-based translation system, Lavergne et al. (2011) proposes a model based on finite state transducers in which the different stages of the translation process (segmentation, reordering, phrase translation etc.) are treated separately and can be composed all together. This model, called CRFPB-SMT hereafter, embeds a mechanism for modelling a translation table by sub-sentential segments (called tuples, but analogous to phrases) and uses CRF as the probabilistic models providing the hypothesis scores.The CRFPB-SMT decoder is based on a composition of WFSTs representing the following steps: segmentation and reordering of the source sentence according to the word tuples, application of the translation, hypothesis scoring based on CRF, and composition with a target language model. Kumar and Byrne (2003) proposed a comparable architecture that used the less efficient Alignment Template Translation Models instead of CRF as the translation model.This architecture allows to consider the translation of a sentence as a composition of transducers in the following order:(4)λtranslation=λS∘λR∘λT∘λF∘λLwhere λSis the acceptor of the source sentence s; λRimplements the segmentation and reordering steps; λTis a dictionary of tuples, combining sequences of the source language and their possible translations based on the tuples inventory; λFis a feature matcher, which assigns probability scores to tuples using a CRF model; λLis a language model of the target language.The reordering model λRis trained using the approach proposed by Crego and Mari no (2006). This approach is based on a part-of-speech tagging of the sentences to reorder the source side of the training corpus.Tuples are extracted from parallel sentences in two steps. First, an iterative procedure allows to combine words. Each group contains words from the source sentence aligned with one or many words from the target sentence. In a second step, tuples are extracted from these groups respecting the word order in the target sentence and following the constraint that no word in a tuple is aligned to a word outside the tuple. The tuple extraction process ends when no smallest tuples can be found without violating the previous constraints.The feature matcher λFrelies on a CRF model to assign probability scores to tuples. This transducer is obtained as a composition of a set of weighted transducers, each one representing a class of functions (in practice the unigram and the bigram feature functions of the CRF model).Several algorithms have been proposed to tune the weights of the log-linear translation model aiming to obtain an optimal translation. Minimum error rate training (MERT) algorithm proposed by Och (2003) is the most used in state-of-the-art LLPB-SMT systems.In this line, we propose to use MERT in order to optimize the weights of the different scored components in the CRFPB-SMT model. In such optimization various parameters used during the decoding are tuned on a development corpus, then the translation is performed using the parameter values found during tuning.The study of the relations between the different approaches in the previous sections was mainly aimed at being able to combine them efficiently for multilingual understanding.In a previous work (Jabaian et al., 2010), we have shown that among several possibilities the best way to port an understanding system to a new language is also the simplest: to translate user utterances in the new language back to the language of the existing understanding system and then to use this system to label the translation hypothesis.This strategy supposed that a SLU system is available for the source language, and SMT is used to translate the target test sentences back to the source language. The translations become the inputs of the source SLU system. So, this proposition is based on a pipeline of a translation system (LLPB-SMT) and an understanding system (CRF). This strategy might be highly dependent on the performance of the SMT used to translate the data. The overall performance depends also on the robustness of the source SLU tagger to translation errors.The SMT system can be obtained following standard routines (based on large collections of parallel texts), or by developing a domain-adapted SMT system right from the start. The best hypothesis generated by the translation system is conveyed as input to the understanding system. However, other translation hypotheses could have tagging results with higher scores. So, the selection of the best translation does not necessarily optimize the behaviour of the overall system.A joint decoding between translation and understanding can be an efficient solution to this problem. The joint decoding has the advantage of optimizing the selection of the translation taking into account the tags that can be assigned to the best possible translations.Moreover the CRFPB-SMT approach can be generalized to the understanding task (comparable to what was done in Section 2 with LLPB-SMT). Therefore an understanding system λunderstandingcan be obtained in the same way as proposed in Section 3. This representation allows to obtain a graph of understanding hypotheses similar to that obtained for translation. Since the translation output vocabulary is the same as for the understanding input, these two graphs can be easily composed using the composition function (∘) to derive a joint graph:(5)λjoint=λtranslation∘λunderstandingThis composition takes a sentence in the target language as input and assigns a sequence of concepts to that sentence using a semantic tagger available for the source language. Although graphs are composed sequentially this consists globally in a joint decoding between the translation and the understanding systems since the probability scores of their models are taken into account simultaneously to determine the best overall hypothesis.Interestingly enough the transducer λjointcan be generalized quite easily to allow a composition with a speech recognition graph in the context of a human–machine dialogue system (Jabaian and Lefèvre, 2013).

@&#CONCLUSIONS@&#
