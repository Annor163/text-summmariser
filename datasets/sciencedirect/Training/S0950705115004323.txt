@&#MAIN-TITLE@&#
Exploring events and distributed representations of text in multi-document summarization

@&#HIGHLIGHTS@&#
We explore an event detection framework to improve multi-document summarizationWe use distributed representations of text to address different lexical realizationsSummarization is based on the hierarchical combination of single-document summariesWe performed an automatic evaluation and a human study of the generated summariesQuantitative and qualitative results show clear improvements over the state-of-the-art

@&#KEYPHRASES@&#
Multi-document summarization,Extractive summarization,Event detection,Distributed representations of text,

@&#ABSTRACT@&#
In this article, we explore an event detection framework to improve multi-document summarization. Our approach is based on a two-stage single-document method that extracts a collection of key phrases, which are then used in a centrality-as-relevance passage retrieval model. We explore how to adapt this single-document method for multi-document summarization methods that are able to use event information. The event detection method is based on Fuzzy Fingerprint, which is a supervised method trained on documents with annotated event tags. To cope with the possible usage of different terms to describe the same event, we explore distributed representations of text in the form of word embeddings, which contributed to improve the summarization results. The proposed summarization methods are based on the hierarchical combination of single-document summaries. The automatic evaluation and human study performed show that these methods improve upon current state-of-the-art multi-document summarization systems on two mainstream evaluation datasets, DUC 2007 and TAC 2009. We show a relative improvement in ROUGE-1 scores of 16% for TAC 2009 and of 17% for DUC 2007.

@&#INTRODUCTION@&#
Many automatic summarization systems have been proposed in order to cope with the growing number of news stories published online. The main goal of these systems is to convey the important ideas in these stories, by eliminating less crucial and redundant pieces of information. In particular, most of the work in summarization has been focused on the news domain, which is strongly tied to events, as each news article generally describes an event or a series of events. However, few attempts have focused on the use of automatic techniques for event classification for summarization systems for the news domain [1]. In fact, most of the work on multi-document summarization are either based on centrality-based [2–5], Maximal Marginal Relevance (MMR) [6–9], and coverage-base methods [1,10–15]. Generally, centrality-based models are used to generate generic summaries, the MMR family generates query-oriented ones, and coverage-based models produce summaries driven by topics or events.The use of event information in multi-document summarization can be arranged in the following categories: initial hand-based experiments[16]; pattern-based approaches based on enriched representations of sentences, such as the cases of the work presented by Zhang et al. [15] and by Li et al. [13], which define events using an event key term and a set of related entities, or centrality-based approaches working over an event-driven representation of the input [1], where events are also pattern-based defined; and, clustering-based event definition [17].The major problem of these approaches is that is difficult to relate different descriptions of the same event due to different lexical realizations. In our work, we address this problem by using an event classification-based approach and including event information supported by two different distributed representations of text—the skip-ngram and continuous bag-of-words models [18]. Our event detection and classification framework is based on vector-valued fuzzy sets [19,20]. We evaluate our work using the standard summarization evaluation metric, ROUGE [21]. Moreover, to better understand the impact of using event information, we also perform a human evaluation using the Amazon Mechanical Turk11https://www.mturk.com/.Our main goal in this work was to produce event-based multi-document summaries that are informative and could be useful for humans. The human evaluation shows that our summaries are on average more useful for humans than the reference summaries. While we conducted our experiments in the news domain, our methods are also applicable to other domains, such as opinion and meta-review summarization in consumer reviews [22].In this document, the next section describes the related work to contextualize the findings obtained in the experimental results. Section 3.2 introduces the Event Detection framework; which is enhanced by the Continuous Skip-gram Model presented in Section 3.3; both are included in a Event-based Multi-Document Summarization framework (Section 3). The experimental results are included and discussed in Section 4. Section 5 details the conclusions and discusses future research directions.

@&#CONCLUSIONS@&#
In this work, we explore a multi-document summarization framework based on event information and word embeddings that achieves performance above the state-of-the-art.The multi-document summarization framework was developed by extending a single-document summarization method, KP-Centrality, in two hierarchical ways: single-layer and waterfall. The single-layer approach combines the summaries of each input document to produce the final summary. The waterfall approach combines the summaries of the input documents in a cascade fashion, in accordance with the temporal sequence of the documents. Event information is used in two different ways: in a filtering stage and to improve sentence representation as features of the summarization model. Related to event information, we also explored the temporal sequence of the input documents by increasing the size of the initial and intermediate summaries, used by our framework. To better capture content/event information expressed using different terms, we use two distributed representations of text: the skip-ngram model, the continuous bag-of-words model, and the distributed representation of sentences. Event detection is based on the Fuzzy Fingerprint method and trained on the ACE 2005 Corpus.To evaluate this multi-document summarization framework, we used two different setups: an automatic evaluation of the informativeness of the summaries using ROUGE-1, and a user study.Our experiments showed that the use of event information combined with a distributed text representation (the SKIP model) further improved a generic multi-document summarization approach above state-of-the-art. Although we propose two different strategies for developing our multi-document methods, single-layer and waterfall, the best results were not achieved by the same architecture in the evaluation datasets because waterfall approach seems to be preferable to summarize large number of documents (e.g., 25 documents) and the single-layer seems more suitable for small number of documents (e.g., 10 documents). We confirmed this tendency by reducing the documents per topic to 10 in DUC 2007 and experimenting with waterfall and single-layer architectures. Both architectures achieved better results than the baseline and the reference systems. Analysis of the results also suggests that the waterfall model offers the best trade-off between performance and redundancy.A possible future research direction is the compression of the sentences selected by our extractive summarizer. The process of compressing sentences should use event information to delete irrelevant words and to shorten long phrases. A solution to adequately compress sentences using event information entails solving multiple subproblems. For example, the identification of the relation between named entities (relationship extraction), identification of sentences mentioning the same event (event co-reference), and extract when the events take place (temporal information extraction), among other problems.