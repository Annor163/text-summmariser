@&#MAIN-TITLE@&#
Joint Sparsity and marginal classification for improving Sparse Imputation performance in speech recognition

@&#HIGHLIGHTS@&#
The self-similarity nature of speech is used to improve the Sparse Imputation method.The similar frames of speech utterance are identified using marginal classification.The Joint Sparsity method is used to reconstruct noisy component of similar frames together.

@&#KEYPHRASES@&#
Sparse Imputation,Robust automatic speech recognition,Compressive sensing,Joint Sparsity,Self-similarity,

@&#ABSTRACT@&#
Sparse Imputation (SI) is a relatively new method that reconstructs missing spectral components of noisy speech signal with the help of the sparse-based representation approaches. In this method, the redundancy of signal in the frequency domain helps to rebuild noisy spectral components from the remained reliable ones. On the other hand different parts of speech signal, despite time intervals between them, can be inherently similar to each other. In this paper, a major modification over the SI method is proposed that in addition to data redundancy property of speech signal in small regions, takes the advantages of its self-similarity nature over long intervals. By identifying mostly similar frames, using a method based on the marginal classification, the Joint Sparsity method is applied and a method dubbed as the Joint Sparse Imputation is presented. The experiments conducted on AURORA 2 data set show that the proposed method significantly improves the recognition results in different noisy conditions, compared to the original SI method.

@&#INTRODUCTION@&#
The Sparse Imputation (SI) is a method in the field of noise robust speech recognition which follows reconstructing missing spectral components of speech signal using the sparse representation-based approaches. In fact, this approach is a subset of the missing feature/data approaches [1,2] which concentrates on compensation of the additive noise effects. In such methods, with the help of the mask estimation methods [3–6], unreliable spectral components (on which the destructive effect of noise is significant) are first identified and tagged. These unreliable components are then reconstructed using the remained reliable ones on which the effect of noise is negligible.The Sparse Imputation method was first introduced by Gemmeke [7]. In this method, the emerging theory of compressive sensing (CS) [8] was successfully utilized to reconstruct the unreliable components of noise corrupted signals. In the Sparse Imputation, the CS is utilized to compensate noisy feature vectors for the task of automatic speech recognition; but, there are other approaches that use the CS to enhance speech signal quality [9].In the common CS approach, signal y is sampled using a random measurement matrixΦmeasurment; the goal of the CS approach is to recover y from the sampled signalb=Φmeasurmentyusing the recovery algorithm of CS as given by(1)x^=argminx{‖Φmeasurmenty-ΦmeasurmentAx‖2+λ‖x‖1},whereAis a sparsifying basis for y and x is a sparse vector in theAspace. The scalarλis a constant weight used to balance between the fidelity (ℓ2norm) and the sparseness (ℓ1norm) terms. In contrast, in the missing feature [2] problem, we have a noisy signalỹ=y+nthat parts of it is destroyed by a random additive noise (n). Discarding the destroyed parts and modeling this effect of noise with a measurement matrixΦnoisesuch asΦmeasurment, we could recover y fromb=Φnoiseỹ(reliable components of observed noisy signal), using an algorithm similar to the recovery algorithm of CS.Here,Acould be a sparsifying basis for y[10] or a dictionary consisted of exemplars of y[11]. The clean estimate ofỹwould beAx^.The main basis of the missing feature methods is established on the inherent information redundancy in speech signal. This means that the information in speech signal is not limited to a certain range of its time–frequency spectrum. For more explanation, it can be referred to the performed experiments in [12,13] showing that even with a small part of speech spectrum, still the remaining signal is understandable to the human listeners. On the other hand, in numerous references it has been pointed out that speech signal has considerable fractal properties in the time domain [14–16]. The fractal properties are closely related to self-similarity and in other words it means that different parts of speech, despite having time intervals from each other, could be potentially very similar and could have the same natures. This phenomenon motivated us to propose a method that leverages the self-similarity feature of speech signal to help better reconstruction of the missing spectral components of noisy speeches. The importance of this issue in the field of the missing feature is that if some of the spectral components of a frame are lost, one would hope that in another time position of the same signal, there are one or more less degraded frames with nearly similar components, which, along with reliable components of the given frame, can be used for better reconstruction of its unreliable components. In this manner, a higher efficiency of missing feature methods can be expected. In other words, the noisy frames that are similar in nature are reconstructed together, in a Joint manner. A similar approach, also known as the Multiple Measurement Vectors, is used in many applications such as the distributed compressive sensing [17,18] and the images noise removal [19].In this paper, we aim to exploit the self-similarity property, available in speech signal using the Joint Sparsity approach to improve the performance of the Sparse Imputation method. For this purpose, we first offer a method based on the GMM clustering and marginalization process in order to be able to determine the similar speech frames, despite the destructive effect of noise on them. Then, the relations needed to use the Joint Sparsity approach inside the Sparse Imputation method are presented.The paper is organized as follows, in Section 2.1 we introduce the Sparse Imputation method. In Section 2.2, details of the Joint Sparsity method and its mathematical relations are presented. In Section 2.3, the necessary relations for employing the Joint Sparsity are detailed. Moreover, the proposed method for determining the similar frames of speech is presented in this section. Section 3 specifies the exploited data set and the performed experiments. Implementation results and the discussion are presented in Section 4, and finally in Section 5 conclusions are presented.

@&#CONCLUSIONS@&#
