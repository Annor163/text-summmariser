@&#MAIN-TITLE@&#
Effective learning hyper-heuristics for the course timetabling problem

@&#HIGHLIGHTS@&#
Course timetabling constraints are converted into generic structures.Two types of learning for operator selection are contrasted: online and offline.An empirical approach for selecting the best operators from a pool is proposed.Online learning shows competitive results, even producing new best-known solutions.The proposed method achieves a balance between generality and effectiveness.

@&#KEYPHRASES@&#
Timetabling,Hyper-heuristics,Heuristics,Metaheuristics,Combinatorial optimization,

@&#ABSTRACT@&#
Course timetabling is an important and recurring administrative activity in most educational institutions. This article combines a general modeling methodology with effective learning hyper-heuristics to solve this problem. The proposed hyper-heuristics are based on an iterated local search procedure that autonomously combines a set of move operators. Two types of learning for operator selection are contrasted: a static (offline) approach, with a clear distinction between training and execution phases; and a dynamic approach that learns on the fly. The resulting algorithms are tested over the set of real-world instances collected by the first and second International Timetabling competitions. The dynamic scheme statistically outperforms the static counterpart, and produces competitive results when compared to the state-of-the-art, even producing a new best-known solution. Importantly, our study illustrates that algorithms with increased autonomy and generality can outperform human designed problem-specific algorithms.

@&#INTRODUCTION@&#
The design of timetables is a widespread human activity that can be formulated as an optimization problem, and thus solved using modern search methodologies. Educational timetabling is a widely studied class of timetabling problems concerning the scheduling of meetings between students and lecturers. Several variants of educational timetabling problems have been studied in the literature (Adriaen, De Causmaecker, Demeester, & Vanden Berghe, 2006). The Course Timetabling Problem is one of such variants, in which a number of events or lectures of university courses need to be scheduled over a prefixed period of time (normally a week), satisfying various constraints on rooms, time-slots and students. Many articles related to educational timetabling have been published, and automated approaches to timetabling are used in practice. A number of survey articles have appeared over the years from the early (Carter, 1986; Schaerf, 1999) to more recent articles (Burke & Petrovic, 2002; Lewis, 2008; Qu, Burke, McCollum, Merlot, & Lee, 2009). Two recent approaches include an adaptive linear combination of heuristics (Rahman et al., 2014) and a two-stages decomposition of an integer programming model applied to a practical case (Sørensen & Dahms, 2014). The state-of-the-art approaches for course timetabling are further discussed in Section 4.3.Automating the design of timetables is a complex task. It requires a detailed and difficult to elicit knowledge of the problem and the particular instance to be solved. A recent trend in search and optimization, hyper-heuristics, aims at reducing the role of the human expert in the process of designing computational search methodologies, and thus raise the level of generality in which these methodologies operate (Burke et al., 2003, 2010, chap. 15). A survey of the state of the art in hyper-heuristics has been recently published (Burke et al., 2013). Hyper-heuristic approaches have been applied to educational timetabling with encouraging results (Qu, Burke, & McCollum, 2009; Burke, McCollum, Meisels, Petrovic, & Qu, 2007; Soria-Alcaraz Jorge, Terashima-Marin, & Carpio, 2010). An automated approach to course timetabling also requires the ability to model different classes of problems with a wide range of characteristics and constraints. The modeling methodology proposed in (Soria-Alcaraz Jorge, Carpio, Puga, Terashima-Marin, et al., 2013; Soria-Alcaraz Jorge et al., 2013) (Methodology of Design) fills this requirement by providing a generic representation applicable to real-world instances.An important aspect of hyper-heuristics is generality and how to define it. As discussed in (Misir, Verbeeck, De Causmaecker, & Vanden Berghe, 2013), generality can be across various problem domains (Ochoa, Hyde, et al., 2012; Ochoa et al., 2012) or across various heuristic sets (Chakhlevitch & Cowling, 2005; Misir, Verbeeck, De Causmaecker, & Vanden Berghe, 2010). Generality has also been related to the ability to solve several variants of the same problem, which is achieved by designing problem models with increased generality. This is the case of the excellent approaches dealing with vehicle routing (Pisinger & Ropke, 2007) and nurse rostering (Burke & Curtois, 2014), respectively. This latter understanding of generality is the most relevant to our automated approach to course timetabling. We consider a single problem and a single heuristic set. Indeed a pre-processing stage is suggested to select the most adequate members of the heuristic set. However, our approach is general in that different types of course timetabling policies and constraints can be modeled. This is an important feature in real-world timetabling, as it is common that whenever a change emerges in institutional policies (adding, removing or changing current timetabling constraints) it is necessary to change the previously used algorithm to handle these new situation. The proposed general modeling methodology is then combined with an adaptive search algorithm incorporating learning mechanisms and effective move operators to produce a state-of-the art approach.This article implements an iterated local search hyper-heuristic framework that combines several move operators for the course timetabling problem. The autonomous design of algorithms requires the incorporation of machine learning mechanisms. The article contrasts two types of learning: static (offline) learning, in which there is a clear distinction between a training phase and an execution phase; and dynamic (online) learning, which takes place while the algorithm is solving a given instance. The resulting algorithms are tested over the set of publicly available real-world instances collected from the first and second International Timetabling competitions (McCollum et al., 2010).The next section formulates the course timetabling problem and describes the modeling methodology used. Section 3 describes the proposed iterated local search hyper-heuristic framework, including the learning mechanisms and the move operators considered. The longest section in the article, Section 4, describes the group of empirical studies conducted and analyzes the results. Finally, Section 5 summarizes the main findings and suggests directions for future work.The course timetabling problem can be formulated as a constraint satisfaction problem in which the variables are events. The problem may be concisely defined (Conant-Pablos, Magaña-Lozano, & Terashima-Marín, 2009), in terms of a set of events (courses or subjects)E={e1,e2,…,en}, a set of time-periodsT={t1,t2,…,ts}, a set of places (classrooms)P={p1,p2,…,pm}, and a set of agents (students registered in the courses)A={a1,a2,…,ao}. An assignment is then given by the quadruple(e∈E,t∈T,p∈P,S⊆A), and a solution to the problem is a complete set of n assignments (one for each event) that satisfies the set of hard constraints.The modelling methodology proposed in (Soria-Alcaraz Jorge, Carpio, Puga, & Sotelo-Figueroa, 2013; Soria-Alcaraz Jorge, Carpio, Puga, Terashima-Marin, et al., 2013) (methodology of design) is used here to represent the course timetabling instances and their constraints. This methodology allows different types of course timetabling policies and constraints to be modelled by converting all time and space constraints into a single constraint type: student conflicts.The ability to model across different institutions and formulations is achieved by translating the original timetable instance data into a set of generic data structures which are later used by the hyper-heuristic. Specifically, the information is integrated into three data structures: (i) subject-subject matrix (MMA), (ii) list of possible timeslots (LPH) and (iii) list of possible classrooms (LPA). As described in (Soria-Alcaraz Jorge, Carpio, Puga, & Sotelo-Figueroa, 2013; Soria-Alcaraz Jorge, Carpio, Puga, Terashima-Marin, et al., 2013), an important advantage of this methodology is that the generic structures facilitate the construction of feasible solutions. The subject-subject matrix contains the number of students in conflict for a given pair of subjects, i.e. the number of students who are enrolled in a given pair of subjects. The LPH list contains the allowed timeslots for the corresponding subject. The LPA list contains the classrooms available to be assigned to each subject without conflict.These structures are then used to construct timetables. An important advantage of this methodology is that the generic structures facilitate the construction of feasible solutions. Specifically, the Cartesian product of lists LPH (timeslots) and LPA (classrooms) is constructed as shown in Fig. 1. A timetable is encoded as a vector of length equal to the number of subjects, in which positions indicate subjects. The integer values in the vector are indices representing a pair(LPHi,LPAi), whereLPHiis a valid timeslot for the subject i andLPAiis a valid classroom for the subject i. This vector represents a complete timetable assignment. In this formulation, the search space is then given by the Cartesian productLPHi×LPAi, and the objective is to reduce the total number of student conflicts. Table 1gives information about the problem instances considered.Hyper-heuristics search the space of heuristics rather than that of solutions, and use limited problem specific information to control the search process. The problem specific information is encapsulated into the problem model and a pool of low-level heuristics or search operators.The proposed hyper-heuristic strategy can be seen as an adaptive version of the iterated local search strategy combining several move operators. Iterated local search is a relatively simple yet powerful strategy. It operates by iteratively alternating between applying a move operator to the incumbent solution (perturbation stage) and restarting local search from the perturbed solution (improvement stage). This search principle has been rediscovered multiple times, within different research communities and with different names (Battiti, Brunato, & Mascia, 2007). The term iterated local search (ILS) was proposed in (Lourenço, Martin, & Stützle, 2003).A number of adaptive variants of multi-neighborhood iterated local search have been recently proposed (Ochoa, Walker, et al., 2012; Walker et al., 2012) with encouraging results in other problem domains. If several options are available for conducting perturbation and improvement, a mechanism needs to be provided to choose between them. The idea is to use online learning to adaptively select the operators either at the perturbation stage or the improvement stage; or both. These approaches inspired the algorithm implemented in this article, which can be seen in Algorithms 1 and 2. In this implementation, the perturbation stage (step 4 in Algorithm 1) applies a single fixed move operator to the incumbent solution. This move operator (Simple Random Perturbation – SRP) simply selects uniformly at random a single variable and substitutes it for another variable in the range selected uniformly at random.Online learning is then applied to the improvement stage (Algorithm 2), in which a low-level heuristic from the pool is selected and applied to the incumbent solution (steps 3 and 4). This operator selection step uses learned probabilities to conduct the selection. The process of learning the operator probabilities is conducted using online (dynamic) and offline (static) schemes as detailed below. Throughout this article we use the terms ‘operator’, ‘heuristic’ and ‘low-level heuristic’ interchangeably.The next subsection describes the mechanisms for adaptively operator selection. Section 3.2, describes how to statically tune operator selection probabilities. Finally, Section 3.3 lists and describes the set of heuristics (operators) considered in our implementation.Algorithm 1High Level Iterated Local Search (ILS)1:s0=GenerateInitialSolution2:s∗=ImprovementStage(s0)3: while!StopCriteria()do4:s′=SimpleRandomPerturbation(s∗)5:s∗′=ImprovementStage(s′)6:iff(s∗′)<f(s∗)then7:s∗=s∗′8:end if9: end while10: returns∗Improvement Stage1:ls←IncumbentSolution2: while!LocalStopCriteria()do3:hi=SelectHeuristic()4:ls∗=apply(hi,ls)5:iff(ls∗)<f(ls)then6:ls=ls∗′7:end if8: end while9: returnlsAn adaptive operator selection scheme consists of two components: (i) a credit assignment mechanism, which associates a reward with each operator, modeling its predicted utility and (ii) a selection rule, which determines the operator to be used at each time step, as a function of reward. We detail these below.We implemented the extreme value credit assignment, which is based on the principle that large (but possibly infrequent) improvements in the objective score are likely to be more effective than small frequent improvements (Fialho, Da Costa, Schoenauer, & Sebag, 2008). It rewards operators which have had a recent large positive impact on the objective score, while consistent operators yielding only small improvements receive less reward. Rewards are updated as follows, when a heuristic h is selected, it is applied to the current solution. The fitness of this new solution is computed and the change in fitness is added to a FIFO list of size W. This list is unique and common for all operators. Thereafter, the operator reward is updated to the maximal fitness improvement in the list. More formally, if t be the current step andδ(t)the fitness improvement observed at time t, then the expected reward for heuristic h is computed as follows (Eq. (1)):(1)rˆt=argmax{δ(ti),i=1…W}As seen in Eq. (1), the extreme value mechanism requires a regulatory integer parameter W, the window size. If W is too small, the range of information on offer is narrowed, meaning that useful operators are missed. If it is too large, information considered may be from many iterations ago and hence no longer be relevant.Operator selection rules typically associate probabilities with operators via proportional selection. Let K denote the number of operators (low-level heuristics). The selection mechanisms maintain a probability vector(pi,t)i=1,…,K, and an estimate of the current operator credit denoted asqˆi,t. At each iteration time t:•Operator i is selected with probabilitypi,t, according to a roulette-wheel selection scheme.The selected operator is applied, and a creditrtis computed using the credit assignment mechanism (extreme-value in our implementation).The quality estimateqˆi,tof the selected operator is updated according to the rewardrt, using an additive relaxation mechanism with learning rateα(0<α⩽1). The learning rate controls the memory of the quality estimate. Specifically, the memory span decreases with increasingα, as indicated by Eq. (2).(2)qˆi,t+1=(1-α)×qˆi,t+α×rtProbability Matching corresponds to the standard roulette wheel selection. The goal is to makepi,tproportional toqˆi,t. An operator that performs very badly during a long period of the search will have its quality estimate decreased to a very low value, or even zero. To avoid such operators being completely ignored, the selection rules normally assign a minimal selection probabilitypmin>0. Eq. (3) describes the PM rule:(3)pi,t+1=pmin+(1-K∗pmin)qˆi,t+1∑j=1Kqˆj,t+1In contrast, Adaptive Pursuit follows a winner-take-all strategy, selecting at each step the operatorit∗with maximal reward, and increasing its selection probability accordingly. Eqs. (4)–(6) describes this mechanism:(4)i∗=argmax{qˆi,t,i=1…K}(5)pi∗,t+1=pi∗,t+β(1-(K-1)pmin-pi∗,t),(β>0)(6)pi,t+1=pi,t+β(pmin-pi,t),fori≠i∗As discussed above, adaptive operator selection mechanisms introduce new parameter values. The values used in our hyper-heuristic implementation are reported in Section 4.2, specifically, in Table 4. They were selected after some preliminary experiments.The previous section discussed mechanisms for dynamically adapting the operators selection probabilities. These probabilities can alternatively be considered as fixed (static) parameters of the ILS hyper-heuristic algorithm that can then be automatically tuned. Operators are then selected by a roulette-wheel mechanism based on these statically-tuned probabilities. Several frameworks have been proposed in the literature for automated parameter tuning and algorithm configuration (Nannen & Eiben, 2006; Birattari, 2009; Hutter, Hoos, Leyton-Brown, & Stützle, 2009). We use here ParamILS, a framework for automated algorithm configuration achieved via a local search in the configuration space. The key idea behind ParamILS is to combine a stochastic local search algorithm (iterated local search) with mechanisms for exploiting specific properties of algorithm configuration. The search process starts from a given configuration (which is generally the target algorithm’s default configuration) as well as r additional configurations chosen uniformly at random from the given discrete ranges of the configuration parameters. Theser+1initial configurations are evaluated, and the best performing is selected as the starting point of the ILS. To evaluate a configuration, the idea is to perform a fixed number of runs of the target algorithm with the given configuration on the set of training instances. The process proceeds with the iterated local search strategy, using the one-exchange neighborhood (i.e.inducing an arbitrary change in a single target algorithm parameter) in the improvement stage, and a number of steps s of the same neighborhood as the perturbation stage. Small values of s (i.e.s=2) have been found to be sufficient for obtaining good performance of the overall configuration procedure (Hoos, 2012, chap. 3). In Hutter et al.(Hutter et al., 2009), extensive evidence is presented that ParamILS can find substantially improved parameter configurations of complex and highly optimized algorithms.Section 4.2 (specifically, Table 5) reports the values obtained after tuning operator selection probabilities, using ParamILS, in our hyper-heuristic implementation.A pool of 9 low-level heuristics were implemented. These range from simple randomized exchange or swap neighborhoods to greedy and more informed procedures. We proposed two novel operators, Statistical Dynamic and Double Dynamic perturbations, which consider a probability distribution based on the frequency of variables selection.1.Simple Random Perturbation (SRP): uniformly at random chooses a variable i and changes its value for another one inside its feasible domainLPHi×LPAi(selected uniformly at random).Best Single Perturbation (BSP): chooses a variable following a sequential order (according to the Cartesian productLPH×LPA) and changes its value to that producing the minimum conflict. A record is kept of the last selected variable, so the order is continued when the heuristic is called again.Statistical Dynamic Perturbation (SDP): chooses a variable following a probability distribution based on the frequency of variable selection in the last k iterations. Variables with lower frequency will have a higher probability of being selected. Once selected, the value is randomly changed. This heuristic is an original contribution of this article. Algorithm 3 describes the pseudo-code.Double Dynamic Perturbation (DDP): similar to heuristic SDP, in that it receives an input solution and selects a new variable with a probability inversely proportional to its frequency of selection in the last k iterations. It differs from SDP in that it internally maintains an additional solution (which is copy of the first initialized solution) and makes random changes to it following the same distribution. The best of the two modified solutions is returned. This heuristic is an original contribution of this article. Algorithm 4 describes the pseudo-code.Swap (SWP): selects two variables uniformly at random and interchanges their values if possible. Otherwise leaves the solution unchanged.Two Points Perturbation (2PP): selects uniformly at random two indices in the integer string representation and modifies all variables between the indices with randomly selected feasible values. This yields a strong perturbation.Move to Less Conflict (MLC): locates the variable producing the most conflicts and changes its value to the that causing the minimum possible conflict. In other words, it applies the Best Fit principle.Burke-Abdullah (BA): hybrid heuristic that chooses a variable by means of either Fail-First (FF) or Brelaz Heuristic (BZ) (Gent, MacIntyre, Presser, Smith, & Walsh, 1996) and then changes its value according the best possible solution obtained by the following 4 algorithms: Sequential selection, Least Constrained Value, Randomly or Minimum Conflict. (Abdullah, Burke, & McCollum, 2007)Conant-Pablos (LSA): hybrid heuristic that randomly selects a variable with hard constraint conflicts and changes it by a feasible value selected using either the Minimum Constraint or Least Constrained Value (Gent et al., 1996) heuristics (Conant-Pablos et al., 2009).Statistical Dynamic Perturbation (SDP)Require:Solution,K,HistoryList(K),Frequency[Solution.NumOfVars]1:Solutionnew=Copy(Solution)2:UpdateFrequency(HistoryList,Frequency)3:Selectiont=SelectVariableWithDistribution(Frequency)4: ifHistoryList.getRecorderSteps()>=Kthen5:HistoryList.remove(Step0)6: end if7:HistoryList.add(Selectiont)8:AssignRandomlyValue(Selectiont,Solutionnew)9:t=t+110:Return(Solutionnew)Double Dynamic Perturbation (DDP)Require:InnerSolution,Solution,K,HistoryList(K),Frequency[Solution.NumOfVars]1: ift==0then2:InnerSolution=Copy(Solution)3: end if4:Solutionnew=Copy(Solution)5:UpdateFrequency(HistoryList,Frequency)6:Selectiont=SelectVariableWithDistribution(Frequency)7: ifHistoryList.getRecorderSteps()>=Kthen8:HistoryList.remove(Step0)9: end if10:HistoryList.add(Selectiont)11:AssignRandomlyValue(Selectiont,Solutionnew)12:AssignRandomlyValue(Selectiont,InnerSolution)13:t=t+114: ifEvaluation(InnerSolution)<=Evaluation(Solutionnew)then15:Solutionnew=Copy(InnerSolution)16: end if17:Return(Solutionnew)The choice of heuristics for the pool is somewhat arbitrary and reflects our knowledge of the representation and the problem. Since there is no fixed procedure in the literature for guiding the selection of the best set of heuristics for a given representation and problem, choices are generally based on empirical evidence. In order to refine our initial choice of operators, we propose a single test procedure described in detail in Section 4.1.

@&#CONCLUSIONS@&#
The main contribution of this article is a highly-automated approach to course timetabling, obtained by combining a generic modeling approach with an adaptive search methodology incorporating learning mechanisms and effective move operators. The approach is simultaneously general and effective; general, in that different types of course timetabling policies and constraints can be modeled; effective, in that a number of move operators of different characteristics and strengths are combined into an adaptive hyper-heuristic approach, producing state-of-the art results.The proposed hyper-heuristic approach is based on the simple yet powerful iterated local search principle, which alternates between improving and perturbation stages. Adaptability is achieved by incorporating learning mechanisms (also called adaptive operator selection) to learn and apply alternative move operators in the improvement stage, selected from the available pool according to their past performance. The methodology also benefits from novel effective move operators, and an empirical approach for selecting the best performing operators from a larger available pool.Several learning mechanisms, including online (dynamic) and offline (static) approaches, were implemented and tested. The best performing mechanism resulted an online mechanism that combines extreme value credit assignment with an adaptive pursuit selection rule. This best-performing hyper-heuristic produced competitive results as compared to the state-of-the-art on the 2007 International Timetabling Competition instances, even producing a new best-known solution.An analysis of the learned probabilities and selection frequency of the operators in the pool reveals that different instances have different operator profiles. It is clearly demonstrated that operators cooperate and complement each other in the process of effectively solving an instance. There is no single best operator across the search process: some operators dominate at certain stages while others take over at different stages. This justifies and confirms the advantages of using online adaptive mechanisms. While there is no clear pattern across all instances, in general operators exhibiting higher degrees of randomness are preferentially selected at the early stages of the search. This is consistent with the expectation that at early stages, the search should be more explorative.Future work will explore more sophisticated online learning mechanism, and will implement additional move operators. Population-based adaptive approaches will also be implemented and tested. Understanding and matching the effectiveness of particular move operators to particular instances and stages of the search process is an open area that requires further investigation. Finally, since the proposed adaptive high-level strategy operates in a domain-independent manner, it can be easily adapted to other timetabling, scheduling and routing problems subject to available problem-specific models and operators.