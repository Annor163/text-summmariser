@&#MAIN-TITLE@&#
Exploratory failure time analysis in large scale genomics

@&#HIGHLIGHTS@&#
A novel procedure called Correlation Profile Test (CPT) is proposed.A novel permutation test, the hybrid permutation test, is proposed.CPT fits genomics applications better than common survival analysis methods.CPT is general and can have wide applications beyond genomics.

@&#KEYPHRASES@&#
Censored failure time data,Exploratory analysis,Failure event point process,Stochastically monotone dependence,Correlation Profile Test,Hybrid permutation test,Large scale genomic analysis,GWAS,Genotype–phenotype association,

@&#ABSTRACT@&#
In large scale genomic analyses dealing with detecting genotype–phenotype associations, such as genome wide association studies (GWAS), it is desirable to have numerically and statistically robust procedures to test the stochastic independence null hypothesis against certain alternatives. Motivated by a special case in a GWAS, a novel test procedure called Correlation Profile Test (CPT) is developed for testing genomic associations with failure-time phenotypes subject to right censoring and competing risks. Performance and operating characteristics of CPT are investigated and compared to existing approaches, by a simulation study and on a real dataset. Compared to popular choices of semiparametric and nonparametric methods, CPT has three advantages: it is numerically more robust because it solely relies on sample moments; it is more robust against the violation of the proportional hazards condition; and it is more flexible in handling various failure and censoring scenarios. CPT is a general approach to testing the null hypothesis of stochastic independence between a failure event point process and any random variable; thus it is widely applicable beyond genomic studies.

@&#INTRODUCTION@&#
The advance of high throughput genotyping assays has allowed biomedical researchers to obtain genome-wide the genotypes of hundreds of thousands single nucleotide polymorphisms (SNPs) in a large number of individuals, and have provided unprecedented opportunities to identify new genetic variations underlying various phenotypes of interest, by genome-wide association study (GWAS). Common methods to test genotype–phenotype association include parametric and nonparametric models and tests, such as linear regression, Pearson’s Chi-square test, Kruskal–Wallis test, Cochran–Armitage trend test, etc., depending on the experimental design and the data type of the phenotype. Phenotypes of failure times subject to right censoring are often analyzed in cancer clinical GWAS. For this kind of phenotype semi-parametric hazard rate regression models (Cox, 1972; Kalbfleisch and Prentice, 2002, Chapter 4–6 and Fine and Gray, 1999) or accelerated failure time models (Buckley and James, 1979; Wei et al., 1990; Lin and Geyer, 1992; Lin et al., 1998) are possible choices. Motivated by a phenomenon encountered in a GWAS described below, this paper presents a novel approach called Correlation Profile Test (CPT).A motivating example. In a GWAS of long-term treatment outcome of childhood leukemia with relapse as a cause-specific end point (detailed description in Section  4), we encountered a SNP for which all failures (relapses) and competing events occurred only in the individuals with the wild type genotype AA. The total sample sizen=707(8 had genotype value missing), with 679 wild type (AA), 11 heterozygous (AB), and 9 homozygous mutant (BB) individuals. The three genotypes AA, AB, BB were coded into ordinal values as 0, 1, 2 respectively. The 8 individuals with missing genotype values had no events, and were removed from analysis. The total number of failures (relapse) was 70; 24 individuals had competing events, and 605 were censored. Individuals who had events are all wild type (AA). Traditional Cox regression with genotype as the explanatory variable could not produce a reliable estimate of the coefficient because iterations for the maximum pseudolikelihood estimation did not converge properly; whereas Fine and Gray (1999) regression modeling of the hazard rate function of the time to relapse subdistribution produced a highly significant result: coefficient estimate −11.36, standard error 0.33, two-sidedPvalue 0. On the other hand Gray’s (1988) test comparing cumulative incidence functions of relapse across the three genotypes is not significant:P=0.35.The goal of GWAS is not to model precisely the hazard rate of the failure-time phenotype as a function of SNPs, but rather to identify SNPs on which the phenotype is stochastically dependent. Currently this goal can be partially fulfilled by testing the coefficients in a hazard rate regression model, or a nonparametric test derived from hazard function estimators. Despite representing an extreme case, the above example does prompt the need in GWAS-type applications for a more general stochastic dependence test procedure that is robust in computation and maintains performance when the assumptions required for hazard rate regression modeling fail to hold. On this account, completely nonparametric omnibus tests (Fleming and Harrington, 1991, Chapter 7; Gray, 1988) are preferable. On the other hand in vast majority of GWAS applications, genotypes are regarded as ordinal variables, and it is often desirable to test the independence (“no association”) null hypothesis against the “additive”, “dominate” or “recessive” genetic effect alternatives, which is a stochastically monotone alternative (detailed in Section  2.1). It would be then compelling to develop test procedures specifically targeting the stochastically monotone alternative hypotheses. Additionally, there are often applications in which the phenotype measures repeated failures (e.g., multiple episodes of certain toxicity caused by chemotherapy), or the censoring mechanisms are mixed or informative (detailed in Section  5). The existing nonparametric procedures do not fit naturally in these scenarios.Correlation Profile Test (CPT) is developed to address the above issues. Briefly, each subject’s survival course is regarded as a point process on[0,∞)which increases by 1 at each failure time—the “event point process” (Kalbfleisch and Prentice, 2002, Chapter 5). The survival data in a sample of sizenconsist ofnobserved point processes, some of which are only partially observed up to the censoring time. Suppose a covariate variable (a SNP) is also observed on each subject in the sample and it is desired to test the null hypothesis that failure time and the covariate are stochastically independent. CPT aggregates the correlations between the covariate and the event point process at a finite number of properly placed time points into a test statistic. Statistical significance is determined by a novel procedure called hybrid permutation test that combines the asymptotic null distribution of the test statistic and permutations. Analytical insights and a simulation study show that compared to the popular methods CPT maintains nominal significance levels well, and outperforms the existing methods when the condition of proportional hazards does not hold. In exact or near proportional-hazards scenarios, CPT suffers some efficiency loss compared to existing methods that are sensitive to differences in hazard rates. Moreover, CPT is a very flexible procedure that can be easily extended to various failure time scenarios more complex than traditional survival data, by properly modifying the construction of the event point process.Definitions, construction of the CPT statistic, hybrid permutation test, and stratified CPT are described in Section  2. A simulation study and some discussions are given in Section  3. A genomic application, along with a comparison of CPT to other methods on a real dataset, is presented and discussed in Section  4. Extensions of CPT to several non-traditional failure time scenarios are described and discussed in Section  5. Additional discussions and concluding remarks are made in Section  6.First consider the classical survival case; extensions are discussed in Section  5. Suppose each individual in the population possesses a time to failure (event time)TE∼FEand a censoring timeTC∼FC, withTEandTCindependent of each other. Only observable are the timeY=min(TE,TC)and the event indicatorδ=I(TE≤TC). For ease of development consider equivalently the event point processN≔{N(t)=I(TE≤t),t∈[0,∞)}, which is observable till the timeYifδ=0. LetX∼FXbe an explanatory (factor) variable, which can be continuous, ordinal, or binary. The observable is the triplet(Y,δ,X). Precisely speaking, exploratory failure time analysis deals with testing the null hypothesisH0:Nis independent ofX,versus various alternatives. Different types of alternatives can be targeted by various constructions of the CPT statistic. The type of alternatives of interest most often in practice is the stochastically monotone alternative whenXis continuous or ordinal:Nis stochastically increase inXif for anyx1<x2the conditional distribution ofN(t)givenX=x2is stochastically greater than or equal to the conditional distribution ofN(t)givenX=x1, for allt∈[0,∞), and strict stochastic order holds for at least one pair of distinctXvalues. This type of stochastic monotonicity includes the dominate and recessive effects in genomic applications: for example the conditional distributions ofN(t)givenX=0andX=1are stochastically equal, and is stochastically greater givenX=2—this defines the recessive pattern. A CPT statistic targeting stochastically monotone alternative hypotheses can be constructed through the correlation profile functionρ(t)≔Corr(N(t),X),t∈[0,∞).A random sample of sizenconsists of(Yi,δi,Xi),i=1,…,n, i.i.d. random vectors. For theith individual, define the observed event point process as (NAdenotes unobserved/missing value)(1)Ni(t)≔{0ifδi=1andt<Yi1ifδi=1andt≥Yi0ifδi=0andt≤YiNAifδi=0andt>Yi,t∈[0,∞). LetIE(t)≔{i:Ni(t)=1,i=1,…,n}be the index of individuals who have failed before or at timet, letIR(t)≔{i:Ni(t)=0,i=1,…,n}be the index of individuals who are still at-risk at timet, letI(t)≔IE(t)∪IR(t), and let|I(t)|be the number of elements inI(t). Then defineN¯(t)≔|I(t)|−1∑i∈I(t)Ni(t),X¯(t)≔|I(t)|−1∑i∈I(t)Xi, and define the sample correlation profile function(2)ρ˜n(t)≔∑i∈I(t)(Ni(t)−N¯(t))(Xi−X¯(t))∑i∈I(t)(Ni(t)−N¯(t))2∑i∈I(t)(Xi−X¯(t))2.Fix a relatively small integerJ(sayJ=9), and lettjbe thejJ+1th sample quantile of all observed failure times (j=1,…,J). The sequence{tj,j=1,…,J}will be referred as time-sampling points. The CPT statistic is defined as(3)Sn≔1J∑j=1Jρ˜n(tj).Note the time sampling points{tj,j=1,…,J}are placed adaptively by taking the sample quantiles of the unconditional (marginal) empirical distribution of the failure times (Yi’s withδi=1, fori=1,…,n), not involvingX. If beyond sometJ′withJ′<Jthere is no longer any individual at risk, then the above sum just runs throughj=1,…,J′. In practice the summation can be stopped even earlier, at aJ′such that the number of individuals still at risk is≤n′(sayn′=3).A broader spectrum of stochastic monotone relationship can be tested by replacingXifori∈I(t)in the sample correlation profile function with its (average) rankRi, and replacingX¯(t)withR¯(t)≔|I(t)|−1∑i∈I(t)Ri. Notably, if there are consistent positive (negative) sample correlations at the vast majority of the time-sampling pointstj(j=1,…,J),Sntends to have a large magnitude; this test statistic is thus sensitive to the stochastic monotone alternatives. The asymptotic null distribution ofSnand a test procedure called hybrid permutation test will be derived in Section  2.2.Some insights into this Pearson’s correlation approach can be seen by examining the covarianceCov(N(t),X). For this purpose we take the constructive definition of a finite point process (Daley and Vere-Jones, 1988, P. 121). LetDbe a Bernoulli random variable indicating if an individual ever fail (D=1), and assumeDfollows the Bernoulli(π(X)) distribution givenX. LetFE(t|X)≔Pr(TE≤t|D=1,X),t∈[0,∞)be the conditional cdf of the failure timeTEgivenXandD=1,I(⋅)be the indicator function, andRbe the real line. ThenN(t)=DI(TE≤t),E[N(t)]=Pr(DI(TE≤t)=1)=∫Rπ(x)FE(t|x)dFX(x), andE[N(t)X]=∫Rxπ(x)FE(t|x)dFX(x); together giving(4)Cov(N(t),X)=∫Rπ(x)FE(t|x)(x−μX)dFX(x).Notably this covariance (consequentlyρ(t)) is large in magnitude ifCov(π(X)FE(t|X),X)is large in magnitude, and CPT is sensitive to this type of dependence structure. Two special cases are: (a)Dis independent ofX; hence the overall failure probabilityπis free ofx. CPT will be sensitive if the conditional cdfFE(t|X)is highly correlated withXfor everyt. (b)TEis independent ofX; CPT will be sensitive ifπ(X)is highly correlated withX. In this case using a nonlinear monotone transformation onX(such asexp(X)1+exp(X)) may help the power. To contrast with other failure time methods, it is instructive to consider the conditional sub-distribution function of the time to failure defined by the conditional probability that the individual fails before or at timetgivenX, namely,F1(t|X)≔Pr(N(t)=1|X)=Pr(TE≤t,D=1|X)=π(X)FE(t|X). This sub-distribution has the hazard rate functionλ1(t|X)=π(X)fE(t|X)1−π(X)FE(t|X), withfE(t|X)=dFE(t|X)/dt. Case (b) implies thatλ1(t|X)=π(X)fE(t)1−π(X)FE(t), which is very similar to the proportional hazards formλ∗(t|X)=π(X)fE(t)1−FE(t)with the baseline hazard rate functionfE(t)1−FE(t). In factλ∗(t|X)is an upper bound ofλ1(t|X)for everyt∈[0,∞). Therefore this type of association (alternative hypothesis) favors the procedures mainly based on semi-parametric models of the hazard rate function, and CPT may not be as efficient. Notably in the traditional survival analysis setting it is assumed implicitly thatπ(X)≡1(every subject dies eventually); by the point process formulation adopted herein it can be seen that hazard rate regression can be more sensitive than CPT if the failure probability depends on but the time to failure is free of the covariateX. Case (a) on the other hand givesλ1(t|X)=πfE(t|X)1−πFE(t|X), which strongly deviates from the proportional hazards structure. Hence in this case hazard rate function regression methods may not be as efficient as CPT. These qualitative properties are specifically demonstrated by the simulation results (Tables 1 and 2, Section  3): CPT is sensitive to case (a), but not to case (b) particularly when it is difficult to captureπ(X)by a linear model. Notably, the conditional sub-distribution functionF1(⋅|X)is essentially the leading term of a mixture cure model; so in case (b) incorporation of certain cure model approach may help increase the power (for example Laska and Meisner, 1992 for discreteX); this is a point worthy of future investigation.Presence of a competing risk. In certain applications, in addition to censoring, a competing risk is an end-point event whose occurrence prevents further observation (follow up) on the individual (Gray, 1988). In such case the event indicator is typically coded asδi={0censored1failure of interest2competing event .The regular censoring indicated byδ=0represents the “administrative censor” (Gray, 1988). Because the interest here is not to estimate the cumulative incidence of each failure type, for the purpose of testing stochastic dependence the competing eventδ=2can be regarded merely as an additional censoring mechanism. The modification to the observed event point process is simply to replace in the conditionδi=0byδi≠1in Eq. (1).For either the classical survival or the multiple failure case (see Section  5), the asymptotic distribution of the test statisticSnunder the independence null hypothesis is established by the following theorem; the proof is given in the Appendix.TheoremAssume that  (a)  the proportion of at-risk individualsλn(tj)in computingρ˜n(tj)is bounded almost surely from below by somep0>0for eachnand eachj=1,…,J′≤J, and  (b)  the second moment ofXexists,E(X2)<∞. Under the independence null hypothesis, the CPT statisticSnis asymptotically normal with zero mean and asymptotic varianceτn2, i.e.,Snτn⟹N(0,1),n⟶∞,whereτn=τn(FE,FC,FX,J)(n=1,2,…)is a sequence depending on the underlying event time distributions andJ. Moreover,τn2=O(n−1),n⟶∞.Utilizing this result, the basic idea of the hybrid permutation test is to estimate the asymptotic standard deviationτnby permutation and then plug it into a z-test: Randomly permute the covariateXi(i=1,…,n)values; computeSnaccording to Eqs. (2) and (3) using the permuted data; repeatB(a few hundred) times to obtain simulated observations ofSnunderH0:Sn,1′,…,Sn,B′. The statistical significance of the observed test statisticSn,obsis given by, for a two-sided test,P=2{1−Φ(|Sn,obs/τ̂n|)}, whereτ̂nis the sample standard deviation of the simulated observations{Sn,1′,…,Sn,B′}, andΦ(⋅)is theN(0,1)cdf. Although the asymptotic mean is zero, there can be finite sample bias; thus it is recommended to use(Sn,obs−μ̂n)/τ̂ninstead, withμ̂nthe sample mean ofSn,1′,…,Sn,B′.In a large-scale genomics application a massive number of such test is performed. A slightly conservative test to help reduce the number of false positive hits is to replaceΦ(⋅)by the cdf of the Studenttdistribution withB−1degrees of freedom in thePvalue calculation. WhenBis on the order of 102 this modification does not make much difference at the customary 0.05 or 0.01 level, but can be appreciably different fromN(0,1)at the extreme tails (say 10−6 and beyond).Back to the motivating example described in Introduction, the CPTPvalue of the test usingSnin Eq. (3) is 0.2956 from hybrid permutation (200 rounds) andN(0,1)approximation, giving the same conclusion as Gray’s test.The CPT presented above targets the stochastic monotone alternative hypothesis. Although in genomic applications monotone alternatives are the easiest to interpret biologically, another class of alternatives that might be of interested is that the genetic effect switches direction during the survival course. For example, the event point processNis stochastically increasing inXin a time interval[0,T](Tcan be either deterministic or random), then becomes stochastically decreasing inXin(T,∞). A modification on the CPT test statistic in Eq. (3) to target this type of alternative is to take the average of the absolute values of the correlation coefficients:(5)Sn;Beta≔1J∑j=1J|ρ˜n(tj)|.Heuristically, because under the null hypothesis eachρ˜n(tj)follows a unimodal symmetric distribution on the interval[−1,1], the distribution ofSn;Betawhich is an average of the absolute values of several such random variables, can be approximated by a unimodal distribution on the interval[0,1]under the null hypothesis. Recently Ji et al. (2005) use mixtures of Beta distributions to model a set of sample correlations. Borrowing their idea, a hybrid permutation test can be constructed based on aBeta(a,b)distribution approximation to the null distribution ofSn;Beta. Letμ̂nandτ̂nbe the sample mean and standard deviation of the simulated observations ofSn;Betaunder the null hypothesis obtained by permutation runs as described earlier. Method of moments estimators of the Beta distribution parameters areâ=μ̂nĉandb̂=ĉ−â, whereĉ=μ̂n(1−μ̂n)/τ̂n−1. In practice a boundary control should be added by settingâ=max(μ̂nĉ,ϵ)andb̂=max(ĉ−â,ϵ), withϵa small positive fraction (e.g. 10−5). This approach will be shown to work well by the simulation study in Section  3.Often in a study cohort there are well-defined strata (subgroups) across which the failure time may follow different distributions. In this case it is necessary to adjust the test of the stochastic independence null hypothesis for the stratum effect; one approach is to perform a stratified test.A simple stratified test can be constructed as follows. Use a common numberJ, generate separately in each stratum the set of time-sampling points{tj,j=1,…,J}and compute the CPT statistic as descried in Eq. (3). LetSkbe the CPT statistic for thekth stratum (k=1,…,K). Letμ̂kandτ̂kbe the permutation-estimated asymptotic null mean and standard deviation ofSkas described above, where permutations are performed within each stratum separately and independently. A stratified CPT test statistic is(6)S=∑k=1K(Sk−μ̂k)∑k=1Kτ̂k2.Under the independence null hypothesis,Sapproximately followsN(0,1); thus aPvalue can be computed asP=2(1−Φ(|S|)). More conservatively,Φ(⋅)can be replaced by the cdf of the Studenttdistribution withBK−Kdegrees of freedom, withBthe common number of permutations used to compute eachSk. Notably, this test will have good power if there is high homogeneity, that is, the directions of theN-Xstochastic monotone relationship are the same in (almost) all strata, so that most of(Sk−μ̂k)(k=1,…,K)have the same sign and large magnitude.Alternatively a stratified test statistic sensitive to stochastic monotonicity regardless direction in each stratum is(7)Sq=∑k=1K(Sk−μ̂kτ̂k)2,which follows approximately the Chi-square distribution withKdegrees of freedom under the null hypothesis.A test along the line of meta-analysis can be considered as well, using Fisher’s transformation. LetPkbe the CPTPvalue computed from the hybrid permutation test on stratumk, and defineSp=−∑k=1Klog(Pk). Then under the null hypothesisSpapproximately follows theGamma(K,1)distribution. This approach can be applied to perform stratified test using theSn;Betastatistic defined in Eq. (5).Here for simplicity a common numberJacross all strata is used for the time sampling points in the construction. In practice it is conceivable that one can simply use the order statistics of all observed failure times in the stratum as time-sampling points forSk(or in unstratified test forSnin Eq. (3)); the asymptotic normality may still hold. If the minimum size of the setIR(t)is set ton′(say=3) for all strata, then depending on the censoring pattern in different strata, the truncation pointJ′may vary from stratum to stratum. Adaptive determination ofJ(orJ′andn′) in stratified or unstratified tests remains an open problem at this point. The simulation study and the real data example indicate that settingJ=9works well in a wide spectrum of scenarios.Because CPT is a completely nonparametric, moment-based test, it is expected that under the exact proportional hazard model, Cox regression model will perform better. On the other hand CPT does not assume any model form for the failure time, one thus expects it to perform better than the hazard rate function regression models when there is a deviation from the proportional hazards model. Some analytical insights along this line have been discussed following Eq. (4). In this simulation study the performances of unstratified CPT (Eq. (3)) and the more general CPT (Eq. (5); referred as CPT.Beta henceforth) are compared with those of Cox regression, Fine–Gray regression, and Gray’s test. Four scenarios of different combinations of the failure time models and a single ordinal covariateX(taking values 0, 1, 2) are considered. With large-scale genomics applications in mind, type-I error level and power of the assessed procedures are estimated at the 0.005 nominal significance levels in all cases. One thousand (1000) simulations are run to estimate power under alternative hypotheses and 10,000 simulations are run to estimate the type-I error probabilities. All simulations are done using R. Cox regression, Fine–Gray regression and Gray’s test are computed using the R functions coxph, crr and cuminc, respectively.Pvalues of CPT and CPT.Beta are computed by the hybrid permutation procedure using 200 permutations andN(0,1)and Beta approximations respectively, as described in Section  2. In all cases the number of time-sampling points is setJ=9.The ordinal covariateXtakes values 0, 1, 2 with respective probability 0.1, 0.4, 0.5. The censoring timeTC∼Exp(0.2). An observation of the failure event point process is simulated by two steps. First conditional onXa Bernoulli observationDis drawn according to the probabilityπ(X)≔Pr(Fail|X)=0.2exp(−θ(X−2)),θ≥0. Next ifD=1then the event point processN(⋅)has a single jump at the timeTEsuch that givenXandD=1,[TE|(X,D=1)]∼Lognormal(βX,1),β≥0; otherwiseN(⋅)remains constantly 0. An observation of the competing risk point processNR(⋅)is generated in the same way with different parameters:DR∼Bernoulli(0.1),NR(⋅)has a single jump of 1 atTRwith[TR|DR=1]∼U(0,7)ifDR=1; otherwiseNR(t)=0for allt≥0.In this case lower values ofXare less frequent in the population, yet individuals with lower values ofXare more likely to fail ifθ>0, and tend to fail more quickly ifβ>0. The null hypothesis corresponds toθ=β=0. Observed power and significance level are given for sample sizesn=200 and 700 in Table 1. All procedures can hold the nominal significance levels fairly well although CPT.Beta is slightly liberal. FG and Gray’s tests are slightly liberal only at the smaller sample sizen=200. Whenβ>0, a case deviating from proportional hazards, CPT uniformly outperforms the other procedures. Whenθ>0andβ=0(a near proportional-hazards case), CPT suffers some efficiency loss. At(θ,β)=(0.5,0)andn=400, the power of CPT and CPT.Beta is 0.57 and 0.63 respectively, which is a level comparable to the other methods atn=200. The performance pattern observed here can be understood by the discussion following Eq. (4) in Section  2: Whenθ>0andβ=0, the power comes from onlyCov(π(X),X)which is relatively low for this model; yet at the same time this type of alternatives has the hazard rate function in the form favoring the methods based on hazard rate function regression modeling. Notably all procedures have rather low power for small effect sizes (θ=0.25,β=0). Whenβ>0a substantial amount of power comes fromCov(FE(t|X),X)which is fairly high for the Lognormal model; and substantial deviations from the proportional hazards structure make the hazard rate regression methods less efficient.In the second case,Xtakes values 0, 1, 2 with respective probability 0.98, 0.015, 0.005; all the other parameters are the same as in Case 1. Note in this case higher values ofXis extremely rare in the population, yet individuals with higherXare less likely to fail (ifθ>0) and tend to have longer time to failure ifβ>0. This mimics the situation of the motivating example in Introduction. As shown in Table 2, it is clear that, after balancing the trade-off between type-I error probability and power, CPT and CPT.Beta performs better than the other methods. Notably, the same as in Case 1, all procedures have low power for small effect sizes (θ=0.25,β=0).Here a recessive effect relatively difficult to detect is considered. The distribution ofX,TCand the competing risk point process are the same as in Case 2. GivenX,Pr(D=1|X)=0.6exp(θ(I(X=2)−1)),θ>0; and[TE|(X,D=1)]∼Lognormal(β(1−I(X=2)),1),β>0. In this model individuals with the very rare homozygous mutant genotype (X=2) have the highest overall probability of failure and tend to fail earlier than those with the other genotypes; wild type and heterozygous individuals have the same overall probability of failure and the same failure time distribution. In order to have a non-trivial probability to observe the homozygous mutant genotype, a larger sample sizen=1500is used in the simulation.It is seen in Table 3that among all five procedures only CPT can hold the nominal significance level well. Although theoretically the stochastic monotonicity as defined in Section  2 includes the recessive effect pattern, the CPT approach nonetheless has limited power in this case. The same pattern as in Case 1 can be observed here in Table 3; and whenβ>0the CPT tests have similar power compared to Gray’s test. FG and Gray’s procedures can have larger power than CPT, at the cost of much inflated type-I error probability. It should be noted that all procedures compared here have rather low power (≤0.43) in this difficult scenario. Balancing the trade off between power and the ability of holding the nominal significance level, CPT would perform the best here, followed by Cox regression.Here a case of delayed failures is considered. The delay causes a switch in the direction of the genetic effect on (association with) the failure event point process: before the delayNis stochastically increasing inX, and switches to be decreasing inXafter the delay.Xtakes values 0, 1, 2 with respective probability 0.55, 0.43, 0.02. Under the null hypothesis,Pr(D)=0.2andTE∼Lognormal(0,1). Under the alternative hypothesis,Pr(D=1|X=1)=Pr(D=1|X=2)=0.1andPr(D=1|X=0)=0.28;TEis generated asTE=Td+T, with[T|D=1,X]∼Lognormal(βX,1)(β≤0)and an independent random delay[Td|D=1,X]∼Gamma(10,1)I(X=0). In order to observe the delayed effect it is necessary to have prolonged follow up time; thus the censoring time is setTC∼Exp(1/12), and for the competing risk point processPr(DR)=0.02and[TR|DR=1]∼U(0,12). This model defines a fairly complex non-monotone relationship between the event point processNandXunder the alternative hypothesis: The wild type (X=0) individuals have the highest overall probability of failure and tend to fail late (ifβ<0) and after a random delay.As seen in Table 4, in this non-monotone scenario both CPT.Beta and Gray’s test are slightly liberal at the 0.005 significance level; it is clear however CPT.Beta is very sensitive to this type of alternatives and the other methods have little power to detect the stochastic dependence.To illustrate the practical use of CPT and contrast it with the hazard rate regression approach, a dataset of germline SNPs on Chromosome 9 and treatment outcome of childhood acute lymphoblastic leukemia (ALL) patients is analyzed. The subjects came from three clinical study protocols, P9906 (a Children’s Oncology Group legacy trial), TOT-XIIIB and TOT-XV (two St. Jude Children’s Research Hospital front line trials), comprising of five treatment strata: P9906, TOT-XIIIB standard/high risk (T13B-SH), TOT-XIIIB low risk (T13B-L), TOT-XV-standard/high risk (T15-SH) and TOT-XV low risk (T15-L). P9906 is a study on high risk patients. These three protocols used very different risk classification criteria and treatment regimen for each risk level; thus it is necessary to stratify the analysis with the five protocol-risk defined treatment strata. Generally speaking high/standard risk patients received more intense chemotherapy (but very different between the three protocols), and are more likely to relapse (Fig. 1). The goal here is to identify SNPs that are stochastically monotonically associated with the failure event (ALL relapse) point process consistently across the protocol-risk defined treatment strata, to identify germline mutations that may put patients at higher risk of relapse. SNPs demonstrating the stochastic monotonicity pattern are clinically and biologically most meaningful for this particular study. Thus a stratified CPT with directional statistics as defined in Eq. (6) is appropriate.Germline SNP genotype data were generated by Affymetrix 100 K, 500 K, and SNP6.0 GeneChips. Focusing on Chromosome 9 only, 21,909 SNPs are included in the analysis after quality control. The phenotype is time to relapse since the initiation of treatment of the primary ALL. Stochastic monotonicity of the failure event (ALL relapse) point process in each SNP genotype coded as 0  =  AA, 1  =  AB, 2  =  BB is tested by two methods: Fine–Gray (1999) hazard regression model and stratified CPT (Eq. (6)) with five different treatment strata (P9906, T13B-SH, T15-SH, T13B-L, T15-L). Death in remission and second cancer are regarded as competing events, and failure to achieve complete remission is considered as a failure at time zero. The profile information criteria for massive multiple testsIp(Cheng et al., 2004) is applied to determine the statistical significance (Pvalue) threshold in each analysis.Both analyses yield a large number of germline SNPs for their stochastic association with ALL relapse. Interestingly, the findings include SNPs near two genes, ABL1 and MLLT3, well known for their structural alterations in leukemia (tumor) DNA resulting in hard-to-cure ALL subtypes. Findings here suggest that germline point mutations near these genes may also affect the treatment outcome. Despite a substantial overlap in the “statistically significant” SNPs by each method, many top hits by stratified CPT are not captured by Fine–Gray regression, and vice versa (Table 5).It is instructive to examine a few SNPs in detail. The SNP A-2066957 is another incidence the same as the motivating example described in Introduction—the minor allele is infrequent and all events occurred in the wild-type individuals.SNP A-1998030 in the ABL1 gene is captured by stratified CPT but not by Fine–Gray regression. The B allele is the minor allele. Notably, despite that the cumulative incidence functions in each treatment stratum are not well separated by the genotype (A–E, Fig. 2), it is evident that consistently across the five strata individuals having the B allele tend to relapse earlier (F–J, Fig. 2), resulting in the event point process monotonically increasing in the number of B allele (K–O, Fig. 2). Despite the relatively small effect size of the B allele, the accumulation of consistent evidence across all strata drives the stratified CPT to a high significance level. Additionally, by visual examination the proportional hazards assumption does not seem to hold (A–E, Fig. 2).SNP A-1996168 downstream the MLLT3 gene is captured by Fine–Gray regression but not by stratified CPT. The A allele is the minor allele. It is evident that the statistical significance is driven by the large differences in cumulative incidence functions in two strata, P9906 and T15-SH (A and C, Fig. 3). These differences are also reflected well in the sample correlation profile functions (K and M, Fig. 3), but the lack of consistent evidence in the other strata lowers the significance of the stratified CPT (L, N, and O Fig. 3). However the unstratified CPT nonetheless reaches a high significance level (Table 5); and stratified CPT withSqdefined in Eq. (7) showed high significance (Pvalue 0.00051). Other SNPs in Table 5 show patterns similar to what is described above. Another SNP downstream of the MLLT3 gene is captured by CPT but not by Fine–Gray regression. The two SNPs (A-1996168, A-1838092) are more than 190,000 base pairs away and are not in high linkage disequilibrium (correlation 0.0857).These results essentially recapture what has been observed in the simulation study although stratified CPT is applied. Additionally it can be observed that CPT is more sensitive to the effect of infrequent genotypes involving the minor allele on the time to failure (Fig. 2).Although the primary objective of this application is to discover SNPs consistently associated with ALL relapse across different protocol-treatment strata, it is instructive to examine the findings by the more general CPT statisticSn;Betadefined in Eq. (5) and compare with the other tests. The stratified version ofSn;Betabased on combining stratum-specificPvalues (see Section  2.4) is applied. The test captures another SNP, A-2237842, downstream of the MLLT3 gene, and in very weak linkage with SNP A-1996868 in Fig. 3 (correlation coefficient 0.2048). Fig. 4shows this SNP’s interesting possible interaction effect with the treatment protocols: The count of the variant (B) allele is positively associated with relapse in the P9906 and T15 protocols (in both low and standard/high risk strata) but negatively associated with relapse in the T13B protocol. Stratified CPT with the statisticSqshowed the highest statistical significance among all five procedures. Table 6also contains a few examples that the SNP has substantial stochastically monotone association with relapse consistently across all strata, leading to high significance for all five procedures.The CPT procedure can be extended to more complex situations by properly modifying the way of counting failures. This is fulfilled by redefining for each case the observed event point processNi(⋅)of each individual in the sample, whereas the construction of the test statistic as defined by Eqs. (2), (3) and (5), and the test procedures remain unchanged.Recurrent failures with or without competing risk. Unlike in the classical survival scenario where the failure of interest is an endpoint, it is now assumed that an individual can experience multiple times of a specific type of failure of interest, and occurrence of censoring or a competing event prevents the further observation (follow up) on the individual. The event point process now takes the formN≔{N(t)=number of failures before or att,t∈[0,∞)}, which is observable till the time of censoring or a competing event. It is assumed here that the competing event is not recurrent, and follow up on the individual stops if a competing event occurs on the individual. In a sample the data of individuali(i=1,…,n)consist of(Yij,δij)(j=1,…,Ki), whereYij’s are increasingly ordered event timesYi1<⋯<YiKiandδij=1forj=1,…,Ki−1ifKi>1, indicating repeated failures of interest. For anyKi≥1(i=1,…,n)δiKi={0censored1failure of interest2competing event (if present) .A fundamental difference here from the classical survival analysis setting is that an individual is still at-risk after the failure of interest has occurred. Thus arguably there is no more information on the event point process beyond the last time pointYiKieven if the last event is a failure of interest (i.e.,δiKi=1). Therefore the observed event point process should be redefined as (assumingYi1<⋯<YiKi):Ni(t)≔{∑j=1KiI(δij=1)I(t≥Yij)ift≤YiKiNAotherwiset∈[0,∞),i=1,…,n. Note this is not a generalization of Eq. (1) where the value of the event point process remains 1 beyond the failure time. Alternatively, it may be desirable to impute the unobserved part of the event point process when the individual has had at least one failure of interest, the “last observation carried forward” criteria gives the following definition which includes Eq. (1) as a special case:Ni(t)≔{∑j=1KiI(δij=1)I(t≥Yij)ift≤YiKiNi(YiKi)ift>YiKiandNi(YiKi)>0NAift>YiKiandNi(YiKi)=0.Note this definition reduces to Eq. (1) forKi=1.In computingρ˜n(t)in Eq. (2), one simply redefinesIE(t)≔{i:Ni(t)>0,i=1,…,n}.Informative censoring. In certain applications where the relevant follow-up time is confined in a finite interval, the administrative censoring represents the fact that either the individual never failed in the entire relevant follow-up interval, or in recurrent failure case, never failed between the last episode of failure and the end of follow up. An example is the occurrences of certain acute toxicity during a (relatively) long period of chemotherapy; the study objective is to assess the association of the acute toxicity (failure) event process with some patient factorXduring the chemotherapy. Thus adverse events beyond the chemotherapy period are not of interest; the follow up stops if the patient finishes the therapy (administratively censored,δi=0), or some competing event occurs during therapy forcing withdraw of treatment (δi=2). In this scenario the administrative censoring is in fact informative as it provides a complete observation of the event point process. It is desirable then to utilize this information in the test statistic. This can be fulfilled by again properly modifying the observed event point processNi(⋅)as follows.The same as done earlier, it is assumed that the competing event is not recurrent, and follow up on the individual stops if a competing event occurs on the individual before the administrative censoring point. If the failure of interest is an end point (non-recurrent) and there is no competing risk, then simply defineNi(t)=I(δi=1)I(t≥Yi),t∈[0,∞). In presence of competing risk, defineNi(t)≔{I(δi=1)I(t≥Yi)ifδi≠20ift≤Yiandδi=2NAift>Yiandδi=2.For recurrent failures with or without a competing risk, defineNi(t)≔{∑j=1KiI(δij=1)I(t≥Yij)ifδiKi=0∑j=1KiI(δij=1)I(t≥Yij)ift≤YiKiandδiKi≠0NAift>YiKiandδiKi≠0.Here again the individual is still at-risk after experiencing an episode of failure of interest as long as the administrative censoring point has not been reached. It may be desirable to impute the unobserved part of the event point process when the individual has had at least one episode of failure of interest, then the “last observation carried forward” strategy gives the following alternative definition:Ni(t)≔{∑j=1KiI(δij=1)I(t≥Yij)ifδiKi=0∑j=1KiI(δij=1)I(t≥Yij)ift≤YiKiandδiKi≠0Ni(YiKi)ift>YiKi,Ni(YiKi)>0,andδiKi≠0NAift>YiKi,Ni(YiKi)=0,andδiKi≠0.Notably, this setting is similar to the problem of nonignorable dropouts caused by censoring due to competing risks (Rotnitzky et al., 2001; Scharfstein et al., 1999), but the analysis objective here is exploratory.Motivated by a GWAS application, a novel approach (CPT) to testing the stochastic independence null hypothesis involving failure times subject to right censoring is developed. This approach has its unique strengths and limitations compared to the existing hazard rate regression and nonparametric test methods. In human genetic studies dealing with failure time phenotypes, it is always of the most interest to detect the additive (strictly stochastically monotone), dominate, or recessive genetic effects which are the most biologically interpretable, regardless the proportional hazards condition. These genetic effect patterns are covered by the stochastic monotone alternative hypothesis described in Section  2. The simulation results indicate that, for monotone (additive) and recessive effect patterns the CPT approach uniformly has higher or similar power compared to existing methods when the proportional hazards condition does not hold. The more general CPT.Beta procedure clearly outperforms the existing methods when the stochastic dependence is non-monotone and complex. In the scenarios where the proportional hazards condition holds exactly or approximately, the CPT approach is less efficient. The loss of power can be compensated by larger sample sizes typical in GWAS applications. Because the nature of the genetic effect and the stochastic dependence structure is unknown a priori, the CPT approach effectively complements the existing failure time analysis methods.The CPT approach is quite flexible and can be adapted to several different failure time scenarios with simple modifications to the counting schema. Modifications to the hazard rate regression models to accommodate such scenarios and recurrent failures do not appear straightforward. Lastly, CPT is numerically more robust because it is solely based on sample moments and does not reply on any convergence of numerical iterations to solve an estimation equation. This feature is particularly desirable in large-screening applications such as GWAS of failure time phenotypes.The CPT approach employs a non-traditional and very flexible method, the hybrid permutation test, to determine statistical significance. A major feature of this method is that it combines the existing parametric analytical approximation (derived from asymptotic theory or by a heuristic) with simulation (permutation) to construct a much more computationally efficient test procedure compared to the naive permutation test. In GWAS applications high significance levels typically beyond 10−4 are desired; at least 10,000 naive permutations have to be performed in order to differentiate such significance level from 0; whereas a hybrid permutation test requires only a few hundred (typically 200) permutations. The reduction in computational effort is at least 50 times, a reduction highly desirable in GWAS type applications. Note the estimation of the parameters (τnandμnfor example) only involves computing a few sample moments from a few hundred data points; thus with the contemporary statistical software such as R, the computation effort for this part is negligible. The simulation study in Section  3 indicates that the hybrid permutation tests considered herein can hold the significance level fairly well at the relatively stringent 0.005 significance level, and in the case it fails (Case 2: Table 2), the other methods are even worse. A formal investigation and further development of hybrid permutation tests are certainly worthy of future efforts, although these are beyond the scope of this paper.Notably CPT is a general approach to the inference of the association between a failure event point process and any random variable; thus it is widely applicable beyond genomic studies.

@&#CONCLUSIONS@&#
