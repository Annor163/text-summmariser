@&#MAIN-TITLE@&#
A computational framework for cancer response assessment based on oncological PET-CT scans

@&#HIGHLIGHTS@&#
Computational cancer evolution assessment from a pair of oncological PET-CT scans.Automatic PET tumor segmentation and decision making system proposal.Supervised learning framework with a novel multi modal feature set.Introduction to computer aided diagnosis tools in a nuclear medicine scenario.

@&#KEYPHRASES@&#
Computer aided diagnosis,Nuclear medicine,Machine learning,Image processing,Quantitative analysis,

@&#ABSTRACT@&#
In this work we present a comprehensive computational framework to help in the clinical assessment of cancer response from a pair of time consecutive oncological PET-CT scans. In this scenario, the design and implementation of a supervised machine learning system to predict and quantify cancer progression or response conditions by introducing a novel feature set that models the underlying clinical context is described. Performance results in 100 clinical cases (corresponding to 200 whole body PET-CT scans) in comparing expert-based visual analysis and classifier decision making show up to 70% accuracy within a completely automatic pipeline and 90% accuracy when providing the system with expert-guided PET tumor segmentation masks.

@&#INTRODUCTION@&#
18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET) has become a standard imaging method for the staging, restaging, and monitoring of treatment response in a variety of tumors. By injecting the 18F-FDG (fluorodeoxyglucose) radiopharmaceutical to the patient, a metabolic activity volume, measured in SUV (standard uptake value [1]) units, is acquired. FDG-avid tumors such as lymphoma, sarcoma, breast cancer or ovarian cancer show higher than normal SUV values in non-physiological locations, leading to a more accurate diagnosis than MR (magnetic resonance) imaging or CT (computed tomography) in some oncological scenarios [2]. Current technology offers integrated PET-CT and more recently PET-MRI scanners, which provide co-registered PET and CT/MR scans of the patient [3].This technology has proven especially useful in patient׳s global cancer response assessment [4,5], where a comparative analysis between two time consecutive whole body PET-CT scans can provide an accurate insight of the morphological and physiologic cancer evolution trends. Generally, nuclear medicine physicians assess a patient’s cancer progression or response (Fig. 1) condition following a trained visual analysis of both scans.By segmenting the tumor volume from the PET scans, changes in metabolic tumor volume (MTV) and its metabolic activity (typically modeled by its mean or maximum SUV values) have shown to be a valuable quantitative indicator of the cancer evolution stage, as described in Refs. [6,7]. However, these studies focus on a particular subset of cancer scenarios, where typically only one significant tumor lesion is analyzed, and changes in the tumor spread over time are not taken into consideration. Sampedro et al. recently showed in [8] that the cancer spread information should be taken into consideration in the quantitative analysis of the oncological state from PET scans.Note that as obtaining an accurate expert-guided tumor segmentation of whole body PET scans is highly time-inefficient in the clinical day-to-day setting, sometimes a very rough approximation of the volume and activity of each tumor lesion is obtained by placing a user-variable radius sphere on top of the lesion and reading its diameter (commonly in mm) and the mean and maximum metabolic activity values (SUVmean, SUVmax) within the sphere’s volume.In this work we introduce a computational framework for the analysis of the cancer time evolution based on two time consecutive PET-CT scans. The aim of this system is to aid in the decision making process regarding the cancer progression or response condition by providing supporting quantitative information from image analysis and machine learning techniques.Despite being a highly challenging computational scenario (as shown in subsequent sections), nuclear medicine experts agree on the need of such a computational system that could provide objective and quantitative information to support the visual analysis, which is well-known to suffer from inter- and intra-observer variabilities [9].To the best of our knowledge, the computational modeling of the described scenario has not been addressed by the scientific community. Although nuclear medicine software stations include several tools to carry out expert-guided PET segmentation and allow the direct superimposition of segmentation masks from one PET scan to another, they lack a comprehensive computational decision making and quantitative framework analogous to the one proposed in this work.The rest of the paper is organized as follows. Section 2 describes the materials used for the validation of the proposed system. Section 3 presents an in-depth characterization of the methodology proposed for the implementation of the computational framework. Section 4 shows the results of the proposed system (using semi-automatic and automatic configurations) and discusses its possible applications in the clinical setting. Finally, Section 5 concludes the paper and points out some future work required to fully validate the proposed system in the clinical domain.A total of 200 whole body FDG PET-CT scans were obtained from the Philips PET-CT Gemini TF machine located at the nuclear medicine department in the Hospital de Sant Pau (Barcelona, Spain). Each scan contains two co-registered volumes (PET and CT) in DICOM (Digital Imaging and Communications in Medicine) format. From the DICOM metadata, SUV values for PET voxels and HU (Hounsfield units [10]) values for CT voxels can be computed. A PET voxel corresponds to 64mm3 and a CT voxel to 2mm3. Volume dimensions are 144×144×Np for PET volumes and 512×512×Nc for CT volumes (Np and Nc being the number of slices for each volume). Np and Nc (ranging from 192 to 213 and 511 to 623, respectively) are related with a ratio of Nc/Np=2.66. However, the actual number of slices is dependent on the volume of interest selected by the acquisition technician, varying with the patient’s height and the anatomical limits of interest (typically either from neck to middle-thigh or from the top of the skull to the feet). The patient’s position during acquisition is also variable (mainly related to arm positioning).These 200 scans correspond to 100 patients with Non-Hodgkin lymphoma or breast cancer (where the proposed framework would be of much clinical interest), each one having two time consecutive scans (T and T+1) with which oncological evolution is addressed. The time elapsed between scans is typically between 3 and 8 months, depending on external clinical factors such as the type of treatment received and other clinical and logistic variables.The ground truth information regarding clinical condition for each case was given following a consensus of three independent nuclear medicine physicians (53 cancer progression and 47 cancer response conditions). The same consensus also agreed conceptually about the existence and location of tumor lesions in all PET scans. Subsequently, each physician segmented a random third of the scans, therefore providing the expert-guided tumoral segmentation masks of 200 PET scans. Note that in an analogous context, Sampedro et al. [11] showed good inter-observer segmentation overlap degree in segmenting oncological PET scans, and therefore this issue is not considered in this work.The disease extent was variable across subjects, ranging from a single small tumor lesion to a highly spread metastatic tumor. However, the majority of the cases (approximately 80%) showed multiple tumor lesions (analogous to the scans inFigs. 1a and 2), where the decision making process becomes more difficult in clinical practice and automatic segmentation techniques would be valuable, as the semi-automatic approach would be highly time-consuming.

@&#CONCLUSIONS@&#
We described a common clinical diagnostic scenario in nuclear medicine imaging, the cancer evolution assessment (its progression or response stage) via a pair of time consecutive PET-CT scans, and proposed a computational framework to complement the expert’s visual analysis with relevant quantitative and subject-independent information within this diagnostic context.Since modeling this particular clinical scenario following the high level expert’s knowledge and reasoning from a computational point of view represents a challenging problem, a supervised machine learning framework has been proposed. A trade-off is observed between the use of a completely automatic (and therefore time-efficient and subject independent) approach with a performance accuracy of 70% at detecting the correct cancer evolution condition (taking as a reference the expert’s visual analysis), and a semi-automatic approach where the system is provided with the PET tumoral segmentation masks carried out by the trained physicians, which show up to 90% performance. In any case, the set of numerical indicators used as feature set within the machine learning framework or the numerical outputs of the trained classifiers may provide the expert with relevant quantitative information, contributing to improve the overall diagnostic accuracy in the clinical setting.Future work includes, at the clinical level, the incorporation and long term validation of the proposed system in the day-to-day medical practice as well as the introduction of a new quantification module to model the overall intensity of a particular cancer progression or response condition, which would become a very useful tool to help in oncological treatment response analysis and management. At the technological level, we plan on reducing the computation time of the system using GPU-based parallelization techniques as well as dealing with the multi-class problem of recognizing each of the evolution patterns instead of the general response/progression state by introducing successful multi-class frameworks such as error-correcting-output-codes [18].None declared.