@&#MAIN-TITLE@&#


@&#HIGHLIGHTS@&#
A new affinity-based k-anonymity model that leverages query refinement patterns.A novel notion of generalized graph k-cores.A link between k-anonymity and k-cores.A novel evaluation test based on sensitive and non-sensitive queries.A comparison between k-anonymity under affinity and under WordNet generalization.

@&#KEYPHRASES@&#
k,Θ,-affinity privacy,Search log anonymization,Semantic k-anonymity,n-grams,Graph k-cores,Query expansion,

@&#ABSTRACT@&#
Search log k-anonymization is based on the elimination of infrequent queries under exact matching conditions, usually at the cost of high data loss. We present a semantic approach to k-anonymity, termedkΘ-affinity, in which a query can be protected by affine rather than identical queries. Based on the observation that many infrequent queries can be seen as refinements of a more general frequent query, we develop a three-step privacy model. We first represent query concepts as probabilistically weighted n-grams and extract them from the search log data. We then expand the original log queries with such concepts, defining the affinity between two queries as the similarity of their expanded representations. Finally, after building the graph of Θ-affine queries (for a given threshold Θ), we find the generalized k-cores of this graph, which coincide with the sets of queries satisfyingkΘ-affinity privacy. Experimenting with the AOL dataset, we compare k-anonymity under affinity to k-anonymity under equality and under WordNet generalization. We show thatkΘ-affinity achieves similar levels of privacy while at the same time reducing the data losses to a great extent. We also discuss its sensitivity to attacks.

@&#INTRODUCTION@&#
Search log data contain information about the interactions between users and search engines, usually including user IP, request time, query text, search results, and clickthrough data. The analysis of users’ activity (as recorded in search logs) allows improvement and personalization of search services along several dimensions. Query logs are valuable for researchers and data analysers to develop and test better ranking and query refinement algorithms (Jiang, Pei, & Li, 2013), as well as to understand query intents (Jansen, Booth, & Spink, 2008) and query reformulation strategies (Carpineto, Romano, & Bernardini, 2012) and to detect shifting trends in longitudinal search behavior (Beitzel, Jensen, Chowdhury, Frieder, & Grossman, 2007). In addition, they have proved to be useful for many other applications, including targeted advertisement (Burghardt, Böhm, Guttman, & Clifton, 2010) and detection of epidemics (Ginsberg et al., 2009).However, as query logs are subject to disclosure of personal information, storing and publishing these data pose several threats to their owners, discussed by Cooper (2008). As a matter of fact, since the AOL incident in 2006, in which a user was identified from a search log with randomized user identifiers (Barbaro & Zeller, 2006), the collectors of search log data have been wary of publishing them for new data users. One of the rare exceptions (to our knowledge) are the datasets made available at the Workshops on Web Search Click Data in recent WSDM conferences (see e.g., Serdyukov, Dupret, & Craswell (2014)), which are meant for the evaluation of search log mining algorithms and are fully anonymized; i.e., all users, queries, query terms, urls, url domains, and clicks are numbers.1These data sets should be reasonably safe, although it is conceivable that certain types of privacy-relevant entities such as person names and company names might be disclosed by comparing the released distributions to those of an external data base with unmasked queries (Kumar, Novak, Pang, & Tomkins, 2007).1The removal of specific entities such as names, age, and address through ad hoc techniques does not prevent user identification. Since 2006, several anonymization methods have been proposed that modify the content of the original query log in more principled ways; e.g., (Adar, 2007; Korolova, Kenthapadi, Mishra, & Ntoulas, 2009; Hong, He, Vaidya, Adam, & Atluri, 2009; Götz, Machanavajjhala, Wang, Xiao, & Gehrke, 2012). Such techniques lie along the spectrum of trade-offs that exist between privacy guarantees and data utility. Typically, increasing the limitations to information disclosure decreases the amount of useful data retained. As both the utilities gained from search logs and the discovery of private data from them rely, to a significant extent, on information retrieval techniques, the information retrieval community is in a good position to address this research problem.One fundamental type of disclosure is represented by single queries that are unique or quasi-unique identifiers of some individual. This problem can be tackled using the well known model of k-anonymity for search query logs (Adar, 2007).A query log L satisfies k-anonymity if for every query in L there exist at least k−1 identical queries in L issued by distinct users.In this way, there is at most 1/k probability to link a query to a specific individual. However, this method leads to extreme data loss, with the deletion of a huge number of potentially useful and presumably harmless queries. For instance, about 90% of distinct queries in the AOL search log dataset (containing about 10millions distinct queries submitted by about 650,000 users from March to May 2006) were issued by a single user.This problem is not specific to k-anonymity because most anonymization methods rely on the removal of infrequent queries, explicitly or implicitly. Applying differential privacy to the AOL dataset, for instance, the queries whose frequency is below 110 are virtually guaranteed not to be released (Korolova et al., 2009), thus yielding a sanitized log containing a very tiny fraction (i.e., 0.14%) of the distinct queries present in the original query log.The main drawback of k-anonymity can be tackled by relaxing the requirement that other users entered exactly the same query. In this way, a (released) infrequent query can be masked by a frequent, semantically similar item. To achieve this goal, we can exploit the fact that many infrequent queries can be seen as refinements of frequent queries, as illustrated in the following example.We extracted and analyzed the AOL search queries about Tiger Woods. There are as many as 365 distinct queries containing the string ‘tiger woods’. Most of these follow the pattern Q+R, where Q is the string ‘tiger woods’ and R is a sequence of words, but even the patterns R+Q and R+Q+R are well represented, as shown in Fig. 1. The query ‘tiger woods’ was entered by 227 distinct users, with the overwhelming majority of queries (i.e., 327) submitted by a single user. Such queries would be deleted if we simply require that there must be at least two distinct users per query, while they contain useful information to identify the natural subtopics of the query ‘tiger woods’.On the other hand, this example suggests that if we were able to recognize the affinity of a query to a frequent canonical concept of which it can be seen as a refinement, we could increase the amount of highly infrequent queries released by k-anonymization techniques by a great deal and in a presumably safe manner. Hu, Qian, Li, pei, and Zheng (2012) have estimated that about 40% of search log queries follow a Q+R query refinement pattern.Based on these observations, we propose the following semantic definition of k-anonymity, termed k-anonymity under affinity.A query log L satisfies k-anonymity under a Θ-affinity threshold, noted askΘ-affinity, if for every query in L there exist at least k−1Θ-affine queries in L issued by distinct users.There are two main issues involved in this definition, namely the computation of the affinity between two queries and the computation of the set ofkΘ-affine queries. As affinity relies on the refinement patterns noted above, we expand each query with the concepts contained in it, modeled as probabilistically weighted n-grams that are automatically extracted from the search log. Then we show that the computation of the set ofkΘ-affine (expanded) queries can be traced back to a well known notion of graph theory, namely k-cores (Seidman, 1983). The solution consists of two steps: (a) building the graph of Θ-affine queries and (b) computing a generalized version of the k-cores of this graph, in which vertices (e.g., queries) are enriched with class (e.g., users) identifiers. We ran a range of experiments using the AOL dataset underkΘ-affinity, aimed to evaluate the trade off between privacy and utility as well as the ability to release non-sensitive queries, including a detailed comparison with the other main semantic approach to k-anonymity, i.e., based on WordNet generalization (He & Naughton, 2009).The main contributions of the article are the following.•We introduce a novel notion of semantic k-anonymity that leverages the query refinement patterns observable in search log data.We build a practical framework that integrates query concept mining, query expansion, and graph-theoretical analysis.As a byproduct of our research, we identify a novel notion of generalized k-cores and provide an efficient algorithm for their computation.We provide a focused evaluation of the ability to retain infrequent queries not containing sensitive information, including the use of an ad hoc test set.We compare our approach to k-anonymity under WordNet generalization, implemented at the query level.The remaining of the article has the following organization. After reviewing related work in Section 2, in Section 3 we describe the main components of our method, i.e., extraction of n-grams, query expansion, construction of query graph, and computation of generalized k-cores. We then present in Section 4 the experiments with the AOL search log data set, showing that our method is able to release a much larger amount of queries without sacrificing privacy, compared to k-anonymization under equality and under generalization. In Section 5 we discuss how our approach can be used to improve the user’s privacy and its sensitivity to attacks, and finally conclude the article in Section 6.

@&#CONCLUSIONS@&#
