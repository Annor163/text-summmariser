@&#MAIN-TITLE@&#
Camera model identification based on the generalized noise model in natural images

@&#HIGHLIGHTS@&#
Camera model identification is addressed using hypothesis testing theory.The statistical performance of the proposed test is analytically established.The generalized noise model is exploited in the proposed test.A novel camera fingerprint is proposed.

@&#KEYPHRASES@&#
Digital forensics,Camera model identification,Hypothesis testing,Natural image model,Nuisance parameters,

@&#ABSTRACT@&#
The goal of this paper is to design a statistical test for the camera model identification problem. The approach is based on the generalized noise model that is developed by following the image processing pipeline of the digital camera. More specifically, this model is given by starting from the heteroscedastic noise model that describes the linear relation between the expectation and variance of a RAW pixel and taking into account the non-linear effect of gamma correction. The generalized noise model characterizes more accurately a natural image in TIFF or JPEG format. The present paper is similar to our previous work that was proposed for camera model identification from RAW images based on the heteroscedastic noise model. The parameters that are specified in the generalized noise model are used as camera fingerprint to identify camera models. The camera model identification problem is cast in the framework of hypothesis testing theory. In an ideal context where all model parameters are perfectly known, the Likelihood Ratio Test is presented and its statistical performances are theoretically established. In practice when the model parameters are unknown, two Generalized Likelihood Ratio Tests are designed to deal with this difficulty such that they can meet a prescribed false alarm probability while ensuring a high detection performance. Numerical results on simulated images and real natural JPEG images highlight the relevance of the proposed approach.

@&#INTRODUCTION@&#
Digital forensics has received a great attention from law enforcement agencies and academic researchers in the past decade. Because of dramatic advancement in computing and network technologies, the accessibility and transmission of digital images have been increased remarkably. Digital images can be easily edited, altered or falsified because of a large availability of image editing software tools. Consequently, the reliability and trustworthiness of digital images have been questioned when used as evidence in legal and security domains. Reliable forensic methods are urgently needed by law enforcement agencies to restore the trust to digital images.Generally, digital image forensics involves two key problems: image origin identification and image forgery detection (see [1] and the references therein for a detailed introduction). The problem of image origin identification aims at verifying whether a given image was acquired by a specific camera, or at determining camera models/brands as well as types of imaging mechanism (e.g. scanners, cell-phone cameras, or computer graphics). The image forgery detection aims at detecting any act of manipulation such as splicing, removal or adding in an image.There are two approaches to address these problems. Active approach such as digital signatures [2] and digital watermarking [3] has some limitations because a dedicated information has to be embedded during the creation of an image, which increases the production cost of digital cameras, and the credibility of information embedded in the image remains questionable. Passive approach has been increasingly studied in the past decade since it does not impose any constraint and does not require any prior information. Forensic analysts have only the suspect image at their disposal and must explore useful information from that image to gather forensic evidence, trace the acquisition device and detect any act of manipulation. Passive approach is based on internal traces left by the camera in a given image. These internal traces can be provided by investigating the image acquisition pipeline; see [4,5] for an overview of the structure and processing stages of a typical digital camera. Every stage from real-world scene acquisition to image storage can provide clues for forensic analysis.In image origin identification problem, it is important to distinguish the problem of camera instance identification and the problem of camera model/brand identification. More specifically, fingerprints used for camera instance identification should capture individuality, especially cameras coming from the same model. For camera model/brand identification, it is necessary to exploit fingerprints that are shared between cameras of the same model/brand but discriminative for different camera models/brands.In general, passive forensic methods proposed for the image origin identification problem can be divided into two fundamental categories. Methods in the first category rely on the assumption that there are differences in image processing techniques and component technologies among camera models. Lens aberration [6], Color Filter Array (CFA) pattern and interpolation algorithms [7–10], and JPEG compression [11] are considered as influential factors for camera model/brand identification. Using these factors, a forensic feature set is provided and used in a machine learning algorithm. The main challenge is that the image processing techniques remain identical or similar, and the components produced by a few manufacturers are shared among camera models. Moreover, as in all applications of machine learning, it is difficult to select an accurate feature set.Methods in the second category aim at identifying unique characteristics or fingerprints of the acquisition camera device. Sensor Pattern Noise (SPN) is caused by imperfections during the manufacturing process and non-uniformity of photo-electronic conversion due to inhomogeneity of silicon wafers. This is the unique fingerprint which the methods are mainly based on to identify the camera unit. The reader is referred to [12] for the first version of this work and [13–15] for the enhanced version. Two main components of the SPN are the Fixed Pattern Noise (FPN) and the Photo-Response Non-Uniformity (PRNU) noise. The FPN used in [16] for camera unit identification can be compensated by subtracting a dark frame from the output image. Therefore, the FPN is not a robust fingerprint and no longer used in later works. The PRNU, which is directly exploited in [13–15], can be also used for camera model identification as proposed in [17] based on the assumption that fingerprint obtained from images in the TIFF or JPEG format contains traces of post-acquisition processes (e.g. demosaicing) that carry information about the camera model. The ability to extract this noise reliably from a given image is the main challenge in this category due to interference of non-unique operations (e.g. demosaicing and JPEG compression).The present paper addresses the problem of camera model identification based on passive approach. In the literature, a majority of prior works are based on machine learning methods to design a detector. The main drawback is that this framework requires an expensive training stage that comprises many images with different characteristics (e.g. image content or camera settings) from various sources to represent a real-world situation, which might be hardly available in practical forensic situations. Another drawback of all machine learning methods is that the assessment of their statistical performance still remains an open problem [18]. Within this framework, their performance is only evaluated empirically on a large image database and it is difficult to warrant a prescribed false alarm rate.On the opposite, the approach proposed in this paper is based on hypothesis testing framework [19]. While the application of hypothesis testing is often more complex than the training of a classifier using machine learning methods, this first approach has indisputable advantages. Typically, this approach allows the design of a statistical test that is optimal with respect to a desired criterion, for instance minimizing false alarm probability and maximizing detection power and, very often permits the establishing of theoretical priorities of the optimal test, that is probabilities of false alarm and miss detection. Besides, hypothesis testing usually provides valuable insight into the problem of how each parameter impact the performance of the optimal statistical test.However, one of the main challenges when applying the hypothesis testing framework is that it requires an accurate statistical image model so the detector can be designed with high performance. In our previous works, hypothesis testing framework has already been exploited to address the problem of camera model identification [20,21]. More specifically, the first camera model identification method [20] proposed within this framework has been targeting RAW images using heteroscedastic noise model. This noise model takes into account the contribution of Poisson noise in the RAW image acquisition process by characterizing the noise variance as a linear function of RAW pixel's expectation [25,26]. However, the RAW format is hardly available in majority of practical forensics applications and most cameras output digital directly in JPEG format. Hence, for a more practical application, we have recently proposed an approach for camera model identification using Discrete Cosine Transform (DCT) coefficients from JPEG images [21]. Those works exploited a state-of-the-art statistical model of DCT coefficients provided in [23,22] that was obtained by studying and modeling the main steps involved in the image processing pipeline of a typical digital camera [22].It is important to note that the two main differences between the former approach proposed in [20] and the latter one in [21] is that 1) the former exploits noise statistics in the spatial domain while the latter is based on the fact that statistics of DCT coefficients change with different sensor noises combining with various in-camera processing algorithms and 2) those approaches have targeted different image formats, i.e. RAW format for the former and JPEG format for the latter.It should be noted that, to the best of our knowledge, the problem of camera model identification from rendered natural images (not RAW) in the spatial domain has not been studied within the framework of hypothesis testing theory. The main advantage of using pixels in the spatial domain is that this information is always available regardless the file format and compression scheme. The goal of this paper is thus to study the design of an optimal detector from rendered images and using pixels in the spatial domain.As noted above, to apply the hypothesis testing theory, it requires a model to represent the rendered image in the spatial domain. Recently, the study of noise statistics in the spatial domain of a rendered digital image has been performed in our previous research [24]. Since the heteroscedastic noise model characterizes accurately a RAW image, it is proposed to start from that model and take into account effects of post-acquisition processes to develop a so-called generalized signal-dependent noise model that has not been proposed yet in the literature. This noise model describes a non-linear relation between output pixel's expectation and variance. The generalized noise model can characterize an original rendered image accurately, see more details in [24]. Similar to [20], the present paper exploits the generalized noise model to design a statistical test within hypothesis testing framework for camera model identification from rendered images. The main contributions are the following:•The approach is based on the generalized noise model that characterizes accurately the statistical properties of rendered digital image, after in-camera post-acquisition processes. Three parameters(a˜,b˜,γ)that are specified in the generalized noise model are exploited as camera fingerprint for camera model identification.Stating the camera model identification problem in hypothesis testing framework, the paper proposes an optimal detector given by the Likelihood Ratio Test (LRT) in an ideal context where all model parameters are known. This optimal detector serves as an upper-bound of any statistical test for the camera model identification problem.In the practical context, the model parameters are unknown. The paper proposes two Generalized Likelihood Ratio Tests (GLRTs) to deal with the difficulty of unknown parameters. The statistical performance of the GLRTs is analytically established. Moreover, the proposed GLRTs allow us to guarantee a prescribed false-alarm rate and the setting of decision threshold independently of the image content, which is crucial in an operational context. Numerical experiments also show that the loss of power of GLRTs compared with the LRT is negligible.The paper is organized as follows. Section 2 presents the generalized noise model and proposes the camera fingerprint that is further exploited for camera model identification. Section 3 states the camera model identification problem in the framework of hypothesis testing theory and studies the theoretical LRT assuming that all model parameters are known in advance. In practice, those parameters are unknown when inspecting a digital image. Section 4 designs two GLRTs to address the difficulty of unknown parameters. Section 5 presents numerical results of two proposed GLRTs on simulated and real natural JPEG images. Finally, Section 6 concludes the paper.This section briefly describes main steps in the image processing pipeline of a digital camera and presents the generalized noise model that has been provided in [24]. Based on this noise model, a new camera fingerprint is proposed for camera model identification.A typical image processing pipeline includes two stages: RAW image acquisition and post-acquisition processes (e.g. demosaicing, white-balancing and gamma correction), see more details in [4,22,23]. The output image is a full-color high-quality image, referred to as TIFF image. JPEG compression can also be performed for ease of storage and transmission.The study of noise statistics in a natural image in TIFF or JPEG format has been accomplished in our previous work [24]. Firstly, RAW image can be modeled by considering noise sources that corrupt the image during its acquisition process [20,25,26]. Typically, the RAW image model consists of a Poissonian part that addresses the photon shot noise and dark current and a Gaussian part for the remaining stationary disturbances, e.g. read-out noise. For the sake of simplification, the Gaussian approximation of the Poisson distribution can be exploited because of a large number of incident photons, which leads the heteroscedastic noise model(1)xi∼N(μxi,aμxi+b),wherexidenotes a RAW pixel andμXdenotes the expectation of a random variable X. This model gives pixel's variance as a linear function of pixel's expectationμxi. The parameters(a,b)were proposed in our previous work [20] as fingerprint for camera model identification from RAW images.Then, it is proposed to start from the heteroscedastic noise model to study noise statistics in TIFF image. Assuming the operations of demosaicing and white-balancing are linear [4], a short calculation shows that the white-balanced pixel still follows the Gaussian distribution(2)yi∼N(μyi,a˜μyi+b˜),where(a˜,b˜)differ from the parameters(a,b)due to the operations of demosaicing and white balancing. Then by taking into account the non-linear effect of gamma correction, a so-called generalized noise model is given as(3)σzi2≜f(μzi;a˜,b˜,γ)=1γ2μzi2−2γ(a˜μziγ+b˜),wherezidenotes the output pixel,σX2denotes the variance of a random variable X, γ is the correction factor (typicallyγ=2.2). It can be noted from (3) that in a natural image, noise is non-stationary and signal-dependent. It is shown in [24] that the generalized noise model is also relevant to characterize JPEG images with moderate-to-high quality factors (QF≥70). The model parameters(a˜,b˜,γ)can be estimated by the Maximum Likelihood (ML) approach, see details in [24].For camera model identification problem, it is necessary to evaluate the variability of the camera fingerprint for different camera settings and different devices per camera model, and to verify their discriminability for different camera models. Fig. 1shows the estimated parameters(a˜,b˜)on JPEG images of Canon Ixus 70 camera for different camera settings and Fig. 2shows the estimated parameters(a˜,b˜)on JPEG images acquired by different devices of Canon Ixus 70 model. Furthermore, Fig. 3illustrates the discriminability of the parameters for different camera models [24]. It is worth noting that the parameters(a˜,b˜)are invariant to imaged scenes and camera settings and discriminative for different camera models. It should be noted that the difference between estimated gamma factors of different camera models is a little small (see details in Table 1). The parameters(a˜,b˜,γ)are relevant to be exploited as camera fingerprint to identify camera models.The application of hypothesis testing theory requires to know the statistical distribution of a JPEG pixel. To this end, it is necessary to model the JPEG compression chain rigorously. JPEG compression mainly involves the Discrete Cosine Transform (DCT) and the quantization in the DCT domain, while the JPEG decompression performs dequantization and inverse DCT operation to return to spatial domain [28]. In general, the reconstructed image from a compressed file usually differs from the original image. There are two fundamental factors involved in this spatial-domain error [29]: the DCT basis vectors, and quantization error introduced in the DCT domain. The spatial-domain error at a pixel location is a weighted sum of 64 DCT-domain quantization errors within an8×8block. Providing an exact statistical distribution of the JPEG pixel is a challenging task due to the difficulty of establishing mathematically the model of DCT coefficients [22], characterizing the effect of quantization in the DCT domain [23], and deriving the distribution of the sum of those random variables.To overcome those difficulties, it is proposed to invoke the Lindeberg Central Limit Theorem (CLT) [19, theorem 11.2.5]. A preprocessing stage involves dividing the JPEG image Z into K non-overlapping homogeneous segmentsSkof sizenk,k∈{1,…,K}. In each segmentSk, the pixelszk,i,i∈{1,…,nk}are assumed to be independent and identically distributed. Such segmentation technique is detailed in [24]. In fact, this preprocessing stage is also performed for estimation of parameters(a˜,b˜,γ). The JPEG pixelzk,iin the segmentSkcan be decomposed as(4)zk,i=μk+ηzk,i,whereμkdenotes the expectation of all pixels in the segmentSkandηzk,iaccounts for the spatial-domain noise after JPEG compression. Since the DCT can approximately decorrelate the input image [29], the spatial-domain noiseηzk,iin the decompressed JPEG image can be seen as a linear combination of independent random variables. In virtue of the Lindeberg CLT, the noiseηzk,ican be approximately modeled by the Gaussian distribution with zero-mean [29]. Meanwhile, the variance of noiseηzk,idepends on pixel's expectationμkaccording to the generalized noise model (3). Fig. 4shows the empirical distribution of noise residuals in a segment extracted from a natural JPEG image, compared with theoretical Gaussian distribution. Therefore, it is proposed to model the JPEG pixelzk,ias(5)zk,i∼N(μk,f(μk;a˜,b˜,γ)).Let analyze two camera modelsS0andS1. Each camera modelSj,j∈{0,1}is characterized by three parameters (a˜j,b˜j,γj). For obvious reasons, it is assumed that(a˜0,b˜0,γ0)≠(a˜1,b˜1,γ1). In a binary hypothesis testing, the inspected image Z is either acquired by camera modelS0or camera modelS1. The goal of the test is to decide between two following hypotheses:∀k∈{1,…,K},∀i∈{1,…,nk}(6){H0={zk,i∼N(μk,σk,02)}H1={zk,i∼N(μk,σk,12)},whereσk,j2=f(μk;a˜j,b˜j,γj)is the noise variance with respect to the expectationμkunder hypothesisHj. As previously explained, this paper focuses on designing a test that allows us to guarantee a prescribed false-alarm rate. Hence, letKα0={δ:sup(μ,a˜0,b˜0,γ0)⁡PH0[δ(Z)=H1]≤α0}be the class of tests whose false alarm probability is upper-bounded by the rateα0. Hereμ=(μ1,…,μK)is the mean vector andPHj[E]stands for the probability of event E under hypothesisHj,j∈{0,1}, and the supremum over(μ,a˜0,b˜0,γ0)has to be understood as whatever model parameters might be. Among all the tests in the classKα0, it is aimed at finding a test δ which maximizes the power functionβδ, defined by the correct detection probability:(7)βδ=PH1[δ(Z)=H1].The problem (6) highlights three fundamental difficulties of the camera model identification. First, even when all model parameters(μ,a˜j,b˜j,γj)are known, the most powerful test, namely the LRT, has never been studied in the literature. The second difficulty concerns unknown image parametersμin practice. Finally, the camera parameters(a˜j,b˜j,γj)are also unknown, thus the hypothesisHjbecomes composite.Suppose that the camera modelS0is available, thus forensic analysts can have access to its characteristics, or its fingerprints, i.e. its camera parameters(a˜0,b˜0,γ0)can be known. Therefore, they can make a decision by checking whether the image under investigation Z contains the fingerprint(a˜0,b˜0,γ0). In other words, it is proposed to solve the problem (6) when the alternative hypothesisH1is composite, i.e. the camera parameters(a˜1,b˜1,γ1)are unknown. It can be noted that a test that maximizes the correct detection probability whatever(a˜1,b˜1,γ1)might scarcely exist. The main goal of this paper is to study the LRT and to design the GLRTs to address the second and third difficulties.When all model parameters are known, in virtue of the Neyman–Pearson lemma [19, theorem 3.2.1], the most powerful test δ solving the problem (6) is the LRT given by the following decision rule(8)δ(Z)={H0ifΛ(Z)=∑k=1K∑i=1nkΛ(zk,i)<τH1ifΛ(Z)=∑k=1K∑i=1nkΛ(zk,i)≥τ,where, to ensure that the LRT is in the classKα0, the decision threshold τ is the solution of the equationPH0[Λ(Z)≥τ]=α0and the Likelihood Ratio (LR) of one observationzk,iis defined by(9)Λ(zk,i)=log⁡12πσk,12exp⁡[−(zk,i−μk)22σk,12]12πσk,02exp⁡[−(zk,i−μk)22σk,02]=12log⁡(σk,02σk,12)+12(1σk,02−1σk,12)(zk,i−μk)2.In order to analytically establish the statistical performance of the LRT, it is necessary to characterize the statistical distribution of the LRΛ(Z)under each hypothesisHj. To this end, the approach is based on the Lindeberg CLT [19, theorem 11.2.5] that requires to calculate the expectation and variance ofΛ(zk,i).Proposition 1Under hypothesisHj, the first two moments of the LRΛ(zk,i)are given by(10)mk,j≜EHj[Λ(zk,i)]=12log⁡(σk,02σk,12)+12(1σk,02−1σk,12)σk,j2(11)vk,j≜VarHj[Λ(zk,i)]=12(1σk,02−1σk,12)2σk,j4,whereEHj[⋅]andVarHj[⋅]denote respectively the mathematical expectation and variance under hypothesisHj.ProofThe proof of Proposition 1 is given in Appendix A.  □In virtue of Lindeberg CLT, the statistical distribution of the LRΛ(Z)under hypothesisHjis derived as(12)Λ(Z)⟶DN(mj,vj),where the notation⟶Ddenotes the convergence in distribution and(13)mj=∑k=1K∑i=1nkmk,j=∑k=1Knkmk,j(14)vj=∑k=1K∑i=1nkvk,j=∑k=1Knkvk,j.Since a natural image is heterogeneous, it is proposed to normalize the LRΛ(Z)in order to set the decision threshold independently of the image content. The normalized LR is defined by(15)Λ⋆(Z)=Λ(Z)−m0v0.The LRΛ(Z)differs from the normalized LRΛ⋆(Z)only by an additive constant and a multiplicative constant, which does not change the decision rule given by the LRT. Accordingly, the corresponding testδ⋆is rewritten as follows(16)δ⋆(Z)={H0ifΛ⋆(Z)<τ⋆H1ifΛ⋆(Z)≥τ⋆,where the decision thresholdτ⋆is the solution of the equationPH0[Λ⋆(Z)≥τ⋆]=α0. The decision thresholdτ⋆and the power functionβδ⋆are given in the following theorem:Theorem 1In an ideal context where all the model parameters(μ,a˜j,b˜j,γ)are known in advance, the decision threshold and the power function of the LRTδ⋆are given by(17)τ⋆=Φ−1(1−α0)(18)βδ⋆=1−Φ(m0−m1+τ⋆v0v1),whereΦ(⋅)andΦ−1(⋅)denote respectively the cumulative distribution function of the standard Gaussian random variable and its inverse.ProofFor the sake of clarity, the proof of Theorem 1 is given in Appendix B.  □From Theorem 1, it can be noted that the decision thresholdτ⋆is now independent of the image content. Therefore the LRTδ⋆can be applied to any natural image. The LRTδ⋆allows us to warrant a prescribed false alarm rate and maximizes the correct detection probability. Since its statistical performance is analytically established, it can provide an analytically predictable result for any false alarm rateα0. The detection powerβδ⋆serves as an upper-bound of any statistical test for the camera model identification problem.The scenario studied in the LRT may not be realistic because the parameters(μk,a˜1,b˜1,γ1)are unknown in practice. This section designs two GLRTs to deal with the difficulty of unknown parameters. It is proposed to replace unknown parameters by their ML estimates in the LRΛ(zk,i)(9).The GLRT designed in this subsection deals with the difficulty of unknown image parametersμkassuming that the camera parameters(a˜0,b˜0,γ0)and(a˜1,b˜1,γ1)are known, i.e. the inspected image Z is either acquired by the known camera modelS0or the known camera modelS1.By replacing the unknown parameterμkby its estimateμˆkin the LRΛ(zk,i)(9), the Generalized Likelihood Ratio (GLR)Λˆ1(zk,i)is given by(19)Λˆ1(zk,i)=12log⁡(σˆk,02σˆk,12)+12(1σˆk,02−1σˆk,12)(zk,i−μˆk)2,whereσˆk,j2=f(μˆk;a˜j,b˜j,γj). In the estimation method proposed in [24], it is assumed that the variance of the estimatesμˆkis negligible when the number of pixels is large. Therefore, the mathematical expectation and variance of the GLRΛˆ1(zk,i)do not change. Consequently, the statistical distribution of the GLRΛˆ1(Z)=∑k=1K∑i=1nkΛˆ1(zk,i)under hypothesisHjcan be approximated as(20)Λˆ1(Z)⟶DN(mj,vj),where the expectationmjandvjare given respectively in (13) and (14).Similarly, the normalized GLRΛˆ1⋆(Z)can be defined asΛˆ1⋆(Z)=Λˆ1(Z)−m0v0. However, the expectationm0and variancev0cannot be defined in practice since the parametersμkare unknown. Therefore, it is proposed to replaceμkbyμˆkin (13) and (14) to obtain estimates ofm0andv0, denotedmˆ0andvˆ0. The normalized GLRΛˆ1⋆(Z)is given in practice as(21)Λˆ1⋆(Z)=Λˆ1(Z)−mˆ0vˆ0.Since the variance of the estimatesmˆ0andvˆ0is negligible, it follows that(22){Λˆ1⋆(Z)⟶DN(0,1)underH0,Λˆ1⋆(Z)⟶DN(m1−m0v0,v1v0)underH1.Finally, the GLRTδˆ1⋆based on the normalized GLRΛˆ1⋆(Z)is given by(23)δˆ1⋆(Z)={H0ifΛˆ1⋆(Z)<τˆ1⋆H1ifΛˆ1⋆(Z)≥τˆ1⋆,where the decision thresholdτˆ1⋆is the solution of the equationPH0[Λˆ1⋆(Z)≥τˆ1⋆]=α0. From (22), the decision threshold and the power of the GLRTδˆ1⋆can be accordingly defined as in the Theorem 1.This subsection deals with a scenario where the image parametersμkand the camera parameters(a˜1,b˜1,γ)are unknown. Thus the hypothesisH1becomes composite. The GLRT designed in this subsection aims to verify whether the inspected image Z is acquired by the camera modelS0. The inspected image Z is allowed to be taken from an unknown camera model.Before designing the GLRT, the ML estimation of camera parameters(a˜1,b˜1,γ1)is performed on the inspected image Z; see details in [24]. Here we setγ1=γ0and the estimation problem with three parameters is reduced to the one with two parameters(a˜1,b˜1). The ML estimates(a˜ˆ1,b˜ˆ1)are asymptotically consistent [19], i.e. they asymptotically converge in probability to their true value:a˜ˆ1⟶Pa˜1andb˜ˆ1⟶Pb˜1. The parameters(a˜1,b˜1,γ1)would characterize a certains unknown camera model. Furthermore, the ML estimates(a˜ˆ1,b˜ˆ1)exhibit a certain variability. Letσa˜12,σb˜12,σa˜1b˜1denote respectively the variance ofa˜ˆ1, the variance ofb˜ˆ1and the covariance betweena˜ˆ1andb˜ˆ1.By replacing(μk,a˜1,b˜1)by(μˆk,a˜ˆ1,b˜ˆ1)in (9), the GLRΛˆ2(zk,i)is now given by(24)Λˆ2(zk,i)=12log⁡f(μˆk;a˜0,b˜0,γ0)f(μˆk;a˜ˆ1,b˜ˆ1,γ1)+f(μˆk;a˜ˆ1,b˜ˆ1,γ1)−f(μˆk;a˜0,b˜0,γ0)2f(μˆk;a˜ˆ1,b˜ˆ1,γ1)f(μˆk;a˜0,b˜0,γ0)(zk,i−μˆk)2.Proposition 2Under hypothesisHj, using the Delta method[19, theorem 11.2.14], the first two moments of the GLRΛˆ2(zk,i)can be approximated as(25)EHj[Λˆ2(zk,i)]=mk,j(26)VarHj[Λˆ2(zk,i)]=vk,j+14VarHj[f(μˆk;a˜ˆ1,b˜ˆ1,γ1)]σk,14+34VarHj[f(μˆk;a˜ˆ1,b˜ˆ1,γ1)]σk,18σk,j4,whereVarHj[f(μˆk;a˜ˆ1,b˜ˆ1,γ1)]is given by(27)VarHj[f(μˆk;a˜ˆ1,b˜ˆ1,γ1)]=μk4−2γ1γ14σa˜12+μk4−4γ1γ14σb˜12+2μk4−3γ1γ14σa˜1b˜1.ProofThe proof of Proposition 2 is given in Appendix C.  □It can be noted that the mathematical expectation of the GLRΛˆ2(zk,i)does not change. Besides, the second and the last terms in (26) aim to take into account the variability of(a˜ˆ1,b˜ˆ1)in the variance of the GLRΛˆ2(zk,i). For brevity, let denotev˜k,j=VarHj[Λˆ2(zk,i)]. In virtue of the Lindeberg CLT, the GLRΛˆ2(Z)=∑k=1K∑i=1nkΛˆ2(zk,i)follows the Gaussian distribution under hypothesisHj(28)Λˆ2(Z)⟶DN(mj,v˜j).where the expectationmjis given in (13) and the variancev˜j=∑k=1Knkv˜k,j.Finally, the GLRTδˆ2⋆based on the normalized GLRΛˆ2⋆(Z)=Λˆ2(Z)−mˆ0v˜ˆ0is written as(29)δˆ2⋆(Z)={H0ifΛˆ2⋆(Z)<τˆ2⋆H1ifΛˆ2⋆(Z)≥τˆ2⋆,wheremˆ0andv˜ˆ0are estimates ofm0andv˜0by replacing unknown parameters(μk,a˜1,b˜1)by(μˆk,a˜ˆ1,b˜ˆ1), and the decision thresholdτˆ2⋆is the solution of the equationPH0[Λˆ2⋆(Z)≥τˆ2⋆]=α0.Theorem 2When the imageZis tested against the known camera modelS0characterized by(a˜0,b˜0,γ0), the decision threshold and the power function of the GLRTδˆ2⋆are given by(30)τˆ2⋆=Φ−1(1−α0)(31)βδˆ2⋆=1−Φ(m0−m1+τˆ2⋆v˜0v˜1).ProofThe proof of Theorem 2 is given in Appendix D.  □The statistical performance of the proposed GLRTsδˆ1⋆andδˆ2⋆is analytically provided. Moreover, they allow us to warrant a prescribed false alarm rate and set the decision threshold independently of image content (see (17) and (30)). It is worth noting that the GLRTδˆ1⋆can be interpreted as a closed hypothesis testing since the decision is made only between two known camera modelsS0andS1. Meanwhile, the GLRTδˆ2⋆becomes an open hypothesis testing because it aims to verify whether the given image is acquired by camera modelS0or not. These two proposed GLRTs can be straightforwardly applied in practice, depending on the requirements of the operational context.The implementation of the GLRTδˆ2⋆requires to know the covariance matrix of ML estimates(a˜ˆ1,b˜ˆ1). However, the ML estimates(a˜ˆ1,b˜ˆ1)are solved numerically [24], which causes a difficulty of defining their statistical properties. To overcome this difficulty, firstly it is proposed to estimate the parameters(a˜,b˜,γ)on each image from 50 images taken by the camera modelS0since this camera model is assumed to be available. These images are selected randomly to cover different image contents. Then the averaged gamma is calculated over 50 previous gamma values. To reduce the variability of the estimates, we set the parameter γ to the averaged gamma value and re-estimate the parameters(a˜,b˜)on each image. Consequently, the empirical covariance matrix can be calculated from 50 couples(a˜ˆ,b˜ˆ). This empirical covariance matrix is used for the GLRTδˆ2⋆. Strictly speaking, this covariance matrix characterizes the variability of the camera parameters(a˜0,b˜0). By doing so, it is expected that the estimates(a˜ˆ1,b˜ˆ1)would fall into the neighborhood of the camera parameters(a˜0,b˜0). In other words, the inspected image Z is expected to be taken by the camera modelS0. This step is also performed in the test with real images.Since the JPEG format is nowadays the most common image format used by digital cameras and other photographic image capture devices. Therefore, in experiments on simulated images and real images, we will work mostly with JPEG format.The detection performance of the proposed tests is first theoretically studied on a simulated database. Suppose the camera modelsS0andS1are respectively characterized by(a˜0,b˜0,γ0)=(−0.0012,0.11,0.8)and(a˜1,b˜1,γ1)=(−0.0025,0.20,0.85). These parameters respectively correspond to Nikon D70 and Nikon D200 camera models in the Dresden image database [27], see Fig. 3 and also details in [24]. From a simple synthetic image given in [26], those camera parameters are used with the generalized noise model (3) to generate randomly 5000 images for camera modelS0and 5000 images for camera modelS1. These images are further compressed with different quality factors using the software imagemagick. Therefore, these images could follow the image processing pipeline as described in Section 2.Firstly, it is desirable to compare the detection performance of the practical GLRTs with the theoretical LRT to observe the loss of power in the GLRTs caused by the estimation error of unknown parameters. The detection performance of the proposed tests for different number of pixels is illustrated in Fig. 5. The pixels in the tests are extracted randomly. The power functionβδof each test is plotted as a function of the false alarm rateα0. It can be noted that the loss of power between the LRTδ⋆and the GLRTδˆ1⋆is negligible even with a small number of pixels (e.g. 50 pixels), which also indicates that the parametersμkare well estimated. Moreover, from Fig. 5, a small loss of power between the GLRTδˆ1⋆and the GLRTδˆ2⋆is revealed. Nevertheless, this loss of power decreases when the number of pixels increases. Actually, the fact of selecting randomly a number of pixels (e.g. 50 and 100 pixels) for the proposed tests allows a better visibility since their power function is perfect (i.e.βδ=1) from only 500 pixels for any false alarm rate. On the contrary to other methods that exploit all the pixels, only a small number of pixels is required to achieve a high detection performance, which emphasizes the strength of the proposed approach. This observation could be useful in case of real images.Furthermore, it is necessary to study the impact of JPEG compression factor on the detection performance of the GLRTδˆ2⋆. As mentioned in Section 2, the generalized noise model is also relevant for JPEG images with moderate-to-high quality factors (QF≥70). Fig. 6shows its detection performance for different quality factors (QF=70,80,90,100). As expected, the correct detection probabilityβδdecreases with the decline of the quality factor since the compression error intervenes more importantly in the generalized noise model.In hypothesis testing framework studied in this paper, the camera fingerprint(a˜0,b˜0,γ0)is assumed to be known in advance. Therefore, this fingerprint needs to be defined accurately in practice. To this end, it is proposed to estimate the parameters(a˜0,b˜0,γ0)using the same technique of calculating the covariance matrix proposed in Section 5.1. Firstly, the estimates(a˜ˆ,b˜ˆ,γˆ)on each image are given and the reference parameterγ0is calculated as the average of 50 gamma values. Then the parameters(a˜,b˜)are re-estimated on each image by setting γ to the referenceγ0. The reference parameters(a˜0,b˜0)are finally obtained by averaging the previous estimates(a˜ˆ,b˜ˆ). The covariance matrix of(a˜0,b˜0)can be also defined. Evidently, using more images will get a better estimate but it is also less realistic. The number of 50 is a good trade-off.To highlight the relevance of the proposed GLRTs, two Nikon D70 and Nikon D200 camera models of the Dresden image database [27] are chosen to conduct experiments since two camera models of the same brand are expected to exhibit similar characteristics. Only the red color channel is used in this experiment. The Nikon D70 and Nikon D200 cameras are respectively set atH0andH1. The reference parameters of each camera model are defined as discussed above. Fig. 7shows the detection performance of the GLRTsδˆ1⋆andδˆ2⋆for different numbers of pixels. We can note a similar behavior to the detection performance on the simulated database. There is a small loss of power between the two power functions since the estimates(a˜ˆ1,b˜ˆ1)used in the GLRTδˆ2⋆are influenced by the image content. Nevertheless, this loss of power also decreases as the number of pixels increases. Two proposed GLRTs are nearly perfect from 500 pixels.Furthermore, as mentioned above, the proposed tests allow us to warrant a prescribed false alarm probability. Therefore, it is desirable to compare the empirical false alarm probability of the proposed GLRTs in practice with theoretical one given in (17) and (30). Fig. 8shows the comparison between the theoretical and empirical false alarm probabilities, which are plotted as a function of decision threshold τ. The two proposed GLRTsδˆ1⋆andδˆ2⋆show an ability to guarantee a prescribed false alarm rate, even though there is a slight difference in some cases (typicallyα0≤10−3) due to the influence of image content, the presence of weak outliers in the segmentsSk, and the inaccuracy of the CLT for modeling tails.Experiments are then conducted on a large database to verify the efficiency of the proposed approach. The whole Dresden image database [27] is used in our experiment (camera models with only one device available is excluded). Technical specifications of the cameras are shown in Table 2, see more details in [27]. The database covers different devices per camera model, different imaged scenes, different camera settings and different environmental conditions. The images are acquired with different JPEG quality factors. For each camera model, 50 images are used to estimate the reference parameters and other images are used for the testing stage.Firstly, the GLRTδˆ2⋆is conducted to verify whether a given image is acquired by the camera model of interest. The decision thresholdτˆ2⋆is given by the Theorem 2 corresponding to the false alarm rateα0=10−5. If the normalized GLRΛˆ2⋆(Z)is smaller than the decision thresholdτˆ2⋆, the hypothesisH0is accepted, i.e. the given image is declared taken by the camera model of interest. On the contrary, the hypothesisH1is accepted. The detection performance of the GLRTδˆ2⋆is shown in Table 3. In this table, each camera model is considered as hypothesisH0(row) and all images (column) are tested againstH0. The values in the table indicate the percentage of images that are detected taken by the camera modelH0. The table in this paper is not used in the same way as in the classification in which the sum for each class yields100%. The inspected image is brought into the binary testing of the known camera modelH0against the others, thus the sum of a class may not yield100%. Therefore, it could lead to a scenario that an image is detected taken by at least two camera models. To deal with this scenario, the GLRTδˆ1⋆could be performed on the camera models of conflict to better classify the inspected images.The comparison with prior-art detectors includes the Support Vector Machine (SVM)-based detector that has already been performed on the Dresden database [27]. This detector is based on the statistical difference in natural images that are captured by different camera models. To capture this statistical difference, the SVM-based detector uses 46 different features. The feature set includes three main groups: color features describing the color reproduction of a camera model, wavelet statistics quantifying sensor noise and image quality metrics measuring sharpness and noise. The reader is referred to [30] for more details of this feature set. Moreover, the SVM might be the most popular choice among many existing powerful machine learning algorithms for supervised classification. The SVM-based detector has used 60% of the images of one device per model for training and all images of the remaining devices for testing. The detection performance of the SVM-based detector is shown in Table 4. The proposed detectorδˆ2⋆is almost equivalent to the SVM-based detector.Furthermore, the PRNU-based detector [14] is also performed for reference. The PRNU is considered as the reliable fingerprint for image origin identification. Note that this detector is only performed on one device per model. Its detection performance is shown in Table 5. It is worth noting that the SVM-based and PRNU-based detectors cannot guarantee a prescribed false alarm rate. The proposed detector is not only able to guarantee a prescribed false alarm rate but also ensure a high detection performance. This emphasizes the strength of the proposed approach that is based on a relevant parametric image model to design a statistical test within hypothesis testing framework.Besides, we also conduct the detector based on DCT coefficients statistics that is provided in our previous work [21] for comparison (see Table 6). It could be noted that for a few cases (e.g. K, Pe, Ri), this DCT-based detector slightly outperforms the proposed detector. This can be justified that the quantization table used in those models might be important, so noise information in the spatial domain might be lost compared to the one in DCT domain. However, overall the DCT-based detector is less powerful and provides an important misclassification.Another problem in image origin identification is to verify the robustness of camera fingerprint against post-processing operations. To do this, we have conducted some common operations on the original JPEG images taken from Nikon D70 camera model such as double compression, histogram equalization, Gaussian filtering, and resizing. In case of double compression, the original image is compressed with quality factor 97, then it is re-compressed with quality factor 80. The estimated parameters in each case are respectively shown in Fig. 9, Fig. 10, Fig. 11, Fig. 12. From those figures, we can note that the estimated parameters(a˜,b˜)change completely after implementing the operation. This may be justified due to the fact that the parameters(a˜,b˜)characterize the statistical properties of a digital image. Therefore, if an operation modifies statistical properties of the image or a sufficiently large area in the image, the parameters(a˜,b˜)would be estimated differently if the image model and the estimation algorithm do not take into account yet the operation. It can be noted that while this observation shows the weak robustness of the parameters(a˜,b˜)against post-processing operations, it can allow us to deal with the image forgery detection when a forger attempts to falsify the original image.

@&#CONCLUSIONS@&#
