@&#MAIN-TITLE@&#
An optimized GPU implementation of a 2D free surface simulation model on unstructured meshes

@&#HIGHLIGHTS@&#
A GPU implementation of a FV method for the 2D Shallow Water Equations is presented.Structured and unstructured meshes allow different implementations.NVIDIA C2070 GPU is compared against Intel Core 2 Quad Processor.The basic GPU implementation obtains between 20× and 30× of speed-up.Some strategies on the mesh order allow to double the performance, reaching 50×.

@&#KEYPHRASES@&#
GPU,Finite volume methods,Unsteady flow,Unstructured meshes,Dry/wet boundaries,CUDA,High performance computing,

@&#ABSTRACT@&#
This work is related with the implementation of a finite volume method to solve the 2D Shallow Water Equations on Graphic Processing Units (GPU). The strategy is fully oriented to work efficiently with unstructured meshes which are widely used in many fields of Engineering. Due to the design of the GPU cards, structured meshes are better suited to work with than unstructured meshes. In order to overcome this situation, some strategies are proposed and analyzed in terms of computational gain, by means of introducing certain ordering on the unstructured meshes. The necessity of performing the simulations using unstructured instead of structured meshes is also justified by means of some test cases with analytical solution.

@&#INTRODUCTION@&#
Physically based simulations of complex systems usually require large computational facilities to be completed in a reasonable time. Moreover when the simulated phenomenon is unsteady and based on a dynamical estimation of the updating time step, the computational performance is an important topic to be taken into account. One of the most widespread strategies to reduce the computational cost is the use of parallel techniques, involving a suitable number of processors. Since CPU frequencies seem to be reaching their maximum capacity [1], nowadays Many-Core parallel techniques appear to be an interesting option.In recent years, Graphic Processing Unit (GPU) has been used to accelerate the calculations because of its inherent vector-oriented designing. This paradigm is known as General-Purpose Computing on Graphics Processing Unit (GPGPU) and it is widely used for a very large range of applications in CFD such as [2–5] as well as other environmental applications such [6]. In the present work, special attention is paid to the application of these GPUs to unsteady flows of interest in hydraulics. Shallow Water models in particular are widely used to simulate surface geophysical flows. These situations usually involve large size domains and long time scales. Practical applications require a compromise between spatial accuracy and computational efficiency. In order to achieve the necessary spatial resolution, rather fine grids become necessary in many cases requiring more data storage, increasing proportionally the number of operations and reducing the allowable time step size for explicit calculations. When, at the same time, a reasonable computational time is desired, the use of GPU codes is one of the options for computing large space and temporal domain problems.The idea of accelerating the calculations in unsteady hydraulic simulation using multiple CPU was recently reported in [7,8] or [9] as well as using GPU in [10–12] or [5]. Although a very good compromise between number of CPUs used and performance is offered by the former option, the cost of using multiple CPU is significant due to the hardware investment and associated use. Alternatively, the GPU technology offers the performance of smaller clusters with less disbursement [13]. The main difficulty, and apparent drawback, when porting codes from CPU to GPU, is the cell order required by the GPU to process data efficiently. This drawback is not present when dealing with structured meshes due to the inherent order and a simple and efficient implementation is relatively easy to be obtained.Despite the wide use of structured meshes, complex geometries for internal or external boundaries are problematic to be represented if not using unstructured meshes. Moreover, when dealing with topographic representation some recent works [14] have shown the benefit of using unstructured meshes in unsteady hydraulic simulations over irregular topography. The quality of the numerical results is sensitive to the grid resolution. Hence grid refinement is clearly an option to modify the whole resolution. In that sense, adaptive grid refinement, readily available when using triangular unstructured meshes [15], designed to follow local bed variations or irregular boundaries can be very useful. The present work is motivated by the implementation in GPU of a code able to perform unsteady hydraulic simulations on variable density triangular unstructured meshes.The performance of GPU based calculations with Double Precision (double) is lower than those that use Single Precision (float) [16,5]. In the particular case of the 2D Shallow Water Equations with source terms [17,18], the use of float is not always desirable. In fact, when simulating complex topography cases, wave propagation over dry beds represents a numerical challenge. The past experience with the dynamical stability control of such transient flows involving wet/dry fronts indicates that double precision is always required. All the performance analysis presented will deal with that kind of data.In the first part of the text, the governing equations are outlined. They are followed by a description of the finite volume updating scheme used. Then, the most relevant general aspects of the implementation in GPU are identified. The particular difficulties encountered when dealing with triangular unstructured meshes and some improvements to overcome them are detailed in the following section. Finally, they are applied to two test cases in order to prove their behaviour when using unstructured meshes.The two-dimensional Shallow Water Equations (SWE), which represent depth averaged mass and momentum conservation, can be written as follows:(1)∂U∂t+∇→E=Hwhere(2)U=h,qx,qyTare the conserved variables with h representing the water depth,qx=hu,qy=hvandu=(u,v)the depth averaged velocity vector along the(x,y)coordinates respectively. The fluxes of these variables areE=(F,G)given by:(3)F=qx,qx2h+12gh2,qxqyhT,G=qy,qxqyh,qy2h+12gh2Twhere g is the acceleration due to the gravity.The source terms of the system are the bed slope and the friction terms:(4)H=0,-gh∂z∂x-τb,xρw,-gh∂z∂y-τb,yρwTwhereτb,xandτb,yare the components of the bed friction stress andρwis the water density. These friction losses in both(x,y)axis are written in terms of the Manning’s roughness coefficient n:(5)τb,xρw=ghn2uu2+v2h4/3,τb,yρw=ghn2vu2+v2h4/3The numerical resolution of system (1) can be obtained by means of the first order upwind finite volume scheme. Integrating in a volume or grid cellΩthe numerical scheme can be expressed compactly:(6)∂∂t∫ΩUdΩ+∑k=1NE(δE-T)k·nklk=0It is possible to define a Jacobian matrixJ∼kof the normal flux at each edge as a result of the local linearization(7)δ(E·n)k=J∼kδUkand to diagonalize it in terms of matricesP∼andΛ∼, formed by its eigenvaluesλ̃mand eigenvectorsẽmrespectively:(8)P∼=101ũ-c̃nx-c̃nyũ+c̃nxṽ-c̃nyc̃nxv+c̃ny,Λ∼=λ̃1000λ̃2000λ̃3,ẽ1=1ũ-c̃nxṽ-c̃ny,ẽ2=0-c̃nyc̃nx,ẽ3=1ũ+c̃nxṽ+c̃ny,λ̃1=ũ·n-c̃,λ̃2=ũ·n,λ̃3=ũ·n+c̃whereũ·n=ũnx+ṽny. The definition of the averaged variables is as follows [19]:(9)ũk=uihi+ujhjhi+hj,ṽk=vihi+vjhjhi+hj,c̃k=ghi+hj2The difference across the edge k can be projected onto the eigenvectors basis [18]:(10)δUk=Uj-Ui=P∼kA∼kwhereA∼k=(α̃1,α̃2,α̃3)kTcontains the set of wave strengths. Following the same procedure with the source terms [18](11)(T∼n)k=P∼kB∼kwhereB∼k=(β̃1,β̃2,β̃3)kTcontains the source strengths.More information about the values of the wave and the source strengths as well as the entropy fix can be found in [18]. The contributions due to the fluxes and the source terms are combined in a compact expression(12)(γ̃m)k=λ̃mα̃m-β̃mkThe 2D numerical upwind explicit scheme is formulated using only the contributions that arrive to the cell:(13)γ̃k-=121-signλ̃kγ̃kso that the finite volume approach for the updating of a single cell of areaΩiis [20]:(14)Uin+1=Uin-ΔtΩi∑k=1NE∑m=13γ̃m-ẽmlknConsidering that in the explicit scheme (14) each k cell edge is used to deliver information between a pair of neighbouring cells of different size, the time step size compatible with numerical stability is limited by(15)Δt⩽Δtλ̃Δtλ̃=min(χi,χj)maxm=1,2,3|λ̃m|so that the following dimensionless quantity is defined(16)CFL=ΔtΔtλ̃⩽1to control the numerical stability of the method.Considering unstructured meshes, the distanceχiin each cell i must consider the volume of the cell and the length of the shared k edges.(17)χi=Ωimaxk=1,NElkFor more details, see [21,18].The GPU contains a large number of processors working all together applying the same operation over different elements. In order to program using this paradigm, NVIDIA has developed CUDA (Compute Unified Device Architecture) [22] that abstracts some aspects of the hardware, allowing programmers to develop general purpose programs efficiently.There are two main points to understand the performance of GPUs by means of CUDA. The first is based on the way CUDA applications are developed. The basic element to be processed is called Thread. Threads are identified by labels ranging between 0 and BlockDim. The group of Threads is called Block, and it contains a (recommended) 32 multiple number of Threads. Finally any group of Blocks is called Grid. The second aspect of interest is the hardware architecture. The minimum unit is the Streaming Processor (SP), where a single Thread is executed. A group of SPs form the Streaming Multiprocessor (SM), typically with 32 SPs. Finally, a GPU is composed by between 2 and 16 SMs.NVIDIA GPUs are generally formed by Streaming Multiprocessors (typically 14–16 in the Tesla Series) which contain Streaming Processors (32 in the case of the Tesla) ([23]). The GPU distributes the Blocks among the SMs. The SMs in turn assign the Threads to the SPs. All SPs inside the multiprocessor perform the same operations at the same time, but each of them applies it to a different element inside a vector. The designing of the GPU is the reason of the recommendation of configure blockDim multiple of 32. The set of 32 threads processed in a SM is called warp.CUDA for C is an extension of the C Standard programming language which includes the possibility of specifying three key abstractions in the execution: hierarchy of thread groups, shared memories and barrier synchronization. These are exposed to the programmer as a set of extensions that may be introduced in the code. The most significant change in the syntax is the necessary parameters for the execution of the functions. In particular, the functions include:where blocksPerGrid is the number of blocks of size threadsPerBlock launched in the stream streamId. Moreover, inside each function, each thread may establish its identifier taking into account its own threaId.x and blockId.x (in the case of 2D or 3D blocks, it is possible to get access to the.y,.zID). This provides each thread the way of establishing a unique access as, for instance, the value of a vector V:More details of the standard can be found in [22].The implementation of numerical models using GPU requires to take into account four important aspects:•Number of elements to be processed: The number of Blocks and the number of Threads within each Block are parameters to be tuned by the programmer. They determine the maximum number of elements the GPU can process (Blocks times Threads per Block). This number must be greater than or equal to the number of elements to be processed.Bottlenecks: In order to process all the operations following the GPU paradigm, special attention must be paid to the shared information between the processing elements.Data transfer reduction: The communication between CPU and GPU is very slow. In general, all the operations must take place inside the GPU, otherwise the overhead caused by data transfers may generate such a cost that the global performance of the implementation can be lower than on CPU.Floating point data precision: The GPU arithmetic performance is halved when using double precision data. Many applications require double precision because of numerical aspects but there exist many others for which simple precision is enough to develop the calculations. When single precision is acceptable, performance can be almost doubled on GPU.The main loop of our implementation is shown in Listing 1where the fundamental of the programming and the general aspect of the simulation code are shown.First, the number of elements of the Blocks is defined statically at the beginning attending to the criterion of occupancy of the streaming multiprocessors (See CUDA GPU Occupancy Calculator [23]). For our purposes, the amount of 96 Threads/Block and 256 Threads/Block has been identified in general as the best configuration for meshes with less than 100,000 elements and more than 100,000 elements respectively.Bottlenecks appear when reduction patterns are present in the algorithms. The necessity of using reduction functions during the computation can be implemented using cublas. cublas library has high-level functions that work retrieving results to GPU or to CPU. When interested in using them without taking out the data from the GPU, thus must be specified as in Listing 2stating that all results have to be returned to the GPU memory.The proposed model formulated as in (14) requires the computations of the minimum globalΔtthat verifies the stability condition (16) when running along all the cell edges. It is achieved by means of the functions cublasIdamin. Fig. 1illustrates an example of the behaviour of this function obtaining the minimum among all of them. Details are shown in Listing 3.As the calculation is controlled by CPU, it is necessary to transfer the updatedtn+1. AfterΔtis calculated, the updating operation can be performed as in Listing 4hence the updated value oftn+1is transferred to the CPU.Δtis the only variable that has to be transferred every time-step due to the control of the global calculation by the CPU. When data dumping is required, all variables at the cells must be transferred to the CPU. This transfer is slow. Although out of the scope of this work, this particular operation may be optimized making use of concurrent execution and asynchronous data transfer.Structured meshes have proved suitable for GPU computations [11]. Indeed, the GPUs have been developed optimizing the accesses to memory when this kind of structures (grids) are used. The main question when calculating with structured meshes to solve the Shallow Water Equations is whether they provide good results when the topography is complicated. It is more difficult to apply local refinement of the mesh if necessary and, when solving river basins, the angularity of the mesh could lead to artificial viscosity near the shores. Moreover, when the simulation requires to respect some kind of structure, the flexibility of the mesh allows fitting to represent it properly [15].The main advantage of structured meshes is the inherent order existent in their creation. Neighbouring cells are usually near in memory. When the solver works by edges, this point is very important in order to get the coalesced access to the main memory in GPU [24].The way the calculations are made over unstructured meshes is not the same as that when using structured meshes. The work in [25] provides a way to make the calculations using the NSEW scheme, implying that the order of the cells is inherent to the manner of accessing the data. However, when using unstructured meshes, the most common way of performing the calculation is by solving the fluxes by edges rather than by cells because the number of operations is nearly halved. In the present work three main aspects have been identified as relevant to construct an optimal solver in GPU when working with unstructured meshes:•Cell ordering: The way cells are ordered is important when accessing data from two neighbouring cells.AoS vs. SoA: The choice of using Array of Structures or Structure of Arrays may improve the performance of the solverEdges ordering: From the previous two points, when calculating by edges, the ordering of these shows relevant results.In consequence, there is a limitation because of the variable wet-dry cells that appear in unsteady cases and may decrease the overall performance of the code. Warp divergence occurs when two threads have different evaluation in a control flow structure. Within a warp, the hardware in not capable of executing if and else statements and serialization of execution paths is required. More details about warp divergence can be found in [26]. This implies that when two elements to be processed must apply different operation by means of a flow control structure (i.e. if…else… such as in the case of wet-dry frontier), first those threads that satisfy the condition will apply the first operation and then, those Threads which enter in the else condition will apply the other operation. This special issue may have important impact on the performance of the application. The order of the cells, will avoid partially this limitation and is next discussed.Cell ordering has relevant weight on the way the cells are connected. This is controlled by the connectivity matrix, defined as:(18)mi,j=1if celliand celljare neighbours andi<j0otherwiseCoalesced memory access or memory coalescing refers to combining multiple memory accesses into a single transaction. Every successive 128 bytes (32 single precision words) memory can be accessed by a warp (32 consecutive threads) in a single transaction. Among the conditions that may result in uncoalesced load, i.e., memory access becomes serialized, the more problematic is when memory access is sparse [23]. Structured meshes, in general, have coalesced-pattern implicit in their construction and this allows not only to know implicitly the index of the cell given the edge but also an ordered manner of performing the memory access. This is illustrated by the sketch in Fig. 2.On the other hand, unstructured meshes require to have an auxiliary index vector to perform the calculations by edges. Taking this into account, the coalescence for the access to the cells given the edge depend on their design. An example of the access pattern is described in Fig. 3. In contrast to Fig. 2, unstructured meshes require connectivity between edges and cells.Two 32-triangular element meshes are defined in Fig. 4. The first is a triangular structured mesh and the second is a triangular unstructured mesh constructed using Triangle[27]. Also Fig. 4 shows the connectivity matrix of both meshes. That of the structured mesh is very close to a banded matrix whereas that of the unstructured mesh does not have that pattern. This implies that, for the structured mesh, the memory will be more ordered and the memory transactions will be performed faster.When dealing with unstructured meshes, some manipulations can be applied to change the connectivity matrix to make it become closer to a tridiagonal matrix. The RCM (Reverse Cutchil-McKee) algorithm transforms a sparse matrix into a banded matrix form with a small bandwidth. This bandwidth can be measured as:(19)φ=max{|f(vi)-f(vj)|:vivj∈E}where|f(vi)-f(vj)|defines the distance between elementsviandvj. For our purpose,f(vi)is the index of the elementviand the difference of the indexes of two neighbouring elementsviandvjrepresents the distance in memory allocation for those elements.In terms of matrices, the graph bandwidth is the bandwidth of the symmetric matrix, which represents the adjacency matrix of the graph. Applying this transformation to the unstructured mesh of Fig. 4, the bandwidth goes fromφ=29(original bandwidth) toφ=5(Fig. 5), so, in the worst case, two variables related to the same edge, will be allocated at most 6 memory positions apart.A very frequent question when working with arrays is the use of Structure of Arrays (SoA) or Arrays of Structures (AoS). This is more important when working with GPU. In Fig. 6the difference between both options is displayed. Taking into account that the considered variables areU={h,hu,hv}, it is necessary to store them ordered by cells. While SoA stores first allh1..NCfor the NC mesh cells and thenhu1..NCandhv1..NC, AoS stores{h,hu,hv}1then{h,hu,hv}2and so on up to NC.Contrary to the CPU, the GPU has a very small cache and, moreover, the accesses are improved in groups of 32 elements. Therefore, when a single Thread accesses any memory address, it will move a group of 32 elements starting in that memory address to the cache. If the contiguous Threads access the near memory addresses, there is no need to access the memory again, because the GPU have already brought the following 31 elements to the cache.When the GPU performs the memory load in order to obtain the value of h (for instance) for a given identifier, if the memory is ordered as AoS (Listing 5, lines 10–12), the accesses pattern is 3-displaced. This is so because, given a Thread accessing to position i, the neighbouring Thread in the Warp will need to access positioni+3. However, if the memory is ordered as SoA (Listing 5, lines 5–7) the access to position i, will be made concurrently to the access to positioni+1by the next Thread and the coalesced access will be automatically produced. It is important to note that if, as in the example, data types are double, internally two cycles are required for a Warp. This is so because the 16 first Threads will access the first 128 bytes and the second 16, the next 128 bytes, covering each 16 the amount of bandwidth allowed by the Caching GPU Load Operation. For the case of AoS, the first 6 Threads will hit in the access, but the 6 next Threads will need to load 128 bytes again because of the structure of the memory space. Although AoS is clearer conceptually, SoA improves memory load operations in this type of problems and is thus recommended in GPU implementations.Bearing in mind that the default mode of the load operation in the GPU is Caching, it attempts to hit the load in L1 and L2 cache with load granularity of 128-Byte. If the data type used is double, it takes 8 bytes to store data and for a Warp, if the data are contiguous, it is necessary to access twice the main memory. On the other hand, when using float only one access is required. For our case, it was decided to write operations as appears in Listing 1. It is worth stressing that the cache mechanism will not be sufficient to compensate a bad coalescence.The third point deals with edge ordering. Edges are defined by the label of their neighbouring cellscid1andcid2, and by their own label i. When operating on edges, functions like the one in Listing 6are used. Here, the cell identifiers are stored in two vectors using an SoA approach to improve memory access. The way that accesses are made are the last point where coalescence is necessary.The lack of coalescence happens because the Threads in a Block will be assigned consecutive edge identifiers, but will access variables which have been indexed by cells. See an example in Listing 6 where a function needs to operate on a variable at both sides of the edge. One of the Threads will access edge i, retrieve the neighbouring cellscid1[i]andcid2[i], then access the cell-indexed depth vector:h[cid1[i]]. The next Thread, operating oni+1will retrievecid1[i+1]andcid2[i+1]in a coalesced way. There is no guarantee however, thatcid1[i]andcid1[i+1]are close to one another, and thus coalescence problems happen when this Thread requires accessh[cid1[i+1]].Listing 7is presented as a way to force coalescence by means of edges ordering. Note that the matrix is symmetric and an element{cid1,cid2}appears in{cid2,cid1}. To avoid this replication, it is necessary to establish the matrix as a triangular matrix. Here only the element that verifiescid1<cid2has been kept.With this ordering, defining thekth edge aswk=(cid1,cid2),1<k<nEdges, andcid1andcid2being the identifiers of the neighbouring cells for that edge, the following property is enforced:(20)wk-1=(cida,cidb)|cida<cid1∨[(cida=cid1)∧(cidb⩽cid2)]Therefore, when Thread i in a Warp accesses position idx and Threadi+1to the position idx+1, the cell data that these Threads must load are as close as possible. Applying this technique to the unstructured mesh presented earlier, it is possible to observe in Fig. 7how the proximity of the numbering can be obtained.These three optimization strategies, cell ordering, the use of SoA and the edge ordering, help to achieve the proximity in the memory space, allowing Threads the accessing to the nearest possible taking the advantage of the coalescence within a Warp.

@&#CONCLUSIONS@&#
A general implementation of a finite volume scheme on Graphic Processors Unit has been analyzed in this work. Unstructured meshes are useful for many fields of engineering but GPU designing is oriented to structured meshes. The results have been compared with an OpenMP implementation. In this work, some improvements on the way of preprocessing the meshes have demonstrated good results, improving the performance of the GPU implementation when unstructured meshes are used. Specifically the use of SoA for the definition of variables, and the application of cell and edge ordering algorithms have been shown to have a noticeable influence on GPU performance. When not all the domain is used, these strategies allow coalesced memory to avoid Thread divergences. When almost all the domain is used, the profit of the coalesced memory access is obtained increasing in both cases the performance between 10% and 25% with small meshes and with no moving boundaries and 60–100% with more than 100,000 cells and variable domain.These results provide a very useful technique that leads to a very efficient implementation on modern GPUs. It is important to note that although the OpenMP parallel version is really easy to implement in a reasonable time when compared to the CUDA version, that requires more time in order to be careful with details related to the architecture, the final results are worth the effort according to our results.The proposed strategy can be extended to other solvers based on calculations by edges and also to other methods where calculations and storage are performed by nodes to simulate unsteady flows on unstructured meshes.