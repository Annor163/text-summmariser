@&#MAIN-TITLE@&#
Detecting positive and negative deceptive opinions using PU-learning

@&#HIGHLIGHTS@&#
Detection of negative deceptive opinion spam.Improved PU-learning approach.Compares the performance of the proposed approach and the original PU-learning method.The role of opinions’ polarity in the detection of deception.Reports experimental results on a set of negative deceptive opinions.

@&#KEYPHRASES@&#
Opinion mining,Opinion spam,Deceptive opinions,PU-learning,

@&#ABSTRACT@&#
Nowadays a large number of opinion reviews are posted on the Web. Such reviews are a very important source of information for customers and companies. The former rely more than ever on online reviews to make their purchase decisions, and the latter to respond promptly to their clients’ expectations. Unfortunately, due to the business that is behind, there is an increasing number of deceptive opinions, that is, fictitious opinions that have been deliberately written to sound authentic, in order to deceive the consumers promoting a low quality product (positive deceptive opinions) or criticizing a potentially good quality one (negative deceptive opinions). In this paper we focus on the detection of both types of deceptive opinions, positive and negative. Due to the scarcity of examples of deceptive opinions, we propose to approach the problem of the detection of deceptive opinions employing PU-learning. PU-learning is a semi-supervised technique for building a binary classifier on the basis of positive (i.e., deceptive opinions) and unlabeled examples only. Concretely, we propose a novel method that with respect to its original version is much more conservative at the moment of selecting the negative examples (i.e., not deceptive opinions) from the unlabeled ones. The obtained results show that the proposed PU-learning method consistently outperformed the original PU-learning approach. In particular, results show an average improvement of 8.2% and 1.6% over the original approach in the detection of positive and negative deceptive opinions respectively.

@&#INTRODUCTION@&#
The Web is not only the greatest repository of digital information ever invented but also the largest communication platform. This characteristic has motivated businesses of all sizes and kinds, such as television networks, film makers, hotels and restaurants, to use the Web as a critical marketing venue by creating websites and discussion forums for their products and services (Duan, Gu, & Whinston, 2008). With the increasing availability of such review sites and blogs, consumers rely more than ever on online reviews to make their purchase decisions. A recent survey found that 87% of them have reinforced their decisions to purchase a product or service by positive online reviews. At the same time, 80% of consumers have also changed their minds about purchases based on negative information they found online.1How Online Reviews Affect Your Business. http://mwpartners.com/positive-online-reviews. Visited: April 2, 2014.1Detecting opinion spam is a very challenging problem since opinions expressed on the Web are typically short texts, written by unknown people using different styles and for different purposes. Opinion spam has many forms, e.g., fake reviews, fake comments, fake blogs, fake social network postings and deceptive texts. Opinion spam reviews may be detected by methods that seek for duplicate reviews (Jindal & Liu, 2008); however, this kind of opinion spam only represents a small percentage of the opinions from review sites. In this paper we focus on a potentially more insidious type of opinion spam, namely, deceptive opinion spam, which consists of fictitious opinions that have been deliberately written to sound authentic in order to deceive the consumers.The detection of deceptive opinion spam has been recently solved by means of supervised text classification techniques. These techniques have demonstrated to be very robust if they are trained using large sets of labeled instances from both classes, deceptive and truthful opinions. For example, some works have reportedF1measures around 0.90 (Feng & Hirst, 2013; Ott, Choi, Cardie, & Hancock, 2011; Ott, Cardie, & Hancock, 2013). Nevertheless, in real application scenarios it is very difficult to construct such large training sets and, much more important, it is almost impossible to determine the authenticity of the opinions, i.e., to assemble a set of verified truthful reviews (Mukherjee, Liu, Wang, Glance, & Jindal, 2011). In order to meet this restriction in this paper we propose to apply PU-learning (Liu, Dai, Li, Lee, & Philip, 2002) to detect deceptive opinion spam in order to be able to learn only from a few examples of deceptive opinions and a set of unlabeled data, under the consideration that deceptive opinion spam can be accurately generated using a Mechanical Turk crowdsourcing service as suggested by Ott et al. (2011).The PU-learning approach was originally used and evaluated in thematic text classification, in problems showing high cohesion among the documents from the target (positive) class, and having great diversity in the unlabeled subset (Liu et al., 2002, Liu, Dai, Li, Lee, & Philip, 2003). The main contribution of this paper is the proposal of a conservative variant of the original method by Liu et al. (2002) that is especially suited to the task of detection of opinion spam, where deceptive opinions are very diverse in content and style, and there are only slightly differences between deceptive and truthful opinions.The evaluation of the proposed method was carried out using a set of hotel reviews gathered by Ott et al. (2013) containing positive and negative deceptive opinion spam.2http://myleott.com/op_spam.2The results are encouraging; on the one hand, they indicate that using only a hundred of examples of deceptive opinions for training it is possible to reach classificationF1measures of 0.8 and 0.7 for positive and negative opinions respectively. On the other hand, they demonstrate the appropriateness of the proposed PU-learning variant for detecting opinion spam, since its results significantly outperformed those from the original approach in both kinds of opinion spam. As a further contribution, in a last experiment we analysed the role of opinions’ polarity in the detection of deception. Our results confirm that negative deceptive opinions are more difficult to detect than positive spam, but they also show that having one single classifier for analysing both kinds of opinions is better that using two separate classifiers, suggesting that there are common characteristics in the way people write positive and negative opinion spam.The rest of the paper is organized as follows. Section 2 introduces some related works in the field of opinion spam detection. Section 3 describes our adaptation of the PU-learning approach to the task of opinion spam detection. Section 4 presents the different opinion spam datasets used in the experiments. Section 5 describes the experimental settings and presents the results from the classification of deceptive and truthful reviews in several sets of positive and negative opinions. Finally, Section 6 presents our conclusions and discusses some future work directions.

@&#CONCLUSIONS@&#
Three are the contributions of this paper: (i) we approached the problem of the detection of deceptive opinions using the PU-learning technique because of the scarcity of deceptive examples we believe it is the most adequate way; (ii) we proposed a novel, more conservative at the time of selecting the reliable negative examples, PU-learning approach; (iii) we analysed the role of the opinions’ polarity in the detection of deception. The evaluation of the proposed method was carried out using the standard-de facto hotel reviews dataset described in Ott et al. (2013) that contains both positive and negative deceptive opinions. The results are encouraging and indicate that using only a hundred of examples of deceptive opinions for training it is possible to reachF1measures of 0.8 and 0.7 for positive and negative deceptive opinions respectively. They show the appropriateness of the proposed PU-learning conservative variant for detecting opinion spam, since its results consistently outperformed those obtained with the original approach in both kinds of deceptive opinions. In a further experiment where the role of opinions’ polarity in the detection of deception is analysed, the obtained results confirm that negative deceptive opinions are more difficult to detect than positive ones, but they also show that having one single classifier for analysing both types of deceptive opinions is better that using two separate classifiers, suggesting that there are common characteristics in the way people write positive and negative deceptive opinions.As future work we aim at applying the novel PU-learning for detecting deceptive language to approach problems such as the detection of online sexual predators as well as the detection of lies in general.