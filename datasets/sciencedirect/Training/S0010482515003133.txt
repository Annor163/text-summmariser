@&#MAIN-TITLE@&#
Reliable resource-constrained telecardiology via compressive detection of anomalous ECG signals

@&#HIGHLIGHTS@&#
Reliable resource-constrained telecardiology is proposed in a two-tier framework.Our technique suits rural communities with limited power and bandwidth.Compressive sampling and high-sensitivity detection remain at the core.Classifiers are designed by exploiting self-similarity and periodicity of ECG.High reliability is maintained even at substantial power and bandwidth savings.

@&#KEYPHRASES@&#
Telecardiology,Compressive sampling,Hurst exponent,Autocorrelation,Receiver operating characteristics,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
The electrocardiogram (ECG) has emerged as an indispensable tool in diagnosing and managing cardiovascular diseases (CVDs), which account for about 30% of the global death [1]. In certain scenarios, including high-risk-patient care, ECG from a subject is continuously monitored to detect deviation from normal sinus rhythm. However, practical difficulties arise when only a few general physicians (or nurses), but no experts in cardiology, are available locally for on-site monitoring. In such situations, need based transportation of experts, despite being both time consuming and expensive, used to be the only recourse available in the past. With the advent of information technology, telecardiology, possibly accompanied by automated diagnostic assists, is fast becoming an attractive alternative [2–9]. Specifically, rather than physically relocating experts to the bedside of the patient, ECG signal collected from the patient is electronically transported to experts, thereby increasing overall responsiveness while bringing down cost.A design framework for such systems has been presented, albeit in broader contexts [10,11]. A number of specific aspects, such as data acquisition [12,13], technology adoption [14,15], privacy and security [16–18], and network architectures and protocols [19,20], have also been studied. In this context, various quality-of-service models have been suggested [21]. Such telecardiology systems are already functional in certain communities at an operating cost that is affordable to many [2–4]. For instance, a successful Brazilian system reports a cost of about US$ 9 for single access [22]. However, their operational feasibility crucially depends on various factors, including local availability of health workers with basic medical training, and reliable communication links such as landline phones. Unfortunately, even such basic resources are not available to a large section of world population, and the aforementioned sum may not be affordable to them. In this backdrop, we take a frugal engineering approach [23], and propose a novel telecardiology architecture that ensures reliable cardiac care even under severe resource constraints, and operates at significantly lower costs.First we attempt to paint a realistic picture of the target demographics, and accordingly, set our objectives. Taking India as an example, about 276 million individuals live on less than US$ 1.25 per day (the figure rises to 1.2 billion worldwide), and a majority of them live in remote rural areas [24]. Many of them need to traverse about 9km to reach the nearest sub-health-center, which typically employs two health workers but no medical doctors, and provides only rudimentary facilities [25]. Further, a large number of rural communities have no access to the electrical grid and landline phones [26]; however, the high penetration of mobile phones, albeit with poor service quality, provides a silver lining [27]. Against this backdrop, we ask: Can such basic mobile network be leveraged to provide reliable healthcare at an attractive cost to the aforementioned communities living at “the bottom of the pyramid” [28], even in the face of attendant severe constraints on power and bandwidth? In this paper, we pose this challenge as an engineering problem, provide a mathematical solution, translate the solution to a novel two-tier telecardiology architecture, and demonstrate its efficacy via extensive simulations on standard databases.As alluded earlier, a conventional telecardiology system, depicted in Fig. 1a, simply records user ECG, transmits it unaltered to a diagnostic center, and is generally used in primary care centers [2]. Such primary care centers are usually manned by personnel with certain level of medical training, supplied with grid power, and equipped with reliable communication link. However, such a system does not function in our setting, where access to power and bandwidth are unreliable, and health workers are practically absent. In this context, we seek a low-power solution that prolongs battery life of the user device. Further, to utilize the unreliable mobile network, we propose to use the short message service (SMS), a robust alternative to a dedicated link, establishing which over a rickety mobile network could be unreliable. In this setting, consider communication of 8.2s worth of ECG sampled at 500Hz into 12-bit words. The usual ASCII coding would take 44 messages costing about US$ 0.7 (at the rate US$ 0.016 per SMS, now prevalent in India), which is more than half of the target daily income [24], and unacceptably high. Accordingly, it becomes imperative to reduce the bandwidth requirement significantly.However, design of a low-power low-bandwidth telecardiology system poses considerable engineering challenge. To appreciate the design challenges, first consider a system constrained by communication bandwidth only. Clearly, one would compress the recorded ECG signal before transmission [29,30]. However, high-efficiency compression algorithms are generally compute-intensive, and hence consume significant amount of power. Therefore, under an additional power constraint, the aforementioned approach loses its appeal. On the other hand, very low power ECG acquisition and monitoring systems have been developed for personalized healthcare applications, but such systems cannot handle the requisite communication range [31–33]. Such competing implications of various constraints render greedy approaches unattractive and prompt us to develop a new paradigm.Accordingly, we propose a novel telecardiology framework, where resource constraints are met by compressively sampling ECG signals [34], and identifying and transmitting only anomalous signals. Specifically, we envisage a two-tier architecture, shown in Fig. 1b, where power-constrained users from a locality record ECG data in a compressive manner, and communicate those to a resource-rich local subcenter. Each such subcenter detects anomalous signals and transmits only those signals over a bandwidth-constrained link to the diagnostic center. We assume such center to be adequately equipped to make professional diagnosis, correct possible misclassifications in received signals, and initiate medical intervention (possibly via SMS) as required. Desirably, the experiences of both subjects and experts remain essentially unaltered (vis-à-vis traditional telecardiology), as a subject still collects the ECG signal using the same transducers, and an expert visualizes that signal at the diagnostic center at essentially the same quality (with R2 score greater than 95%).In this framework, system design involves a tradeoff among three quantities of generally descending importance: the fraction of unserved patients, which we take as the performance/quality criterion, user power, and transmission bandwidth. We would target missing no more than a small fraction of patients (e.g., no more than five patients in a thousand, requiring sensitivity greater than 99.5%), while reducing user power requirement with an aim of prolonging device life, and transmission bandwidth to lower operating cost. The aforementioned quantities are in turn functions of three parameters: effective downsampling factor resulting from compressive sampling, sensitivity, and specificity of the anomaly detector. Thus, towards realizing resource-constrained telecardiology, one needs to first study anomaly detection based on compressive samples.The problem of classifying ECG signals into normal and anomalous categories has widely been investigated. For instance, ventricular arrhythmia detection has been attempted using Karhunen–Loève transform [35] and artificial neural network [36]. In the general context, wavelet-based estimation of the characteristic points of ECG signals (P, Q, R, S, and T) and anomaly detection using such points have been reported [37,38]. There have also been attempts based on fractal dimension and measures of self-similarity such as Hurst exponent [39]. However, the aforementioned anomaly detection algorithms generally set classifier design as the final goal, and attempt at neither compressive detection nor optimizing system reliability subject to resource constraints.In this context, we take a holistic approach towards reliable resource-constrained telecardiology enabled by compressive anomaly detection. Specifically, taking inspiration from earlier work, we propose an anomaly detection scheme that uses two inherent properties of ECG signals, namely, self-similarity and periodicity. In particular, Hurst exponent, a measure of self-similarity, tends to be larger for abnormal signals [40,41]. Further, normal signals are approximately periodic [42]. Hence we propose an empirical measure, autocorrelation ratio (ACR), of closeness to such normal periodicity, thus segregating abnormal signals. Subsequently, we propose a composite classifier based on Hurst exponent and ACR that is found to perform better than those based on individual criterion. We then characterize and compare such classifiers using receiver operating characteristics (ROC), trading off sensitivity against specificity. Classifier design based on compressive samples poses further difficulty as Hurst exponent and ACR need now be estimated compressively. We overcome this difficulty by utilizing sparseness of ECG signals in wavelet basis [43,44]. Finally, we demonstrate, using the PhysioNet databases [45], a reliable telecardiology system, which even at a downsampling factor of five leaves no more that 0.5% patients unserved, and in the process saves user power by 80% and transmission bandwidth by 83.4%. This not only translates to a five-fold longer battery life, but also an average bandwidth cost of US$ 0.12, which is less than 10% of the target income level.Our main contributions are summarized below:1.Reliable resource-constrained telecardiology is conceptualized in a two-tier framework with high-sensitivity compressive anomaly detection at its core.Various downsampling factors and patterns are investigated against reconstruction and detection fidelities.Known Hurst-exponent-based classifiers are augmented with the proposed ACR measure to achieve higher accuracy in the targeted high-sensitivity regime.A resource-constrained telecardiology system is realized, whose reliability is demonstrated using standard databases. Specifically, a five-fold increase in battery life, and a 83.4% reduction in bandwidth cost are achieved compared to classical telecardiology.As alluded earlier, we seek to design telecardiology systems for a vast segment of the population living on about US$ 1.25 per day [24], having practically no access to local health workers [25], and facing severe scarcity of power and communication bandwidth [26]. To make matters worse, the available mobile network generally provides poor service quality [27]. As a counter, we propose to use the short message service (SMS), which is more robust than relying on dedicated links [46]. In this framework, a conventional telecardiology system, shown in Fig. 1a, transmitting an 8.2s ECG-segment sampled at 500Hz into 12-bit words, would require 44 messages upon ASCII coding. Those cost about US$ 0.7 (at the rate of US$ 0.016 per SMS, currently prevalent in India), amounting to more than half of the target daily income [24], which is unacceptably high.In this setting, we envisage a low-power low-bandwidth-cost solution that does not require medical training to operate. To this end, we identify as key infrastructural element the ubiquitous mobile base station [27], which does not suffer from power and comuputational resource constraints. Specifically, we propose a two-tier telecardiology architecture with such base stations as local subcenters, where the user ECG is first communicated to the said subcenter, and after certain processing, is transmitted to the diagnostic center (Fig. 2). The power requirement at the user end is reduced by compressively collecting only one out of D usual samples, and sending it to the subcenter. Specifically, one needs an analog-to-digital converter (ADC), programed to sample according to preassigned compressive pattern, and a transmitter to communicate such samples to the local subcenter. We shall see that near perfect recovery of the full rate signal is possible from such downsampled data due to sparsity properties of ECG signals [40,43]. Thus, for example, an effective downsampling factor of D=5, without any further processing, cuts by 80% the power budget (prolonging the device battery life five fold), as well as the bandwidth budget. Further, we propose to make additional bandwidth savings by sending only abnormal signals, as normal signals need no medical intervention. As the attendant detection of abnormal signals could be compute-intensive (requiring additional power), in view of the user power constraint, such detection is performed only at the local subcenter. Assuming that the user only pays for communication between the subcenter and the diagnostic center, such savings in bandwidth translate to additional cost savings. However, a practical detection algorithm is expected to be imperfect, and one desires to miss only a small fraction of abnormal signals. In such scenario, a target maximum fraction of unattended/missed patients often serves as a reliability criterion [21]. In the present work, we set our target at five in thousand or less (requiring a classifier sensitivity greater than 99.5%).Desirably, the proposed system does not require the subject to either possess medical training, or physically interact with health workers. Further, the local subcenter only needs to provide power, computational resources, and access to communication, but no health facility. Accordingly, the proposed framework realistically caters to the intended communities, and the subject pays for the bandwidth cost only when the ECG is deemed potentially abnormal. In the event the user ECG is transmitted, a suitable diagnostic advise is delivered to the subject from the diagnostic center, possibly via SMS. In this manner, we envisage bringing under a health cover, albeit rudimentary, various remote communities, which otherwise remain outside the purview of traditional health services.The bandwidth requirement of the aforementioned telecardiology system is given by(1)B={Se×α+(1−Sp)×(1−α)}/D,where, D is the effective downsampling factor due to compressive sampling, Se and Sp respectively are the Sensitivity and Specificity of the classifier employed and α indicates the prevalence rate of CVDs, and the bandwidth requirement for the conventional system is taken as the unit. An ideal classifier (Se=1, Sp=1) would require a bandwidth ofB=α/D. Further, assuming power requirement P to be proportional to the number of samples, and taking the power requirement for original sampling as the unit, one has(2)P=1/D.Finally, we adopt as the performance/quality metric Q the fraction of subjects with anomalous ECG unattended by the system, i.e.(3)Q=1−Se.Thus, bandwidth (B), power (P) and quality (Q), the quantities defining a resource-constrained system, are all specified by three parameters, effective downsampling factor (D), sensitivity (Se) and specificity (Sp).Now we pose compressive anomaly detection as a hypothesis testing problem. A downsampling patternϕ⊆{1,2,…,N}with factorD=N/|ϕ|retains the i-th sample of signalx∈RN,i∈ϕ, to obtain the downsampled signal xϕ. Given ϕ, denote byΓϕ⊆RN/Dthe set of downsampled ECG signals xϕ. A classification rule for hypothesis H1 (abnormal) versus H0 (normal) partitionsΓϕinto subsets Γ0 and Γ1 such that given anyxϕ∈Γϕ, we decide Hjifxϕ∈Γj(j=0 or 1). Ideally, Γ0 and Γ1 should, respectively, correspond to normal and abnormal signals only (i.e., Se=1, Sp=1). Practically, we aim at designing Neyman–Pearson classifiers: for a given value α, we maximize Sp subject toQ=1−Se≤α[47]. We then seek to plot ROC by varying α.Before proceeding with the design of compressive classifiers, we provide a brief account of compressive sampling and recovery.We use compressed sensing (CS) to recover high dimensional sparse vectors based on few linear measurements [48]. Specifically, it deals with the problem of economical recovery of an unknown signal x from its linear measurements〈<x,ϕj〉, whereϕj∈Rn,j=1,2,…,N, and〈x,ϕj〉indicates the inner product of x and ϕj. Then signal recovery from such measurements is(4)minx∥x∥0subjecttoΦx=y,where∥x∥0stands for the number of nonzero components in x, that is,∥x∥0=|{i:xi≠0}|and Φ is the matrix whose rows are ϕj. In general, (4) is intractable. Fortunately, under certain technical conditions, solution to (4) is equivalent to its l1-norm based optimization problem [44]:(5)minx∥x∥1subjecttoΦx=y,the recovery of sparse solution from (5) is possible as long as the synthesis matrix Φ satisfies (i) Restricted Isometry Property (RIP) and (ii) smaller value for the coherence parameter (μ), which is the absolute of maximum off-diagonal entry inΦTΦ[49].Signal recovery when the number n of measurements is much smaller than signal length N is of particular interest. The special case of compressive sampling arises when the process of linear measurement reduces to keeping n nonuniformly spaced samples, and leaving out the rest (N−n) ones. In this case, the measurement matrix Φ has rows with all entries zero except one entry of one, and the locations of those unity entries are distinct.In actual applications, suppose the user produces a vector x of, say, N ECG samples at the original sampling rate. We retain only a subset xΦof elements of x according to a pattern Φ at a downsampling factor D. In the present work, we consider the following choices of Φ:1.Uniform downsampling retains one sample and loses the nextD−1, and repeats;Random sampling from uniform bins retains one sample, randomly selected from uniformly divided bins of size D; andUnconstrained random downsampling retainsN/Dsamples, selected randomly without any constraint.Naturally occurring signals can often be represented sparsely in some transform basis with little loss of information. In the context of ECG signals, wavelet transform is a natural candidate for sparse representation in ‘db4’ wavelet basis [43] (Fig. 3b). This is apparently due to the inherent scaling property of ECG data sets [50]. Suppose Φ is a row restriction matrix that picks the rows of the wavelet reconstruction matrix WT, that is,Φx=ΦWTc. The wavelet coefficients (c) may be recovered from the following optimization problem:(6)c^=argmin∥c∥1subjectto∥Φx−ΦWTc∥2≤ϵ,provided c is sufficiently sparse, andΦWTand size ofΦxsatisfy sparse recovery properties. The quantityϵ>0is a small quantity whose choice is to be made based on compressibility. In order to recover wavelet coefficients, one needs to solve (6), for which we make use of the widely used orthogonal matching pursuit (OMP) algorithm, an iterative greedy method, whose solution is obtained by calculating locally optimal solution at each iteration. Though such sequence of locally optimum solutions is not guaranteed to converge at globally optimum solution, OMP remains attractive for its simplicity and low computational complexity [51]. The pseudo code for OMP used in the present application is shown in algorithm 1.Algorithm 1Pseudo code for recovering wavelet coefficients from compressive samples.We propose a compressive classifier based on two inherent properties, self-similarity and periodicity. From the wavelet coefficients recovered using OMP algorithm [44], we estimate Hurst exponent: a measure of self-similarity and autocorrelation ratio: an empirical measure indicating closeness to periodicity of normal signals to aid ECG signal classification.Based on the scaling property of a self-similar function f, i.e.,f(2−nt)=2−nHf(t), H being the Hurst exponent, one can estimate H, from its wavelet coefficients [52]. For a discrete signal x, wavelet coefficients at the same location k at different scales j and m are related viacj,k=2−(j−m)(2H+1)2cm,k[53]. Hence the energy Ejat scale j is related to energy Emat scale m by (assuming Nkcoefficients at location k)(7)Ej≔1Nk∑k|cj,k|2=2−(j−m)(2H+1)Nk∑k|cm,k|2=2−(j−m)(2H+1)Em,leading to the energy scale formula(8)log2Ej=−j(2H+1)+log2E0.Thus Hurst exponent H is estimated from the slope of linear fit to(j,logEj).The unbiased autocorrelation function (ACF) of signal x is defined by(9)R(τ)=1N−τ∑k=0N−1xkxk+τ=1N−τ∑k=0N−1ckck+τ,where setxk=0,k∉{0,1,…,N−1}. The second inequality in (9) follows from the isometry and localization properties of wavelets. As seen in Fig. 3c, the ACF of normal ECG signal exhibits spikes at regular intervals due to inherent periodicity of ECG signals. Complicating matters, ACFs of certain anomalous signals are also nearly periodic; however, those tend to possess more dominant negative peaks compared to that of normal beats. Motivated by this observation, we define an autocorrelation ratio (ACR)(10)ρ=|∑i∈IposR(i)∑i∈InegR(i)|,where index set Ipos(resp. Ineg) collects indices corresponding to K (taken as 10) largest positive (resp. negative) values of ACFR(·). Of course, we expect ACR to be low for anomalous signals.At the local subcenter, wavelet coefficients are recovered using either Nyquist reconstruction (uniform sampling) or OMP (otherwise) and estimates Hurst exponent H using (7) and ACR ρ by first estimating ACF via (9). Finally, as depicted in Fig. 4, a signal is marked normal ifH<Hthandρ>ρthfor suitable thresholds Hthand ρth, and anomalous otherwise. The latter signals are then transmitted to the diagnostic center. Clearly, the classifier performance is dictated by the choice of such thresholds. We compare three cases: (i) Hurst classifier, where ACR ρ plays no role, i.e.,ρth=0; (ii) ACR classifier, where H is ignored, i.e., Hthis set to a large value; and (iii) Composite classifier, where both Hthand ρthare active. Using the proposed classifier, we seek to achieve reliable telecardiology (missing less than five patients per thousand, i.e.,Q≤0.5%, orSe≥99.5%), while lowering power and bandwidth budgets.Before validating the proposed design, we provide a brief overview of ECG anomalies considered and standardization across different databases to generate signal vectors.Anomaly in the ECG signal arises from abnormal electrical activity in the heart. A large heterogeneous group of conditions, where the heart beat is either too fast or too slow, and may be either regular or irregular, are described as cardiac arrhythmia [54]. Further, a subclass of conditions that start in the atria are called atrial or supraventricular (above the ventricles) arrhythmias. Analogously, ventricular arrhythmias begin in the ventricles. Arrhythmias originating in the atria are further sub-categorized as atrial fibrillations (AFIB), atrial flutter, supraventricular tachycardia, and those originating in ventricles as ventricular fibrillation (VFIB), ventricular tachycardia (VT) and ventricular flutter. Various other anomalous heart conditions exist; however, rather than taking all such conditions into account, we shall focus on three abnormal conditions, namely, AFIB, VFIB and VT, and attempt to distinguish those from the normal (NSR).We now validate the proposed design using ECG signals from the PhysioNet databases [45]. Specifically, NSR, MVA and AFIB signals are taken from the MIT-BIH database, and VT signals from the Creighton University database. Note that the later three signal categories are anomalous. Baseline wander in each signal is removed, sampling frequency is standardized at 500Hz (via suitable upsampling), and a segment of 4096 samples (amounting to a duration of 8.2s) is taken as a signal vector [55]. Altogether, we consider 15 normal and 24 abnormal subjects, and 20 such segments from each, giving rise to 780 signal vectors.

@&#CONCLUSIONS@&#
