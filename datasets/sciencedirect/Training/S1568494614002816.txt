@&#MAIN-TITLE@&#
Detection of severe obstructive sleep apnea through voice analysis

@&#HIGHLIGHTS@&#
The present study focuses on voice alone as a primary discriminating source of information between healthy subjects and severe OSA.Statistical analysis as well as performance of several classifiers indicate that voice has a clear potential to detect severe OSA.Analysing the features we conclude that vowel and phrase features and both uttering positions are useful.CCR, Sensitivity and Specificity (all above 80%) point out the potential of voice as a discriminating factor between healthy subjects and severe OSAFuture work will focus on clinical validation results for a comprehensive body of new subjects, with an already trained classifier using this model.

@&#KEYPHRASES@&#
Obstructive sleep apnea,Voice processing,Genetic algorithms,Feature reduction,

@&#ABSTRACT@&#
This paper deals with the potential and limitations of using voice and speech processing to detect Obstructive Sleep Apnea (OSA). An extensive body of voice features has been extracted from patients who present various degrees of OSA as well as healthy controls. We analyse the utility of a reduced set of features for detecting OSA. We apply various feature selection and reduction schemes (statistical ranking, Genetic Algorithms, PCA, LDA) and compare various classifiers (Bayesian Classifiers, kNN, Support Vector Machines, neural networks, Adaboost). S-fold crossvalidation performed on 248 subjects shows that in the extreme cases (that is, 127 controls and 121 patients with severe OSA) voice alone is able to discriminate quite well between the presence and absence of OSA. However, this is not the case with mild OSA and healthy snoring patients where voice seems to play a secondary role. We found that the best classification schemes are achieved using a Genetic Algorithm for feature selection/reduction.

@&#INTRODUCTION@&#
Obstructive Sleep Apnea Hypoapnea Syndrome (OSA for short) is a common sleep disorder that manifests itself by daytime sleepiness caused by a cease in breathing occurring repeatedly during sleep, often for a minute or longer and as many as hundreds of times during a single night. OSA is associated with a reduced-calibre upper airway, and repetitive effects of apneas and hypopneas include oxygen desaturation, reductions in intrathoracic pressure, and central nervous system arousals [1]. Diagnosis of the sleep condition is based on the calculation of the apnea–hypopnea index (AHI) which measures the frequency of reductions in airflow associated with upper-airway collapse or narrowing that occurs with the state change from wakefulness to sleep [1]. The gold standard procedure to determine the AHI is polysomnography, however it is a quite costly methodology [2]. No other measure has proven to be superior to AHI in assessing the overall effect of obstructive sleep apnea. Nevertheless, there is no common consensus between laboratories regarding its definition. Other metrics such as the number or frequency of arousals during a night sleep might be considered an equally good indicator of OSA [1]. Thus, seeking alternative methods of diagnosis that are simpler and more cost effective is fully motivated, and in recent years it was advocated that voice may play a central role into detection of OSA syndrome. Preliminary findings on speech disorder in OSA have been reported firstly in [3] employing a rather small sample (39 subjects) and subjective results of acoustic evaluation of voice changes in OSA, followed by a study [4] on a bigger sample (252 patients) giving again only subjective judgement results. An attempt to a more objective evaluation study was given in [5]. To discriminate between OSA patients and controls, the authors apply spectral analysis to vowels, but again the sample taken into account is small (28 subjects). Recently, in [6] and [7] the authors show the importance of using voice as a discriminatory factor for detection of severe sleep apnea employing Gaussian Mixture Models on phrases (in [6]) and on vowels (in [7]). However, the authors recognize the need for a wider training and validation sets. So far, either due to small samples or subjective judgements, it is hard to quantify up to what extent or under what circumstances we might consider voice as a good discrimination measure between OSA and healthy subjects. Recent efforts such as [8] try to model the upper-airway in OSA subjects as compared to controls by employing computational fluid dynamics models, and they conclude that there is a clear tendency to closure of the upper-airway in OSA. As the upper-way coincides in part with the vocal tract, the thinning of the lumen and tendency to closure experienced in OSA do suggest that there may be an identifiable dysfunction in voice also.

@&#CONCLUSIONS@&#
The present study focuses on voice alone as a primary discriminating source of information between healthy subjects and severe OSA. Both statistical analysis on several voice extracted features, as well as performance of several classifiers indicate that voice has a clear potential to detect severe OSA among healthy subjects. The performance of the classifiers has been estimated using robust statistical techniques (S-fold crossvalidation) while counting with a relatively large body of subjects (i.e. 248), larger than most of the present studies analyzing the relationship between voice and OSA. The group of subjects involved in our experimental design increases to 376, when including the intermediate cases as well. We may get a better grasp on the relationship between OSA and voice by looking at the extreme cases that also have a clear-cut diagnosis. The results in terms of CCR, Sensitivity and Specificity, all above 80% for several classifiers point out the good potential of voice as a discriminating factor between healthy subjects and severe OSA.Careful analysis on subjects with different degrees of OSA reinforced our prior belief that voice may act as a good discriminating factor for most of the severe cases. However, for intermediate cases where upper-airway closure may not be so pronounced (thus voice not much affected), we cannot rely on voice alone for making a good discrimination between OSA and non-OSA.Analysing the features discovered by the feature reduction methods, we conclude that both vowel and phrase features are useful (more vowel features are selected, however) and both uttering positions as well, with more features selected from the stretched (‘E’) uttering.The GA feature selection method proved to be the best reduction scheme that is well adapted to the classifier, and that achieves the best CCR, Sensitivity and Specificity with a small variance of these results due to the specifically designed fitness function (see Eq. (3)), for almost all cases involved in comparison. The GA is capable of discovering useful associations between voice features, and that are not apparent beforehand, the degree of utility being in direct relationship to the classifier performance.Feature selection is a crucial stage in our design as there are many features that can be extracted from voice and speech but there is no a priori knowledge regarding the most discriminant to be employed in the detection of the OSA cases. Therefore, we would like to highlight the use of GAs as one of the most innovative aspects in the present study. GAs have turned out to be the perfect choice when it comes to salient feature discovery, achieving good adaptation with the classification tools employed.For a screening application that detects severe OSA cases among healthy people we may employ an ensemble classifier that combines the output of various classifiers to yield a more robust decision. As seen from Classifier comparison section such an ensemble classifier achieves slightly better results than the best classifier (BC-GA). Moreover, fusion with other measures from the subject's medical record (i.e. sex, age, BMI, EPW, blood pressure) is expected to increase the overall performance. Such parameters are correlated with the AHI index and thus with the presence or absence of OSA, and may shed light into the suitable discrimination of the intermediate subjects as well (mild OSA, snoring subjects), subjects that are difficult to classify by voice analysis only. A multiclass approach, instead of a binary classification, is also expected to increase the classification performance. We might consider more than 2 classes, such as, for example: controls, healthy snoring subjects, mild-OSA, and severe-OSA, and we may make a differentiation between sexes, as well.So far, results presented as an S-fold crossvalidation for several classifiers are by no means a substitute for a clinical validation study. Crossvalidation served us to better estimate the discriminating potential of voice, and the expected correct classification rate, sensitivity and specificity. Actually, during each training-testing experiment involved in the S-fold crossvalidation only a fifth of the total number of subjects (about 50, for the extreme cases problem) was employed for validation purposes, the rest being used to train the classifier. For future work, we will seek to produce clinical validation results for a comprehensive body of new subjects, with an already trained classifier using the model developed in this paper.