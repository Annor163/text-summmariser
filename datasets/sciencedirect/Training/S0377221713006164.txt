@&#MAIN-TITLE@&#
Tabu-enhanced iterated greedy algorithm: A case study in the quadratic multiple knapsack problem

@&#HIGHLIGHTS@&#
Iterated greedy algorithms are tested on the quadratic multiple knapsack problem.A memory-enhanced destruction mechanism for iterated greedy is proposed.Problem-knowledge exploitation is identified in the iterated greedy proposal.Tabu-enhanced iterated greedy solves the problem effectively.

@&#KEYPHRASES@&#
Iterated greedy search,Tabu search,Quadratic multiple knapsack problem,Destruction mechanism,

@&#ABSTRACT@&#
Iterated greedy search is a simple and effective metaheuristic for combinatorial problems. Its flexibility enables the incorporation of components from other metaheuristics with the aim of obtaining effective and powerful hybrid approaches. We propose a tabu-enhanced destruction mechanism for iterated greedy search that records the last removed objects and avoids removing them again in subsequent iterations. The aim is to provide a more diversified and successful search process with regards to the standard destruction mechanism, which selects the solution components for removal completely at random.We have considered the quadratic multiple knapsack problem as the application domain, for which we also propose a novel local search procedure, and have developed experiments in order to assess the benefits of the proposal. The results show that the tabu-enhanced iterated greedy approach, in conjunction with the new local search operator, effectively exploits the problem-knowledge associated with the requirements of the problem considered, attaining competitive results with regard to the corresponding state-of-the-art algorithms.

@&#INTRODUCTION@&#
Iterated greedy search (IG) is a simple metaheuristic for problems of combinatorial optimisation (Culberson & Luo, 1996; Fanjul-Peyro & Ruiz, 2010; Framinan & Leisten, 2008; Jacobs & Brusco, 1995; Lin, Lee, Ying, & Lu, 2011; Lozano, Molina, & García-Martínez, 2011; Ribas, Companys, & Tort-Martorell, 2011; Rodriguez, Lozano, Blum, & García-Martínez, 2013; Ruiz & Stützle, 2007; Urlings, Ruiz, & Stützle, 2010; Yuan et al., 2008). The IG model generates a sequence of solutions by iterating over greedy constructive heuristics, which are applied to a single solution, using two main phases: destruction and construction. During the destruction phase, some solution components are removed, producing a partial solution. The construction procedure then applies a greedy constructive heuristic to complete this partial solution. Then, an acceptance criterion is applied to decide whether the new candidate solution will replace the current solution. An optional local search phase for improving the initial solution and the reconstructed solution may be added before the main loop and the acceptance test, respectively. The flexibility of the IG framework enables the incorporation of components from other metaheuristics with the aim of obtaining effective and powerful hybrid metaheuristics (Lozano & García-Martínez, 2010; Talbi, 2002; Yuan et al., 2008).Tabu search (Glover & Laguna, 1997) is a metaheuristic that pushes a local search to explore more widely in the solution space. A short-term memory, the tabu list, records recent changes to the solution; they cannot again be tried for a fixed number of steps. Ideas from tabu search are often combined with other metaheuristics (Cheang, Gao, Lim, Qin, & Zhu, 2012; Jarrah & Bard, 2012; Wu, Sun, & Srikanthan, 2012).We explore the application of a tabu destruction mechanism to the IG algorithm as compared to the standard mechanism, which removes solution components completely at random. The Tabu-enhanced IG model (TIG) marks the removed solution components in a tabu list and prevents them from being removed again in the subsequent iterations. As in the basic tabu search scheme, the number of iterations that solution components are protected is defined by a user parameter, the tabu tenure.We have considered the Quadratic Multiple Knapsack Problem (QMKP) (Hiley & Julstrom, 2006) as the application domain. It consists of assigning a set of objects disjunctively to a set of knapsacks with the aim of maximising the total sum of profits, subject to capacity constraints. However, profit values are assigned not only to individual objects but to pairs of them, too, so traditional approaches that do not consider the interactions between the objects are not expected to effectively address the problem (Julstrom, 2005). We also propose a novel local search operator for this problem that is analysed in conjunction with the TIG model. The experiments developed not only show that the resulting algorithm is able to effectively exploit the problem-knowledge associated with the QMKP requirements, but that it is competitive with the state-of-the-art approaches to this problem.The rest of the article is structured as follows. In Section 2, we introduce the proposed TIG algorithm. In Section 3, we describe the QMKP, the application domain in which our proposal will be analysed, and the corresponding state-of-the-art approaches to its solution. In Section 4, we present the empirical studies, which are designed to: (1) analyse the influence of the parameters and settings associated with our proposal and the benefits derived from the application of the tabu-enhanced destruction mechanism, (2) compare the results of a tuned TIG instance with those of other approaches from the literature, and (3) detect the algorithmic components that effectively exploit the problem-knowledge associated with the QMKP. Finally, in Section 5, we discuss conclusions and further work.We describe the proposed approach, TIG, which is an improved IG model applying a new destruction mechanism with a tabu list. The general description of the complete algorithm is presented in Section 2.1, and the motivation for tabu-enhanced destruction mechanism in Section 2.2.Fig. 1depicts the outline of an IG algorithm slightly adapted to apply the tabu-enhanced destruction mechanism. IG search starts from a single complete initial solution usually constructed from scratch by a greedy procedure (steps 1–3). Then, it iterates through a main loop in which first a partial solution Sdis obtained at the destruction phase (step 6), and second a complete candidate solution Scis reconstructed by applying the greedy procedure to Sd(construction phase, step 7). A local search phase is added to improve the constructed solutions (steps 3 and 8). Before continuing with the next iteration, an acceptance criterion decides whether the solution returned by the local search procedure, Sls, becomes the new current solution (step 12). The process iterates until some termination conditions have been met (e.g. maximum number of iterations, or maximum computation time allotted). The best solution, Sb, generated during the iterative process is kept as the overall result.The specific features of the TIG method are:•A novel tabu-enhanced destruction mechanism (Section 2.2) is invoked at the destruction phase (step 6).We have explored the following two acceptance criteria:–Replace if better acceptance criterion (RB): The new solution is accepted only if it provides a better objective function value (Ying & Cheng, 2010).Random walk acceptance criterion (RW): An IG algorithm using the RB acceptance criterion may lead to the stagnation of the search due to insufficient diversification (Lozano et al., 2011; Ruiz & Stützle, 2007). At the opposite extreme is the random walk acceptance criterion, which always applies the destruction phase to the most recently visited solution, irrespective of its objective function value. This criterion clearly favours diversification over intensification, because it promotes a stochastic search in the space of local optima.The greedy procedure, which provides the initial solution and reconstructs partial ones (steps 2 and 7, respectively), is specific to the problem at hand. For the QMKP we apply the approach proposed by Hiley and Julstrom (2006) (Section 3.2).For the local search phase, we have investigated four specific improvement methods for the QMKP (described in Section 3.3). Two are from the literature and the two others are new. They are all based on exchanging objects from different knapsacks.The destruction phase of the IG algorithm provides starting points for the construction phase, so that the search samples a variety of points in the search space. In its simplest form, destruction removes random components from the current solution (Ruiz & Stützle, 2007, 2008; Ying, 2008), though more elaborate procedures are possible. For example, Fanjul-Peyro and Ruiz (2010) proposed heuristic functions for the stochastic selection of the components to be removed for the unrelated parallel machine scheduling problem (Rodriguez, Blum, García-Martínez, & Lozano, 2012). They first defined several probability density functions for choosing a machine according to its workload, and then, jobs that could be processed faster in other machines than in that selected were considered for removal.With the aim of improving the diversification production of the IG destruction phase, we propose the application of a short-term memory that prevents recently removed elements (which are probabilistically reinserted in the construction phase) from being deleted again in subsequent iterations. Every time a component is removed from the solution at the destruction phase, the tabu-enhanced procedure marks this component in a tabu list. Only unmarked solution components are allowed to be removed at the destruction phase. The number of iterations that a component remains marked is specified by a user parameter called tabu tenure.The combination of tabu search elements with iteration methods has its beginnings in the strategic oscillation framework (Glover, 1977; Glover & Laguna, 1997), and has reported successful results in several application fields, such as binary quadratic programs (Glover, Kochenberger, & Alidaee, 1998), the multi-resource generalised assignment problem (Yagiura, Iwasaki, Ibaraki, & Glover, 2004), the maximally diverse grouping problem (Gallego, Laguna, Martí, & Duarte, 2013) and the linear ordering problem with cumulative costs (Duarte, Martí, Álvarez, & Ángel-Bello, 2012), among others. Strategic oscillation is a search strategy that, similarly to the IG model to a certain degree, operates by moves defined in relation to a critical boundary in regions of the search space that are expected to contain solutions of particular interest. This critical boundary is often associated with the problem’s constraints. One of the main differences between IG and strategic oscillation models is that the latter usually permit the critical boundary to be crossed whereas the former keep the search process within the region of feasible solutions.Fig. 2presents the pseudocode of the tabu-enhanced destruction mechanism. It receives the solution from where components are removed (S), the number of components to be removed (nd), the current state of the tabu list (Ltabu), and the tabu tenure parameter (tt); and returns the new partial solution (Sd) and the new state of Ltabu. Select-Unmarked-Component(Sd, Ltabu) (step 6) chooses a component of the solution that is not marked in the short-term memory Ltabu. Function Mark-Component(Ltabu, j, tt) (step 8) marks component j in the short-term memory and sets its tabu tenure to the value tt. Finally, function Reduce-Tenure(Ltabu, i) (step 2) decrements the tenure value of component i in one.The number of possible partial solutions that can be sampled from a complete candidate is equal to the binomial coefficientCn-|Ltabu|nd, which is the number of ways, disregarding order, that ndelements can be extracted from among (n−∣Ltabu∣) non-tabu components (with nd⩽n−∣Ltabu∣). Bearing in mind the direct correspondence between the value of parameter tt and ∣Ltabu∣, once Ltabucontains the first tt elements, we realise that ndand tt have a clear influence on the number of distinct partial solutions that can be sampled from the same complete one, which is the binomial coefficientCn-ttnd. Some comments are necessary in regard to the diversification provided by this mechanism. The possibility of sampling from a greater set of possible partial solutions enables the algorithm to increase its diversifying characteristics, and the size of this set is greater with higher nd(in the range [0, ⌊(n−tt)/2⌋]) and lower tt settings. Furthermore, moderate tt values greater than 0 force the algorithm to lead the process to different regions of the space of partial solutions, by preventing previously removed elements from being extracted. The effect is that diversification is probabilistically increased by this guided sampling, which reduces the number of possible partial solutions. Then, the interaction between parameter tt and nddetermines the diversification that is promoted by the destruction mechanism: higher ndvalues, in the aforementioned range, are expected to promote more diversification, but its effect can be elevated, with moderate tt values greater than 0, or reduced, with larger settings.In the QMKP (Hiley & Julstrom, 2006), we are given a set of n objects and K knapsacks. Each object i∈{1,2,…,n} has a profit piand a weight wi, each pair of objects (i and j) has a profit pij, and each knapsack k∈{1,2,…,K} has a capacity Ck. Objects and knapsacks will be referred to by their index positions in order to keep the notation as uncomplicated as possible. The profit pijassociated with the pair of objects i and j is added to the total profit if both i and j belong to the same knapsack. The objective is to allocate each object to at most one knapsack in such a way that the total weight of the objects in each knapsack k does not exceed its capacity Ckand the total profit of all the objects included in the knapsacks is maximised. Formally, given the binary variables xik, which indicate whether the object i is included in the knapsack k, the QMKP is formulated as:(1)Maximise∑i=1n∑k=1Kxikpi+∑i=1n-1∑j=i+1n∑k=1Kxikxjkpij,(2)subjectto∑i=1nxikwi⩽Ck,∀k∈{1,2,…,K},(3)and∑i=1Kxik⩽1,∀i∈{1,2,…,n}.QMKP cases arise in real-world situations where resources with different levels of interaction among themselves have to be distributed to different tasks, for instance, assigning team members (potentials are considered both individually and in pairs) to different projects. The QMKP is an extension of two well known combinatorial optimisation problems, the multiple knapsack problem and the quadratic knapsack problem. As with its predecessors and many other knapsack problems (Florios, Mavrotas, & Diakoulaki, 2010; Leâo, Santos, Hoto, & Arenales, 2011; Sbihi, 2010), the QMKP is NP-hard (Hiley & Julstrom, 2006).Hiley and Julstrom (2006) were the first to study this problem and they proposed three approaches to its solution: a greedy heuristic (commented upon in Section 3.2), which was able to provide feasible solutions from scratch; a hill-climbing method that consisted of removing some random objects from their corresponding knapsacks and applying the mentioned greedy heuristic to refill the solution; and a generational genetic algorithm. This latter comprised a population of solutions that were initialised by assigning iteratively objects to random knapsacks that could accommodate them. Afterwards, binary tournament selection and mutation and crossover operators were executed iteratively according to a crossover probability parameter. The mutation removed two random objects from their knapsacks and applied the greedy heuristic, and the crossover first copied into the offspring all the object assignments common to its two parents and then considered all the remaining objects in a random order for the knapsacks that could accommodate them. The best solution was preserved through the iterations.Singh and Baghel (2007) addressed the QMKP with a grouping genetic algorithm. It was a steady-state model in which crossover and mutation produced a single child at each iteration (in a mutually exclusive manner), which replaced the least fit member of the population. Solutions were encoded as a set of knapsacks and multiple copies of the same solution were avoided by checking new ones against the existing population members. Initial solutions were created by the greedy heuristic in Hiley and Julstrom (2006) (Section 3.2), but assigning a random object to an arbitrary knapsack. Binary tournament was applied. The crossover operator iteratively selected one of the two parents, assigned the knapsack with the largest profit value to the child, and updated the remaining knapsacks in both parents; then unassigned objects were included in the knapsacks without violating their capacity constraints. Mutation removed some objects from knapsacks and refilled them randomly.Saraç and Sipahioglu (2007) proposed another genetic algorithm. Initial solutions were generated by assigning random objects whose weights were smaller than the remaining capacity of the current knapsack, from the one with the smallest capacity to that with the largest. Binary tournament was applied to allow solutions to be copied to the next generation. The crossover operator interchanged the object assignments between two randomly selected parents. When a knapsack capacity was exceeded because of this interchange, the object was removed from the knapsack. Subsequently, unassigned objects were considered according to a heuristic rule (Hiley & Julstrom, 2006). Two mutation operators were included. One of them removed four objects from their knapsacks and refilled the solution, and the other tested interchanging objects assigned to different knapsacks. Elitism was applied to maintain the best solution from one generation to another.Currently, the state-of-the-art for the QMKP is an artificial bee colony algorithm with local search presented by Sundar and Singh (2010). Bees were classified into employed, scouts and onlookers, and exploited food sources that represented solutions to the problem. Initially, each employed bee was associated with a randomly generated food source (candidate solution) generated in a manner similar to Singh and Baghel (2007). During each iteration, each employed bee determined a new food source in the neighbourhood of its currently associated food source and computed its nectar amount (fitness). If the nectar amount was higher than that of its current food source, the employed bee moved to the new food source, abandoning the old one, otherwise it continued with the old one. Subsequently, onlookers chose one of the food sources associated with employed bees by means of binary tournament selection, and determined a new food source in the neighbourhood that replaced the selected one if it was better. When a food source was not improved over a predetermined number of iterations, the associated employed bee abandoned it to become a scout. This scout drew a new random solution and became an employed bee associated with it. When exploring the neighbourhood of food sources, bees applied a knapsack replacement procedure between two solutions with a specific probability or otherwise a heuristic perturbation operator. An improvement method (described in Section 3.3) was executed when the difference between the fitness of the global best solution and the current one was inferior to a prespecified threshold. The artificial bee colony algorithm presented by Sundar and Singh was compared with the approaches mentioned above, obtaining better results in almost all the considered problem instances.Hiley and Julstrom (2006) described a greedy constructive algorithm, which might be used to build feasible solutions for the QMKP. We firstly define the contribution (Δ(i, k)) and density (D(i, k)) of an object i with regards to knapsack k∈{1,…,K}, as the sum of profit values associated with the object i and those already in the knapsack k, and its division by the weight of object i, respectively:(4)Δ(i,k)=pi+∑j∈kpij,(5)D(i,k)=Δ(i,k)/wi.The greedy construction algorithm consists of performing iteratively the assignment of object i, from those not allocated to any knapsack yet, to knapsack k, maximising the value D(i, k) and subject towi+∑j∈kwj⩽Ck. This process is repeated until there is no other object with Δ(i, k)⩾0 that fits into any knapsack k. At each insertion, the fitness of the new solution is efficiently computed by adding up the corresponding contribution value Δ(i, k):(6)f(S′)=f(S)+Δ(i,k).Sundar and Singh (2010) proposed the application of a local search method that looked for an exchange between an unassigned object i and another j, already inside knapsack k, so that the exchange improved the solution quality (Δex(i, j)>0) without violating the knapsack’s capacity:(7)Δex(i,j)=Δ(i,k)-Δ(j,k)-pij,subjecttowi-wj+∑l∈kwl⩽Ck.As soon as a profitable exchange was found, the local search performed that exchange, i.e., it implemented a first-improvement strategy. This local search is referred to as FirstLS. We also consider the application of the best-improvement strategy that searches for the pair of objects (i, j) that maximises Δex(i, j). The corresponding improvement method is referenced as BestLS.We have designed two other local search methods that consider the exchange of any two objects, whether they are assigned to a knapsack or not. We expect this to be beneficial for the QMKP because it considers additional possibilities that previous local optimisers do not, in particular, the case of exchanging two objects that are already included in two different knapsacks. We then define the following exchange contribution metricΔex∗(i,j), which is general for any of the following cases:•Exchanging two unassigned objects without effectΔex∗(i,j)=0.Exchanging two objects assigned to the same knapsack without effect (Δex∗(i,j)=0).Exchanging an unassigned object and another included in a knapsack (Δex∗(i,j)=Δex(i,j)).Exchanging two objects assigned to two different knapsacks (i and j from knapsacks k1 and k2, respectively). Here the contribution is composed of the contribution of object i in k2, plus the contribution of object j in k1, minus their contributions in k1 and k2, respectively, minus twice the profit of the pair (i, j).Hiley and Julstrom (2006) described another hill-climbing method that removed a number of random objects from each knapsack and then refilled the knapsacks in a random order. Since the described procedure is somewhat similar to the basic operation of IG algorithms, this method has not been considered among the studied local search approaches.

@&#CONCLUSIONS@&#
We have proposed a tabu-enhanced destruction mechanism that improves the operation of standard IG algorithms with the production of diverse partial solutions. It makes use of a short-term memory that marks the components recently removed from the current solution and prevents the destruction mechanism from selecting them for removal in subsequent iterations. We have considered the QMKP as the application domain, for which a novel local search operator has been designed, and the influence of the different parameters and strategies of TIG have been analysed. From the experiments carried out, we have concluded that the proposed tabu destruction mechanism provides advantages to the IG algorithm in comparison to the standard destruction approach. Moreover, we have compared the results of the final proposal with those from the literature for the QMKP, showing that the TIG model is competitive with the state-of-the-art algorithms, emerging as the tool of choice for this problem. Finally, we have analysed the algorithmic components of the proposal, with regard to other IG versions and competitive general-purpose methods, in order to ensure that the TIG algorithm was able to effectively exploit the problem-knowledge associated with the requirements of the QMKP.We believe that the Tabu-enhanced IG framework presented is a significant contribution, worthy of future study. We intend to explore two interesting avenues of research: (1) to adapt the TIG approach for its application to other challenging combinatorial problems, such as the demand-constrained multi-dimensional knapsack problem and (2) to build hybrid metaheuristics combining the proposed TIG model with other salient approaches for the QMKP (e.g., artificial bee colony algorithms), or classic models (e.g., applying a simulated annealing strategy as acceptance criterion).