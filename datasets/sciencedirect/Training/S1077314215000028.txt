@&#MAIN-TITLE@&#
A comprehensive overview of methodologies and performance evaluation frameworks in 3D mesh segmentation

@&#HIGHLIGHTS@&#
An overview of the state-of-the-art in 3D mesh segmentation.An overview of performance evaluation frameworks for 3D mesh segmentation.New categorization for 3D mesh segmentation methodologies.Pros and cons in performance evaluation frameworks.

@&#KEYPHRASES@&#
3D mesh segmentation,3D shape analysis,3D object representation,

@&#ABSTRACT@&#
3D mesh segmentation has become a crucial part of many applications in 3D shape analysis. In this paper, a comprehensive survey on 3D mesh segmentation methods is presented. Analysis of the existing methodologies is addressed taking into account a new categorization along with the performance evaluation frameworks which aim to support meaningful benchmarks not only qualitatively but also in a quantitative manner. This survey aims to capture the essence of current trends in 3D mesh segmentation.

@&#INTRODUCTION@&#
The constant increase in the availability of 3D digital objects has induced interest in 3D shape analysis algorithms, for which 3D mesh segmentation is considered as one of the most challenging goals. 3D mesh segmentation can be defined as the partition of a 3D mesh into sub-meshes. LetM=(V,F,E)be a 3D mesh, defined as a collection of vertices V, faces F, and edges E. Mesh segmentation partitions the set V or the set F into disjoint subsets.3D mesh segmentation is addressed in a plethora of applications. For example in reverse engineering applications which deal with reconstructing a CAD model from input originating from a laser scanner, there exists a need for 3D mesh segmentation into a set of regions, such that each region can be approximated by a surface. A recent application of 3D mesh segmentation is Component-Based Shape Synthesis [1], which makes use of segmentation and labeling to produce new models by transferring corresponding segments from one model to the others. Other applications of segmentation are style transfer [2], modeling by example [3], modeling from interchangeable parts [4], 3D scene analysis [5], part-based recognition [6], 3D video compression [7] and 3D object retrieval [8,9]. The segmentation algorithms are often driven by the context of the associated application.In this paper, we aim to provide a comprehensive overview of the existing frameworks for 3D mesh segmentation. Previous surveys have been reported in [10,11]. We enhance previous categorizations by new trends and goals, e.g. motion-based segmentation, and couple the methodological part with the existing performance evaluation frameworks. Last but not least, we conclude with a fruitful discussion on the current problems and future challenges.The remainder of the paper is structured as follows: In Section 2, key aspects on 3D mesh segmentation methodologies are given, Section 3 is dedicated to presenting an overview of the existing methodologies after a meaningful categorization, while Section 4 details existing performance evaluation frameworks. Section 5 presents an in-depth comparative discussion, and finally, conclusions are drawn in Section 6.3D mesh segmentation is not a simple task. Several methodological frameworks have been developed to address the underlying challenge. The existing frameworks have been structured in a way that takes into account key aspects, i.e. goal (surface-type vs. part-type), type of geometric criteria (region-based vs. boundary-based), degree of learning (supervised vs. unsupervised), user involvement (automatic vs. interactive), number of objects used as information sources (single vs. multiple), type of features (geometric vs. structural), and finally the granularity of the produced result (hierarchical vs. non-hierarchical). In the sequel, a discussion of the aforementioned key aspects is given.A common discrimination is made between surface-type and part-type methods. Surface-type segmentation partitions the object into meaningful surface primitives, while part-type segmentation segments the object into meaningful parts (Fig. 1). The goal of the segmentation often relates to the type of attributes used. Surface-type segmentation handles the object as a surface and employs only surface-related attributes, while part-type methodologies employ both volumetric and surface attributes to achieve their objective.There are two types of geometric criteria considered, from which two approaches derive. The first, region-based criteria, consider the geometric uniformity among elements of the same segment. Humans tend to divide an object into segments that have some similar property. This property can be diameter, curvature, similarity to a primitive shape, etc. The second type, boundary-based criteria, consider the detection of a 3D object’s segment boundaries. Usually boundaries lie on ridges that represent sharp curvature transitions. The existing methods follow one of the two approaches, or combine both. Most boundary-based criteria of part-type methodologies attempt to quantify the minima rule [12], which states that humans tend to recognize distinct meaningful parts as those that are bounded by lines of minimum negative curvature. Due to the adoption of the minima rule by the overwhelming majority of methodologies, boundary criteria are consistently used. A common technique is the use of region criteria in order to produce a rough estimate of the final segmentation, and the use of boundary criteria as a post-processing step in order to optimize boundaries between already formed regions.Another key aspect among 3D mesh segmentation methods concerns the ability to extract the inherent hierarchical structure of the object, depending on the criteria used. This is aligned perfectly with human perception, because the detail of the parts is not always obvious in many applications or objects. Hierarchical methods (agglomerative or divisive) have the additional information of the hierarchy that produces each part; non-hierarchical methods lack this information. For a divisive methodology the segmentation would be performed in stages with most significant parts extracted at each level. For instance, an approach for the first level segmentation of a human could be the extraction of limb regions first. At the second level the partition would continue by partitioning the limbs on joints. The iteration should break according to some criteria or if the user specifies the desirable level of segmentation.In the case of Supervised Learning the method learns from a number of already segmented and labeled objects, which can be found in the existing ground-truth datasets. The concept of learning could involve the idea of labeling, which is the characterization of a segment with a label. The term semi-supervised implies that the method learns from both labeled models and unlabeled ones. In the unsupervised setting, the segmentation methodologies use only low level information without any prior knowledge.Most mesh segmentation methods partition a single object without any additional knowledge. This problem is challenging and the method has to predict the criteria to use in order to produce a successful segmentation. However, it is common for state-of-the-art methods to use information from multiple meshes. This can yield significantly better results. Multiple information sources can arise in: (i) the use of already manually segmented meshes for training (supervised methods) and (ii) the simultaneous segmentation of objects of the same class by finding correspondences between them (co-segmentation).Another classification of 3D mesh segmentation is between topological and geometric methods. The latter focus on identifying parts that are homogeneous regions with the same geometric attributes (diameter, curvature, proximity to a primitive shape, etc.), while the former focus on analyzing the object in a structural (topological) way. Geometric similarity is not enough, and sometimes misleading, for the characterization of two parts as semantically equivalent (Fig. 2). A detailed report of structural methodologies can be found in [13].A critical point in mesh segmentation methods is whether they require user input to segment an object. A lot of methods are fully automatic and no user input is required. However, frequently a set of parameters need to be provided by the user, e.g. the number of segments, the hierarchical levels, a threshold to control the detail of the segmentation, etc. Moreover, some fully interactive applications have been developed, in which the desirable segmentation is produced by the user. There are two main approaches in interactive methods. The first is boundary-based, in which the user clicks on the area which he considers boundary. The method then makes a cut on the mesh based on geometric criteria. The second approach is region-based, in which the user distinguishes two regions that he wishes to be in separate segments. The method then produces the segments usually in a region growing manner.In this section, we present the state-of-the art in mesh segmentation methods, after a grouping which relies on the core technique used. In particular, ten variations of methodological frameworks are presented:•Segmentation based on clusteringSegmentation based on region growingSegmentation based on surface fittingSegmentation based on topologySegmentation based on spatial subdivisionSegmentation based on spectral analysisSegmentation based on boundary detectionSegmentation based on motion characteristicsSegmentation based on probabilistic modelsCo-segmentationWe comment here that although we have grouped the methods according to the main approach they use, a lot of methods have elements which can be attributed to more than one group, e.g. co-segmentation methodologies which use spectral analysis. We avoid adopting the classification of [11] since we attempt to include each methodology in a general framework, instead of surveying the mesh segmentation techniques themselves. However, within each category, the techniques used are discussed along with the attributes and any other common feature.A popular way to address the problem of 3D mesh segmentation is to assign each face or vertex to the nearest segment based on a clustering technique. The core of methods of this category is the calculation of the distance of each node to the cluster centroid, since the mesh graph structure is taken into account. A common approach is defining a weight between adjacent nodes and calculating the distance of each node to a predefined set of seeds or representatives of the final clusters. The location of the seed points is usually determined by maximizing the total pairwise distance between them. The number of representatives is usually provided by the user or guessed heuristically. Each face then is assigned to the segment, which corresponds to the minimum distance to the seed point, calculated as a traversal cost passing through neighboring nodes to reach the destination. Let M denote the mesh,nian element, face or vertex, assigned to segmentSiin a segmentationS={S1,S2,…,SN}. The goal is to minimize the following energy function:(1)E=∑Si∈M∑nj∈SiDistance(nj,seedi)At a glance in Table 1we can divide clustering methodologies into iterative and direct techniques. In iterative techniques the seeds are recalculated at each iteration and the clustering is performed based on the new distances (k-means [15]), while in direct techniques the initial assignment will determine the final segmentation. The attributes used in the calculation of the distance are angles and geodesic distance. Some methodologies assign an extra weight to concave edges. Since most methodologies included in this category use geodesic distance to determine clusters, they are best suited for segmentation into large components, while they usually fail to identify small details.The work in [16] defines a distance between adjacent facesfiandfj:(2)D(fi,fj)=1-δ1-cos2θij+δ·geod(fi,fj)whereθijis the dihedral angle corresponding to the two faces andgeod(fi,fj)is the geodesic distance between the two faces’ barycenters. One seed is placed in the face which is closer to the barycenter of each disconnected component of the mesh. The farthest faces are added to the seed faces iteratively until a target number is reached. Each face is assigned to the nearest cluster, new representatives are chosen and faces are reassigned until convergence.The method in [17] defines weights in the dual graph of a mesh between adjacent facesfiandfjcombining the concavity weightConc(fi,fj)in Eq. (A.1) with a geodesic term:(3)Dfi,fj=δ·geod(fi,fj)avg(geod)+(1-δ)·Conc(fi,fj)avg(Conc)whereδcontrols the contribution of each term andgeod(fi,fj)denotes the geodesic distance between the centers of two adjacent faces. Seed faces are strategically added until adding a new one decreases dramatically the sum of the distances between each other. Each face is assigned to the closest seed, while some faces remain fuzzy. The boundary will lie on the fuzzy region. The final cut is determined by applying a minimum cut/maximum flow algorithm [18] in the fuzzy region (Fig. 3).The first step of the method in [19] is the clustering of the mesh normals with the mean shift algorithm [21,22]. The adaptive mesh smoothing technique [23] is applied to the clustered normals to perform a filtering. This filtering succeeds in making the algorithm robust to local noise. A seed triangle is chosen randomly. If the target number of segments is not reached, the farthest triangle is added as seed iteratively. A distance is defined between two trianglesfi,fjwith respect to the mean shift filtered normalsNmi,Nmj:(4)D(fi,fj)=||Nmi-Nmj||Dijkstra’s algorithm using the above distance determines the closest seed to each triangle. At each iteration a seed is recalculated for each segment as the geodesic center of the patch.The work in [4] describes a method of swapping components between objects (Fig. 4). For this purpose a mesh segmentation methodology is introduced using a measure based on both convexity, as the sum of distances of a part to its convex hull, and compactness, as the area to volume ratio of its convex hull. The method uses Lloyd’s algorithm to partition hierarchically the mesh based on the above measure.In [20]n faces are picked as seeds. A distance is defined between two adjacent faces using the concavity weight Conc of Eq. (A.1):(5)D(fi,fj)=Conc(fi,fj)avg(Conc)whereavg(Conc)denotes the average concavity weight. A probabilityP(ei,j)is associated with each edgeei,jrespecting Eq. (5), representing the probability that a random walk will pass through this edge:(6)P(ei,j)=|ei,j|·exp-d(fi,fj)where|ei,j|denotes the length of the edgeei,j. The probabilities are then normalized for each face so that they sum to one. Each face is assigned to the cluster that yields the largest probability that a random walk will arrive to the seed face. To automatically segment an object, seeds are sampled so that distance between them remains large enough. The object is over-segmented and the final segmentation is a result of iteratively merging adjacent parts using a cost based on common boundary length.Region growing is one of the earliest techniques used for 3D mesh segmentation. Methods first assign each vertex or face an attribute value, usually curvature. A number of seed points are selected, in most cases local extrema, and these seed points are expanded until some termination points are met. Although in most cases region growing is combined with curvature, the result of such methodologies highly depends on the attributes used and the termination criteria. Unlike Clustering methodologies, region growing does not favor segmentation into large parts. Nevertheless, the initial seed selection is more important than in Clustering, since seeds do not change. Bad seed selection is usually corrected by a post-processing merging stage.The work in [24] describes a region growing segmentation method, which relies on the minima rule. The method is based on the Fast Marching method for geodesics [25] using the two principal curvaturesKmax,Kmin. TheKminvalues are used to divide the vertices into two clusters (boundary, with negativeKmin, or not). The segmentation is performed using a hill climbing algorithm, originating from vertices with non boundary vertices, which favors propagation to vertices with similar curvature and avoids climbing across negative curvature regions. In particular the directional cost from vertex j to vertex i is defined as:(7)Wji=Kmaxcos2θj+Kminsin2θjwhereθjis the angle between the tangent unit vector and the maximum principal direction at vertex j. One drawback mentioned by the authors is that the method requires that two segments are completely separated by large values of negative minimum curvature in order to be efficient.The algorithm in [26] uses the absolute values of the maximum and minimum principal curvature in order to segment CAD models into regions of similar curvature. Firstly, a pre-processing step identifies sharp vertices. Vertices are clustered using k-means, based on the absolute values of principal curvature|Kmin|and|Kmax|. Adjacent triangles of the same cluster that do not share a sharp edge are merged, forming regions of similar curvature. The resulting regions are merged based on a region merging distance, which favors merging of small regions, regions that have a large common border and regions who have similar average curvature. This iterative process continues until a target number of segments is reached, or if the smallest occurring merging distance between adjacent regions surpasses a threshold (Fig. 5).The method [27] defines the following weight for each edge(i,j)of the dual graph of the mesh:(8)W(i,j)=1-Ni→·Nj→||pi-pj||where·denotes the dot product and||·||the Euclidean norm.Ni→is the normal andpithe barycenter of face i. The method requires some hints provided by the user. Some faces are manually characterized as positive, which indicates that they belong to the segment of interest, while other faces are manually characterized as negative, not belonging to the segment. Nodes of the graph are added either to the positive or to the negative cluster in a greedy region growing manner, where the face i with the minimum weightW(i,j)to an assigned face j is added first. Segmentation is performed in a simple direct manner but in need of hints by the user.Some of the earliest approaches in 3D mesh segmentation involve approximation of 3D objects with known surfaces. The observation that most object parts can be approximated by a primitive shape or a high order surface lead to significant amount of work in that direction. Most surface-type methodologies belong to this category. Surface fitting is mostly applicable to mechanical CAD objects. However, [28] demonstrated that natural objects can also be approximated in a hierarchical way with cylinders. This could as well result in an intuitive, part-type segmentation using surface-type criteria. We could distinguish between greedy methodologies, where clusters can only expand or merge (agglomerative clustering), and global error minimization methodologies in which triangles can switch between clusters at each iteration (Lloyd’s algorithm, variational). In the latter fitting errors are recalculated and triangles are assigned to the closest segment minimizing a total error function, while in greedy approaches triangles cannot change cluster after being assigned to one. In global error minimization approaches, however, an initialization is necessary, which often dictates that the number of clusters have to be provided in advance. Most methods use as a fitting error the sum of Euclidean distances of each mesh triangle or vertex to the respective points of the approximated surface. In some cases the distance between normals of mapped points is considered, while in others both error metrics are combined (see Table 2).The method in [29] segments a mesh into planar regions approximating its surface with little distortion. Thus a mesh is represented by less information without losing its shape. A plane is represented by an average point P and a normalN→. Two fitting error metrics are considered: the EuclideanL2and the normal-basedL2,1. Let R denote a region as a set of triangles andp=(P,N→)denote an approximated plane. The termprojp(x)denotes the orthogonal projection of x on p, whileNx→denotes the normal vector on x.(9)L2(R,p)=∫x∈R||x-projp(x)||2dx(10)L2,1(R,p)=∫x∈R||N→-Nx→||2dxNotice that the integration over the whole surface instead of summing the error of each triangle makes the method robust to irregular tessellation. The best fitting proxies all over the mesh are the ones that minimize the sum of errors of all proxies. The minimization of the total error is achieved in a variational manner by extending Lloyd’s algorithm.The methodology in [32] extends the variational surface fitting approach of [29] by using planes, spheres, cylinders and blending surfaces. The distance measure is similarly either theL2or theL2,1.The segmentation algorithm in [31] aims at segmenting noisy meshes created by range scans using surface approximation. After calculating mean and Gaussian curvature values at each vertex, curvatures are smoothed using both mean and median filters. Large regions with vertices having the same sign of both curvatures are shrunk to a limit and form seeds for a region growing step, while concave edges are excluded. The seed regions are expanded with the criterion that the resulting regions approximate a bicubic Bézier surface. Errors in normal angles and in position are used to determine if a vertex fits to an already formed region.The method in [28] segments the object into parts that can be approximated by a patch having a primitive shape (Fig. 6). Given a set of faces, the goal is to find the primitive that fits best along the surface. Three primitive surfaces are considered: cylinder, sphere and plane. To determine which primitive is the best fit, anL2error is calculated for each of the three possible options. The segmentation is performed in an agglomerative clustering manner.The work in [30] describes a mesh segmentation method for the purpose of texture atlas generation. The goal is to segment an object into developable surfaces, which approximate groups of conic sections that share the same axis. A modified version of the Lloyd’s algorithm [15] is used to segment the object into surfaces based on a cost function, which combines surface fitting error with a cost favoring round shaped segments and smooth boundaries. After convergence of the Lloyd iterations the unassigned triangles are assigned to a cluster or form new ones, boundaries are smoothed with a min cut algorithm, and adjacent segments are merged if the Gaussian curvature along their boundary is zero.The method in [33] uses the same approach as [29]. However, it combines both error definitions Eqs. (9) and (10) into one Eq. (11), withωbeing a constant:(11)E(R,p)=L2,1(R,p)+ωL2(R,p)while it extends the idea to quadric surfaces. In addition, a boundary smoothing step is proposed with the fuzzy mincut algorithm [17]. The fitting errors to adjacent regions determine the probability of each triangle to be assigned to either region, while the weight for each dual edge(i,j)is:(12)w(i,j)=length(i,j)length(i,j)+avg_length(i,j)wherelength(i,j)denotes the length of edge(i,j)andavg_lengththe average edge length of the mesh. The above weight (12) succeeds in minimizing the total length of the boundary and does not concern with concavity, since it is a surface-type methodology.Methods based on topology are mainly suited for articulated objects. The idea is that the topology of a feature comprises higher level information as well as a more suitable segmentation criterion than the feature itself. It is of crucial importance to define here the Average Geodesic Distance function Eq. (13)[34], which is nearly pose invariant, and succeeds in identifying protrusive parts of the object. The average geodesic distance of a nodenito all the other N nodes of the mesh can be expressed as follows:(13)AGD(ni)=1N∑j=1Ngeod(ni,nj)wheregeod(ni,nj)denotes the geodesic distance between nodesniandnj. This function is widely used in the construction of Reeb Graphs.A Reeb graph is constructed by defining a real continuous function on the mesh to divide it into equivalence classes [35]. Two points must have the same function value and have a path of points with the same value connecting them in order to be in the same equivalence class. The most frequent function used is the AGD. The Reeb graph is typically constructed by quantizing the function values. The common procedure used in Reeb graph-based mesh segmentation frameworks is merging the nodes of the Reeb graph with respect to their degree. For instance nodes having degree 2 or less would have to be merged together representing a tubular part of the object. These methods rely heavily on the selection of the function, different functions would result in a completely different graph. Typically, in the merging stage concave regions are considered in order to align the result with the minima rule.In [36] geodesic extrema of the mesh are extracted with the Tree Diameter algorithm [37] and are characterized as feature points. The mesh is divided into regions of similar geodesic distance to the closest feature point. In addition to the geodesic distance, a concavity-based distance based on curvature index [38] is defined in order to add additional weight in areas with negative Gaussian curvature. This step leads to the construction of the Reeb Graph of the 3D object, using as function the combined curvature and geodesic distance of each vertex to the closest feature point. A merging stage follows based on the degree and the average Gaussian curvature of each node (Fig. 7). The authors describe as well an application of this approach in a hierarchical manner.The method in [39] divides the surface of the mesh using the AGD resulting in a Reeb graph representation of the mesh. Adjacent regions with the same number of neighboring regions are merged. The final decomposition is optimized by adjusting the boundaries of segments with the minimization of an energy function using a gradient descent algorithm. The function ensures that the final boundary will reside close to the original one as well as it will have a small minimum curvature value.In these methods an assumption is made that objects consist of a core segment and limbs, which are all connected to the core and not to each other. Consequently, locating the boundaries of the core should be enough to produce the segmentation. However, the methods fail to deal with objects whose part topology does not follow this convention. The first step of these methods is the location of feature points, usually on geodesic extrema, using the AGD function [34]. These feature points represent protrusive parts and the goal is to separate them from the core segment. A region growing technique from the feature points towards the core or vice versa should be enough to produce a successful segmentation.The method in [40] represents the mesh in a pose invariant way using Multi-Dimensional-Scaling (MDS). Geodesic feature points are located using the AGD function, as well as satisfying the constraint to reside on the convex hull of the transformed object. The next step is the location of the core partition. Each vertex n is transformed using the spherical mirroring technique.(14)nmirror=n+2R-||n-C||n-C||n-C||where R and C are the center and the radius of the bounding sphere of the mesh. The above transformation succeeds in making the vertices of the core partition external so that they can be extracted. Vertices on the convex hull of the mirrored object and the faces they define on the original object form an initial core segment. This segment then grows until all other segments are separated or a threshold is surpassed (Fig. 8). Last step of the algorithm is the refinement of the boundaries between partitions using minimum graph cuts.In [41] after the location of feature points as geodesic maxima, the approximation of the object core is performed. The core is expanded in a region growing manner, with respect to the AGD value of each vertex. The boundary between a feature point and the core will lie between isolines of the geodesic function where significant variation in the perimeter occurs. Finally, a minimum cut algorithm is employed in the same manner as [17] to refine the boundaries.In methodologies based on spatial subdivision, the objects are hierarchically subdivided based on multi-scale volumetric attributes at the part level. In [42] varying scales of the structuring element of the opening morphology operation are used, while in [43] multiple spheres of increasing radii intersect with the object. In [44] bounding boxes of the parts are used. The effect of methods in this category depends on the criteria used, which is convexity for [42,44] and diameter for [43]. Since these methodologies subdivide volume, they are not suitable for segmenting a surface that does not represent a volume.The method in [42] performs a voxelization of the object as a preprocessing step. First the opening operation of mathematical morphology is performed to the 3D binary image of voxels representing the object. This operation results in a decomposition of the object by rounding its corners. Multiple decompositions are produced by alternating the radius of the ball shaped structuring element by which the opening is calculated. The best segmentation is selected as the one that yields the highest convexity, which is the sum of the convexity value of all parts weighted by their normalized volume. The process is repeated hierarchically and finally adjacent parts are merged based on convexity in a post-processing step (Fig. 9).Plumber [43] can be used to locate tubular parts of an object. The idea is that an intersection of a tube with a sphere of the appropriate radius will result in exactly two closed curves. Regions with 2 intersections with a sphere of a certain radius are expanded until 3 or more intersections are found or an already visited area is encountered. Spheres with increasing radii are used to characterize the whole area of the mesh.The method in [44] hierarchically divides the object into two parts that have maximum convexity. The Minimum Volume Bounding Box (MVBB) [45] of a part is used as a measure of convexity. The problem can be reduced to finding the best split of a box, i.e. the division which results in two new bounding boxes with the minimum summed volume. The procedure iterates until the overall volume decrease is not significant (Fig. 10).Spectral analysis is gaining popularity among researchers in the field of 3D mesh segmentation, mostly because it can highlight global shape properties using local relations. Spectral methods make use of the eigenvalues and eigenvectors of a properly constructed square matrix, which is informative of local geometric attributes of a mesh. A comprehensive survey of spectral analysis methodologies can be found in [46]. Generally the eigenfunctions and eigenvalues of a LaplacianΔon a manifold surface are pairs of solutions of the Helmholtz equation:(15)Δu=-λuWe can divide spectral analysis techniques in mesh processing into two categories based on the definition ofΔin Eq. (15):The discrete setting. For the discrete setting, the graph representation of the mesh is used, thus define the Graph Laplacian or Laplacian matrixL, which is related to the adjacency matrix of the graph, as a N-by-N square matrix, where N is the number of nodes of the graph.(16)Lij=wij,(ni,nj)is an edge-∑j=1Nwij,i=j0,elseWe refer the reader to [46] for more variations and properties of the Laplacian. In this case Eq. (15) is transformed intoLu=-λu.The continuous setting. Generally, the Laplace operatorΔ=∇2is defined as the divergence of the gradient and measures the local deviation of a function in Euclidean space. The Laplace–Beltrami operator is the generalization of the Laplace operator for functions defined on manifolds. There are several approaches to approximate the Laplace–Beltrami operator on a mesh surface, which is not continuous [47]. A Discrete Laplace operator, however, cannot satisfy all properties of a smooth Laplacian [48]. The most popular of them is by using cotangent weights in the Laplacian of the mesh Eq. (16).(17)wij=cotθij+cotθji2whereθijandθjiare the opposite angles of the edge incident to verticesniandnj.The problem of the high complexity of the eigendecomposition of a mesh with thousands of vertices and faces can be solved with the approach described in [49]. In both settings, depending on the application, one or more eigenvectors are selected, usually the k first or last, sorted by the magnitude of the corresponding eigenvalues. These k eigenvectors form a k-dimensional feature vector for each node. The problem can be degraded to clustering the nodes based on their spectral feature with a clustering algorithm [50] like k-means. Most methodologies relate the number of segments k to the number of eigenvectors used. However, except for the eigengap criterion, which is not always reliable, the choice of k using information solely from the eigenvectors is difficult, due to their oscillatory nature. It is evident that the choice of the weights between nodes when creating the Laplacian will determine the eigenfunction values, thus the geometric property on which the weights are based on will drive the segmentation. In conclusion, in a typical spectral segmentation algorithm three issues have to be resolved (Table 3):•the choice of the type of the Laplacian or the Laplace–Beltrami operatorthe weighting scheme of the Laplacian based usually on a geometric property following the minima rulethe clustering techniqueIn the rest of the section we will use the notationsλkandukas thekth eigenvalue–eigenvector pair of the Laplace–Beltrami operatorΔ. In the sequel some attributes defined using the Laplace–Beltrami operator are presented.The Heat Kernel Signature. The heat kernel is defined as the fundamental solution of the well known heat equation on a manifold. The heat kernel measures the amount of heat transferred from nodenitonjafter time t, provided a heat unit source at nodeni:(18)H(ni,nj,t)=∑k=0∞e-λktuk(ni)uk(nj)In [55] the Heat Kernel Signature is defined as the heat kernel between a node and itself as follows:(19)HKS(n,t)=∑k=0∞e-λtuk(n)2The Diffusion Distance. In [56] the diffusion distance is defined between two pointsniandnjat a time scale t. It represents the connectivity of two points at a given scale based on the hypothesis that two points have to be considered to be close if there are a lot of paths connecting them. This is accomplished by summing the paths of all random walks starting from nodeniand ending atnjafter time t:(20)Dif2(ni,nj,t)=∑k=0∞e-λktukni-uknj2The Discrete Conformal Factor. The Discrete Conformal Factor (CF) is defined in [57]. To compute the Conformal Factor, first the Gaussian curvatureKorig(ni)is approximated on each vertex of the mesh [58]. A target Gaussian curvature is defined for each vertex as a proportion of the sum of the curvature over all verticesKT(ni)=areani∑Korig, whereareanidenotes the fraction of the total area assigned to vertexni. The Conformal Factor CF is then defined as the solution of the following equation:(21)ΔCF=KT-KorigwhereΔdenotes the discrete Laplace Beltrami operator.In the work [53] a new function is defined called the Heat Mean Signature (HMS) as the average heat transferred from a vertex to all other N vertices of the mesh.(22)HMS(ni)=1N∑j,j≠iNH(ni,nj,t)First, the number of segments C is determined by the rank of the eigenvalue that the first significant increase with respect to the previous one occurs. The next step is locating the C heat centers, or feature points, that represent the segments. The first heat center will be the point with the maximum HMS, while iteratively the most distant points are chosen, in terms of heat diffusion Eq. (18), until the target number C is reached. The segmentation is finally accomplished by employing k-means, with the heat centers updated so that they are the most distant points within a segment (Fig. 11).The diffusion distance Eq. (20) is used in the work [52]. The average diffusion distance (ADD) is computed over the whole surface of a mesh.(23)ADD(ni)=1N∑j=1NDif2(ni,nj,t)The average diffusion is recalculated within each segment, and the points with the minimum ADD values comprise the medial structure. Starting with the whole mesh as a segment its medial loop is computed. The most distant vertex to the existing medial structures, whose ADD surpasses a threshold, is added as a medial structure. Using the medial structures, new boundaries are computed by clustering the faces of the mesh based on the diffusion distance to the current medial structures. The same procedure is repeated until convergence. The algorithm can be hierarchically employed to each segment depending on user intention.The use of features based on spectral decomposition of the Laplace–Beltrami operator is known to be efficient with articulated objects. The scale parameter t depends on local geometry as it has small values, while as it gets larger, it takes into account more global geometric characteristics of the object. A heuristic is used in [52] to calculate the optimal scale for the ADD of each segmentS:t=12λ1areaSareatotalfor segmentation purposes. The heat kernel and the diffusion distance, which are defined as distances between two points, are closely related. In [55] it is proven that the level sets of HKS and ADD, which are scalar functions on a surface, coincide. All functions defined in this Section exhibit maximum values on the most distant points; for more details about the effects of each feature we refer the reader to the related works.The method in [51] uses spectral embedding to successfully segment 3D meshes. Firstly, the Laplacian matrix is constructed using the following weights:(24)Wij=|ki|+|kj|·|<e→,z→>|·lifki<0orkj<0∊otherwisewherekiandkjare the minimal principal curvatures at verticesi,j,z→is the normalized average of the principal curvature directions,e→is the normalized direction of edgee=(i,j), and l is the length of e normalized by the average length of all edges in the mesh and∊a small constant. The leading 3 eigenvectors form a 2-D representation of the mesh, since the first eigenvector is constant. The vertices are projected to the 2 eigenvectors by settingXnew=uuTXold, whereXolddenotes the coordinates of the vertices in the Euclidean space, which results in a 2-D contour. The segmentation is performed in the 2D-space. A convexity function is computed as a measure of segmentability of the contour. This 2D-projection is iteratively subdivided until it is no longer segmentable.A spectral method is described in [54] which uses the following weighting scheme for the Laplacian matrix of the mesh.(25)Wij=|e|exp-Concfi,fjwhere Conc is defined in Eq. (A.1) and|e|is the length of the common edge of facesfiandfj. The first k eigenvectors corresponding to the smallest non-zero eigenvalues define a k-dimensional function (Fig. 12). The segmentation is performed in a variational manner with the Mumford–Shah model [59] using the aforementioned function. For the calculation of the optimal number of partitions the RatioCut model (A.5)[60] is used. The RatioCut value is computed for various number of segments n. The n that yields the most sudden change in the RatioCut value decides the number of segments (n-1).The spectral segmentation method in [61] proposes a significantly different Laplacian matrix. The method is driven by the definition of convexity; a shape is convex if no line connecting two points passes through the exterior of the shape. In this spectral framework, two vertices are connected with an edge if they are mutually visible via a ray passing through the interior of the object and not intersecting with the mesh. They formulate a new definition for part convexity, as the percentage of mutually visible pairs of points out of the total possibilities. The segmentation is performed by clustering the eigenvectors with k-means, and the number of segments k is selected so that the aforementioned convexity measure is maximized.Boundary-based methods attempt to locate the boundaries of the segments instead of the segments themselves. This approach assumes that edges that lie on the boundary of two segments have similar attributes. As demonstrated by [62,63], typically boundaries will be located in concave areas of high dihedral angles, and will have common curvature-based characteristics as well as diameter (see Figs. 28 and 32). The boundary detection problem is a completely different problem than division into regions. Even though the attributes that are used are similar, mostly obeying the minima rule, the techniques are dissimilar. Boundary detection involves dividing the set of edges E of the mesh into two disjoint subsetsE={C,E⧹C}, so that the edges belonging to the cutC⊆Edivide the mesh into meaningful parts. Therefore it is a binary division problem. In addition, boundaries have to form closed contours, which should not intersect or reside close to another contour. Consequently the problem needs different treatment than vertex or face division (Table 4). A common approach for boundary detection methodologies is a voting scheme, where multiple values of a function are calculated by alternating some of the parameters or initial conditions. For the final detection of the boundary, all instances are taken into account and a score is calculated for each edge or face, depending on the occasions that it was part of a boundary.Randomized Cuts [64] is a method that computes multiple segmentations of an object (by alternating a parameter) to find the optimal solution. First, the dual graph of the input mesh is built by assigning to each mesh edge a concavity weight (Eq. (A.2)). This weight is used to calculate either a cut cost or a traversal cost for each edge (depending on the algorithm used). The method considers k-means, hierarchical clustering, or minimum graph cuts to produce segments for a given mesh. After producing a sufficient number of segmentations, the most frequent boundaries are picked for the final segmentation (Fig. 13).An interactive tool [65] follows user strokes to locate segment boundaries. The tool features a part brush and a patch brush. The part brush attempts to locate boundaries through the isolines of a harmonic field. The harmonic field is the solution of the Poisson equationΔΦ=0using the Laplace operator with cotangent weights. Following a user stroke isolines of the harmonic field produced are considered for boundaries. The best isoline is chosen considering distance from the center of the stroke and its radius. The patch brush aims to segment sharp features in a region growing greedy manner, following the user strokes. A cost of merging two faces in the same cluster during the region growing is defined:(26)wij=(1+|ϑij|)||n→i-n→j||whereϑij=n→i·e→ij||e→ij||ande→ijis an edge connecting face centers andn→iis the normal of face i. Both terms of (26) favor sharp features. To achieve robustness to noise the normals are smoothed with a gaussian filter as a preprocessing step.The work in [66] is a fully automatic method, which achieves segmentations by sampling isolines of a harmonic field, which requires two points on the mesh as boundary conditions in order to be defined (Fig. 14). The field is similar to [65], however the weighting strategy on the Laplacian matrix defines the following weight for each edge:(27)wij=|eij|·βGij+∊where|eij|is the length of the edge(i,j),Gijis the sum of the absolute Gaussian curvature at vertex i andj,∊is a small constant andβis a constant equal to 1 if the respective vertices are not concave or equal to 0.01 if either vertex is concave. Multiple fields are calculated, by using different boundary conditions and the final boundaries are selected as the field isolines with large gradient and small perimeter. The weighting scheme of Eq. (27) compared to the cotangent weights of [65] produces more isolines near the boundaries, which is crucial since this method is completely automatic, and lacks the information of the proximity of a user click.The Dot Scissor is an interactive mesh segmentation tool [67]. It requires a mouse click by the user on the mesh where a cut needs to be placed. The best cut among all possible cuts that cross the area around the mouse click is then chosen by the tool. The method is based on the concavity-aware segmentation field [66], with the difference on the weighting scheme:(28)wij=|eij|e¯cif any ofiorjis concave1otherwiseThe term|eij|denotes the edge length,e¯denotes the average edge length and c is a small constant. Notice that the curvature term from Eq. (27) is removed to reduce sensitivity to surface noise and fine details. The user first places a circle, the dot circle, on an area of a desired segment boundary. Then K random diametrical pairs are sampled on the circle. The latter are used to define K harmonic fields. Isolines of the fields that pass through the dot circle are considered candidate cuts. The isoline score depends on three factors: concavity, tightness and proximity to user click. The isoline with the best accumulated score is chosen as the best cut. This interactive tool produces more accurate boundaries than [65], since it uses concavity information.The algorithm in [62] uses the AdaBoost classifier [68] to determine edges that should constitute the boundaries trained with a set of already segmented meshes. The model takes as input feature vectors of each edge of the ground truth segmentations and a class label L so thatL=+1if the edge is part of a boundary andL=-1if it is not. The feature vector contains a set of geometric criteria, such as shape diameter, curvature and dihedral angles. The trained classifier takes as input the feature vector of an edge and returns a value, the sign of which determines the class of the edge (boundary or not). The edges characterized as boundary are neither smooth nor closed. Thus, post-processing is used to thin boundaries, remove branches, close the boundaries, and smooth them (Fig. 15).Probabilistic methods assume that the label of each face or vertex of the mesh is a random variable. Probabilities are calculated based on the mesh geometry. The method in [69] uses the GMM-EM algorithm, which assigns to each face a probability based on the resemblance of a feature histogram to a mixture of Gaussian distributions. However, it does not take into account each node’s adjacent labels, and it is practically a clustering technique. This is solved by other methods, which calculate the parameters of a random field model, which takes as input a feature vector for each node and a possible set of labels and outputs a probability for each node to be assigned each of the labels. Label probabilities are calculated with respect to graph adjacency, meaning that neighboring nodes are more likely to have the same label. Structure-awareness is a big advantage of random fields as opposed to clustering techniques, which contributes to the suitability of this model for the mesh segmentation problem. We can observe two distinct approaches: Markov Random Fields (MRF) and Conditional Random Fields (CRF). Conditional Random Fields are adopted from the learning methodologies, whose main advantage is that dependencies between adjacent nodes can be parameterized, in contrast to MRF, thus a penalty term can be assigned to edges predicted to lie on boundaries. After the parameters of the model are defined or learned, the segmentation is performed by maximizing the energy function that sums the probability that each node is assigned to the correct segment. Such models are suitable for training from already segmented and labeled meshes. The efficiency of such methodologies depends on both the attributes they use to calculate probabilities and the way they model structural relations.The method in [70] presents a general segmentation framework using Markov Random Fields. The authors do not specify the features to use. An initial k-means clustering is performed to the features measured on the mesh and a median filter is applied to the values. To estimate the parameters of the prior model least squares estimation is employed, while for the observation model parameters are learned using classical maximum likelihood estimators. The final labeling will be decided by the maximization of the a posteriori probability, which is accomplished using Simulated Annealing [71]. The latter is a method, which changes the state of each vertex gradually, by lowering a virtual temperature factor, so that a better estimation of the model is achieved.The work in [69] attempts to calculate the local thickness at each face and thus defines a function, called the shape diameter function (SDF). For any given point of a mesh, SDF calculates the distance to its antipodal point. Several rays are sent from the center of each face to the direction of a cone centered on the inward-normal and stop when they intersect with the inner surface of the mesh. The SDF of a face is defined as the weighted average of all rays’ lengths which fall within one standard deviation from the median of all lengths. A Gaussian mixture model is used on the SDF histogram to segment the mesh in k clusters. k Gaussians are fit in the histogram to assign a probability to each face belonging to any Gaussian. The actual partitioning is performed using the Expectation Maximization algorithm. The segmentation is smoothed using a k-way graph-cut [72]. The number of clusters k chosen, is related to the number of levels in the hierarchy and not to the number of parts (Fig. 16).Supervised machine learning methods are typically completed in two distinct steps. During the off-line step a classifier is trained by a set of already segmented objects. During the on-line step a mesh is segmented by making use of a function produced during the off-line step. Supervised learning methods typically perform well because they make use of the knowledge of the ground truth segmentation. They exhibit impressive results for almost any type of object, as long as reliable manual segmentations exist. However, less effective results could be produced by such methodologies, in case that there is large variability in the already segmented meshes.The main idea of the approach in [73] is to assign a label to each face of the mesh from a set of labels. To this end the CRF model [74] is used. A vector of unary featuresxiis calculated for each face and a vector of pairwise featuresyijfor each edge. Features include SDF, Shape Contexts, Spin Images, Curvature, PCA, Distance from medial surface, AGD, Euclidean coordinates and dihedral angles. The Jointboost classifier [75] is trained with feature vector-label pairs from the ground truth so that the parameters of the model are learned. The classifier then is applied in the test dataset and outputs a probability for each face regarding the labels. The labeling (Fig. 17) is determined by maximizing the total energy using alpha expansion graph-cuts [72].The method in [76] learns from a set of segmented training meshes. The difference with the previous approach is that it uses a distinct classifier for each possible label l and it pairs each face with a probability of being assigned the particular label (Fig. 18). By learning the classifiers for all labels, each face of the mesh will have a probability distribution of being assigned any label. The labeling is performed jointly, meaning that two objects’ nodes form a combined graph before the assignment, thus labeling takes into account correspondence between two meshes. Faces of different meshes with similar descriptors are connected with an inter-mesh edge. The labeling is optimized with a graph cut algorithm [72].The method in [77] proposes mesh segmentation with semi-supervised CRFs, where the training process takes into account not only manually previously segmented labeled meshes, but also unsegmented meshes. This makes learning less susceptible to badly segmented meshes than [73]. The objective function that needs to be maximized involves both labeled and unsegmented unlabeled meshes: The parameters of the model are learned with Virtual Evidence Boosting, which includes Belief Propagation, that takes into account neighborhoods and dihedral angles to propagate labels, and Logitboost, which performs feature selection.The work in [78] is an interactive tool for 3D mesh segmentation. The method requires that the user labels with a color seed regions using a brush. A local geometric feature is assigned to each face of the mesh, which consists of a 4D histogram of angles and distances between pairs of sampled points, as well as the x coordinate of the barycenter of each face. The labels propagate over the mesh following the Manifold Ranking semi-supervised learning algorithm [79]. In order to reduce complexity, the mesh is first segmented into patches before the label propagation. The methodology presents excellent results, however the experiments were conducted in a supervised manner by attempting to reproduce the ground truth.The goal of motion-based methods is to identify parts of articulated moving objects (Fig. 19). The main idea behind this approach is to locate joints of the segments. Parts of the object, in which big variation among poses occurs are joints, and consequently will form boundaries between segments. On the other hand, rigid regions that remain indifferent to motion form segments of the object. The methodologies require a set of poses of the same mesh. The attributes that these methodologies are based on is proximity to rigid transformation or deformation. All following methodologies assume that a point-to-point correspondence between all poses of the same object is established.The method in [81] addresses the problem of motion segmentation by assuming that points in rigid regions of an articulated object will undergo the same transformation in motion sequences. Variation of points of different poses is calculated with the use of Lie algebra. The segmentation is achieved by minimizing an energy term in a variational manner.The method in [80] first constructs the outline of each mesh from several viewpoints, the augmented silhouette (Fig. 20). Among different poses the angles in the silhouette are computed, and nodes on which large angle difference occurs are considered for the non-rigid joint region of the mesh. The final segmentation is achieved by first constructing a map of minimum diffusion distance [83] of all nodes to these selected nodes, in a multiple-source region growing manner.In [82] a deformation weight is assigned to each edge, representing the maximum difference between any pair of the corresponding dihedral angles among all poses. The segmentation will occur on edges with high deformation weight. This is accomplished by computing the minimum spanning tree of the dual graph with deformation weights. Deleting edges with the largest weights that surpass a threshold result in the segmentation.A decisive step for mesh segmentation is finding correspondence between similar shapes by segmenting objects simultaneously or learning the correspondence and utilizing the knowledge to achieve better results. Methods that gather information of similar objects in order to produce consistent segmentations form this category. The critical point here is that parts semantically similar are not always geometrically similar, or they share some geometric attributes but are not necessarily identical. This is the main challenge co-segmentation ought to deal with. There are two main approaches. The alignment approach [84,2], where objects are aligned to find correspondence, and the descriptor space approach. Notice that in this category we have classified only methods that use unsegmented, unlabelled meshes to perform the segmentation. Methods try to produce a successful segmentation without any prior knowledge. The knowledge that is being utilized by these methodologies is that all objects belong to the same class (e.g. chairs, humans, etc.), as well as the number K of semantic labels. The co-segmentation is performed jointly to all objects, while taking into account correspondence.In the alignment approach correspondence is determined by aligning objects, and connecting close parts. In the feature space clustering approach, correspondence is found by calculating distance between descriptors. A naive approach would be to combine all faces of all objects in the co-segmentation. However, this would be impractical and time-consuming. A typical methodology of the co-segmentation framework would instead first over-decompose each object separately into patches using some existing algorithm and search for similarities in the patch level. Then, a geometric distance-proximity is defined between two patches representing the probability to be assigned the same label. In particular, a full affinity matrix is computed for each descriptor, containing all patches of all available objects. The main diversifying factor of these methods is the clustering technique they use and the way they combine multiple affinity matrices. The patches are clustered into K clusters providing a meaningful segmentation for each object, as well as part correspondence between objects. Some methodologies, after obtaining the knowledge of labeling, jointly reprocess the co-segmentation in the face-level in order to refine boundaries. Others involve the refinement in the co-segmentation process, or perform this step on each object after over-segmentation.The work in [84] processes a graph which includes all meshes. The nodes of the graph comprise all the faces. Edges exist not solely between adjacent faces in the same mesh, but between corresponding faces of different meshes. Adjacency edges have a weight equal to (A.2), whereαis a constant,θis the dihedral angle of the mesh edge, and l its length. Correspondence edges are found by aligning two meshes and finding for each point of one mesh the closest compatible point of the other one (Fig. 21). After the graph is constructed, the segmentation is performed using hierarchical agglomerative clustering. The clustering is completed in two steps. First, an over-segmentation of each mesh is performed using only adjacency edges, which is significantly faster than the co-segmentation, resulting in an over-segmentation. Then, using the previous result, the full correspondence-based segmentation is performed.The method in [2] describes a co-segmentation method similar to [84]. Objects are first clustered by style, relying on the scale of each part. This can solve the problem of similar objects having different part scales not being aligned, which is not addressed in [84]. Then, within each style, objects are over-segmented using the method of [64]. For each part generated by the segmentation method the oriented bounding box (OBB) is computed. It co-segments objects in a hierarchical agglomerative clustering manner by defining an adjacency cost between faces that belong to the same object, depending on convexity, and a correspondence cost, which is a cost of alignment of the respective OBBs.The method in [87] is different from other co-segmentation methods, since it attempts to segment simultaneously diverse objects in a heterogeneous database (Fig. 23). Firstly, multiple segmentations are produced for each model using randomized cuts [64]. The geometric similarity between two segments is calculated as [88]. The goal is to find segmentations that maximize both frequency of occurrence as well as correspondence between distinct segmentations [89,90]. The above maximization is performed with linear programming. The main advantage of this methodology is not requiring knowledge of the class of an object, however for large databases the process is memory and time consuming.In [91] each mesh is segmented individually with the mean-shift algorithm. This is performed by first computing a number of descriptors on each face of the mesh, such as shape diameter [69], geodesic distance to the base of the upright oriented object (GB) and angle between the normal vector of each face and the upright orientation vector. For each segment histograms of face feature values are computed, as well as segment properties, which include area and PCA based features. A diffusion map is calculated based on distance of two patches’ descriptors. The segments are then divided into clusters using hierarchical agglomerative clustering. The labeling is finally refined by applying a statistical model and producing the final assignment with alpha expansion graph cuts (Fig. 24).First step of the algorithm in [92] is an over-segmentation of the objects using normalized cuts [64] into 50 patches. For each patch 5 descriptors are calculated: Gaussian Curvature, SDF, AGD, CF and shape contexts (SC). A single affinity matrix is computed using sparse subspace clustering [93] combined with a penalty term to produce an affinity matrix which outputs large affinity when two patches are similar in a subset of features. The minima rule [94] is taken into account by multiplying the affinity values with a minimum curvature term Fig. 25). The segmentation is performed with the normalized cut method [95]. Last step is boundary refinement with minimum graph cuts [17].The method in [86] uses normalized cuts [95] for the initial over-segmentation of the set of objects. Six part descriptors are computed on each patch: HKS, AGD, CF, SDF, SC, and Gaussian curvature (Fig. 22). The method calculates an affinity matrix for each feature separately. It iterates for all features by projecting each affinity matrix onto the subspace spanned by the eigenvectors of the others (Fig. 25). The final segmentation is produced by k-means clustering.The method in [96] first over-segments the objects using normalized cuts and computes four descriptors for each patch: AGD, CF, SDF, and SC. Thus, four histograms correspond to each patch. An affinity matrix is constructed based on the Earth Mover’s Distance between two patches’ descriptors. An initial co-segmentation is performed by using the normalized cuts spectral clustering technique. Then, the co-segmentation is refined by calculating a Gaussian Mixture Model on the data, and using [72] for the assignment. The refinement is performed iteratively, until a target accuracy is met.The method in [97] firstly over-segments the meshes into 30 patches and refines the boundaries with graph cuts. The descriptors taken into account are the SDF, CF, SC, GB. An affinity matrix is constructed for each feature considering only the k-nearest neighbors of each patch. The combined affinity matrix will be the weighted sum of all affinity matrices. The weights are selected in a way that, when applying spectral clustering, the total intra-cluster weight sum is minimized [98].The methods described in the sequel attempt to produce error-free results by combining co-segmentation and user interaction.In [14] an initial over-segmentation is produced for each object using k-means clustering. The borders are refined by means of graph cuts. The initial segments are divided into classes using the [91] approach. The user can interfere with two types of constraints: must-link and cannot-link, which are suggested by the system. Must-link forces correspondence between two segments and cannot-link prevents two segments from linking. The user interaction is taken into account so that clusters are matched or divided and thus close to error-free segmentation can be produced.The method in [99] uses SDF, CF, SC, AGD, and GB histograms as patch descriptors. The histograms are concatenated and the weighting scheme of the graph takes into account only the most similar patches. The approach used here is semi-supervised, where the user is required to label some seed patches. The labels propagate to all patches using the iterative method in [100] until convergence, and the process is repeated until the user is satisfied. In addition, this work proposes a system, where an object can be segmented individually (as a validation set), using the information of the previously segmented meshes.A lot of progress has been made during the past years in the evaluation of segmentation methods. Measuring the success of a method is not a simple task. The problem lies in the fact that segmentation is subjective, thus no gold standard exists; no unbiased judge can decide what a perfect segmentation is. Significant improvement has been made towards better evaluation of methods [102,101,63,103,104]. Before that, researchers mostly used an intuitive way of judging their methods’ performance and results were approximate. The first effort of evaluating mesh segmentation algorithms qualitatively was the work of [102]. Several criteria were chosen to distinguish and evaluate decomposition results (type of segmentation, extracting the “correct” segments, boundaries, hierarchical/multi-scale segmentation, sensitivity to pose, asymptotic complexity, control parameters). The effort is interesting, yet the problem persists that no ground-truth or quantitative measures were used. The contribution of [63,101] is twofold: the construction of a set of manually segmented objects and the definition of evaluation metrics. The set of manually segmented objects can be considered as ground truth, and the performance of a method can be calculated relatively to the ground truth. An automatic methodology is considered successful, if it produces segmentations close to the manual ones. As a direct result, measures had to be defined to calculate the amount of closeness of an automatic segmentation to a manual one.In addition, the introduction of evaluation frameworks has induced a lot of progress in understanding the criteria used by humans to segment objects. Indeed, humans tend to make cuts on concave regions. Glancing at Fig. 28, it is clear that cuts are located on regions of negative minimum curvature, while humans avoid placing boundaries on regions of zero Gaussian curvature, which aligns with the minima rule. For further study of human segmentations, we refer the reader to the original article [63].An overview of the existing datasets (see also Table 6) as well as the metrics used to assist mesh segmentation evaluation is provided in the sequel.Dataset 1. The Princeton ground-truth [63] (Fig. 26) contains 380 models of 19 classes (20 models per class). It partitions the faces of each mesh and the models were taken from the SHREC’07 database [105]. For each model, the number of available manual segmentations varies from 5 to 20.Dataset 2. The LIFL/LIRIS dataset of [101] (Fig. 27) contains 28 models of 5 classes. For each model 4 manual segmentations are available resulting in a total of 112 segmentations. They are based on vertex partitioning and the models come from the INRIA GAMMA database and the Princeton Shape Benchmark [106].One major issue of the two above multiple ground-truth efforts is the subjects that performed the segmentations. In Dataset 1 the segmentations are performed on-line with random subjects from around the world, while in Dataset 2 the segmentations were performed by volunteering staff and students of the University of Lille and Insa-Lyon. The interest and reliability of the human subjects of Dataset 1 can compromise to a degree the quality of the ground truth (Fig. 29). In fact, human segmentations in [63] in some cases yielded larger error than some automatic methods.Dataset 3. Recently, since co-segmentation of sets of objects is gaining recognition, a project [14] has been carried out to produce the COSEG dataset and ground truth to assist this trend (see Figs. 30and Figs. 31). Seven sets of shapes are taken from [91] and four new ones were introduced resulting in a total of 11 sets of objects and ground truths. The sets vary in size from 12 objects (Goblet class) to 500 (Large Chair class). This set contains one ground truth for each object, and objects of the same class are labeled correspondingly. The segmentations were performed manually by the respective research groups. The latter makes evaluation more straightforward, since multiple ground truths need not be taken into account, and a definition of a pairwise distance is sufficient.Dataset 4. Motion-based methodologies (Section 3.9) mainly used the Sumner dataset [107], which contains 7 3D mesh sequences. These methodologies use particular models with several poses from other popular 3D model databases as well, such as AIM@SHAPE or TOSCA.Generally, an effective evaluation metric should have high discriminative power between good and bad segmentations. A random segmentation should produce the minimum score, while a nearly perfect segmentation should produce a very high score. In order to quantitatively measure the quality of a segmentation four metrics are introduced in [63], while the 3D-NPRI is introduced in [103], the Classification Accuracy (CA) and the Segment-Weighted Error (SWE) in [73]. These are presented in the sequel and according to [103] they can be divided into three categories:•Boundary matching metrics: boundary matching metrics measure the distance between cuts of different segmentations (Cut Discrepancy).Region differencing metrics: region differencing metrics measure how much regions of two different segmentations overlap (Hamming Distance, Consistency Error).Non-parametric tests: they measure consistency of labels of the same face or vertex in two different segmentations (Rand Index).The following metrics define a measure of similarity between two distinct segmentations. Consequently, in datasets containing more than one ground truth for each model, the minimum distance of an automatic segmentation to any of the ground truths would reflect the quality of the segmentation. However, the two multiple ground truth benchmarks suggest to average the distance to all manual segmentations. Thereby, they compensate for irregular unreliable ground truths and achieve better scores for segmentations that are similar to most of the manual ones (i.e. an automatic segmentation similar to a frequent pattern in the ground truths will achieve higher score than another similar to only one ground truth). In the following, we denote asS1andS2the two segmentations to compare.Cut Discrepancy (CD) The Cut Discrepancy metric measures distance between cuts. It sums the minimum geodesic distances of the cuts of one segmentation against another. LetC1andC2be the sets of points on the mesh belonging to the cuts of the two distinct segmentationsS1andS2respectively:(29)CD(S1,S2)=DCD(S1,S2)+DCD(S2,S1)avgRadius(30)DCD(S1,S2)=mean{distance(p1,C2),∀p1∈C1}(31)distance(p1,C2)=min{dG(p1,p2),∀p2∈C2}wheredGdenotes the geodesic distance between two points on the mesh and avgRadius is the average Euclidean Distance from all points of the mesh to its centroid.The above metric is most effective among segmentations that are relatively consistent. However, it is undefined when no cuts exist at all.Hamming Distance (HD) The idea behind Hamming Distance is, for each segment in the first segmentation, to find the best corresponding segment, and sum their difference. It is defined as:(32)HD(S1,S2)=12DHDS1,S2+DHDS2,S1(33)HD(S1,S2)=∑i||S2i⧹S1it||||S||whereSijdenotes the jth segment of the ith segmentation.||·||is a measure for a set of faces (total area, cardinality, etc). “⧹” denotes set subtraction,S1itdenotes the best corresponding segment inS1toS2i, and S the whole mesh. One of the metric’s disadvantages is that it involves calculating a correspondence between segments. In terms of efficiency, it naturally produces good results when segments correspond, but performs worse as segmentations do not align with the ground truth.Rand Index (RI) Rand Index attempts to calculate area overlap, as HD, but without the need to find corresponding segments first. It measures the accumulated likelihood of polygonal faces having been segmented in the same way in both segmentations, i.e. belonging to the same or to different segments. Let N be the number of faces of the mesh, then:(34)RI(S1,S2)=2N-1∑i,j,i<jCijPij+1-Cij1-PijCijPij=1, if faces i and j belong to the same segment in both segmentations.Cij=1, if faces i and j belong to the same segment in the first segmentation.Pij=1, if faces i and j belong to the same segment in the second segmentation. Consequently(1-Cij)(1-Pij)=1if faces i and j belong to different segments in both segmentations. Values ofRI(S1,S2)close to 1 indicate a good match between two segmentations, but the value1-RI(S1,S2)is often used in evaluations in order to be compatible with error metrics.Consistency Error (CE). This is a measure that aims to solve the problem of other metrics failing in decompositions with different hierarchical granularity. Consistency error is split into Global Consistency ErrorGCE(S1,S2)and Local Consistency ErrorLCE(S1,S2), which are defined using a local refinement errorE(S1,S2,fi).(35)E(S1,S2,fi)=||R(S1,fi)⧹R(S2,fi)||||R(S1,fi)||(36)GCE(S1,S2)=1Nmin∑iE(S1,S2,fi),∑iE(S2,S1,fi)(37)LCE(S1,S2)=1N∑imin{E(S1,S2,fi),E(S2,S1,fi)}whereR(Si,fi)denotes the set of faces belonging to the segment that contains facefiin segmentationSi,⧹denotes set subtraction and N denotes the number of faces of the mesh. However, there is a trade-off with this metric achieving good results for hierarchical granularity. Extremely coarse or extremely fine segmentations would yield nearly perfect results, as the one would be measured as a refinement of the other.Classification Accuracy (CA). A Classification Error was defined in [73] which measures the percentage of the mesh area which is correctly labeled:(38)CE=∑iαiIci,ci∗∑iαiwhereI(ci,ci∗)=1in the case of correct labeling andI(ci,ci∗)=0, otherwise.αidenotes the area of facei,ciis the ground truth label of face i,whileci∗is the automatic segmentation label. The measureCA=1-CEwould represent the Classification Accuracy. The above metric is widely used in combination with the [14] COSEG dataset. This is a very strict measure and is not intended to be used by completely unsupervised methodologies, since it implies knowledge of the potential labels.Segment-Weighted Error (SWE) An alternative metric to measure classification error is the Segment-Weighted Error, which emphasizes the error in the label level. LetAcidenote the area of the segment with labelci:(39)SWE=∑iαiAciI(ci,ci∗)The SWE averages the percentage of error of each segment, instead of calculating the percentage of error of the whole object.Multiple ground-truth measures attempt to consider all existing ground truth segmentations of the same model to calculate the error of an automatic segmentation.The 3D Normalized Probabilistic Rand Index (3DNPRI). This measure assumes that a vertex belonging to the same segment in the ground truth is a random variable obeying a Bernoulli distribution, calculated over the whole set of available ground truth segmentations. IfSais the segmentation being evaluated and{Sk}the corresponding ground truth set then the 3D Probabilistic Rand Index 3DPRI can be defined as:(40)3DPRI(Sa,{Sk})=1N2∑i,ji<jeijpij+(1-eij)(1-pij)eij=1means that the vertices i and j belong to the same segment of the automatic segmentation.pijis the probability of two vertices belonging to the same segment in the ground truth set. The above measure is normalized by the authors in [103] with respect to an expected valueE[3DPRI]calculated on the whole dataset using random segmentations. The 3DPRI measure produces similar scores for most segmentations, and with the normalization against random segmentations it achieves superior discriminative effectiveness. Thus, the 3DNPRI is defined as:(41)3DNPRI(Sa)=3DPRI(Sa,{Sk})-E3DPRI1-E3DPRIThis measure takes values between −1 and 1, in contrast to the 3DPRI which has range between 0 and 1. 1 means perfect match, 0 represents a random segmentation while −1 complete dissimilarity.Similarity Hamming Distance (SHD). The Similarity Hamming Distance extends the idea of HD to multiple ground truths. For each segmentsa,iof segmentationSa, overlapping segments of the ground truthok,i(having at least one common face withsa,i) that have larger total area than half the area ofsa,iare considered. The most similar one is taken into account for the calculation of SHD. The distance between two segments is defined as:(42)Distance=β·EMDD2(sa,i,ok,i)+(1-β)·dist(sa,i,ok,i)whereEMDD2denotes the earthmover’s distance between the D2 distributions [108] of the two segments,dist()denotes the Euclidean Distance between the centers of the two segments scaled in the range [0,1] andβis a weight. The SHD is the Hamming Distance betweenSaand the most similar parts located in the ground truths.Adaptive Entropy Increment (AEI). The AEI attempts to minimize the error of a segmentation if all its segments are present in any of the ground truths. The entropyH(G1,…,Gn)of n ground truth segmentationsGiis defined as:(43)H(G1,…,Gn)=-∑P(G1,…,Gn)log(P(G1,…,Gn))whereP(G1,…,Gn)denotes the probability that random segments of the segmentations overlap. The entropy sums over all possible combinations of segments for all ground truth segmentations. By adding the automatic segmentation A the entropy will increase, unless all the segments it comprises exist in the ground truths as well. The normalized entropy incrementΔHis defined as:(44)ΔH=H(G1,…,Gn,A)-H(G1,…,Gn)+∊H(A)+∊whereH(A)denotes the increment in the worst case scenario where the automatic segmentation is completely different than the ground truth segmentations, and∊a small constant.Finally, the Adaptive Entropy Increment (AEI) is defined with respect to N random segmentationsAr:(45)AEI=ΔHE(ΔH)(46)E(ΔH)=1N∑r=1NΔH(G1…,Gn,Ar)The quantitative evaluation results for different algorithms with respect to each dataset and the corresponding metrics are illustrated in Tables 5, 8, 9. Each metric addresses the problem from a different point of view. CD is the only boundary matching measure, its main disadvantages being intolerance to different hierarchies of the same segmentation and producing high error when boundaries are not precise. CE deals with the problem of taking into account different hierarchies of the same segmentation, at the cost of failing to deal with extremely fine or coarse segmentations. HD has the disadvantage that a correspondence between segments has to be found before comparing two segmentations, however correct correspondence is not guaranteed by the region overlapping criterion. This is addressed by SHD which uses a geometric criterion to find correspondence between segments. RI implicitly measures segment overlap without finding segment correspondence. 3DNPRI’s main contribution is extending RI to multiple ground truths and increasing its discriminative power by normalizing with respect to randomly generated segmentations. Last, the metrics defined in [109], SMD and AEI, address the problem of evaluating against multiple ground-truths by comparing segments of the automatic segmentation to any segment of the ground truth regardless of the segmentation it belongs to.

@&#CONCLUSIONS@&#
In this paper, we have surveyed existing frameworks for 3D mesh segmentation. We have discussed several key aspects that differentiate the approaches studied. We have introduced a meaningful categorization, by identifying the main directions in the field. In addition, the existing frameworks for 3D mesh segmentation performance evaluation have been surveyed. We studied the existing ground truths with the metrics they proposed, discussed their contributions and weaknesses. Finally, we described the current trend of learning and co-segmentation methodologies, which yield excellent results by using the extra information available.Learning methodologies proved that an improved segmentation can be produced, if the knowledge of how similar objects should be segmented exists. Co-segmentation methodologies demonstrated that they can yield similar results without the knowledge of a ground truth segmentation, using only correspondence with similar objects. Despite the overwhelming advances in the field, 3D mesh segmentation still remains a difficult and open problem. State-of-the-art methodologies can achieve excellent results, but within a certain domain/context. The difficulty of the problem is mainly due to its abstract nature, and partly due to the complex and numerous criteria used by humans.