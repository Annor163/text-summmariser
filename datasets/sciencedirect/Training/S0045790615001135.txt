@&#MAIN-TITLE@&#
A framework for a real time intelligent and interactive Brain Computer Interface

@&#HIGHLIGHTS@&#
A framework for a real time implementation of a Brain Computer Interface.Implementation & comparison of different feature extraction methods and classifiers.Accuracy & processing time comparison for detection of event related potentials-ERP.An implementation of a prototype system using the proposed BCI framework.Real time EEG data collection and classification of ERPs using Hex-O-Speller.

@&#KEYPHRASES@&#
Electroencephalography (EEG),Data collection,Brain–computer interface (BCI),Event-related potentials (ERP),Classification,

@&#ABSTRACT@&#
This research proposes a framework for a real time implementation of a Brain Computer Interface (BCI). This interface is designed with a future objective of providing a testing platform as an interactive and intelligent Image Search and Retrieval tool that allows users, disabled or otherwise, to browse and search for images using non-invasive electroencephalography (EEG) signals. As a proof of concept, a prototype system was designed and implemented to test real time data collection and navigation through the interface by detection and classification of event-related potentials (ERPs). A comparison of different feature extraction methods and classifiers for the detection of ERPs is performed on a standard data set to determine the best fit for the real time implementation of the BCI. The preliminary results of the real time implementation of the prototype BCI system are quantified by the success rate of the user/subject in navigating through the interface and spelling a search keyword using the mental-typewriter Hex-O-Speller.

@&#INTRODUCTION@&#
Assistive devices and technologies are essential in enhancing the quality of life for individuals. Significant research in developing assistive smart devices and technologies for disabled individuals to improve upon motor movements, speech, touch and bio-signals has been done. Most of these systems depend on some residual motor movement or speech. The Brain Computer Interface (BCI) systems completely bypass any motor-output by decoding the brain state of an individual, which can be an emotion, attention, an event related potential (ERP) or an imagined movement. These BCIs can help disabled individuals that have minimal to no voluntary muscle/movement control, thereby attempting to give some autonomy to individuals by providing the brain with alternate ways of communication.In [1], the authors comprehensively describe the existing Brain Computer Interface trends and applications and its use as an augmenting and alternative communication system. It categorizes the BCI systems based on the inputs i.e. the stimulus presentation paradigms and the elicited EEG responses. It details further in the effective and commonly used preprocessing and classification techniques. Matrix Speller, Hex-O-Speller and Rapid Serial Visual Presentation are the existing visuospatial presentation techniques (described in Section 2.1) for eliciting event related potentials (ERPs). It also expands upon motor imagery-movements induced responses as a control paradigm for communication in BCI.This framework for the BCI is an attempt to use and augment the existing EEG based research and understand how it can be applied to make devices such as smart-phones, tablets or computers, and technologies smarter and more interactive. Today the dependencies and reliance on smart devices, computers and applications; especially the ones that use the information available on internet, are indisputable. Modern users expect the applications and technologies to be smart and learn from the usage and the choices made by the user. The proposed study will further reinforce this notion, by taking into consideration and understanding their thoughts/actions by decoding their brain state, thus making them more user friendly and intelligent. Multiple studies in the psychophysiology and neuroscience fields have been done to understand the relation of emotions [2], attention [3], interest [4] and motor movements [5] to the brain activity and EEG responses [6]. However, there are relatively fewer real world applications that use these methods and findings. The research presented in [7] compares the performance of Brain Computer Interface (BCI) to Eye Tracking Interface (ETI) in terms of how fast a decision/classification could be made for a visual stimulus targets on a smaller screen. It observed that BCI performed better for small screen targets compared to ETI, and recommended the use of BCI over ETI in small screen applications like smart phones.Research in using the EEG signals to enhance and augment the retrieval of meaningful information from images and videos has been done. Similar studies to the one proposed use EEG signals and image processing to find similar images or specific objects in images [8]. These reinforce an image search by leveraging the robust and invariant object recognition capabilities of the human brain [9]. In [10,11], rapid visual presentation has been used to categorize objects in images and do image search respectively. The study in [12] describes the discriminatory EEG signals in response to events of interest in a surveillance video. The above referenced BCI research uses a single type of visual stimulus i.e. RSVP. The proposed framework for the BCI is an attempt to use different stimuli such as the Hex-O-Speller along with RSVP to give more flexibility and autonomy while doing image searches. This will result in a more enhanced image browsing, search and retrieval process. The framework for the BCI focuses only on the visual stimulus, but it can be further extended to auditory stimuli like music or sounds. The proposed framework because of its modular setup can be used to create experiments, collect data with different type of stimulus, train and classify in real time.The principal challenge with this research is that there is no defined model or relation that relates a user’s interest to the contents of an image. In order to formulate a relation, experiments as proposed in Section 6[13] can be designed and performed using the proposed BCI. Another challenge is that a large amount of training data is needed to be collected, thereby a longer training time, for getting higher accuracy for a single-trial EEG signal classification [14,15]. Moreover, in a real time implementation of a BCI, timing synchronization between the generation of visual stimuli and data collection is challenging. Also the EEG recording devices are a bit uncomfortable and less fashionable. However, there have been significant advances in wearable technologies and new devices like the Emotive research headset [16] and EEG head bands that collect wireless EEG data and are relatively comfortable and fashionable. The proposed modular framework for the BCI can be used to address and research the aforementioned challenges individually. Nonetheless, this study is a step towards better understanding the use of brain signals as a feedback to devices and applications to understand the user better.The remainder of this document is organized as follows: Section 2 describes the background information for this work. Section 3 describes the proposed approach for the BCI framework. It elaborates various aspects of the BCI system, explains different feature extraction methods and classifiers used for detecting event related potentials on the standard dataset. Preliminary results of the BCI system and comparison of different methods for classifying event related potentials are presented and discussed in Section 4. Conclusions are drawn in Section 5, and the future work is discussed in Section 6.

@&#CONCLUSIONS@&#
