@&#MAIN-TITLE@&#
Coordinate-free geometry and decomposition in geometrical constraint solving

@&#HIGHLIGHTS@&#
We solve 2D/3D geometric constraints by using coordinate-free formulation.Statements are translated into formalism that reduces the number of equations.A decomposition algorithm is proposed to produce small subsystems.Subsystems are solved by homotopy.

@&#KEYPHRASES@&#
Geometrical constraint solving,Cayley–Menger determinants,System decomposition,Equational system optimization,Homotopy,

@&#ABSTRACT@&#
In CAD, a designer usually specifies mechanisms or objects by the means of sketches supporting dimension requirements like distances between points, angles between lines, and so on. This kind of geometric constraint satisfaction problems presents two aspects which solvers have to deal with: first, the sketches can contain hundreds of constraints, and, second, the problems are invariant by rigid body motions. Concerning the first issue, several decomposition methods have been designed taking invariance into account by fixing/relaxing coordinate systems. On the other hand, some researchers have proposed to use distance geometry in order to exploit invariance by rigid body motions. This paper describes a method that allows us to use distance geometry and decomposition in the same framework.

@&#INTRODUCTION@&#
Problems of geometric constraint satisfaction where constraints express geometric requirements related to distances, angles, tangencies and incidences occur in many fields such as CAD, geometric modeling, robotic or molecular modeling. The problem consists in finding the position and the orientation of some given objects in a way that some given constraints are satisfied. More particularly, in CAD, problems come from the specification of pieces or mechanisms given in the form of a sketch drawn by a designer using basic geometric primitives such as points, lines, planes, circles, spheres, etc., and metric requirements such as distances between points, angles between lines or planes. In that framework, the aim is to get coordinates for the points, planes, circles, etc., so that the incidence relations given by the sketch, and the added metric constraints are fulfilled. By essence, these problems are invariant by direct isometries (or rigid body motions for engineers), that is, applying a rigid body motion on a solution yields another solution. It is also usual to assume that the objects are well defined that is there is a finite number of solutions up to rigid body motions. In that situation, the problem is said to be well-constrained.Several methods designed to solve such problems are described in the literature (see  [1] for a recent state of the art). Some methods consider the coordinates of primitives and try to solve the equation system either numerically, for instance with Newton–Raphson  [2] or homotopy  [3] methods, or symbolically for instance by using Gröbner basis or Ritt–Wu principle  [4]. However, these methods suffer drawbacks that we want to overcome: symbolic methods have an exponential complexity, and numerical methods are unable to produce all the solutions within a reasonable time. Other methods are more sticked to geometry: they use knowledge-based systems (KBS)  [5,6] or graph operations  [7] to solve small problems and are designed to decompose larger problems into smaller subproblems when it is possible. These methods for decomposing geometric problems always take into account the rigid body motion invariance. The way they proceed amounts to first fix some coordinates and then relax them by letting act the group of rigid body motions on the solutions for the subproblems. When successful, these techniques may allow to yield all solutions in a reasonable time.Unfortunately, 3D problems, even the ones involving few objects, are hard or impossible to solve by using only constructive methods. And numerical solvers have to face systems with dozens of equations and whose global degree is too high to enable the use of homotopy to follow all the possible paths. For some years, another approach has been studied which ignores coordinates in the first time and which is more able to take rigid body motion invariance into account  [8–10]. This approach is based on coordinate-free geometry. The idea consists of replacing coordinates by all the distances between points. The main ingredient to write down equations is the Cayley–Menger determinant between some sets of constrained points. This method had been successful on some problems like the Stewart platform problem  [8] or the Malfatti problem  [9] where the equation system to solve is very small compared to the classical approach based on Euclidean coordinates. However, such systems were built by hand and, in the coordinate-free geometry framework, there are no known methods for decomposing big systems.We propose here a method to automatically produce equation systems using the Cayley–Menger determinant and to structurally decompose the constraint systems whenever possible. The resulting systems can then be solved by classical homotopy in order to yield either all the solutions, or, at least, the highest number of possible solutions.This paper is organized as follows. Section  2 introduces distance geometry and Cayley–Menger determinants. Section  3 gives algorithms to provide Cayley–Menger systems from constraints systems. Section  4 presents our algorithm of decomposition of Cayley–Menger systems. The numerical approach and some results are given in Section  5. Section  6 concludes and mentions some limits and future works.A geometric constraint system, in short GCS, is defined by a tripleC[X,A]whereXis a set of unknowns,Ais a set of parameters andCis a set of constraints onXandA. The unknowns correspond to some geometric entities (also called primitives or objects) such as points, lines, circles, planes, etc., the constraints are relationships involving distances, angles, tangencies, incidences, etc., and the parameters are the values imposed as dimensions like distance and angle values.More specifically, we consider here rigid bars problems as encountered for instance in CAD, robotics and molecular modeling. So, entities are points and hyperplanes, that is, lines in 2D and planes in 3D; constraints are about distances between two entities and angles between hyperplanes. The model that we use does not include 3D lines. However, it is often possible to replace them by pair of incident points. For instance, when angles between 3D lines are considered, they often concern adjacent segments. So the angle between segmentp1p2and segmentp1p3can be transformed into a distance that is expressed as a function of lengths of both segments and the angle. Unless otherwise stated, we assume that statements are in 3D. It is also assumed that constraint systems are well-constrained, meaning first that there is a finite number of solutions up to rigid body motions, and second, that in some open neighborhood of the parameter values, each solution is a continuous function of the parameter values. Thus parameters are assigned to non-critical values (or regular values). For instance, for a triangle specified by its three lengths, no length equals the sum of the two other lengths. Note that the triangle can still have some special property, like a right angle, or being equilateral: we do not impose the parameter values to be generic. Indeed, the zero distance is used later on to specify point–plane incidence.A geometric constraint system is usually associated with its corresponding graphs of constraints. Indeed, as constraints always involved two objects in our case, a constraint system can be represented by graphG=〈V,E〉whereVis the set of vertices for entities andEis the set of pairwise edges for constraints. An edge between:•two points mean the point–point distance constraint;two hyperplanes represent the angle constraint;a hyperplanehand a pointpmean distance betweenpand its projection ontoh(it is 0 ifplies onh).In the rest of the paper, for the sake of simplicity, when there is no ambiguity, we confound both notions of GCS and its associated graph of constraints.As an example, we consider a GCS coming from a mechanism constituted by two stacked Stewart platforms. Recall that a Stewart platform is an articulated system that can be represented as a triangle basis connected by six bars to another triangle whose position depends on the lengths of the bars. Fig. 1(a) shows a double Stewart platform and Fig. 1(b) is the corresponding graph. The GCS includes 9 points and 21 distance constraints.Geometrically, the notion of determinant is related to volume. By classical operations on determinants, Cayley expressed the volume of a simplex in terms of distances. If coordinates of points are rows of matrices, multiplications of such matrices perform dot products that eliminate coordinates and make distances appear. Later, Menger studied its relevance to solve geometrical problems. Since then, the Cayley–Menger determinant is used to express or solve the geometric problem in a coordinate-free framework. Lu Yang  [11] extended Cayley–Menger determinants to hyperplanes and hyperspheres.Given a set ofnpoints{p1,…,pn}in the Euclidean space of dimensiond, the Cayley–Menger (CM for short) determinant of these points is defined by:D(p1,…,pn−1,pn)=|011⋯110r1,2⋯r1,n1r2,10⋯r2,n⋮⋮⋮⋱⋮1rn,1rn,2⋯0|whereri,jis the squared distance betweenpiandpj. ThenD(p1,…,pn)is the determinant of a symmetric matrix.In dimensiond, a set ofn≥d+2points specified by a Cayley–Menger determinant is embeddable inRdifD(p1,…,pn)=0. In particular, in 3D, for 5 and 6 distinct points it comes:D(p1,p2,p3,p4,p5)=0andD(p1,p2,p3,p4,p5,p6)=0.These properties are widely used in the following to write down the system of equations corresponding to GCS.In addition, forn=d+3, Sippl and Scheraga  [12] showed that equationD(p1,…,pn−1,pn)=0can be substituted byD∗(p1,…,pn−1,pn)=0where:D∗(p1,…,pn−1,pn)=|011⋯1110r1,2⋯r1,n−2r1,n−11r2,10⋯r2,n−2r2,n−1⋮⋮⋮⋱⋮1rn−2,1rn−2,2⋮rn−2,n−2rn−2,n−11rn,1rn,2⋯rn,n−2rn,n−1.|.This simplification that removes one line and one column is made thanks to Jacobi’s theorem with the fact that minors involvingd+2objects are equal to 0. So, in 3D, the matrix for 6 points has the same size than a 5 points matrix. This property is useful to lower the degree of the equations.In this paper, we use the extended definitions coming from  [11] in which points and hyperplanes are considered within a coherent framework. In  [11], hyperspheres are also included in the framework, but we do not consider this case here. For a given set ofnobjectspi, wherepican be a point or a hyperplane, matrixMis defined as follows:M=(0δδtG)withδ=(δ1,…,δn)andδi=1ifpiis a point andδi=0if it is a hyperplane. Withgi,jtheith row andjth column element ofG, we have:•gi,jis the squared distance betweenpiandpjif they are both points (ri,jabove)gi,jis the signed distance ofpiandpjif one is a point and the other a hyperplane (so it is 0 for the incidence relation)gi,jequals−12cos(pi,pj)if they are both hyperplanes.The determinant ofMis still called a Cayley–Menger determinant and the previous notationD(p1,…,pn)is used. The propertyD(p1,…,pn)=0ifn≥d+2and the simplificationD∗are still valid. ACM-determinant can be expanded in an equation wheregi,jare either unknowns or numeric values if they correspond to a parameter. Now, let us see how to use this to solve distance and angle constraints.Given a setXof points and hyperplanes, and a set of constraintsCinvolving distances, incidences and angles, the objects ofXcan be determined by solving the GCS corresponding toC. But, they can also be determined if all the distances or angles between any pair of objects ofXare known, or at least, a representative sub-set of all these distances and angles which could make feasible a simple computation of coordinates of all objects by intersecting spheres and planes. The previous properties help: if we can find numeric values for all the distances (or angles) such thatD(p1,p2,p3,p4,p5)=0, we can compute the coordinates of, sayp4andp5according to a position of(p1,p2,p3)and the values of the distances. This way, the constraints of distance or angle give known values in the previous determinant, and each absence of constraint between two objects gives an unknown distance or angle that we have to find in order to solve the problem. The initial problem of finding some coordinates is then translated into a problem where some distances or angles are known and we want to know the other distances or angles between some pairs of objects.Following this approach, we have to find subsets ofX, each of size equal or greater thand+2. Each subset gives rise to the nullity of a determinant, that is an equation, and the overall system of equations must be well-formed that is: there are as many equations than unknowns and no subsystem has more equations than unknowns. Obviously, there are a lot of possibilities to build such equation systems. In general, they have fewer equations than the corresponding GCS. With example of Fig. 1, the Cartesian approach leads to a 21-equation system. In Table 1, we give some examples of well-formed systems of equation that come from the Cayley–Menger determinant approach.In Cayley–Menger determinants (CM-system for short), unknowns are pairwise relations such as point–point distances, point–plane distance or angle between planes. Once numerically solved, the values of distances and angles are used to determine the coordinates of points and planes. To achieve this, a setRof 3 primitives say{p1,p2,p3}is chosen. Such a set of primitives is called a reference. For each primitivep, if relations betweenpand all elements ofRare known, then coordinates ofpcan be computed. This implies that a construction must be known for each possible GCS involving four entities and six constraints.Systems 1, 2 and 3 are all well-formed and the natural question is how to get such a well-formed system and which to choose to efficiently solve the constraints. The following section addresses these issues.To build a well-formedCM-system it is possible to first choose a referenceRand then build a system that will provide numeric values of relations between all primitives andR. The construction of such systems relies on what we call the external edges ofR. Given a graphG=(V,E)and a setR⊂V, an edge(x,y)is an external edge ifx∉Randy∉R. So external edges are edges whose end vertices do not belong to referenceR.As a preliminary remark, it has to be mentioned that our framework is generic in the sense that the constraints are algebraically independent and do not induce incidence constraints. For instance, points are not colinear or coplanar if such constraints are not in the GCS.An entity is a point or a plane and has 3 degrees of freedom. Each constraint removes one degree of freedom. So each vertex in a constraint graph is an endpoint of at least 3 edges. If this is not true the assumption that the constraint system is well-constrained does not hold. If an entitypis not involved in any external edge so it is connected by three constraints toR. Entitypcan be removed and computed after the whole system is solved. Such entities are then filtered out before running algorithms onCM-system computation. The following first algorithm is only based on external edges. Three points are chosen forR, and we noteR={p1,p2,p3}:Algorithm: CM3Input: constraint graphGandROutput:CM-system SCM1—SCM =0̸2—for each external edge(P,Q)ofGaddD(R,P,Q)to SCMAccording toR, resulting systemSCMmay contain more or less equations. This is discussed further.Let us prove thatSCMis structurally well-constrained, that is:(a)it contains as many equations as unknowns;each of its subsystems contains more unknowns than equations.Since the constraint system is assumed to be well-constrained there are two necessary conditions. First, a GCS ofnentities has3n−6constraints. Indeed, points and planes in 3D have 3 degrees of freedom and a rigid object has 6 degree of freedom, 3 for rotations and 3 in translations. Second, for any subsystem ofc′constraints involvingn′entities, we havec′≤3n′−6.Let us show (a) first. Ifkis the number of external edges,SCMhaskequations. In equationD(R,P,Q), thegi,j’s are: 3 relations within elements ofR, 3 relations betweenPandR, 3 relations betweenQandRand finally the relation betweenPandQ. In the whole systemSCM, the number of entities isnand eachpi∉Ris the end of at least one external edge. So, the number ofgi,j’s ofSCMis3+3(n−3)+k=3n−6+k. Given that3n−6are parameters among thegi,j’s, it remainskunknowns.For (b), consider a subsystem ofSCMwithk′<kCM-determinants involvingn′≤nentities. With the same arguments than for (a), the number ofgi,j’s is3n′−6+k′. Among them, the number of unknowns, i.e. that do not correspond to a parameter, is less or equal to3n′−6because of the second necessary condition. So the number of unknowns is greater or equal tok′.Actually, we can directly prove thatSCMis equivalent to the constraint systemSrepresented byG. Indeed,SCMis not over-constrained, since every solution ofSgives a solution ofSCM. In turn, each constraint ofSis taken into account inSCM. If(pi,pj)is the edge for a constraintc, there are 3 cases. First, ifpi∈Randpj∈R,ctakes place in every equation. Ifpi∉Randpj∉R,cis an external edge and was used to form one equation. Finally ifpi∈Randpj∉R, thencappears in each equation wherepjis an end of an external edge which is the case for at least one external edge. So, constraintcis taken into account inSCM.In Table 1, system 2 is returned byCM3withR={p1,p7,p8}and system 3 withR={p4,p5,p6}.A 4 point reference can also be considered. Let us takeR={p1,p2,p3,p4}. This second algorithm is described by the following pseudo-code:Algorithm: CM4Input:GandR={p1,p2,p3,p4}Output:CM-system SCM1—SCM =0̸2—for each entity P in{p5,…,pn}addD(R,P)to SCM3—for each external edge(P,Q)ofGaddD∗(R,P,Q)to SCMAgain, we can prove that CM-systems yielded by CM4 are well-formed. For point (a), let us notenthe number of entities fromGandkthe number of external edges. AlgorithmCM4putst=(n−4)+kequations onSCM. Consider now the number of unknowns. In step 2, each entityPis connected by 4 relations toR. There are(n−4)such entities. Step 3 addsknew relations and there are 6 relations within elements ofR. Among these4(n−4)+k+6relations,3n−6of them are parameters, so it remainsn−4+kunknowns.For point (b), we consider a subsystemSCMwithm=m1+m2equations withm1the number of equations coming from step 2, andm2the number of equations coming from step 3. Suppose that this subsystem involvescconstraints of the GCS andyentities. The number ofgi,j’s is4(y−4)+m2+6and the number of unknowns isx=4(y−4)+m2+6−c. We have to prove thatx≥m. Since the GCS is well-constrained, we also havec≤3y−6. Thus, we obtain:x≥y−4+m2.It is easy to see thaty−4≥m1(y−4=m1when considering the whole system). We can then conclude thatx≥m.In Section  2, system 1 was provided withR={p3,p4,p6,p9}, the first five equations come from step 2 and the last four come from step 3.Systems can be roughly compared according to their size that is the number of equations. First, one can wonder if CM3 and CM4 always provide smaller systems than the Cartesian approach. With|R|=3, the output CM-system is smaller than the Cartesian system ifk<3n−6which always occurs sincekis the number of external edges. Indeed,kis always lower than the overall number of geometric constraints. With|R|=4, output CM-system is smaller whenn−4+k<3n−6, this implies thatk<2n−2. Withnpoints and|R|=4there aren−4points that are not inR. External edges are edges between thesen−4points and there are at most3(n−4)−6such edges. So,kis bounded by3n−18. Finally,3n−18≥2n−2may occur fromn=16and in that case, CM4 may provide a bigger system than the Cartesian approach. If this occurs, CM3 will be preferred.To avoid any ambiguity, in the following,k3is the number of external edges for a 3 points reference andk4for a 4 points reference.Next, one can ask whether it is better to choose either a 3 points or a 4 points reference. Given a 3 points referenceR3, if a 4th vertexpis added, does the number of unknowns could decrease? WithR4=R3∪{p}, it is obvious thatk3>k4andk3−k4is the degree ofpin the graph. The number of equations is smaller ifn−4+k4<k3, that impliesn−4<k3−k4. So, if there exists a vertex the degree of which is greater or equal ton−4then the number of equations can be reduced withR∪p.According to the chosen reference, the system of equations could be different. The question is whether there is a better system than others. Actually the answer depends on the numeric solving method. Two were tested: the Newton–Raphson method  [2] and Homotopy  [13,14,3]. The first one has a complexity related to the size of the system. The solving time for homotopy mostly depends on the degree of the system and on the size of the system to a lesser extent. Recall that for a monomialx0α0⋯xnαn, its degree isα0+⋯+αn. The degree of a polynomial is the maximum of the degrees of its monomials. And for a system of polynomials of degreesd0,d1⋯dm, its degree isd0⋅d1⋯dm.With CM3 or CM4 the number of equations isO(k). To get the smallest value fork, vertices of a reference must cover a maximum set of edges. This is strongly related to the maximum coverage problem which is NP-hard. Withnstanding for the number of entities in the GCS, since the number of reference to try isO(n3)for CM3 andO(n4)for CM4, a brute force algorithm can be used in practice.For larger problems, a classical greedy algorithm provides a satisfactory outcome and for most of our examples it gives the best result. The greedy algorithm consists in iteratively choosing one of the most connected vertices and removing it from the graph. For instance, with example of Fig. 1, greedy strategy with 3 points reference could giveR={p4,p5,p6}and a system of size 6.Once a CM-system has been built, it has to be solved. CM-systems usually have several solutions, most of which are non-reals (about two-thirds of the solutions in our experiments). Indeed, many numerical values found are negative whereas they often represent squared distances. A numerical method like Newton–Raphson has a complexity mostly related to the size of the system. But this method only provides one solution. Since we have algebraic systems of equations, classical homotopy methods can be used in order to get all the solutions.With homotopy, the criterion is the degree of the system (Bézout or BBK bound). Indeed, the total degree of the system determines the number of paths which have to be followed by homotopy. Here, we have considered Bézout bound which is the product of the degrees of the equations. Let us notice that equations coming from CM determinants with 5 or 6 objects have degree either 2 or 4. As mentioned, due to Sippl optimization, the size of the matrix is the same for 5 or 6 objects. If all unknowns are in theith row (andith column by symmetry) then the degree is 2. Otherwise, it is 4. Homotopy complexity is mostly related to the degree of the system but also linked to the number of equations since in each path the system must be evaluated many times. Finding out the best system is then an optimization problem. It amounts to getting a system with a minimum degree with the least equations.So far, a brute-force algorithm is used. It tries all the possible references and provides two systems: the system that minimized the Bézout bound and the one with the smallest size. But it is possible to do better with a process of decomposition.In Section  2.2, system number 3 on Table 1 contains 6 equations and there is no smaller system when using algorithm CM3. Considering a single Stewart platform we could have a system with only 2 equations by using CM determinants. So by considering separately the two platforms, the overall system could have only 4 equations. Actually, this could be achieved by decomposing the system of constraints. We first recall some basic principles of structural and geometrical decompositions.Structural decomposition was first studied in order to perform a triangulation by blocks of systems of equations. Structural decomposition means here that only rearrangements of unknowns and of equations are used in a combinatorial way to decompose that systems. The first block contains as many unknowns than equations and can be solved first independently of the other equations. Once the equations of the first block are solved, the values of these unknowns become parameters in the other blocks. Thus, the system can be solved block by block.A classical algorithm for computing a structural decomposition is based on the well-known Dulmage–Mendelsohn decomposition (DM for short)  [15]. It uses a bipartite graph in which the unknowns yield the first set of vertices and the equations yield the second one. Each arc expresses then the membership of an unknown to an equation and is oriented from the unknown to the equation. In the first step, a maximum matching is sought in order to associate each unknown to the equation that can solve it. In the next step, for each arc of the matching the method adds an arc oriented in the opposite direction. Vertices are then divided into three parts. All vertices that can be reached from unsaturated equations (that are not extremity of a matching edge) are in the over-constrained part. Vertices that can be reached from unsaturated unknowns are in the under-constrained part and remaining vertices are in the well-constrained part. This latter is a subgraph wherevunknowns are matched tovequations. It has been shown that the decomposition does not depend on the choice of the maximum matching.In turn, the well-constrained part can be more finely divided into strongly connected components. In the reduced graph of strongly connected components, vertices represent blocks and arcs impose the order in which the blocks are to be solved. On the one hand, in  [16], this method is used in the context of systems of equations for the geometry where it is used to guide the sequence of pseudo-divisions in the Ritt–Wu method. But, on the other hand, the Dulmage–Mendelsohn algorithm has also been adapted to constraint graphs  [17]. There, the input is no more a bipartite graph, but a constraint graph where the vertices are labeled by the degree of freedom (in short DoF), the primitives and the edges, which corresponds to constraints, are labeled by the DoF they remove.Classical methods of geometric decomposition are based on the invariance up to rigid body motions and then involve two additional ingredients with the notions of references and borders.Given a GCS issued from CAD, a plain DM decomposition of a GCS would place all vertices in the under-constrained part. It is therefore necessary to choose a reference for “pinning” some primitives in order to get as many equations as unknowns. For instance in a 2D problem, a reference may be obtained by fixing a point at the origin and the direction of an incident line. Choosing a reference, however, has a great influence on the decomposition. In the example in the 2D sketch in Fig. 2with 12 points and 21 distances, the structural decomposition using DM is different according to the choice of a pair of points as a reference. For instance, by fixing:1.pointsp10andp11, we get the decomposition{p10},{p11},{p1,…,p9,p12}pointsp7andp8, we get{p7},{p8},{p1,…,p6},{p9,…,p12}pointsp1andp2, we get{p1},{p2},{p3},{p4},{p5,…,p8},{p9,…,p12}.Choosing a reference is quite different when considering usual geometric solvers using coordinates or CM-based solvers. In the first case, the primitives are always chosen in order to fulfill some constraints imposed by the constraint graph. For instance, in the 2D case, the choice of two points is subject to the condition that they must be involved in a distance constraint. On the contrary, when solving a GCS by a CM method as the previous ones, we can choose any triple or quadruple of points without consideration of constraint. In the following we will use the term of CM-reference to make a clear distinction with the usual notion.The notion of border is also an important notion when dealing with invariance. Indeed, the symmetry of an invariant system is broken by fixing a reference. The solutions found for a subsystem are not the general solutions and they cannot be used for continuing the resolution. On the other hand, one can add any invariant constraint built with the values of the solved subsystem and add them to complete the remaining constraint system.For example, consider the classic 2D GCS given in Fig. 3(a). After fixing the pointp1andp2, the algorithm of  [17] finds blocks{p1,p2,p6}and{p3,p4,p5}. This amounts to solve separately on the one hand trianglep6p1p2pand on the other hand all the other equations, that is to say, the figure composed of 5 points fromp2top6. But this system of 5 points is not rigid. However, if after the resolution of the trianglep6p1p2, the calculated distancep2p6is added as shown in Fig. 3(b) then the remaining system becomes well constrained up to rigid body motions. The GCS consisting of the pointsp2andp6with the distancep2p6is called the border. The new system can in turn be decomposed by choosing another reference. One can for example set the pointsp3and direction of segmentp3p4and isolate trianglep2p3p4.To summarize, values found for unknowns are used when using plain DM decomposition while in geometric decomposition, the transmitted information is looser and consists of relationships that are invariant up to rigid body motions (distances, angles, and so on).Most work on GCS decomposition methods is based on a general pattern; see for example  [18] or  [19]. For the present, we use the formalism of graphs as a GCS can be seen as a graph. Strictly speaking, with constraints with arity greater than 2, a GCS is a hyper-graph but the following discussion can easily be generalized to hyper-graphs.Let us recall some basic notions. With a graphG=〈V,E〉:•ifV1⊂V, thenG[V1]denotes the induced graph, it is a subgraph ofGan edge-induced graph is denoted byG[E1]whereE1⊂E: each endpoint of an edge ofE1is a vertex ofG[E1]G2=G−G1is the subgraphG[E−E1], so constraints ofG1are not inG2,G1andG2can have common primitivesG1+G2=(V1∪V2,E1∪E2)G1∩G2is the subgraphG[V1∩V2]a subgraphG1ofGis faithful ifG1contains primitives only connected to primitives ofG1, in others words, withG2=G−G1, the graphG1−(G2∩G1)is not emptyand for a subgraphG1(V1,E1)ofG, ifG2=G−G1, the borderBG1/Gis given(V1∩V2,(E1∩E2)∪Eb)whereEbis a set of constraints such thatBG1/Gis not under-constrained.With this terminology, a geometrical decomposition of graphGis a sequenceG1,G2,…,Gnwhere:•G1is a well-constrained subgraphG2,…,Gnis the decomposition sequence of graphG−G1+BG1/G.The result of a decomposition process is not necessarily unique. A decomposition is said maximal ifnis maximal.The more commonly used method for proceeding a bottom-up geometrical decomposition is as follows:Algorithm: GDecompositionInput: A GCSGas a constraint graphOutput: a list of constraint graphs1—inG, choose a referencernot yet chosen2—get a faithful graphG1⊂G+r(ris inG1)ifG1=G+rthenif no more unchosen reference inGthenreturnG1else goto 13—compute the borderBG1/G4—return GDecomposition(G1) @ GDecomposition(G−G1+BG1/G)where @ is the operator of concatenation of lists. This algorithm is rather a general method since the different tasks can be implemented in different ways.In step 1, the choice of reference is often made by searching a pattern: a planplwith a point ofpland a line ofplincident to the point, three points with three distances, etc. For step 2, once a referenceris set, a structural decomposition can produceG1, note thatris inG1. Indeed, any other subsystem is under-constrained. To findG1, other techniques are possible such as the use of geometric properties that reveal a subgraphG1and solve it at the same time.The goal of step 3 is to produce a not under-constrained subgraph. Several approaches exist. In the classical ones, the border can be completed to be well-constrained. It is easy most of the time since the border is often limited to two points and three points in 2D in 3D. When the border contains more elements it is necessary to use techniques such as those presented in  [20,21] for 2D problems or to invoke witness methods like in  [22]. In addition, completion may take the solving method into consideration like in  [20]. For instance, if subgraphs are solved by the locus intersection method, they must be completed in order to make this method successful. On the other hand, it is also possible to consider coherently over-constrained borders by saturating the corresponding constraint graph. Withnprimitives on the border, this leads to addO(n2)constraints. This obviously implies that the corresponding solving method can manage over-constrained GCS.In step 4, the call to GDecomposition(G1) leads to consider all possible references. To avoid this, the recursive call is not always performed, especially ifG1has few primitives. It is then not guaranteed to find the minimal decomposition.Once a decomposition is found, the successive constraint systems are solved in the order they appear in the list. The terminal solving methods can be either numerical or based on geometrical construction, or with ad hoc pre-determined systems. The solutions of the different systems are then assembled two by two with respect to their border. Since the constraint systems are well-constrained, the primitives of the border are sufficient to calculate a displacement that will join the two systems.For CM-systems, a bottom-up decomposition goes back over the GDecomposition method but with some distinctive features. Consider the steps of the above method.First, at step 1, a reference must be chosen. Recall that in GCS terminology, the notion of reference is slightly different from the one used in the CM-system. For a GCSS, a reference is any sub-GCSRsuch that the group of rigid body motions acts regularly on its solution set.For instance, in 3D, a configuration with three points constrained by three distances is a reference. But, the configuration corresponding to a tetrahedron constrained by six pairwise distances is not a reference since there could be two solutions up to rigid body motions.On the contrary, when considering CM-systems, a reference is made up by three objects without consideration on the constraints between them. The three distances or angles between that objects could even be three unknowns in the CM-system: the relative locations of the objects will be known once the whole system will be solved.Once a referenceris arbitrarily chosen, a system of equations is formed. Unlike the approach that works directly on the GCS (Cartesian approach, for example), a choice of reference leads to a specific system of equations as explained in Section  3. So a change of reference changes the system of equations.Step 3 has to be discussed before step 2. The completion of the border consists of adding pairwise relations of primitives of the border. With CM-methods this can be done by saturation that is to say by adding all possible distances. The border is then over-constrained beyond five primitives, indeed, with 3 or 4 points, for example, saturation distances lead to a triangle or tetrahedron in which all distances are known. Thus, the search for a subsystem in step 2 must take this into account and should be able to manage a possibly over-constrained system.In step 2, the algorithm of structural Dulmage–Mendelsohn decomposition is used to produce a faithful subgraphG1. Because of the border, the system is potentially over-constrained. The DM-decomposition then produces an over-constrained part. Therein, the matching associates each unknown to one equation and some equations are not matched. Since these equations are redundant, they can be removed.After the removal of unmatched equations, we get a structurally well-constrained system. Continuing the DM-decomposition yields the DAG (directed graph without cycle)DGof strongly connected components. SubgraphG1is built from the constraints contained in the componentsCc1,Cc2,…,Ccksuch as:•Cc1,Cc2,…,Cckis the beginning of a topological sort of vertices ofDGG1is faithfulG1is minimal in terms of primitives.So, our decomposition method for CM-systems follows this algorithm:Algorithm: decomposition for CM-systemsInput: a constraint graphGOutput: a list of irreducible constraint subgraphs ofG1—choose a 3 point referencernot chosen forG, if no morereference then returnGget equational systemEq=CM3(G,r)2—perform a Dulmage–Mendelsohn decomposition withequations removal:get bipartite graph fromEqcompute a maximum matchingremove unsaturated equationsget DAGDGof strongly connected componentsG1=getFaithfulGraph(DG, G)ifG1=Gthen goto 13—G2=G−G1BG/G1=completion(G1∩G2), makeBG/G1a cliqueadd note that new edges are distances whose values will comefromG1once solved4—decompose(G1) @ decompose(G2+BG/G1)Algorithm: getFaithfulGraphInput: a DAGDGof strongly connected components of equationsa constraint graphGOutput: a subgraph ofG1—Get a sequenceS=Cc1,Cc2,…,Cckthat corresponds to thebeginning of a topological sort of vertices ofDGand letG1bethe corresponding constraint subgraph ofGkis chosen such thatG1is faithful.2—By depth-search inDG, consider other beginnings of topologicalsort in order to makeG1minimal in terms of primitives.The decomposition yields a list of subgraphs that must be solved and then merged. Algorithms CM3 and CM4 of Section  3 can be used in turn with all possible references in order to get the best equational system in terms of the number of equations.A decomposition could be performed either on a CM-system or on a GCS after its translation into a system of equations and after adding coordinates for a reference. A natural question arises about the difference between the decomposition of a GCSGor a CM-system derived fromG.The geometric decomposition methods always organize constraints in order to make appear monolithic rigid subsystems. The main feature of these approaches lies in the consideration of the invariance up to rigid body motions that enables:•to add constraints for referencesto add constraint on the border of subsystemsto remove constraint of reference for merging subsystems.Moreover, the fact that one primitive at least does not belong to the border of subsystems guarantees the termination of the decomposition process.For a given reference, it is known that the maximal decomposition is given by the algorithm of Dulmage–Mendelsohn. Trying all possible references ensures to yield a maximal decomposition. Thus, the geometric decomposition algorithms proposed in works like  [19,18] give the same results up to the choice of references. That is to say they give the same decomposition to the same problems. The difference lies in how references are chosen and how borders are built.In Section  3, we saw that for a GCSGtranslated into a CM-systemCby algorithms CM3 or CM4, all constraints ofGare taken into account inCand all solutions ofGare solutions ofC. The same reasoning can be made for a subsystemG1ofG. If, forG, a CM-reference is chosen inG1then the CM-system will have a CM-subsystem that corresponds toG1. Since, at worst, all references are considered,G1will be found. With CM-systems, elementary components (Cciin the algorithm above) are not the same as the traditional approach (with Cartesian equations or constraints) but subgraphs returned by the procedure getFaithfulGraph are the same.The difference mainly is in the ingredients of this decomposition which are references and borders. CM-references of 3 points are used for the decomposition. The production of these 3 points is basic and does not require a study as in most other methods. Once the decomposition is obtained, CM-references of 4 points can be considered on each sub-system to try to reduce the number of equations or the degree of the system.Regarding the border, this method has the advantage of not needing a well-constrained completion. The border may be over-constrained and is therefore very easy to make by saturating the system. In the research phase of the strongly connected components, supernumerary constraints are removed, but they must then be taken into account in the optimization of each subsystem. Indeed, for a given reference, the constraints in the border are primarily eliminated if they are of external edges.Finally, the interest of a CM-decomposition lies in a simpler production of references, a simpler completion of border and smaller systems of equations on which the decomposition is calculated.The decomposition algorithm implements a divide and conquer strategy. Its average complexity is not easy to compute since the step where the division occurs cannot be predicted. However we can make a rough analysis regardless of the division step to give an order of the worst case. The objective is to show that the algorithm can be reasonably used in practice.In our decomposition algorithm, for each reference the following steps are applied in sequence: DM algorithm, a topological sorting and border calculation. Note that in a constraint graph withnvertices the number of edges is3n−6which is inO(n). During the decomposition process, the number of references that are considered isnchoose 3 which is inO(n3). Foreequations, the complexity of DM is inO(e2.5)(see  [23]). Sinceeis inO(n), DM decomposition complexity is inO(n2.5). The topological sort which applied to the graph of strongly connected components is linear in the number of edges of the DAG. The process of saturating a border can be done inO(n2)as it is to produce the constraints for each pair of vertices. Thus, for each reference we have in the worst case aO2.5complexity. Then taking account of all the references, the complexity of our decomposition algorithm is at worst inO(n3+2.5).Subsystems about 3 entities are too small to be faithful. Subsystems of 4 entities are tetrahedron and can be filtered out as earlier explained. So minimal subsystems have 5 entities. To have a light presentation of the decomposition algorithm we did not specify the subsystems with five entities are returned as is. Thus, all references are not considered in the decomposition algorithm. Nevertheless for each subsystem, algorithm CM3 or CM4 can be performed to try to reduce the size of the system to be solved. Thus, ultimately, all references are potentially tested.CM-systems contain polynomial equations. To solve them, existing methods are often expensive. This is the case of Gröbner basis or methods based on Bernstein polynomials  [24]. Homotopy methods, also called continuation method, can be very expensive but the cost is a priori known because it strongly depends on the degree of the system. They also have the advantage of being implemented in several software robust and efficient as PHCpack, Bertini or Hom4PS  [25].Basically, a homotopy function is defined byH(X,t)=(1−t)⋅F(X)+t⋅G(X)withtin range[0,1]. FunctionG(X)is the function whose solutions are sought. FunctionF(X)is a function whose solutions are known and which has as many solutions as functionG.Softwares that implement homotopy input a polynomial system, they calculate the degreedof the system and generate a systemF(X)withdknown solutions. By varyingt, each solution ofF(X)heads toward a solution ofG(X). From values andxi,tithe new valuexi+1,ti+1is calculated by prediction–correction  [26]. However,dis an estimate of the number of solutions and some of them lead to solutions at infinity. This is for example the case of a system of degree one involving the intersection of two parallel lines. When following a solution path to infinity,tgrows slowly and never reaches 1. In most software, a solution is considered to be the solution at infinity whentgrows slowly and tends to 1 but this stopping numerical criterion does not guarantee thattwill never reach 1. Such solutions are penalizing on the one hand because they slow down the search for solutions and on the other hand because some other solutions can be wrongly considered solutions at infinity.Homotopy software is not always very stable. Indeed, the functionF(X)is constructed randomly and some solutions can be misinterpreted as solutions at infinity. For our experiments we used Hom4PS. This software is fast and robust in the sense that solutions are always the same from one running to another.Fig. 4(a) and (b) present two examples taken from  [27]. It is a matter of distance models of two molecules that are disulfide for Fig. 4(a) and bicyclohexane for Fig. 4(b). They involve 3D points and distance constraints.Decomposition algorithm establishes that the disulfide model is irreducible. Next, brute-force algorithms, i.e. calling CM4 or CM3 with all possible references, provide results that are summarized in Table 2. With a 4 points reference, one of the best CM-system in terms of number of equations has 6 equations and its degree is 212. Hom4PS was executed first in the classical mode and then in the polyhedral mode. In the classical mode, the number of solutions ofF(X)to track is the Bézout bond (BB) which is the degree of the polynomial system. In the polyhedral mode, a better estimation of the number of possible solutions is performed. It is based on the mixed volume polytope computation  [28] and then leads to follow a smaller number of paths to track. In  [27] distances are proposed and 18 solutions are found in about 13 min with a divide-and-conquer solver based on Bernstein representation. With the proposed CM-system, Hom4PS finds the solutions in 5.3 s. By selecting the degree criteria, the brute-force algorithm yields another reference with more equations but with lower degree. So the number of paths to track is reduced and the numerical solving is faster. With a 3 points reference, one of the best system both in terms of size and degree has 5 equations and a Bézout bound of 29. Although the BKK bound is higher than in the previous experiment, a lower number of equations makes the computational time shorter.Table 3presents some examples processed with and without decomposition. The third line is related to example of Fig. 4(b). Without decomposition the smallest system has 8 equations and is solved in more than 4 s. Decomposition yields three subsystems:{p1,p2,p3,p4,p5,p6},{p1,p2,p7,p8,p9,p10}and{p1,p2,p6,p10}. The first two subsystems have two equations. Indeed, with{p1,p2,p4}as CM-reference, there are two external edgesp5p6andp3p5. Each external edge leads to an equation and the whole system has two unknowns: distancesp1p4andp2p5. The third subsystem is a tetrahedron where all the distances are known so no numerical solving is needed. In this subsystem, all data are known to perform a immediate computation of coordinates. In Table 3, repartition of equations is denoted by 2/2/0 meaning that the constraint problem is cut in three subsystems, two with two equations and one with no equation. Finally all coordinates are computed according to the decomposition order. Since pairs of subfigures share three points with consistent distances, they can be assembled.The example named pyramids refers to Fig. 4(c). It consists of two pyramids sharing edgep3p4and constrained by an angle between planespl2andpl3. Pointsp5,p1,p2lie onpl2andp8,p7,p6lie on planepl3. The two pyramids with coplanar bases are independently solved in subsystems with two equations. Each subsystem has five points, one plane, eight constraints of distance and four constraints of incidence. For pyramid with base in planepl1for example, a CM-reference could bep1,p2,p3. So there are two external edges: distancep5p4and coplanarityp4pl1leading to two equations. Another subsystem has planepl2and pointsp1,p2,p5. This system has no equation. It is the same with planepl3and pointsp8,p6,p7. The remaining GCS is shown in Fig. 4d where distances between pointsp3,p4and planespl2,pl3are added border constraints. Again, in CM formalism, this system has no unknowns.The last example comes from a random arrangement of 10, 100 and 200 Stewart platforms. Decomposition process isolates each platform that are separately solved.

@&#CONCLUSIONS@&#
