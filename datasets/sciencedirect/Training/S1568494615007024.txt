@&#MAIN-TITLE@&#
Solving generalized Nash equilibrium problems through stochastic global optimization

@&#HIGHLIGHTS@&#
Presents a global optimization application to a relevant class of strategic games (generalized Nash equilibrium problems).Proposes a simpler solution to GNEP's based on flexible constrained optimization, avoiding multilevel optimization typical complexity.Extends the scope of presently known (and effective) methods for GNEP's by allowing nonconvex cost functions for individual players and related relaxations.

@&#KEYPHRASES@&#
Adaptive simulated annealing,GNEP,Generalized Nash equilibrium problems,Nash equilibria,Global optimization,Metaheuristics,

@&#ABSTRACT@&#
Generalized Nash equilibrium problems address extensions of the well-known standard Nash equilibrium concept, making it possible to model and study more general settings. The main difference lies in that they allow both objective functions and constraints of each player to depend on the strategies of other players. The study of such problems has numerous applications in many fields, including engineering, economics, or management science, for instance. In this work we introduce a solution algorithm based on the Fuzzy Adaptive Simulated Annealing global optimization method (Fuzzy ASA, for short), demonstrating that it is possible to transform the original task into a constrained global optimization problem, which can be solved, in principle, by any effective global optimization algorithm, but in this paper our main tool will be the cited paradigm (Fuzzy ASA). We believe that the main merit of the proposed approach is to offer a simpler alternative for solving this important class of problems, in a less restrictive way in the sense of not demanding very strong conditions on the defining functions. Several case studies are presented for the sake of exemplifying the proposal's efficacy.

@&#INTRODUCTION@&#
This paper aims to introduce a new approach for solving generalized Nash equilibrium problems (GNEP's, for short), taking into account that they have been used actively in many fields during the past decades, and research on this topic is gaining momentum, particularly in the operations research field. The proposed method transforms the original problem into a constrained optimization one and, by means of a global optimization algorithm, searches for points that represent the desired generalized Nash equilibria for the original task. Hence, the effectiveness of the overall method depends primarily on the efficacy of the chosen optimization algorithm. As GNEP's are used to model many problems in different disciplines, researchers in diverse fields tend to work independently. Hence, even today many existing results are not widely known, although some basic concepts were well-established, such as the problem definition and certain approaches considered adequate for solving the problem, such as using Nikaidô–Isoda functions. The general issue itself (GNEP) has been referred to as a social equilibrium problem, coupled constraint equilibrium problem, or abstract economy. We will adopt the term generalized Nash equilibrium problem, and define it in the sequel [4].As is well-known, in GNEP's, players’ cost functions and their strategies are real valued and continuous, but more importantly they have the distinctive feature that players face constraints that depend on their opponents’ strategies. This feature contrasts with standard Nash equilibrium problems, in which players’ actions are not restricted by the strategies chosen by others. As expected, the coupled constrained action space in GNEP's makes them more difficult to solve than in conventional Nash equilibrium problems and, naturally, algorithms able to solve them can be applied to standard NEP's as well. GNEP's can be situated in a setting consisting of N players, where player i controls nivariables, concentrated into a vectorxi∈ℝni. Denoting by x the vector formed by all these strategic variables, we have(1)x≜x1x2⋮xNwherex∈ℝnand n=n1+n2+⋯+nN. Also, we denote by x−ithe vector x without the xisub-vector.(2)x−i≜x1x2⋮xi−1xi+1⋮xNMoreover, it is usual to write x=(xi, x−i). Please, observe that the notation (xi, x−i) does not mean that the components of x have been reordered, and xiis the first block. An additional assumption is that all players announce simultaneously their decisions (strategic values), and each one is assigned one loss or cost function ϕi(x) (ϕi:ℝn→ℝ). Hence, when overall decision vector is x, player i has to “pay” or “lose” ϕi(x). In this fashion, the cost function of a specific player may depend on other players’ decision vectors, the same occurring to the strategy sets of each player, what is not true in standard Nash equilibrium problems.Assuming that players act rationally, that is to say, given the decision vector x−iof other players, they try to choose a decision vector xithat minimizes their cost function, it is natural to expect that a search for the solution of the following optimization problem occurs at each game instance(3)minxiϕi(xi,x−i)s.t.xi∈Xi(x−i)whereXi(x−i)≜{xi∈ℝni|(xi,x−i)∈X}, and X is assumed to be a non-empty, closed and convex subset ofℝn. X is the overall strategy set.So, we can define a vectorx*=(x*,1,x*,2,…,x*,N)Tas being a generalized Nash equilibrium if, for all i=1, 2, …, N, the subvector x*,isolves the following optimization problem(4)minxiϕi(xi,x*,−i)s.t.xi∈Xi(x*,−i)or, equivalently,(5)ϕi(x*,i,x*,−i)≤ϕi(xi,x*,−i)∀xi∈Xi(x*,−i)for i=1, …, N.GNEP's are also known as, for instance, social equilibrium problems, or Nash equilibrium problems with shared constraints, among other expressions. The GNEP was formally introduced by Debreu [3] in 1952, and since then has been deeply associated to the mathematical economics field. However, only in recent decades interesting applications to other areas started to arise, and researchers recognized its importance outside economics. Although it can be applied to virtually any field, typical applications can be found in telecommunications and electrical engineering, computer science, market regulation, or ecological scenarios, for instance.It is worth mentioning that GNEP's frequently have multiple solutions. In general, different solutions of specific equilibrium problems (such as the standard Nash equilibrium problems or GNEP's) may have different implications, differently from an optimization problem in which all optimal solutions can be regarded as having equal value in terms of the objective function. From this viewpoint it may be meaningful to choose a particular generalized equilibrium, featuring a certain additional property. In [34] it is proposed the solution concept named “normalized equilibrium”, that is a special GNE characterized by conditions imposed on Lagrange multipliers associated with the constraints in each player's problem. The uniqueness of a normalized equilibrium can be established under certain conditions [34,17].It is a well-known fact that the standard NEP can be transformed into a variational inequality problem [5]. In addition, it is possible to face GNEP's as quasi-variational inequalities (QVI's, for short) [2,16]. On the other hand, considering that efficient methods for solving QVI's are rare, this type of characterization might not be very useful, in practical terms. In another direction, it was stated in [6,11], for example, that certain solutions of the GNEP (the normalized Nash equilibria) can be found by solving a suitable standard VIP associated to the GNEP.However, certain VIP based methods require a higher degree of smoothness of the cost functions than other approaches, based on Nikaidô–Isoda functions [26], that play a central role in the related literature. Relaxation methods using Nikaidô–Isoda functions are studied in [24,35], and a proximal-like method based on them is presented in [11].In [18], it is reported the use of a regularized version of the Nikaidô–Isoda function in order to get different optimization problems whose global minima are the normalized solutions of the GNEP. In that work, the function and its regularized version are formally defined, and they obtain a constrained optimization problem equivalent to the GNEP. However, the objective function corresponding to this optimization problem is nonsmooth. Then a smooth optimization problem is derived whose solutions characterize the class of normalized Nash equilibria of the GNEP. Following this, it is shown how the previous techniques can be used in order to get a smooth unconstrained optimization reformulation of the normalized GNEP solutions. The regularized Nikaidô–Isoda function was employed earlier for solving standard NEPs in [15]. The standard NEP is known to be a special case of an equilibrium programming problem [10]. This observation is emphasized in [18] by interpreting the GNEP as a particular instance of an equilibrium programming problem.Although GNEP's represent an important modeling paradigm [1], the existing approaches aiming at their solution are somewhat dispersed, in terms of the diversity of theoretical tools used when trying to solve them. Rosen studied jointly convex GNEP's [34] and this context was very frequent in the literature until very recently. He introduced the first algorithm (a projected gradient-type method) for solving jointly convex GNEP's, and some other algorithms were later developed for this kind of problems, one of the most important is the relaxation method [24,35], based on Nikaidô–Isoda functions. Of course, other approaches may be employed when solving jointly convex problems. Among them we may highlight the recently proposed methods from [17–19], which are still based on the Nikaidô–Isoda function and consequently computationally intensive, or one of the variational inequality approaches [6], which are also limited to the jointly convex case. There are many other proposals, and the interested reader can consult [4] and the pointers therein to the related literature. When considering unrestricted GNEP's the situation becomes even more difficult, because it is known that a GNEP can be reduced to a Quasi Variational Inequality [2,4,16]. On the other hand, the development of globally convergent algorithms for the solution of QVI's is still a tough task, and this transformation is of little algorithmic use, even if one can use gap functions to transform a given GNEP into an optimization problem. Nikaidô–Isoda functions can be very useful in transforming GNEP's into optimization problems, but the computational overhead is substantial and the conditions for establishing convergence are somewhat complicated [33,9]. Unfortunately, we can say that, excepting penalty methods and algorithms for very specific applications, the study of methods for solving general GNEP's and their convergence in more general conditions is still in its infancy. Penalty algorithms directed to the solution of GNEP's are based on the common penalization approach, by eliminating the hard inter-related constraints in a GNEP, and reducing it to a somewhat simpler NEP. To this latter problem, we can then apply several methods based on the optimization or variational inequality techniques, for instance. The penalization approach to GNEP's is relatively recent and was initiated by Fukushima and Pang in [12], in which they propose a sequential penalty approach for solving GNEP's, and an infinite sequence of differentiable penalized problems is solved.The use of exact penalty approaches in which a single nondifferentiable NEP has to be solved was treated in [8], being this issue also addressed in [13], where, among other things, some conditions are stated under which a penalty approach can be employed to find solutions for GNEP's. Although many problems have to be fully addressed (among them a complete understanding of theoretical conditions under which useful results can be established for a penalty approach), penalty based methods seem to be very promising approaches for solving GNEP's [7].In [23] a metaheuristic paradigm is employed to study the Nash normalized equilibrium, which can be obtained by transforming the GNEP into a bi-level program with an optimal value of zero in the upper level. In that paper, it is proposed a Differential Evolution based bi-level programming algorithm that uses Stochastic Ranking to handle constraints and solve the resulting bi-level programming formulation – in this work Nikaidô–Isoda functions are used as well.In [18], it is described a well-known approach, cited previously in this text and detailed here in order to illustrate the computational complexity normally associated to existing methods aimed at solving GNEP's. In that paper, the main theoretical tool used in obtaining one of the optimization reformulations of the GNEP is the Nikaidô–Isoda function, defined by(6)Ψ(x,y)≜∑i=1N[ϕi(xi,x−i)−ϕi(yi,x−i)]From which we can define(7)V(x)≜supy∈Ω(x)Ψ(x,y),x∈Xwhere it is assumed that the supremum always exists for some y∈Ω(x). Then it is possible to conclude that V(x) is nonnegative for all x∈Ω(x), and that x* is a solution of the GNEP if and only if x*∈Ω(x*) and V(x*)=0. Therefore, finding a solution of the GNEP is equivalent to computing a global minimum of the optimization problem(8)minx∈Ω(x)V(x)with(9)Ω(x)≜X1(x−1)×⋯×XN(x−N)It is worth noting that this optimization problem usually has a nontrivial feasible set, taking into account that Ω(x) depends on the overall vector x. But, in view of a certain result established in [18] (Lemma 2.1), problem (8) is found to be equivalent to the following one(10)minx∈XV(x)Note that to each evaluation of V(x) corresponds a full optimization operation, defined by (7).Even though Nikaidô–Isoda functions are very well-established in the literature, they feature certain not so favorable properties. First, given a vector x, the supremum in (7) may not exist unless additional assumptions (like the compactness of X) hold, and, besides, this supremum is usually not attained at an isolated, single point, implying that the mapping V and, therefore, the corresponding optimization reformulation (10), may be nondifferentiable. To overcome these difficulties, a simple regularization of the Nikaidô–Isoda function may be used (please, see [18]) – this idea was employed earlier in other contexts [14,15,25]. In summary, we conclude that the present approaches to the GNEP are computationally expensive, and a new approach that could simplify the search process and reduce the overall processing effort would be welcome.In this work, our aim is show that it is possible to find Nash equilibria (of games with continuous strategy sets) in GNEP's after a single optimization run. The general idea can be applied, in principle, by means of any effective, general purpose metaheuristic global optimization method, and we chose the one known as Fuzzy Adaptive Simulated Annealing (Fuzzy ASA). The focus is on demonstrating that the Fuzzy ASA method is able to solve GNEP's, faced as constrained optimization problems, and without using multi-level optimization techniques. The first step is to alter the problem of computing generalized Nash equilibria, that can be faced as a set of coupled and simultaneous constrained optimization problems, into a single one, whose solutions are exactly the optimizers of the original problem. This can be done by means of penalty techniques, and this transformation is shown to be effective, making it possible to succeed in our task. Besides, taking into account the ample scope of Fuzzy ASA, the proposed method tends to be more flexible than some of the already existing ones in many circumstances, taking into account that it is able to deal with nondifferentiable and nonconvex functions defined on nonconvex domains. In order to be more precise, let us consider the following GNEP.Findx*=(x*,1,x*,2,…,x*,N)T∈ℝnsuch that, for all i=1, 2, …, N, the subvector x*,isolves the following optimization problem(11)minxiϕi(xi,x*,−i)s.t.xi∈Xi(x*,−i)or, equivalently,(12)ϕi(x*,i,x*,−i)≤ϕi(xi,x*,−i)∀xi∈Xi(x*,−i)for i=1,…,N. WhereXi(x*,−i)≜{xi∈ℝni|(xi,x*,−i)∈X}, and X, the overall strategy set, is assumed to be a nonempty and closed subset ofℝn(n=∑i=1Nni).In our proposal, it is assumed that the functions ϕiare continuous and not necessarily differentiable or convex, being, obviously, bounded on compact domains – in the literature, further conditions are typically imposed on them.•InitializationFor each ϕiand Xi(x−i), determine their specific attributes that could be translated into numerical constraints which, once incorporated in penalized cost functions, could guide the algorithm toward the set of proper solutions.For instance, if the loss functions are differentiable, forcing their partial gradients (player i has control of only nivariables) to zero helps in finding proper equilibria, considering that it is a necessary condition that occurs at extrema of that kind of mappings.The same is valid relatively to Xi(x−i) sets, becoming easier whenever they are expressed as parametric inequalities, namely,(13)Xi(x−i)≜{xi∈ℝni|gi(xi,x−i)≤0}Step 1For each attribute found in the previous step, define an additive (penalty) term capable of translating the respective attribute into a numerical value, so that to lower values correspond more favorable regions of the search space and vice-versa. For example, norms of gradients could be proper additive terms when trying to reach local extrema of differentiable functions.Step 2Construct the overall objective function by defining weights that will be used in the penalized global optimization step. These weights will be multipliers for each additive term, determining the relative importance of each one during the optimization process, like in typical penalized minimization situations.The resulting cost function will have the following general appearance(14)C(x)≜∑i=1NFϕi×ϕi(x)+∑i=1NFGradi×∥∇niϕi(x)∥2+∑i=1NFConstri×Constri(x)+∑i=1NAttrFAttri×Attrϕi(x)whereFϕi,FGradi,FConstriandFAttriare the mentioned weights,∇niϕi(x) is the partial gradient of ϕi(x), if it is differentiable,Constri(x) corresponds to the penalty term associated to ϕi(x),Attrϕi(x)corresponds to ith auxiliary numerical function capable of driving the optimization process into favorable regions (NAttrinstances).Step 3Submit C(x) to the chosen global optimization algorithm (in this paper, we will use Fuzzy ASA).Final decision stepExtract the several subvectors from the overall x found in the previous step and assess the outputs. In case of unsatisfactory results, go to step 2, else emit the subvectors as the definitive solution.As stated above, any effective global optimization algorithm could, in principle, be used to optimize the global cost function. Our particular choice was motivated by the fact that Fuzzy ASA has shown to be very efficient in many different fields and able to deal with difficult optimization tasks.Fuzzy Adaptive Simulated Annealing is based on the ASA method [20] that uses the simulated annealing concept to optimize numerical functions, but presenting a significant number of improvements. In this section we will describe some relevant features of this important implementation.It is the dynamical re-scaling of parametric temperatures, adapting generating probability distribution functions to each dimension according to different sensitivities. Therefore, if the cost function does not present significant variations whenever a given parameter is varied in run-time, it is understood that, by extending the search interval amplitude in that particular dimension, the overall performance could be improved, and vice-versa.ASA software architecture offers the possibility of adjusting several structural parameters related to the quenching process, allowing the user or any automatic control mechanism to change the default behavior of the “cooling” process, responsible for driving the evolution of the parametric temperatures. This mechanism is useful in case of stagnation inside suboptimal regions.The ASA implementation allows users to alter virtually any subsystem without expressive programming effort. It is thus possible to change the behavior of generation/acceptance processes, termination criteria, or seed generation, by changing the values of certain easily accessible variables. In this fashion, after acquiring some experience on its structure, application development is usually fast.The ASA approach aims to find function minimizers inside a pre-established hyper-rectangle and generates points componentwise, according to the following scheme:xi+1=xi+Δxi,withΔxi=yi(Bi−Ai),[Ai,Bi]=intervalcorrespondingtoi-thdimension,yi∈[−1,1]isgivenbyyi=sign(ui−1/2)Ti[(1+1/Ti)|2ui−1|−1],where ui∈[0, 1] is generated by means of the uniform distribution, and Tiis the present temperature relative to dimension i.The compactness of search space is not a serious limitation in practical applications and, in the absence of previous information about optima locations, it suffices to choose sufficiently large hyper-rectangular domains. In addition, the quenching mechanism can benefit, in many cases, the efficiency of the convergence process, although there is always the possibility of reaching prematurely local extrema. In certain settings, however, we may not have alternative ways out of a stagnation situation. In order to overcome this problem, a fuzzy controller was constructed (Fuzzy ASA) [30]. The approach is very simple: the original ASA system is faced as a MISO (Multiple Input Single Output) dynamical system and the additional code simply inserts a feedback loop, by sampling its output (current value of objective function) and acting in its inputs (a subset of run-time adjustable parameters, related to the quenching process) according to a fuzzy control strategy (control algorithm), behaving like human beings whenever subject to similar situations. Hence, active run-time fuzzy control coupled to previously existing ASA mechanisms can regulate temperature evolution, besides being able to take evasive actions in case of premature convergence. In its present version, Fuzzy ASA code rises the quenching degree after detecting decreasing optimization performance or potential stagnation states, aiming to recover from a possible undesirable convergence to nonglobal optima. It is important to note that this additional module does not try to substitute the many effective devices already present in the original ASA code, just complementing them in atypical situations.It is worth to highlight that ASA and its variations, like Fuzzy ASA for example, have been applied to several important fields, such as Signal Processing, Geophysics, or Statistics [20,21,27,28,30,31]. This can be understood by noting that, in practically all scientific domains, it is possible to transform certain design tasks into parametric optimization ones by finding cost functions capable of conveying all necessary constraints, and whose optimizers correspond to proper solutions for the original problems.

@&#CONCLUSIONS@&#
