@&#MAIN-TITLE@&#
Video-based personalized traffic learning

@&#HIGHLIGHTS@&#
We introduce a novel method to estimate vehicles’ personalized driving characteristics based on an input video.The learned characteristics can be employed for traffic reconstruction and agent-based traffic simulation.Our offline learning approach with an adaptive genetic algorithm outperforms existing methods for model calibration.Our system can describe drivers’ adaptation to the surrounding traffic situation using IDMM.

@&#KEYPHRASES@&#
Traffic control,Personalized learning,Video-based,Genetic Algorithm,

@&#ABSTRACT@&#
We present a video-based approach to learn the specific driving characteristics of drivers in the video for advanced traffic control. Each vehicle’s specific driving characteristics are calculated with an offline learning process. Given each vehicle’s initial status and the personalized parameters as input, our approach can vividly reproduce the traffic flow in the sample video with a high accuracy. The learned characteristics can also be applied to any agent-based traffic simulation systems. We then introduce a new traffic animation method that attempts to animate each vehicle with its real driving habits and show its adaptation to the surrounding traffic situation. Our results are compared to existing traffic animation methods to demonstrate the effectiveness of our presented approach.

@&#INTRODUCTION@&#
With the popularity of vehicles and the dramatically increasing demand on transportation, road transport has brought about more and more serious negative effects—traffic congestion, traffic accident, and environmental pollution. Traffic management has been a global challenge with its direct impact on economy, environment, and energy. Meanwhile, traffic simulation has found its wide use in computer animation, computer game, and virtual reality [1,2]. Some methods try to simulate each vehicle’s behaviors while others aim to capture high-level flow appearance. However, the simulated results usually do not correlate to each driver’s personalized driving behavior. Moreover, with better vehicle detection and tracking technology and more software tools for viewing road network, such as OpenStreetMap and GPS, there is a growing need to present realistic traffic scenarios in a virtual environment based on real-world vehicle trajectory data.In the real world, drivers’ driving behaviors vary significantly depending on time, place, personality trait, and many other social factors. These variations in driving behaviors are often characterized by observable factors such as driver’s speed choice, gap acceptance, preferred rate of acceleration or deceleration, environmental adaptation factor, and so on. Estimating such characteristics is an important task if we want to reconstruct the traffic flow correlating to an input real traffic. However, existing traffic simulators set these parameters as random values around the average of empirical values, which are hard to reflect drivers’ personalized driving behaviors in a specific environment. Moreover, little attention has been paid to this problem in existing traffic simulation methods.In this paper, we propose a data-driven method to simulate virtual traffic flows that exhibit driving behaviors imitating real traffic flows. We record the motion of vehicles from an aerial view using a camcorder, extract the two-dimensional moving strategies of each vehicle in the video, and then learn the specific driving characteristics from the observed trajectories.Learning driving behavior from videos is a challenging problem because the motion of each driver is influenced by not only the local road traffic condition, but also the driver’s personality and social factors, which cannot be directly seen in the captured video. We choose a short clip from the input video as the learning sample, and use a microscopic traffic model to approximate each vehicle’s behavior. Since 1940s, lots of traffic simulation models have been proposed, tested and evaluated for calibration. Among them, the intelligent driver model (IDM) [3] was proven to be one of the best approximation models and it conforms to our daily driving habits. The intelligent driver model with memory (IDMM) [4] is an expansion of IDM which introduces memory effects to describe drivers’ adaption to the congested traffic. In this work, we revise the original IDMM model to describe the adaptation of drivers to the surrounding traffic situation (not limited to congested traffic).We present a mapping between the low-level IDMM parameters and high-level driving characteristics. Inspired by the theory on the car-following model calibration [3], we utilize a nonlinear optimization scheme to compute each vehicle’s optimal parameter set of IDMM. Different from previous model calibration methods, we develop an adaptive genetic algorithm to better fit for traffic animation.The main contribution of the paper is that we introduce a novel method to estimate vehicles’ personalized driving characteristics based on training data from an input video. These parameters are then employed to reconstruct the traffic flow conforming to the video. We also present a new traffic animation method using IDMM to show drivers’ adaptation to the surrounding traffic situation. In addition, we propose an offline learning approach combining IDMM with an adaptive genetic algorithm, which outperforms existing methods for model calibration. Our approach can reproduce new traffic scenarios exhibiting similar driving behaviors with the sample video. Fig. 1shows a reconstructed scenario using our method.The rest of the paper is organized as follows. Section 2 describes the related work on traffic animation and model calibration. Section 3 presents an overview of our approach. Sections4 and 5 give a detailed description of the algorithm. The performance analysis and simulation results are shown in Section 6. Finally, we conclude the paper and discuss the future work in Section 7.

@&#CONCLUSIONS@&#
This paper presents a new approach for traffic reconstruction and sample-based simulation, in which each vehicle’s specific driving characteristics are learned from the trajectory data exacted from the video sample provided by users. We introduce an adaptive genetic algorithm to search for each vehicle’s optimal parameter set of IDMM. Our adaptive genetic algorithm outperforms existing methods for model calibration. The adaptive crossover and mutation rate and elitist strategy greatly accelerate the convergence speed and improve the overall search capabilities. What’s more, because of the use of IDMM, our system can describe the adaption of drivers to the surrounding traffic situation.To the best of our knowledge, in the computer graphics community, this is the first attempt at presenting each vehicle’s real specific driving characteristics and simulating a virtual traffic flow that behaves similarly to the real traffic in the input video.Besides the AGA, other nonlinear optimization methods, such as PSO, are suitable candidates for the offline learning as well. Our offline training process can be further accelerated because each driver’s driving characteristics can be calculated in parallel with the input video available. In our current implementation, the vehicle trajectory data is obtained using the software NGSIM-VIDEO. The defects of the software itself and the shortcomings in manual operations both may bring about the noise in data. We are now developing our own system on vehicle detection and tracking. In addition, we mainly focus on the de-acceleration strategy learning. Little work has been done to lane-changing behaviors because of its complex nature. In our future work, an extension would be to learn each vehicle’s lane changing habits to overcome the limitation, which will lead to a more vivid traffic reconstruction and simulation.