@&#MAIN-TITLE@&#
Comparison of beamformers for EEG source signal reconstruction

@&#HIGHLIGHTS@&#
Eight beamformers were compared on reconstruction of EEG source signals.Spatial and directional pass-bands were calculated for both simulated and real EEG.Effects of different parameters of simulated source on beamformer output are shown.White-noise spatial maps of the beamformers are shown.

@&#KEYPHRASES@&#
Beamformer,EEG,Gain,Region of interest (ROI),Signal-to-noise power ratio (SNR),Time-course reconstruction,

@&#ABSTRACT@&#
Recently, several new beamformers have been introduced for reconstruction and localization of neural sources from EEG and MEG. Although studies have compared the accuracy of beamformers for localization of strong sources in the brain, a comparison of new and conventional beamformers for time-course reconstruction of a desired source has not been previously undertaken. In this study, 8 beamformers were examined with respect to several parameters, including variations in depth, orientation, magnitude, and frequency of the simulated source to determine their (i) effectiveness at time-course reconstruction of the sources, and (ii) stability of their performances with respect to the input changes. The spatial and directional pass-bands of the beamformers were estimated via simulated and real EEG sources to determine spatial resolution. White-noise spatial maps of the beamformers were calculated to show which beamformers have a location bias. Simulated EEG data were produced by projection via forward head modelling of simulated sources onto scalp electrodes, then superimposed on real background EEG. Real EEG was recorded from a patient with essential tremor and deep brain implanted electrodes. Gain – the ratio of SNR of the reconstructed time-course to the input SNR – was the primary measure of performance of the beamformers.Overall, minimum-variance beamformers had higher Gains and superior spatial resolution to those of the minimum-norm beamformers, although their performance was more sensitive to changes in magnitude, depth, and frequency of the simulated source. White-noise spatial maps showed that several, but not all, beamformers have an undesirable location bias.

@&#INTRODUCTION@&#
Electroencephalography (EEG) and magnetoencephalography (MEG) are noninvasive tools for functional brain imaging using scalp recording. Compared with other common tools for brain functional imaging such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), which measure relatively slow changes in blood flow and metabolic activity which are indirect markers of brain electrical activity, EEG and MEG measure brain electrical activity with millisecond temporal resolution. This advantage provides opportunities for studies of highly dynamic and transient neural activity. In recent years, brain source imaging and reconstruction from continuous and single-trial EEG/MEG data have received increased attention aimed at improving the understanding of rapidly changing brain dynamics [1–3] and using this for improved real-time brain monitoring, brain computer interface (BCI), and neurofeedback [4–6]. In contrast, EEG and MEG have poor spatial resolution relative to fMRI and PET. This is, in part, due to EEG and MEG mostly reflecting the electrical activity of the cortical grey matter, with deeper brain activities attenuated and contributing considerably less to the EEG/MEG signals. The beamformer provides a versatile form of spatial filtering, suitable for processing data from an array of sensors [7]. Beamformers were originally applied in array signal processing including sonar, radar, and seismic exploration [8]. The basic principle of beamformer design is to allow the neuronal signal of interest to pass through in a certain source location and orientation, called a pass-band, while suppressing noise or unwanted signal in other locations or orientations, called a stop-band [9]. A major limitation of beamformers is that they cannot properly reconstruct two spatially separate but temporally-correlated sources [9–11]; for example, they cancel each other when spatially far from each other or merge when they are spatially placed close to each other [9].In recent years, new beamformers have been introduced for brain source localization and signal reconstruction from EEG and MEG [7,9,12,13]. The performances of these beamformers have mostly been evaluated in terms of accuracy for source localization of strong electric/magnetic signals, such as epileptogenic spikes [10,14], auditory evoked potentials [7,13,15], and median-nerve evoked potentials [9]. Aside from source localization, the application of beamformers to signal reconstruction of predefined regions of interest (ROI) in the brain is gaining increased attention in neuroimaging laboratories and is a common process in applications of EEG and MEG [16]. Examples of such ROIs are the motor cortex for BCI [17], intracerebral current flow for neurofeedback [16], or any region in the brain found to have consistent changes in activity via functional imaging techniques such as fMRI or PET. However, a comparison of several new and conventional beamformers for time-course reconstruction of a desired source has not been previously undertaken.Beamformers applied to EEG or MEG fall into two categories: (A) scalar beamformers, which reconstruct the source time-course via a single output, and (B) vector beamformers which, reconstruct the source time-course in 3 orthogonal directions. For scalar beamformers, the orientation of the brain source can be estimated via techniques such as grid search [18,19], whereas vector beamformers do not require orientation of brain sources as they reconstruct the source time-series in 3 orthogonal time-courses. There are two methods for implementation of vector beamformers which are discussed in [20]. In the first method, the vector beamformer is a single beamformer with 3 orthogonal outputs, as applied in [10]. In the second implementation, the vector beamformer is made of 3 scalar beamformers in the 3 orthogonal directions as in [9,21].In the current study, we investigated the performance of 8 beamformers: (1) minimum-variance (MV) (also known as distortionless minimum-variance [12]), (2) weight-normalized minimum-variance (WNMV) [12]) (also known as Borgiotti–Kaplan [7,22], (3) standardized minimum-variance (SMV) [12], (4) eigenspace extension of the minimum-variance (ESMV) [23], (5) higher-order covariance matrix of minimum-variance (HOC) [9], (6) generalized sidelobe canceller form of quiescent beamformer (GSC) [24], (7) standardized low-resolution electromagnetic tomography (sLORETA) [25], and (8) array-gain constraint minimum-norm with recursively updated Gram matrix (AGMN-RUG) [13]. Gain, defined as the ratio of the input signal-to-noise ratio (SNR) to that of reconstructed time-course SNR, was used to quantify the performance of the beamformers in the ROI, with respect to changes in source parameters of depth, orientation, magnitude, and frequency. Spatial and directional pass-bands were provided to show the spatial resolution of the beamformers. White-noise spatial maps of the beamformers were obtained by back-projection of the white noise to the source-space via beamformers to determine which beamformers have a location bias. For the most part, the scalar beamformers were applied to determine the performance of the beamformers with respect to changes in the input parameters and the spatial resolution.Throughout this paper, plain italics indicate scalars, lower-case boldface italics indicate vectors, and upper-case boldface italics indicate matrices. Subscript b refers to assumed location or orientation of the source and subscript d refers to actual location or orientation of the source. The Frobenius norm was used to obtain the norm of the matrices and vectors.The reconstructed source time-seriessˆ(t,rb,qb)from the EEG for a scalar beamformer is(1)sˆ(t,rb,qb)=wT(rb,qb)b(t),whererb=[rbx, rby, rbz]T(mm) andqb=[qbx, qby, qbz]Tare the assumed source location and orientation respectively for calculation of the beamformer weight vector, ∥qb∥=1,w(rb,qb)is the weight vector for the scalar beamformer, andb(t)=[b1(t), b2(t), …, bM(t)]Tis the measured EEG data on M electrodes at time t. Each beamformer has its own formulation ofw(rb,qb).For a vector beamformer the reconstructed time-course can be written as(2)sˆ(t,rb)=WT(rb)b(t).In the above implementation, the vector beamformer is a single beamformer with 3 orthogonal outputs, as shown in [10]. A second implementation is shown in [9]:(3)sˆμ(t,rb)=wμT(rb)b(t),μ=x,y,z.Similar to [20], we call the first implementation a 3-D vector beamformer and the second implementation a 3-scalar vector beamformer.Spatial filters can also be divided into two main families: minimum-variance and minimum-norm based spatial filters. In this study the MV, WNMV, SMV, HOC and ESMV beamformers belong to the minimum-variance family of spatial filters whereas GSC, sLORETA, and AGMN-RUG beamformers belong to the minimum-norm family of spatial filters. The minimum-variance spatial filters seek an adaptive solution for the minimization of the reconstructed source power. For the scalar beamformers, and without the loss of generality, this can be expressed as(4)w(rb,qb)=argminw(rb,qb)(wT(rb,qb)Cw(rb,qb))subject to(5)wT(rb,qb)l(rb,qb)=1forMV,ESMV,andHOC,wT(rb,qb)w(rb,qb)=1forWNMV,wT(rb,qb)l(rb,qb)=(lT(rb,qb)C−1l(rb,qb))1/2forSMV,and(6)l(rb,qb)=L(rb)qb.L(rb)=[lx(rb),ly(rb),lz(rb)]mm is M×3 lead-field matrix which gives the sensitivities of M EEG sensors for an assumed source location atrbandCis the covariance matrix of EEG channels(7)C=〈b(t)bT(t)〉,where 〈…〉 is the ensemble average. Since the minimum-variance beamformers require the inverse of the covariance matrixC−1, a problem may arise when theCis not full rank. Brookes et al. [26] have suggested using a long window (i.e., as long as possible) of sensor data for calculation ofC, which helpsCretain its full rank and obtain a better spatial resolution. However, using a long window of sensor data increases the risk of including the artefacts which happen frequently during recordings. Alternatively, when the use of a long window is not possible or the input SNR is high thenCwill not be a full rank matrix and the regularized inverse is suggested (C+γI)−1 instead ofC−1, whereIis the unitary matrix, γ=0.003λ1 is the regularization factor, and λ1 is the largest eigenvalue ofC[7]. The regularized inverse will also increase the Gain of the beamformer [18,27,28] but leads to higher interference from other sources close to the source of interest signal and reduces the spatial resolution; that is, there is a trade-off between spatial resolution and Gain. The effect of regularized inverseCon performance of the MV beamformer is well discussed in [26,29]. In this study we applied γ=0.001λ1 for regularization of the covariance matrix for all situations sinceCwas not full rank in some cases.The second family is that of minimum-norm in which the weight vector is derived by minimization of(8)w(rb,qb)=argminw(rb,qb)(wT(rb,qb)GΩw(rb,qb))subject to(9)wT(rb,qb)l(rb,qb)=1forGSC(quiescent),wT(rb,qb)GΩw(rb,qb)=1forsLORETAandAGMN−RUG,whereGΩis the gram matrix(10)GΩ=∑rb∈ΩL(rb)LT(rb)and Ω is the ROI which can include several voxels dependent upon the size of ROI. The sLORETA and AGMN-RUG require the inverse of gram matrix. For inverse gram matrix the regularized inverse was used (GΩ+γI)−1, where γ is the regularization parameter. Options for the regularization parameter have been rigorously investigated [30]. Typically, γ is set to the average of the variance of the sensor noise [31].The normalized lead-field vectorl˜(rb,qb)is used in this study for all beamformers. The use of the normalized lead-field vector avoids the potential norm artefact of the lead-field vector [32], in which the norm of lead-field can change for different locations. For example in the case of spherical head model, the norm of lead-field becomes zero at the centre of the sphere and the weight vector for the MV beamformer become infinity.(11)l˜(rb,qb)=l(rb,qb)∥l(rb,qb)∥.The MV beamformer is the best known beamformer in EEG and MEG applications [32]. Its weight vectorwT(rb,qb)for an assumed location and orientation of the source is(12)wMV(rb,qb)=C−1l˜(rb,qb)l˜T(rb,qb)C−1l˜(rb,qb).The WNMV beamformer was proposed for EEG and MEG applications in [7]. Since the constraint of WNMV iswWNMVT×l˜=τandwWNMVT×wWNMV=1, therefore(13)wWNMV(rb,qb)=τwMV(rb,qb),τ=l˜T(rb,qb)C−1l˜(rb,qb)l˜T(rb,qb)C−2l˜(rb,qb).(14)wWNMV(rb,qb)=C−1l˜(rb,qb)l˜T(rb,qb)C−2l˜(rb,qb).The WNMV beamformer uses a normalized weight vectorwWNMVT×wWNMV=1which ensures the signal reconstructed from any location has the same gain and, hence, avoids location bias, even when the non-normalized lead-field is used.The SMV beamformer was introduced in [12] and its vector version in [33]. The constraint for SMV iswWNMVT×l˜=τand(15)τ=l˜T(rb,qb)C−1l˜(rb,qb),(16)wSMV(rb,qb)=C−1l˜(rb,qb)l˜T(rb,qb)C−1l˜(rb,qb).In the case of formulation, the SMV beamformer is in fact the minimum-variance version of the well known sLORETA, i.e., substituting theCbyGΩyields sLORETA. The constraint of SMV beamformers ensures that the power of the reconstructed signal from any location in the brain is standardized with respect tolT(rb,qb)C−1l(rb,qb)which avoids the location bias. Thus, if there is only white noise on the sensors (C=I) then for all locations in the source space(17)τ=l˜T(rb,qb)l˜(rb,qb)=1and, therefore, SMV has a normalized white-noise spatial map and, hence, no location bias.The ESMV beamformer [23] is based on eigen decomposition of the covariance matrix into noise and signal subspaces(18)C=ESΛSEST+ENΛNENT,where(19)ΛS=diag[λ1,λ2,…,λJ]andΛN=diag[λJ+1,λJ+2,…,λM],where diag[…] is the diagonal matrix with its elements being the eigenvalues of the signal spaceΛSand noise spaceΛN, and the columns inESandENbeing the eigenvectors ofC. J is the number of the eigenvalues of the signal space. The weight vector for the ESMV beamformer is(20)wESMV(rb,qb)=ESESTwMV(rb,qb).In Eq. (19) the eigenvalues from 1 to J belong to signal space and have greater values than σ2, where σ2 is the variance of the background EEG. A difficulty associated with the application of ESMV is how to estimate J. At source locations, the lead-field vector is orthogonal to the noise subspace of the covariance matrix [34](21)lT(rb,qb)EN=0,but, in practice, the left side of Eq. (21) never becomes equal to zero [35]. In fact, J can be any number from 1 to M depending on the magnitude of the source. This is a limitation of the ESMV beamformer as it needs user information to define J. A work-around for this difficulty, suggested by [32], is to overestimate J (i.e., J+ΔJ), which gives a marginal drop in SNR compared with the correct estimation of J. However, the user may underestimate J and remove the desired signal from the signal space. As a result, the ESMV beamformer is more desirable for cases when the SNRin is high and, therefore, the eigenvalue of the signal space is several times greater than that of the noise space and J will be a small number such as 1, 2 or 3.The HOC beamformer was introduced in [9] and has a similar formula to that of the MV beamformer except for the use of higher-order terms (e.g., 2 or 3) in the covariance matrix(22)wHOC(rb,qb)=C−nl˜(rb,qb)l˜T(rb,qb)C−nl˜(rb,qb),n=2or3.In our study n=3. In [9] the HOC was compared with other beamformers, including MV and WNMV, and was shown to be superior in the case of source localization by neural activity index for strong sources, but no example was given of time-course reconstruction.The GSC beamformer has two channels, the first being the forward channel which can be any type of beamformer and the second being the blocking (also called nulling) channel. In this paper, the GSC used in [24] was implemented. The forward channel for this GSC beamformer is the minimum-norm filter (also called quiescent beamformer)(23)wf(rb,qb)=l˜(rb,qb)l˜T(rb,qb)l˜(rb,qb),whereas the blocking channel includes a matrixBnwhich is in the null space of the lead-field matrix and aims to pass the background signal and not the desired signal(24)Bn=null[l˜(rb,qb)],where null[…] refers to null space. Because of this nulling channel, GSC beamformers are also called nulling beamformers. Thesˆ(t,rb,qb)via GSC is obtained by(25)sˆ(t,rb,qb)=wfT(rb,qb)b(t)−(bT(t)bn)wn(t),wherewn(t)is the weight vector of an adaptive algorithm such as least-mean-square (LMS) or recursive-least-square (RLS) [24]. Although GSC has been called the generalized sidelobe canceller form of the minimum-variance beamformer [24], the GSC described in [24] belongs to the minimum-norm family of spatial filters as its forward channelwfis a minimum-norm filter. Indeed it is possible to derive the generalized sidelobe canceller for any beamformer by adding the blocking channel parallel to the beamformer. The GSC described in [24] is one of the earliest beamformers used in EEG and MEG signal processing.SLORETA [25] is a form of spatial filter which has a similar weight vector to the SMV beamformer but uses the gram matrix instead of the covariance matrix. SLORETA is in fact the minimum-norm version of SMV beamformer. Hence, sLORETA is independent of the measured data in calculating the weight vector(26)wsLORETA(rb,qb)=GΩ−1l˜(rb,qb)l˜T(rb,qb)GΩ−1l˜(rb,qb).In the AGCMN-RUG beamformer [13], the weight vector is(27)wAGCMN−RUG(t,rb,qb)=G¯Ω−1(t)l˜(rb,qb)l˜T(rb,qb)GΩ−1(t)l˜(rb,qb),where, for a single point ROI, the gram matrix is(28)G¯Ω(t)=l˜(rb,qb)sˆ2(t,rb,qb)l˜T(rb,qb).The AGCMN-RUG beamformer is similar to sLORETA, with the main difference being that in AGCMN-RUG the gram matrix is updated for each time sample and, hence, the weight vector also needs to be calculated for each time sample. In the original paper [13], an important advantage of the AGCMN-RUG beamformer was claimed to be that it does not require the covariance matrix of the measured signal. However, after providing the formulations, Greenblatt et al. [12] mentions that in practice this beamformer is influenced by measured noise and, consequently, a regularized version of the AGCMN-RUG was proposed as a solution which uses the covariance matrix of the measured signal to regularize the gram matrix. The regularized version was used in this study.

@&#CONCLUSIONS@&#
