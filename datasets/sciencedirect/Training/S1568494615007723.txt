@&#MAIN-TITLE@&#
Parameter optimization of software reliability growth model with S-shaped testing-effort function using improved swarm intelligent optimization

@&#HIGHLIGHTS@&#
The proposed approach does not require any assumption for software failure data.Implementation of the proposed approach is very easy.The proposed SRGMTEF has a reasonable predictive capability.

@&#KEYPHRASES@&#
Software reliability growth model,S-shaped testing-effort function,Parameter optimization,Quantum particle swarm optimization,Software testing,

@&#ABSTRACT@&#
Software reliability growth model (SRGM) with testing-effort function (TEF) is very helpful for software developers and has been widely accepted and applied. However, each SRGM with TEF (SRGMTEF) contains some undetermined parameters. Optimization of these parameters is a necessary task. Generally, these parameters are estimated by the Least Square Estimation (LSE) or the Maximum Likelihood Estimation (MLE). We found that the MLE can be used only when the software failure data to satisfy some assumptions such as to satisfy a certain distribution. However, the software failure data may not satisfy such a distribution. In this paper, we investigate the improvement and application of a swarm intelligent optimization algorithm, namely quantum particle swarm optimization (QPSO) algorithm, to optimize these parameters of SRGMTEF. The performance of the proposed SRGMTEF model with optimized parameters is also compared with other existing models. The experiment results show that the proposed parameter optimization approach using QPSO is very effective and flexible, and the better software reliability growth performance can be obtained based on SRGMTEF on the different software failure datasets.

@&#INTRODUCTION@&#
Software reliability is one of the most important indicators when the software is released. Practical experience shows that software defects can cause the software system failure. To avoid software defects and reduce software maintenance costs, software reliability prediction is very important. Generally, software's reliability is indicated by user feedback including problem reports, system outages, and complaints or compliments and so on. However, it is too late to get information from the user feedback. Software developers need to know whether their products are reliability before the products are used by users. Software reliability models attempt to provide this information.There are two types of software reliability models [1–8]. The first type of models attempts to predict software reliability by designing parameters [1–5] and the second type of models attempts to predict software reliability by test data [6–8]. The first type of models is usually called “defect density model” and it uses code characteristics such as lines of code (LOC), nesting of loops, external references, input/outputs, and so forth to estimate the number of the defects in the software. The second type of models is usually called software reliability growth model (SRGM), which attempts to correlate fault detection data with known functions such as an exponential function. If the correlation is very good, the known function can be used to predict software's future behavior. In this paper, we only focus on SRGM.The past thirty years, many SRGMs have been proposed and discussed [6–8]. A SRGM can be regarded as a mathematical expression that fits the experimental data. It may be simply obtained by observing the trend of reliability growth curve [9]. The testing-effort was considered into an important consumed resource during the software test procedure, including the CPU time, the number of test cases and human resources etc. [10]. In general, the contribution of the testing-effort is more direct for detecting software defects efficiency [11], and its change with test time has a significant influence for the shape of software reliability growth curve [12]. Early SRGM does not consider testing-effort or hypothesis testing-effort is a constant [8], which is unreasonable obviously.A lot of testing-effort functions (TEF) have been proposed such as Weibull [13], logistic [14], generalization logistic [12], generalized exponential [15] functions and so on. Various SRGMTEF models have been studied including exponential Non-Homogeneous Poisson Process (NHPP) SRGM [10], S-shaped NHPP SRGM [16] and SRGM with change-points [12], etc. In the software testing process, the following situations frequently occur. Initially, the testing-effort's growth was very rapid. After a certain time, due to the impact of software structure and learning, the growth rate of testing-effort will gradually slow and eventually stable. So, the growth rate of testing-effort with time will show the S-shaped [17]. Therefore, in this paper, we only consider SRGM with S-shaped TEF.Existing results show that it is most common to optimize the parameters of SRGM with S-shaped TEF using statistical technique [18]. Often, some assumptions or transformations of original software failure data are required in order to conventional estimation methods can be used. For example, to estimate parameters of SRGM with S-shaped TEF, SRGM assumes that each failure occurs independently and randomly, and subjects to the same distribution. However, in the real situations, the failure distribution may be influenced by many factors such as operational environment, testing strategy and resource allocation etc. Therefore, to satisfy these assumptions is very difficult in real problems. As intelligent optimization methods not requiring additional assumptions, in this paper, intelligent optimal algorithm is used to optimize parameters of SRGM with S-shaped TEF.Swarm intelligence optimization is a series of relatively new optimization algorithm including genetic algorithm [19,20], ant colony optimization [21,22] and particle swarm optimization (PSO) [23,24] and so on. It simulates the swarm behavior of the social individuals, using the information interchange and cooperation between individuals to achieve the optimization. Compared to the other swarm intelligence algorithms, PSO has the following advantages [23,24]. (1) PSO is a simple algorithm. (2) PSO has fewer control parameters and better convergence performance. (3) In the implementation process of PSO, it does not need any assumptions for software failure data, and only uses the characteristics of the data itself. PSO is mainly used to solve some nonlinear complex optimization problems [24], and it has attracted many researchers and has emerged as the most popular tool for intelligent optimal problems. However, PSO also has some disadvantages such as slower convergence rate in the late phase of PSO, usually to has three parameters and easy to fall into local minimum, which is not a global convergence algorithm [25] and so on [26]. We notice that, in addition to the advantages of PSO, quantum particle swarm optimization (QPSO) [26] has global search capability, non-velocity vector and QPSO only one parameter, which indicates QPSO easier to control. Therefore, in this paper, QPSO is applied to optimize parameters of SRGM with S-shaped TEF.By retrieving, we found that the results to optimize parameters of SRGM using swarm intelligence optimization algorithm are very little, and only two papers were found [27,28]. In [27], Kim et al. used a real-valued genetic algorithm to estimate the parameters of SRGM. The results indicated that the real-valued genetic algorithm is more effective in the parameter estimation of SRGM than other GA approaches. In [28], Sheta used PSO algorithm to estimate the parameters of SRGM. The proposed approach illustrated significant advantages in handling variety SRGMs. Unlike the above two approaches, [27,28]’s parameter estimation approaches are only for early SRGM, namely not to consider testing-effort. We notice that the parameter estimation approach for early SRGM can only be applied to an ideal environment [7,12]. For complex software environment, there are some limits to estimate parameters. The main contributions of this work are the following:(1)The parameter optimization process of the proposed SRGM with S-shaped TEF based on QPSO does not need to be divided into several phases, and all parameters are estimated simultaneously.The proposed parameter optimization approach for SRGM with S-shaped TEF based on QPSO does not need any assumptions for software failure data, and only dependents on the characteristics of the data itself.The prediction result of SRGM with S-shaped TEF does not require user participation and its prediction process is completely automated.The rest of this paper is organized as follows. In Section 2, we introduce SRGM with S-shaped TEF. Furthermore, the standard QPSO and its improving to optimize parameters of SRGM S-shaped TEF are described in Section 3. In Section 4, the comparison criteria are discussed. Section 5 presents used datasets, the experimental results and time complexity analysis respectively. Finally, conclusions are given in Section 6.TEF can describe the change of software reliability with time. In general, the software reliability is highly correlated with the amount of testing-effort to spend on detecting and correcting software errors [29]. Common TEFs are listed in Table 1.In Table 1, W(t) is the cumulative testing-effort on time interval (0, t], w(t) is the growth rate function of testing-effort at time t, and f(t) is a learning factor function (which is an increasing function with respect to t).Some authors [13,15] reported that Weibull-Type testing-effort curves (3–4 in Table 1) may have an obvious peak during the software development process when shape parameter m>3, therefore S-shaped growth trend cannot be well described by Weibull-Type testing-effort curve. Although Logistic-Type TEF (5–6 in Table 1) is S-shaped TEF, when t=0, the calculated initial testing-effort W(0) is not 0, and this conclusion is not consistent with human intuition. TEF with learning function [30] (8 in Table 1) is very complex, which is inconvenient used. These shortcomings result that TEFs in Table 1 are not more concerned.Inflected S-shaped model (ISSM) was first proposed in [8], which described the variation of testing-effort with time to obtain the S-shaped growth curve for the cumulative number of detected faults. ISSM has been applied to software reliability modeling [31] and it also is a finite failure model. The system equation for W(t) is(1)W(t;b,N,ξ)=N⋅1−e−bt1+ξe−btwhere b, N and ξ are three unknown model parameters.By the Eq. (1), we know that:(1)W(0)=0, i.e., the initial testing-effort is 0.W(t) is non-negative and increases monotonically with time t, i.e., W(t) is increasing with the testing-effort growing continuously during software testing process.The Eq. (1) is S-shaped function.Growth rate function isAccording to [10], we can get NHPP SRGMTEF as follows:(3)dm(t)dt1w(t)=r(a−m(t))where a>0 is expected number of initial error in the system, and r is the error detection rate per unit testing-effort at time t, and m(t) represents the expected mean number of detected errors in time (0, t] which is assumed to be a bounded non-decreasing function with respect to t, and m(0)=0.Solving Eq. (3), we have(4)m(t)=a(1−e−r(W(t)−W(o)))We notice that W(0)=0, then the Eq. (4) can be simplified as follows(5)m(t)=a(1−e−r⋅W(t))Substituting the Eq. (1) into Eq. (5), we get(6)m(t;a,r,b,N,ξ)=a(1−e−r⋅N⋅1−e−bt1+ξe−bt)To establish an effective NHPP SRGMTEF (i.e., Eq. (6)), we need to select five optimization parameters, namely a, r, b, N and ξ.In general, the parameters of the Eq. (6) can be estimated by statistical methods. Estimation process is divided into two phases [9,18]. In the first phase, the values b, N and ξ are first estimated by LSE. In the second phase, the values a and r are then estimated by MLE. We notice that the five parameters a, r, b, N and ξ are important for the Eq. (6). There is influence each other between these parameters, and which should not be separately estimated. Furthermore, the application of estimation methods (e.g., LSE and MLE) requires software failure data to satisfy some assumptions. For real data, these assumptions are difficult satisfied. In this paper, we use QPSO algorithm to obtain these parameters simultaneously. We first introduce standard PSO.Standard PSO is a population-based optimization technique, which was proposed by Eberhart and Kennedy in 1995 [24]. As an important optimization tool, PSO has been successfully applied in many fields, such as attribute selection [32], image enhancement [33], and data mining [34] and so on. In standard PSO, the potential solutions, called particles, fly in the search space. Each particle adjusts its position from time to time according to the flying experience of its own and neighbors. It is initialized with a population of random potential solutions and the algorithm searches for optima satisfying some performance.Each particle i has a position represented by a vector Xi. A particle swarm moves through a d-dimensional problem space, with the velocity of each particle represented by a vector Vi. The particle velocity and position equations form are given by(7.a)Vi(t+1)=ω⋅Vi(t)+c1r1i(Pi,best(t)−Xi(t))+c2r2i(Pglobal(t)−Xi(t))(7.b)Xi(t+1)=Xi(t)+Vi(t+1)where t is current iteration number, ω is inertia weight, c1 and c2 are positive constants,r1iandr2iare uniformly distributed random numbers on the interval [0,1]. Pi,best is the best known position of particle i and Pglobal is the best known position of the entire swarm. We let Xi(t)=(Xi1(t), Xi2(t), …, Xid(t)) and Vi(t)=(Vi1(t), Vi2(t), …, Vid(t)).The first part of Eq. (7.a) represents the inertia of the previous velocity, the second part is the cognition part and it tells us about the personal experience of the particle, the third part represents the cooperation among particles and is therefore named as the social component. ω, c1 and c2 are the predefined by the user.The fitness value of particle i[35], at iteration t, is as follows(8)F(Xi(t))=1L∑k=1L∑j=1d(Xij(k)(t)−Xˆij(k)(t))2where for particle i,Xˆij(k)is the jth actual component of the kth observation sample, andXij(k)is the jth output component of the kth sample, and L is total number of the samples. For Eq. (8), F(·) is as small as possible. The best position Pi,best of particle i is determined by the following formula:(9)Pi,best(t+1)=Xi(t),ifF(Xi(t))<F(Pi,best(t))Pi,best(t),ifF(Xi(t))≥F(Pi,best(t))At each update step of PSO, the velocity of each particle is calculated according to Eq. (7.a) and the position is updated according to Eq. (7.b). When a particle finds a better position than the previously best position, this better position will be stored in the memory. The algorithm goes on until a satisfactory solution is found or the predefined number of iterations is met.In standard PSO, the convergence of the particle is realized by the track form. And because the particle velocity is always limited, the search space in the search process is a limited area, which cannot cover the entire feasible space. In general, standard PSO cannot guarantee that the probability for searching the global optimal solution is 1. Furthermore, the particles meet the character of aggregation state in the quantum space, it can implement search in the whole feasible solution space, the quantum model (QPSO) [36,37] of standard PSO was proposed, and its performance is far superior to the standard PSO [20]. Besides, in QPSO, the velocity and position information of the particle are attributed to one parameter. The probability of the particle appearing in position X may be obtained from probability density functionψ(X)2, the wave function ψ(X(t)) [38] of the particle is described as follows.(10)ψ(X(t))=1Qe−mbest(t)−X(t)Qwhere the parameter Q depending on energy intension of the potential well specifies the search scope of a particle, and mi,best is defined as the mean of the best positions of all particles in the population, namely(11)mi,best=1S∑i=1SPi,best(t)Here S is number of all particles. According to [38], the parameter Q and the position X is updated respectively according to the following iterative equations.(12)Q(t+1)=2⋅α⋅mi,best(t)−X(t)(13.a)Xi(t+1)=pi(t)+α⋅mi,best−Xi(t)⋅ln1ui(t),ifs≥0.5(13.b)Xi(t+1)=pi(t)−α⋅mi,best−Xi(t)⋅ln1ui(t),ifs<0.5where uiand s are uniformly distributed random numbers on the interval (0, 1), and uniformly parameter α is called contraction–expansion coefficient. And(14)pi(t)=φi(t)⋅Pi,best(t)+(1−φi(t))⋅Pglobal(t)where φiis uniformly distributed random number on the interval (0, 1). So, in QPSO, Eq. (7) is replaced by Eq. (13). The flow chart of QPSO algorithm is shown as follows.QPSO algorithmInitialize the current positions and the Pbestpositions of all the particlesDoCalculate mi,bestby equation (11) for particles i, where i=1, 2, …, SSelect a suitable value for αFor particles i=1 to SCalculate the fitness value of particle i according to equation (8)Update Pi,best(t) and Pglobalusing equation (9)For dimension 1 to dφ=rand (0, 1)u=rand (0, 1)If s=rand (0, 1) ≥ 0.5update particles position using equation (13.a)elseupdate particles position using equation (13.b)Until terminal condition is metIn this paper, the termination criterion of QPSO is that, if the absolute difference between the F(t+1) and F(t) of 10 times continuously is less than δ, then stop QPSO; otherwise until the maximum number Gmax of iterations is met. Where δ is a training threshold.In QPSO, α is unique parameter, which can balance the local and global search of QPSO during the search process, and therefore it is very important. In this paper, its value is selected according to the conclusion of [39], i.e., as long as α satisfies inequality α<e0.5772156649=1.7811, which can ensure that QPSO is convergent.Although the performance of QPSO is far superior to the standard PSO [26], the premature convergence is still present in QPSO. To solve this problem, we will improve QPSO (still called QPSO).In the later phase of QPSO algorithm, the main reason of algorithm easy to fall into local optima is that all particles fall into a local area to not get out. Therefore, for the population of current generation, some particles with the high fitness value should be replaced by the particles generated by a random search in order to enhance the population diversity. In this paper, the implementation process of improving operation is as follows:(1)Calculate the fitness value of each particle i, where i=1, 2, …, S.After selecting two particles with first highest fitness value, the operation of these particles is as follows:In this paper, the run criterion of improving operation is that, if all absolute differences between the F(t+1) and F(t) of 10 times continuously are greater than δ, then to run improving algorithm, otherwise not run. The main design idea of proposed implementation operation is to get rid the identity of the population when to occur the premature convergence.We use x-fold cross-validation method (CVM) to train the SRGMTEF on the training set. In fact, this is a fitting process which optimizes the parameters of SRGMTEF to make the model fit data of training set as well as possible. In x-fold CVM, the original data of training set is randomly partitioned into x subsets. Of the x subsets, a single subset is retained as the test set for testing the SRGMTEF, and the remaining x−1 subsets are used as training sets. The CVM is then repeated x times (the folds), with each of the x subsets used exactly once as the test set. The x results from the folds then can be averaged to produce a single estimation. The advantage of CVM over repeated random sub-sampling is that all observations are used for both training and test, and each observation is used for testing exactly once [40].In this paper, training process of SRGMTEF is built by given set of parameters {a, r, b, N, ξ}, using x−1 subsets as training sets. The evaluation fitness value of the parameters set (i.e., the particle) is calculated by the Average Error (AE) [10] or Mean of Squared Errors (MSE) [10] on the test set. This procedure is repeated x times, and each subset is used once for testing. To measure the goodness of SRGMTEF, we also use the Relative Error (RE) [17] and index of correlation (R2) [12]. AE, MSE, RE and R2 represent as follows.(1)AE is defined as(17)AE=1L∑i=1Lhi−hˆihi×100%where H=(h1, h2, ..., hL) andHˆ=(hˆ1,hˆ2,...,hˆL)are actual cumulative fault numbers and predicted fault values respectively, and L is the number of observation samples. A smaller AE indicates better performance.MSE gives the qualitative comparison, and is used because it can provide a well-understood measure of the differences between actual cumulative and predicted values. MSE is given as follows:(18)MSE=1L∑i=1L(hˆi−hi)2where a smaller MSE indicates a minimum fitting error, and better reliability performance.The predictive validity is defined as the capability of SRGMTEF to predict future failure behavior from present and past failure behavior. Assume that we have observed h failures by the end of test time th. We use the failure data up to time te(≤th) to determine the parameter ofpˆ(t). Substituting the estimates of these parameters in the mean value function yields the estimate of the number of failurespˆ(th)by th. The estimate is compared with the actually observed number h. This procedure is represented for various values of te. RE is given as follows:(19)RE=pˆ(th)−hhValues close to zero for RE indicate more accurate prediction and hence a better SRGMTEF.To measure the goodness between actual cumulative number and predicted fault number, we use the R2 represented as follows:(20)R2=1−∑i=1L(hi−hˆi)2∑i=1L(hi−have)2where have is the mean of actual cumulative fault numbers. R2 value is more approaches 1, which represents better goodness effect of SRGMTEF.

@&#CONCLUSIONS@&#
In this paper, we explored the application of QPSO for optimizing parameters of SRGM with S-shaped TEF. It is the first attempt to apply QPSO to the parameter estimation of SRGM with S-shaped TEF. The optimized SRGM with S-shaped TEF is flexible and can be used to describe the actual expenditure patterns more faithfully during software development. The proposed approach has the following characteristics:(1)The proposed approach can overall fit the actual data and overall prediction error is minimal, which shows that ISSM is more appropriate than other TEFs for selected datasets.The proposed approach does not require any assumptions for the software failure data, and only use characteristics of the data itself, which shows that the implementation of proposed approach is very easy.The performance of proposed SRGM with S-shaped TEF is compared with other traditional models. The results show that better performance is obtained on different real failure data, and the proposed SRGM with S-shaped TEF has a reasonable predictive capability.