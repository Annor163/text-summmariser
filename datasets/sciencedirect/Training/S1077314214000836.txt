@&#MAIN-TITLE@&#
Online domain-shift learning and object tracking based on nonlinear dynamic models and particle filters on Riemannian manifolds

@&#HIGHLIGHTS@&#
Online domain-shift learning of dynamic object appearances with out-of-plane motions.Bayesian formulation on Riemannian manifolds using nonlinear state space models.Two particle filters, one on manifolds for appearance learning, another for object tracking.Occlusion handling to prevent online learning when objects are likely occluded.Tracking scheme is applied to visual-band videos and thermal infrared videos.

@&#KEYPHRASES@&#
Domain-shift object learning,Manifold appearance learning,Visual object tracking,Infrared object tracking,Riemannian manifolds,Covariance tracking,Object partition,Particle filters,Occlusion handling,Nonlinear dynamic model,

@&#ABSTRACT@&#
This paper proposes a novel online domain-shift appearance learning and object tracking scheme on a Riemannian manifold for visual and infrared videos, especially for video scenarios containing large deformable objects with fast out-of-plane pose changes that could be accompanied by partial occlusions. Although Riemannian manifolds and covariance descriptors are promising for visual object tracking, the use of Riemannian mean from a window of observations, spatially insensitive covariance descriptors, fast significant out-of-plane (non-planar) pose changes, and long-term partial occlusions of large-size deformable objects in video limits the performance of such trackers. The proposed method tackles these issues with the following main contributions: (a) Proposing a Bayesian formulation on Riemannian manifolds by using particle filters on the manifold and using appearance particles in each time instant for computing the Riemannian mean, rather than using a window of observations. (b) Proposing a nonlinear dynamic model for online domain-shift learning on the manifold, where the model includes both manifold object appearance and its velocity. (c) Introducing a criterion-based partial occlusion handling approach in online learning. (d) Tracking object bounding box by using affine parametric shape modeling with manifold appearance embedded. (e) Incorporating spatial, frequency and orientation information in the covariance descriptor by extracting Gabor features in a partitioned bounding box. (f) Effectively applying to both visual-band videos and thermal-infrared videos. To realize the proposed tracker, two particle filters are employed: one is applied on the Riemannian manifold for generating candidate appearance particles and another is on vector space for generating candidate box particles. Further, tracking and online learning are performed in alternation to mitigate the tracking drift. Experiments on both visual and infrared videos have shown robust tracking performance of the proposed scheme. Comparisons and evaluations with ten existing state-of-art trackers provide further support to the proposed scheme.

@&#INTRODUCTION@&#
Tracking visual object from videos has drawn increased interest in recent years [1,2]. Many robust trackers have been successfully developed however challenges remain especially when dynamic objects contain large out-of-plane changes and significant appearance changes, experience long-term partial occlusions or intersections with other objects in dynamic background and crowded scenes. Online learning of object appearances is an essential issue for mitigating the tracking drift, where off-line learning is often unrealistic for dealing with real world problems. One of the main tasks for online learning is to estimate current statistics, parameters or states of non-stationary objects from new observations. It enables a tracker to adaptively utilize a timely reference object model for tracking. A main challenge for online learning of visual object is the ambiguity on image changes that can be caused either by object itself (e.g. deformation, pose, self-occlusion) or by other occluding object/background. It is desirable that an online learning method adapts to changes in object intrinsic parameters (e.g. pose, appearance and shape) and is insensitive to extrinsic variations (e.g. illumination, occlusion, background, camera motion and viewpoint). Several online learning methods have been proposed. For example, Refs. [3,4] uses vector space learning that incrementally updates the sample mean of object appearance. Refs. [5,6] proposes manifold learning where dynamic object appearance is described as a point moving on a smoothed manifold surface. Since images of dynamic objects, especially out-of-plane objects, reside in nonlinear spaces, or manifolds [7], using a set of low-dimensional subspaces on manifolds has led to more robust online domain-shift learning as comparing with those using a single vector space.Using covariance matrices of image features as object descriptors has drawn increasing interest lately for visual tracking [8]. It enables efficient description of object features, and shows to be robust and versatile for variations in illuminations, views and poses at modest computational cost. The space of non-singular covariance matrices of image features can be formulated as connected points (corresponding to smoothly shifting in different subspaces) on a Riemannian manifold. This paper addresses online domain-shift learning and tracking on Riemannian manifolds by using a set of weighted candidate covariance matrices as object descriptors.

@&#CONCLUSIONS@&#
