@&#MAIN-TITLE@&#
OntoVIP: An ontology for the annotation of object models used for medical image simulation

@&#HIGHLIGHTS@&#
We propose an ontology for the annotation of medical image simulation object models.We extract and reuse relevant subsets of existing ontologies.We use this ontology in the implementation of the Virtual Imaging Platform (VIP).Such annotations facilitate the query/retrieval of the models.Should facilitate interoperation with software modeling biological phenomena.

@&#KEYPHRASES@&#
Simulation,Ontologies,Semantic web,Ontology web language,Medical imaging,

@&#ABSTRACT@&#
This paper describes the creation of a comprehensive conceptualization of object models used in medical image simulation, suitable for major imaging modalities and simulators. The goal is to create an application ontology that can be used to annotate the models in a repository integrated in the Virtual Imaging Platform (VIP), to facilitate their sharing and reuse. Annotations make the anatomical, physiological and pathophysiological content of the object models explicit. In such an interdisciplinary context we chose to rely on a common integration framework provided by a foundational ontology, that facilitates the consistent integration of the various modules extracted from several existing ontologies, i.e. FMA, PATO, MPATH, RadLex and ChEBI. Emphasis is put on methodology for achieving this extraction and integration. The most salient aspects of the ontology are presented, especially the organization in model layers, as well as its use to browse and query the model repository.

@&#INTRODUCTION@&#
Medical imaging has become a very rich source of information which plays a major role in diagnosis, therapy and patient follow-up. Several imaging modalities, e.g. Computed Tomography (CT), Magnetic Resonance Imaging (MRI), Ultrasound (US) and Positron Emission Tomography (PET), allow exploring and imaging various facets of the morphology and physiology of a living body, at various spatial and temporal resolutions. The progress of medical imaging will certainly continue and one can foresee that all this imaging data will be used in the future to build some sort of digital patient avatars (i.e. virtual representation) composed of a set of personalized and integrated models representing anatomical, physiological and pathophysiological aspects of the organism. Such avatars could be used to test and compare various therapeutic approaches, to predict their outcome, and thus contribute to decision making. However, prerequisites for this to materialize are: (1) that such models are developed, something that initiatives like the Virtual Physiological Human (VPH) strongly support [1,2] and (2) that appropriate model identification methods are developed, whose function is to estimate the various model parameters from the specific patient multimodal image data.In this context, an important issue remains: how to validate such models and associated identification methods? Medical image simulation appears as an interesting approach to this problem. It has undergone significant progress in the last ten years, with simulators being developed for many imaging modalities, e.g. SINDBAD [3] in CT, SIMRI [4], BrainWeb [5] in MR, SORTEO [6], GATE [7] in PET and FIELD-II [8] in US. This allows addressing a number of needs related both to the design and optimization of imaging equipment and the validation of image processing software. Indeed, image simulation allows generating realistic images of a virtual object, of which characteristics can be defined arbitrarily (e.g. presence of pathology, arbitrary choice of its size and location), and from which one can derive any kind of simulated image (i.e. by tuning spatial and temporal resolution, nature and level of noise in images, etc.). The key thing with this approach is that it provides a ground truth regarding image content, which enables quantitative assessment of image processing software. For instance, one can actually compare the result of a segmentation algorithm with the actual definition of the imaged object.The Virtual Imaging Platform (VIP) (http://vip.creatis.insa-lyon.fr) provides researchers with a platform gathering several image simulators of various modalities [9]. Its major goals are: (1) to offer an easier access to simulators whose installation and use is usually perceived as very complex to potential users, (2) to gather simulators of various modalities, and (3) to deploy them on grid computing resources so that reasonable execution times can be obtained while image simulation usually requires huge computation.This article focuses on the sharing and reuse of the models used for medical image simulation. A basic assumption of this work is that a major barrier to the wide-scale use of these techniques is the difficulty of creating realistic models that are suited to the researchers’ specific needs. VIP aims at setting up a model repository to facilitate their sharing and reuse, based on a comprehensive conceptualization of those models, suitable for all imaging modalities and simulators considered in the VIP project and built according to an ontological approach. The first motivation for a such choice is the need to rely on of a semantically-rich vocabulary to annotate the models; such annotations will enable the VIP platform’s users to assess whether an existing model can actually meet their specific needs, or be used as a starting point to derive from it an appropriate model. A second motivation concerns the representation of knowledge about the objects represented in a model involved in an image simulation, such as relating objects and materials to their physical properties; a particular aspect is the ability to use the same model in simulations with simulators of different modalities, which requires that the physical properties of materials and tissues be represented in consistent ways for all modalities. The third concerns the interoperability between biological modeling software and medical image simulation software, which requires that common semantics are given to shared information (regarding anatomical structures, presence of pathology, quantities represented in the models or characterizing the tissues properties).This paper describes the design methodology and the implementation of an ontology for medical image simulation models, tailored to the needs of integrating the SINDBAD, SIMRI, SORTEO and FIELD-II simulators in the VIP platform, but easily extensible to address the needs of other simulators in the future. This ontology, called OntoVIP is used to semantically annotate the models’ files (images, meshes, etc.). It is freely available for consultation, download and reuse, both from the VIP web site,1http://www.creatis.insa-lyon.fr/vip/ontologies.html.1and from the National Center for Biomedical Ontology (NCBO) BioPortal.2http://bioportal.bioontology.org/ontologies/OntoVIP.2This paper also demonstrates the added value of this ontology for visualizing the models content and querying the models repository.This article is organized as follows. Section 2 describes the methodology used to design the ontology, with special attention to the reuse and consistent integration of relevant ontologies. Section 3 (Results) presents the ontology itself and its use in the VIP platform to browse and query the models repository. Section 4 (Discussion) positions our achievements with respect to our initial goals and motivations and provides further details on specific problems we have met and on the solutions proposed to overcome them. The paper concludes in Section 5 with some perspectives opened by this work.

@&#CONCLUSIONS@&#
