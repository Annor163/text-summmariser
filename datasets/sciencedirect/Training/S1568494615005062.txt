@&#MAIN-TITLE@&#
Simultaneous instance and feature selection and weighting using evolutionary computation: Proposal and study

@&#HIGHLIGHTS@&#
The paper presents a framework for simultaneous instance and feature selection and weighting.An extensive comparison of all the possible combinations is carried out.The proposal is also studied in class-imbalanced datasets.

@&#KEYPHRASES@&#
Instance selection,Feature selection,Instance weighting,Feature weighting,Class-imbalanced datasets,

@&#ABSTRACT@&#
Current research is constantly producing an enormous amount of information, which presents a challenge for data mining algorithms. Many of the problems in some of the most relevant research areas, such as bioinformatics, security and intrusion detection or text mining, involve large or huge datasets. Data mining algorithms are seriously challenged by these datasets. One of the most common methods to handle large datasets is data reduction. Among others, feature and instance selection are arguably the most commonly used methods for data reduction. Conversely, feature and instance weighting focus on improving the performance of the data mining task.Due to the different aims of these four methods, instance and feature selection and weighting, they can be combined to improve the performance of the data mining methods used. In this paper, a general framework for combining these four tasks is presented, and a comprehensive study of the usefulness of the 15 possible combinations is performed.Using a large set of 80 problems, a study of the behavior of all possible combinations in classification performance, data reduction and execution time is carried out. These factors are also studied using 60 class-imbalanced datasets.

@&#INTRODUCTION@&#
The overwhelming amount of data available in any research field poses new problems for data mining and knowledge discovery combinations. This huge amount of data makes most existing algorithms inapplicable to many real-world problems. Two approaches have been used to face this problem: scaling up data mining algorithms [1] and data reduction. However, scaling up a certain algorithm is not always feasible. Data reduction consists of removing the missing, redundant, information-poor and/or erroneous data to obtain a tractable problem size. Data reduction techniques use different approaches, including feature selection [2], feature-value discretization [3] and instance selection [4].The feature and instance weighting processes aim to improve the performance of the data mining task. Because no data reduction is performed, the main target is a better result of the data mining process, e.g., a better clustering or a more accurate classifier.These four processes have been used separately, and in a few cases in combinations of two, as in simultaneous instance and feature selection. However, there is no general framework for combining all of them. In this paper, first a general framework for combining the four processes using evolutionary computation is proposed, and a complete study of the performance of all possible combinations is performed. Considering the possible combinations and the four methods separately, the 15 possibilities using standard datasets and class-imbalanced problems are evaluated.The underlying idea of this paper is to answer the question of whether combining these four processes might improve performance. To achieve this goal, a unified approach for the four tasks that allows combining any of them is needed. We must then perform a thorough experimental comparison of the different combinations to study their behavior.To provide the necessary focus, the study is restricted to the classification problem, although a similar study could be performed for other data mining tasks, such as clustering. A nearest neighbor rule is used as the base classification method. We have used this classification method because it is the most commonly used when instance selection is applied. Furthermore, due to the large number of experiments reported, using more than a classifier method was not feasible.Although many methods have been proposed for each of these tasks, we restrict ourselves to evolutionary approaches for two reasons. First, evolutionary approaches perform better when they are compared with other algorithms [5] as a general rule. Wrapper approaches usually offer better performance than filters [6]. Second, as we intend to try all possible combinations of the four tasks, only powerful metaheuristics offer the necessary flexibility for such fusion. Among those metaheuristics, evolutionary computation has shown arguably the best performance across a wide variety of problems.This paper is organized as follows. Section 2 presents a short review of instance and feature selection and weighting. Section 3 describes our proposed framework. Section 4 shows the experimental setup. Section 5 presents and discusses the experimental results, and Section 6 states the conclusions of our work.As a general statement of the problem, consider a problem involving K classes and N training instances with M features whose class membership is known. Let T={(x1, y1), (x2, y2), …(xN, yN)} be the set of N training samples, where each instance xibelongs to a domain X. Each label is an integer from the set Y={1, …, K}.Considering this setup, the feature selection, feature weighting, instance selection and instance weighting processes can be carried out. Each process has different aims. In the following, each task is briefly explained.Instance selection [7] consists of the selection a subset of the whole available dataset to achieve the original objective of the data mining application as if all of the data were used. Several different instance selection variants exist. Two major models are distinguishable [5]: instance selection as a method for prototype selection for algorithms based on prototypes (i.e., K-nearest neighbors) and training set selection to obtain the training data for a learning algorithm (i.e., classification trees or neural networks).The instance selection problem for instance-based learning can be defined as [8] “the isolation of the smallest set of instances that enable us to predict the class of a query instance with the same (or higher) accuracy than the original set”.Different groups of learning algorithms have different learning/search bias [9] that must be addressed by instance selection algorithms. This may make many instance selection algorithms useless when their design philosophy is not appropriate for the problem at hand. Wrapper approaches do not assume any data structure or classifier behavior, adapting the instance selection to classifier performance. This, they usually are the best performing methods.Brighton and Mellish [8] stated that the structure of the classes for a given dataset can differ greatly; an instance selection procedure can thus have good performance in one problem and a poor performance in another. Thus instance selection algorithms must gain some insight into the class structures to perform an efficient instance selection. However, this insight is rarely available and very difficult to obtain. However, approaches based on evolutionary computation do not assume any special form of the space, classes or boundaries between classes; and are only guided by the ability of each subset of instance to solve the data mining problem. The algorithm thus learns the relevant instances from the data without imposing any constraint in the form of classes or boundaries between them. García-Pedrajas and Pérez-Rodríguez [10] proposed selecting the instances more than once for a better accuracy and reduction.Evolutionary computation has been shown [5,11,12] to be the most efficient combination for instance selection. However, it suffers from scalability problems. The computational cost, even for moderately large datasets [13], is a serious problem for this approach. For very large or huge datasets, evolutionary computation-based methods are not applicable. Stratification [14] and democratization [13,15] have been proposed to solve this scalability problem. A similar approach was constructed to scalable instance selection specially focused on class-imbalanced datasets [16].Instance weighting is arguably the least frequent of these tasks. Problems in instance weighting include the large search space and the difficulty of devising algorithms. There are two alternatives for instance weighting. Instance weights can be used for case-based methods, such as nearest neighbors:(1)d(q,x)=∑j=1Mvx2(qj−xj)2,wherevxis the weight associated with instance x. Instances with a higher value ofvxare less relevant for classification, as they tend to be effectively less closer to the query instance. With instance weighting, more complex decision surfaces can be constructed  [17].A second alternative may be specifically designed for many classifiers, such as decision trees [18], and consists of weighting the relevance of each instance in the classification. These weights can be used for classifier boosting [19] or class-imbalanced datasets [20,21]. However, this alternative is not applicable for a 1-NN; this paper thus does not consider it.Feature selection is an important and frequently used data preprocessing technique for data mining [22]. In contrast with other dimensionality reduction techniques, feature selection preserves the original variable semantics, thus offering the advantage of interpretability by a domain expert [23].Feature selection has been a fertile research and development field since the 1970s in statistical instance recognition [24], machine learning [4,25], and data mining [26], and it has been widely applied to many fields, including text categorization [27], image retrieval [28] customer relationship management [29], intrusion detection [30], and genomic analysis [31].Feature selection can be defined as selecting a subset of M′ features from a set of M features, M′<M, such that the value of a criterion function is optimized over all subsets of size M′  [32]. The feature selection objectives are manifold, the most important ones being the following [23]:•To avoid over-fitting and improve model performance, i.e., prediction performance for supervised classification and better cluster detection for clustering.To provide faster and more cost-effective models.To gain a deeper insight into the underlying processes that generate data.Feature selection usually has two main goals: reducing datasets and gaining knowledge about the most important problem features. Many algorithms have been developed for feature selection. The interested reader may refer to any feature selection reviews [2,33–35].Evolutionary computation has been widely used for feature selection, as it is an efficient wrapper approach for this task [36–43].Using feature weights [44], i.e., using weighted metrics, has a different objective. In this case, the aim is not to reduce the training set size but instead to improve classifier performance.In the general case, the search process looks for a weight vector w such that the following weighted distance between an instance x∈T and a query instance q is used [45]:(2)d(q,x)=∑j=1Mwxj2(qj−xj)2,wherewxjis a weight associated with the j-th component of the training instance x. Defined this way, each feature in each instance has a different weight. The method must learn NM parameters, which is exceedingly high for any practical purpose. This number can be reduced using the same weights for all instances in a class [45] or the most common approach of using just one weight for each feature throughout the whole training set. Our experiments use the latter approach. Feature weighting has also been used for clustering [46–48].A few combinations have been developed and tested as a general approach and for specific problems. Using artificial immune systems, Lin and Chen [43] developed an algorithm to select features and assign feature weights for case-based reasoning. Khola [49] proposed combining both tasks using a genetic algorithm. Giraldo et al. [50] used a genetic algorithm to combine feature selection and weighting. Tahir et al. [51] also performed the same task using Tabu search.Many algorithms have been developed to tackle either instance or feature selection. However, few papers have aimed at simultaneous instance and feature selection [52]. One problem with combining both approaches is the lack of theoretical basis for developing algorithms with strong theoretical backgrounds. In absence of this theory, heuristics combinations must be used. A first straightforward approach is performing one process after the other. However, this approach does not benefit from combining both processes.A better approach would be combining both searches. Evolutionary computation offers a suitable tool for approaching the simultaneous selection of both instances and features. Using a chromosome that encodes instances and features, any evolutionary computation combination can be used. This approach has been used in several works [53–57]. Derrac et al. [42] used a cooperative coevolutive approach with three populations, one performing instance selection, another performing feature selection, and the third performing both instance and feature selection. García-Pedrajas et al. [58] used a memetic algorithm combined with a stratification strategy for simultaneous scalable instance and feature selection.Feature weighting and instance selection have been applied to collaborative filtering [59] using a unified information-theoretic approach to measure the relevance of features and instances.Wettschereck et al. [6] found that continuous weighting combinations tend to outperform feature selection algorithms for tasks where some features are useful but less important than others.To combine the four tasks, we consider the most general approach, when the four methods are conducted simultaneously. The first decision is which general scheme to use for the overall approach. After considering the different choices, we thought that we needed a powerful metaheuristic which could offer the necessary efficiency and flexibility to combine the four tasks [60]. Evolutionary computation, swarm intelligence, stochastic optimization or any other similar method could be used. We have chosen evolutionary computation as it usually achieves results that are above, or at least match, the results of other metaheuristics. However, the conclusions of our work do not depend on a specific search method provided a powerful one is used.Wettschereck et al. [6] found that methods that use performance feedback to assign weight settings demonstrated three advantages over other methods: they require less pre-processing, perform better in the presence of interacting features, and generally require less training data to learn good settings. Evolutionary algorithms have also been used for all these tasks separately. They have been used for feature weighting [56,60,61], feature selection [36,39,41], instance selection [5,62] and instance weighting [63].From the evolutionary computation perspective, we have a problem in which real numbers and binary values must be evolved together. We have thus combined two of the most successful combinations for each task, specifically, a differential evolution algorithm and a CHC genetic algorithm. CHC stands for Cross generational elitist selection, Heterogeneous recombination and Cataclysmic mutation. Weights are evolved using a differential evolution algorithm, and selection is evolved using a binary CHC genetic algorithm.Given that there are N training instances with M features, the chromosome is of length 2N+2M. For each instance and feature, the chromosome codifies a real value, its weight, and a binary value based on whether it is selected. If any of the four tasks is not performed, the corresponding part of the chromosome remains fixed. For example, if no instance selection is conducted, all values corresponding to instance selection are set to 1 and are not modified during the evolution. An example of a chromosome for a dataset with 10 instances and 5 features is depicted in Fig. 1.The evolution follows the standard differential evolution scheme. Recombination is accomplished using the standard differential evolution recombination method combined with HUX (half uniform crossover (HUX) [64]) crossover for the binary part of the chromosome. This operator generates two offspring from two parents. Each offspring inherits the matching bits of the two parents, and half of the non-matching bits from each parent alternately. Fig. 2shows an example of this operator for two parents with 10 bits.The fitness value, F, for an individual, is given thus by:(3)F=αaacc+αi(1−fi)+αf(1−ff),where acc is the accuracy of the individual measured using a nearest neighbor rule, fiis the fraction of selected instances, ffis the fraction of selected features and αa+αi+αf=1. The values of αa, αiand αfare chosen to give accuracy and reduction the same importance. Thus, if instance and feature selection are conducted, the coefficients are αa=0.5, αi=αf=0.25; if only instance selection is conducted, then αa=0.5, αi=0.5, αf=0.0; if only feature selection is conducted, then αa=0.5, αi=0.0, αf=0.5; and if no selection is used, then αa=1.0, αi=αf=0.0. Accuracy measure is explained in Section 4.2.Differential evolution [65] is a parallel direct search method with a population of NP vectors in dimension D. The initial vector population is chosen randomly and should cover the entire parameter space. Differential evolution generates new parameter vectors by adding the weighted difference between two population vectors to a third vector. Let this operation be called mutation. The mutated vector's parameters are then mixed with the parameters of another predetermined vector, the target vector, to yield the trial vector. Parameter mixing is often referred to as “crossover” in the evolutionary computation community and is explained below in more detail. If the trial vector yields a higher fitness function value than the target vector, the trial vector replaces the target vector in the following generation. This last operation is called selection. Each population vector must serve as the target vector once, so NP competitions occur in one generation.More specifically, the basic strategy can be described using three different operators: mutation, crossover and selection. Consider that a new population for generation G+1 from the population of generation G is being generated. For mutation, a mutant vector for each target vector xi,G, i=1, 2, 3, …, NP is generated thus:(4)vi,G+1=xr1,G+F·(xr2,G−xr3,G),with random different indexes r1, r2 and r3 and F>0. The randomly chosen integers r1, r2 and r3 are also chosen to be different from the running index i, so NP must be greater than or equal to four to allow this condition. F is a real and constant factor in [0, 2], which controls the differential variation amplification.Crossover is used to increase the diversity of the perturbed parameter vectors. The trial vector ui,G+1=(u1i,G+1, u2i,G+1, …, uDi,G+1) is formed thus:(5)uji,G+1=vji,G+1ifr≤CRorj=rnbr(i),xji,Gotherwise,where r is a random number in [0, 1] and rnbr(i) is a randomly generated index to ensure that ui,G+1 gets at least one parameter fromvi,G+1. CR is the crossover constant, CR∈[0, 1], which has to be determined by the user. The actual values used in our experiments for these parameters are shown in Section 4.Finally, selection is performed. To decide whether it should become a member of generation G+1, the trial vector ui,G+1 is compared to the target vector xi,Gusing the greedy criterion. If vector ui,G+1 yields a better fitness function value than xi,G, then xi,G+1 is set to ui,G+1; otherwise, the old value xi,Gis retained.The combined algorithm works as follows. The initial population is randomly created using a probability of 0.5 for selecting a feature or instance and a uniform distribution of weights in the interval [0, 1]. If any of the four tasks is not carried out, the corresponding weights are set to 1. Then, a new population is generated by differential mutation, recombination and selection. Recombination is made using the adapted version of HUX explained above. This cycle is repeated the number of generations given as a parameter. Finally the individual with the best fitness in the last population is returned as the result of the optimization process.We used a set of 80 problems, shown in Table 1, to test the performance of the different combinations using the proposed framework. Most datasets are from the UCI Machine Learning Repository [66]. To estimate reduction and accuracy, we used a 10-fold cross-validation combination and a nearest neighbor (1-NN) classifier. Three repetitions of the experiments were performed for each partition, for a total of 30 runs per dataset.We used 60 problems to test the ability of our proposal in class-imbalanced datasets. The imbalance ratio is measured as the number of negative instances for every positive instance. An imbalance ratio of 1:30 means that there are 30 times more negative instances than positive ones. All problems are two-class problems, with an imbalance ratio of the minority class to the majority class ranging from 1:2 to 1:130. Table 2shows the features of these problems. These datasets are from the UCI MLR, the Kent Ridge Bio-medical Dataset (http://datam.i2r.a-star.edu.sg/datasets/krbd/index.html) or were created following García et al. [67] from UCI datasets.The source code in the C language used for all experiments is licensed under the GNU General Public License. The code, dataset partitions and detailed numerical results for all of the experiments are available at http://cib.uco.es/index.php/supplementary-material-for-ifws.For the evolutionary algorithm parameters, we have a population of NP=100 individuals. The population was evolved until 10,000 fitness function evaluations were performed. The differential evolution algorithm parameters were fixed to F=0.8 and CR=0.9 following previous recommendations [65]. These values are fairly common in the literature. We did not perform extensive fine tuning of the parameters values to avoid making the results too dependent from our experimental setup.All of the experiments were performed in a cluster of 32 blades. Each blade is a bi-processor Dell Power Edge M600 with four cores per processor. The blades are interconnected with a master node with a 1 GB network. The processors run at 2.5GHz, and each blade has 16GB of memory.To compare groups of methods, we first perform an Iman–Davenport test to ascertain whether there are significant differences among combinations. The Iman–Davenport test is based on theχF2Friedman test [68], which compares the average ranks of K algorithms. After performing the Iman–Davenport test, pairwise comparisons like the Wilcoxon test can be performed.The Wilcoxon [69] test is a statistical test for comparing algorithm pairs. This test assumes limited commensurability and is safer than parametric tests because it does not assume normal distributions or variance homogeneity. Empirical results [70] show that it is also stronger than other tests. However, when all algorithms are compared with a control method, it is not advisable to perform many Wilcoxon tests against the control method. A general procedure to control the family-wise error in multiple hypothesis testing can be used instead.The test statistic for comparing the i-th and j-th classifier using these methods isz=(Ri−Rj)/k(k+1)/6N). The z value is used to find the corresponding probability from the normal distribution table, which is then compared to an appropriate α. Step-up and step-down procedures sequentially test the hypotheses ordered by their significance. The ordered p values are denoted using p1, p2, ⋯, so p1≤p2≤…≤pk−1. Holm [71] developed a method which compares each piwith α/(k−i). Holm's step-down procedure starts with the most significant p value. If p1 is below α/(k−1), the corresponding hypothesis is rejected, and p2 with α/(k−2) can be tested. If the second hypothesis is rejected, the test proceeds with the third, and so on. As soon as a certain null hypothesis cannot be rejected, all remaining hypotheses are also retained.For standard datasets, we report accuracy and reduction as main performance values, when the method combination includes either feature or instance selection. Reduction is measured as the percentage of total data removed during the evolution. Thus, given a dataset with N training instances and M features, the reduction when niinstances and nffeatures are selected is given by:(6)R=1.0−niNnfM.Accuracy is usually measured as the percentage of instances classified correctly. However, that measure is not useful for imbalanced data, especially when the number of instances of the minority class is small compared to the majority class. For an imbalance ratio of 1:100, a classifier that assigns all instances to the majority class has 99% accuracy. Several measures have been developed to consider the imbalanced nature of the problems. Given the number of true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN), several measures can be defined. The most common are sensitivity, Sn=TP/(TP+FN), and specificity, Sp=TN/(TN+FP). These measures can be combined in the G-mean measure:(7)G−mean=TPrate·TNrate.The G-mean measures the balance performance of the learning algorithm between the two classes. When using our general framework, the only modification for experiments with standard datasets is using the G-mean, instead of accuracy, for the fitness function.

@&#CONCLUSIONS@&#
In this paper, we presented a framework for simultaneous instance and feature selection and weighting. We performed a comprehensive set of experiments to test the performance of all combinations of these four processes. In the study, we considered classification performance, reduction and execution time.For classification performance, feature weighting was the overall best method. Conversely, feature selection obtained the worst classification performance results. If our main aim is data reduction, combining feature and instance selection achieved the highest reduction results and had good classification performance. For classification performance, marginal improvement might be obtained adding feature or instance weighting to this combination, but the overall performance is not likely to improve significantly.We also studied the effects of feature selection, feature weighting, instance selection and instance weighting and their possible combinations when applied to class-imbalanced datasets. We used a fairly large set of 60 problems. The results showed that instance and feature selection combined with random undersampling is the best choice to handle these problems.A natural extension of this work would be to investigate whether the same conclusions can be obtained using other classifiers, including decision trees and support vector machines. Furthermore, the tasks addressed in the paper are intrinsically multiobjective, as we have two goals, reducing the dataset and achieving a high accuracy. Thus, an interesting research line is the study of whether the use of a multiobjective optimization method could improve the results presented here.