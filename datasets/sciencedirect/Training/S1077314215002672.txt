@&#MAIN-TITLE@&#
Illumination invariant optical flow using neighborhood descriptors

@&#HIGHLIGHTS@&#
Optical flow approach robust towards illumination changes and texture variability.Accurate multiscale TV-l1 approach for both small and large displacements.Accurate results for very different scenes with constant algorithm parameters.High performance was obtained on the Middlebury, KITTI and MPI Sintel databases.The algorithm enabled mosaicing of endoscopic images under different modalities.

@&#KEYPHRASES@&#
Optical flow,Neighborhood descriptors,Bilateral filtering,Image registration,Endoscopic image mosaicing,

@&#ABSTRACT@&#
Total variational (TV) methods using l1-norm are efficient approaches for optical flow determination. This contribution presents a multi-resolution TV-l1 approach using a data-term based on neighborhood descriptors and a weighted non-local regularizer. The proposed algorithm is robust to illumination changes. The benchmarking of the proposed algorithm is done with three reference databases (Middlebury, KITTI and MPI Sintel). On these databases, the proposed approach exhibits an optimal compromise between robustness, accuracy and computation speed. Numerous tests performed both on complicated data of the reference databases and on challenging endoscopic images acquired under three different modalities demonstrate the robustness and accuracy of the method against the presence of large or small displacements, weak texture information, varying illumination conditions and modality changes.

@&#INTRODUCTION@&#
Dense optical flow estimation has gained an immense interest in the field of computer vision since last few decades. It has been successfully used in various applications like object detection [1,2], image segmentation [3,4], structure from motion [5,6], image registration [7–11] and image mosaicing [12–14]. In general, optical flow algorithms are supposed to mimic human visual perception by estimating the motion of objects and/or of complete scene parts. However, robust optical flow computation is challenging due to strong scene variability in terms of texture, illumination conditions, topology differences, local deformations, large displacements and occlusions. In addition, artifacts caused by the image acquisition conditions like the blur caused by camera motion and the defocus or refocus of the lens foster these challenges and lead to an inaccurate estimation of the optical flow field. Therefore, obtaining a dense and accurate optical flow field under challenging scene and image acquisition conditions is still an open problem in computer vision.It is beyond the scope of this paper to present an overview on the entire dense optical flow methods. We have therefore mainly focused on illumination invariant methods and the methods that are based on non-local regularization for the accurate estimation of optical flow fields.The majority of dense optical flow algorithms are motivated by the foundation work of Horn and Schunck [15]. This method uses a variational framework that minimizes an energy including a data-fidelity term and a regularizer. The data-term is formulated as a brightness constancy assumption (BCA) which means that the degree of similarity between two pixels or regions depends on their intensity likeness. This classical data-term has been successfully used when the brightness constancy assumption is fulfilled [7,8,16,17]. However, in many scenes with varying illumination conditions this assumption does not hold true. This may occur in both classical photography (where local or global illumination changes appear in images due to shadows, camera viewpoint changes, moving objects in the scene or day light variations) and in medical images (for example, due to vignetting artifacts, organ specularity and different image acquisition protocols). Some algorithms [9,18,19] use a gradient constancy assumption (GCA) as a complementary term along BCA to deal with illumination changes between image pairs. Ali et al. [20,21] introduced a structure constancy assumption (SCA) integrated with the BCA assumption in the data-term. Structure estimates of the objects are used in the latter approaches using eigenvalue information from Hessian images. Ali et al. in  [22] used 2nd order Riesz wavelet transform for enhancing the edge structures and used a diffusion tensor to relax the strict structure based data-term. A non-local filtering was used in their optical flow estimation algorithm for robustly preserving the edge pixels.Efforts have also been made in preserving the motion discontinuities along the object boundaries. Due to the quadratic nature of its regularizer and data-term, the classical Horn–Schunck model [15] does not preserve flow discontinuities along the edges and is unable to handle outliers in the data-term. Most recent approaches [8,9,16–20,23] use l1-penalization for both the data term and the regularization term. The l1 data fidelity term is robust to outliers and the non-smooth regularizer allows for flow discontinuities along the edges. However, the preservation of flow discontinuities along the edges can still be improved. Wedel et al. [17] performed a structure–texture decomposition of images to allow for discontinuities along the edges. This decomposition is based on the Rudin–Osher–Fatemi (ROF) model proposed in [24] for image denoising. Werlberger et al. [25] suggested to replace the isotropic TV-regularization with an image driven anisotropic Huber-regularizer. A non-local smoothing approach using the bilateral filtering was directly integrated in the regularization term in [23,26]. Sun et al. [27,28] proposed a similar approach, using non-local cues for a heuristic median filtering based approach for refining optical flow fields. Such non-local weight uses 3 different correlation measures, namely: spatial, color and occlusion of a pixel of interest with respect to the neighboring pixels.In many real scenes, it is important to model a data-term which is invariant to illumination changes. A major drawback of the data-term modeling of most of the TV-approaches lies in their inability to accurately estimate optical flow field in image pairs with large illumination variability. The recent trend in optical flow field computation is estimation of flow fields in real scenes with large illumination changes. This is also the aim of this contribution.

@&#CONCLUSIONS@&#
