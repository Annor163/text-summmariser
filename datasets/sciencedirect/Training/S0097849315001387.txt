@&#MAIN-TITLE@&#
A discriminative approach to perspective shape from shading in uncalibrated illumination

@&#HIGHLIGHTS@&#
We estimate shape and reflectance map of an unknown object from a single image.The object is assumed to have uniform diffuse albedo.The model works in uncalibrated illumination with a perspective projection model.We leverage a novel large scale dataset in a discriminative learning approach.Training uses synthetic data rendered given the estimated lighting.

@&#KEYPHRASES@&#
Shape from shading,Discriminative prediction,Silhouette cues,Synthetic training data,

@&#ABSTRACT@&#
Estimating surface normals from a single image alone is a challenging problem. Previous work made various simplifications and focused on special cases, such as having directional lighting, known reflectance maps, etc. This is problematic, however, as shape from shading becomes impractical outside the lab. We argue that addressing more realistic settings requires multiple shading cues to be combined as well as generalized to natural illumination. However, this requires coping with an increased complexity of the approach and more parameters to be adjusted. Starting from a novel large-scale dataset for training and analysis, we pursue a discriminative learning approach to shape from shading. Regression forests enable efficient pixel-independent prediction and fast learning. The regression trees are adapted to predicting surface normals by using von Mises–Fisher distributions in the leaves. Spatial regularity of the normals is achieved through a combination of spatial features, including texton as well as novel silhouette features. The proposed silhouette features leverage the occluding contours of the surface and yield scale-invariant context. Their benefits include computational efficiency and good generalization to unseen data. Importantly, they allow estimating the reflectance map robustly, thus addressing the uncalibrated setting. Our method can also be extended to handle perspective projection. Experiments show that our discriminative approach outperforms the state of the art on various synthetic and real-world datasets.

@&#INTRODUCTION@&#
Shape from shading – the problem of estimating surface normals from just a single image – is a heavily ill-posed problem. For this reason many simplifying assumptions have been made, such as assuming smooth surfaces, uniform albedo, a known reflectance map, or even light coming from a single directional light source in known direction. Such strong assumptions strongly limit the applicability in practice, however. Outside of controlled lab settings, less restrictive assumptions are needed. In this paper, we estimate the surface of a diffuse object with uniform albedo together with its reflectance map in uncontrolled illumination, given only a single image (Fig. 1). To recover fine surface detail, our goal is to avoid strong spatial regularization. To that end, we generalize shading cues to more realistic lighting, as well as combine them owing to their complementary strengths. While this affects the model and computational complexity, and leads to an increased number of parameters, we show how to address these challenges with a discriminative learning approach to shape from shading.A key property of our approach is that it allows to combine several shading cues. We consider (1) the color of the pixel itself, which is a strong cue in hued illumination [2], and is often exploited by using a second order approximation of Lambertian shading [3]. Our experiments (Section 9.1) show, however, that the cue becomes less reliable in the presence of correlated color channels (e.g. in near white light) or noise. We aid disambiguation by adding (2) local context[4], which to date has been limited to the case of directional lighting. We capture the local appearance context using a texton filter bank [5], instead of using the colors in the neighborhood directly. Through cue combination in our learning framework, we achieve automatic adaptation to uncontrolled lighting and reconstruct fine surface detail. Finally, we introduce novel (3) silhouette features. While the use of silhouette information in shape from shading dates back to foundational work by Ikeuchi, Horn, and Koenderink [6,7], previous work has only constrained surface normals at the occluding contour and employed global reasoning to propagate the information to the interior [8]. We show how to generalize the occluding contour constraint to the surface interior, which yields (spatial) contour information at every pixel that is furthermore invariant to the local scale of the object. These silhouette features are applicable to both orthographic and perspective cameras. Moreover, our novel silhouette features also give a coarse estimate of the surface by themselves, which allows us to estimate the unknown reflectance map.A number of challenges arise in discriminative learning for uncalibrated shape from shading: First, we require a training database of surfaces captured in the same conditions as the object to be reconstructed. It seems infeasible to capture all possible combinations of surfaces and lighting conditions, and inserting known reference objects in the scene [9] is typically impractical. For this reason, some learning approaches [10,11] create databases on-the-fly by rendering synthetic shapes once the lighting condition is known. Our approach adopts this strategy, but relies on a significantly larger database of 3D models than previous work in order to capture the variation of realistic surfaces. Second, and in contrast to [10,11], we cope with unknown illumination at test time. To that end we estimate the reflectance map from our silhouette features, and train the discriminative approach once the reflectance has been estimated. Third, (re-)training for the specific lighting condition at test time requires efficient learning and inference. Enabled by the diverse cues discussed above, we adopt regression forests for efficient pixel-independent surface normal prediction by storing von Mises–Fisher distributions in the leaves. Finally, an optional refinement step enforces integrability of the predicted surface normals. Fig. 2depicts the entire pipeline. Note that this work is based on a previous conference publication [12], which we generalize here to the perspective case. Moreover, we provide additional detail and illustrations.After introducing our approach, we assess the contribution of the different cues using a statistical evaluation and as components of our pipeline. Moreover, we evaluate our method both qualitatively and quantitatively on synthetic data as well as a novel real-world dataset, where it outperforms several state-of-the art algorithms.

@&#CONCLUSIONS@&#
