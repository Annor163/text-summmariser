@&#MAIN-TITLE@&#
A self-adaptive multi-objective harmony search algorithm based on harmony memory variance

@&#HIGHLIGHTS@&#
This paper aims to improve the performance of harmony search algorithm for solving multi-objective optimization problems.Firstly, a novel self-adaptive mechanism has been proposed to improve performance of harmony search algorithm for solving multi-objective problems.Secondly, the proposed algorithm is applied to solve many classical benchmark problems and it is also compared with other multi-objective evolutionary algorithms.Thirdly, the proposed algorithm is applied to solve a practical engineering problem.Fourthly, the impact of harmony memory size on the performance of the proposed algorithm is analyzed.

@&#KEYPHRASES@&#
Multi-objective optimization,Pareto front (PF),Harmony search (HS),Self-adaptive parameter setting,Self-adaptive bandwidth,

@&#ABSTRACT@&#
Although harmony search (HS) algorithm has shown many advantages in solving global optimization problems, its parameters need to be set by users according to experience and problem characteristics. This causes great difficulties for novice users. In order to overcome this difficulty, a self-adaptive multi-objective harmony search (SAMOHS) algorithm based on harmony memory variance is proposed in this paper. In the SAMOHS algorithm, a modified self-adaptive bandwidth is employed, moreover, the self-adaptive parameter setting based on variation of harmony memory variance is proposed for harmony memory considering rate (HMCR) and pitch adjusting rate (PAR). To solve multi-objective optimization problems (MOPs), the proposed SAMOHS uses non-dominated sorting and truncating procedure to update harmony memory (HM). To demonstrate the effectiveness of the SAMOHS, it is tested with many benchmark problems and applied to solve a practical engineering optimization problem. The experimental results show that the SAMOHS is competitive in convergence performance and diversity performance, compared with other multi-objective evolutionary algorithms (MOEAs). In the experiment, the impact of harmony memory size (HMS) on the performance of SAMOHS is also analyzed.

@&#INTRODUCTION@&#
The majority of real-world optimization problems consist of multiple objectives which usually conflict with each other, the so called multi-objective optimization problems (MOPs). MOPs generate a set of optimal solutions instead of a single solution, largely known as Pareto optimal set [1]. The efficiency to find multiple solutions of most classical optimization algorithms is low since these optimization algorithms usually achieve only one Pareto optimal solution in one run, therefore, these algorithms have to be run many times to acquire the Pareto optimal set.In the last few decades, evolutionary algorithms have attracted great attention among researchers to solve MOPs, many multi-objective evolutionary algorithms (MOEAs) have been developed, such as NSGA-II [1], PESA-II [2], SPEA2 [3] and M-PAES [4]. The reason for the fast development of MOEAs is that these algorithms are able to find multiple Pareto optimal solutions in just one single execution. Harmony search (HS) algorithm, inspired by the music improvisation process, is a new kind of meta-heuristic algorithm [5]. The HS algorithm has been applied to solve a wide variety of optimization problems [6–9] as it has several advantages including: (a) HS has fewer control parameters and the initial value setting of decision variables is unnecessary and (b) HS is easy to be implemented and understood.Recently, there are several attempts to extend the HS to solve MOPs. Literature [10] has used HS to solve multi-objective optimization of time-cost trade-off, while this algorithm has little diversity of non-dominated solutions as it only uses dominated-based comparison and ignores diversity comparison. The multi-objective harmony search algorithm proposed by Sivasubramani et al. [11] is able to converge to Pareto optimal solutions, however it has low convergence rate and needs a large number of iterations. This low convergence rate can be attributed to the use of an improved harmony search (IHS) algorithm [12] whose convergence rate is far from fast. Two detailed proposals for applying basic HS algorithm to solve MOPs have been proposed by Ricart et al. [13], however these algorithms show poor performance in terms of convergence and diversity. Pavelski et al. [14] have investigated four variants of HS algorithm for solving MOPs. However, these four variants cannot generate true and well-distributed Pareto optimal solutions. The poor performance of all aforementioned multi-objective HS algorithms can be attributed to the fact that these algorithms have poor search abilities for MOPs. Moreover, the control parameters of these multi-objective HS algorithms need to be set by users according to experience and problem characteristics. As a result, this causes great burden to new users, and hinders the application and development of multi-objective HS algorithm.In view of the shortcomings of above-mentioned multi-objective HS algorithms, a self-adaptive multi-objective harmony search (SAMOHS) algorithm based on harmony memory (HM) variance is proposed in this paper. The variation of the population variance has great influence on the explorative ability of the HS algorithm [15], and the variance of HM reflects the diversity of HM to some extent [16]. Inspired by these researches, a novel self-adaptive mechanism based on the variation of the HM variance is employed in SAMOHS. The proposed self-adaptive mechanism has three main improvements, they are: (a) each decision variable has its own control parameters, which are updated adaptively during the search process; (b) a self-adaptive parameter setting based on variation of HM variance is employed for harmony memory considering rate (HMCR) and pitch adjusting rate (PAR); (c) a modified self-adaptive bandwidth (bw) is proposed for HS. By using the self-adaptive mechanism, the SAMOHS has better adaptability and robustness. In addition, the global and local search abilities of SAMOHS are improved, and the burden of parameters setting is alleviated. For solving MOPs, a non-dominated sorting [1] and truncating procedure [3] are utilized to update the HM effectively and to preserve the diversity of non-dominated solutions in HM.The rest of this paper is organized as follows. In Section 2, basic concepts of MOPs are briefly presented. Section 3 describes the basic HS algorithm. In Section 4, the motivations and framework of the proposed SAMOHS algorithm are presented. The experimental results are given in Section 5. Finally, the conclusion is given in Section 6.In this section, basic concepts on multi-objective optimization relevant to this paper are presented. The mathematical model of MOPs is formulated as [17]:(1)minimizef(x)={f1(x),f2(x),…,fk(x)}Tsubjecttox⊂S⊂Rnwith k≥2 conflicting objective functions fi:S⟶R. Heref(x) denotes the vector of objective function value to be optimized, and the decision vectorx=(x1, x2, …, xn)Tbelongs to the search space S defined usually with constraint functions.Consider two decision vectorsg=(g1, g2, …, gn)T∈S andh=(h1, h2, …, hn)T∈S for MOPs in Eq. (1), the relation betweengandhcan be mathematically described as [18]:(2)g≺≺h,if∀i∈{1,2,…,k},gi<hig≺h,if∀i∈{1,2,…,k},gi≤hi∩∃i∈{1,2,…,k},gi<hig⊀h,if∃i∈{1,2,…,k},gi>hiwhere ≺≺,≺ and ⊀ denote strong dominance, dominance and not dominated, respectively.A decision vectorx★∈S for this problem is Pareto optimal solution if there is nox∈S satisfies withf(x)≺f(x★). An objective vectorz★=f(x★) is called Pareto optimal if corresponding vectorx★ is Pareto optimal solution. The set of all Pareto optimal solutionsx★∈S is called Pareto optimal set, so the Pareto optimal set is also a set of non-dominated solutions. For a given MOP and its corresponding Pareto optimal set P★, the optimal Pareto front (PF) is defined as PF★={f(x)∣x∈P★}.The main purpose of multi-objective optimization is to obtain the Pareto optimal set and the optimal PF. Recently, an exact algorithm in relation to a multi-objective maintenance problem, able to describe the entire PF in a very short computational time, has been developed [19]. However, in most cases, finding the optimal PF that contains all these points is not realistic [20]. Therefore, it is necessary to find an approximated PF that contains points as evenly spread and as close as possible with respect to the optimal PF in case of without any further information. In order to acquire the approximated PF, the common method is to calculate the feasible domain S and its correspondingf(S) by applying specific algorithms.HS algorithm is a simple but powerful memory-based stochastic search technique for solving global optimization problems. In the basic HS algorithm, each solution is expressed by a n-dimension real vector and typically named a “harmony” [5]. An initial population of harmony vectors stored in a HM is randomly generated. A new harmony is then improvised based on all harmonies stored in the HM by applying an improvisation scheme. Afterwards, the newly generated harmony is compared with the worst harmony in HM and replaces the worst one if it has a better fitness value. The algorithm repeats until a predefined stopping condition is met.A typical optimization problem is formulated as follows:(3)Minimizef(x)subjecttoxj∈[LBj,UBj],j=1,2,…,nwhere f(x) is the objective function;x=(x1, x2, …, xn) is the set of n-dimension decision variable; LBjand UBjdenote the lower and upper limits for xj, respectively.The main procedure of the basic HS algorithm for optimization problem in Eq. (3) is described as follows:Step 1: Initialize the algorithm parameters. The following parameters of HS algorithm are set: harmony memory size (HMS), HMCR, bw, PAR, and the number of improvisations (NI).Step 2: Initialize the harmony memory. In this step, the HM matrix is filled with HMS randomly generated harmony vectors:(4)HM=X1X2⋮Xi⋮XHMS=x1,1x1,2⋯x1,j⋯x1,nx2,1x2,2⋯x2,j⋯x2,n⋮⋮⋯⋮⋯⋮xi,1xi,2⋯xi,j⋯xi,n⋮⋮⋯⋮⋯⋮xHMS,1xHMS,2⋯xHMS,j⋯xHMS,nStep 3: Improvise a new harmony. A new harmony vector Xnew=(xnew,1, xnew,2, …, xnew,n) is generated by applying three rules: (a) memory consideration, (b) pitch adjustment and (c) random selection. Generating a new harmony is typically named “improvisation” [21]. The improvisation procedure works as follows:Algorithm 1The procedure of improvisation in HSforj=1, …, ndoifrand()≤HMCRthenxnew,j∈{x1,j, x2,j, …, xHMS,j}//memoryconsiderationifrand()≤PARthenxnew,j=xnew,j±rand()×bw//pitchadjustmentend ifelsexnew,j=LBj+rand()×(UBj−LBj)//randomselectionend ifend forwhere rand() is a random number generated from an uniform distribution of [0,1].Step 4: Update the harmony memory. If the newly generated harmony Xnewis better than the worst harmony stored in the HM, judged by their objective function values, the HM will be updated. It means that the new harmony with better state will replace the harmony with the worst fitness value in HM.Step 5: Check the stopping criterion. If the stopping criterion is met, algorithm computation is terminated. Otherwise, go to Step 3.When the HS is employed to solve MOPs, it is difficult to set its control parameters. On one hand, the performance of HS is extremely sensitive to values of control parameters. This means that different parameter values can cause different performance in terms of convergence precision, convergence rate and reliability. On the other hand, the fixed parameter value is inappropriate for balancing diversity and intensity during the search process. Although various dynamic parameters setting strategies and self-adaptive mechanisms have been proposed for single objective HS algorithm, there are few researches for multi-objective HS algorithm. In addition, dynamic parameters setting strategies still have some disadvantages [12], such as all decision variables use the same control parameter during the search process. This is difficult to find a good balance between exploration and exploitation since each decision variable has its own characteristics.In view of these problems, a novel self-adaptive mechanism for multi-objective HS algorithm is proposed in this paper. The proposed self-adaptive mechanism has three main improvements, including (a) each decision variable has its own control parameters, which are updated adaptively during the search process; (b) self-adaptive parameter setting based on variation of HM variance is employed for HMCR and PAR; (c) a modified self-adaptive bw is proposed for HS. The details of the proposed SAMOHS algorithm are described below.In this section, the proposed SAMOHS based on HM variance is presented. It should be noted that the HM updating for MOPs is different from single objective optimization. For the HM updating in solving MOPs, the HM is updated after generating HMS new harmonies instead of one harmony at each iteration. The implementation procedure of the proposed SAMOHS is shown in Fig. 1and it can be summarized as follows:Step 1. Initialize the algorithm parameters. Set the maximal number of iteration T, let iteration counter t=1, randomly generate initial harmony memory HMtand evaluate all harmonies in HMt. Specify the minimum value and maximum value as HMCRminand HMCRmax, set [PARmean1, PARstd1] and [PARmean2, PARstd2] for PAR, set [Kmin1, Kmax1] and [Kmin1, Kmax1] for K and HMS.Step 2. Update the control parameters. The control parameter values HMCRj,t, PARj,tand bwj,tfor each variable are assigned according to the proposed self-adaptive mechanism as described in Section 4.2.Step 3. Improvise a new harmony memory. Execute the procedure of improvisation as shown in Algorithm 1 by using parameter values HMCRj,t, PARj,tand bwj,tfor HMS times to form a new harmony memoryHMtnew.Step 4. Evaluate fitness value. Evaluate the fitness value of each harmony inHMtnew.Step 5. Update harmony memory. The detailed updating procedure of HM is described in Section 4.3.Step 6. Check termination criterion. If t≥T is reached, set A to the set of solutions expressed by the non-dominated solutions in HMt+1, output the non-dominated set A and terminate the algorithm. Otherwise, increase iteration counter (t=t+1) and go to Step 2.Since the key parameters HMCR, PAR and bw play a crucial role on the performance of HS algorithm and it is really difficult to tune these parameters, a novel self-adaptive mechanism based on the variation of the HM variance is proposed in this paper. It is necessary to emphasize that the proposed self-adaptive parameter setting is inspired by single objective differential evolution algorithm [22], however the proposed self-adaptive parameter setting is based on the HM variance. The details of the proposed self-adaptive mechanism for SAMOHS are described below.Firstly, HMCRj,t, PARj,tand Kj,tare encoded into each decision variable xj, as shown in Fig. 2. Here t denotes the current iteration and Kj,tis a mutative coefficient used to modify the distance bandwidth bwj,t. Thereafter, the parameters HMCRj,t, PARj,tand Kj,tare adaptively updated as follows during the search process. If the variation of VARjis Case 1 or Case 2, HMCRj,t, PARj,tand Kj,tare renewed by Eqs. (8)–(10), respectively. Otherwise, HMCRj,t, PARj,tand Kj,tare all renewed by Eq. (5). Here, Case 1 is defined as: the HM variance value VARjof jth variable decreases in α (α=3 is utilized in this paper) consecutive iterations. Case 2 is defined as: the HM variance value VARjof jth variable increases in β (β=4 is utilized in this paper) consecutive iterations.(5)HMCRj,t=HMCRj,t−1PARj,t=PARj,t−1Kj,t=Kj,t−1The variance value of jth variable in current HM can be mathematically defined as follows:(6)VARj=1HMS∑i=1HMS(xi,j−x¯j)2(7)x¯j=1HMS∑i=1HMSxi,jwherex¯jis the HM mean value of jth variable which is given by Eq. (7), and xi,jrepresents jth decision variable value of the ithe harmony stored in HM.The HMCRj,tis set as follows and illustrated in Fig. 3.(8)HMCRj,t=U[HMCRmin,HMCRmedium];VARj,t<VARj,t−1<…<VARj,t−αU[HMCRmedium,HMCRmax];VARj,t>VARj,t−1>…>VARj,t−βwhere U[Umin, Umax] means the function of uniform distribution within the lower limit Uminand upper limit Umax, HMCRmediumis the medium value of the interval [HMCRmin, HMCRmax], VARj,tis the HM variance value of jth variable in the current iteration, VARj,t−1 is the HM variance value of jth variable in the last iteration.Remark 1: From Eq. (8) and Fig. 3, it can be observed that the parameter setting for HMCRj,tis different from other variants of HS. In the basic HS, when the variance of HM decreases fast, the HS can not stop this tendency because of its fixed parameter values. As a result, the diversity of HM falls sharply, the HS is easy to trap into local optimal. On the other hand, if the variance of HM increases continuously, this will lead to poor local search ability. Therefore, the parameter setting in Eq. (8) is able to overcome this shortcoming. The HMCRj,twill be assigned a small value when the variance of HM decreases fast, as small value HMCRj,tcan bring more new solutions by executing more random selection operations. As a result, the diversity of HM increases timely. In the same way, the HMCRj,twill be assigned a big value when the variance of HM increases sharply, as big value HMCRj,tis helpful to enhance the local search ability of HS.The PARj,tis set as follows and illustrated in Fig. 4.(9)PARj,t=randn(PARmean1,PARstd1);VARj,t<VARj,t−1<…<VARj,t−αrandn(PARmean2,PARstd2);VARj,t>VARj,t−1>…>VARj,t−βwhere randn(PARmean, PARstd) means the function that is normally distributed with mean PARmeanand standard deviation PARstd.Remark 2: It can be seen from Eq. (9) and Fig. 4 that the function of parameter setting for PARj,tis similar to HMCRj,t. In Case 1, the PARj,tis assigned a relative big value for the purpose of enhancing the diversity of HM. While in Case 2, the PARj,tis assigned a relative small value with the aim of slowing down the speed of exploration. Therefore, the parameter setting for PARj,tis helpful for keeping a good balance between exploration and exploitation.The Kj,tis set as follows and illustrated in Fig. 5.(10)Kj,t=U[Kmin1,Kmax1];VARj,t<VARj,t−1<…<VARj,t−αU[Kmin2,Kmax2];VARj,t>VARj,t−1>…>VARj,t−βwhere U[, ] is a function of uniform distribution as Eq. (8). In this paper, Kmin1=1.5, Kmax1=2.0, Kmin2=0.1 and Kmax2=0.5. That is to say, the coefficient Kj,tis assigned a value in the range of [1.5, 2.0] and [0.1, 0.5] for the Case 1 and Case 2, respectively.As stated before, the coefficient Kj,tis utilized to modify the bw. Like HMCR and PAR, each decision variable has its own bw during the search process. To further enhance the search ability of HS, the modified self-adaptive bw, which is given in Eq. (11), is proposed in this paper. The bw for each variable is computed as follows:(11)bwj,t=Kj,t×VARjwhereVARjis the standard deviation of jth variable in the current HM, and bwj,tdenotes the distance bandwidth of jth variable for the current iteration.Remark 3: Mukhopadhyay et al. [15] suggested that it was usually useful to use the standard deviation of the current HM for bw. It can be clearly seen from Eqs. (10) and (11) and Fig. 5 that the bwj,tis bigger thanVARjwhen the coefficient Kj,tis assigned a relative big value greater than 1 in the Case 1. While in the Case 2, the bwj,tis smaller thanVARjwhen the coefficient Kj,tis assigned a relative small value less than 1. It is really helpful to use a magnified bw when the variance of HM decreases sharply, in the same way, a shorted bw is used when the variance of HM increases quickly. Therefore, the exploration and exploitation abilities of HS are strengthened with the introduction of the parameter setting for coefficient Kj,t.Remark 4: Since a normal distribution is used for PAR, the values of PAR are highly concentrated around a certain value during the search process. This ensures that pitch adjustment operations can be kept at a relatively stable level. This is helpful to preserve the diversity of HM. For the parameter HMCR, a uniform distribution is chosen. Compared to the normal distribution, the uniform distribution is more effective to diversify the HMCR and thus avoid the premature which occurs under highly concentrated HMCR. For the parameter K, a uniform distribution is also used. The reason is that the diverse K is helpful to diversify the bw. What's more, the diverse bw value is useful to diversify HM.Firstly, the new harmony memoryHMtnewis combined with the current harmony memory HMtasHMt⋃HMtnew, which has the size of 2×HMS. ThenHMt⋃HMtnewis performed a fast non-dominated sorting procedure [1]. The detailed non-dominated sorting process can be described as follows:(a)For each solution p inHMt⋃HMtnew, compute two entities: (1) domination count np, the number of solutions that dominate p; (2) Sp, a set of solutions inHMt⋃HMtnewthat p dominates.All solutions inHMt⋃HMtnew, which have their domination count as zero, are belong to the first front.For each solution p with np=0, visit each member (q) of its set Spand implement nq=nq−1. In this way, for any member q with nq=0, put it in a separate list Q. These members in Q belong to the second front. The above procedure is continued with each member of Q and the third front is identified. This process continues until all fronts are identified.After the non-dominated sorting procedure is completed, each harmony inHMt⋃HMtnewis assigned a ranking. Harmonies in theHMt⋃HMtneware transferred to HMt+1 in the sequence of their ranking. To select exactly HMS harmonies from the last non-dominated front, a truncating procedure in [3] is utilized to cut down the size of harmonies until the size of last front is equal to the space available in HMt+1. The HMt+1 is for the next improvisation.In this section, several benchmark problems are used to evaluate the performance of proposed SAMOHS algorithm. Firstly, the comparisons of SAMOHS with other MOEAs are described and discussed. Secondly, the comparisons of SAMOHS with other multi-objective HS algorithms have been implemented. Thirdly, the SAMOHS has been applied for satellite heat pipe design. Finally, the sensitivity of SAMOHS to different HMS has been investigated.In order to evaluate the performance of the proposed SAMOHS algorithm, it is compared with three classical MOEAs, they are: NSGA-II [1], SPEA2 [3] and MOPSO [20].Fourteen classical test problems frequently used in the MOEAs literature are selected in this section. They are all unconstrained problems, including eight bi-objective problems: Schaffer, Fonseca, and Kursawe [1], as well as ZDT1–ZDT4, ZDT6 [23], and six tri-objective problems: DTLZ1, DTZL2, DTLZ4–DTLZ7 [24].In this paper, three quality indicators which are frequently utilized in MOEAs are used to evaluate the performance of multi-objective optimization algorithms. The quality indicators are generational distance (GD) [25], hypervolume (HV) [26] and Spread (Δ).The convergence indicator GD is calculated as:(12)GD=1n∑i=1ndip1/pwhere p=2, n is the size of the approximated PF, diis the Euclidean distance (measured in objective space) between the ith solution on the approximated PF and the nearest solution on real PF.For evaluating bi-objective problems, the uniformity and diversity indicator Δ in [1] is defined as:(13)Δ=df+dl+∑i=1N−1|di−d¯|df+dl+(N−1)d¯where dfand dlare the Euclidean distances (measured in objective space) between the extreme solutions and the boundary solutions of the obtained non-dominated set, N is size of the obtained non-dominated set, didenotes the Euclidean distance between the adjacent solutions in the obtained non-dominated set of solutions andd¯is the average of all di.For over two objectives problems, the revised indicator Δ in [27] is defined as:(14)Δ=∑i=1md(Ei,Ω)+∑X∈Ω|d(X,Ω)−d¯|∑i=1md(Ei,Ω)+(|Ω|−m)d¯(15)d(X,Ω)=minY∈Ω,Y≠X∥F(X)−F(Y)∥(16)d¯=1|Ω|∑X∈Ωd(X,Ω)where (Ei, …, Em) are m extreme solutions in a set of known Pareto optimal solutions, Ω is a set of non-dominated solutions, m is the size of objectives.The convergence and diversity indicator HV can be mathematically defined as:(17)HV=⋃i=1|Ω|νiwhere νiconsists of a pre-determined reference point and ith solution in Ω as the diagonal corners of the hypercube, Ω is the obtained non-dominated set.The HV computes the volume (measured in objective space) between the obtained non-dominated solutions and a reference point, and a larger HV value is desirable. It is necessary to emphasize that the solutions that do not dominate the reference point are excluded in the HV computation. Since the calculation of the HV is related to the reference point, the HV value of a set of solutions is normalized by a reference set of Pareto optimal solutions with the same reference point [18]. The HV value is confined in [0,1] after normalization.According to the proposed self-adaptive mechanism in this paper, the initialization step should assign an interval to HMCR, it was usually appropriate to use a large HMCR value (i.e., HMCR≥0.9) [12]. In view of this, HMCRminand HMCRmaxare set to 0.9 and 1.0, respectively. According to literatures [28–30], it is generally appropriate to take a small value for PAR. Therefore, PARmean1, PARstd1, PARmean2 and PARstd2 are set to 0.2, 0.025, 0.1 and 0.025, respectively. For the parameter HMS, it is set to 100 for fair comparison.The real-coded version of NSGA-II created by Deb et al. [1] is used in this experiment, it uses the following parameter values: a cross probability of 0.9, a mutation probability of 1/n (n is the number of decision variables), distribution index for SBX and mutation are both 20, and a population size of 100. The default parameters used in the SPEA2 are the same with NSGA-II. The MOPSO uses a population size of 100, a repository size of 100, a mutation probability of 0.5, and divisions for adaptive grid of 30. To ensure a fair comparison, the four algorithms are executed under the same conditions, including a population size of 100, the maximum function evaluation is 25,000 for bi-objective problems, and 50,000 for tri-objective problems.In this section, the GD indicator value, spread indicator value and HV indicator value obtained by SAMOHS, NSGA-II, SPEA2 and MOPSO in 30 independent runs are reported in Tables 1–3, respectively. Additionally, the mean of GD indicator value, spread indicator value and HV indicator value obtained by these four algorithms in 30 independent runs are shown in Figs. 6–8, respectively. The mean and standard deviation of the these three performance indicators are calculated for a quantitative analysis. It is necessary to emphasize that the experimental results of NSGA-II, SPEA2 and MOPSO are directly taken from [18] to make a fair comparison.It can be clearly seen from Table 1 and Fig. 6 that the SAMOHS has obtained better values for the GD indicator than other three algorithms in all test problems. This means that the approximated Pareto fronts obtained by SAMOHS are closer to the optimal Pareto fronts than those obtained by NSGA-II, SPEA2 and MOPSO.Table 2 and Fig. 7 clearly show that the SAMOHS generates ten best results out of fourteen test problems for the spread indicator. More specifically, comparing with NSGA-II, SAMOHS generates much better results for all test problems except ZDT3. Therefore, it can be claimed that SAMOHS outperforms NSGA-II concerning the diversity of the approximated Pareto fronts. Compared with SPEA2, SAMOHS yields better results for all problems except Kursawe, Fonseca and ZDT3. When comparing with MOPSO, SAMOHS generates much better results for all problems except problems ZDT2 and ZDT3. The main reason that SAMOHS shows weak performance on ZDT3 problem is that the PF of ZDT3 problem is discontinuous. On the one hand, the discontinuous PF of the problem ZDT3 is related to the discrete Pareto optimal solutions in decision variable space. On the other hand, the computation of bw is related to the HM variance of each variable. The discrete Pareto optimal solutions of ZDT3 in decision variable space are not helpful to diversify bw. As a result, the diversity performance of SAMOHS on ZDT3 problem can be weakened.It can be seen from Table 3 and Fig. 8 that the SAMOHS has the best HV values among the four algorithms on all test problems. This means that the SAMOHS outperforms algorithms NSGA-II, SPEA2 and MOPSO when considering convergence and diversity simultaneously. For problem DTLZ6, the algorithms NSGA-II, SPEA2 and MOPSO yield a value of zero. The reason is that the Pareto fronts obtained by these three algorithms are unable to reach close to the optimal PF. However, the proposed SAMOHS yields a value close to 1. This means that the SAMOHS is able to generate a true and well-distributed PF on problem DTLZ6.In order to clearly show the approximated PF obtained by SAMOHS algorithm, Figs. 9–11illustrate the approximated PF of all test problems generated by SAMOHS. In Fig. 9, the real PF and approximated PF obtained by SAMOHS are both shown in the same figure. As for Figs. 10 and 11, the left panel is the real PF and the right panel is for approximated PF obtained by SAMOHS. It can be seen from Figs. 9–11 that the approximated PF generated by SAMOHS are distributed uniformly along the real PF for all test problems. So it is easy to know that SAMOHS is able to converge to the real PF for all test problems.To make convincing conclusions, analysis of mean values of the three performance indicators by using Wilcoxon test [31] is implemented. The Wilcoxon test is a fair test that aims to discover significant differences between the performance of two compared algorithms. The test computations are described as follows:(18)R+=∑di>0rank(di)+12∑di=0rank(di)(19)R−=∑di<0rank(di)+12∑di=0rank(di)where diis the difference between the performance scores of the two algorithms on ith out of N′ benchmark test functions. R+ is the sum of ranks for the benchmark test function on which the second algorithm is superior to the first, and R− is the sum of ranks for the opposite. It means that a bigger value R+ demonstrates the first algorithm is better than the second one. The Family Wise Error Rate (FWER) [31] is defined as the probability of making one or more false detections among all the hypotheses when implementing multiple pairwise tests. The results obtained by the four algorithms are analyzed independently for all test functions by computing the P value in a pairwise comparison. All the computations of the P value are carried out by the well-known statistical software package SPSS.The results of Wilcoxon test for the SAMOHS against NSGA-II, SPEA2 and MOPSO are reported in Table 4. It can be observed that the proposed SAMOHS is much better than NSGA-II, SPEA2 and MOPSO with a level of significance α=0.01 (P value of FWER is 0.003) for GD. As for Spread indicator (Δ), SAMOHS outperforms NSGA-II, SPEA2 and MOPSO with a level of significance α=0.05 (P value of FWER is 0.030). With respect to HV, SAMOHS has much better performance than NSGA-II, SPEA2 and MOPSO with α=0.01 (P value of FWER is 0.003). From above experimental results and analysis, it can be concluded that SAMOHS outperforms the NSGA-II, SPEA2 and MOPSO in convergence performance, moreover, SAMOHS obtains a better diversity performance than NSGA-II, SPEA2 and MOPSO.The Friedman test is effective when comparing more than two algorithms on several problems [32]. In order to further compare the performance of the four algorithms, the Friedman test is conducted on the mean values of the three performance indicators by making using of the software package SPSS. The experimental results is summarized in Table 5. It can be seen from Table 5 that the SAMOHS has the best ranking for the three performance indicators.To demonstrate the effectiveness of the proposed self-adaptive strategy, the SAMOHS is also compared with MOHS1 and MOHS2 created by Ricart et al. [13]. MOHS1 and MOHS2 both employ basic HS algorithm to solve MOPs, so it is feasible to verify the improved performance of SAMOHS using the proposed self-adaptive strategy.As MOHS1 and MOHS2 are only evaluated on bi-objective functions in [13] and these two algorithms need to set parameters according to specific problem, the default test problems in [13] and three aforementioned bi-objective problems are selected. Therefore, the test problems are ZDT1–ZDT4, ZDT6, Schaffer, Fonseca, and Kursawe. Since ZDT5 is a problem with binary variables and SAMOHS algorithm uses decimal variables, the problem ZDT5 is not included.The control parameters for the proposed SAMOHS are set before in Section 5.1.3. To ensure the fair comparison, MOHS1 and MOHS2 use the default control parameters in [13]. The parameters for the SAMOHS, MOHS1 and MOHS2 are presented in Table 6, where Δxis the range of values of search space. It is unnecessary to set bw since it is adaptively updated in the SAMOHS. Additionally, PARmean1, PARstd1, PARmean2 and PARstd2 are set to 0.2, 0.025, 0.1 and 0.025, respectively. Table 6 clearly shows that the HMS and maximum function evaluation for these three algorithms are all set to 100 and 25,000, respectively. So, the comparison between the SAMOHS and other two algorithms is fair.The previously presented three performance indicators using the algorithms SAMOHS, MOHS1 and MOHS2 in 30 independent runs are reported in Tables 7–9. In addition, the mean of these indicators values obtained by the three algorithms in 30 independent runs are illustrated in Figs. 12–14.From Table 7 and Fig. 12, it can be easily seen that the SAMOHS obtains the best performance among these three algorithms in terms of convergence. It means that the approximated Pareto fronts achieved by the SAMOHS are nearer to the real Pareto fronts than those obtained by MOHS1 and MOHS2.According to the results from Table 8 and Fig. 13, the SAMOHS generates six best results out of eight test problems for the spread indicator. Compared with MOHS1, SAMOHS obtains better results for all test problems except ZDT3. For the ZDT3, the results obtained by SAMOHS and MOHS1 are almost similar, and the SAMOHS has smaller standard deviation value than that of MOHS1. It means that the SAMOHS has better stability than MOHS1. Compared with MOHS2, the SAMOHS generates better results for all test problems except ZDT3 and ZDT6, the results obtained by SAMOHS and MOHS1 on ZDT3 and ZDT6 are similar. Therefore, it is reasonable to claim that the SAMOHS outperforms MOHS1 and MOHS2 concerning the diversity of the approximated PF.Table 9 and Fig. 14 obviously show that the proposed SAMOHS generates best HV results for all test problems except problem ZDT6. For the problem ZDT6, MOHS2 obtains the best result, and the result of SAMOHS is very close to the result of MOHS2. Hence, it can be claimed that the SAMOHS is competitive when compared with MOHS1 and MOHS2 concerning convergence and diversity simultaneously.In order to illustrate the PF performance, experimental results of these three algorithms for problems Schaffer and ZDT4 are depicted in Figs. 15 and 16, respectively. It can be seen from Fig. 15 that MOHS1 and MOHS2 are able to converge to the true PF for the problem Schaffer, while they are unable to generate a well-distributed PF, especially for the MOHS1. For the SAMOHS, it obtains a true and well-distributed PF. The better performance of SAMOHS can be attributed to the fact that the proposed self-adaptive distance bandwidth in SAMOHS is able to enhance global and local search abilities. From Fig. 16, it can be observed that the MOHS1 and MOHS2 fail to converge to the true PF for problem ZDT4, but the proposed SAMOHS is able to generate a true and well-distributed PF. The better performance of SAMOHS can be attributed to the fact that the self-adaptive parameter setting based on HM variance for HMCR and PAR can keep a better balance between exploration and exploitation.According to above experimental results and analysis, it can be concluded that the proposed SAMOHS outperforms the algorithms MOHS1 and MOHS2 in convergence metric and diversity metric. In addition, the performance of SAMOHS is improved greatly by using the proposed self-adaptive mechanism. These experimental results demonstrate the power and effectiveness of the proposed self-adaptive mechanism.Since heat pipe is usually applied for the satellite cooling system, the heat pipe design is extremely useful, and many studies have focused on this problem [33–35]. Geem and Hwangbo [36] have used HS algorithm to deal with this problem, but they transformed this multi-objective problem into a single objective optimization problem, which means that it needs to be run many times to acquire Pareto optimal set. In view of this, the satellite heat pipe design problem is solved by the SAMOHS, MOHS1 and MOHS2 in this paper.The heat pipe model is introduced in the literature [36]. The aim of this problem is to maximize thermal conductance and minimize total mass simultaneously. It has five design parameters, and the detailed variable ranges are presented in Table 10.The objective function of thermal conductance is to be maximized and it can be mathematically modeled as follows:(20)G=f(Lf,Lc,tf,tb,Top)=0.3745378−0.9352909*tb+1.01612*tb2+0.02324128*Lc−0.007209993*Lc2+0.001838379*Lf−0.00005379707*Lf2+0.02447391*tf+0.002304583*tf2−0.0006483411*Top−0.0000009232971*Top2−0.02259702*tb*Lc−0.004735652*tb*Lc2+0.1102442*tb2*Lc−0.009702533*tb2*Lc2+0.005382211*tb*Lf−0.00009540484*tb*Lf2+0.00515048*tb2*Lf−0.0001232524*tb2*Lf2+0.2972589*tb*tf−0.1052935*tb*tf2−0.5422262*tb2*tf−0.1829687*tb2*tf2The total mass is to be minimized and it can be represented as follows:(21)M=f(Lf,Lc,tf,tb)=(1313.877−75.5*Lc+11.0*Lc2+1.402597*Lf−(1.278314e−15)*Lf2+62.38776*tf−6.122449*tf2−380.8*tb+1120*tb2)*21For a practical problem, it demands an exact solution from the obtained Pareto optimal set. As each solution meets all objectives to some degree, the fuzzy membership approach [37] is utilized to choose a best compromise solution in this paper. Firstly, each objective function for each solution in the obtained non-dominated set is expressed by a membership function defined as follows:(22)μki=1;fk<fkminfkmax−fkfk−fkmin;fkmin<fk<fkmax0;fk>fkmaxwherefkminandfkmaxare the minimum and maximum value of kth objective function in the approximated non-dominated set, respectively; i denotes the ith solution. Secondly, the normalized membership function μifor each solution i is computed as follows:(23)μi=∑k=1Mμki∑i=1N∑k=1Mμkiwhere M denotes the number of objective functions, and N is the number of non-dominated solutions. Finally, the solution which has maximum value of μiis chosen as the best compromise solution.To test the adaptability of the SAMOHS, it uses the same parameter setting given in Section 5.2.2 except maximum function evaluation. The MOHS1 and MOHS2 also use the same parameter setting as described in Section 5.2.2 except maximum function evaluation. For fair comparison, all algorithms perform maximum function evaluation of 50,000.

@&#CONCLUSIONS@&#
