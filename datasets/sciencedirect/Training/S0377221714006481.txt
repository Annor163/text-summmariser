@&#MAIN-TITLE@&#
Exact approaches for lifetime maximization in connectivity constrained wireless multi-role sensor networks

@&#HIGHLIGHTS@&#
We address a lifetime maximization problem in wireless multi-role sensor networks.The approach is based on column generation where the pricing subproblem is difficult.We use Benders’ decomposition and constraint programming for the pricing subproblem.The computational experiments show the effectiveness of the approaches.

@&#KEYPHRASES@&#
Integer programming,Wireless sensor networks,Column generation,Constraint programming,Benders’ decomposition,

@&#ABSTRACT@&#
In this paper, we consider the duty scheduling of sensor activities in wireless sensor networks to maximize the lifetime. We address full target coverage problems contemplating sensors used for sensing data and transmit it to the base station through multi-hop communication as well as sensors used only for communication purposes. Subsets of sensors (also called covers) are generated. Those covers are able to satisfy the coverage requirements as well as the connection to the base station. Thus, maximum lifetime can be obtained by identifying the optimal covers and allocate them an operation time. The problem is solved through a column generation approach decomposed in a master problem used to allocate the optimal time interval during which covers are used and in a pricing subproblem used to identify the covers leading to maximum lifetime. Additionally, Branch-and-Cut based on Benders’ decomposition and constraint programming approaches are used to solve the pricing subproblem. The approach is tested on randomly generated instances. The computational results demonstrate the efficiency of the proposed approach to solve the maximum network lifetime problem in wireless sensor networks with up to 500 sensors.

@&#INTRODUCTION@&#
Wireless sensor networks (WSN) have undergone a growing popularity during the last decade (Arampatzis, Lygeros, & Manesis, 2005; Diamond & Ceruti, 2007; Hadjidj, Souil, Bouabdallah, Challal, & Owen, 2013; Othman & Shazali, 2012). The wide range of potential applications for sensors made them an interesting area of research (Yick, Mukherjee, & Ghosal, 2008; Zorbas & Douligeris, 2010). Data such as temperature, light, sound or pressure can be collected by sensors and then transmitted to the user through multi-hop communication. Military applications as depot monitoring or intrusion detections in remote environments, industrial applications as inventory control, environmental monitoring, health-care monitoring, among other fields are only a small sample of the fields into which WSN are used.WSN are typically composed by a large amount of sensor nodes deployed to accomplish some monitoring and communications tasks. Sensors are constrained devices with low computing capabilities that are basically composed by three components (Anastasi, Conti, Di Francesco, & Passarella, 2009): a sensing subsystem, a processing subsystem and a wireless communication subsystem. These components are coupled to guarantee that each device is able to collect information from the environment, to decide how to manage that information and how and where to transmit that information to be processed. Additionally, the power supply is obtained from a battery provided with a limited amount of energy. As a consequence, energy usage is a major concern in wireless sensor network design. In most applications, the use of wireless sensors demands the efficient design of strategies to manage their energy while keeping network operating properly.Some applications require the sensors to be located in remote or hostile environments in which sensor placement cannot be controlled. Instead, sensors are randomly deployed from a remote location and their operations cannot be planned before their deployment. Hence, the replacement of sensors batteries is not possible. Consequently, some scenarios require the operation of sensors to answer to unknown operating conditions and topologies. Then, the way in which sensors are used must be defined in situ after network topology is known.This research considers target coverage with wireless sensor networks, i.e., sensors are used to collect information from the targets located within their sensing range. In order to efficiently use sensors battery’s energy, a typical approach is to deploy more sensors than actually needed. Then, it is possible to identify subsets of sensors (covers) able to satisfy the coverage (i.e., the coverage of some or all the targets) and connectivity requirements (i.e., the information must be transmitted to a base station) (Deschinkel, 2011; Raiconi & Gentili, 2011; Rossi, Singh, & Sevaux, 2012; Zorbas, Glynos, Kotzanikolaou, & Douligeris, 2010). Hence, lifetime, defined as the total time during which the WSN is able to provide target coverage and to send sensing information to the base station, is extended by activating these subsets at different moments. Therefore, such an approach can be successfully extended to consider WSN in which sensors can adopt different roles at different energy consumption rates.A wide range of exact and heuristic approaches has been proposed to efficiently use the energy in wireless sensor networks. A complete review of approaches to efficiently use the energy on WSN is presented by Zorbas and Douligeris (2010). Efforts have been mostly focused on the design of methods to maximize network lifetime by using heuristic criteria (Deschinkel, 2011; Gentili & Raiconi, 2013) and hybrid approaches as linear programming based rounding methods (Cardei, Thai, Li, & Wu, 2005). Gu, Zhao, Ji, and Li (2011) demonstrate that the solutions for the sensors coverage and scheduling problem can be accurately represented by using pattern structures, where patterns (covers) represent the energy consumption rate of sensors during the time interval in which they are active. Exact approaches based on column generation (CG) are currently the state-of-the-art algorithms to solve coverage and scheduling problems in wireless sensor networks (Alfieri, Bianco, Brandimarte, & Chiasserini, 2007; Castaño, Rossi, Sevaux, & Velasco, 2013; Cerulli, De Donato, & Raiconi, 2012; Gu, Ji, & Zhao, 2009; Rossi et al., 2012; Singh, Rossi, & Sevaux, 2013). CG relies on covers and decomposes the problem in two subproblems. The restricted master problem (RMP) maximizes the network lifetime on a restricted set of covers, and the pricing subproblem (PS) generates new covers that may increase lifetime even further in the master problem.CG has been shown to be efficient when simple network models are considered, however addressing the subproblem becomes very challenging when network models get more complex, e.g., when connectivity is required or the adoption of different roles for sensors within the network is allowed. Hence, improvements to the classical exact methods are necessary in order to guarantee that optimal solutions are obtained.Most research on maximum network lifetime in WSN is concerned with the design of strategies to efficiently use the energy considering a homogeneous set of sensors being either active or inactive (Cardei & Cardei, 2008; Cardei et al., 2005; Gentili & Raiconi, 2013; Lu, Wu, Cardei, & Li, 2005; Raiconi & Gentili, 2011; Slijepcevic & Potkonjak, 2002). An active sensor is able to monitor all the targets that are located within its sensing range and to establish communication with other sensors, or the base station, if they are located within its communication range. A sensor is inactive if it is neither monitoring nor transmitting and it operates at negligible energy consumption rate without performing any activity within the network. In this paper we adopt a more general approach to consider wireless sensors having up to three operation modes (Zhao & Gurusamy, 2008). An active sensor is a source if it is performing monitoring and transmission tasks and is a relay if it is only used to transmit the information collected by source nodes to other sensors or to the base station. We will show that both scenarios can be tackled in a similar way since the case considering only two operation modes is a special case of the one which considers three modes.In order to solve the problem we propose an exact CG approach, where two methods are proposed for addressing the pricing subproblem. The first one used to address the pricing subproblem, also decomposes it into two, that are solved through a Branch-and-Cut approach based on Benders’ decomposition. Additionally, it is reinforced by adding some valid inequalities and connectivity cuts that help to improve the performance of this approach. The second method used to address the pricing subproblem is based on constraint programming. It uses specialized graph variables with global constraints (tree constraint, global cardinality constraint and channeling constraints) to model an underlying pricing subproblem. A specialized constraint propagation scheme guided by specific problem information is used to bring results in a quasilinear number of decisions throughout the search process.This paper is structured as follows. In Section 2 a detailed description of the maximum network lifetime problem with connectivity constraints is provided as well as the mathematical model adopted to tackle this problem. In Section 3, the solution approach based on CG adopted to solve the problem is presented. Section 4 introduces the two algorithms for addressing the pricing subproblem. In Section 5, the performances of these algorithms are measured, by incorporating them into the CG framework, and by solving the lifetime maximization problem on a large set of instances. Finally, conclusions and future work are presented in Section 6.Consider a set of sensorsS={s1,s2,…,sm}randomly deployed to monitor a set of targetsK={k1,k2,…,kn}and to transfer sensing information to the base station, denoted bys0. Each sensor is able to assume three different roles within the network. A sensor is a source node if it collects information from the targets that are located within its sensing rangeRsand transfer information to the base station or to other nodes located within its communication rangeRc. In addition to its own collected data, a source may also transfer information sent by other sensors. A sensor is a relay node if it is not sensing and is used only to re-transmit information collected by source nodes to other sensors or to the base station. Finally, a sensor that is neither collecting nor transferring information is inactive. The complete list with the notation used along the paper is summarized in Appendix A.LetG(N,A)be a directed graph whereN=S∪K∪{s0}is the set of nodes andAis the set of arcs used to indicate if communication is possible between sensor nodes or if a target is monitored by a given sensor. An arca(u,v)∈A, used to represent the possibility of transmitting information between the elements of the network, exists if:(i)u∈K,v∈Sand u is located within the sensing rangeRsofv,(ii)u,v∈Sand they are located within the communication range of each other or(iii)if the base stationv=s0is located within the communication range of a sensoru∈S.The energy consumption rate (i.e., the consumed power) of a sensor only depends upon its current role: the consumption rate of a source (respectively a relay and an inactive sensor) is denoted byEs(respectivelyErandEi). The setE={Es,Er,Ei}contains the energy consumption rates of the sensors. In generalEs>Er>Ei, but this hypothesis is not necessary here. IfEs⩽Er, the relay mode is useless and can be discarded, consequently an active sensor is always a source. The latter case has been considered by Castaño, Rossi, Sevaux, and Velasco (2013), where the use of hybrid approaches is proposed to solve the problem.LetPjbe a partition ofSinto three (non overlapping) sets: the source nodes (Ssj), the relay nodes (Srj) and the inactive nodes (Sij). We defineNjasNj=N⧹Sijand letG[Nj]denote the subgraph of G induced byNj. The partitionPjis said to be feasible if for all targetski∈K, there exists a path fromkitos0inG[Nj]. Let Ω denote the set of all feasible partitionsPj, the maximum network lifetime problem with role allocation and connectivity constraints (CMLP-MR) is to find the optimal utilization time of these partitions; so as to maximize lifetime while respecting the battery’s capacitybsvof the sensors. The case in whichEs=Eris known as connected maximum network lifetime problem (CMLP)(Castaño et al., 2013; Raiconi & Gentili, 2011).The set of binary variablesysuℓjis used to identify the structure of the partitionPj. It is used to indicate whether or not a sensorsuassumes the energy consumption profileℓ∈Ein feasible partitionPj∈Ω. In this way, a cover is defined as a vector indicating the power allocated to each particular sensor according to the partitionPj. Hence, the structure of the cover can be derived from the structure of the partition. Fig. 1presents a simple representation of the concept of partition. In Fig. 1 a potential network configuration is presented, where dotted lines indicate the possible links between the sensors (circles) and the base station (triangle) or the sensors and the targets (squares). In Fig. 1(b) and (c) two different feasible partitions ofSare represented; the solid lines indicate the connections actually established between the nodes of the network. These partitions correspond toSsj={s5,s7},Srj={s1,s3}andSij={s2,s4,s6}for Fig. 1(b) andSsj={s4,s6},Srj={s1,s2}andSij={s3,s5,s7}for Fig. 1(c). Finally, Fig. 1(d) presents an infeasible partition that cannot provide full target coverage.As previously mentioned, the objective is to maximize network lifetime by allocating an optimal time intervaltjfor each partitionPjto be used. For each sensor, a battery constraint is imposed to guarantee that the allocated time intervals respect the limited energy resources considering that sensors can operate at different energy consumption rates. Then, the implicit network configurations are represented by columns (covers) indicating at each row the energy consumption rate at which their nodes operate for each time interval along network lifetime. Assuming that the set Ω is completely known, and so the valuesysuℓj, it is possible to formulate the problem by using the following linear programming model (Model M1):Model M1: Maximum network lifetime problem(1)Maximize:∑j|Pj∈Ωtj(2)∑j|Pj∈Ω∑ℓ∈Eℓysuℓjtj⩽bsu∀su∈S(3)tj⩾0∀j|Pj∈ΩThe objective of model (1)–(3) is to maximize network lifetime (1) by using the partitionsPj∈Ω. Constraints (2) are used to guarantee that the initial amount of energybsufor each particular sensor is respected. As expected, time variablestjare continuous (3), and can be upper-bounded by taking into account initial battery level and consumption rate. However, enforcing these upper bounds is of no use for solving this problem.In Model M1, the number of columns grows exponentially with the number of sensors. Consequently, assuming that the whole set of feasible partitions is known in advance is not always realistic. Moreover, it is well known that, in the optimal solution, only part of these columns will be used for a non zero time, and the remaining will not be useful at all. Therefore, a more intelligent strategy is to generate them only if they are required and promising to extend network lifetime. In this paper the use of CG is proposed as a strategy to identify interesting partitions leading to network lifetime improvements. Considering the fact that Model M1 is a LP problem that can be easily solved with standard solvers when the number of columns is not prohibitively large, the focus is to efficiently generate those interesting connected structures, called attractive covers.In Model M1, the CG algorithm starts with a subset of coversΩ′⊆Ω. Solving M1 on that subset allows to access optimal dual variables valuesπ→={π1,π2,…πm}associated to each sensors’ battery constraint. Then, these values are used in the pricing subproblem (PS) to identify only interesting partitions leading to lifetime improvements. In other words, PS is used to gradually enlarge setΩ′with interesting covers that are added to the initial pool of columns of M1, allowing to increase the network lifetime. The reduced cost criterion is used to identify those interesting columns. If the optimal network configuration obtained by PS produces a column with positive reduced cost, which means that it has potential to extend lifetime, it is added to the setΩ′(i.e., an additional column in the Model M1) and the process starts again. Otherwise, the CG process terminates, proving that the current solution of the master problem is optimal.Any valid cover derived from partitionPjhas to cover all the targets. Consequently, in order to generate interesting covers, we devise a network flow model where each target sends one unit of flow. The coverage requirement is then satisfied by a cover if and only if the base station receives|K|units of flow. The variablesxuvare integer variables used to identify the amount of flow passing through the linka(u,v)and the binary variableysvℓjis used to identify the energy consumption profile assumed by sensorsv. Such a situation is represented by using the following mathematical model:Model M2: Pricing subproblem(4)Maximize:1-∑v∈S∑ℓ∈Eπvℓysvℓj(5)Subjectto:∑u∈S|∃a(v,u)xvu=1∀v∈K(6)∑u∈N|∃a(v,u)xvu-∑u∈N|∃a(u,v)xuv=0∀v∈S(7)∑u∈N|∃a(u,s0)xus0=|K|(8)xuv⩽|K|(ysvErj+ysvEsj)∀u,v∈S|∃a(u,v)(9)xvu⩽|K|(ysvErj+ysvEsj)∀v,u∈S|∃a(v,u)(10)xuv⩽ysvEsj∀u∈K,∀v∈S|∃a(u,v)(11)∑ℓ∈Eysvℓj=1∀v∈S(12)xuv∈Z+∪{0}∀u,v∈N(13)ysvℓj∈{0,1}∀v∈N,ℓ∈EAs previously mentioned, the objective function is to maximize the reduced cost (4). The Eqs. (5)–(7) are balance flow conservation constraints used to guarantee that flow arise only on targets (5), passes through sensor nodes without any consumption (6) and is directed to the base station which “consumes” that flow (7). Constraints (8 and 9) guarantee that links between nodes of the network are used only if the sensors operating the corresponding sensing and transmission are either sources or relays. In the same way, constraints (10) allow the existence of sensing links only if the corresponding sensor is active as a source; only one unit of information is originated in the target node. Finally, constraint (11) is used to guarantee that sensors assume exactly one of the three energy consumption profiles presented in this paper.As it will be shown, the classical implementation of CG based on state-of-the-art solvers present several drawbacks that may affect the usability of CG to solve CMLP and CMLP-MR. Instead, in this paper a Branch-and-Cut based on Benders’ decomposition (BBC) (Benders, 1962) approach, and a constraint programming approach are developed to efficiently solve PS.Consider the Model M2. If the values for the set of variablesysvℓjare predefined, and considering that no cost is associated to thexuvvariables, the problem is reduced to check whether or not each target can send one unit of flow to the base station. Then, the set of variablesysvℓjcan be considered as a set of complicating variables increasing the difficulty of the PS. If their values are known, the number of integer variables required to obtain an optimal solution for PS is largely reduced as the configuration of the network becomes easy to compute.Benders’ decomposition (Benders, 1962) is an approach for exploiting the structure of mathematical programming problems with complicating variables (Geoffrion, 1972); Benders’ decomposition has been largely used in network design problems (de Camargo, Miranda, & Luna, 2008; de Sá, de Camargo, & de Miranda, 2013; Easwaran & Üster, 2009). As in column generation, Benders’ decomposition divides a problem in two subproblems: A Benders master problem (BMP) containing only complicating variables and a Benders’ subproblem (BSP) useful to create a correct representation of the optimal solution, based on the extreme directions and extreme points of the dual problem associated to the BSP.In this paper the proposal is to use BBC in order to solve PS, i.e., to generate interesting columns for Model M1. On one hand BMP is used to allocate energy consumption rates to the sensors on the network depending on the task assigned to them in the network. On the second hand, BSP is used to check whether or not the solution found is feasible in terms of connectivity and coverage. When it is not feasible, it can be used to generate new cuts to be included in BMP and guide theysvℓjvalues to the optimal solution.Letθvddenote the dual variable values associated with flow constraints (5), andθs0dthe dual variable value associated with flow constraint (7).βuvdandηuvdare used to identify the dual variables related with constraints (8)–(10) respectively. The set of extreme rays computed iteratively through BSP is denoted byD. The Benders reformulation of Model M2 can be expressed as follows through Model M3:Model M3: Benders’ Master Problem(14)Maximize:1-ZBMP(15)Subjectto:ZBMP⩾∑v∈S∑ℓ∈Eysvℓjℓπv(16)∑u,v∈S|∃a(u,v)(ysvErj+ysvEsj)βuvd|K|+∑v,u∈S|∃a(v,u)(ysvErj+ysvEsj)βvud|K|+∑v∈Kθvd-|K|θs0d+∑v∈Kθvd-|K|θs0d+∑u∈K,v∈S|∃a(u,v)(ysvEsj)ηuvd⩾0∀d∈D(17)∑ℓ∈Eysvℓj=1∀v∈S(18)∑v∈S|∃a(u,v)ysvEsj⩾1∀u∈K(19)∑v∈S|∃a(v,s0)(ysvErj+ysvEsj)⩾1(20)∑v|∃a(u,v)(ysvErj+ysvEsj)⩾(ysuErj+ysuESj)∀u∈S|∄a(u,s0)(21)ysvℓj∈{0,1}∀v∈N,∀ℓ∈E(22)ZBMP⩾0As previously mentioned, the model above is used to identify interesting columns for Model M1 which is calculated based on the reduced cost criterion (14). The set of Benders feasibility cuts is represented by constraints (16), it consists in an exponential set of constraints that brought the information provided by the infeasible solutions found for BSP. Initially, these constraints are not included in BMP as they are added afterwards by computing Benders’ feasibility cuts.A typical solution for the pricing subproblem is highly affected by the set of variablesysvℓj. As observed in Model M2, the allocation of roles to the sensors affects network structure as well as feasibility. Consequently, it is possible to define structural inequalities, based on these variables, which are valid for the model and help to strengthen the model formulation (Saharidis, Boile, & Theofanis, 2011). The set of constraints (18) are used to enforce coverage, i.e., at least one sensor operating as a source must be active around each target. In the same way, constraint (19) indicates that at least one active sensor must be located within the communication range of the base stations0in order to transmit the collected flow to this one. Finally, the constraints (20) are used to forbid sensors operating as source or relay, that are not located within the communication range of the base stations0, to be active if they are isolated.The classical implementations of Benders’ decomposition implies that an IP problem has to be solved iteratively to prove optimality each time that a new cut is found. This might not be a problem at the beginning of the solution process, when the number of constraints is low; nonetheless, it can be quite complex when new constraints are added. Moreover, no feasible solution is obtained until the end of the solution process. To overcome this problem, we embed the generation of Benders’ feasibility cuts within a Branch-and-Cut strategy (BBC) as proposed by Errico, Crainic, Malucelli, and Nonato (2012). In this way, it is possible to take advantage of the infeasible integer solutions found to improve the solution process, and to reduce the computational time.The new cuts for BMP are generated through BSP. Considering the fact that variablesxuvmake no contribution to the objective function, the information leading to construct useful cuts is only derived from infeasible solutions for BSP, or the unbounded solution for the dual associated to BSP. The information required to compute these new cuts is obtained by computing the Farkas’ dual variables associated to BSP when it is infeasible. Then, the classical constraint, widely known as Benders’ feasibility cut as can be seen in Eq. (16), is built using this information.It is possible to construct an additional set of constraints to strengthen the BBC strategy. It is intended to avoid connected components that are not connected to the base station. As for the Benders’ feasibility cuts, these new cuts are added to Model M3 each time that an infeasible solution for BSP is found. The structure and purpose of such constraints is summarized in Lemma 1.Lemma 1Consider an infeasible partition obtained through pricing subproblem. LetC⊆Sdenote the set of connected components that do not contain the base station neither has any sensor able to communicate to this one andccia connected component in this set. Then, in order to recover feasibility, it is at least necessary for each connected componentccito establish a connection with a sensor out of it. That is, it must satisfy the following constraint:(23)∑su∈cci(ysuErj+ysuEsj)⩽|cci|∑sv∈S⧹cci|su∈cci,∃a(u,v)(ysvErj+ysvEsj)∀cci∈CConstraint(23)explicitly establishes that a connected componentccidisconnected from the base station can only operate if a neighboring sensor is activated to receive the signals coming from it. Most generally, it will obligate sensors not inccito be activated each time that an element that belongs to it is used as it is necessary to transmit the information to the base station.It is widely known that column generation can present some drawbacks that may limit its usability (Marsten, Hogan, & Blankenship, 1975; Moungla, Létocart, & Nagih, 2010; Vanderbeck, 2005). Especially in WSN networks lifetime optimization, Gu et al. (2009) demonstrated that the use of approximated criterion might be necessary to stop the CG process when a near optimal solution is detected. In CMLP and CMLP-MR the use of state-of-the-art ILP solvers to solve PS tends to generate densely populated columns, i.e., partitions with an unnecessary high number of active sensors, in those iterations in which most of the associated dual variables have a zero value. This is detrimental to CG convergence.Several factors have been identified as the causes of the slow convergence of CG and a bunch of approaches to attack this problem have been proposed when this is an effect of the degeneracy problems in the master problem (Marsten et al., 1975). However, it might not be the case in CMLP and CMLP-MR. Consequently, we propose the use of a different approach to speed up convergence. An additional constraint is used to limit the number of sensors active in a given column returned through PS and to avoid the heading-in effect observed during the first iterations. This constraint is modified dynamically throughout CG to guarantee that in the end the solution found is optimal. LetMax_Actjbe an arbitrarily selected upper bound on the maximum number of active sensors (as source or relays) in a partition, or column in the model M1. In order to avoid generate highly populated columns the following constraint can be added to Model M3:(24)∑v∈S(ysvErj+ysvEsj)⩽Max_ActjAs expected, the previous constraint may be removing feasible solutions that are potentially interesting to continue the CG process. This means that, by considering this constraint, CG may converge prematurely, perhaps in a suboptimal solution if an interesting column is cut off by constraint (24). In order to overcome this issue and to keep the method operating as an exact approach, a dynamic modification of the value ofMax_Actjis proposed (Algorithm 1). The general idea is to start CG with a reduced search space and gradually enlarge this by a factor(1+α), whereα>0, throughout the CG process. Finally, once the value ofMax_Actjreaches m, the number of sensors in the network, and assuming that no positive reduced cost columns exists, the current solution of the pricing subproblem is optimal.Algorithm 1Acceleration procedure for column generationTo solve PS a model based on CP is proposed. This section describes the structure of the model, the variables used, and the constraints involved as well as the search strategy adopted.Variables A directed graph variableT[NT,AT](Dooms, Deville, & Dupont, 2005) is introduced. It is based on the graphG(N,A), and represents the underlying solution.NTis a subset of nodes (NT⊆N) activated in the partition andATis the subset of arcs (AT⊆A) incident toNT. A mandatory set of nodesKand the base stations0directly belong to the kernel of nodes set of this graph variable.Integer domain variables vectors of size m are manipulated:(i)Succ whereD(Succu)={1,…,m}represents the index of the successor of node u (Succ is composed by two parts, successors from target nodeK, called SuccK, and successors from sensor nodesS, called SuccS),(ii)DegS and DegK whereD(DegSu)={0,…,m}andD(DegKu)={0,…,n}represent incoming degree on nodeu∈Srespectively fromSandKand(iii)Cost whereD(Costu)={0,…,πu}represent the associated dual value of node u. Finally an integer variable TotalCost sum up all these Cost variables (where variables are in upper case, as is common in constraint programming).Constraints The following CP Model M4 is proposed:Model M4: Pricing Problem in Constraint Programming(25)tree(T,1)(26)sumWeight(T,Cost,TotalCost)(27)TotalCost≤1(28)channeling(T,Succ)(29)globalCardinality(SuccS,S,DegS)(30)globalCardinality(SuccK,S,DegK)(31)DegK(u)>0⇔Cost(u)=Esπu∀u∈S(32)DegS(u)>0⇒Cost(u)⩾Erπu∀u∈S(33)DegS(u)+DegK(u)=0⇔Cost(u)=Eiπu∀u∈SEqs. (25) imply that T is constrained to be a unique tree, as described by Fages and Lorca (2011) and Unsworth Prosser and Unsworth (2006). Complexity to maintain such a constraint is referred to be enforced inO(|NT|+|AT|). Constraints (26 and 27), indicate that the overall sum of the cost associated to the nodes S, referred as TotalCost, is restricted to be lower than 1 to ensure generation of profitable columns for RMP. Only bound consistency on TotalCost is necessary and the associated scalar complexity is linear inO(|NT|).Constraints (28)–(33) are associated to the computation of the cost for a given configuration. First, Succ variables are derived from T via a standard channeling constraint (28) to maintain the domain of variable Succ equivalent to the neighbors of nodes in T, i.e.v∈D(Succu)⇔v∈e(u,v). Second, two global cardinality constraints are used to compute the occurrence number of node u inSfrom respectively their neighbors ofSandK(29 and 30), i.e., incoming degree fromSand fromK. Finally, the three remaining constraints describe the three different energy consumption conditions of a node, with associated ratesEs,ErandEi.Search Strategy. As a search implementation, we use a standard max regret strategy on Cost variables. The regret here is the difference between the smallest value (Eiπu) and the next value (Erπu) of the variables. The biggest regret (and first in enumeration) occurs for the most penalized nodes. Value assignment starts from minimum value (i.e.trying to deactivate the node). Reachability propagator inside the tree constraint ensures that the necessary connecting nodes will not be removed in the path between the targets and the base station in the final solution.Eqs. (25) and (26) could be aggregated in a single global weighted node spanning tree constraint, where propagator can be developed in the spirit of what has been done for the weighted edge spanning tree constraint (Régin, Rousseau, Rueher, & van Hoeve, 2010). A simple propagator is used because 94% of instances are solved up to proven optimality with an average complexity to find new column that is lower than the total number of nodes in the graph (i.e., the propagation automatically fixes the last nodes and very few backtracks are necessary).In order to evaluate the advantages offered by each of the proposed approaches a set of experiments is conducted to compare the performance over a set of 160 instances. The instances were randomly generated with a number of sensors in|S|={100,200,300,400,500}and a number of targets in|K|={15,30}. Sensors are assumed to be deployed in a500×500area with a fixed communication rangeRcof 125 and two different sensing rangesRs=100and 125 (Castaño et al., 2013). We assume that the energy consumption rate associated to a sensor acting as a source isEs=1.0, as a relay isEr=0.8, and inactiveEi=0for the case of CMLP-MR. By contrast, in CMLP it is assumed thatEs=Er=1.0andEi=0. In both cases it is assumed a homogeneous set of sensors with an initial charge of the battery corresponding tobsu=1.A CPU time limit of 3600second is established for the execution of the proposed approaches. The best solution found during this time is returned and used for comparison. The experiments were performed over a workstation with 6gigabite RAM DDR3 and an Intel Xeon Quad-Core W3550 processor @3.06gigahertz.Tables 1–4present the results obtained through the single application of an ILP solver to solve the pricing subproblem during CG iterations (CG+ILP), the proposed BBC strategy (CG+BBC) and the constraint programming approach (CG+CP). The columnsm,nandRsindicate respectively the number of sensors, targets and the sensing range of the instances. The column Opt/BKS∗ indicates the optimum solution – or the best known solution when it is written in bold face – for the considered group of instances. If none of the proposed approaches is able to compute the solution within the time limit, the best known solution is computed by allowing the process to continue up to 10 additional hours. In order to compare the performance of the different methods considered in this paper the best solution found (Sol), the computational time in seconds (Time), the required number of CG iterations (#Iters) and the deviation (%Dev) compared to the BKS are presented.The results obtained through the use of GC+BBC and GC+CP seem to indicate that both methods outperform CG+ILP. It is observed that CPU time and quality of the solutions found are improved through the solution approaches. According to the results observed, both CG+BBC and CG+CP approaches might be used as efficient strategies to tackle the PS derived from the CG framework adopted to solve CMLP and CMLP-MR. The experiments indicate that CG+BBC and CG+CP find 69.3% and 94.4% of the optimal solutions for the evaluated instances respectively, while only 12.5% are returned by CG+ILP. Additionally, it is observed that all the instances solved by CG+BBC are also solved by CG+CP. By restraining the analysis to the specific set of instances solved up to proven optimality by CG+BBC, it can be computed that the average CPU time consumed by this method is slightly lower than the required by CG+CP, i.e., 277.3second against 351.5 respectively. Regarding CG+BBC, the experiments indicate that the cause of a poor performance in the 33% of unsolved instances is to be sought in some particular iterations of CG. In those cases, the combined effect of the values for the dual variables and the inner characteristics of the instance leads to longer computational times. Hence, the solution process may get stuck without any improvement until time limit is reached. In the case of CG+CP it may be partially explained by a slower convergence of CG that leads to an increased number of iterations. As a consequence, the method might be unable to find the optimal solution within the time limit.As previously mentioned, by limiting the number of active sensors in a partition it is possible to decrease the number of CG iterations necessary to find an optimal solution. Fig. 2a and b depict the typical evolution of the objective function in terms of the number of iterations and CPU time, respectively, for the acceleration procedure introduced in Section 4.1. An accelerated convergence is generally obtained over the whole set of instances as a consequence of the proposed approach which produces scarcely populated columns. The latter result might indicate that the heading-in effect, which reduces the performance of CG, can be efficiently addressed by limiting the production of useless columns (that spent large amounts of energy) at the beginning of the solution process. Thus, it is possible to reduce the total CPU time required to compute the optimal solution as a consequence of the reduction of the number of iterations required to achieve the optimal solution. Nonetheless, it might come at expenses of an increase on the average CPU time required per iteration. This is a consequence of the fact that PS becomes more difficult during the first iterations of CG.According to the experimental results, the performance CG+BBC might be affected by the characteristics of the instances. As it might be expected, the CPU time required to solve the problems is related with the number of available nodes in the network. However, the impact of the increase in the sensing range seems to be bigger and leads to higher computational times, probably as an effect of the increment in the density of the graphs or the availability of sensing links to be established that may increase the computational effort required to solve PS. On the other hand, the performance of CG+CP is virtually neither affected by characteristics as the sensing or communication range, nor for the characteristics of the energy consumption in sensors (bimodal vs. multimodal). Nonetheless, an expected increase in CPU time is observed as the size of the instances gets bigger.

@&#CONCLUSIONS@&#
This paper explores the use of exact approaches in order to maximize the lifetime in wireless sensor networks operating under coverage and connectivity constraints. A CG algorithm exploiting separately a Branch-and-Cut algorithm based on Benders’ decomposition and a constraint programming approach is proposed. The former is used to take advantage of the structure of the network design problem arising in PS. The latter is levered by dual cost profile to focus on propagation on the network.An extensive set of experiments demonstrates that both algorithms outperform the results obtained through the single utilization of an ILP solver throughout iterations of the CG algorithm. The results indicate that the BBC and CP approaches can be used efficiently to tackle the pricing subproblem and to reduce the computational time required to solve CMLP-MR and CMLP. Moreover, these results are promising as they might indicate that similar approaches based on CG can be used to maximize network lifetime in WSN containing more sophisticated sensors with more capabilities than in this paper. Moreover, it indicates that CG can be used as an efficient method to guarantee the optimality of the solutions found and to provide practitioners, maybe considering distributed approaches, with an optimal upper bound to evaluate their proposals.Further research will consider specific features about strategies to improve the performance of both methods when solving the pricing subproblem and its extension to network design problems and energy usage optimization in wireless networks. Hybrid approaches combining the proposed exact methods with (meta) heuristic approaches in order to improve the efficiency of the proposed CG methods will be considered as well. Finally, the extension of the method to consider variants of the problem in which partial coverage of the targets is allowed (e.g., quality of service) and more sophisticated energy consumption models for the sensors, e.g., considering the cost of establishing a connection between nodes and targets, is a promising future research direction.