@&#MAIN-TITLE@&#
Rescheduling on identical parallel machines with machine disruptions to minimize total completion time

@&#HIGHLIGHTS@&#
Rescheduling with machine disruptions on identical parallel machines is studied.The trade-off between the disruption cost and scheduling criterion is addressed.Computational complexity status and efficient solution procedures are provided.Numerical studies are conducted to evaluate the performance of the algorithms.

@&#KEYPHRASES@&#
Combinatorial optimization,Production,Rescheduling,Bicriterion analysis,Two-dimensional fully polynomial-time approximation scheme,

@&#ABSTRACT@&#
We consider a scheduling problem where a set of jobs has already been assigned to identical parallel machines that are subject to disruptions with the objective of minimizing the total completion time. When machine disruptions occur, the affected jobs need to be rescheduled with a view to not causing excessive schedule disruption with respect to the original schedule. Schedule disruption is measured by the maximum time deviation or the total virtual tardiness, given that the completion time of any job in the original schedule can be regarded as an implied due date for the job concerned. We focus on the trade-off between the total completion time of the adjusted schedule and schedule disruption by finding the set of Pareto-optimal solutions. We show that both variants of the problem areNP-hard in the strong sense when the number of machines is considered to be part of the input, andNP-hard when the number of machines is fixed. In addition, we develop pseudo-polynomial-time solution algorithms for the two variants of the problem with a fixed number of machines, establishing that they areNP-hard in the ordinary sense. For the variant where schedule disruption is modeled as the total virtual tardiness, we also show that the case where machine disruptions occur only on one of the machines admits a two-dimensional fully polynomial-time approximation scheme. We conduct extensive numerical studies to evaluate the performance of the proposed algorithms.

@&#INTRODUCTION@&#
Most modern production and service systems operate in a dynamic environment in which unexpected disruptions may occur, necessitating changes in the planned schedule, which may render the originally feasible schedule infeasible. Examples of such disruption events include the arrival of new orders, machine breakdowns, order cancellations, changes in order priority, processing delays, and unavailability of raw materials, personnel, tools, etc. Rescheduling, which involves adjusting the original schedule to account for a disruption, is necessary in order to minimize the effects of the disruption on the performance of the system. This involves a trade-off between finding a cost-effective new schedule and avoiding excessive changes to the original schedule. The degree of disruption to the original schedule is often modeled as a constraint or part of the original scheduling objective (Hall, Liu, & Potts, 2007; Hall & Potts, 2004, 2010; Hoogeveena, Lentéb, & T’kindtb, 2012; Jain & Foley, 2016; Liu & Ro, 2014; Qi, Bard, & Yu, 2006; Unal, Uzsoy, & Kiran, 1997; Wang, Liu, Wang & Wang, 2015; Yan, Che, Cai, & Tang, 2014; Yang, 2007; Yuan & Mu, 2007). Variants of the rescheduling problem can be found in many real-world applications such as automotive manufacturing (Bean, Birge, Mittenthal, & Noon, 1991), space shuttle missions (Zweben, Davis, Daun, & Deale, 1993), shipbuilding (Clausen, Hansen, Larsen, & Larsen, 2001), short-range airline planning (Yu, Argello, Song, McCowan, & White, 2003), deregulated power market (Dahal, Al-Arfaj, & Paudyal, 2015), etc.The literature on rescheduling abounds. For recent reviews, the reader may refer to Aytug, Lawley, McKay, Mohan, and Uzsoy (2005), Billaut, Sanlaville, and Moukrim (2002), Ouelhadj and Petrovic (2009), and Vieira, Herrmann, and Lin (2003). In this paper we review only studies on machine rescheduling with unexpected disruptions arising from machine breakdowns that are directly related to our work. Leon, Wu, and Storer (1994) developed robustness measures and robust scheduling to deal with machine breakdowns and processing time variability when a right-shift repair strategy is used. Robustness is defined as the minimization of the bicriterion objective function comprising the expected makespan and expected delay, where the expected delay is the deviation between the deterministic makespan in the original and adjusted schedules. Their experimental results showed that robust schedules significantly outperform schedules based on the makespan alone. Ozlen and Azizoğlu (2011) considered a rescheduling problem on unrelated parallel machines, where a disruption occurs on one of the machines. The scheduling measure is the total completion time and the deviation cost, which is the total disruption caused by the differences between the original and adjusted schedules. They developed polynomial-time algorithms to solve the following hierarchical optimization problems: minimizing the total disruption cost among the minimum total completion time schedules and minimizing the total completion time among the minimum total disruption cost schedules. Qi et al. (2006) considered a rescheduling problem in the presence of a machine breakdown in both the single-machine and two parallel-machine settings with the objective of minimizing the total completion time plus different measures of time disruption. They provided polynomial-time algorithms and pseudo-polynomial-time algorithms for the problems under consideration. Zhao and Tang (2010) extended some of their results to the case with linear deteriorating jobs. Liu and Ro (2014) considered a rescheduling problem with machine unavailability on a single machine, where disruption is measured as the maximum time deviation between the original and adjusted schedules. Studying a general model where the maximum time disruption appears both as a constraint and as part of the scheduling objective, they provided a pseudo-polynomial-time algorithm, a constant factor approximation algorithm, and a fully polynomial-time approximation scheme when the scheduling objective is to minimize the makespan or maximum lateness.In this paper we address the issue of how to reschedule jobs in the presence of machine breakdowns. We assume that a set of jobs has been optimally scheduled according to the shortest processing time (SPT) rule to minimize the total completion time on m identical parallel machines (Baker, 1974). However, the processing of most of the jobs has not begun. This situation arises when schedules are planned in advance of their start dates, typically several weeks earlier in practice. Based on the SPT schedule, a lot of preparation work has been made, such as ordering raw materials, tooling the equipment, organizing the workforce, fixing customer delivery dates, etc. Due to unforeseen disruptions, different from the setting in Ozlen and Azizoğlu (2011), we consider the situation where machine breakdowns may occur on more than one machine, and the disruption start time and the duration of a machine disruption may differ on different machines. This necessitates rescheduling the remaining jobs in the original SPT schedule. However, doing so will disrupt the SPT schedule, causing havoc on the preparative work already undertaken. Thus, on rescheduling, it is important to adhere to the original scheduling objective, say, the total completion time, while minimizing the disruption cost with respect to the SPT schedule. In this paper we use the maximum time deviation or the total virtual tardiness, where the completion time of a job in the SPT schedule can be regarded as an implied due date for the job concerned here, to model the disruption cost with respect to the SPT schedule. Instead of modeling the degree of disruption over the original schedule as a constraint or part of the scheduling objective, we focus on the trade-off between the total completion time of the adjusted schedule and schedule disruption by finding the set of Pareto-optimal solutions for this bicriterion scheduling problem. The purpose of this paper is twofold. One is to study this innovative and more realistic scheduling model. The other is to ascertain the computational complexity status and provide solution procedures, if viable, for the problems under consideration.To motivate our scheduling problem, consider a practical example related to the manufacturing of containers. In this context, the manufacturing process is labor intensive and several machines are deployed to manufacture a host of various container types. The preparation for the manufacturing of each type of containers incurs a high operational cost. The factory takes customer orders during the current scheduling cycle (usually a month) and generates an optimal production schedule for the next period that minimizes the scheduling cost measured as the total flowtime for manufacturing all the ordered containers. In other words, the factory uses the SPT dispatching rule to schedule the manufacturing of the containers. The delivery times and related transport arrangements of the finished containers are then determined accordingly. However, unexpected disruptions such as machine breakdowns may occur that will render the machines unavailable for certain periods of time, which will affect the utilization of the machines and order delivery to customers. This will result in the original SPT schedule no longer optimal, wreak havoc on the preparative work already undertaken, and make an impact on the subsequent transport arrangements. Hence, it is important to react quickly to such disruptions whereby the affected jobs need to be rescheduled with a view to reducing the scheduling cost, while not causing excessive schedule disruption with respect to the original SPT schedule (excessive schedule disruption will increase the operational cost or result in the loss of customer goodwill). From the viewpoint of the production planner, a trade-off between the scheduling cost and deviation from the original SPT schedule is desired. This situation can be modeled as our problem of rescheduling on identical parallel machines with machine disruptions to minimize the total completion time.The rest of the paper is organized as follows: In Section 2 we formally formulate our problem into two variants. In Section 3 we analyze the computational complexity and derive structural properties that are useful for tackling the two variants of the problem under study. In Section 4 we develop a pseudo-polynomial-time dynamic programming solution algorithm for the variant with the maximum time deviation as the schedule disruption cost and a fixed number of machines, establishing that it isNP-hard in the ordinary sense. In Section 5 we also develop a pseudo-polynomial-time dynamic programming solution algorithm for the variant with the total virtual tardiness as the schedule disruption cost and a fixed number of machines, establishing that it isNP-hard in the ordinary sense, and convert the algorithm into a two-dimensional fully polynomial-time approximation scheme for the case where machine disruptions occur only on one of the machines. In the last section we conclude the paper and suggest topics for future research.There are n jobs in the job setJ={1,2,…,n}to be processed without interruption on m identical parallel machines{M1,…,Mm},which can deal with only one job at a time. All the jobs are available for processing at time zero. Each job j has a processing requirement of length pj. We assume that the jobs have been sequenced in an optimal schedule that minimizes the total completion time. It is well known that the jobs should be scheduled in the SPT order with no idle time between them for this purpose, whereby the jobs are sequenced successively on the m machines, i.e., jobsi,m+i,…,m⌊n/m⌋+iare successively scheduled on machine i without any idle time,i=1,…,m,where ⌊x⌋ denotes the largest integer less than or equal to x. Let π* denote the sequence in which the jobs are scheduled in this SPT order. Hereafter, we assume that all the pjare known non-negative integers and the jobs are sequenced in the SPT order such that p1 ≤ ⋅⋅⋅ ≤ pn, and denote by CSthe makespan of the SPT schedule. Letpmin=minj=1,…,n{pj},pmax=maxj=1,…,n{pj},andP=∑j=1npj.Each machine Mi,i=1,…,m,may have an unavailable time interval [Bi, Fi] resulting from a machine breakdown with0≤Fi−Bi≤Dand Bi≥ 0, and at least one of the inequalitiesB1≤F1,B2≤F2,…,Bm≤Fmis strict, where D denotes an upper limit on the durations of machine disruptions on each machine, which can be estimated based on past experience. We assume, without loss of generality, that Bi< Fifori=1,…,m1,andBi=+∞fori=m1+1,…,mfor some positive integer m1, which models the case where machine disruptions occur only on the first m1 machines. LetBmax=maxi=1,⋯,m1{Bi}andFmax=maxi=1,…,m1{Fi}. It is clear thatFmax≤Bmax+D. During job processing, machine disruptions occur so that the original SPT schedule is no longer optimal, or worse, no longer feasible. As a consequence, we wish to reschedule all the uncompleted jobs in response to the disruptions. We assume that Biand Fi,i=1,…,m,are known at time zero, prior to processing but after scheduling the jobs of J, and focus on the non-resumable case with the following assumption: If Biand Fi,i=1,…,mare all known after time zero, then the jobs of J having already been processed are removed from the problem, while the partially processed jobs, at most one on each machine, can either be processed to completion and removed, or processing can be halted immediately and started again from the beginning at a later time, with J and n updated accordingly. In this case, we reset the time index such that machine Mi,i=1,…,m,is available from τionwards with at least one of the τi’s equal to 0. Here, τican be regarded as the release time of machine Mi,i=1,…,m.For any feasible schedule ρ of the jobs of J, we define the following variables for j ∈ J:Cj(ρ): the completion time of job j,Tj(ρ)=max{Cj(ρ)−Cj(π*),0}: the virtual tardiness of job j, where Cj(π*) can be viewed as a special type of due date, called the virtual due date of job j, andΔj(ρ)=|Cj(ρ)−Cj(π*)|: the time disruption of job j.Without ambiguity, we will drop ρ in our notation and just write Cj, Tj, and Δjfor short. Furthermore, letΔmax=maxj∈JΔjbe the maximum time disruption of the jobs.The quality of a schedule ρ is measured by two criteria. The first is the original scheduling objective, i.e., the total completion time, and the second is a measure of the schedule disruption cost in terms of the maximum time deviation or the total virtual tardiness with respect to the original SPT schedule.As for all bicriterion optimization problems, we need to establish a relationship or tradeoff between the two criteria in the objective function. In this paper we focus on the Pareto-optimization problem: Given the two criteriav1=∑Cjandv2=Δmaxor=∑Tj,determine the set of all Pareto-optimal solutions (v1, v2), where a schedule ρ withv1=v1(ρ)andv2=v2(ρ)is called Pareto optimal (or efficient) if there does not exist another schedule ρ′ such that v1(ρ′) ≤ v1(ρ) and v2(ρ′) ≤ v2(ρ) with at least one of these inequalities being strict.Graham, Lawler, Lenstra, and Rinnooy Kan (1979) introduced the three-field notation α|β|γ for describing scheduling problems. For the first field α, we useα=Px,hm11to denote that there are m identical parallel machines, where x is empty when m is considered to be part of the input andx=mwhen m is fixed, and that there is a single unavailable time interval on the first m1 machines. For the second field β, we useτ=(τ1,…,tm)to denote the release time vector of the m machines, andβ=[Bi,Fi]1≤i≤m1to represent that machine disruptions occur only on the first m machines and the unavailable time interval on machine Miis [Bi, Fi],i=1,…,m1,while in the γ field, we use (v1, v2) to indicate a Pareto-optimization problem with two criteria v1 and v2. In our models,v1=∑Cjand v2 ∈ {Δmax , ∑Tj}. Specifically, we address the problemsPx,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,Δmax)andPx,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,∑Tj),where x is empty orx=m.In this section we address the computational complexity issues of the considered problems and derive several structural properties of the optimal schedules that will be used later in the design of solution algorithms for the problems.We first show that both problemsP,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,Δmax)andP,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj, ∑Tj) areNP-hard in the strong sense.3-PARTITION: Given an integer E, a finite set A of 3r positive integers aj,j=1,…,3r,such that E/4 < aj< 2/E,∀j=1,…,3r,and∑j=13raj=rE,can the setI={1,…,3r}be partitioned into r disjoint subsetsI1,…,Irsuch that∑j∈Ihaj=Eforh=1,…,r?Theorem 3.1The problemP,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,Δmax)isNP-hard in the strong sense.We establish the proof by making a reduction from 3-PARTITION to the problemP,hm11|τ,[Bi,Fi]1≤i≤m1|∑Cj≤ QA, Δmax  ≤ QB. Given an instance of 3-PARTITION, construct an instance of the scheduling problem as follows:•The number of jobs:n=3r;The number of machines:m=r;The number of disrupted machines:m1=r;Job processing times:pj=aj,j=1,…,3r;The release times of the machines:τi=0,j=1,…,r;The disruption start times:Bi=E,j=1,…,r;The disruption finish times:Fi=(3r+2)E,j=1,…,r;The threshold value for ∑Cj:QA=3rE;The threshold value for Δmax :QB=(6r+2)E.Analogous to the proof of Theorem 2 in Levin, Mosheiov, and Sarig (2009), it is easy to see that there is a solution to the 3-PARTITION instance if and only if there is a feasible schedule for the constructed instance of the problemP,hm11|τ,[Bi,Fi]1≤i≤m1|∑Cj≤ QA, Δmax  ≤ QB.□In a similar way, we can establish the following result.Theorem 3.2The problemP,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,∑Tj)isNP-hard in the strong sense.As a result of Theorems 3.1 and 3.2, we focus only on the case with a fixed number of machines m in the sequel. Note that even the single-machine case with a known future machine unavailability, denoted as1,h1∥∑j=1nCj,isNP-hard (Adiri, Bruno, Frostig, & RinnooyKan, 1989). Hence both of our problemsPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax)andPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj)areNP-hard, too, which have been further shown to beNP-hard in the ordinary sense by developing pseudo-polynomial-time algorithms for them in the subsequent sections.The following lemma provides an easy-to-prove property of the original SPT schedule for the problem Pm||∑Cj.Lemma 3.3For any two jobs j and k in the original SPT schedule π*for the problemPm∥∑j=1nCj,j < k impliesCj(π*)−pj≤Ck(π*)−pk.After rescheduling, we refer to the partial schedule of jobs finished no later than Bion machine Mi,i=1,…,m1,as the earlier schedule on machine Mi; the partial schedule of jobs in the earlier schedules on all the machine Mi,i=1,…,m1,as the earlier schedule; and the partial schedule of jobs that begin their processing at time Fior later on machine Mi,i=1,…,m1,and that are processed on machine Mi,i=m1+1,…,m,as the later schedule. The next result establishes the order of the jobs in the earlier schedule on each machine Mi,i=1,…,m1,and the order of the jobs in the later schedule.Lemma 3.4For each of the problemsPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax)andPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj),there exists an optimal schedule ρ*in which(1)the jobs in the earlier schedule on each machine Mi,i=1,…,m1,follow the SPT order; andthe jobs in the later schedule follow the SPT order.(1) Consider first the earlier schedule in ρ* on any machine Mi,i=1,2,…,m1. If property (1) does not hold, let k and j be the first pair of jobs for which j precedes k in π*, implying that pj≤ pk, but k immediately precedes j in ρ* on machine Mi. Constructing a new schedule ρ′ from ρ* by swapping jobs k and j while leaving the other jobs unchanged. Furthermore, let t denote the processing start time of job k in schedule ρ*. Then we haveCk(ρ*)=t+pk≥t+pj=Cj(ρ′)andCj(ρ*)=Ck(ρ′)=t+pj+pk. Hence,Cj(ρ′)+Ck(ρ′)=2t+2pj+pk≤2t+pj+2pk=Ck(ρ*)+Cj(ρ*),making∑j=1nCj(ρ′)≤∑j=1nCj(ρ*). To show that ρ′ is no worse than ρ*, it suffices to show that Δmax (ρ*) ≥ Δmax (ρ′) for the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,Δmax)and ∑Ti(ρ*) ≥ ∑Ti(ρ′) for the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑Cj,∑Tj). Indeed, by Lemma 3.3, pj≤ pkimplies that Cj(π*) ≤ Ck(π*). Thus, it follows from the proof of Lemma 1 in Liu and Ro (2014) that Δmax (ρ*) ≥ Δmax (ρ′) and from Emmons (1969) that ∑Ti(ρ*) ≥ ∑Ti(ρ′). Repeating this argument a finite number of times establishes property (1).(2) Denote by I the set of jobs in the later schedule with|I|=n′. Re-index the jobs in I as1′,2′,…,n′such thatp1′≤p2′≤⋯≤pn′. In what follows, we show that it is optimal to sequence the jobs in I in SPT order. To achieve this, it suffices to show that there exists an optimal schedule in which job n′ among the jobs in I has the latest processing start time. If this is the case, then the problem can be decomposed into a problem of scheduling the firstn′−1jobs on machine Miafter Fi,i=1,…,m1,and on machine Mi,i=m1+1,…,m,and then inserting job n′ at the earliest possible time when any one of the machines becomes available. Similarly, the problem with the firstn′−1jobs can be further decomposed into a problem with the firstn′−2jobs and scheduling jobn′−1,and so on. Thus property (2) follows.Since job n′ has the largest processing time among the jobs in the set I, analogous to the proof of property (1), we can show that it must be the last job on machineMi1to which it was assigned. Now suppose that there exists an optimal schedule ρ* in which there is a job j′, other than job n′, assigned to a different machineMi2but with a later processing start time than that of job n′. Let t1 be the processing start time of job n′ on machineMi1and t2 be the processing start time of job j′ on machineMi2with t1 < t2. We construct a new schedule ρ′ by letting job j′ start its processing at t1 on machineMi1and job n′ start its processing at t2 on machineMi2,while leaving the other jobs unchanged. Such an exchange makes job j′ start earlier byt2−t1and job n′ start later byt2−t1. The total completion time, however, does not change. Now we show that ρ′ is no worse than ρ*. There are two cases to consider.Case 1:  Job j′ is early in ρ′, i.e.,t1+pj′≤Cj′(π*). It follows fromt1≤Cj′(π*)−pj′≤Cn′(π*)−pn′that job n′ is early in ρ*. Hence,Δj′(ρ′)=Cj′(π*)−pj′−t1,Δn′(ρ*)=Cn′(π*)−pn′−t1,Tj′(ρ′)=Tn′(ρ*)=0.Furthermore, if job n′ is tardy in ρ′, i.e.,t2+pn′≥Cn′(π*). It follows fromt2≥Cn′(π*)−pn′≥Cj′(π*)−pj′that job j′ is also late in ρ*. Hence,Δn′(ρ′)=Tn′(ρ′)=t2+pn′−Cn′(π*),Δj′(ρ*)=Tj′(ρ*)=t2+pj′−Cj′(π*).Thus, it follows fromCj′(π*)−pj′≤Cn′(π*)−pn′thatΔj′(ρ′)≤Δn′(ρ*),Δn′(ρ′)≤Δj′(ρ*)andTn′(ρ′)+Tj′(ρ′)=Tn′(ρ′)≤Tj′(ρ*)=Tj′(ρ*)+Tn′(ρ*).If job n′ is early in ρ′, i.e.,t2+pn′≤Cn′(π*),we haveΔn′(ρ′)=Cn′(π*)−pn′−t2,Tn′(ρ′)=0,Δj′(ρ*)=|t2+pj′−Cj′(π*)|,Tj′(ρ*)=max{t2+pj′−Cj′(π*),0}.Thus, it follows fromCj′(π*)−pj′≤Cn′(π*)−pn′and t1 < t2 thatΔj′(ρ′)≤Δn′(ρ*),Δn′(ρ′)≤Δn′(ρ*)andTn′(ρ′)+Tj′(ρ′)=0≤Tj′(ρ*)+Tn′(ρ*).Case 2:  Job j′ is tardy in ρ′, i.e.,t1+pj′≥Cj′(π*). It follows from t1 < t2 that job j′ is also tardy in ρ*. Hence,Δj′(ρ′)=Tj′(ρ′)=t1+pj′−Cj′(π*),Δj′(ρ*)=Tj′(ρ*)=t2+pj′−Cj′(π*).Furthermore, if job n′ is tardy in ρ′, i.e.,t2+pn′≥Cn′(π*),we haveΔn′(ρ′)=Tn′(ρ′)=t2+pn′−Cn′(π*),Δn′(ρ*)=|t1+pn′−Cn′(π*)|,Tn′(ρ*)=max{t1+pn′−Cn′(π*),0}.Thus, it follows fromCj′(π*)−pj′≤Cn′(π*)−pn′and t1 < t2 thatΔj′(ρ′)≤Δj′(ρ*),Δn′(ρ′)≤Δj′(ρ*)and thatTn′(ρ′)+Tj′(ρ′)≤Tj′(ρ*)+Tn′(ρ*).If job n′ is early in ρ′, i.e.,t2+pn′≤Cn′(π*),it follows from t1 < t2 that n′ is also early in ρ*. HenceΔn′(ρ′)=Cn′(π*)−pn′−t2,Δn′(ρ*)=Cn′(π*)−pn′−t1,Tn′(ρ′)=Tn′(ρ*)=0.Thus, it follows fromCj′(π*)−pj′≤Cn′(π*)−pn′thatΔn′(ρ′)≤Δn′(ρ*),Tn′(ρ′)+Tj′(ρ′)=Δj′(ρ′)≤Δj′(ρ*)=Tj′(ρ*)+Tn′(ρ*).Thus, in any case, schedule ρ′ is no worse than ρ* for the two problems under consideration. The result follows.□It is worth noting that scheduling the jobs in the earlier schedule in SPT order, each as early as possible, is not necessarily optimal even for the case without the schedule disruption cost. This is because such rescheduling may waste a long period of machine idle time immediately preceding the start time of each machine disruption, which we illustrate in the following example.Example 3.5Letn=3,m=2;p1=2,p2=3,p3=4;τ1=τ2=0;B1=B2=5;andF1=F2=6. If the jobs are scheduled in the same sequence as π*, each as early as possible, then jobs 1 and 3 are scheduled in the intervals [0, 2] and [6, 10], respectively, on machine M1, while job 2 is scheduled in the interval [0, 3] on machine M2, yielding an objective value of 15. In an optimal schedule, however, jobs 1 and 2 are scheduled in the intervals [0, 2] and [2, 5], respectively, on machine M1, while job 3 is scheduled in the interval [0, 4] on machine M2, yielding an objective value of 11.In this section we consider the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax). We first develop a pseudo-polynomial-time dynamic programming (DP) algorithm to solve it, followed by an experimental study to evaluate the effectiveness of the DP-based solution algorithm.We start with providing an auxiliary result.Lemma 4.1For the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax),the maximum time disruption Δmaxis upper-bounded bymax{min{Bmax,P}+D,CS−pmin}.It suffices to show that Δmax (ρ*) is less thanmax{min{Bmax,P}+D,CS−pmin},where ρ* is an optimal schedule for the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|∑j=1nCjthat satisfies Lemma 3.4. We first consider the jobs with Cj(ρ*) > Cj(π*). IfCj(ρ*)≤min{Bmax,P}+D,thenΔj≤min{Bmax,P}+D; otherwise, Lemma 3.4 indicates that all the jobs completed after timemin{Bmax,P}+Dand before job j in ρ* are processed before job j in π*, soΔj≤min{Bmax,P}+D. Alternatively, when Cj(ρ*) ≤ Cj(π*), we haveΔj≤CS−pminsince CSis the maximum completion time of the jobs in π*. Thus,Δmax(ρ*)≤max{min{Bmax,P}+D,CS−pmin}.Our DP-based solution algorithm STDP for the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax)relies strongly on Lemmas 3.4 and 4.1. Note that after rescheduling, a job in the earlier schedule might be completed earlier than in π*. In this case, as Δmax  is defined asmaxj∈J|Cj−Cj(π*)|,the job might be immediately preceded by an idle time period. Thus, we design algorithm STDP on the basis of solving a series of the constrained optimization problemPm,hm11|τ,[Bi,Fi]1≤i≤m1,Δmax≤Q|∑j=1nCjwith0≤Q≤max{min{Bmax,P}+D,CS−pmin}. The constraint Δmax  ≤ Q implies that, in a feasible schedule ρ,Cj(ρ)≥Cj(π*)−QandCj(ρ)≤Cj(π*)+Q,forj=1,…,n. Accordingly, each job j has an implied release timerjQ=Cj(π*)−pj−Qand an implied deadlined¯jQ=Cj(π*)+Q.Let(j,B,F,T,v)Qbe a state corresponding to a partial schedule for the jobs{1,…,j}such that the maximum time deviation is less than Q, where•B=(t1′,t2′,…,tm1′):tk′,k=1,…,m1,denotes the completion time of the last job scheduled before Bkon machine Mk;F=(t1,t2,…,tm1): tk,k=1,…,m1,stands for the total processing time of the jobs scheduled after Fkon machine Mk;T=(tm1+1,tm1+2,…,tm):tm1+k,k=1,…,m−m1,measures the completion time of the last job scheduled on machine Mk;v: the total completion time of the partial schedule.Algorithm STDP follows the framework of forward recursive state generation and starts with the empty state in which no job has been scheduled yet, i.e.,j=0. The setSjQcontains the states for all the generated sub-schedules for jobs{1,…,j}. The algorithm recursively generates the states for the partial schedules by adding a job to a previous state. Naturally, the construction ofSjQmay generate more than a single state that will not lead to a complete optimal schedule. The following result shows how to reduce the state setSjQ.□For any two states(j,B,F,T,v)Qand(j,B′=(t1′′,…,tm1′′),F′=(t1′,…,tm1′),T′=(tm1+1′,…,tm′),v′)inSjQ,iftk′≤tk′′fork=1,…,m1,tk≤tk′fork=1,…,m,and v ≤ v′, we can eliminate the latter state.Let S1 and S2 be two sub-schedules corresponding to the states(j,B,F,T,v)Qand(j,B′,F′,T′,v′)Q,respectively. And letS˜2be a sub-schedule of the jobs{j+1,…,n}that is appended to the sub-schedule S2 so as to create a feasible scheduleS^2. In the resulting feasible scheduleS^2,the total completion time is given as follows:∑Cj(S^2)=v′+∑k=j+1nCk(S˜2).Sincetk′≤tk′′fork=1,…,m1andtk≤tk′fork=1,…,m,set{j+1,…,n}can also be added to the sub-schedule S1 in an analogous way asS˜2,denoting the resulting sub-schedule asS˜1,to form a feasible scheduleS^1,and we haveCk(S˜1)≤Ck(S˜2)fork=j+1,…,n. In the resulting feasible scheduleS^1,the total completion time is given as follows:∑Cj(S^1)=v+∑k=j+1nCk(S˜1).It follows from v ≤ v′ that∑Cj(S^1)≤∑Cj(S^2). Therefore, sub-schedule S1 dominates S2, so the result follows.□We provide a formal description of algorithm SMDP as follows:Sum-Max-DP AlgorithmSMDPStep 1. [Preprocessing] Re-index the jobs in SPT order.Step 2. [Initialization] For eachj=1,…,n,seti=j−m⌊j/m⌋andCj(π*)=∑k=i,m+i,…,m⌊j/m⌋+ipk;for eachQ∈[0,max{min{Bmax,P}+D,CS−pmin}],setS0Q={(0,B,F,T,0)Q},whereB=(τ1,…,τm1),F=(0,…,0︸m1)andT=(τm1+1,…,τm),and setrjQ=Cj(π*)−pj−Qandd¯jQ=Cj(π*)+Q.Step 3. [Generation] GenerateSjQfromSj−1Q.For eachQ∈[0,max{min{Bmax,P}+D,CS−pmin}]doForj=1to n doSetSjQ=∅;For each(j−1,B,F,T,v)Q∈Sj−1QdoSett=min{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk}andk*=argmin{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk};Fori=1to m1 do/*Alternative 1: schedule job j before Bi:Ifmax{ti′,rjQ}+pj≤min{d¯jQ,Bi},thensetSjQ←SjQ∪{(j,B′,F,T,v+max{ti′,rjQ}+pj)Q},whereB′=(t1′,…,t(i−1)′,max{ti′,rjQ}+pj,t(i+1)′,…,tm1′);EndifEndfor/*Alternative 2: assign job j to the later schedule:Ift+pj≤djQ,thensetSjQ←SjQ∪{(j,B,F′,T′,v+t+pj)Q},whereF′=(t1,…,tk*−1,t+pj−Fk*,tk*+1,…,tm1)andT′=Tif 1 ≤ k* ≤m1, otherwiseF′=FandT′=(tm1+1,…,tk*−1,t+pj,tk*+1,…,tm);EndifEndforEndfor[Elimination] /* Update setSjQ*/1.For any two states(j,B,F,T,v)Qand(j,B,F,T,v′)Qwith v ≤ v′, eliminate the latter state from setSjQ;For any two states(j,B=(t1′,…,t(i−1)′,ti′,t(i+1)′,…,tm1′),F,T,v)Qand(j,B=(t1′,…,t(i−1)′,ti′′,t(i+1)′,…,tm1′),F,T,v)Qwithti′≤ti′′,eliminate the latter state from setSjQ;For any two states(j,B,F=(t1,…,ti−1,ti,ti+1,…,tm1),T,v)Qand(j,B,F=(t1,…,ti−1,ti′,ti+1,…,tm1),T,v)Qwithti≤ti′,eliminate the latter state from setSjQ;For any two states(j,B,F,T=(tm1+1,…,tk−1,tk,tk+1,…,tm),v)Qand(j,B,F,T=(tm1+1,…,tk−1,tk′,tk+1,…,tm),v)Qwithtk≤tk′,eliminate the latter state from setSjQ;EndforStep 4. [Return all the Pareto-optimal points]SetQ¯=max{min{Bmax,P}+D,CS−pmin}andi=1;WhileSnQ¯≠∅doSelect(Vi,Qi)=(v,Q)that corresponds to the state(n,B,F,T,v)Qwith the minimum v value among all the states inSnQsuch thatQ≤Q¯as a Pareto-optimal point; SetQ¯=Qi−1andi=i+1;End whileReturn(V1,Q1),…,(Vi−1,Qi−1)and the corresponding Pareto-optimal schedules canbe found by backtracking.Justification for algorithm SMDP.After the [Preprocessing] procedure, for eachQ∈[0,max{min{Bmax,P}+D,CS−pmin}],the algorithm goes through n phases. The jth phase,j=1,…,n,takes care of job j and produces a setSjQ. Suppose that the state setSj−1Qhas been constructed and we try to assign job j now. Due to Lemma 3.4, it is optimal to assign j either to the last position of any machine Mi,i=1,…,m1,that is finished no later than Bi, or to the later schedule on some machine Mi,i=1,…,m,at the earliest possible time when the machine becomes available. Note that after rescheduling, a job might be completed earlier than in π*. In this case, due to the maximum time deviation constraint, the job might be immediately preceded by an idle time period. Thus, if job j is assigned to the last position of machine Mi,i=1,…,m1,that is finished no later than Bi, its processing start time ismax{ti′,rjQ},whereti′>rjQ,i.e.,ti′+pj−Cj(π*)>−Q,implying that job j has a time deviation strictly less than Q, whileti′≤rjQimplies that there may be an idle time immediately preceding job j and that job j has a time deviation of Q time units, and thatmax{ti′,rjQ}+pj≤min{d¯jQ,Bi},which guarantees that job j has a time deviation no more than Q and can be completed before Bi. In this case, we updateti′asmax{ti′,rjQ}+pjand the contribution of job j to the scheduling objective ismax{ti′,rjQ}+pj,sov′=v+max{ti′,rjQ}+pj. If job j is assigned to the later schedule on some machine Mi, we havei=k*by Lemma 3.4 and its processing start time is t, where the conditiont+pj≤djQguarantees that job j has a time deviation less than Q. In this case, the contribution of job j to the scheduling objective ist+pj,sov′=v+t+pj. Naturally, the construction process ofSjQmay generate more than a single state(j,B,F,T,v)Qwith the sameB,F,andT. Among all these states, by the elimination rule 1 in algorithm SMDP, we keep inSjQonly the state with the minimum v value to ensure the finding of the minimum objective value. By Lemma 4.2, the elimination rules 2–4 in algorithm SMDP can also be used to eliminate the non-dominated states. It is easy to see that for eachQ¯∈[0,max{min{Bmax,P}+D,P−pmin}],an efficient solution is given by the pair(V,Q)=(v,Q),which corresponds to the state(n,B,F,T,v)Qwith the minimum v value among all the states inSnQsuch thatQ≤Q¯.Theorem 4.3Algorithm SMDP solves the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,Δmax)in O(nmax {min{min{Bmax,P}+D,CS−pmin}Pm∏i=1m1Bi)time.The optimality of algorithm SMDP is guaranteed by Lemmas 3.4, 4.1 and 4.2, and the above analysis. We now work out the time complexity of the algorithm. Step 1 implements a sorting procedure that needs O(nlog n) time. In Step 3, for each Q, before each iteration j, the total number of possible states(j−1,B,F,T,v)Q∈Sj−1Qcan be calculated in the following way: there are at most Bipossible values forti′,i=1,…,m1,and at most P possible values for ti,i=1,…,m. Because of the elimination rule, the total number of different states at the beginning of each iteration is at mostO(Pm∏i=1m1Bi). In each iteration j, there are at mostm1+1new states generated from each state inSj−1Qfor each candidate job. Thus, the number of new states generated is at most(m1+1)O(Pm∏i=1m1Bi). However, due to the elimination rules, the number of new states generated inSjQis upper-bounded byO(Pm∏i=1m1Bi)after the elimination step. Thus, afternmax{min{Bmax,P}+D,CS−pmin}iterations, Step 3 can be executed inO(nmax{min{Bmax,P}+D,CS−pmin}Pm∏i=1m1Bi)time, as required. Step 4 takesO(max{min{Bmax,P}+D,CS−pmin}Pm∏i=1m1Bi)time. Therefore, the overall time complexity of the algorithm isO(nmax{min{Bmax,P}+D,CS−pmin}Pm∏i=1m1Bi).□The proof of Theorem 4.3 also implies that the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1,Δmax≤Q|∑j=1nCjcan be solved inO(nPm∏i=1m1Bi)time. In particular, whenm=m1=1,the corresponding problem, denoted as 1, h1|Δmax  ≤ Q|∑Cj, can be solved in O(nPB1) time. In what follows, we develop an alternative algorithm for the problem 1, h1|Δmax  ≤ Q|∑Cjby exploiting the following stronger results on the optimal schedule, the proofs of which are analogous to those of Lemmas 2 and 3 in Liu and Ro (2014), respectively.Lemma 4.4For the problem 1, h1|Δmax  ≤ Q|∑Cj, there exists an optimal schedule ρ*in which:(1)the jobs in the earlier schedule are processed with at most one inserted idle time period;each job processed in the earlier schedule after an inserted idle time period starts processing exactly at its induced release time;the jobs processed in the earlier schedule after an inserted idle time period are processed consecutively in π*.For the problem 1, h1|Δmax  ≤ Q|∑Cj, there exists an optimal schedule ρ*in which if a job is immediately preceded by an idle time period in the earlier schedule, then in π*the job has a start time later than F1.Combining Lemmas 3.4, 4.4, and 4.5, we can apply algorithm ML in Liu and Ro (2014) with a slight modification to solve the problem 1, h1|Δmax  ≤ Q|∑Cj. As a result, the problem 1, h1|Δmax  ≤ Q|∑Cjcan also be solved in O(n2B1Q) time (see Theorem 2 in Liu & Ro, 2014).We performed numerical studies by varying the problem size to assess the performance of algorithm SMDP. We coded the algorithm in Java and conducted the experiments on a Dell OptiPlex 7010 with a 3.40 gigahertz, 4 gigabyte memory Intel core i5-3570 CPU. For simplicity, we only studied the two-machine case withm1=1. The number of jobs considered was n ∈ {10, 15, 20, 25}. For each value of n, we randomly generated 30 instances for each combination of the specifications for the two parameters B1 andD=F1−B1. Randomly generating the job processing times pjfrom the uniform distribution (1, 20), we considered the case where B1 ∈ {⌊P/8⌋, ⌊P/6⌋, ⌊P/4⌋}, andD∈{⌊P/80⌋,⌊P/50⌋,⌊P/30⌋}. For each value of n, we recorded the average number of Pareto-optimal points, the maximum number of Pareto-optimal points, and the average time required to construct the entire Pareto set for a single instance. For each of the4*3*3=36parameter combinations, we generated 30 instances, i.e., we tested a total of 1080 instances. Table 1summarizes the results. The main observations from Table 1 are as follows:•As expected beforehand, the number of Pareto-optimal points increases as the number of machines increases;The number of Pareto-optimal points is insensitive to the duration of the machine disruption and the disruption start time;The average time required to construct the entire Pareto-set decreases as the disruption start time increases;In most cases the algorithm fails to solve instances with up to 25 jobs due to space capacity limitation.In this section we consider the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj). We first develop a pseudo-polynomial-time DP algorithm to solve the problem, and then show that the special case withm1=1admits a two-dimensional fully polynomial-time approximation scheme (FPTAS), which is the strongest approximation result for a bicriterionNP-hard problem. Recall that an algorithm Aε for a bicriterion problem is a(1+ɛ)-approximation algorithm if it always delivers an approximate solution pair (Z, T) withZ≤(1+ɛ)Z*andT≤(1+ɛ)T*for all the instances, where (Z*, T*) is a Pareto-optimal solution. A family of approximation algorithms {Aε} defines a two-dimensional FPTAS for the considered problem, if for any ε > 0, Aε is a(1+ɛ)-approximation algorithm that is polynomial in n, L, and 1/ε, whereL=logmax{n,τmax,Bmax,D,pmax}is the number of bits in binary encoding for the largest numerical parameter in the input.We can easily derive the following result by Lemma 4.1.Lemma 5.1For the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj),the total virtual tardiness∑j=1nTjis upper-bounded bynmax{min{Bmax,P}+D,CS−pmin}.Our DP-based solution algorithm STDP for the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj)follows the framework of forward recursive state generation and relies strongly on Lemma 3.4. Algorithm STDP contains n phases. In each phase j,j=0,1,…,n,a state spaceSjis generated. Any state inSjis a vector(j,B,F,T,v1,v2)corresponding to a partial schedule for the jobs{1,…,j},whereB,F,andTare defined as those in Section 4.1, and v1 denotes the total completion time of the partial schedule, while v2 represents the total virtual tardiness of the partial schedule. The state spacesSj,j=0,1,…,nare constructed iteratively. The initial spaceS0contains(0,B,F,T,0,0)as its only element, whereB=(τ1,…,τm1),F=(0,…,0︸m1),andT=(τm1+1,…,τm). In the jth phase,j=1,…,n,we build a state by adding a single job Jjto a previous state, if it is possible for the given state. That is, for any state(j,B,F,T,v1,v2)∈Sj−1,by Lemma 3.4, we includem1+1possibly generated states inSjas follows:(1)Schedule job Jjbefore Bion machine Mi,i=1,…,m1. This is possible only whenti′+pj≤Bi. In this case, the contributions of job Jjto the total completion time objective and the total virtual objective areti′+pjandmax{ti′+pj−Cj(π*),0},respectively. Thus, ifti′+pj≤Bi,we include(j,B′,F,T,v1+ti′+pj,v2+max{ti′+pj−Cj(π*),0})inSj.Assign job Jjto the later schedule. In this case, sett=min{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk}andk*=argmin{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk},which denote the earliest possible time when the machine becomes available after disruption and the corresponding machine with the earliest available time, respectively. Then the contributions of job Jjto the total completion time objective and the total virtual objective aret+pjandmax{t+pj−Cj(π*),0},respectively. Thus, we include(j,B,F′,T′,v1+t+pj,v2+max{t+pj−Cj(π*),0})inSj,whereF′=(t1,…,tk*−1,t+pj−Fk*,tk*+1,…,tm1)andT′=Tif 1 ≤ k* ≤ m1; otherwise,F′=FandT′=(tm1+1,…,tk*−1,t+pj,tk*+1,…,tm).Before presenting algorithm STDP in detail, we introduce the following elimination property to reduce the state setSj.Lemma 5.2For any two states(j,B,F,T,v1,v2)and(j,B′=(t1′′,…,tm1′′),F′=(t1′,…,tm1′),T′=(tm1+1′,…,tm′),v1′,v2′)inSj,iftk′≤tk′′fork=1,…,m1,tk≤tk′fork=1,…,m,v1≤v1′andv2≤v2′,we can eliminate the latter state.The proof is analogous to that of Lemma 4.2.□We give a formal description of algorithm STDP as follows:Sum-Tardiness-DP AlgorithmSTDPStep 1. [Preprocessing] Re-index the jobs in SPT order.Step 2. [Initialization] SetS0={(0,B,F,T,0,0)},whereB=(τ1,…,τm1),F=(0,…,0︸m1)andT=(τm1+1,…,τm); For eachj=1,…,n,seti=j−m⌊j/m⌋andCj(π*)=∑k=i,m+i,…,m⌊j/m⌋+ipk.Step 3. [Generation] GenerateSjfromSj−1.Forj=1to n doSetSj=∅;For each(j−1,B,F,T,v1,v2)∈Sj−1doSett=min{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk}andk*=argmin{mink=1,…,m1{Fk+tk},mink=m1+1,…,mtk};Fori=1to m1 do/*Alternative 1: schedule job j before Bi:Ifti′+pj≤Bi,thensetSj←Sj∪{(j,B′,F,T,v1+ti′+pj,v2+max{ti′+pj−Cj(π*),0})},whereB′=(t1′,…,t(i−1)′,ti′+pj,t(i+1)′,…,tm1′);EndifEndfor/*Alternative 2: assign job j to the later schedule:setSj←Sj∪{(j,B,F′,T′,v1+t+pj,v2+max{t+pj−Cj(π*),0})},whereF′=(t1,…,tk*−1,t+pj−Fk*,tk*+1,…,tm1)andT′=Tif 1 ≤ k* ≤m1, otherwiseF′=FandT′=(tm1+1,…,tk*−1,t+pj,tk*+1,…,tm);Endfor[Elimination] /* Update setSj*/1.For any two states(j,B,F,T,v1,v2)and(j,B,F,T,v1,v2′)withv2≤v2′,eliminate the second state from setSj;For any two states(j,B,F,T,v1,v2)and(j,B,F,T,v1′,v2)withv1≤v1′,eliminatethe second state from setSj;For any two states(j,B=(t1′,…,t(i−1)′,ti′,t(i+1)′,…,tm1′),F,T,v1,v2)and(j,B=(t1′,…,t(i−1)′,ti′′,t(i+1)′,…,tm1′),F,T,v1,v2)withti′≤ti′′,eliminate the latter state from setSj;For any two states(j,B,F=(t1,…,ti−1,ti,ti+1,…,tm1),T,v1,v2)and(j,B,F=(t1,…,ti−1,ti′,ti+1,…,tm1),T,v1,v2)withti≤ti′,eliminate the latter state from setSj;For any two states(j,B,F,T=(tm1+1,…,tk−1,tk,tk+1,…,tm),v1,v2)and(j,B,F,T=(tm1+1,…,tk−1,tk′,tk+1,…,tm),v1,v2)withtk≤tk′,eliminate the latter state from setSj;EndforStep 4. [Return all the Pareto-optimal points]SetQ¯=nmax{min{Bmax,P}+D,CS−pmin}andi=1;WhileQ¯≥0doSelect(Vi,Vi)=(v1,v2)that corresponds to the state(n,B,F,T,v1,v2)with theminimum v1 value among all the states inSnsuch thatv2≤Q¯as a Pareto-optimal point; SetQ¯=Vi−1andi=i+1;End whileReturn(V1,V1),…,(Vi−1,Vi−1)and the corresponding Pareto-optimal schedules canbe found by backtracking.Algorithm STDP solves the problemPm,hm11|τ,[Bi,Fi]1≤i≤m1|(∑j=1nCj,∑j=1nTj)in O(n2 max {min{Bmax,P}+D,CS−pmin}Pm−1∏i=1m1Bi)time.Given that algorithm STDP implicitly enumerates all the schedules satisfying the properties given in Lemma 3.4, the DP-based algorithm finds an efficient solution for each possibleQ¯through state transition. Verification of the time complexity of the algorithm is analogous to that of algorithm SMDP, where the difference lies in that before each iteration j, the total number of different possible combinations of(B,F,T)is upper-bounded byPm−1∏i=1m1Bidue to the fact that∑k=1m1(tk′+tk)+∑k=m1+1mtk=∑k=1jpk,while the total number of different possible combinations of v1 and v2 is upper-bounded bynmax{min{Bmax,P}+D,CS−pmin}due to the elimination rules and the fact that v2 is upper-bounded bynmax{min{Bmax,P}+D,CS−pmin}.□In this section we show how to obtain a good approximation of an efficient point on the trade-off curve by using the trimming-the-solution-space approach for the special case withm1=1. It is based on an approximate DP algorithm STAA with a slight modification of algorithm STDP. We present the idea as follows: For any δ > 1 and ε > 0, partition the intervalI1=[0,P]intoL1=⌈logδP⌉subintervalsI1(1)=[0,0],Ik(1)=[δk−1,δk),k=1,…,L1−1,IL1(1)=[δL1−1,P];and partition the intervalsI2=[0,n(F1+P)(1+ɛ)]andI3=[0,nmax{F1,CS−pmin}(1+ɛ)]intoL2=⌈logδn(F1+P)(1+ɛ)⌉subintervalsI1(2)=[0,0],Ik(2)=[δk−1,δk),k=1,…,L2−1,IL2(2)=[δL2−1,n(F1+P)(1+ɛ)],andL3=⌈logδnmax{F1,CS−pmin}(1+ɛ)⌉subintervalsI1(3)=[0,0],Ik(3)=[δk−1,δk),k=1,…,L3−1,IL3(3)=[δL3−1,nmax{F1,Cs−pmin}(1+ɛ)],respectively. This will divideI1×⋯×I1︸m×I2×I3into a set ofL1mL2L3(m+2)-dimensional subintervals. We develop an alternative DP algorithm STAA that differs from algorithm STDP in that out of all the states such that(t1,…,tm,v1,v2)falls within the same(m+2)-dimensional subinterval, only the state with the smallestt1′value is kept, while all the other states are eliminated. We formally describe the resulting procedure as follows:Sum-Tardiness-AA AlgorithmSTAAStep 1. [Preprocessing] The same as that in algorithm STDP.Step 2. [Partitioning] Partition the intervalI1=[0,P]intoL1=⌈logδP⌉subintervalsI1(1)=[0,0],Ik(1)=[δk−1,δk),k=1,…,L1−1,IL1(1)=[δL1−1,P];and partition the intervalsI2=[0,n(F1+P)(1+ɛ)]andI3=[0,nmax{F1,CS−pmin}(1+ε)] intoL2=⌈logδn(F1+P)(1+ɛ)⌉subintervalsI1(2)=[0,0],Ik(2)=[δk−1,δk),k=1,…,L2−1,IL2(2)=[δL2−1,n(F1+P)(1+ɛ)],andL3=⌈logδnmax{F1,CS−pmin}(1+ɛ)⌉subintervalsI1(3)=[0,0],Ik(3)=[δk−1,δk),k=1,…,L3−1,IL3(3)=[δL3−1,nmax{F1,CS−pmin}(1+ɛ)],respectively.Step 3. [Initialization]: The same as that in algorithm STDP.Step 4. [Generation]: GenerateSjfromSj−1Forj=1to n doSetSj=∅;/*the exact dynamic program:For each(j−1,t1′,t1,T=(t2,…,tm),v1,v2)∈Sj−1do/*Alternative 1: schedule job j on machine M1 beforeB1:Ift1′+pj≤B1,thensetSj←Sj∪{(j,t1′+pj,t1,T,v1+t1′+pj,v2+max{t1′+pj−Cj(π*),0})};Endif/*Alternative 2: assign job j to machine M1 after F1:setSj←Sj∪{(j,t1′,t1+pj,T,v1+F1+t1+pj,v2+max{F1+t1+pj−Cj(π*),0})};Fori=2to m do/*Alternative 3: schedule job j on machine Mi:setSj←Sj∪{(j,t1′,t1,T′,v1+ti+pj,v2+max{ti+pj−Cj(π*),0})},whereT′=(t2,…,ti−1,ti+pj,ti+1,…,tm);EndforEndfor[Elimination] /* Update setSj*/1.For any two states(j,t1′,t1,T=(t2,…,tm),v1,v2)and(j,t1′′,t1′,T′=(t2′,…,tm′),v1′,v2′)inSj,where(t1,t2,…,tm,v1,v2)and(t1′,t2′,…,tm′,v1′,v2′)fall within the same(m+2)-dimensional subinterval witht1′≤t1′′,eliminate the latter state from setSj;For any two states(j,t1′,t1,T,v1,v2)and(j,t1′,t1,T,v1,v2′)withv2≤v2′,eliminate the second state from setSj;For any two states(j,t1′,t1,T,v1,v2)and(j,t1′,t1,T,v1′,v2)withv1≤v1′,eliminate the second state from setSj;For any two states(j,t1′,t1,T,v1,v2)and(j,B,t1′,t1′,T,v1,v2)witht1≤t1′,eliminate the latter state from setSj;For any two states(j,t1′,t1,T=(tm1+1,…,tk−1,tk,tk+1,…,tm),v1,v2)and(j,t1′,t1,T=(tm1+1,…,tk−1,tk′,tk+1,…,tm),v1,v2)withtk≤tk′,eliminate the latter state from setSj;EndforStep 4. [Result] The same as that in STDP.For any eliminated state(j,t1′,t1,T=(t2,…,tm),v1,v2)∈Sj,there exists a non-dominated state(j,t1′′,t1′,T′=(t2′,…,tm′),v1′,v2′)such thatt1′′≤t1′,tk′≤δjtk,k=1,…,m,v1′≤δjv1,andv2′≤δjv2.The proof is by induction on j. It is clear that the lemma holds forj=1. As the induction hypothesis, we assume that the lemma holds for anyj=l−1,i.e., for any eliminated state(l−1,t1′,t1,T=(t2,…,tm),v1,v2)∈Sl−1,there exists a non-dominated state(l−1,t1′′,t1′,T′=(t2′,…,tm′),v1′,v2′)such thatt1′′≤t1′,tk′≤δl−1tk,k=1,…,m,v1′≤δl−1v1,andv2′≤δl−1v2. We show that the lemma holds forj=l.Consider an arbitrary state(l,t1′,t1,(t2,…,tm),v1,v2)∈Sl. First, we assume that job l appears in the earlier schedule obtained under the exact dynamic program, wheret1′≤B1. While implementing algorithm STAA, the state(l,t1′,t1,T=(t2,…,tm),v1,v2)is constructed from(l−1,t1′−pl,t1,(t2,…,tm),v1−t1′,v2−max{t1′−Cl(π*),0})∈Sl−1. According to the induction assumption, there exists a state(l−1,t1′′,t1′,T′=(t2′,…,tm′),v1′,v2′)such thatt1′′≤t1′−pl,tk′≤δl−1tk,k=1,…,m,v1′≤δl−1(v1−t1′),andv2′≤δl−1(v2−max{t1′−Cl(π*),0}). On the other hand, sincet1′′+pl≤t1′≤B1,the state(l−1,t1′′+pl,t1′,T′,v1′+t1′′+pl,v2′+max{t1′′+pl−Cl(π*),0})is generated under the exact dynamic program. It follows directly from the elimination procedure that there exists a state(l−1,t1′˜,t1˜,T˜=(t2˜,…,tm˜),v1˜,v2˜)such that(a)t1′˜≤t1′′+pl≤t1′,tk˜≤δtk′≤δltk,k=1,…,m,v1˜≤δ(v1′+t1′′+pl)≤δ(v1′+t1′)≤δ(v1′+δl−1t1′)≤δδl−1v1=δlv1,andv2˜≤δ(v2′+max{t1′′+pl−Cl(π*),0})≤δ(v2′+max{t1′−Cl(π*),0})≤δ(v2′+δl−1max{t1′−Cl(π*),0})≤δlv2.It follows that the induction hypothesis holds forj=lwhen job l appears in the earlier schedule obtained under the exact dynamic program.We now assume, without loss of generality, that job l appears in the later schedule on machine M1 obtained under the exact dynamic program. While implementing algorithm STAA, the state(l,t1′,t1,T=(t2,…,tm),v1,v2)is constructed from(l−1,t1′,t1−pl,T,v1−t1−F1,v2−max{F1+t1−Cl(π*),0})∈Sl−1. According to the induction assumption, there exists a state(l−1,t1′′,t1′,T′=(t2′,…,tm′),v1′,v2′)such thatt1′′≤t1′,t1′≤δl−1(t1−pl),tk′≤δl−1tk,k=2,…,m,v1′≤δl−1(v1−t1−F1),andv2′≤δl−1(v2−max{F1+t1−Cl(π*),0}). On the other hand, the state(l−1,t1′′,t1′+pl,T′,v1′+F1+t1′+pl,v2′+max{F1+t1′+pl−Cl(π*),0})is generated under the exact dynamic program. It follows directly from the elimination procedure that there exists a state(l−1,t1′˜,t1˜,T˜=(t2˜,…,tm˜),v1˜,v2˜)such that(a)t1′˜≤t1′′≤t1′,t1˜≤δ(t1′+pl)≤δ(t1′+δl−1pl)≤δδl−1t1=δlt1,tk˜≤δtk′≤δltk,k=2,…,m,v1˜≤δ(v1′+F1+t1′+pl)≤δ(v1′+δl−1F1+(t1′+δl−1pl))≤δ(v1′+δl−1F1+δl−1t1)≤δδl−1v1=δlv1,andv2˜≤δ(v2′+max{F1+t1′+pl−Cl(π*),0})≤δ(v2′+δl−1max{F1+t1−Cl(π*),0})≤δlv2.This establishes that the induction hypothesis holds forl=jwhen job j appears in the later schedule on machine M1 obtained under the exact dynamic program. The case where job l appears in the later schedule on each of the othermachines obtained under the exact dynamic program can be similarly proved. Thus, the result follows.□For any ε > 0 and a Pareto-optimal point(V¯,V¯),algorithm STAA finds inO(nm+3Lm+2ɛm+2)time a solution pair(V,V)such thatV≤(1+ɛ)V¯andV≤(1+ɛ)V¯.Letδ=1+ɛ2(1+ɛ)nand(n,t1′,t1,(t2,…,tm),V¯,V¯)be a state corresponding to the Pareto-optimal point(V¯,V¯). By the proof of Lemma 5.4, for(n,t1′,t1,(t2,…,tm),V¯,V¯),there exists a non-eliminated state(n,t1′˜,t1˜,(t2˜,…,tm˜),V,V)such thatV≤δnV¯andV≤δnV¯. It follows from(1+xn)n≤1+2x,for any 0 ≤ x ≤ 1, that(1+ɛ2(1+ɛ)n)n≤1+ɛ1+ɛ≤1+ɛ,soV≤δnV¯≤(1+ɛ)V¯andV≤δnV¯≤(1+ɛ)V¯.For the time complexity of algorithm STAA, Step 1 requires O(1) time. For each iteration j, note that we partition the intervalI1intoL1=⌈logδP⌉=⌈lnP/lnδ≤⌈(1+2n(1+ɛ)/ɛ)lnP⌉subintervals, where the last inequality is obtained from the well-known inequalitylnx≥(x−1)/xfor all x ≥ 1, and we partition the intervalsI2andI3intoL2=⌈logδ(n(F1+P)(1+ɛ))⌉≤⌈(1+2n(1+ɛ)/ɛ)ln(n(F1+P)(1+ɛ))⌉subintervals andL3=⌈logδ(nmax{F1,CS−pmin}(1+ɛ))⌉≤⌈(1+2n(1+ɛ)/ɛ)ln(nmax{F1,P−pmin}(1+ɛ))⌉subintervals, respectively. So we have|Sj|≤(⌈(1+2n(1+ɛ)/ɛ)lnP⌉)m⌈(1+2n(1+ɛ)/ɛ)ln(n(F1+P)(1+ɛ))⌉⌈(1+2n(1+ɛ)/ɛ)ln(nmax{F1,P−pmin}(1+ɛ))⌉=O(nm+2Lm+2ɛm+2)after the elimination process, while Step 2 takesO(nm+3Lm+2ɛm+2)time. Thus, the overall time complexity of algorithm STAA isO(nm+3Lm+2ɛm+2)indeed.□We performed numerical studies by varying the problem size to evaluate the performance of algorithms STDP and STAA. We carried out an experimental study analogous to the one conducted for assessing the performance of algorithm SMDP in Section 4.2. In this experiment we focused on finding a Pareto-optimal solution by applying algorithm STDP and an approximate Pareto solution by applying algorithm STAA for a givenQ¯in various parameter settings. We tested our algorithms on three classes of randomly generated instances:(i)m=2andm1=1,the job processing times pjwere randomly drawn from the uniform distribution (1, 20),B1=⌊P/8⌋,⌊P/6⌋,and ⌊P/4⌋,D=⌊P/80⌋,⌊P/50⌋,and ⌊P/30⌋, andɛ=0.3,0.5,and 0.8;m > 2 andm1=1,the job processing times pjwere randomly drawn from the uniform distribution (1, 20), and B1,D,and ε were chosen randomly from the sets {⌊P/8⌋, ⌊P/6⌋, ⌊P/4⌋}, {⌊P/80⌋, ⌊P/50⌋, ⌊P/30⌋}, and {0.3, 0.5, 0.8}, respectively;m=3andm1=1,2,3,the job processing times pjwere randomly drawn from the uniform distribution (1, 20), and B1 andDwere chosen randomly from the sets {⌊P/8⌋, ⌊P/6⌋, ⌊P/4⌋} and {⌊P/80⌋, ⌊P/50⌋, ⌊P/30⌋}, respectively.Instance classes (i) and (ii) are used to analyze the impacts of disruption start time, disruption duration, and ε, and the impact of number of machines on the performance of algorithms STDP and STAA, respectively, while instance class (iii) is used to analyze the impact of number of disrupted machines on the performance of algorithm STDP. For instance class (i), we tested our algorithms on instances withn=50,80,and 100 jobs; and for instance classes (ii) and (iii), we went no further than instances with 70 jobs, since larger instances took too much time to solve. For each combination of n and instance class (i), we generated 30 instances; and for each combination of n and instance classes (ii) and (iii), we generated 20 instances.Let(Vi,Vi)be a Pareto-optimal solution and(V˜i,V˜i)be an approximate Pareto solution for instance i, wherei=1,…,20or 30. For instance i,i=1,…,20or 30, we defineΔiv1=V˜i−ViVi≤ɛandΔiv2=V˜i−ViVi≤ɛas the relative deviation of the approximate solution from the efficient solution with respect to the total completion time and total virtual tardiness, respectively. For each combination of n, B1, D, and ε, we recorded the average and maximum numbers of states generated by both algorithms STDP and STAA, the average times required to obtain the Pareto-optimal and approximate Pareto solutions, and the average and maximum relative deviations.Tables 2–4 summarize the results of the experimental study for instance class (i) withn=50,n=80,andn=100,respectively.We make the following observations from Tables 2 to 4.•As the disruption start time increases, the number of states increases, so the time required to solve an instance also increases for both algorithms;Algorithm STAA does not perform better than algorithm STDP as expected. The reasons are twofold. One is that in each iteration j, there are two new states generated from each state inSjin algorithm STDP, while in algorithm STAA there are three new states generated. Another is that δ becomes small as the problem size increases, so it becomes more difficult for the quaternarys (t1, t2, v1, v2) to fall within the same 4-dimensional subinterval, implying that the elimination rule 1 in algorithm STAA cannot efficiently eliminate the dominated states;The benefits of Algorithm STAA are particularly evident when the number of jobs is large.Tables 5 and 6 summarize the results of the experimental study for instance classes (ii) and (iii), respectively. Different from Tables 1–4, Tables 5 and 6 also report the number of jobs in a problem that the corresponding algorithm cannot solve within 3600 seconds.We make the following observations from Tables 5 and 6.•When there is only one disrupted machine, i.e.,m1=1,the number of jobs that algorithms STDP and STAA are capable of solving within 3600 seconds decreases and algorithm STAA generates more Pareto-optimal points as the number of machines increases;As stated above, algorithm STAA does not perform better than algorithm STDP as expected;As expected, algorithm STDP performs poorly as the number of disrupted machines increases.

@&#CONCLUSIONS@&#
