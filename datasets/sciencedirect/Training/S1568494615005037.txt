@&#MAIN-TITLE@&#
A memetic algorithm applied to trajectory control by tuning of Fractional Order Proportional-Integral-Derivative controllers

@&#HIGHLIGHTS@&#
This paper proposes a PSO-memetic algorithm using Fractional Calculus (FC).The FC illustrates a potential for interpreting progression of the algorithm by controlling its convergence.An empirical comparison study is presented for solving different test functions.Experiments are also performed to obtain the optimal gains of Fractional Order PID controller.Results verify the efficiency of the proposed algorithm.

@&#KEYPHRASES@&#
Memetic algorithm,Local search,Particle swarm optimization,Fractional calculus,Fractional PID controller,

@&#ABSTRACT@&#
This paper introduces a novel memetic algorithm namely Fractional Particle Swarm Optimization-based Memetic Algorithm (FPSOMA) to solve optimization problem using fractional calculus concept. The FC illustrates a potential for interpreting progression of the algorithm by controlling its convergence. The FPSOMA accomplishes global search over the whole search space through PSO whereas local search is performed by PSO with fractional order velocity to alter the memory of best location of the particles. To assess the performance of the proposed algorithm, firstly an empirical comparison study is presented for solving different test functions adopted from literature. Comparisons demonstrate the preference of FPSOMA than other related algorithms. Subsequently, experiments are conducted to achieve optimal gains of Fractional Order Proportional-Integral-Derivative (FO PID) controller in solving tracking problem. Results verify the efficiency of the proposed algorithm.

@&#INTRODUCTION@&#
Nowadays, controlling of the processes is an important topic in scientific researches. Proportional-Integral-Derivative (PID) controllers are continuing to be used in many control applications by minimizing the error between a desired set point and output of the process [1]. This is because of simplicity realization and fine stability. The main topic in PID control design is tuning of the gains, which is a dependent problem. Many different types of tuning guidelines have been introduced in the literature such as the Ziegler–Nichols [2], Cohen–Coon rule [3], integral performance standards [4] and Astrom–Hagglund scheme [5].Fractional calculus has a long history over than 300 years [6], but fractional order control has been developed in the last decade for controlling different types of processes [7–10]. Fractional Order PID (FO PID) controllers are recognized to guarantee better performance with respect to the classical PID controllers [11,12]. In spite of more flexibility in comparison to classical PID controllers, designing FO PIDs become more complicated than classical PID controllers since there exist two more parameters in FO PID. In addition, they are more robust in presence of parameters’ uncertainties both in the controlled system and the controller itself [13].Similar to classical PID controllers, an important issue is to determine the controller parameters of FO PID, which should be defined in advance by the designer. The simplest method is the manual tuning, which is a very time-consuming task because of using fractional calculus. To overcome this problem, an optimal tuning methodology of FO PID controller is required by solving an optimization problem. Different kinds of classical techniques have been employed to solve this problem like Gradient Descents [14], which have some drawbacks such as differentiability of the objective function and dependency on initial conditions. Another technique is Evolutionary Algorithms (EAs), which have attracted more and more attentions during recent years [15]. Among them, Genetic Algorithm (GA) is one of the most popular methods [16–18]. Although GA can explore a wide range of search space efficiently, it does not have a useful local search mechanism to achieve accurately searching near a good solution [19]. Particle Swarm Optimization (PSO) is a population-based algorithm originally proposed by Eberhart and Kennedy [20]. Since PSO does not utilize the GA operators like mutation, crossover, and selection operator, it takes less time for evaluation of function in comparison to GA [21] and has been successfully applied in different engineering problems [22–25]. However, PSO has a poor ability to local search since there is no mechanism to control the velocity of the swarm. To enhance the performance of PSO, many techniques have been introduced such as velocity clamping [26] and variable inertia weight [27–30].Generally, EAs suffer from a few disadvantages such as premature convergence and lack of fine tuning of potential solutions [31,32]. Memetic Algorithms (MAs) have been developed to further improvement of the performance of EAs [33–38]. They must have two capabilities, exploration and exploitation, in order to be able to find reasonable solutions. Exploration refers to the ability of investigating various unknown regions in the solution space to discover the global optimum and exploitation indicates the capability of the algorithm to refine a candidate solution to a local optimum, having already found in a region of interest [39–41]. A comprehensive study of exploration and exploitation in EAs can be found in [42]. This paper addresses three significant topics about exploration and exploitation including how to contribute the EA components in exploration and exploitation, how to control exploration and exploitation, and how to achieve balance between exploration and exploitation. For more details, see [42] and references therein.MAs have gained much importance in the field of optimization, because additional knowledge during the search process is incorporated by a local refinement procedure. Success of the algorithms depends on its ability to establish good balance between exploration and exploitation [40,42,43]. In this point of view, designing an MA with good performance is complicated due to the nature of contradiction between exploitation and exploration. It is worth mentioning that evolutionary strategies were also proposed during the last years for optimizing fractional algorithms. Therefore, embedding the fractional calculus concept and evolutionary optimization is a constructive strategy for controller design [9].The goal of this paper is to present a novel MA namely Fractional Particle Swarm Optimization-based Memetic Algorithm (FPSOMA) for tuning the gains of FO PID controller in solving tracking problem. The main motivation of the proposed algorithm is to combine the ability of PSO in global search and the fractional calculus concept with PSO in local search. That is, the proposed MA accomplishes global search over the whole search space through PSO and the local search is carried out by PSO with fractional order velocity. To evaluation the performance of FPSOMA, experiments are firstly performed on benchmark test problems adopted from the literature. The results demonstrate that the proposed algorithm is an efficient approach in terms of search capability. Afterward, FO PID controller design is formulated as a multidimensional optimization problem and the FPSOMA is implemented in trajectory control for solving this problem. The results confirm that the proposed FPSOMA is a powerful tool for tuning of FO PID controller parameters in comparison to other related works including GA [44], PSO [45], PSO-based Memetic Algorithm (PSO-MA) [46], GA-based Memetic Algorithm (GA-MA) [47], DE [12] and ABC [48]. According to our knowledge, this is the first research to apply MA for optimizing parameters of FO PID controllers.The reminder of the paper is organized as follows. The brief overview of PSO is given in Section 2. The proposed MA is presented in Section 3. Section 4 shows the numerical experiments over the test functions. Section 5 demonstrates how EAs can be applied to design FO PID controllers. Finally, conclusions are given in Section 6.PSO inspired from the simulation of social behavior of a group of birds. Due to some attractive aspects such as quick convergence and easy implementation, PSO has been broadly applied for different optimization problems [23–30,49–52]. A set of randomly generated solutions propagates in the whole search space toward the optimal solution over a number of iterations by sharing information between all particles. Each particle retains track of its own previous best position and their group previous best position in this procedure. At each iteration, the velocity and position of ith particle are calculated as follows.(1)vi(t+1)=vi(t)+φ1(Pbesti–xi(t))+φ2(Gbest−xi(t))(2)xi(t+1)=xi(t)+vi(t+1)where xiandviare the corresponding position and velocity of the particle, φ1 and φ2 are the randomly uniformly terms,Pbestiis the best of solutions that the particle has reached and Gbestis the best position found by all particles called as global best.The PSO algorithm is repeated and updated at each iteration using Eqs. (1) and (2), until the stopping criterion is satisfied.It is found that PSO has a poor ability to search for a fine particle because it lacks a velocity control mechanism. Large velocities can cause particles to leave the defined boundary constraints of the problem, which leads to the divergence of the swarm. To counter this problem, some modifications have been introduced in literature such as velocity clamping [26] and adjustment of the inertia weight [27–30]. Eberhart et al. [26] proposed the following mechanism called velocity clamping.(3)vi(t+1)=v′i(t+1)ifv′i(t+1)<VmaxVmaxifv′i(t+1)≥Vmaxwhere Vmax defines the maximum value for the velocity component.The choice of Vmax defines whether the swarm will tend toward exploration or exploitation. Small values of Vmax tend to cause particles to explore only their local regions, and may cause them to become trapped in local minima. Furthermore, the number of steps required to reach a good local solution may increase.Generally, population-based algorithms are capable of exploring and exploiting the promising regions in the search space. However, some of them like PSO have a tendency of premature convergence. Here, an MA algorithm is proposed by incorporating PSO with a Local Search (LS) operator. In the proposed algorithm, PSO with fractional order velocity is employed as the LS operator with the optimal initial swarm to find the best optimum design. After each function evaluation some particles, which are the best among them, are opted for local refinement using the local operator. The details of the proposed algorithm are given in the next section.The purpose of MA is to enhance the quality of the solutions by combining global and local search together. The reason of combining two different search processes is to improve exploration of the search space and exploitation of the neighborhood locality. It was shown that the MAs are more competitive both in effectiveness and efficiency than traditional EAs [53,54]. However, success of the MAs depends on its ability to establish good balance between exploration and exploitation [40,42,43]. In this point of view, the manner of designing an MA with a good performance is intricate. Therefore, significant topic in MAs is the choice of LS operators. In this form, it must be specified how to choose individuals for LS as well as how to perform an efficient LS to improve the individuals’ quality.GAs can be easily combined with any other traditional optimization techniques resulting in MA [55]. This kind of combination of two different search procedures will improve the search performance of the GAs. GA along with gradient-based information as LS has been utilized to develop MAs [34,56]. However, the gradient-based approaches failed in the cases of multimodal and non-differentiable functions [36]. As a result, population-based LS algorithms have advantages over the gradient-type LS algorithms [57]. It has been shown that performance of any search algorithm can be enhanced further by combining with other search algorithms [58]. Here, the proposed algorithm is a class of PSO-based MAs in which PSO with fractional-order velocity [59,60] is employed as the LS. This issue will be addressed in the next section.In basic PSO-based MA, memes are opted to be refined using LS operator to update corresponding the position and value of objective function. However, the last memory of each meme is only utilized in this procedure. Accordingly, to increase memory of the memes for controlling their convergence, we introduce a novel PSO-based MA namely FPSOMA by incorporating fractional calculus in LS process. This makes the algorithm works more accurately. The velocity equation given in Eq. (1) can be written as follows:(4)vi(t+1)−vi(t)=φ1(Pbesti−xi)+φ2(Gbest−xi)The discrete time expression of Grunwald–Letnikov fractional derivative of continuous function x(t) is [59](5)Dα[x(t)]=1Tα∑k=0r−1kΓ(α+1)x(t−kT)Γ(k+1)Γ(α−k+1)where T is the sampling period, r is the truncation order and α is the order of the velocity derivative which can be generally varied between [0,1].From Eq. (5), it can be seen that the left side of Eq. (4) is the discrete time expression with α=T=1 as(6)Dαv(t+1)=φ1(Pbesti−xi)+φ2(Gbest−xi)It is apparent that one can control the memory effect by setting α. By choosing the first r=4 terms of Eq. (5), we have(7)v(t+1)−αv(t)−12α(1−α)v(t−1)−16α(1−α)(2−α)v(t−2)−124α(1−α)(2−α)(3−α)v(t−3)=φ1(Pbesti−xi)+φ2(Gbest−xi)Therefore, it yields(8)v(t+1)=αv(t)+12α(1−α)v(t−1)+16α(1−α)(2−α)v(t−2)+124α(1−α)(2−α)(3−α)v(t−3)+φ1(Pbesti−xi)+φ2(Gbest−xi)The larger values of r leads to results of the same type [59].In the following, the issues related to combining global and local searches together are given. These issues addressed by LS are determining the frequency of LS, choosing individuals for LS and deciding the intensity of LS, which have directly impacts on complexity and time consumed by the procedure.Frequency of LS: Frequency of LS indicates the number of LS iterations in internal loop that each individual can be provided for optimality. Here, this parameter relies on the number of individuals employed in LS.Choosing individuals for LS: Since LS is itself a separate optimization process when it is embedded into another algorithm, the intricacy of the procedure significantly increases. Therefore, it is not feasible to apply LS on all individuals and requires a selection policy for filtering the individuals. That is, every individual in the population can be chosen but preference can be given to elite solutions to undergo LS [31,61]. Here, the selection procedure is performed based on the fitness of each individual. Using elitist strategy, the best individuals in each generation are chosen to conduct LS process. The elitist selection creates a new population by choosing the best individuals from the current population. To some extent, this mechanism maintains the diversity of population.Intensity of LS: The intensity of LS (i.e. for how long is local improvement attempted on a particular solutions) is also a key parameter to deal with MAs in literature [54,62]. This adjustment can be conducted blindly (i.e. prefixing a constant value), or adaptively. In this paper, LS is restricted to one step per generation. That is, elites at every generation are identified and are given to one-step LS.Within the proposed FPSOMA, a population of particles is first initialized with random positions and velocities and they will be arranged according to their fitness values. At the initial step, the personal best of each particle Pbestis set equal to itself and the global best of every particle is subsequently obtained. Accordingly, m elite particles, which are the best among them, are opted to perform LS process. During the LS process, these particles can accomplish to update the positions and velocities according to Eqs. (2) and (8), respectively. If one particle can get a better solution than its personal best Pbest, the newly achieved solution will be replaced instead of Pbest. Finally, the global best of each particle Gbestis updated according to the global best obtained in LS. Then, the termination criterion is tested, and the search is terminated if the solution is found or the predefined Number of Fitness Evaluation (NFE) is reached. The procedure of PSO-based MA can be summarized as follows.BEGIN FPSOMAObjective function f(x), x=(x1, x2, ..., xd)NFE=0;FORi=1:nInitialize the particles of the population randomly;Evaluate f(xi);NFE=NFE+1;pi≔xi;END FORWHILE (Stopping criterion)FORi=1:nUpdateviandxiusing Eqs. (1) and (2), respectively;Evaluate f(xi);NFE=NFE+1;IFf(pi)<f(xi)pi≔xi;END IFSelect m elite particles from the current population for local refinement;FORk=1:mUpdatevkandxkusing Eqs. (8) and (2), respectively;Evaluate f(xk);NFE=NFE+1;IFf(pk)<f(xk)pk≔xk;END IFEND FORRank the particles and find the current best;Update the global best Gbest;END FOREND WHILEEND FPSOMATo analyze the performance of FPSOMA, 14 benchmark functions are adopted from literature [63,64]. These functions span a different set of problem characteristics such as unimodal, multimodal, separable and non-separable. The suite is contained of the test functions as follows: Rosenbrock (f1), Rastrigin (f2), Himmelblau (f3), Michalewicz (f4), Griewank (f5), Ackley (f6), Sphere (f7), Elliptic (f8), Schwefel (f9), Shifted Sphere (f10), Shifted Rosenbrock (f11), Shifted Rastrigin (f12), Shifted Ackley (f13), Shifted Elliptic (f14). All simulations are performed using MATLAB R2013a (8.1.0.604) 64-bit (win 64), and a computer with the specifications as follows: ASUS Laptop/Processor: Intel® Core™ i5-2450M CPU 2.50GHz/Installed Memory (RAM): 4.00GB (3.78 usable)/System Type: 64-bit win7 Operating System/VGA: GeForce NVidia 610M 2G.Two statistical approaches can be considered to analyze the results: value-based approach and rank-based approach. In the value-based approach, solution quality is considered in terms of two performance metrics including mean and standard deviation normally. However, Črepinšek et al., have suggested to comprehensive comparison between EAs, computational effort and robustness are required [65]. These metrics are evaluated for the algorithms with different benchmark function sets. In the rank-based approach, some strategies have been introduced in literature [39,66,67]. In [39], direct measures to analyze the exploration capabilities of EAs have been introduced. Here, a measure called the “Exploration ratio”, which is computed by using an ancestry tree and calculating the percentage of nodes in the tree for which the distance between parent and children individuals is over a threshold. In [66], a chess rating system has been introduced for comparing and ranking EAs based on exploration and exploitation measurement. However, to perform statistical analyses, the procedures can be categorized into two parametric and nonparametric classes based on the concrete type of data employed [68]. In the current paper, in order to fairly compare the algorithms, a complete set of performance measures is utilized. In the value-based approach, we utilize the guidelines suggested in [65] to carry out the experiments in the present work. In addition, the Friedman test, which is a non-parametric test, is used to make algorithm ranking [69]. Under the null-hypothesis, it states that all the algorithms are equivalent, thus a rejection of this hypothesis implies the existence of differences among the performance of all the algorithms studied. To make the Friedman non-parametric test reliable, it requires more than 10 problems and more than 5 different algorithms, which is satisfied in our experimental study [66].As mentioned in Section 3.2, the value α is introduced to enhance the performance of the proposed FPSOMA. In this section, we study the sensitivity of the algorithm to the parameter α and its influence on the convergence of the algorithm. To this end, a comparison between the performances of the FPSOMA is performed in optimizing the test functions with different values of α which is varied between [0,1] in step of 0.1. Results are shown in Fig. 1. From Fig. 1, it can be concluded that the convergence of the algorithm depends directly upon α such that the convergence velocity decreases as α value increases. Even though, the algorithm finds better results with the increase of alpha value.

@&#CONCLUSIONS@&#
This paper proposed a novel MA namely FPSOMA to solve engineering optimization problems. In the proposed algorithm, PSO with fractional velocity as local search operator was employed to promote best-performing particles and improve global optimality. To assess the capability of the FPSOMA, it was exploited to solve the test functions with different aspects. The empirical results revealed that FPSOMA is a competitive and easy implemented algorithm with good performances in terms of effectiveness, efficiency and robustness. Furthermore, FPSOMA was successfully applied to tuning the parameters of the FO PID controller. The corresponding results verified that the proposed FPSOMA is a promising alternative approach for controlling the systems by adjusting FO PID controller parameters efficiently.