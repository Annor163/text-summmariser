@&#MAIN-TITLE@&#
Robust polyhedral Minkowski sums with GPU implementation

@&#HIGHLIGHTS@&#
We compute Minkowski sum boundaries of two input polyhedra.Sum polygons from convolution are created, subdivided, and traversed for boundary construction.The algorithm is robustly implemented on CPU and GPU both.The performance on GPU is orders-of-magnitude higher than previous works.

@&#KEYPHRASES@&#
Minkowski sums,Robust computational geometry,GPU algorithms,

@&#ABSTRACT@&#
We present a Minkowski sum algorithm for polyhedra based on convolution. We develop robust CPU and GPU implementations, using our ACP strategy to eliminate degeneracy and to enforce a user-specified backward error bound. We test the programs on 45 inputs with an error bound of10−8. The CPU program outperforms prior work, including non-robust programs. The GPU program using 2688 CUDA cores exhibits a median speedup factor of 36, which increases to 68 on the 6 hardest tests. For example, it computes a Minkowski sum with a million features in 20 seconds.

@&#INTRODUCTION@&#
Minkowski sums are a core computational geometry concept with applications in solid modeling, packing, assembly, and robotics. The Minkowski sum of point setsAandBisA⊕B={a+b∣a∈A∧b∈B}.IfAandBare polyhedra,A⊕Bis a polyhedron. Fig. 1shows a starA, a tetrahedronB, andA⊕B. Minkowski sums facilitate contact analysis. Let−A+tdenoteAreflected around the origin and translated byt. The polyhedra−A+tandBoverlap iftis in the interior ofA⊕Band touch iftis on its boundary. In Fig. 1, the snapshots show−A+tiandBat threetion the boundary ofA⊕B. A vertex ofAtouches a facet ofBatt1, two edges touch att2, and both cases occur att3. Configurations where one pair of features touch, such ast1andt2, are in the interior of boundary facets, whereas configurations where two pairs touch, such ast3are on their edges.The most efficient approach to Minkowski sum computation uses Kaul and Rossignac’s convolution  [1]. Our prior algorithm using that convolution  [2] is the first robust implementation of any convolution algorithm for general polyhedra (Section  2). We present an improved algorithm that is faster and that uses less memory (Section  3). The computational bottleneck in convolution algorithms is finding which facets intersect. We present a novel kd-tree algorithm that finds all intersecting pairs in a set of geometric objects without splitting objects and without using a hash table to avoid duplicate tests. The memory bottleneck is the arrangement of the convolution. We present a novel technique for discarding a large portion that does not contribute to the Minkowski sum boundary.We implement our algorithm robustly, using our ACP strategy  [3] to eliminate degeneracy and to enforce a user-specified backward error bound (Section  4). Appendix describes a GPU implementation. We tested both programs on 45 pairs of polyhedra with an error bound of10−8(Section  5). The CPU program outperforms prior work, including non-robust programs. The GPU program using 2688 CUDA cores exhibits a median speedup factor of 36, which increases to 68 on the 6 hardest tests. For example, it computes a Minkowski sum with a million features in 20 s.The main approaches to computing Minkowski sums of polyhedra are convex decomposition and convolution.The first approach decomposes the polyhedra into convex components, computes the Minkowski sums of the components with a specialized algorithm  [4], and returns their union. This approach is inefficient because a polyhedron withrreflex edges can haveΩ(r2)convex pieces, so an input withnedges can entail a union ofΩ(n4)component Minkowski sums. Hachenberger  [5] provides an exact implementation of this algorithm. The program is very slow  [6,7,2]. Varadhan and Manocha  [8] reduce the constant factor by computing the union approximately yet with the correct topology, using a volumetric grid. They observe that the approach remains slow.The second approach computes a set of facets, called a convolution, that is a superset of the boundary ofA⊕B. A facetfof the arrangement of these facets boundsA⊕Bif−A+t∩B≠0̸and−A+t′∩B=0̸for arbitraryt∈candt′∈c′in the (open 3D) cellscandc′on either side off.The kinetic convolution  [9,10] is defined using an assignment of a set of outward normals to each boundary point of a polyhedron. A facet is assigned its normaln. An edge with incident facet normalsn1andn2is assigned the arcn1n2on the Gauss sphere. A vertex is assigned the interior of the spherical polygon defined by the arcs of the incident edges. Features fromAandBare compatible if they have a common normal. The kinetic convolution is the set of Minkowski sums of compatible pairs. The 2D version of the convolution has a winding number property that determines if cellc∈A⊕B. This property does not hold for general polyhedra  [10].We illustrate these concepts withAa sphere and withBa hollow box that contains a solid tetrahedron (Fig. 2). The cells that comprise the Minkowski sum are drawn in yellow. The sphere overlaps the box in the outer cell and overlaps the tetrahedron in the inner cell.Lien  [11] provides a non-robust implementation of a kinetic convolution algorithm. He computes the 2D arrangement of each facet of the convolution defined by the other facets, groups the faces of these arrangements into polygonal surfaces, and uses intersection tests to identify those surfaces that bound the Minkowski sum. There is no error bound. The output facets can intersect, whereas the Minkowski sum is a simple polyhedron, so applications that rely on this property may fail.Fogel and Halperin  [4] compute the Minkowski sum of two convex polyhedra. The kinetic convolution forms a single surface that bounds the Minkowski sum, so there is no need to compute an arrangement. Barki, Denis, and Dupont  [7] compute the Minkowski sum of a general polyhedron and a convex polyhedron. They compute a subset of the kinetic convolution that works for this special case. The rest of the algorithm is similar to Lien’s  [11]. Both Fogel and Halperin and Barki et al. provide exact implementations.Campen and Kobbelt  [6] use the kinetic convolution to compute the outer boundary of the Minkowski sum. The algorithm has limited applicability because inner boundaries are common, e.g. for polyhedra with inner cavities, in part layout, and in mechanical design. They provide an exact implementation via a prior technique  [12] that requires them to use planes as geometric primitives and to define vertices as intersection points of three planes. The vertex accuracy is10−5even though the plane accuracy is10−16(IEEE double). Converting the Minkowski sum to a boundary representation can cause facets to intersect.Kaul and Rossignac  [1] define a subset of the kinetic convolution, which we call the convex convolution, that is still a superset of the boundary ofA⊕B. The set of normals at a boundary pointp∈Ais replaced by the subset corresponding to the convex closure ofAin a neighborhood ofp. No normals are assigned to concave edges and fewer normals (possibly none) are assigned to vertices with concave incident edges. In Fig. 2, the convex convolution has fewer facets than does the kinetic convolution yet is still a subset of the Minkowski sum boundary.We  [2] developed a robust implementation of a convex convolution algorithm. The data structures are incompatible with distributed computation. The memory footprint is larger than the output size. The robustness technique requires custom logic for every type of degenerate input, and its error is not bounded.Li and McMains  [13] approximate the outer boundary of the Minkowski sum using the convex convolution, voxelization, and the GPU. The accuracy is limited by the volumetric resolution: the reported results have a resolution of 10243, which yields a10−3error. Increasing the resolution incurs a cubic running time penalty and is limited by the GPU memory size.Fig. 3summarizes our Minkowski sum algorithm. The inputs are polyhedra with triangular facets with outward oriented normals. Step 1 constructs the convex convolution. Step 2 intersects its facets. Step 3 computes the arrangements defined by the intersection edges. Step 4 identifies the faces of the arrangements that comprise the Minkowski sum boundary. Step 5 triangulates the boundary facets via monotone decomposition.Although our algorithm has the same structure as our prior algorithm  [2], we employ novel techniques that reduce memory usage and that enable distributed computation. We describe the algorithm briefly and discuss the innovations in detail. We can assume that the inputs are in general position because of our robustness technique (Section  4). This assumption simplifies the algorithm and the presentation.Step 1 of the algorithm constructs the convex convolution ofAandB. Its facets are triangles and parallelograms because the facets ofAandBare triangles. We identify the pairs of features with shared normals using a binary spatial partition of the Gauss sphere  [14]. Although the kinetic convolution can be computed in an output sensitive manner  [10], we do not attempt output sensitive computation of the convex convolution because the running time of our algorithm is negligible.Step 2 of the algorithm constructs the intersection edges of the convolution, which we call FF-edges. One endpoint of each FF-edge is the intersection point of a convolution edge and a facet, which we call an EF-vertex. The other endpoint is also an EF-vertex or is a convolution vertex. In Fig. 4, facets=v1v2v3v4intersects facets{r,u,v,w}and forms EF-vertices{v5,v6,v7,v8,v9}and FF-edges{v4v5,v5v6,v6v7,v8v9}.Testing a pair of facets for intersection and if so constructing their FF-edge are constant-time operations. The key to an efficient algorithm is to test as few non-intersecting pairs as possible. Since an output sensitive algorithm is not available, we construct a kd-tree for the facets and test the pairs that share a leaf. The drawback of kd-trees is that two facets can share multiple leafs if some splitting planes intersect them both. Prior work uses hash tables to detect duplicate pairs, but constructing hash tables on the GPU requires a large amount of temporary storage because the required space is proportional to the number of lookups, not the number of entries  [15]. For example, our helix+helix example generates 72 M facet pairs which would occupy about 1 GB temporary storage. We have developed a novel type of kd-tree that solves this problem.Each facetpis labeled with a bit vectorl(p)=0. We construct a kd-tree for the labeled facets. If the splitting plane at depthdintersectsp,pis assigned to the left subtree and the right subtree is assigned a copy ofpthedth bit of whose label is set to one. If not,pis assigned to one subtree. A leaf is generated if a maximum depth or a minimum number of facets is reached. Fig. 5shows an example in which facetspandqare inserted into a kd-tree with rootn0, depth-1 nodesn1andn2, and leafsn3,…,n6. Whenpis split atd=1by the dashed vertical line, it is assigned ton5andn6with labels 10 and 11. In a leaf, facetspandqare tested for intersection ifl(p)∧l(q)=0(the bit-wise conjunction). In our example,pandqappear in leafsn3,n5, andn6, but are only tested inn3becausel(p)∧l(q)is 10 inn5and is 11 inn6.No pair is tested twice becausel(p)∧l(q)can equal zero only in the leftmost leaf that containspandq. Any other leaf that containspandqhas a common ancestor with the leftmost leaf at some depthd. Thedth bits ofl(p)andl(q)equal one in the other leaf becausepandqwere assigned to both subtrees at depthdand the other leaf is in the right subtree.Every intersecting pair is tested becausel(p)∧l(q)=0in their leftmost leaf. If not, the leftmost leaf would be in the right subtree of some ancestor andpandqwould be assigned to both of its subtrees. Sincepandqintersect, no splitting plane separates them, so they would share a leaf in the left subtree. This leaf would be to the left of the leftmost leaf.Step 3 of the algorithm computes the arrangement of each facet defined by its FF-edges. The arrangement consists of faces bounded by polygonal loops. We split the edges of the facet at their EF-vertices and split its FF-edges at their intersection points, which we call FFF-vertices. We form the loops by traversing the sub-edges. We compute their nesting order, which defines the faces, via ray casting in the plane of the facet. In Fig. 4(b), FF-edgesv6v7andv8v9intersect at FFF-vertexv10and the faces are numbered 1–4.Step 4 of the algorithm identifies the faces of the facet arrangements that bound the Minkowski sum. Only some faces are candidates. Of the four faces that share a sub-edge of an FF-edge, the two faces on the outward normal sides of both facets are candidates. If two or more faces share a sub-edge of a convolution edge, two of them are candidates based on a geometric test  [1]. The candidates define polyhedral surfaces. A surface contributes to the Minkowski sum boundary if it is closed and−A+tdoes not overlapBfor an arbitrary vertext=b−aof the surface, except thatatouchesb.The CPU program assigns the candidate faces to surfaces by breadth-first traversal of the face adjacency graph. This algorithm is suboptimal for the GPU because the running time is proportional to the graph diameter independently of the number of processors. Instead, we compute the surfaces in parallel with the union-find algorithm whose time complexity is nearly proportional toe/pforeedges andpprocessors. Each face is initialized to a singleton set. In each cycle, each face is assigned a process that merges its set with those of its graph neighbors.A cell is an outer or inner boundary if by itself it represents a bounded or unbounded polyhedron. To classify a cell, take the vertex with maximumzand its outgoing edge with smallest obtuse angle with thez-axis. Because neighboring edges have larger angle, the two incident faces slope downward from this edge. If the edge is convex, the exterior is above the edge and unbounded, and the cell is outer. If the edge is reflex, the interior is above the edge and unbounded, and the cell is inner. We assign an inner boundary to its cell by intersecting a ray through one of its vertices with the outer boundaries and selecting the closest one that is intersected an odd number of times.The Minkowski sum boundary is typically a small subset of the arrangement of the convolution. The rest of the arrangement, called the blocked portion, is in the Minkowski sum interior. Storing the blocked portion makes the memory footprint of the program far exceed the output size, which inhibits distributed computation. We discard most blocked vertices and never compute most blocked sub-edges and faces.The facets of the convolution are oriented so that the polyhedra−A+tandBintersect fortin a neighborhood of a facet on the negative side of its normal. Since this neighborhood is blocked, we can discard the part of the convolution that it contains without losing any part of the Minkowski sum boundary.We use three tests for being blocked. (1) Lete=v0vkhave tangentu=vk−v0and contain verticesv1,…,vk−1sorted alonge(Fig. 6). The containedviare EF-vertices for a convolution edge and are FFF-vertices for an FF-edge. Eachviis the intersection point ofewith a facetsiwith normalni. Ifni⋅u>0, the intersection ofv0viwith a neighborhood ofviis in the interior ofA⊕Bdue tosi, so the sub-edgevi−1viis blocked. Likewise,vivi+1is blocked ifni⋅u<0. The only non-blocked sub-edge in our example isv2v3. (2) If both incident sub-edges ofviare blocked,viis blocked. (3) Ifviis a blocked EF-vertex, the sub-edgevivfof the incident FF-edgefis blocked.We reduce the memory footprint by dividing the facets into groups prior to edge intersection and merging the groups after discarding blocked vertices. We form groups of approximately equal size by constructing a kd-tree for the facet centroids. The facets whose centroids share a leaf are the primary members of a group. We ensure that a group contains all the facets that intersect its primary members by including the facets that intersect the bounding box of its primary members. For each group, we construct FF-edges for the primary members that intersect other members, construct FFF-vertices for the intersecting pairs of FF-edges, and discard the blocked vertices. After merging the group data, we form the sub-edges and the faces.The goal of robustness is to implement an algorithm in a manner that guarantees an accurate output for every input. The output of a computational geometry program can have combinatorial and geometric components. In our case, these are the combinatorial structure of the Minkowski sum and the coordinates of its vertices. One error metric, called the forward error, is the distance between the output and the exact answer. Euclidean distance is a fine metric for geometric error, but we are unaware of a useful metric for combinatorial error. Moreover, the forward error conflates the quality of the algorithm, which is what we wish to measure, with the condition of the problem, which is beyond our control. Consequently, numerical analysis eschews forward error in favor of backward error: the minimum distance from the input to an alternative input for which the output is the exact answer. The backward error models computational error identically to measurement error in the input. It models combinatorial and geometric error in the same manner.One robustness strategy  [16], called exact computational geometry (ECG), is to compute combinatorial structure exactly. Since the control logic is expressed in terms of predicates, polynomials whose signs are interpreted as truth values, it suffices to evaluate predicates exactly. Exact evaluation is accelerated by first attempting to resolve the sign with error-bounded floating point arithmetic. This approach works poorly for degenerate predicates, that is predicates whose value is zero. The first problem is that exact evaluation of degenerate predicates is slow because floating point evaluation necessarily fails. The impact on overall running time is large because degenerate predicates are common in real-world inputs, due to symmetry, to design constraints, and to convention. The second problem is that degeneracy creates a third branch at every point in the control logic. These branches are typically ignored in theoretical analysis because they contribute nothing fundamental to the algorithm. Yet they must be handled by a robust implementation.A second robustness strategy  [17], called controlled perturbation (CP), eliminates degenerate predicates by adding a random perturbation in[−δ,δ]to each input parameter. The algorithm is executed with error-bounded floating point predicate evaluation. If all the predicates are resolved, the output is returned; otherwise, the algorithm is rerun. Since every predicate is correct in the final run, the combinatorial structure is correct and the backward error is bounded by the finalδ. CP avoids the slowness of ECG because most predicates are resolved after even a tiny input perturbation. Whereas ECG forces the program to handle degenerate predicates, CP allows the program to ignore them, since they cannot occur in the final run.The problem with CP is that a largeδis required to resolve a singular predicate (zero value and zero gradient), in particular10−5for Minkowski sums of polyhedra  [2]. We  [3] solve this problem with a variant of CP, called adaptive controlled perturbation (ACP), in whichδis user-specified and predicates are evaluated exactly on the perturbed input. We evaluate predicates in floating point interval arithmetic. If the interval does not contain zero, the sign is resolved. Otherwise, we re-evaluate in extended precision interval arithmetic, starting with quad-double and doubling the precision until the sign is resolved or until a maximum precisionpis exceeded. Exceedingpindicates that the predicate is degenerate or nearly degenerate for the perturbed input. We change the random seed and doublepto handle both cases, and restart the algorithm.The CPU implementation of the ACP strategy is straightforward. The coordinates of the vertices ofAandBare the input parameters, hence are perturbed. The coordinates of the other vertices are defined parameters. These vertices store their coordinates as floating point intervals and also store pointers to their defining vertices. A convolution vertex points to itsAandBvertices. An EF-vertex points to its convolution edge and facet. An FFF-vertex points to its three facets. ACP uses these pointers to increase the precision of a vertex by recursively increasing the precision of its defining vertices then recomputing the intervals of its coordinates. Precision is increased solely when a predicate cannot be resolved in floating point and is decreased immediately to avoid storage of extended precision data. The GPU version of ACP is described in the Appendix.

@&#CONCLUSIONS@&#
