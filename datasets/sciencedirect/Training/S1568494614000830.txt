@&#MAIN-TITLE@&#
Establishing Nash equilibria of strategic games: a multistart Fuzzy Adaptive Simulated Annealing approach

@&#HIGHLIGHTS@&#
Presents an optimization application to a relevant and large class of strategic games.Automatically finds all Nash equilibria for a difficult test set composed of several strategic games.Overcomes previous related computational results.

@&#KEYPHRASES@&#
Nash equilibria,Economic games,Simulated annealing,Fuzzy ASA,Soft computing,Space-filling curves,

@&#ABSTRACT@&#
This paper's proposal is to show some significant results obtained by the application of the optimization algorithm known as Fuzzy Adaptive Simulated Annealing (Fuzzy ASA) to the task of finding all Nash equilibria of normal form games. To that end, a special version of Fuzzy ASA, that utilizes space-filling curves to find good seeds, is applied to several well-known strategic games, showing its effectiveness in obtaining all Nash equilibria in all cases. The results are compared to previous work that also used computational intelligence techniques in order to solve the same problem but could not find all equilibria in all tests. Game theory is a very important subject, modeling interactions between generic agents, and Nash equilibrium represents a powerful concept portraying situations in which joint strategies are optimal in the sense that no player can benefit from changing her/his strategy while the other players do not change their strategies as well. So, new techniques are always welcome, mainly those that can find the whole set of solutions for a given strategic game.

@&#INTRODUCTION@&#
In principle, game theory aims to model socio-economic phenomena and the evolution of the interaction between agents (usually known as players), whose specific actions can interfere in the overall process – in general, the decision of a given player can change the course of the whole game. The basic assumptions are that players will track well-defined targets (typically modeled by payoff functions) and use their a priori expectations about the other players’ possible decisions in order to reach their final objectives. Game theory was applied to many areas, including computer game programming, biology, management, and mainly microeconomics, that seems to be until now its most significant source of problems.As game theory is an important analytical tool aimed at studying a large variety of human interactions in which the final results depend on the joint strategies taken by several agents, an equilibrium is considered a good model for a stable outcome of a given game. Although there exist a variety of candidate equilibrium concepts in the literature, Nash equilibrium is seen as the most important one and almost surely the most studied. A Nash equilibrium is a set of strategies such that (at that special configuration) each player's strategy is an optimal response to the other players’ strategies [12,13,15] – the concept captures a special kind of steady state of a strategic game, in which each player acts rationally and holds (presumedly) correct expectations with respect to the other players.Taking into account that computation of Nash equilibria of complex normal form games is a nontrivial problem, several algorithms were synthesized over the years to compute them [12,13,19,21]. In addition, it is possible to find many recent works solving similar problems [2–4,7,8,11]. Other methods for solving finite games are implemented in the Gambit package [14], that contains a programming library and associated software tools for the construction and analysis of extensive and normal form games – some of the example games distributed with Gambit were used as test objects to assess the method described in this paper.The adequate method for computing Nash equilibria of finite games depends on several factors, including whether you need to find pure or mixed strategy equilibria, or want to find only one or all equilibria. So, we can define a solution as a systematic description of the outcomes that may emerge in a game [19] and in this paper we consider exclusively strategic (normal form) games.The optimization method used in this paper to find Nash equilibria of strategic games can be considered an evolution of the original ASA method [5], taking into account that, despite of its widespread utilization and efficacy, the latter did not approach the global optima of specific cost functions, under certain conditions. Because of this, a fuzzy controller was incorporated to the original implementation of ASA, and was shown to be effective in several occasions, as amply exemplified in [18] – this version is known as Fuzzy ASA, and uses the concept of quenching for the sake of avoiding “bad” attraction basins (neighborhoods without global optima). It is worth to highlight that it uses the built-in infrastructure of ASA to operate, changing specific ASA parameters in run-time so as to direct the optimization process, aiming not to be caught in suboptimal regions. In [16] some improvements were incorporated again, in terms of obtaining better starting points, in a deterministic fashion. The enhancement is based on the use of α-dense curves, that are intended to be approximations of abstract space-filling curves. In [17] another different, but related, method was introduced, aimed again at finding good “seeds” in a deterministic way, this time using space-filling curves. In that paper it was shown how to synthesize new space-filling curves based upon key theorems of General Topology, and how to implement their approximations in practice. Our intention is to apply this latest implementation in order to solve the main problem, namely, finding all Nash equilibria of generic finite strategic games in normal form, drawing conclusions about its efficacy in this special task.Considering that the problem of finding Nash equilibria of a finite strategic game admits different alternative formulations, it is worth to say that computing such solutions remains a difficult task and, besides, algorithms unable to compute several (or all) Nash equilibria can be unsatisfactory for many practical uses.Although the above mentioned problem (finding Nash equilibria of finite normal form games) can be solved by finding fixed points of certain functions [13], one of the most significant presently known theoretical results is that the problem of computing a Nash equilibrium can be faced as a global optimization one [12,13,20]. This approach opens a new universe of possible methods of solution for the problem at hand, considering the large number of effective optimization methods available in the literature, especially those using computational intelligence methods, such as genetic algorithms, particle swarm optimization, or differential evolution.In this article, our aim is to demonstrate that the optimization algorithm known as Fuzzy Adaptive Simulated Annealing (Fuzzy ASA, for short) is effective in approximating Nash equilibria for finite strategic games, being able to overcome other powerful methods [9,10,20] in finding all solutions for a given game. To reach our aim, the six test games used in [20] were employed here as well, so as to make it possible to compare the two methods – the main focus is on showing that the proposed method can find all equilibria in all runs. As Fuzzy ASA is not population-based, we employed a multistart version that consists of applying a preprocessing stage based on space-filling curves and is able to find several “promising” starting points, so as to escape from suboptimal minima, trying to get to the various global minimizers corresponding to the desired Nash equilibria. In what follows the paper will describe the Fuzzy ASA paradigm, its application to the underlying problem and the obtained results, to be interpreted at the end.Fuzzy Adaptive Simulated Annealing is based on the ASA method [5] that, on its turn, uses the simulated annealing concept [1], but presenting a significant number of improvements. Here, we describe only a few of them.It is the dynamical re-scaling of parametric temperatures, adapting generating probability distribution functions to each dimension according to different sensitivities. In a few words, if the objective function does not present significative variations whenever a given parameter is altered, it could be advantageous to extend the search interval amplitude in that dimension in particular, and vice-versa.The ASA implementation offers the possibility of adjusting several structural parameters related to the quenching process, allowing the user or any automatic control mechanism to change the default behavior of the “cooling” process and drive the evolution of the parametric temperatures. This device is useful in case of stagnation near suboptimal regions.The ASA system was idealized so as to allow users to alter virtually any subsystem without significant programming effort. This way, it is possible to change the behavior of generation/acceptance processes, termination criteria, or seed generation.ASA was designed to find function minimizers inside a pre-established hyperrectangle and generates points componentwise, according to the following scheme:xi+1=xi+Δxi, with Δxi=yi(Bi−Ai),[Ai, Bi]=interval corresponding to ith dimension,yi∈[−1, 1] is given byyi=sign(ui−1/2)Ti[(1+1/Ti)|2ui−1|−1],where ui∈[0, 1] is generated by means of the uniform distribution, and Ti= present temperature relative to dimension i.The compactness of search space is not a severe limitation in practice and, in the absence of previous information about optima location, it suffices to choose sufficiently ample hyper-rectangular domains. As cited before, the quenching mechanism can improve, in many cases, the efficiency of the convergence process, although there is always the possibility of reaching prematurely nonglobal extrema. In certain contexts, however, we may simply not have alternative ways out of a stagnation situation. In order to overcome this difficulty, a fuzzy controller was designed (Fuzzy ASA) [16,18]. The approach is simple: the original ASA system is seen as a MISO (Multiple Input Single Output) dynamical system and the supplementary code simply “closes the loop”, by sampling its output (current value of objective function) and acting in its inputs (a subset of run-time adjustable parameters, related to the quenching process) according to a fuzzy law (control algorithm), imitating human behavior whenever subject to similar underlying situations. In this way, active run-time fuzzy control coupled to previously existing ASA mechanisms can regulate temperature evolution, besides being able to take evasive actions in case of premature convergence. In its present version, Fuzzy ASA code rises the quenching degree after detecting decreasing optimization performance or potential stagnation states, aiming to recover from a possible undesirable convergence to nonglobal optima. It is worth to note that this additional module does not try to substitute the many effective devices already present in the “standard” ASA code, just complementing them in atypical situations. Fig. 1depicts how Fuzzy ASA is structured.As in other methods for optimization of arbitrary numerical functions [23], ASA and Fuzzy ASA techniques could benefit from the choice of good starting points. Accordingly, it would be helpful to have a preprocessing step that could find a small set of good seeds, avoiding convergence to suboptimal regions and, besides, making it possible to find multiple global minimizers in only one run. To get this benefit, a preprocessing device based on space-filling curves was recently synthesized and is fully described in Refs. [17,18]. As its effectiveness is based upon the ability to visit all regions of multidimensional configuration spaces, it is also important to say that, although there are several space-filling curves able to filling up multidimensional domains, at least in theory, the respective numerical approximations can, and in fact frequently do, exhibit holes because of truncation or limitations of present day computing paradigms. It is worth to highlight that an important qualitative property of space-filling curves is their ability to “sweep” deterministically high–dimensional domains, so as to improve the likelihood of finding good “seeds” for posterior optimization stages, taking into account the existence of several methods whose final results depend strongly upon their starting points. In this fashion, it is of interest to investigate new ways of finding adequate starters, particularly those located in attraction basins of global optima. Some sample points of a typical 2-dimensional space-filling curve in different resolutions are shown in Fig. 2. They represent discretizations in different levels, in order to illustrate their ability to fill a higher dimensional space.Despite the fact that this front end can be used together with any optimization method, in this article we use the fuzzy adaptive simulated annealing algorithm, taking into account its excellent performance in difficult optimization tasks and the robustness of that method. In this paper, by a space-filling curve we mean a surjective and continuous function from a real interval, [0,1] for example, to a compact subset of a finite-dimensional vector space, which can be identified toℝn, the n-dimensional Euclidean space. Space-filling curves were fully studied in the past and there are many theoretical results stating necessary conditions for their existence [22]. Besides, long time before the invention of digital computers, mathematicians proposed constructive examples and established several interesting properties of space-filling curves. More recently, researchers have found additional ways to apply previous knowledge about these curves to various important areas, including optimization of numerical functions. Here, the underlying idea is to compose a given objective function with a space-filling curve corresponding to a compact superset of the respective domain. In this fashion it is possible to reduce a multivariate problem to a univariate one. Hence, at least in theory, it would be possible, by solving the auxiliary one-dimensional problem, to come back to the n-dimensional domain and find the desired optimum point. Unfortunately, such ideas are difficult to implement even in the present, because some complications arise, particularly in high-dimensional configuration spaces. The main difficulty regarding implementation issues is that virtually all curves idealized in the far past did not take into account the finite word length of digital computers (one good reason for this is that digital computers were invented long after their synthesis).Before closing this section, it is worth citing that ASA and its variations, like Fuzzy ASA for example, have been applied to several important fields of knowledge, such as Signal Processing, Geophysics, or Statistics (please, see [5,6,16–18] and references therein). This is so because, in practically all scientific domains, it is possible to transform certain design tasks into parametric optimization ones by synthesizing cost functions that are able to convey all necessary constraints, and whose optimizers correspond to adequate solutions to the initial problems.A strategic game is a generic model for the interaction between agents, that can also be called decision makers and are usually referred to as players. In each move, a given player chooses a specific alternative to take in a certain set of possible actions. The model describes interactions between the players by means of functions that quantify the mutual effect of the actions of all players and their rewards (payoff functions). In more precise terms, a strategic game can be defined in the following way:A finite strategic game (with pure strategies) is composed of three elements:•A finite set {1, 2, …, N} of players.A set of sets of actions Si, or pure strategies, so that each player is associated to a finite group of moves he or she can take. So, we haveSi={si1,…,simi},where miis the number of actions available to player i.Also, we denote by a−ithe profile (a1, …, ai−1, ai+1, …, aN) obtained from (a1, …, ai−1, ai, ai+1, …, aN) by excluding the action of player i. In addition, the notation (ai, a−i) is used to represent the complete profile of actions.A set of payoff functions, one for each player, as followsui:S→ℝwhereS=S1×S2×…×SN.These functions map each configuration of actions to a real value.Strategic games are able to model a very large range of practical situations. In many cases we can have the players representing firms, the actions could be possible acquisitions to be made, and the payoff function the resulting profits relative to the final choices. Another context could be, for example, a group of competing football teams (players), each one trying to hire one (football) player among several others (possible actions), and the payoff would be the final result in the championship. Yet another situation is a fight between two boxers (players) that have to decide about a finite set of actions to take in order to score or defeat definitely the adversary (knockout), that corresponds to the payoff. It is important to highlight that time has no significance in this fundamental model, so that the players choose their actions once and for all, without relative time delays or related things, in the sense that no player is informed about the actions chosen by other players, that is to say, we are talking about simultaneous move games. However, in certain kinds of games an action may involve activities that extend over time, and might have to take into account a complex set of conditions. In this fashion, an action is also known as a strategy. On the other hand, the fact that time has no influence in the model means that when analyzing a given phenomenon as a strategic game, we disregard the complications that may arise if players are allowed to change their minds as events evolve: it is assumed that actions are chosen once and for all.A central question in game theory is trying to predict what actions will be chosen by players in a particular situation. It is usual to assume that each player chooses the best available (more profitable) action. The best action for any given player tends to depend, in general, on the other players’ actions. So, when choosing an action a player must take into account the actions that the other players can choose. That is, they must construct a belief about the other players’ actions. Consequently, it is interesting to investigate in what situations can such a belief be synthesized. The assumption underlying the analysis is that each player can estimate a certain degree of belief from the past experience playing the game, and that this previous knowledge is sufficient to predict how the opponents will behave, at least approximately – this ability will make it possible to enrich the model with mixed strategies. It is a fact that no one tells a given player the actions the opponents will choose, but the previous involvement in the game leads players to be sure of these actions. So, the usual mechanism for solving this type of problem is based on each player choosing a specific action according to a rational reasoning, given the belief about the other players’ behavior, assuming that every player's belief about the other players’ actions is correct. These two ingredients are contained in the usual definition of a Nash equilibrium, that can be informally formulated by saying that it is an action profile with the property that no player can do better by choosing an action distinct from the present configuration. In this way, when playing the game and the action profile gets to a Nash equilibrium, no player has a rational motivation for choosing any action different from his or her current position, that is to say, there is no advantage in changing. Viewed from another angle, Nash equilibria express stable social situations, in the sense that if all the players adhere to it, no one is going to deviate from that favorable situation. The other basic assumption of the theory, that players’ beliefs about each other's actions are correct implies, in particular, that two players’ beliefs about a third player's action tend to be the same. Because of this, it is sometimes said that the players’ expectations are coordinated. In general, the situations to which we wish to apply the theory of Nash equilibrium do not correspond exactly to certain idealized settings. This means that in some cases the players might not have enough experience with the game, and in others they may not view each play of the game in a proper way. So, the notion of Nash equilibrium can be appropriate in many situations, but, of course, there are opportunities in which it will be better to choose another concept to represent a specific type of equilibrium.Now the notation to be used in the rest of the paper will be defined – the following is based on [20]. We represent by Δithe set of probability mass functions on Siand by Δ the Cartesian product∏i=1NΔi. In this fashion, we see thatΔ⊂ℝm(m=∑i=1Nmi)and the elements of Δihave finite domains, being real valued functions defined on Si, symbolicallypi:Si→ℝ.Besides, they necessarily satisfy∑sij∈Sipi(sij)=1with pi(sij)≥0.The notation sijwill be used to represent strategies pi∈Δifor which pi(sij)=1, that is to say, it is a representation for pure strategy profiles. In this fashion, (sij, p−i) is the state in which player i chooses pure strategy sij(100 % of belief).In order to allow the forementioned “degrees of belief” enter the model, the use of mixed strategies is fundamental. So, the role played by the piis exactly that – the players will be able to assign different “weights” to each possible action of all players by adjusting them, making it possible to calculate an extended, aggregate payoff function (for each player i) that is a kind of expected value of each possible configuration of the game. This function is defined below for player i:(1)Ui(p)=Δ∑s∈Sp(s)ui(s)where(2)p(s)=∏i=1Npi(si)and(3)s=(s1,s2,…,sn)Finally, now comes the formal definition of a Nash equilibrium.A mixed strategy profilep*=(p1*,p2*,…,pN*)∈Δis a Nash equilibrium ifUi(pi,p−i*)≤Ui(p*)for all i=1, …, N and pi∈Δi.This definition means that for a strategy profile p* to be a Nash equilibrium it is necessary that no player has an action resulting in a better payoff than she or he receives by choosingpi*, assuming that the other players do maintain their positions aspj*(j≠i). In other words, in that special configuration any isolated deviation is damaging.As stated before, we can find a Nash equilibrium of a normal form game by means of the global minimization of a real valued function [12]. In that approach, three auxiliary matrix functions, x, z and g, are defined and give rise to the overall cost function, that is the key for finding Nash equilibria for a given finite, normal form game. They are presented below:(4)xij(p)=ΔUi(sij,p−i)(5)zij(p)=Δxij(p)−Ui(p)(6)gij(p)=Δmax(zij(p),0)for p∈Δ.The overall cost function is(7)v(p)=Δ∑i=1N∑j=1mi(gij(p))2,p∈Δ.As cited before, p* is a Nash equilibrium if and only if it is a global minimum ofvin Δ (Refs. [12,13,20]), orv(p*)=0, taking into account thatv(p)≥0.This paper addresses the problem of finding all global minima of the functionv, defined by (7).To demonstrate the effectiveness of the proposed method we will compare our results to those presented in [20], that is a very interesting paper, evidencing the power and simplicity of computational intelligence methods when compared to traditional ones. However, the assessment will be focused on the effectiveness of the methods, meaning that a given method will be considered fully effective if and only if it is always able to find all minimizers of (7), doing that in 100% of the runs, even though its working principle could be of a stochastic nature, like Fuzzy ASA, for example. In this sense, our aim is different from theirs. In this direction, we chose to use the same test set that the cited paper, making it possible to compare in a fair way the two approaches. The mentioned test set is composed of six different games and the performance of the algorithm on finding Nash equilibria was studied in all of them, which are included in the latest stable version of the excellent GAMBIT software package [14]. GAMBIT can be freely downloaded from http://www.gambit-project.org.All games present more than one Nash equilibria and in all problems the fundamental goal is to detect, if possible, all the equilibria. To obtain the list of Nash equilibria of each game, the GAMBIT package was used and, in what follows, the test problems are identified and their equilibria and payoff functions shown, making it easier for the reader to evaluate the whole apparatus. Besides, each game has a corresponding GAMBIT file containing its precise definition, and the reader may obtain more information about them by examining the respective material.As stated before, the proposed algorithm for finding the whole set of Nash equilibria for a given game is totally based on the minimization ability of (Fuzzy) ASA, coupled to an effective seed finder. In our case, that role is played by space-filling curves in the preliminary phase, based on sampling the cost function domain by means of an adjustable discretization process. That is to say, the minimization process starts by deterministically exploring the objective function domain, trying to detect promising (low cost value) starting points for the main minimization algorithm. The cardinality of the set of seeds is adjustable in our implementation and normally should be set according to the dimension of the problem – the higher the domain dimension, the higher the corresponding cardinality. Another parameter to be set is the number of function evaluations we are willing to spend in the first, exploratory phase – more dimensions mean more function evaluations, once that (intuitively, at least) we have more territory to inspect.In summary, we have the following general algorithm:•Set Fuzzy ASA and initial sampling parameters, according to problem dimension;Start the minimization process;Examine whether a satisfactory number of Nash equilibria were found;If not, adjust parameters and re-run the process from the beginning.Before the mathematical definition of the games used for assessing the proposed method, it is worth to say that, despite their “dry” aspect, they really can represent real world problems and help in the respective solutions. Their most obvious applications are in the microeconomic area, modeling several contexts, like duopolies, oligopolies and several other market conflicts. Hence, in each case, the players model the competitors, the payoff functions quantify the individual gains in each possible scenario, and each Nash equilibrium represents a sustainable condition in which each player could stay with a certain degree of stability.Test Problem 1. It is a normal form game, with 4 players and 2 pure strategies available to each one. The game presents three equilibria and the corresponding GAMBIT specification file is 2x2x2x2.nfg.The equilibria set found by using Gambit is given by•(1, 0, 1, 0, 1, 0, 0, 1)(0.1004, 0.8996, 0, 1, 0, 1, 0.2699, 0.7301)(0, 1, 1, 0, 0, 1, 1, 0)First playeru1(1,1,1,1)=1.131,u1(1,1,1,2)=2.326u1(1,1,2,1)=1.223,u1(1,1,2,2)=5.255u1(1,2,1,1)=4.452,u1(1,2,1,2)=2.747u1(1,2,2,1)=4.564,u1(1,2,2,2)=5.634u1(2,1,1,1)=4.225,u1(2,1,1,2)=1.478u1(2,1,2,1)=4.483,u1(2,1,2,2)=4.383u1(2,2,1,1)=7.566,u1(2,2,1,2)=1.759u1(2,2,2,1)=7.247,u1(2,2,2,2)=4.642Second playeru2(1,1,1,1)=1.210,u2(1,1,1,2)=2.422u2(1,1,2,1)=1.358,u2(1,1,2,2)=5.334u2(1,2,1,1)=4.549,u2(1,2,1,2)=2.243u2(1,2,2,1)=4.326,u2(1,2,2,2)=5.675u2(2,1,1,1)=5.277,u2(2,1,1,2)=2.544u2(2,1,2,1)=5.764,u2(2,1,2,2)=1.436u2(2,2,1,1)=4.655,u2(2,2,1,2)=2.705u2(2,2,2,1)=4.943,u2(2,2,2,2)=1.897Third playeru3(1,1,1,1)=2.426,u3(1,1,1,2)=3.222u3([1,1,2,1)=2.234,u3([1,1,2,2)=2.643u3([1,2,1,1)=1.655,u3([1,2,1,2)=3.518u3([1,2,2,1)=1.762,u3([1,2,2,2)=2.455u3([2,1,1,1)=4.837,u3([2,1,1,2)=1.973u3([2,1,2,1)=4.995,u3([2,1,2,2)=4.864u3([2,2,1,1)=7.076,u3([2,2,1,2)=1.735u3([2,2,2,1)=7.362,u3([2,2,2,2)=4.042Fourth playeru4(1,1,1,1)=2.429,u4(1,1,1,2)=3.024u4([1,1,2,1)=2.238,u4([1,1,2,2)=2.873u4([1,2,1,1)=1.347,u4([1,2,1,2)=3.062u4([1,2,2,1)=1.576,u4([1,2,2,2)=6.523u4([2,1,1,1)=5.645,u4([2,1,1,2)=7.486u4([2,1,2,1)=5.754,u4([2,1,2,2)=5.267u4([2,2,1,1)=4.423,u4([2,2,1,2)=4.043u4([2,2,2,1)=4.382,u4([2,2,2,2)=3.830Test Problem 2. Four person, normal form game, with 2 pure strategies available to each player. The game has 5 mixed equilibria and the corresponding GAMBIT specification file is g3.nfg. The equilibria set found by using Gambit is given by•(0.2, 0.8, 1, 0, 1, 0, 0.6667, 0.3333)(1, 0, 1, 0, 0.4286, 0.5714, 0.8, 0.2)(1, 0, 0.5643, 0.4357, 0.5318, 0.4682, 0.4255, 0.5745)(0.6318, 0.3682, 1, 0, 0.6338, 0.3662, 0.5872, 0.4128)(0.7111, 0.2889, 0.6938, 0.3062, 0.6201, 0.3799, 0.3646, 0.6354)First playeru1([1,1,1,1)=−3,u1([1,1,1,2)=−3u1([1,1,2,1)=−4,u1([1,1,2,2)=−2u1([1,2,1,1)=−3,u1([1,2,1,2)=−3u1([1,2,2,1)=−4,u1([1,2,2,2)=−1u1([2,1,1,1)=−4,u1([2,1,1,2)=−1u1([2,1,2,1)=−4,u1([2,1,2,2)=−3u1([2,2,1,1)=−1,u1([2,2,1,2)=−1u1([2,2,2,1)=−6,u1([2,2,2,2)=−8Second playeru2([1,1,1,1)=−4,u2([1,1,1,2)=−6u2([1,1,2,1)=−2,u2([1,1,2,2)=−4u2([1,2,1,1)=−5,u2([1,2,1,2)=−2u2([1,2,2,1)=−7,u2([1,2,2,2)=−4u2([2,1,1,1)=−5,u2([2,1,1,2)=−3u2([2,1,2,1)=−3,u2([2,1,2,2)=−6u2([2,2,1,1)=−8,u2([2,2,1,2)=−6u2([2,2,2,1)=−3,u2([2,2,2,2)=−5Third playeru3([1,1,1,1)=−1,u3([1,1,1,2)=−6u3([1,1,2,1)=−2,u3([1,1,2,2)=−2u3([1,2,1,1)=−3,u3([1,2,1,2)=−3u3([1,2,2,1)=−6,u3([1,2,2,2)=−5u3([2,1,1,1)=−3,u3([2,1,1,2)=−3u3([2,1,2,1)=−4,u3([2,1,2,2)=−6u3([2,2,1,1)=−3,u3([2,2,1,2)=−2u3([2,2,2,1)=−1,u3([2,2,2,2)=−5Fourth playeru4([1,1,1,1)=−6,u4([1,1,1,2)=−2u4([1,1,2,1)=−3,u4([1,1,2,2)=−6u4([1,2,1,1)=−5,u4([1,2,1,2)=−5u4([1,2,2,1)=−1,u4([1,2,2,2)=−3u4([2,1,1,1)=−3,u4([2,1,1,2)=−4u4([2,1,2,1)=−2,u4([2,1,2,2)=−7u4([2,2,1,1)=−3,u4([2,2,1,2)=−1u4([2,2,2,1)=−2,u4([2,2,2,2)=−5Test Problem 3. This is a 5 player game, with two pure strategies available to each player. The game is characterized by 5 Nash equilibria. The corresponding GAMBIT file is 2x2x2x2x2.nfg and the equilibria set found by using Gambit is given by•(0.1441, 0.8559, 0.2584, 0.7416, 1, 0, 1, 0, 0, 1)(0, 1, 0, 1, 1, 0, 0.7959, 0.2041, 0.5589, 0.4411)(1, 0, 0, 1, 0.1528, 0.8472, 0.6990, 0.3010, 1, 0)(1, 0, 0, 1, 0, 1, 0.1185, 0.8815, 0.5564, 0.4436)(1, 0, 0.2300, 0.7700, 0.6311, 0.3689, 0.6994, 0.3006, 1, 0)First playeru1(1,1,1,1,1)=7.247,u1(1,1,1,1,2)=4.943u1(1,1,1,2,1)=4.837,u1(1,1,1,2,2)=5.645u1(1,1,2,1,1)=1.759,u1(1,1,2,1,2)=2.705u1(1,1,2,2,1)=3.518,u1(1,1,2,2,2)=3.062u1(1,2,1,1,1)=1.223,u1(1,2,1,1,2)=1.358u1(1,2,1,2,1)=1.762,u1(1,2,1,2,2)=1.576u1(1,2,2,1,1)=4.120,u1(1,2,2,1,2)=4.976u1(1,2,2,2,1)=4.864,u1(1,2,2,2,2)=5.267u1(2,1,1,1,1)=2.537,u1(2,1,1,1,2)=2.417u1(2,1,1,2,1)=2.355,u1(2,1,1,2,2)=5.347u1(2,1,2,1,1)=2.778,u1(2,1,2,1,2)=1.646u1(2,1,2,2,1)=1.740,u1(2,1,2,2,2)=4.192u1(2,2,1,1,1)=2.675,u1(2,2,1,1,2)=2.238u1(2,2,1,2,1)=2.426,u1(2,2,1,2,2)=2.429u1(2,2,2,1,1)=2.747,u1(2,2,2,1,2)=2.243u1(2,2,2,2,1)=2.643,u1(2,2,2,2,2)=2.873Second playeru2(1,1,1,1,1)=7.362,u2(1,1,1,1,2)=4.382u2(1,1,1,2,1)=1.478,u2(1,1,1,2,2)=2.544u2(1,1,2,1,1)=1.735,u2(1,1,2,1,2)=4.043u2(1,1,2,2,1)=1.131,u2(1,1,2,2,2)=1.210u2(1,2,1,1,1)=2.234,u2(1,2,1,1,2)=2.238u2(1,2,1,2,1)=5.634,u2(1,2,1,2,2)=5.675u2(1,2,2,1,1)=7.324,u2(1,2,2,1,2)=7.723u2(1,2,2,2,1)=1.428,u2(1,2,2,2,2)=1.521u2(2,1,1,1,1)=1.427,u2(2,1,1,1,2)=1.624u2(2,1,1,2,1)=2.798,u2(2,1,1,2,2)=1.403u2(2,1,2,1,1)=2.342,u2(2,1,2,1,2)=1.640u2(2,1,2,2,1)=3.803,u2(2,1,2,2,2)=2.685u2(2,2,1,1,1)=1.132,u2(2,2,1,1,2)=1.985u2(2,2,1,2,1)=2.326,u2(2,2,1,2,2)=2.422u2(2,2,2,1,1)=3.518,u2(2,2,2,1,2)=3.062u2(2,2,2,2,1)=4.564,u2(2,2,2,2,2)=4.326Third playeru3(1,1,1,1,1)=4.642,u3(1,1,1,1,2)=1.897u3(1,1,1,2,1)=1.973,u3(1,1,1,2,2)=7.486u3(1,1,2,1,1)=4.452,u3(1,1,2,1,2)=4.549u3(1,1,2,2,1)=2.426,u3(1,1,2,2,2)=2.429u3(1,2,1,1,1)=5.255,u3(1,2,1,1,2)=5.334u3(1,2,1,2,1)=2.455,u3(1,2,1,2,2)=6.523u3(1,2,2,1,1)=4.483,u3(1,2,2,1,2)=5.764u3(1,2,2,2,1)=4.248,u3(1,2,2,2,2)=4.533u3(2,1,1,1,1)=4.542,u3(2,1,1,1,2)=4.572u3(2,1,1,2,1)=2.832,u3(2,1,1,2,2)=1.380u3(2,1,2,1,1)=2.164,u3(2,1,2,1,2)=5.349u3(2,1,2,2,1)=3.464,u3(2,1,2,2,2)=2.678u3(2,2,1,1,1)=5.369,u3(2,2,1,1,2)=5.395u3(2,2,1,2,1)=3.222,u3(2,2,1,2,2)=3.024u3(2,2,2,1,1)=1.223,u3(2,2,2,1,2)=1.358u3(2,2,2,2,1)=1.762,u3(2,2,2,2,2)=1.576Fourth playeru4(1,1,1,1,1)=4.042,u4(1,1,1,1,2)=3.830u4(1,1,1,2,1)=7.566,u4(1,1,1,2,2)=4.655u4(1,1,2,1,1)=1.655,u4(1,1,2,1,2)=1.347u4(1,1,2,2,1)=2.326,u4(1,1,2,2,2)=2.422u4(1,2,1,1,1)=2.643,u4(1,2,1,1,2)=2.873u4(1,2,1,2,1)=1.335,u4(1,2,1,2,2)=1.734u4(1,2,2,1,1)=4.995,u4(1,2,2,1,2)=5.754u4(1,2,2,2,1)=5.231,u4(1,2,2,2,2)=5.458u4(2,1,1,1,1)=7.577,u4(2,1,1,1,2)=7.969u4(2,1,1,2,1)=3.974,u4(2,1,1,2,2)=2.793u4(2,1,2,1,1)=2.243,u4(2,1,2,1,2)=5.056u4(2,1,2,2,1)=1.323,u4(2,1,2,2,2)=4.792u4(2,2,1,1,1)=4.669,u4(2,2,1,1,2)=4.274u4(2,2,1,2,1)=4.452,u4(2,2,1,2,2)=4.549u4(2,2,2,1,1)=2.234,u4(2,2,2,1,2)=2.238u4(2,2,2,2,1)=5.634,u4(2,2,2,2,2)=5.675Fifth playeru5(1,1,1,1,1)=4.225,u5(1,1,1,1,2)=5.277u5(1,1,1,2,1)=7.076,u5(1,1,1,2,2)=4.423u5(1,1,2,1,1)=2.747,u5(1,1,2,1,2)=2.243u5(1,1,2,2,1)=3.222,u5(1,1,2,2,2)=3.024u5(1,2,1,1,1)=4.564,u5(1,2,1,1,2)=4.326u5(1,2,1,2,1)=4.434,u5(1,2,1,2,2)=4.271u5(1,2,2,1,1)=4.383,u5(1,2,2,1,2)=1.436u5(1,2,2,2,1)=4.486,u5(1,2,2,2,2)=4.882u5(2,1,1,1,1)=2.236,u5(2,1,1,1,2)=5.174u5(2,1,1,2,1)=3.575,u5(2,1,1,2,2)=2.269u5(2,1,2,1,1)=1.473,u5(2,1,2,1,2)=4.580u5(2,1,2,2,1)=1.214,u5(2,1,2,2,2)=4.462u5(2,2,1,1,1)=1.131,u5(2,2,1,1,2)=1.210u5(2,2,1,2,1)=1.655,u5(2,2,1,2,2)=1.347u5(2,2,2,1,1)=5.255,u5(2,2,2,1,2)=5.334u5(2,2,2,2,1)=2.455,u5(2,2,2,2,2)=6.523Test Problem 4. This is a normal form game with 3 players and 2 pure strategies available to each player. This game presents 9 Nash equilibria. However, the latest available graphical version of Gambit at the time of this writing (0.2007.12.04) was able to find only seven points, terminating abnormally with a warning message. Consequently, we will list below only the seven ones found by Gambit. The two missing equilibria were found (by the proposed method) to be (0.4,0.6,0.5,0.5,1/3,2/3) and (0.5,0.5,0.4,0.6,0.25,0.75). The corresponding GAMBIT file is 2x2x2.nfg.The equilibria set found by using Gambit is given by•(1,0,1,0,1,0)(1,0,0,1,0,1)(0,1,0,1,1,0)(0,1,1,0,0,1)(0,1,0.25,0.75,0.3333,0.6667)(0.5,0.5,0.5,0.5,1,0)(0.3333,0.6667,1,0,0.25,0.75)First playeru1(1,1,1)=9u1(1,1,2)=0u1(1,2,1)=0u1(1,2,2)=3u1(2,1,1)=0u1(2,1,2)=3u1(2,2,1)=9u1(2,2,2)=0Second playeru2(1,1,1)=8u2(1,1,2)=0u2(1,2,1)=0u2(1,2,2)=4u2(2,1,1)=0u2(2,1,2)=4u2(2,2,1)=8u2(2,2,2)=0Third playeru3(1,1,1)=12u3(1,1,2)=0u3(1,2,1)=0u3(1,2,2)=6u3(2,1,1)=0u3(2,1,2)=6u3(2,2,1)=2u3(2,2,2)=0Test Problem 5. This is a 3 agent coordination game with 3 strategies available to each player. The game presents 13 equilibria. The GAMBIT file that corresponds to this game is coord333.nfg.The equilibria set found by using Gambit is given by•(1,0,0,1,0,0,1,0,0)(0,0,1,0,0,1,0,0,1)(0,0,1,0,1,0,1,0,0)(0,0,1,1,0,0,0,1,0)(0,1,0,0,0,1,1,0,0)(0,1,0,0,1,0,0,1,0)(0,1,0,1,0,0,0,0,1)(1,0,0,0,1,0,0,0,1)(0.5,0.5,0,0.5,0.5,0,0.5,0.5,0)(0,0.5,0.5,0,0.5,0.5,0,0.5,0.5)(0.5,0,0.5,0.5,0,0.5,0.5,0,0.5)(0.3333,0.3333,0.3333,0.3333,0.3333,0.3333,0.3333,0.3333,0.3333)(1,0,0,0,0,1,0,1,0)First playeru1(1,1,1)=1u1(1,1,2)=0u1(1,1,3)=0u1(1,2,1)=0u1(1,2,2)=0u1(1,2,3)=0u1(1,3,1)=0u1(1,3,2)=0u1(1,3,3)=0u1(2,1,1)=0u1(2,1,2)=0u1(2,1,3)=0u1(2,2,1)=0u1(2,2,2)=1u1(2,2,3)=0u1(2,3,1)=0u1(2,3,2)=0u1(2,3,3)=0u1(3,1,1)=0u1(3,1,2)=0u1(3,1,3)=0u1(3,2,1)=0u1(3,2,2)=0u1(3,2,3)=0u1(3,3,1)=0u1(3,3,2)=0u1(3,3,3)=1Second playeru2(1,1,1)=1u2(1,1,2)=0u2(1,1,3)=0u2(1,2,1)=0u2(1,2,2)=0u2(1,2,3)=0u2(1,3,1)=0u2(1,3,2)=0u2(1,3,3)=0u2(2,1,1)=0u2(2,1,2)=0u2(2,1,3)=0u2(2,2,1)=0u2(2,2,2)=1u2(2,2,3)=0u2(2,3,1)=0u2(2,3,2)=0u2(2,3,3)=0u2(3,1,1)=0u2(3,1,2)=0u2(3,1,3)=0u2(3,2,1)=0u2(3,2,2)=0u2(3,2,3)=0u2(3,3,1)=0u2(3,3,2)=0u2(3,3,3)=1Third playeru3(1,1,1)=1u3(1,1,2)=0u3(1,1,3)=0u3(1,2,1)=0u3(1,2,2)=0u3(1,2,3)=0u3(1,3,1)=0u3(1,3,2)=0u3(1,3,3)=0u3(2,1,1)=0u3(2,1,2)=0u3(2,1,3)=0u3(2,2,1)=0u3(2,2,2)=1u3(2,2,3)=0u3(2,3,1)=0u3(2,3,2)=0u3(2,3,3)=0u3(3,1,1)=0u3(3,1,2)=0u3(3,1,3)=0u3(3,2,1)=0u3(3,2,2)=0u3(3,2,3)=0u3(3,3,1)=0u3(3,3,2)=0u3(3,3,3)=1Test Problem 6. This is a 2 player game with 4 strategies available to each player. This game has a total of 15 Nash equilibria. The corresponding GAMBIT file is coord4.nfg.The equilibria set found by using Gambit is given by•(14/39, 14/39, 7/39, 4/39, 4/25, 6/25, 12/25, 3/25)(0, 14/25, 7/25, 4/25, 0, 2/7, 4/7, 1/7)(14/25, 0, 7/25, 4/25, 4/19,0, 12/19, 3/19)(0, 0, 7/11, 4/11, 0, 0, 4/5, 1/5)(7/16, 7/16, 0, 1/8, 4/13, 6/13, 0, 3/13)(0, 7/9, 0, 2/9, 0, 2/3, 0, 1/3)(7/9, 0, 0, 2/9, 4/7, 0, 0, 3/7)(0,0,0,1, 0,0,0,1)(2/5,2/5,1/5,0, 2/11, 3/11, 6/11, 0)(0, 2/3,1/3,0, 0, 1/3, 2/3,0)(2/3,0,1/3,0,1/4,0,3/4,0)(0,0,1,0,0,0,1,0)(1/2,1/2,0,0,2/5,3/5,0,0)(0,1,0,0,0,1,0,0)(1,0,0,0,1,0,0,0)The payoff functions are defined by:First playeru1(1,1)=3u1(1,2)=0u1(1,3)=0u1(1,4)=0u1(2,1)=0u1(2,2)=2u1(2,3)=0u1(2,4)=0u1(3,1)=0u1(3,2)=0u1(3,3)=1u1(3,4)=0u1(4,1)=0u1(4,2)=0u1(4,3)=0u1(4,4)=4Second playeru2(1,1)=2u2(1,2)=0u2(1,3)=0u2(1,4)=0u2(2,1)=0u2(2,2)=2u2(2,3)=0u2(2,4)=0u2(3,1)=0u2(3,2)=0u2(3,3)=4u2(3,4)=0u2(4,1)=0u2(4,2)=0u2(4,3)=0u2(4,4)=7Now we will present the obtained results and make some comparisons to previous research.

@&#CONCLUSIONS@&#
