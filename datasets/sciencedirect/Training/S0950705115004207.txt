@&#MAIN-TITLE@&#
Learning semantic representation with neural networks for community question answering retrieval

@&#HIGHLIGHTS@&#
Learning the semantic representation using neural network architecture.The neural network is trained via pre-training and fine-tuning phase.The learned semantic level feature is incorporated into a LTR framework.

@&#KEYPHRASES@&#
Community question answering,Question retrieval,Text mining,Yahoo! Answers,

@&#ABSTRACT@&#
In community question answering (cQA), users pose queries (or questions) on portals like Yahoo! Answers which can then be answered by other users who are often knowledgeable on the subject. cQA is increasingly popular on the Web, due to its convenience and effectiveness in connecting users with queries and those with answers. In this article, we study the problem of finding previous queries (e.g., posed by other users) which may be similar to new queries, and adapting their answers as the answers to the new queries. A key challenge here is to the bridge the lexical gap between new queries and old answers. For example, “company” in the queries may correspond to “firm” in the answers. To address this challenge, past research has proposed techniques similar to machine translation that “translate” old answers to ones using the words in the new queries. However, a key limitation of these works is that they assume queries and answers are parallel texts, which is hardly true in reality. As a result, the translated or rephrased answers may not look intuitive.In this article, we propose a novel approach to learn the semantic representation of queries and answers by using a neural network architecture. The learned semantic level features are finally incorporated into a learning to rank framework. We have evaluated our approach using a large-scale data set. Results show that the approach can significantly outperform existing approaches.

@&#INTRODUCTION@&#
With the development of Web 2.0, community question answering (cQA) services like Yahoo! Answers,11http://answers.yahoo.com/Baidu Zhidao22http://zhidao.baidu.com/and WkiAnswers33http://wiki.answers.com/have attracted both academia and industry great attention [1–3]. In cQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions.One fundamental task for reusing content in cQA is finding the existing answers for queries, as query-answer pairs are the keys to accessing the knowledge in cQA. Many studies have been done along this line [1,2,4–10]. One big challenge for community question answering retrieval is the lexical gap between queries and answers in the archives. Lexical gap means that the queries may contain words that are different from, but related to, the words in the answers. For example, if an user’s query contains the word “company” but a target answer contains the word “firm”, then there is a lexical gap and the target answer may easily regarded as an irrelevant one. This lexical gap has become a major barricade preventing traditional IR models (e.g., BM25 [11]) from retrieving the target answers in cQA.To solve the lexical gap problem, previous work in the literature proposed a method to leverage query-answer pairs and learn translation models to improve traditional IR models [1,2]. The basic assumption is that query-answer pairs are “parallel texts” and relationships of words (or phrases) can be established through word-to-word (or phrase-to-phrase) translation probabilities [1,2,8]. Experimental results show that translation models obtain state-of-the-art performance for community question answering retrieval in cQA. However, query-answer pairs are far from “parallel” in practice, there are large number of unaligned words in query-answer pairs than in bilingual pairs, which confuses the word alignment tools [9].In this paper, we study how to learn query and answer representations for community question answering retrieval. Specially, we head for modeling queries and answers in a more natural way. The model should not only highlight the instinct heterogeneity of queries and answers, but also be flexible enough to take other answers rather than the best answers into account. To this end, we propose a novel supervised approach to automatically learn semantic representations for queries and answers. The underlying assumption is that although questions and answers are heterogeneous in many aspects, they share some equivalences in the semantic level. Thus, we can learn the unified representations for query-answer pairs using an approach based on neural networks. In details, the procedure of using a deep neural network (DNN) to rank a set of answers for a given query is as follows. First, a non-linear projection is performed to map the query-answer pairs to a common semantic space. Then, the relevance of each answer given the query is calculated as the cosine similarity between their vectors in that semantic space. The neural network models are discriminatively trained using the query-answer pairs such that the cosine similarity of the best answer given the query is maximized. Finally, this semantic level feature is incorporated into a learning to rank (LTR) framework, which also includes a rich set of statistical-based features described in [12]. The relative importance of each feature is learned via a SVMRank algorithm [13] that utilizes a large-scale query-answer pairs in cQA archive. Different from the previous semantic models that are learned in an unsupervised fashion [14], our models are optimized directly for queries and the corresponding best answers, and thus give superior performance.We evaluate the contribution of our semantic level features for community question answering retrieval under two settings: (1) large-scale automatic evaluation over query-answer pairs in cQA archives; (2) manual evaluation of the top retrieved answers for a set of test queries. We compare our approach to a state-of-the-art LTR model that utilizes only statistical-based features. The performance improved significantly in query-answer ranking by both evaluations when the semantic level features are incorporated, demonstrating the potential of our learn scheme for community question answering retrieval.The remainder of this paper is organized as follows. Section 2 presents the related work. Section 3 describes neural network based approach for question and answer representation. Section 4 presents the learning to rank scoring model. Section 5 presents the experimental results. Finally, we conclude the paper in section 6.

@&#CONCLUSIONS@&#
