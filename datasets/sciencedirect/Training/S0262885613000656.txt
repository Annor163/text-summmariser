@&#MAIN-TITLE@&#
Non-parametric hand pose estimation with object context

@&#HIGHLIGHTS@&#
We developed a system that estimates in real-time the articulated pose of the hand.Our approach is discriminative, with low computational load and fast error recovery.Our system is robust to occlusions, implicitly extracting information from them.The system is thoroughly evaluated with quantitative and qualitative experiments.

@&#KEYPHRASES@&#
Articulated hand pose,Approximate nearest neighbor,Context,

@&#ABSTRACT@&#
In the spirit of recent work on contextual recognition and estimation, we present a method for estimating the pose of human hands, employing information about the shape of the object in the hand. Despite the fact that most applications of human hand tracking involve grasping and manipulation of objects, the majority of methods in the literature assume a free hand, isolated from the surrounding environment. Occlusion of the hand from grasped objects does in fact often pose a severe challenge to the estimation of hand pose. In the presented method, object occlusion is not only compensated for, it contributes to the pose estimation in a contextual fashion; this without an explicit model of object shape. Our hand tracking method is non-parametric, performing a nearest neighbor search in a large database (.. entries) of hand poses with and without grasped objects. The system that operates in real time, is robust to self occlusions, object occlusions and segmentation errors, and provides full hand pose reconstruction from monocular video. Temporal consistency in hand pose is taken into account, without explicitly tracking the hand in the high-dim pose space. Experiments show the non-parametric method to outperform other state of the art regression methods, while operating at a significantly lower computational cost than comparable model-based hand tracking methods.

@&#INTRODUCTION@&#
Human pose estimation is an important task for applications such as teleoperation and gaming, biometrics and prosthesis design, and human–robot interaction. However, accurate 3D reconstruction of human motion from images and video is a highly non-trivial problem, characterized by high-dimensional state spaces, fast and non-linear motion, and highly flexible model structures [2]. All this is applicable to hand reconstruction as well as full body reconstruction [1,3–6]. However, while a full body pose estimator encounters additional challenges from e.g. clothing, a hand pose estimator has to deal with other but equally demanding issues: similarity in appearance between the different parts of the hand (e.g. different fingers), and large self occlusion.An important aspect of hand pose estimation is that humans are frequently interacting with objects. This is the case in the majority of the application areas mentioned above. The grasped object is often occluding a large part of the hand — for a plausible example, see Fig. 1, left.Despite this, researchers have up to now almost exclusively focused on estimating the pose of hands in isolation from the surrounding scene, e.g. [7–11]. As illustrated in Fig. 1, top and middle, this will be inadequate if the observed hand interacts closely with objects during estimation.Object–contextual hand pose estimation has been addressed in a generative manner in two recent works. In [12] the authors show that the hand pose can be reconstructed robustly despite the object occlusion. In [13], this is taken one step further, with explicit reconstruction of the object in 3D. By enforcing physical constraints on the hand pose from the object 3D surface and vice versa, the two pose estimation processes guide each other.In contrast to [12,13], we take a discriminative approach to object–contextual hand pose estimation. The main contribution of this paper is a method for estimating human hand pose, employing contextual information about the shape of the object in the hand. Neither the hand nor the object is explicitly reconstructed; the hand and the object are instead modeled together, encoding the correlations between hand pose and object shape in a non-parametric fashion. In spirit of the recent methods for contextual recognition and estimation, e.g. [3,14,13,6], the object occlusion thereby helps in the hand pose reconstruction.There are two reasons for exploring discriminative hand pose estimation with object context. Firstly, while generative estimation approaches commonly are more accurate, discriminative approaches are commonly more robust and computationally efficient; this is discussed further in Section 2. In, e.g., robotic and gaming applications, computational speed is critical, making discriminative approaches attractive. It is therefore valuable to investigate the possibility of estimating hand pose discriminatively in the context of objects.Secondly, apart from the purely physical object constraints on the hand pose [13], there is also a functional correlation between object shapes and the manner in which they are grasped by a hand [15]. Thus, all physically possible ways of grasping an object are not equally likely to occur during natural object manipulation activities. Probability densities over hand pose conditioned on object shape can be encoded (in a non-parametric manner) in our discriminative method, while it is more difficult to encode this information in a generative model based method.Fig. 1, bottom row illustrates our approach. In our non-parametric method, pose estimation essentially corresponds to matching an observed hand to a very large database (.. entries) of hand views. Each instance in the database describes the articulation and the orientation of the hand. The configuration of a new (real) image can then be found using an approximate nearest neighbor approach, taking previous configurations into account.In our system, the database contains hands both with and without grasped objects. The database depicts grasping hands including occlusion from objects with a shape typical for this kind of grasp; this encodes functional correlations between object shape and the articulation of the grasping hand. The occlusion shape is strongly correlated to grasping type which further has a strong dependency with the hand articulation. Since the underlying assumption is that appearance similarity can be related to similarity in hand pose the object shape contributes to the hand pose estimation.In many scenarios it is hard to differentiate between the palm and the dorsal (“back-hand”) side of the hand. However, the object is much more likely to occlude the palm rather than the dorsal side of the hand. This gives insight on why object knowledge can be exploited in order to resolve the ambiguities typically associated with hand pose estimation. The rest of the paper is organized as follows: In Section 2 the relations to related work are discussed. The probabilistic estimation framework is then outlined in Section 3. The non-parametric hand model is described in Section 4, while Section 5 describes how inference is done over this model. Experiments in Section 6 show the non-parametric method to outperform other state of the art regression methods. We also show qualitative reconstruction results for a number of synthetic and real test sequences.

@&#CONCLUSIONS@&#
We present an efficient non-parametric framework for full 3D hand pose estimation. We show through extensive experimentation that the proposed model is capable of predicting the pose in highly challenging scenarios corrupted by significant noise or with rapid motions. Further, our model is efficient and runs in real-time on standard hardware.The fundamental contribution is a system capable of exploiting contextual information in the scene from the interaction between the hand and a potential object. We show how this information can be exploited in a robust manner, making our system capable of generalizing the pose over different objects. This enables the usage of a fast discriminative method to scenarios where only expensive generative methods previously would have been applicable. We employ a multi-modal temporal model, allowing us to resolve ambiguities through temporal consistency. Our model could easily be extended to simultaneously estimate both the hand pose and the object shape by appending the inference scheme with a smoothness term with respect to object.In future work we would like to evaluate the possibility of exploiting a better pose representation. This would make it possible to even further strengthen the temporal model. In this paper we also assume that the observation model can be modeled using a spherical Gaussian; this encodes an assumption of equal importance of the joint angles. This is unlikely to be true why we would like to explore a likelihood model that better respects the correlation between quality of estimate in joint space. This could potentially allow us to use additional hypotheses for each estimate.Another avenue of future work to investigate is the exploitation of RGB-D data, which would improve both the hand-background segmentation (currently based on skin color) and the feature representation of hand shape (currently HOG).Finally, as noted in Section 2, generative and discriminative approaches have different merits. For applications requiring high accuracy, we therefore plan to run our discriminative hand pose estimator in parallel with a more accurate but less robust generative tracking method, using the discriminative estimates to (re)initialize the generative process.Supplementary material.Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2013.04.002.