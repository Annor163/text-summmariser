@&#MAIN-TITLE@&#
Comparative analysis of multi-objective evolutionary algorithms for QoS-aware web service composition

@&#HIGHLIGHTS@&#
Most existing approaches reduce the multi-objective optimization problem of QoS-aware web service composition to a single-objective problem using scalarization.No comparative study with several multi-objective algorithms has been found in the literature for this specific problem.Several EMOAs are tested: NSGA-II, SPEA2, POSDE, GDE3, and MOEA/D.Differential evolution (DE) algorithms – in particular GDE3 – yields the best results on this specific problem for several scenarios, also having the lowest time complexity.

@&#KEYPHRASES@&#
Service composition,Quality of service,Real world services,Multi-objective optimization,Pareto set,Differential evolution,

@&#ABSTRACT@&#
Web service composition combines available services to provide new functionality. The various available services have different quality-of-service (QoS) attributes. Building a QoS-optimal web service composition is a multi-criteria NP-hard problem. Most of the existing approaches reduce this problem to a single-criterion problem by aggregating different criteria into a unique global score (scalarization). However, scalarization has some significant drawbacks: the end user is supposed to have a complete a priori knowledge of its preferences/constraints about the desired solutions and there is no guarantee that the aggregated results match it. Moreover, non-convex parts of the Pareto set cannot be reached by optimizing a convex weighted sum. An alternative is to use Pareto-based approaches that enable a more accurate selection of the end-user solution. However, so far, only few solutions based on these approaches have been proposed and there exists no comparative study published to date. This motivated us to perform an analysis of several state-of-the-art multi-objective evolutionary algorithms. Multiple scenarios with different complexities are considered. Performance metrics are used to compare several evolutionary algorithms. Results indicate that GDE3 algorithm yields the best performances on this problem, also with the lowest time complexity.

@&#INTRODUCTION@&#
Web services are very popular and widespread in enterprise distributed environments, being a central aspect in Software Engineering. The most significant advantages of the service-oriented approach are: reusability, interoperability across different platforms, location independence, security support, dynamic search/connectivity, and compatibility within the Cloud Computing paradigm.New services can be created by combining existing ones. The process is called service composition or service orchestration[1]. A composite service is a service obtained by composition/orchestration and the way of composing services – the service architecture – is generally described by a workflow.Each service is characterized by a certain functionality (logic/functional aspect) and a set of non-functional aspects called quality of service (QoS) attributes. For instance, the function of a service may be to provide a map for a given address and a QoS attribute may be the associated response time. QoS-aware service composition is discussed in the next section.Different services offering the same functionality may have different QoS attributes [2]. QoS-aware service composition is an NP-hard [3] multi-objective optimization problem (MOP) well known in Service Oriented Computing (SOC) [4,5]. Each QoS attribute may be associated to an objective/criterion. Some objectives cannot be simultaneously optimized: a service may have a lower cost but a higher response time whereas another one may be more expensive but faster.The global QoS of a composite service depends on the QoS of each of the services used in the composition. Therefore, the problem consists in selecting, among all the available services, those ensuring the optimal composite service QoS. User preferences should be also taken into account: some users may prefer cheaper services while other users may prefer high quality services.Numerous approaches have been proposed for solving this problem (e.g., [6–15]). Exhaustive search algorithms try to find the optimal solution whereas meta-heuristic algorithms are only looking for a ‘good’ solution that may be obtained in a reasonable time frame. Different optimization algorithms types have been used: integer programming, linear programming, dynamic programming, tabu search, local search, evolutionary algorithms, and hybrid algorithms. An overview may be found in [13].Existing QoS-aware service composition approaches may be categorized in three classes:•Scalarization-based approaches. A global evaluation function aggregates different QoS attributes into a unique, global score. This aggregation procedure is also called scalarization. Despite the fact that QoS-aware service composition is a multi-objective problem, almost all existing approaches use scalarization in order to reduce this problem to a single-objective one. This is, however, a very particular approach that has some important drawbacks discussed in detail in Section 3.1.3.Pareto-based approaches. Multi-objective (MO) algorithms are used to identify multiple solutions. Very few existing Pareto-based proposals have been found in the literature for this specific problem. Pareto-based approaches offer a higher accuracy in selecting a solution in accordance with user preferences.Hybrid methods. Some recent proposals combining both Pareto and scalarization-based techniques exist. Since they are also based on scalarization they present the same drawbacks already discussed.To the best of our knowledge, there is no Pareto-based approaches comparative analysis available to date targeting the QoS-aware service optimization problem. Hence, this paper analyzes several evolutionary multi-objective algorithms (EMOAs). Some of the most known state-of-the-art EMOAs are evaluated using a dataset collected from real web services. The comparison is based on standard performance metrics and statistical analysis.The next section defines the QoS-aware service optimization problem. Section 3 presents the most relevant existing approaches to address the QoS-aware service composition problem. Section 4 presents a comparative analysis of several state-of-the-art EMOAs. Finally, the last section summarizes the experimental results interpretations and concludes the paper.A composite service may be described by a workflow [16]. A workflow contains activities and composition elements: sequence, parallel, switch (condition) and loop structures. An example including 6 activities: SA1 to SA6 is depicted in Fig. 1. Executing an activity means invoking a service.It is necessary to make a distinction between an abstract service (denoted SAi) and a concrete service (denoted SCi). An abstract service is a model describing a functionality – a service class/type. Each workflow activity SAiis associated to an abstract service. A concrete service SCiis a real web service that may be invoked – an implementation/instance of the abstract service class.A hypothesis is that several alternative concrete services exist for each abstract service. For instance, different booking services may be used for a same flight. Each concrete service is characterized by different QoS attributes. Therefore, it is important to know which concrete service is selected to implement an abstract service. Given l abstract services and k concrete services for each abstract service, there are klcombinations. This is a combinatorial multi-objective optimization problem. The search space is discrete: a solution may be encoded as a vector of l integer values, each value i indicates a concrete service SCi, 1≤i≤k. Finding the optimal service combination is a non-deterministic polynomial-time hard (NP-hard) problem (as identified in [3–5]). This means that an exhaustive search algorithm is impractical, excepting very simple cases (few abstract and concrete services).The problem is not only to find the solutions with the best QoS but also to identify the subset of solutions matching the user preferences.Some of the most used QoS attributes for web services are described bellow (e.g., [7,17,18,13,19]):–Response time (t) represents the round-trip time between sending a request to the service and receiving a response;Availability (a) is defined as being the number of successful invocations over the total number of invocations. It measures the probability that a service is available;Throughput (d) represents the total number of invocations served by a service for a given period of time;Reliability (r) represents the services capacity at ensuring reliable message delivery;Cost/price (c) is sometimes considered as a QoS attribute even if it is not a quality indicator in a strict sense. It represents the cost/price of accessing a service (i.e. the amount of money to pay) for each service request;User rating (u) is a mean score given by the users about their subjective service usage satisfaction.Security (s) is a measure of the security level offered by a service.The QoS attributes of a composite service are obtained by composing the QoS attributes of each of the services used in the composition, as depicted in [17]. Examples of composition rules/operators are proposed in [7,17,5,20,13]. Several of the most used composition rules are depicted in Table 1.The composite service workflow includes several architectural patterns. Four pattern types are considered: sequence composition, parallel composition, condition, and loop. A specific QoS composition rule is defined for each architectural pattern (see Table 1). For instance, the response time of a parallel composition made of two or more services is given by the highest response time. If several services are invoked sequentially, the global response time is the sum of the time response of each service.In the case of conditional/switch pattern (XOR), each service is invoked with a probability piand the response time is an average based on these probabilities.A loop structure will multiply the response time by the number of loop cycles. Similar rules are defined for other QoS attributes (see Table 1).QoS-aware service composition is a multi-objective optimization problem (MOP) since several QoS attributes have to be optimized simultaneously. In this section we formally define a MOP and we introduce its specific terminology.LetS⊆ℝndenote the n-dimensional search space and F⊆S the feasible space. When the optimization problem has no constraint, feasible space and search space are identical (F=S).Let x=(x1, …, xn)∈S, refer to a decision vector. Let us consider m objectives defined by a set of real valued functionsfi:ℝn→ℝwith i=1…m.Functionf(x):ℝn→ℝm, defined as f(x)=(f1(x), …, fm(x)), is called the objective vector.When solving a MOP, the goal is to find decision vectors x*∈F which optimize function f, satisfying a set of defined constraints g (a set of k inequality-based functions), and h (a set of q equality-based functions).In the case of minimization, the standard MOP may be written as:(1)MOP:minimizef(x)=(f1(x),f2(x),…,fm(x)),subjectto:gi(x)≤0,i=1,2,…,k,hj(x)=0,j=k+1,…,k+q.A similar MOP may be defined for maximization.Dealing with m≥2 objectives, the notion of optimality must be re-defined. The main problem is the possibility of having conflicting objectives: improving one objective may cause the degradation of another one.The Pareto-optimal set contains solutions ensuring the best trade-offs between the conflicting objectives. For comparing two solutions, the concept of Pareto dominance is used (e.g., [21]). For a minimization problem, a decision vectorx∈ℝndominates another vectory∈ℝn, denoted by x≺y, if and only if:•x is not worse than y for all objectives, i.e. ∀i∈{1, …, m}:fi(x)≤fi(y) and,x is better than y for at least one objective, i.e. ∃j∈{1, …, m}:fj(x)<fj(y).A solutionx∈ℝnis Pareto-optimal if and only if:∄y∈ℝn,y≺x.The Pareto Set (PS) is defined as the set of all Pareto-optimal solutions:PS={x∈ℝn|∄y∈ℝn,y≺x}.The Pareto front (PF) is defined as the set of all objective function values corresponding to the solution in PS:PF={f(x)|x∈PS}.The most relevant existing solutions for QoS-aware service composition problem are discussed in this section. Significant aspects related to optimization algorithms used by these solutions are emphasized. Three approaches are considered: scalarization-based, Pareto-based and hybrid. Advantages and limitations of each approach are discussed.A multi-objective problem may be solved by reducing it to a single-objective problem using a technique called scalarization. An essential aspect of this technique is the global evaluation function (also called ‘fitness’, ‘utility’, or ‘objective function’). This function associates a score to each solution that makes it possible to decide if a solution is better than another one.An important number of scalarization-based proposals can be found in the literature (e.g., [7,9,8,22–26,4]). The most relevant ones are discussed in the next sub-sections.Two types of fitness functions have been identified: fraction-based and weighted sum-based. Existing proposals using these types of functions are discussed next.In [7], a composite service s is evaluated using a fitness function defined as a fraction:F(s)=w1·Cost(s)+w2·Responsetime(s)w3·Availability(s)+w4·Reliability(s),wherew1are the weights associated to each QoS attribute.The QoS attributes (Cost, ResponsTime, Availability and Reliability) are computed using rules similar to relations given in Table 1. All QoS values are normalized. Similar approaches using GA and fraction-based fitness functions are proposed in [8,22].In [9], the fitness function is given by a weighted sum:F(s)=w1·Cost(s)+w2·Responsetime(s)+w3·Reliability(s)+w4·Userrating(s)+w5·Security(s).Other proposals such as [23–26] also use fitness functions based on weighted sum. For instance, the fitness function F proposed in [26] is:F(s)=∑k=1NQmax(k)−qk(s)Qmax(k)−Qmin(k),where k iterates the QoS attributes, qk(s) are the values of the QoS attribute k for the service s, Qmax(k) is the maximum value of the QoS attribute k and Qmin(k) is the minimum value of the QoS attribute k.This relation includes QoS attributes normalization. The global maximum and minimum values are obtained when the local maximum and minimum are selected for each abstract service. The maximum global cost of a composite service is obtained when concrete services with maximum costs are locally selected in each case. The same is true for the minimum value.A normalized weighted sum with equal weights is considered in [4]. The services are grouped in QoS classes using the K-means algorithm.A constrained optimization approach for QoS-aware service composition is proposed in [27]. The optimization problem is modeled in two ways: (a) as a multidimensional multi-choice 0-1 knapsack problem (MMKP), and (b) as a multi-constraint optimal path problem (MCOP). A hypothesis is that the user expresses its preferences in the form of a set of constraints, for instance: response time<600, cost<250, and availability>85%. The utility/fitness function is a weighted sum:F(s)=∑i=1Nwiqi(s)−Qavg(i)Qstd(i)+∑j=1M1−wjqj(s)−Qavg(j)Qstd(j),where i iterates the N QoS attributes that should be maximized, j iterates the M QoS attributes that should be minimized, qi(s) represents the value of the QoS attribute i, Qavg(j) is the average of the QoS attributes j, Qstd(j) is the standard deviation of the QoS attributes j, andwjis the weight representing the importance of the QoS attributes j.This approach assumes that average and standard deviation may be easily computed for each QoS attribute. However, for complex problems, this task may involve an important computational cost. In order to specify realistic constraints, the user should be aware of the magnitude of each QoS attribute.In [28] the constraints are specified by the end user. For instance the cost for the response time should be lower than a given threshold. The fitness function is a weighted sum that also includes the constraints. The function is:F(s)=1−pd∑i=1Nci(s)yi∑i=1Nwiqi,where i iterates the N QoS attributes, ci(s) are the constraints defined for QoS attributes i for the composite service s, yi=0 if ci(s)≤0 and yi=1 if cli(s)>0, pdis a penalty coefficient, andwiare the weights corresponding to the importance of each normalized QoS attribute qi. According to [28], the service provider should estimate the range of the QoS attributes as a part of the Service Level Agreement (SLA).As noticed in [13], QoS attributes normalization is an important step for computing a global QoS score, which requires minimum and maximum values computation for each QoS attribute.Scalarization techniques require the definition of a relation between the potential solutions. The simplest method is to compute the convex combination of the objective functions fi. Thus, two solutions are comparable using standard relation order: x1 is better than x2 if S(x1) is better than S(x2).A first drawback of the scalarization-based approach concerns the form of the aggregation function. State-of-the-art QoS-aware service composition approaches use weighted sum-based or fraction-based aggregation functions. Which one to choose?Let us suppose that weighted sum is used. There is no proof that the solution found when using weights reflects the user preferences. Indeed, there is no standard method for computing these weights. Usually, weights are deduced by an expert and two different experts might indicate two different sets of weights.When a weighted sum is used, an exhaustive optimization algorithm finds one solution from the Pareto set [29,30]. There is no direct correspondence between the weighting coefficients and the relative importance of the objective functions [29]. There is no method indicating how to modify the weights in order to consistently change the solution. Therefore, the final solution may not reflect the user preferences as required.Moreover, there is no criterion to verify that the solution (obtained by the single-objective algorithm) is indeed non-dominated. The non-dominance is an effect of the optimization algorithm limitations when combined with search space characteristics.On the other hand, Pareto-based approaches do not require the definition of an aggregation function and QoS attributes normalization is not necessary.A second drawback concerns the subjectivity of the weighted sum since weights are often arbitrarily chosen. Existing QoS-aware service composition approaches presume that the user indicates his preferences and weights are chosen based on these preferences. This is based on the hypothesis that the user precisely knows, before seeing the solutions, what he/she wants. A Pareto-based approach allows the user to select a posteriori the preferred solution from the Pareto set, after analyzing all optimal solutions. Let us consider a scenario having the following non-linear objective functions: performance and cost. For instance, a slight performance increase may involve an important cost increase. In such a situation the user may prefer to analyze several solutions and decide a posteriori what he/she prefers.A third drawback concerns the Pareto Front convexity. Pareto-based approaches are able to approximate the PF for both convex and non-convex problems. However, weighted sum aggregation is only suitable for convex problems. A geometrical explanation of this phenomenon is presented in [31]. Non-convex parts of the Pareto set cannot be reached by optimizing convex aggregation functions (as demonstrated in [29]).A fourth drawback concerns the differences between the shapes of the objective functions. The weighted sum is not a suitable approach for functions having different shapes (asynchronously rising or falling) [32].A fifth drawback concerns the number of solutions. Scalarization approaches yield only one solution per run. A Pareto-based approach yields multiple solutions. When using the Pareto approach it is possible to select one solution if desired. However, once we decided to use a scalarization-based method the diversity of solutions is lost.The next section presents several EMOAs Pareto-based approaches.MOPs can be efficiently solved using EMOAs [21]. These algorithms are able to find multiple solutions in a single run. The main objective of an EMOA is to find a set of solutions that approximates the Pareto set still maintaining a good solution diversity. The next section presents the most representative EMOAs. Some of these algorithms have already been applied to the QoS optimization problem.Non-dominated Sorting Genetic Algorithm II (NSGA-II) is a well-known elitist multi-objective optimization algorithm [33]. After the population is initialized, the N individuals are sorted in several fronts/levels. The front 1 includes all the non-dominated individuals from the entire population. The front 2 includes individuals dominating all others except the ones from front 1. The same sorting algorithm is repeated for subsequent fronts. Each individual is assigned a rank/fitness value equal to its front number.A measure called crowding distance indicates, for each individual, how close that individual is from its neighbors based on the Euclidian distance measured in the m dimensional objectives function space. The crowding distance ensures solution diversity.Binary tournament selection aims at selecting parents. Crossover and mutation operators are applied on the selected parents in order to generate offspring, which are further added to the parent population. The same sorting algorithm is applied on the new population. The first N individuals with lowest rank and highest crowding distance are preserved in the population while the others are rejected. The evolutionary process is repeated for a specific number of generations.A NSGA-II based approach for QoS-aware service composition is proposed in [20]. A solution is encoded using an integer vector. The evaluation is based on a scenario with 10 abstract services and 10 concrete services (the search space size is 1010). Five objectives are considered: price, response time, availability, throughput and reputation. An experiment with two objectives is presented. Algorithm parameters are: mutation rate 0.01, population size 120, single-point crossover with a 0.95 rate and binary tournament selection. Individual duplication is checked at each generation. The algorithm runs for 100 generations.Strength Pareto Evolutionary Algorithm 2 (SPEA2) [34] is another well-known elitist evolutionary multi-objective optimization algorithm. SPEA2 uses an archive with a predefined size for storing all the non-dominated solutions found at each generation. This mechanism protects good solutions from random effects. During the evolutionary process, dominated and duplicated solutions are removed from the archive. If the archive is full, some solutions are removed according to a clustering technique ensuring solution diversity.The external population is mixed with the current population. Each individual from the mixed population has a strength value equal to the number of dominated individuals in the mixed population. The fitness of an individual i from the mixed population is computed as the sum of strengths of each individual dominating i (dominator strengths). The goal is to minimize the fitness (non-dominated solutions will have zero fitness).In order to discriminate individuals having the same fitness, an additional density information is added. In the case of SPEA2 kth nearest neighbor clustering method is used. The density function is the inverse distance to the kth nearest neighbor.Binary tournament selection, crossover and mutation are used to produce offspring. The archive is updated at each generation.A SPEA2 based approach for QoS-aware service composition is proposed in [5]. Three criteria are considered: response time, cost, and availability. A scenario with 4 abstract services and 90–500 concrete services per abstract service is considered (search space size is 5004). Integer vector genome encoding, mutation rate of 0.01, population size of 100 individuals, single-point crossover with a 0.95 rate and binary tournament selection are used. The archive size is 200. According to the authors, SPEA2 converges in less than 100 generations.A genetic algorithm called Multi-Objective Multi-State Genetic Algorithm (MOMS-GA) [35] is proposed for general system design optimization. The system is component-oriented (a component corresponds to a web service). Components have different attributes: performance level, cost, weight, and reliability (four objectives). Experiments are based on a system with 5 abstract components connected serially and 4–9 concrete components for each abstract component (the search space size is 95). A multi-state approach is considered. The system and its components may have more than two states: completely working, partially working, partially failed, and completely failed.MOMS-GA uses the universal moment generating function (UMGF or u-transform) method [36] to evaluate the system reliability and availability. A population of 200 individuals evolves through 50 generations. The algorithm uses an integer chromosome representation, a specific crossover operator called ‘subsystem rotation crossover’, a multi-parent recombination, a single-point mutation, and an elitist reinsertion.An evolutionary multi-objective algorithm called E3-MOGA is proposed in [37]. Three objectives are considered: throughput, latency and cost. A scenario with 4 abstract services and 3 concrete services per abstract service is considered (the search space size is 34). Service Level Agreements (SLAs) representing a contract between the service provider and the service consumer are defined. The service provider should offer a higher quality for the higher class consumer. Three different service levels are considered: Platinum (P), Gold (G), and Silver (S).A population of 300 individuals evolves through 200 generations. For each individual, the overall QoS measures are evaluated for each service level (P, G, and S). An individual i is evaluated based on its domination rank (how i outperforms other individuals) and density (how many individuals provide similar objective values). E3-MOGA maintains a set of individuals with higher fitness values (elite population). It also considers a constraint violation degree for individuals that cannot satisfy the SLAs.An entire class of multi-objective evolutionary algorithms are based on a technique called Differential Evolution (DE) [38]. In a series of experiments, DE has proven to be more efficient than simulated annealing and genetic algorithms.Several strategies of DE exist. An example is ‘DE/rand/1/bin’. An individual from the population is encoded as a real value vector. In a first step, three different vectors x1, x2, and x3 are randomly selected from the current population and a trial vectorviis generated:vi=x3+F(x2−x1), where F>0 is a real constant controlling the amplitude (mutation factor) of the differential variation (x2−x1).In a second step, the trial vectorviand the decision vector xiare combined using a binomial crossover operator. A new vector/individual uiis generated as follows:uj,i=vj,i,ifrand[0,1)≤CRorj=randj,xj,i,otherwise,where CR is a user-defined crossover rate, CR∈[0, 1], and the condition ‘j=randj’ means that at least one component j of the mutated vectorviis selected (more than one component are selected with probability CR).During the selection phase, the new vector uireplaces the decision vector xiin the next generation if uihas a better fitness than xi.A Pareto-optimal set multi-objective algorithm based on differential evolution (POSDE) is proposed in [39]. POSDE uses a secondary population (archive) where non-dominated solutions found at each generation are stored. When a new good solution is added to the archive, the existent solutions dominated by the new one are eliminated.The current population is updated based on a DE mechanism. Diversity is ensured by a distance metric used to alter the fitness of each individual when it is compared with the elements of the archive. POSDE requires an additional parameter: the maximum accepted distance between solutions.A multi-objective DE version called Generalized Differential Evolution (GDE3) is proposed in [40]. This algorithm extends the DE/rand/1/bin method to a problem having M objectives and K constraints. The DE selection operator is modified by introducing the Pareto dominance. The trial vector replaces the decision vector in the next generation if the trial vector weakly dominates the decision vector. If there is no dominant vector, then both vectors are preserved in the population. At the end of a generation, the size of the population may increase. In this case, the population is truncated to the original size using a crowding distance based selection approach. The vectors are sorted based on non-dominance and crowdedness and the worst solutions are removed. Decreasing the population size is the most complex operation of GDE3 algorithm.A multi-objective algorithm based on decomposition (MOEA/D) is proposed in [41]. MOEA/D decomposes a MOP into several scalar optimization sub-problems simultaneously optimized.MOEA/D uses the weighted Tchebycheff approach in order to decompose the MOP in a number of single-objective problems. The Tchebycheff norm is:gλ(x,z)=maxi=1,…,m{λi|fi(x)−zi|},∀x∈X,where z is an optimal point. The goal is to minimize gλ.Each sub-problem is characterized by different weight vectors. The number of uniformly distributed weight vectors used is equal to the number λ of optimization sub-problems.An archive is used to store non-dominated solutions – the best individuals found at each generation. If a newly generated offspring is better than an individual inside the archive, then it simply replaces it.According to the authors, MOEA/D's advantages are scalability with the number of objectives, computational efficiency, and high performance for combinatorial optimization problems [41].The study of the existing Pareto-based approaches targeting the QoS-aware service optimization problem revealed that only four multi-objective algorithms (NSGA-II, SPEA2, MOMS-GA and E3-MOGA) have been used so far for QoS-aware services/components composition. Each proposal uses only one algorithm and no comparative analysis of the different EMOAs has been presented to date. Some proposals only consider simple scenarios with few services.Scalarization-based and Pareto-based approaches may be combined together in order to obtain hybrid approaches. Some recent hybrid-based QoS-aware optimization proposals are briefly discussed in this section.An approach based on a method called ‘skyline’ is proposed in [42–45]. The so called ‘static skyline’ [42] is actually equivalent to the Pareto set since the domination relation defined in a ‘skyline problem’ is identical to the Pareto dominance.The skyline-based approach is based on two steps. In the first step, the set of alternative concrete services is reduced by eliminating all concrete services that are Pareto dominated. In other words, only the Pareto-optimal concrete services are used to create composite services. Thus, the search space is reduced. The second step is scalarization-based: a simple additive weighting function and a single-criteria algorithm are used in order to compute a final solution (e.g., [43,45]).In order to reduce the search space, hybrid approaches use Pareto-based optimization for eliminating a concrete services (alternatives) subset. This step involves a significant additional computation cost (time complexity) since, for each abstract service, the Pareto front needs to be found. Since the QoS attributes change over time, this front should be re-computed periodically.Finally, since scalarization is used, the drawbacks already mentioned for the scalarization-based approach are also present for the hybrid approach.The existing approaches study revealed that a comparative analysis is necessary in order to decide which multi-objective algorithm is best suited for the QoS optimization problem. Some EMOAs perform better than others according to the nature and complexity of the particular MOP.A simple visual inspection of the Pareto front is not sufficient to decide which algorithm is better. In order to accurately compare the algorithms, an objective evaluation is required. According to [46,47], when comparing different algorithms, one cannot only rely on a single indicator and the three following performance metrics: Hyperarea/Hypervolume, Spacing, and Set Coverage have at least to be used to compare algorithms performances.The analysis is performed on several scenarios. A scenario is defined by an abstract workflow along with a certain number of alternative concrete services defined for each abstract service. The performance evaluation procedure for one scenario is:i.An abstract workflow (see Section 2) is randomly generated using the algorithm described in Section 4.1.1,For each abstract service, several concrete services are generated. The QoS attributes of these concrete services are collected from real web services. A public database [18] containing about 2500 records characterizing real web services is used as data source (random services are selected from this database).The following multi-objective algorithms are tested on the same scenario: NSGA-II, SPEA2, MOEA/D, GDE3, and POSDE. Problems with 2 and 3 objectives are considered: 2 objectives – maximization of throughput and availability; 3 objectives – maximization of throughput, availability and minimization of response time.Results are collected and compared.The evaluation procedure is tested on several scenarios containing l∈{10, 20, 30} abstract services, and k∈{10, 20, …, 90} concrete services per abstract service. Each experiment is repeated 50 times.The underlying hypothesis is that QoS attributes do not change during the time frame necessary for the algorithm to find a solution (this simplification is also considered by most related approaches).Scenarios generation, genome encoding and specific parameters used by the multi-objective optimization algorithms are described in the following sections.Abstract workflows corresponding to composite services of various complexities are randomly generated using the following algorithm:1Step 1: Initialize the composite service Sc as an empty vector and the index of abstract services i=0.Step 2: Select a random activity A∈ {‘flow’, ‘sequence’, ‘if’, ‘while’, ‘invoke’}. If the selected activity is an ‘if’ condition, then with a certain probability, several ‘elseif’ branches are also appended. A random probability to execute each conditional branch is generated. If the selected activity is a ‘while’, then a random number of iterations is generated.Step 3: If A is ‘invoke’ then increment i (a new abstract service has been added to Sc).Step 4: If Sc is empty then append activity A to the vector Sc. Otherwise, select a random activity B from Sc and insert the activity A so that its execution is linked by B, then update the vector Sc. For instance, if A is ‘invoke’ and B is a ‘while’ then the ‘invoke’ operation is performed within the while loop.Step 5: If i<m, where m is the number of abstract services, then go to Step 2.The implementation is based on ECJ11http://cs.gmu.edu/∼eclab/projects/ecj/.version 20 framework. The source code is publicly available on the GitHub repository.22https://github.com/mrlini/QoSoptimization.In the case of NSGA-II and SPEA2 algorithms, the genome used to encode a solution is an integer vector. Each gene is an integer value representing the index of a concrete service – as depicted in Fig. 2.SA={SA1,SA2,..,SAl} represents the set of abstract services andSCi={SCi,1,SCi,2,…,SCi,k} represents the set of concrete services implementing the abstract serviceSAi. Qi,j=(d, t, a) is the vector of QoS properties (throughput – d, response time – t, availability – a) considered forSCi,j.DE-based algorithms (such as GDE3 or POSDE) have been initially designed for solving continuous problems. Therefore, they use a floating point encoding scheme. As DE-based algorithms have proven their efficiency, DE scheme has been adapted for discrete problems. An example is an algorithm called ‘TruncDE’ [48] that uses floating-point variables for internal DE computations. The values are truncated when the objective-functions are evaluated. The same method is used in our experiments.In order to ensure a fair comparison for all algorithms, we consider a population size of 100 individuals and we run each method for 400 generations.An archive of 100 individuals is considered for SPEA2 and POSDE algorithms.For NSGA-II and SPEA2 algorithms the parameters are: SBX distribution index 20 and polynomial distribution index 20.For DE-based algorithms CR=0.75, and F=0.25 (these values used are based on studies from [49,50]).For MOEA/D algorithm, the neighbor size is set to T=10.This section presents a set of comparative experiments using NSGA-II, SPEA2, MOEA/D, GDE3, and POSDE algorithms. Several scenarios are considered having from 10 to 30 abstract services and from 10 to 90 concrete services per abstract service. Experiments consider two and three objectives.A two-objective optimization problem (throughput and availability) is considered in Fig. 3. The problem scenario implements 10 abstract services and 70 concrete services per abstract service.A three-objective optimization problem (throughput, availability, and response time) is considered in Fig. 4. The problem scenario implements 20 abstract services and 70 concrete services per abstract service.In Fig. 3 it can be observed that each considered algorithm yields slightly different solutions. Due to the stochastic nature of the evolutionary approaches (random initialization, crossover, mutation) and each method characteristics, the solutions are not identical. For instance NSGA-II yields solutions with higher throughput, POSDE and SPEA2 yield solutions with higher availability and GDE3 yields balanced solutions. Some balanced solutions obtained by NSGA-II and SPEA2 are also obtained by GDE3. Most of POSDE solutions are dominated by solutions obtained using NSGA-II, SPEA2 and GDE3. SPEA2 also yields some solutions which are dominated by other solutions. MOEA/D yields only two solutions that are clearly dominated by numerous other solutions.Results with three optimization objectives depicted in Fig. 4 indicate that NSGA-II yields numerous good solutions with high throughput, high availability and low response time. SPEA2 and GDE3 yield numerous good balanced solutions but some of them are dominated by some NSGA-II solutions. POSDE and MOEA/D yield solutions that are, in general, dominated by other solutions.NSGA-II, SPEA2 and GDE3 algorithms are the favorite candidates for solving the QoS optimization problem. Additional experiments based on quality metrics are presented in the next sections.For a two-objective problem the Hyperarea (HA)[21] defines the coverage area of a known PF with respect to the objective space. It represents the sum of all rectangular areas bounded by a reference point and the objective values (f1(x), f2(x)) for each solution. The hypervolume (HV) is a generalization of hyperarea for more than two objectives. A higher value for hyperarea/hypervolume means that a greater portion of the Pareto front is covered. Therefore, a PF with a higher HV value is preferred.Figs. 5 (two-objective problem) and 6(three-objective problem) present standard statistic box-plots (mean, dispersion, and outliers) about the normalized hypervolume values obtained for considered algorithms over 50 independent runs.A high median value indicates that the algorithm finds a good approximation set. A low dispersion value and low number of outliers indicate a robust/stable algorithm (it finds similar solutions on different runs).Experiment results illustrated in Figs. 5 and 6 indicate that the considered algorithms yield a similar HV mean value of 0.14 for all the two and three objective problems scenarios. Therefore, it is difficult to make a clear distinction between the considered algorithms from this point of view.In terms of HV dispersion, there are some visible differences. POSDE algorithm is the most stable (yields the lowest dispersion) – it systematically finds the same solutions on different runs (with two exceptions: three-objective/10 abstract/20 concrete and three-objective/20 abstract/20 concrete). NSGA-II algorithm is very stable for two-objective problem but is slightly unstable for three-objective problem. SPEA2 and GDE3 algorithms are stable for some scenarios and slightly unstable for some others. MOEA/D algorithm is highly unstable (it is however more stable for three-objective problem than for two-objective problem).Statistical analysis. Because data does not respect a normal distribution, a Kruskal–Wallis analysis over the HA/HV values is performed. Test results exhibit statistical differences between algorithms. Each algorithm is compared to all the other algorithms using the Wilcoxon rank-sum test.Table 2presents a comparison between considered algorithms based on HA values and Wilcoxon test results for l∈{10, 30} abstract services, k∈{30, 80} concrete services for two-objective problem.Algorithms are compared two-by-two (lines versus columns in Table 2). Arrows (→, ←, ↑) point towards the algorithm that yields the best results while a square (□) indicates that there is no statistical difference between two algorithms.A rank can be assigned for each algorithm by counting the number of arrows pointing towards that specific algorithm (see Table 2). The ranking is, from the best to the worst algorithm: GDE3 – rank 12, POSDE – rank 10, NSGA-II – rank 7, SPEA2 – rank 4, MOEA/D – rank 0.Table 3presents a comparison between considered algorithms based on HV values and Wilcoxon test results for l∈{10, 30} abstract services, k∈{30, 80} concrete services and three-objective problem.A ranking for the three-objective problem can be also computed based on the results depicted in Table 3. The ranks are, from the best to the worst: GDE3 – rank 9, NSGA-II – rank 9, POSDE – rank 7, MOEA/D – rank 7, SPEA2 – rank 4.In conclusion, statistical analysis with two-objective and three-objective problems indicate that GDE3, NSGA-II and POSDE algorithms yield the best results in terms of Hyperarea/Hypervolume for several scenarios.The Spread (Δ) [21,33] reflects the spread of solutions found by the MO algorithm. The variance of the distances between neighboring vectors is measured. Δ is defined as:Δ=df+dl+∑i=1N−1|di−d¯|df+dl+(N−1)·d¯,where diis the Euclidean distance between consecutive solutions (in the objective space),d¯is the mean of all di, dfand dlare the Euclidean distances between extreme/boundary solutions of the obtained PF, and N is the number of solutions from the Pareto front. If dihas a large variance Δ can be greater than one. In the ideal case of uniform solutions spreading all distances diare equal tod¯and therefore Δ is zero.Fig. 7presents the average spreading values for two-objective problem (this metric cannot be applied for more than two objectives [46]). Lower values indicate a more efficient algorithm.The results depicted in Fig. 7 indicate that GDE3 and POSDE algorithms offer slightly better solutions spreading (lower Δ values) than the other considered algorithms for some scenarios, especially when the problem complexity increases. NSGA-II, SPEA2 and MOEA/D algorithms yield very similar results.Set Coverage (C)[21] is useful for comparing two solution sets found by two different algorithms. If X and Y are two set representing PS approximations, the Set Coverage C(X, Y) is used to measure the percentage of solutions in Y dominated by at least one solution in X in the objective space.The Set Coverage is:C(X,Y)=|{u∈Y|∃v∈X:v≺u}||Y|.If C(X, Y)=1, then all solutions in Y are dominated by some solutions in X. If C(X, Y)=0, then no solution in Y is dominated by a solution in X. When comparing two algorithms, the best algorithm has a higher value for C(X, Y) and a lower value for C(Y, X).Figs. 8 and 9illustrate Set Coverage box-plots for scenarios with 20 abstract services (for 10 and 30 abstract services see Appendix A) and k=10–90 concrete services. Two-objective problem (Fig. 8) and three-objective problem (Fig. 9) are considered. High average values and low standard deviation of C(X, Y) indicate better performances for algorithm X.The results depicted in Fig. 8 (two-objective problem) indicate that, in general, SPEA2 and GDE3 solutions dominate NSGA-II solutions while NSGA-II solutions dominate POSDE solutions. No clear domination is observed between NSGA-II and MOEA/D solutions. Also no clear domination is observed between SPEA2 and GDE3.In the case of three-objective problem depicted in Fig. 9 it can be observed that MOEA/D solutions are, in general, dominated by most of the solutions found by the other algorithms. GDE3 and POSDE obtain high scores and low dispersion values indicating that these algorithms systematically find good solutions. NSGA-II and SPEA2 exhibit average performances, while SPEA2 also exhibit a high dispersion value.Additional experiments, not depicted here due to lack of space, have been performed for scenarios with 10 and 30 abstract services. For two-objective and three-objective problems scenarios with 10 abstract services, all algorithms present similar scores and high dispersion values meaning that they have similar performances. For three-objective problems and 10 abstract services some differences can be observed: GDE3, NSGA-II yield the best results, POSDE also yields good results, MOEA/D yields the weakest results, and SPEA2 yields good average results but with high dispersion values. For scenarios with 30 abstract services, NSGA-II, POSDE and GDE3 outperform the other algorithms. POSDE has the lowest dispersion values. SPEA2 performs average and MOEA/D have the weakest performances.Results based on Set Coverage metric indicate that GDE3 is the best algorithm and MOEA/D the worst. NSGA-II also yields good results while SPEA2 and POSDE yield average results in term of median values. SPEA2 present high dispersion values (instability) and POSDE low dispersion values (stability) of Set Coverage.Single-objective evolutionary algorithms usually have a time complexity equal to O(GN), where G is the number of generations and N is the population size [51]. The computational complexity of multi-objective algorithms is usually higher.NSGA-II computational complexity is O(GMN2) where: G is the number of generations, M is the number of objectives, and N is the population size [33,51].SPEA2 has some advantages over NSGA-II for high-dimensional search spaces but it is, in general, more complex than NSGA-II [34]. For NSGA-II and SPEA2, a method reducing the complexity from O(GMN2) to O(GNlogM−1N), is proposed in [51].MOEA/D algorithm has a complexity equal to O(GMNT), where T is the number of considered solutions (usually T<N).GDE3 complexity is O(GNlogM−1N) [52]. In the case of POSDE no complexity has been reported in literature.A conclusion about the considered EMOAs theoretical complexity is that GDE3 is the least complex algorithm. However, improved versions of NSGA-II and SPEA2 [51] claim to offer a similar time complexity.Experiments measuring the effective runtime have been performed on a Desktop PC with Intel core i7 CPU 950 @ 3.07GHz and 12GB RAM. Each algorithm runs 10 times for several scenarios including combinations of 10, 20, and 30 abstract services and 10, 50, and 80 concrete services per abstract service. Average time in milliseconds has been computed for each algorithm. The results are, in ascending order: GDE3: 10378ms, NSGA-II: 20100.16ms, MOEA/D: 214267.37ms, SPEA2: 26016ms, and POSDE: 29046.5ms. Once more, GDE3 proves to be the favorite algorithm.Excepting MOEA/D, the other considered EMOAs are not well suited (in their original form) for many-objective problems. However, improved versions have been proposed. For NSGA-II, a different distance assignment replaces the crowding distance assignment in order to improve the performances on many-objective problems [53]. SPEA2-CE-KR [54] is an improved version of SPEA2 for many objectives. In the case of DE, a many-objective proposal is MyODEMR (many-objective differential evolution with mutation restriction) [55]. According to the authors, MyODEMR yields better results than MOEA/D and GDE3 on several many-objective standard test problems [55].When using a Pareto-based approach, a set of non-dominated solutions is obtained. Usually a Decision Maker has to select a solution that best suits the needs. A possible approach is to let the end user selecting the final solution. However, in most cases, the user is not an expert and thus this final step may not be trivial for him. Automatic decision making may be obtained using one of the numerous existing methods (e.g., [56,57]).

@&#CONCLUSIONS@&#
QoS-aware web service composition is investigated from a multi-objective optimization problem perspective. The study of literature reveals that no comparative analysis with multi-objective algorithms exists to date.Several well-known state-of-the-art multi-objective algorithms have been considered: NSGA-II, SPEA2, MOEA/D, GDE3 and POSDE. Evolutionary algorithms have been selected for their ability at dealing with huge search spaces – NP-hard problem.The results are compared using several standard performance metrics. Statistical analysis is also performed. Several scenarios including 10, 20 and 30 abstract services and 10–90 concrete services per abstract service have been evaluated for two and three-objective problems.Experiments results reveal some differences between the considered EMOAs. GDE3 is, on average, the best algorithm in most experiments, having also the lowest time complexity. This is the first time when a multi-objective Differential Evolution (DE)-based algorithm is tested on this specific problem.NSGA-II and SPEA2 yield average results that are very good for some scenarios but not as good for some others.POSDE exhibits the most stable behavior but it is, in general, surpassed by GDE3 and, in some cases, also by NSGA-II and SPEA2.Surprisingly, for the QoS-aware service composition problem, MOEA/D, that is considered superior to other algorithms in some other studies, has been systematically outperformed by all other considered algorithms (with some exceptions).Therefore, a final conclusion is that, among all the considered EMOAs, GDE3 is the best choice for the QoS-aware service composition problem.In the future we intend to evaluate some other multi-objective algorithms, especially DE-based ones. Another line of investigation considers interactive EMOAs (e.g., [58]): rather than computing the Pareto Set and selecting a posteriori the preferred solutions, the decision maker preferences are processed at runtime. The search algorithm will thus focus on a specific part of the Pareto Set, corresponding to the decision maker preferences, and hence reducing the computational cost.