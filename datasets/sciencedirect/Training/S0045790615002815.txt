@&#MAIN-TITLE@&#
Design and simulation of a parallel adaptive arbiter for maximum CPU utilization using multi-core processors

@&#HIGHLIGHTS@&#
If we understand Moore's law and Amdahl's law then we can conclude that increasing number of CPU cores in a computing system is of no use just to attain high computation rate.We have designed a new arbitration technique which can use the CPU cores in a most optimised manner and can achieve high degree of task parallelism.The designed arbitration technique is superior to other existing arbitration technique in terms of CPU usage, bandwidth optimization and latency.The designed arbitration technique has been tested using high performance benchmark program to analyse its efficiency.

@&#KEYPHRASES@&#
Parallel adaptive arbiter,Multi-core,CPU utilization,System-on-Chip,Bandwidth allocation,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
An arbiter is considered to be an electronic device which allocates access to the shared resources. In an environment of multi-core systems, the common bus of the System-on-Chip (SoC) is the sharing resource which is shared by multiple cores of the master. An arbiter plays a crucial role when it comes to granting an authority to utilise the shared resource efficiently. It ensures that at a time, at least one master gets access to the bus by observing the number of request issued by different number of masters during any cycle. It samples the multiple requests and decides which master should be given access to the shared bus. The main aim of an arbitration process is to assign processes to be implemented by the processor in such a manner that it meets the objectives such as efficient processor utilization, bandwidth optimization and low latency. As the technology is scaling towards the deep submicron, the feasibility for the integration of multiple processors on a chip is becoming possible. Every year, more amount of transistors are made compatible to fit on a single die, which adverts Moore's law.An arbiter ensures compatibility between on-core speed with the off-core speed because a kind of memory wall starts building up if an enhancement in the on-core speed is not compatible with the off-core and I/O subsystem [1]. A lower frequency bus matched with the higher frequency core will stall the system frequently as the core waits for the data. These mismatches have been compensated till some extent by implementing large and fast, on chip caches, but this cannot be a permanent solution to the problem as by enhancing the size and increasing the on-chip caches, increases both power consumption and the silicon size. The multi-core designs are used as a standard design across the computing spectrum that consists of high-end systems, such as huge servers, telecom infrastructure and supercomputers. Multi-core devices have been in use for many years but in different forms, for instance in the form of uni or the dual Reduced Instruction Set Computing (RISC) cores inside Quad Integrated Communications Controller (QUICC) Engine communication unit [2]. A device that has a multiple cores with various types of instruction sets is known as heterogeneous device, whereas homogenous multi-core devices has multiple identical cores in it. In today's scenario, the main focus is to create multi-core homogenous devices, but a significant amount of advantage can only be gained by using accelerators and specialised cores to shed the load from the main cores [3]. The central challenge considered for multi-core environment is the task of parallelization [4]. In order to attain high degree of task parallelization, an arbitration technique plays a major role by synchronizing the execution of multiple cores. However, the concept of parallel computation is not new for the industry but in order to implement a system which becomes compatible to run in a parallel computing environment is quite arduous task. Multi-core computation emphasises more on data and task parallelism using fine arbitration technique as it focuses on the sector where the software and the system design matters a lot. The design of an arbiter should be kept as simple as possible but it is most important for an arbiter to ensure that it handles the critical path in an efficient manner. Increasing the number of cores on the processor is of no use to gain the system speed in long run. An arbiter is required which can exploit the multiple cores of the processor with a moderate bandwidth allocation. Therefore, a new arbitration technique is proposed which is called a Parallel Adaptive Arbitration (PAA) technique.The performance of the new arbitration design is compared with other well-known arbitration policies for a bus based environment. Various arbitration techniques implemented earlier lacks efficiency in terms of CPU utilization and moderate bus bandwidth allocation therefore, it is essential to come up with an advanced arbitration technique. The final design is modelled using SystemC and OpenMP tools which makes this arbitration technique different. A research study designed to implement the proposed arbitration technique has an objective to develop an arbitration technique which can exploit the multiple cores of the processor using the method of task parallelization and to ensure a moderate bus bandwidth allocation with low latency.In rest of the manuscript, Section 2 discusses related works, which elaborates earlier implemented arbitration techniques in detail. Section 3 introduces the PAA, which describes the implementation of multiple master cores. It also discusses the way SystemC and OpenMP threads interact with each other. Section 4 contains a detailed description of the obtained results, which consists of CPU utilization rate, bandwidth allocation values and latency rate. Finally Section 5 presents the conclusion.

@&#CONCLUSIONS@&#
