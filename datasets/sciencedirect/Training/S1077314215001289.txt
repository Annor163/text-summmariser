@&#MAIN-TITLE@&#
A robust non-rigid point set registration method based on asymmetric gaussian representation

@&#HIGHLIGHTS@&#
An asymmetric Gaussian representation based method for point set registration.A robust estimator (L2E) is used to estimate the transformation in RKHS.Low-rank kernel matrix approximation trick to reduce the computational complexity.

@&#KEYPHRASES@&#
Point matching,Point set registration,Asymmetric Gaussian distribution,Kernel method,

@&#ABSTRACT@&#
Point set registration problem confronts with the challenge of large degree of degradations, such as deformation, noise, occlusion and outlier. In this paper, we present a novel robust method for non-rigid point set registration, and it includes four important parts are as follows: First, we used a mixture of asymmetric Gaussian model (MoAG) Kato et al. (2002) [1], a new probability model which can capture spatially asymmetric distributions, to represent each point set. Second, based on the representation of point set by MoAG, we used soft assignment technique to recover the correspondences, and correlation-based method to estimate the transformation parameters between two point sets. Point set registration is formulated as an optimization problem. Third, we solved the optimization problem under regularization theory in a feature space, i.e., Reproducing Kernel Hilbert Space (RKHS). Finally, we chose control points to build a kernel using low-rank kernel matrix approximation. Thus the computational complexity can be reduced down to O(N) approximately. Experimental results on 2D, 3D non-rigid point set, and real image registration demonstrate that our method is robust to a large degree of degradations, and it outperforms several state-of-the-art methods in most tested scenarios.

@&#INTRODUCTION@&#
Point set registration plays an important role in both computer vision and pattern recognition, and it frequently arises in many applications, such as image registration, medical imaging, structure from motion, 3D reconstruction, image stitching, image retrieval, and object tracking.Formally, a general point set registration method contains two parts, the first one is to recover the correspondences between two point sets, and the second one is to estimate the best transformation which can align the corresponding point pairs. However, point set registration becomes increasingly difficult, because of the challenge of large degree of degradations which make the distribution of point set more complex. In this paper, we mainly concentrate on four cases of degradation, i.e., deformation, noise, occlusion, and outlier. Briefly, noisy data means the feature points cannot be matched precisely, and the data with occlusion and outlier mean some points cannot find their correspondences in the corresponding point set.Generally, the point set registration can be categorized into rigid and non-rigid depends on the transformation pattern. A rigid transformation, which allows the translation, rotation and scaling, is relatively easy to estimate. By contrast, a non-rigid transformation is very difficult to estimate since the true transformation model is usually unknown and difficult to approximate. Moreover, the non-rigid transformation is a main element in point set registration, because it exists in numerous applications, including hand-written character recognition, facial-expression recognition, and medical image registration.Recently, numerous methods exist for rigid and non-rigid point set registration. The Iterative Closest Point (ICP) algorithm [2] is one of the best known algorithms for point set registration, because of its simplicity and low computational complexity. The nearest-neighbor distance criterion is used to assign a binary correspondence at each step of the ICP. Then the transformation is refined by the estimated correspondence. However, it requires a good initial position, i.e., adequately close distance between two point sets.In order to address the limitations of ICP and improve its performance, many interesting methods are proposed. Granger et al. [3] proposed a fast and robust method to align point sets under the expectation maximization (EM) framework, namely EM-ICP. Chui et al. [4] introduced a soft assignment technique and the deterministic annealing to construct a general framework to estimate the transformation and recover the correspondences for non-rigid matching. The core of their work is the transformation model which is built by thin-plate splines (TPS). They present a robust point set registration algorithm named TPS-RPM, and it is more robust than ICP to deformation, noise, occlusion, and outlier, but it has high computational complexity. Zheng et al. [5] proposed a robust point set registration method for non-rigid shapes, and it preserves local neighborhood structures. Moreover, the point set registration problem is interpreted as a graph matching which outperforms the shape context [6] method and TPS-RPM. Huang et al. [7] proposed a shape registration method, which measures the similarity between free form deformations and the shape in the distance transform space.Tsin et al. [8] proposed a correlation-based method named kernel correlation (KC) for point set registration, where the correlation of two kernel density estimates are used to formulate the cost function, and maximizing the correlation between kernels (as an M-estimator) can get the best transformation parameters. Based on the theory of kernel correlation, Jian et al. [9] presented a robust point set registration approach using Gaussian mixture models (GMM), namely L2-TPS, they leverage the closed-form expression for the L2 distance between two Gaussian mixtures which represent the given point sets. Alternatively, Ma et al. [10] introduced L2-minimizing estimate (L2E) [11], a robust estimator in statistics, to estimate the non-rigid transformation, and it needs putative correspondences. Then they use shape context as the feature descriptor to update the correspondences iteratively for point set registration. Li et al. [12] proposed an asymmetric shape representation and a new high-peak-fat-tail Gaussian mixtures kernel method to align two shapes, and they use particle swarm optimization (PSO) instead of the gradient-based methods to find the optimal transformation parameters.Theoretically speaking, all above point set registration methods use distance-based similarity measure to formulate energy functions, and they do not need to build a more complex model which includes outliers. In another idea, more complex model, which includes outliers, is built for point set registration. For example, Myronenko et al. [13] proposed an efficient algorithm, namely coherence point drift (CPD), based on the motion coherence theory (MCT) [14,15]. They use the Gaussian radial basis function (GRBF) to build the transformation model instead of the TPS, and consider the points in a point set which needs to move as the GMM centroids. Most importantly, EM framework is used to estimate the unknown transformation parameters. CPD can get good results in a very short time when handling a large number of points. Ma et al. [16] proposed an interesting method for point set registration by vector field consensus [17], namely RPM-VFC, and it is very similar in the transformation model to CPD.However, point set registration methods still have many unsolved problems: 1) they are sensitive to large degree of degradations, e.g., deformation, noise, occlusion and outlier, 2) the numerical optimization often falls into local minima, 3) their computational complexity are challenging to reduce when handling large data sets.In this paper, we focus on the above unsolved problems of non-rigid point set registration, and present a novel robust point set registration method. Briefly, the core of our method is based on a asymmetric Gaussian representation method, i.e., a mixture of asymmetric Gaussian model (MoAG) to represent the density of the given point set, in particular, assuming that the point set often satisfies asymmetric distribution. Then we use the improved soft assignment technique to fit the correspondences. A robust correlation-based method is used to estimate the parameters of the transformation model, which has been well studied in [11,18]. Moreover, we use the kernel method to build a feature space (RKHS) to solve our cost function in the style of a regularized least square, and we consider the non-rigid transformation as a functional in RKHS. Local minima often exists in gradient based numerical optimization methods, so we use annealing framework to escape the trap of local minima. Finally, we use low-rank kernel matrix approximation to reduce the computational complexity. In our previous work [19], it has been shown that the MoAG model can get better performance in most degradations on 2D point set. Here, we add more method details and experimental analysis. The experimental results demonstrate that our proposed method is robust against a large degree of degradations, and it outperforms several existing methods in most tested scenarios on 2D, 3D point set, and real image data.The rest of the paper is organized as follows: in Section 2, we present the method to represent a point set using mixture of asymmetric Gaussian model. In Section 3, we formulate point set registration based on correlation based method as an optimization problem, and search the optimal solution in RKHS by kernel method. In Section 4, we show the experimental results on 2D, 3D synthetic data and 2D real images. In Section 5, we present a conclusion.Single Gaussian and Gaussian mixture models (GMM) have been proven the popular models in computer vision and pattern recognition. However, they do not always adapt and fit any distribution of patterns, Kato et al. [1] introduced a new probability model named asymmetric Gaussian model (AG) which can capture spatially asymmetric distributions. Asymmetric Gaussian model is another form extending from Gaussian model. It is shown that Gaussian distribution has a symmetric distribution while asymmetric Gaussian representation has an asymmetric distribution, as shown in Fig. 1, where the density functions are plotted. The distribution of asymmetric Gaussian model is given by(1)A(x|μ,σ2,r)=1(2πσ2)D/2((r+1)/2)D[γexp(−|x−μ|22σ2)+(1−γ)exp(−|x−μ|22r2σ2)],where D is the dimension of data, γ ∈ (0, 1) denotes the weighting between two Gaussian components of an asymmetric Gaussian model,γ=1for x ≤ μ, andγ=0for x > μ. σ2 and r2σ2 are the standard deviations of an asymmetric Gaussian model. Note thatr=1means asymmetric Gaussian model is equivalent to Gaussian model.Based on the definition of a single asymmetric Gaussian model, it is easy to construct a mixture of asymmetric Gaussian model which may be well approximate almost any density with a linear combination of local asymmetric Gaussian model. The overall density of the J-component mixture is given by(2)p(x)=∑j=1JwjA(x|μ,σ2,r),where wjis the weight of each component, and{wj}j=1Jare mixing proportions satisfying 0 ≤ wj≤ 1 and∑j=1Jwj=1.In this paper, we define the first point setXM×D=(x1,…,xM)Tas the moving Model set, and the second point setYN×D=(y1,…,yN)Tas the fixed Scene set,X,Y∈R2orX,Y∈R3. We can represent both point sets by a single mixture of asymmetric Gaussian model respectively where the number of asymmetric Gaussian components is equivalent to the number of points in the point set. Note that all asymmetric Gaussian components are weighted equally, and both point sets are normalized as distributions with zero mean and unit variance first.We motivated by the reason that the error of L2-minimizing estimator is less than the error of maximum likelihood estimation (MLE) [11]. Then, in this paper, we use correlation-based method to estimate the similarity between the input point sets, where the point sets are represented by mixture of asymmetric Gaussian model. L2 Euclidean distance is widely used in multiple applications, and many registration methods [2,8–10] based on it. Thus, the problem of point set registration can be well formulated by minimizing the L2 Euclidean distance between two point sets. Note that the structure of the Model set is transformed as v(X, θ) after each step of registration. The correlation between two point sets based on L2 Euclidean distance is defined as follows:(3)dist(X,Y,θ)=∫(MoAG(Y)−MoAG(v(X,θ)))2dx,where MoAG( · ) denotes mixture density of asymmetric Gaussian model constructed from a point set. Thus the parameter θ of the non-rigid transformation can be solved by minimizing Eq. (3)(4)θ^=argminθ∫MoAG(Y)2dx+∫MoAG(v(X,θ))2dx−2∫MoAG(Y)MoAG(v(X,θ))dx.Note that the first term ∫MoAG(Y)2dx is a constant, because it is independent of θ. The second term does not require to estimate, since it can be evaluated exactly for any value of θ. The last term of Eq. (4), ∫MoAG(Y)MoAG(v(X, θ))dx is the key quantity to estimate. Formally, this estimation is equivalent to the Integrated Square Error (ISE or L2E) [10] which is a robust estimator to estimate densities between two point sets. Rewriting Eq. (4), we obtain(5)θ^=argminθ[∫MoAG(v(X,θ))2dx−2MN∑i=1N∑j=1MMoAG(yi−v(xj,θ))],where v is a parameterized spatial transformation family in point set registration, and MN is a normalization term. Under the registration framework, the first term of Eq. (5) is only dependent on Model set, and it is not a key component to estimate. Ignoring the constant independent of parameter θ, σ2, and r, so we can define the cost function of the registration algorithm as follows:(6)Cost(θ,σ2,r)=C−2MN∑i=1N∑j=1MMoAG(yi−v(xj,θ)),whereC=1(2πσ2)D/2((r+1)/2)Dis a constant.Note that the corresponding points can be estimated by minimizing the last term of Eq. (6), then the newly estimated point position of point yithat corresponds to xjis defined as:tj=∑i=1Nφjiyi,where φ is a soft assignment [20–22] correspondence matrix of size M × N in the interval [0, 1], and satisfies∑i=1Nφji=1forj∈1,2,…,M.Mathematically, for points{yi,i∈1,2,…,N}and{xj,j∈1,2,…,M}of two point sets, the distance between arbitrary two points (∀yi∈ Y, ∀xj∈ X) satisfies a Gaussian distribution, we obtain(7)φji=12πσ2exp(−∥yi−v(xj,θ)∥22σ2).Then for outliers, we use xo, yoto denote the outlier cluster centers as discussed in [4](8)φoi=12πξ2exp(−∥yi−xo∥22ξ2),(9)φjo=12πξ2exp(−∥yo−v(xj,θ)∥22ξ2),whereξ denotes a very large scale, in our method, we setξ=max(yi)2. Thus we can obtain the soft assignment correspondence matrix after row and column normalizationφji=φji∑j=1Mφji+φoi,andφji=φji∑i=1Nφji+φjo, respectively. Following the soft assignment, the correspondences can be updated iteratively.The correspondence set is used to update the transformation between Model and Scene point set. After estimating the correspondence in the Section 3.2, we can obtain the newly set of point correspondencesS={(tj,xj)}j=1Min each iteration. So the objective function (6) can be rewritten as follows:(10)Cost(θ,σ2,r)=C−2M∑j=1MMoAG(tj−v(xj,θ)).The motivation to use reproducing kernel Hilbert spaces (RKHS) and the representation theorem: 1) the representation theorem which states that every function in an RKHS is a linear combination of the kernel term evaluated at the training points, and 2) the empirical risk minimization problem from an infinite dimensional to a finite dimensional optimization problem can be effectively simplified by the representation theorem. Then the functional form of the non-rigid transformation family v can be found by calculus of variation in an RKHS.Given the Model setX∈RD,the Scene setY∈RD(whereD=2orD=3), and the estimated correspondences S, so we can define an RKHSHwith a positive definite kernel function k. In this paper, we choose Gaussian radial basis function (GRBF) as the kernel function of our method, which is defined as:k(xi,xj)=exp(−β∥xi−xj∥2),where β is a constant. Thus, we can obtain the kernel matrix K(11)K=[k(x1,x1)…k(x1,xM)⋮⋱⋮k(xM,x1)⋯k(xM,xM)],whereK:RD×RD→RD×Dis an M × M matrix. Note that the kernel matrix associated with a positive definite kernel is positive semi-definite.The transformation functionv∈Hcan be found by minimizing the following regularized least-squares [23,24]:(12)ɛ(v)=minv∈HCost(θ,σ2,r)+λ2∥v∥K2,where the first term is the empirical risk, and the second term is the Tikhonov regularization [25], λ > 0 is a trade-off parameter, ‖ · ‖Kdenotes a norm in the RKHS. Tikhonov regularization form smoothly determines the trade-off between∥v∥K2and the Cost(θ, σ2, r), most importantly, it solves the ill-posed problems in point set registration.According to the representation theorem [26], the solution of Eq. (12) to the Tikhonov regularization can be written in the following form:(13)v(·)=∑j=1MhjK(xj,·)for somehj∈RM.For such a non-rigid transformation, the norm in the RKHS can be rewritten as follows:(14)∥v∥K2=tr(HTKH),whereH=(h1,…,hM)Tis a coefficient matrix of size M × D.Substituting Eqs. (13) and (14) into the cost function (10), we can therefore rewrite it with the Tikhonov regularization as follows:(15)E(H,σ2,r)=C−2MMoAG(T−KH)+λ2tr(HTKH),where tr( · ) denotes the trace of a matrix, andTis the estimated correspondence set of the point set Y that corresponds to X.The aforementioned cost function is convex in the neighborhood of the optimal position and, most importantly, always differentiable. Thus, the numerical optimization problem can be solved by employing some gradient-based optimization methods, such as Quasi–Newton method [27], or global optimization methods, such as Particle Swarm Optimization (PSO). Taking the partial derivative of Eq. (15) with respect to H, we obtain:(16)∂E∂H=2KMσ2(πσ2(r+1)2/2)D/2×(γV∘(B⊗1)+(1−γ)1r2V∘(B^⊗1))+λKH,whereV=KH−T,B=exp(diag(VVT)/2σ2),B^=exp(diag(VVT)/2r2σ2),1 is an 1 × D row vector of all ones,γ=1for tj≤ (KH)j, andγ=0for tj> (KH)j. ○ denotes the Hadamard product and ⊗ denotes the tensor product.However, there often exists local minima which may trap the numerical optimization. Since the large global motion or the non-rigid transformation model has high degrees of freedom. In order to escape from the trap of local minima, we adopt a coarse-to-fine manner, i.e., deterministic annealing optimization framework, which is a useful heuristic method introduced by [4]. The initial temperatures of our method is σ2. Then we reduce the temperatures according toσ2=α×σ2,where α is an annealing rate in the interval [0.90, 0.99], and we setα=0.93in our experiments. Note that the temperature should be set to a relatively large value to make the annealing process slow enough, in this way, we can obtain robust experimental results. Finally, the cost function will converge to an optimal solution after several iterations.The kernel matrix [26,28] plays an important role in the regularization theory, and it provides an easy way to choose an RKHS. However, it is time consuming with the original kernel matrix in registration method, in particular, handling large amount of points. The computational complexity of our method is approximatelyO(M3+M2+MN). Motivated by the principle component analysis, we have an idea to use a low-rank kernel matrix to approximate the original one, because it can choose several principle feature vectors of the kernel matrix, and effectively reduce the computational complexity. Hopefully, low-rank kernel matrix approximation [29] can yield a large increase in speed with little loss in accuracy. Then the low-rank kernel matrix approximation of K can be defined as follows:(17)minK^∥K−K^∥*,where ‖ · ‖* denotes L2 and Frobenius norms.K^is the closest τ-rank matrix approximation to K, and it satisfies both L2 and Frobenius norms. Thus, we can use the matrixK^in place of the original kernel matrix K.Using eigenvalue decomposition of K, we obtain the approximation matrix(18)K^=QΛQT,where Λ is a diagonal matrix of size τ × τ with τ largest eigenvalues, and Q is an N × τ matrix with the corresponding eigenvectors.Based on the approximation matrixK^,we can calculate parameter matrixH^of size τ × D instead of the original matrix H. Thus, Eq. (13) can be rewritten as follows:(19)v=QΛH^.Substituting Eqs. (18) and (19) into Eq. (15), the cost function of our method therefore can be rewritten as follows:(20)E^(H^,σ2,r)=C−2MMoAG(T−UH^)+λ2tr(H^TUH^),whereUM×τ=QΛ.Thus, in the optimization processing, we use the partial derivative of Eq. (20) with respect toH^instead of the Eq. (16)(21)∂E^∂H^=2UMσ2(πσ2(r+1)2/2)D/2×(γV^∘(P⊗1)+(1−γ)1r2V^∘(P^⊗1))+λUH^,whereV^=UH^−T,P=exp(diag(V^V^T)/2σ2),P^=exp(diag(V^V^T)/2r2σ2),γ=1fortj≤(UH^)j,andγ=0fortj>(UH^)j.In practice, τ ≪ M and we setτ=15in our experiments. Therefore, the computational complexity of our method will be reduced toO(τ3+τ2+τN)approximately, then it can be expressed as O(N) if the number of point set is largish. In other words, low-rank kernel matrix approximation enables our method to be applied to large point sets.There are mainly six free parameters: the scale parameter σ2, the asymmetric Gaussian weighting parameter r, the GRBF parameter β, the regularization parameter λ, the number of low-rank feature vectors τ, and the annealing parameter α, in our method.Scale parameter: σ2 denotes a capture range for each mixture of asymmetric Gaussian model, and we set the initial scaleσ2=(1MND)∑i=1N∑j=1M∥(yi−xj)∥2.Asymmetric Gaussian weighting parameter: r controls the asymmetric scale of each asymmetric Gaussian model, and r is set to 1.5.GRBF parameter: β controls the structural strength of the moving point set. β produces locally smooth transformation with small values, while it produces globally translation transformation with large values. Thus, β is set to 0.8.Regularization parameter: λ plays an important role to trade off the empirical risk and smoothness regularization, and λ is set to 0.1.The number of low-rank feature vectors: τ is a small integer, and denotes the degree of approximation between low-rank kernel matrix and the original one. τ ≪ M, and it is set to 15.Annealing parameter: α is annealing rate in the deterministic annealing framework. In order to get robust results, the annealing process is need to slow enough for the method. Due to α is normally between [0.90, 0.99], thus α is usually set to 0.93.Point set registration algorithms usually contain iteration process, we can estimate the non-rigid transformation parameters to update and move the Model point set iteratively, until reach a given termination condition. In the deterministic annealing framework, the termination conditionσfinal2is set to 0.001 according to the initial scale σ2.The pseudo code of our non-rigid point registration method is outlined in Algorithm 1(referred to as MoAGREG).

@&#CONCLUSIONS@&#
