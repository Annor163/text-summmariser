@&#MAIN-TITLE@&#
A hybridization of an evolutionary algorithm and a parallel branch and bound for solving the capacitated single allocation hub location problem

@&#HIGHLIGHTS@&#
A well-known capacitated hub location problem CSAHLP is considered.We develop a hybrid of evolutionary algorithm and branch and bound (EA-BnB).Branch and bound is implemented by using parallelization techniques.The results of experimental study show reliability and efficiency of the EA-BnB.The EA-BnB achieved improvements regarding both solution quality and CPU time.

@&#KEYPHRASES@&#
Metaheuristic,Hybrid algorithms,Evolutionary algorithm,Branch-and-bound,Network design,Hub location problems,

@&#ABSTRACT@&#
In this study, we propose a hybrid optimization method, consisting of an evolutionary algorithm (EA) and a branch-and-bound method (BnB) for solving the capacitated single allocation hub location problem (CSAHLP). The EA is designed to explore the solution space and to select promising configurations of hubs (the location part of the problem). Hub configurations produced by the EA are further passed to the BnB search, which works with fixed hubs and allocates the non-hub nodes to located hubs (the allocation part of the problem). The BnB method is implemented using parallelization techniques, which results in short running times. The proposed hybrid algorithm, named EA-BnB, has been tested on the standard Australia Post (AP) hub data sets with up to 300 nodes. The results demonstrate the superiority of our hybrid approach over existing heuristic approaches from the existing literature. The EA-BnB method has reached all the known optimal solutions for AP hub data set and found new, significantly better, solutions on three AP instances with 100 and 200 nodes. Furthermore, the extreme efficiency of the implementation of this hybrid algorithm resulted in short running times, even for the largest AP test instances.

@&#INTRODUCTION@&#
Hub location problems arise from transportation and telecommunication networks when it is not desirable to directly transport goods, passengers or data between origin–destination pairs, due to extremely high transportation costs. As an alternative, a hub network is used, where hubs act as collection, consolidation, transfer and distribution points. The advantage of exploiting a hub network are lower transportation costs between the hubs, which leads to reductions of overall transportation costs in the network. Origin and destination nodes can be connected to one or more hubs, depending on whether the design constraints allow single or multiple allocation. It is usually assumed that the underlying hub network is fully connected, while non-hub nodes are not necessarily connected to each other. Furthermore, all origin–destination flow has to be routed via at least one hub.Hub location problems usually involve two decision making tasks: choosing which hubs to establish from the given set of potential hubs and the allocation of non-hub nodes to established hubs. Various constraints and objective functions may be assumed. The most common hub location problems are those with the center and median objectives. In the hub median problems, the objective is to minimize the total transportation costs in the network, which is important in transportation systems, such as air cargo and passenger transport, postal and other delivery systems, etc. However, in the case of excessively large or expensive origin–destination distances, the objective of the median type may lead to unsatisfactory results. In these cases, hub center problems represent a better model, minimizing the maximum distance or cost between origin–destination pairs. Hub center problems are mostly applied in designing fast delivery systems (DHL, Fedex, LightSpeed Express, etc.), which are used for urgent deliveries and transportation of perishable or time sensitive items. Various additional constraints may be imposed, such as fixed number of hubs to be located, limited capacities of both hub and non-hub nodes, capacity constraints on links in the network, fixed costs for establishing hubs or hub network, etc. A detailed review of hub location problems and their applications may be found in [3,6].In this paper, we consider a variant of the hub location problem, in the literature known as the capacitated single allocation hub location problem (CSAHLP). In this problem there is capacity restriction on the incoming flow of each potential hub node. The number of hubs to be installed is not fixed in advance, but installing a hub at some location assumes certain fixed costs. We want to choose locations for installing hubs and to allocate each non-hub node to exactly one, previously installed hub, in such a way that the sum of transportation costs between origin–destination pairs and the costs for establishing hubs is minimized. The CSAHLP is an NP-hard optimization problem, since its uncapacitated variant (USAHLP) is known to be NP-hard, even when the set of hubs is fixed [18].The CSAHLP was not so extensively studied in the literature, compared to its uncapacitated version – the USAHLP. There is a plethora of papers dealing with the uncapacitated single allocation hub location problem. Up to now several formulations of the USAHLP were proposed in the literature [2,14,18], and several exact and heuristic methods were developed for solving the USAHLP, see [1,2,21,25]. We refer to some recent studies dealing with the USAHLP, see [7,13,16,20].In the literature one can find several papers that consider the CSAHLP and its appropriate solution methods. Campbel [5] presents the first mixed integer linear programming (MILP) formulation for the problem. Ernst and Krishnamoorthy in [11] extend the formulation of the uncapacitated version of the problem from [22] to the capacitated case. The authors in [11] present another MILP formulation of the problem by involving an additional set of constraints. This formulation was later corrected by Correia et al. in [9] by adding a missing constraint set. Two heuristic algorithms for solving the CSAHLP are proposed in [11], based on simulated annealing (SA) and random descent (RDH) approaches. The upper bounds obtained by the heuristics are used in an LP-based branch- and bound method, which provides optimal solutions for small and medium size AP problem instances with n≤50 nodes. For realistic sized AP problems n=100, 200 that could not be solved exactly, the proposed RDH and SA heuristics provided solutions in a reasonable amount of computer time.Contreras et al. [8] present a Lagrangian relaxation (LR) enhanced with reduction tests, which exploits the structure of the problem and decomposes it into smaller subproblems that can be solved efficiently. The authors present optimal solutions obtained by LR approach for small and medium size AP instances with n≤50 nodes, and tight upper and lower bounds in the case of newly generated instances of larger dimensions. A heuristic approach is employed to obtain good quality feasible solutions for the tested instances.Stanimirović in [23] proposed a genetic algorithm (GA) approach for solving the CSAHLP. The GA from [23] proved to be efficient on small and medium size AP test instances with n≤50 nodes and had a similar performance on larger AP instances with n=100, 200 nodes as the RDH and SA heuristics. In the study by Randall [19], four variations of the ant colony metaheuristic (ACO) are proposed as a solution method for the CSAHLP. The developed ACO approaches use different learning mechanisms for determining the location of hubs and the assignment of non-hub nodes to hubs. The authors investigate the effects of the solution component assignment order, and the form of local search heuristics through the set of computational experiments on small and medium size AP instances with n≤50 nodes.A variant of the CSAHLP is studied in paper [15], where a capacity on the flow that transverses each hub is assumed, and a branch-and-cut algorithm is proposed for solving this problem. Costa et al. [10] propose a bi-objective approach to the CSAHLP. Instead of using capacity constraints to limit the amount of incoming flow in hubs, the authors introduce a second objective function to the model that tries to minimize the time to process the flow entering the hubs. For an overview of the existing literature on the CSAHLP and related problems, we refer the reader to [3].We use a revised formulation of the CSAHLP from [9], including the missing cuts, the lack of which could lead to infeasible solutions, as demonstrated by Correia et al. in [9]. A network I of n distinct nodes is given, with a matrix Cijof transportation cost per unit flow between any two nodes i and j from the network I. In general, this matrix represents any abstract value corresponding to an ordered pair of two nodes. However, in practice, it usually depends on the distance between i and j. Therefore, for a given node k we will label a node l, l≠k as the nearest node to node k, if it has the lowest value of transportation cost from the node k, i.e.,Ckl=minj,j≠kCkj.The amount of flow from an origin i to destination j is given by the flow matrix Wij. This matrix is not necessarily symmetric, and Wiimay be greater than 0. The cost of establishing a hub is associated with every node k and is given by a constant fk. Similarly, the collection capacity of each potential hub k is given by Gk. All flow from an origin i to a destination j has to be routed via some hub nodes k and l, respectively, where k, l∈H and H⊆I is a set of established hubs. Therefore, direct transportation between non hub nodes is not allowed. The costs of collection (from origin to hub), transfer (from hub to hub), and distribution (from hub to destination) are given by the parameters χ, α and δ, respectively. Hence, the total transportation cost (per unit flow) from an origin i to a destination j, via hubs k and l, is equal to χCik+αCkl+δClj. Since the transfer between the hubs has lower cost compared to collection and distribution, it is assumed that χ, δ>α.A binary decision variable Zijtakes the value of 1 if node i is allocated to a hub node j∈H, and 0 otherwise. Hubs are always allocated to themselves, hence, if Zkk=1 then and only then k is a hub. Zkk=1⇔k∈H. No direct flow between non-hub nodes i and j is allowed, so we introduce continuous non-negative variablesYkliwhich represent the amount of flow originated from node i, collected at hub k and distributed via hub l. The triangle-inequality holds for the transportation costs between nodes, so the flow will ever travel via at most two hubs. Finally, Oiand Djrepresent the amount of flow which departs from i∈I and the amount of flow that is distributed to node j∈I, respectively, i.e., Oi=∑j∈IWijand Dj=∑i∈IWij.Using the notation given above, the CSAHLP is formulated as follows [9]:(1)min∑i∈I∑k∈ICikZik(χOi+δDi)+∑i∈I∑k∈I∑l∈IαCklYkli+∑k∈IfkZkksubject to:(2)∑k∈IZik=1for everyi∈I(3)Zik≤Zkkfor everyi,k∈I(4)∑l∈IYkli−∑l∈IYlki=OiZik−∑j∈IWijZjkfor everyi,k∈I(5)∑i∈IOiZik≤GkZkkfor everyk∈I(6)∑l∈I,l≠kYkli≤OiZikfor everyi,k∈I(7)Ykli≥0everyi,k,l∈I(8)Zik∈{0,1}everyi,k∈I.The objective function (1) minimizes the sum of collection, transfer and delivery costs between all origin and destination nodes via their corresponding hubs, and the sum of the fixed cost of establishing hubs. Each non-hub node must be allocated to precisely one hub, as indicated by the constraint set (2). Hubs are allocated each to itself and non-hub nodes are allocated only to hubs, which is ensured by constraints (3). The constraint set (4) enforces the flow conservation equality in the network, while the constraint set (5) ensures that the collection in each hub is limited by the hub's capacity. The constraint set (6) ensures that if Zik=0 thenYkli,l∈Imust also be 0. This is the missing cuts set introduced in [9]. VariablesYkliare continuous and non-negative (7), while the variables Zijare binary (8).Let us assume that a set of hubs H⊆I is somehow predetermined and fixed. In such case, the sum of costs of establishing hubs is fixed, and the objective function is reduced to the sum of transportation costs, which needs to be minimized. For a fixed set of hubs H⊆I, we obtain a subproblem of the CSAHLP, denoted as the CSAHLP(H). Therefore, we modify the formulation from [9], in order to obtain the formulation of the subproblem CSAHLP(H), for a given set of hubs H. Using the same notation as in previous subsection, the subproblem CSAHLP(H) is formulated as follows:(9)min∑i∈I∖H∑k∈HCikZik(χOi+δDi)+∑k∈HCkk(χOk+δDk)+∑i∈I∖H∑k∈H∑l∈HαCklYkli+∑i∈I∖H∑k∈H∑l∈HαClkWliZik+∑k∈H∑l∈HαCklWkl+∑k∈Hfksubject to:(10)∑k∈HZik=1for everyi∈I∖H(11)∑l∈HYkli−∑l∈HYlki=(Oi−Wii)Zik−Wik−∑j∈I∖H,j≠iWijZjkfor everyi∈I∖H,k∈H(12)Ok+∑i∈I∖HOiZik≤Gkfor everyk∈H(13)∑l∈H,l≠kYkli≤OiZikfor everyi∈I∖H,k∈H(14)Ykli≥0for everyi∈I∖H,k,l∈H(15)Zik∈{0,1}for everyi∈I∖H,k∈H.Since each hub from H⊆I must be allocated to itself, and having in mind that variables Zikare binary, the constraint set (3) becomes trivial and can be removed from the CSAHLP(H) model. All other constraint sets correspond to the same constraint sets from the full model. The difference is that in Zikvariables, the first index i takes values only from the set I∖H, and the second index k takes values from the set H (15). Similarly, in theYklivariables, i∈I∖H, and k, l∈H hold (14). Since the hubs are predetermined, the objective function (9) must be reformulated. First term from (1) is broken down into two terms in (9): one term for the collection and distribution from a non-hub node i to a hub node k and one term for the collection and distribution from a hub k to itself. The second term from (1) is split into three terms in (9): one for the transfer of all the flow originating from a non-hub i via hubs k and l, a second term for the transfer of the flow originating from a hub l destined to a non-hub i via its hub k and another term for the transfer of the flow originating from a hub k destined to a hub l. The last term represents the sum of fixed costs for establishing hubs.Note that in the case that h=|H|<<|I|=n, the number of variables and the number of constraints in the CSAHLP(H) are significantly lower compared to CSAHLP formulation. More precisely, instead of n3+n2 variables in the CSAHLP model, we have (n−h)*h2+(n−h)*h variables in the CSAHLP(H). In practice, the case of |H|<<|I| occurs in most situations. For example, for AP test instances with 200 nodes, obtained from the Australian Post network [4], the number of hubs in the optimal or best known solutions is either 2, 3, or 4. This fact was the motivation to create the model for the subproblem CSAHLP(H) and to use it for solving the CSAHLP, which will be explained in the following sections.Capacity constraints (5) in the CSAHLP formulation ensure that the incoming amount of flow in a hub is less than its capacity limit. These constraints represent the main difference of the CSAHLP compared to its uncapacitated variant – the USAHLP. A combination of an evolutionary-based algorithm and local search procedures was successively applied to the USAHLP [16]. However, the capacity constraints (5) may cause various problems when attempting to solve CSAHLP by using a standard evolutionary approach, since there is no guarantee that a pair of feasible individuals will produce feasible offspring when applying an evolutionary operator. Further, the use of local search heuristics, such as those implemented in [16] for the USAHLP, often leads to violating the capacity constraints on hubs when applied to the CSAHLP, and therefore, does not yield good solutions.In this study, we propose a hybrid method for solving the CSAHLP, named Hybrid EA-BnB, which represents a combination of the Branch-and-Bound method (BnB) and an evolutionary approach. The evolutionary part is constructed in such a way to minimize the possibility that infeasible individuals would be produced. A relatively low complexity of the subproblem CSAHLP(H) is the main motivation for applying the BnB method, which is designed so that the overall running time of the hybrid method is not prolonged significantly.An individual's genetic code carries the information only about which nodes are chosen as hubs and which are not. In order to avoid the re-calculation of the objective values of the individuals’ codes that appear multiple times during the algorithm's run, the evaluated objective values are stored in a cache-queue data structure Cache. When the same code is obtained again, its function value is taken from the Cache.In each generation of the proposed hybrid method, for each individual J from the population, the following steps are performed to obtain a valid solution:•search the Cache for individual J;if individual J is not in the Cache, attempt to allocate nodes to hubs using a simple allocation algorithm;if J is not in the Cache, and simple allocation algorithm failed, invoke the parallel branch and bound BnB(J) algorithm with certain restrictions to solve CSAHLP(Hubs(J)).After all individuals are processed in this manner, the BnB is invoked on the best candidate in order to try to obtain some improvements. Then, the selection operator chooses pairs of individuals which will undergo crossover mating. The recombination of the parents produces new candidate solutions, which are further subject to a mutation operator with a certain probability. The described process is iteratively repeated until certain stopping criteria are met. Finally, BnB is invoked on the best individual with a new attempt to improve it. The basic concept of the hybrid EA-BnB for solving the CSAHLP is given in Algorithm 1.The preprocessing part is used to calculate the average (mean) capacity of all nodes and the average fixed cost of nodes, and to sort the outgoing flow set O in descending order into an enumerated array called SortedO. To determine the benefit of this approach, sorting of the set O can be switched on or off using the parameter sortO, see 4.1.In each generation, one individual with the best solution obtained by the SimpleAllocation algorithm is kept as BestCandidate. At the end of each generation, this individual is improved by the BnB algorithm, using one set of parameters (parameter improve). As the last step in the whole algorithm, BnB is invoked again on the individual with the best overall solution, with a different set of parameters (final). The parameters improve and final will be explained in Section 3.3.Algorithm 1Hybrid EA-BnB.Let I=0, 1, …, n−1 be a given set of enumerated nodes in the network. An individual is represented by a binary vector of n bits. Bit positions in the binary vector are enumerated as 0, 1, …, n−1 and each bit corresponds to one node in the network. A hub is established at node k∈I if and only if the bit value on the corresponding position k in the vector is equal to 1. More precisely, if x is the bit value at position k, then Zkk=x. This means that the binary vector (genetic code) carries information only about established hubs and not about allocation of non-hub nodes to hubs.A population numbering a certain number of individuals Nindis generated pseudo-randomly and a bias is introduced, where Nindis a parameter. An individual is created by setting each bit in its genetic code with a certain probability, using a biased pseudo random number generator. The probability p(k) that the bit k will be set to 1 is calculated as:p(k)=(Gk/AverageCapacity)*(AverageCost/fk)*(h/n).The factor Gk/AverageCapacity favors the nodes with capacities higher than average, while the factor AverageCost/fkfavors the nodes with low fixed costs. The factor h/n, where h is a parameter, ensures that only a few nodes are initially selected as hubs in each individual. The value of the parameter h is determined experimentally and set to 5. Finally, if for some k, Ok>Gkholds, then the node k cannot be a hub, because the capacity constraint for node k cannot be satisfied. In order to avoid generating individuals that have located hubs with insufficient capacities, in the case of Ok>Gk, we set p(k)=0.It is still possible that an individual randomly generated in this way would not provide a feasible solution, due to the capacity constraints. If an individual from the initial population does not yield a feasible solution using the SimpleAllocation algorithm, we add more hubs to it, in a pseudo-random way, one by one, until a feasible solution is reached. In other words, we keep changing zero to one in the genetic code of the infeasible individual, until a valid solution is obtained. The SimpleAllocation algorithm will be explained in the next subsection.For each individual J in the population, a set of hubs H=Hubs(J) is obtained from the genetic code. To avoid duplicate processing, the solution to the CSAHLP found for each individual J is cached. If there is no cache entry for J, the algorithm SimpleAllocation is invoked. The goal of this algorithm is to quickly (in polynomial time) provide a feasible solution to the problem. In early stages of processing, we are not concerned with finding optimal solutions of the CSAHLP(H) for a fixed set of hubs H. Instead, we are only searching for various configurations of hubs which lead to good, feasible solutions, by applying the SimpleAllocation procedure. The structure of SimpleAllocation is presented in Algorithm 2.Algorithm 2SimpleAllocation.In the SimpleAllocation algorithm, each established hub is allocated to itself, following the assumptions of the problem. For each non-hub node i, the algorithm sorts the located hubs in ascending order of distance from i, and then attempts to allocate i to the nearest hub k∈H that has enough remaining capacity Gk−Tk. The value of Tkis kept for each hub k∈H, and it must never exceed the capacity limit Gkof a hub k (see constraint (12)). The strategy of allocating non-hubs to closer hubs is used to reduce the total transportation costs in the objective (9). The non-hub nodes are processed in descending order of their outgoing flow SortedO. In this way, we reduce the possibility of reaching the capacity limit of a located hub. In other words, it is better to allocate non-hub nodes with large capacities first, while the hubs are still relatively empty.This simple algorithm for allocation of non-hub nodes showed to be very effective in practice, i.e., it produced valid solutions for almost all hub configurations. If the procedure SimpleAllocation(J) does not yield a valid solution, the individual J is subjected to the BnB algorithm. Among all solutions obtained in one generation by using SimpleAllocation, the solution with the lowest total cost is stored as BestCandidate. In order to improve the best obtained solution, the BnB(BestCandidate) is invoked after all individuals have been processed.The running time of SimpleAllocation(J) is O((n−h)*h*ln(h)), where h=|Hubs(J)|.The purpose of the SimpleAllocation algorithm is to quickly find a valid solution to the CSAHLP(H) for a fixed set of hubs H. The SimpleAllocation procedure is used to avoid invoking the parallel branch-and-bound algorithm on all individuals in every generation. On large scale instances, the algorithm may become time consuming if BnB is invoked numerous times, and for this reason, we tend to reduce the number of BnB calls as much as possible.The proposed BnB is designed to solve the CSAHLP(H) for a given set of hubs H. In order to reduce the processing time, several restrictions and cutoffs are applied, and therefore, the solutions returned by BnB cannot be considered as optimal in general case. However, the conducted computational results on AP hub data set show that the BnB produced solutions that coincide with the best known solutions presented in the literature up to now.The applied BnB method runs as a multi-threaded process. The search tree is traversed in a specific manner by all threads simultaneously. Different threads branch off very early in the search tree and explore and traverse different parts of it. A linear relaxation (LP) of the subproblem is used to obtain the lower bound value which is used as a guide to which branches are more promising than others.During the search process of BnB, in specific situations a particular node of the search tree is converted into a Task, which is then pushed onto the task list. The task list is shared between all threads. A Task is a structure which stores all allocations of nodes to hubs that have been done up to that point in the search tree, and it contains all information necessary for processing a part of the search tree starting from the corresponding node.Formally, Task is a set of ordered pairs (i, k), for some i∈I∖H, k∈H. The set Task may be empty, or it may contain any number of pairs (i, k). CSAHLP(H, Task) denotes a linear programming (LP) relaxation of the model CSAHLP(H) for a given Task. In CSAHLP(H, Task), (15) is replaced by 0≤Zik≤1, for every i∈I∖H, k∈H. Also, for all pairs (i, k) from the given Task, the values of the corresponding variables Zikare fixed to 1 and added as additional constraints, i.e., Zik=1 for every (i, k)∈Task.Each idle thread scans the task list and gets the first available Task, and further traverses the sub-tree from the node which corresponds to the Task. If the task list is empty, and therefore a Task is not available, a thread remains idle, waiting for other running threads to create more tasks. To initialize the whole process, an empty Task is created for the root node.Algorithm 3 shows the basic structure of the task processing part of the BnB method.Algorithm 3Parallel branch-and-bound algorithm – BnB.Algorithm 4Recursive subroutine – Branch.The routine Initialize() creates a certain number of threads, initializes all threads, and prepares them for computation. This includes creating an environment for solving the LP relaxation model CSAHLP(Hubs(J),Task), by adding all the constraints from the original model and setting the initial bound (cutoff) value. This is a crucial step: the bound value is set to the objective function (9) value of the currently best individual in the entire population. Therefore, every time BnB(J) is invoked, it is only looking for a solution of the CSAHLP(Hubs(J)) that is better than the currently best solution of all individuals in the population, if such a solution exists. This dramatically improves the performance, because very often the BnB algorithm ends rather quickly, being unable to reach a better solution. However, on those rare occasions when BnB(J) finds a better solution, the obtained solution is stored as the new best solution of the entire population. The Pop() subroutine gets the first available task from the task list, while Push() subroutine pushes a task onto the task list in a specific order. Main computation and task creation are performed in the Branch subroutine. The subroutine Terminate determines when it is the time to stop processing and return. The structure of Branch subroutine is presented in Algorithm 4.The subroutine Terminate() is used in the parallel while loop, as well as in the Branch subroutine. There are several criteria for termination of branching, which depend on the SearchType parameter. The SearchType parameter can be either improve or final. Assume nt is the number of threads running in parallel. The criteria for BnB search termination are applied as follows:1.If the level (depth) of search is more than 95% of the maximum depth, we do not terminate. We are close to a new solution and it will only take a few more SolveLP calls to reach it, so we do not want to terminate.If SearchType parameter is improve, we are only looking for a temporary solution that is better than the current best solution (the first improvement strategy). In the case that SearchType parameter is final, we continue with improving the solution, until the next termination criteria is met (the best improvement strategy).Terminate if the total number of nodes traversed by all threads is greater than a preset number. This number is set to 2*n*nt when SearchType is improve and to 2*n*nt2 when SearchType is final. However, if SearchType is final, every time a leaf node is reached and thus a new, better solution is found, the node counter resets back to 0, so effectively when SearchType is final the search continues until 2*n*nt2 nodes are traversed without improving the solution.If SearchType is improve, then check if reaching just one leaf node (linearly, without backtracking) from the current node would exceed the node limit set in the previous rule. In such a case, terminate. If SearchType is final do not terminate in this case because another thread might reset the node counter to 0 and so this thread could still reach a leaf node from the current node.As described in the previous section, invoking the LP solver to solve CSAHLP(Hubs(J), Task) includes fixing the decision variables Zikto 1 for every (i, k)∈Task. If the objective function value of the LP solution is worse than the currently set cut off value or if there is no feasible solution, the branching stops. Next, if the task is a leaf node, which means that all nodes are allocated to hubs and therefore all Zikvariables have binary values, then the current LP solution is also the solution of the binary problem for the current task, which effectively means that a new, better solution has been found.Otherwise, branching continues. The LP solver provides an array of values of the decision variables, such that 0≤Zik≤1, i∈I∖H, k∈H and H=Hubs(J). We choose next non-hub node i from the SortedO array, same as in the SimpleAllocation procedure, and for this node i we obtain the values of the corresponding LP decision variables, which are further stored in the array of (k, Zik) pairs, for every k∈H. This array is then sorted in descending order of the values of continuous variables Zik, such that the results with the values closer to 1 will be processed first. Similarly to the parameter sortO, another parameter sortH with possible values on and off is introduced to determine the contribution of this strategy of sorting the HubResults set, see Section 4.1.For all such pairs (k, Zik), new tasks are created and pushed onto the task list, if allowed by certain task creation criteria. This awakes idle threads, which have been waiting for new tasks to be created. Eventually, the current thread processes all (k, Zik) pairs which were not pushed onto the task list by recursively invoking the branching algorithm on a newly created task.The CanPushTask and Push routines may look hidden and insignificant, but they actually determine the performance of the entire BnB algorithm by deciding which tasks will be processed in parallel and in which order.The CanPushTask ensures that for the root node (level 1 node) and all its immediate children nodes (level 2 nodes), all tasks are pushed onto the task list. In general case, this will produce h nodes at level 2 and h2 nodes at level 3, where h=|H|. So, a full tree of tasks is created for the first 3 levels. Starting from level 4, the CanPushTask procedure follows these rules in this order:1.The first (k, Zik) from SortedHubResults is never pushed onto the task list. This means that the allocation of i to k with the highest value of Zikwill be processed immediately by the same thread.If Zik=0 the task is never pushed onto the task list, it waits for all other (k, Zik), Zik≠0 to be processed. It will be processed by the current thread when it backtracks. However, it is likely that the termination criteria will be reached before it is time to process such a node. In general, it is possible that even if Zik=0 in the optimal solution of the LP problem, the same Zikwill take the value of 1 in the solution of the binary problem. That is why the BnB method does not completely ignore this allocation of i to k, but processes it only if allowed by termination criteria.If the number of tasks in the task list is less than 2*nt, then push a task. This ensures that there are always enough tasks for all threads to process.If the SearchType parameter has the value improve, most likely no more tasks will be created after a full tree for the first 3 levels is created, due to the termination criteria. However, if the SearchType parameter is final, then the rules above will take effect. It is important to note that every time a new solution is found in the BnB process, the CleanTasks routine is called, which removes from the task list all tasks that are bound by the new best objective function value.As already stated, the Pop subroutine simply gets the first available task from the task list. Therefore, the order in which tasks are processed depends on how the Push subroutine updates the task list every time it puts a new task on it:•Tasks from lower levels (closer to the root node) are kept before tasks from higher levels, so that different threads will branch off as early as possible.Tasks at the same level are kept in the ascending order of the sort order value so, which is calculated based on the parameter task sort order tso, with possible values off, 1 and 2. If tso=off, then so=0 for all tasks. Hence, in this case the tasks will be processed in the order they are created. If tso=1, then so=value*(1−Zik), where value is the current LP objective function value, and 0≤Zik≤1, both obtained by the SolveLP procedure for CSAHLP(H, Task). This formula should favor the tasks with smaller values of the value variable and, at the same time, the variables Zikthat are closer to 1 than to 0. Finally, if tso=2, then so=1−Zik, thus ignoring the value and favoring only the values of Zikclosest to 1. The results of using different strategies for calculating the task sort order are presented in Section 4.1.Lets assume that nt=4 threads are running simultaneously. As described, a full tree for first 3 levels is created. Then, each of the 4 threads takes a different node from level 3 to process. The choice of the nodes to be processed depends on the order they were arranged in the Push subroutine. If all threads could reach a leaf node in their sub-tree without any backtracking, they would traverse a total of (|I|−|H|−3)*nt nodes. Since |I|≫|H| and |I|≫3, this number is very close to |I|*nt. This is the reason why the maximum number of nodes to be traversed is set to |I|*nt*2 in the Terminate subroutine, when the SearchType parameter has value improve. The use of the factor of 2 allows for some backtracking. When SearchType parameter is final, the maximum number of nodes is multiplied by a factor of nt to allow for more backtracking. Since the node counter is reset to 0 every time a solution is found, this limit is seldom reached. Instead, when SearchType parameter has the value final, the BnB usually ends after having processed all nodes which are not bound by the objective function value of SolveLP, thus effectively reaching the optimal solution.The choice of evolutionary operators in the EA is based on previous evolutionary-based implementations for solving similar hub location problems [13,16,23,24], etc. The values of the parameters used in EA and its operators were determined by the preliminary testing (Section 4.1) in which the starting parameter values are based on the results of tests of previous evolutionary algorithms applied on related hub location problems.In this EA implementation, a modification of the standard tournament selection with variable tournament size [12] is used. In 40% of the cases, the tournament size is 6, and 60% of the cases the tournament size is 5. The selection operator disables duplicate individuals from entering the next generation. This strategy helps in preserving a diversity of the genetic material and in keeping the algorithm away from a local optima trap.We have implemented a two-point crossover operator, which randomly chooses two bit positions in the genetic code and exchanges genetic material of selected parent-individuals between those points. In this way, two offspring-individuals are produced. The crossover operator is applied with a certain probability pcross, which determines the percentage of cases in which parent-individuals will reproduce by exchanging their genetic material.Offspring-individuals generated by two-point crossover are subject to a mutation operator with frozen bits [24]. A bit is called frozen if all individuals in the population have the same bit value at this position. The pmutparameter sets a base probability for any bit to mutate. This probability is pmut/n, where n is the length of the genetic code. However, if a bit is frozen, this base mutation probability is multiplied by the frozen factor parameter fr.Evolutionary operators are iteratively applied until one of the two stopping criteria are satisfied. The algorithm stops if the maximum number of generations Gmaxis reached or the best individual is repeated Rmaxtimes.The steady-state approach with elitist individuals is used as a generation-replacement strategy [17] in the proposed EA. In each generation, the worst 1/3 of the population is replaced, while the remaining 2/3 of the population survives to the next generation, thus preserving highly fitted genes. Individuals with the same objective value, but different genetic codes may dominate in the population after a certain number of generations. If their codes are too similar, this may cause a premature convergence of the EA. Therefore, the recurrence of such individuals is limited to some constant.All experiments were carried out on an Intel Core i5-3470 3.2GHz with 8GB RAM memory under Windows 7 Professional operating system. The hybrid EA-BnB algorithm was implemented in C programming language, using OpenMP for parallelization and CPLEX 12.1 package for solving the LP relaxation CSAHLP(H, Task).The EA-BnB was tested on standard AP hub instances from the literature [4], which include from n=10 to n=300 nodes. These are the only available hub test instances with fixed costs and capacity limits involved.A series of preliminary tests was first performed in order to tune the parameters. All tests were performed on the same parameter tuning test set comprising of 16 out of 30 of all the available test instances. This subset did not include the smallest and the largest test instances, because the former produced optimal results regardless of the parameters and the latter would take too much computing time to complete all tests.The following parameters were tested and tuned:•pmut: mutation probability;fr: frozen factor;pcross: crossover probability;Gmax: the maximum number of generations of the EA;Rmax: the maximum allowed repeats of the best individual;Nind: the number of individuals in the population.First, all combinations of the EA parameters pmut(values 0.3, 0.4, 0.5 and 0.6), fr (values 2, 3, 4 and 5) and pcross(values 0.75, 0.85 and 0.95) were tested, for a total of 48 separate tests, each consisting of 20 runs with different random seeds on each of the 16 test instances. In these tests, we have fixed the values of the remaining three parameters to Gmax=2000, Rmax=50 and Nind=200. These values were chosen based on our previous research of similar problems, see [16,23].Therefore, each combination of the parameters in Table 1represents 16*20=320 runs of EA-BnB. The columns in the table are:•the values of the parameters pmut, fr and pcross;the number of the best solutions (denoted by sol.) reached (out of the 16 test instances);the average number of the best solutions reached for different random seeds (avg.sol);the average time in seconds (denoted by avg.t(s)) needed to complete each run;the average gap (percentage) from the best solution, for different random seeds.It is important to note that the overall differences in time, average gap and the number of solutions are rather small, proving the stability of the EA regardless of the parameters used. Only one combination of the parameters pmut=0.3, fr=3, pcross=0.75 did not reach all of the 16 best solutions. Since the combination pmut=0.5, fr=4, pcross=0.85 resulted with the smallest average gap (agap=0.410) and the highest average number of best solutions reached (avg.sol.=15.50 out of possible 20), this combination was chosen as the best one and it was used in all tests forward.The next test was performed to determine Gmaxand Rmaxand the results are shown in Table 2. The structure of this table is the same as the preceding table, the only difference being the parameters used. For higher values of Gmaxand Rmaxthe EA-BnB results have a lower average gap and provide more stable solutions, but the running time increases. The parameter values Gmax=200 and Rmax=50 were chosen, representing a good compromise between the CPU time and the stability of the results.The last parameter of the EA that was tested is Nind. The first column in Table 3is the number of individuals used and the remaining 4 columns are the same as in previous two tables. Only the value of Nind=200 provided all 16 best solutions. However, 100 individuals were also enough for all test instances with up to 50 nodes and a population of 150 individuals proved to be large enough for all test instances with 100 nodes. Therefore, more individuals are needed in the population in order to keep the diversity of the genetic material and to avoid local optima trap. For this reason, a variable number of individuals which increases with the dimension of the problem n was used in all future tests:•Nind=100 individuals for up to n≤50 nodes.Nind=150 individuals for n=100 nodes.Nind=200 individuals for n=200 and n=300 nodes.Finally, a set of 12 tests was performed on the same 16 test instances, in order to determine the contribution of the strategies used in the BnB algorithm. Some of these tests took a long time to perform, so they were repeated not with 20, but with 10 different random seeds each. The contribution of the following strategies was tested:•Sorting of the O array, used both in the SimpleAllocation and the BnB algorithm – parameter sortO with values on (default) and off.Sorting of the HubResults array, used in the BnB algorithm – parameter sortH with values on (default) and off.Task sort order in the Branch routine of the BnB, parameter tso with values off, 1 and 2. The value off means that no task sorting is applied, i.e., the tasks are processed in the order they are created; the value 1 (default) means that the formula value*(1−Zik) is used for sorting the tasks, and the value 2 means that (1−Zik) is used instead.The results in Table 3 are presented in a similar way as in previous tables. Notice that the maximum possible value in the avg.sol. column was 10 and not 20, because 10 random seeds were used.The sortO parameter had a dominant impact on the performance, in terms of time, quality and stability of the solutions (Table 4). When this parameter is off, it is less likely that the SimpleAllocation algorithm would reach a solution. Therefore, BnB is invoked more often, increasing the running time. Also, the BnB itself would not always find the solution by traversing the allotted number of nodes, thus resulting in low stability (column avg.sol.) and low quality of the solutions (column sol.).The sortH parameter also affected the quality and the stability of the solutions significantly. Sorting of the HubResults array is important when all threads are running and no new tasks are being created. Sorting this array in descending order means that the Zikvariable from the LP solution with the value closest to 1 will be fixed and processed before those with lower values, which increases the probability that the solution will be reached, considering the node limit.Finally, the task sort order parameter provided a small but important impact on the solutions. It is important to note that if tso=off and sortH=on, the order in which tasks are created (and thus pushed onto the task list) depends on the sort order of HubResults. Only when both those parameters are off, the task creation and sort order is determined by the order in which the nodes appear in the input file and can be considered ‘unknown’. On the other hand, when tso=1 or tso=2, the task sort order is precisely determined. As the results demonstrate, tso=1 strategy provided one result which tso=2 could not reach. Therefore, sortO=on, sortH=on and tso=1 values were chosen for all other tests (Table 4).Another set of tests was performed to determine the effect of the number of BnB threads on the performance of EA-BnB. Again, 10 different random seeds were used for each of the 16 test instances. The results are shown in Table 5, with the first column showing the number of threads (nt).EA-BnB with more threads takes more time to complete for two reasons. First is the limit on the number of nodes that BnB traverses before quitting, which is |I|*nt*2 when SearchType is improve and |I|*nt2*2 when SearchType is final. The more threads there are, the more nodes will be traversed. When SearchType is final and the solution cannot be further improved, BnB with 4 threads will traverse 16 times more nodes than BnB with 1 thread before giving up. Second reason is a consequence of the first one: BnB with more threads will obtain better solutions, thus prolonging the number of generations of the EA. The benefit of this approach is clearly visible from the quality (column sol.) and the stability of the solutions (avg.sol. column). The test with 8 threads was performed on the same hardware configuration as other tests, and the CPU had only 4 physical cores.Based on this test, the number of threads is set to nt=4.Once the parameters were determined, a full test of all 30 test instances was performed. Again, in order to enhance and assess the reliability of the EA performance, each test instance is replicated 20 times and tested using different random seeds in every run. The results of the proposed hybrid EA-BnB were compared to the best known results from the literature and to optimal solutions obtained by CPLEX 12.1 solver on AP hub data set.In Table 6, results and comparisons on the AP data set with 10≤n≤50 nodes are presented in table columns in the following way:•Test instance name, including the number of nodes and a two-letter indicator of the type of fixed costs and the type of hub capacities. Letter L stands for loose and letter T stands for tight type of constraints. For example, hub50LT represents an AP test instance with n=50 nodes, loose fixed costs and tight capacity constraints.The optimal solution obtained by the CPLEX 12.1 solver – CPLEX.sol.Time needed to confirm the optimal solution – CPUCPLEX(in seconds).The best solution reached by the proposed EA-BnB, denoted as EA-BnB.sol.Average time needed for EA-BnB to reach its best solution – CPUstart(in seconds).Average time in which EA-BnB reached a stopping criterion – CPUend(in seconds).Average number of generations needed for EA-BnB to reach its best solution – Genstart.Average number of generations in which EA-BnB reached a stopping criterion – Genend.Average gap from the optimal solution through all EA-BnB runs – agap (in percents).Comparison of the EA-BnB and CPLEX 12.1 solutions.Test instances with up to 50 nodes were solved extremely efficiently by the hybrid EA-BnB, reaching optimal solutions in less than 1s. It is important to note that the result for test instance hub50TT has not been confirmed to be optimal until now. The solution for instance 50TT, obtained by both CPLEX solver and EA-BnB method, is presented in the last row of Table 6 and bolded. Our implementation of the CSAHLP model in CPLEX took 1068.3s to confirm for the first time that the optimal value of the objective function 1) is 417,440.9925 for this test problem. As a comparison, the hybrid EA-BnB reached the same solution in 0.912s.For larger AP data sets with 100, 200 and 300 nodes, optimal solutions are not known. The CPLEX solver reaches memory limits and ends prematurely. Instead of an optimal solution, for these test instances the best known solution from the paper by Contreras et al. [8] is shown in Table 7, along with the results obtained by EA-BnB.For 3 test instances with 100 and 200 nodes and loose hub capacity constraints, EA-BnB reached the best known solutions reported up to now. For 3 test instances (hub100TT, hub200LT and hub200TT) with tight hub capacity constraints, EA-BnB improved the best known solutions. The results for two test instances with 300 nodes have not been reported until now.For the test instance hub200LL the best solution obtained by EA-BnB is 241,992.9734 and it is worse than the solution reported in [8] with the value of 231,069.50. The best solution from literature prior to [8] was the same as the EA-BnB solution ([23,11]). In the EA-BnB solution for this test problem there are only 2 established hubs, at nodes 43 and 159. Two hubs can be chosen from 200 nodes in2002=19,900ways. Using CPLEX 12.1 solver we conducted an exhaustive search, trying to find a solution better than 242,000 for the CSAHLP(H) model for each of the 19,900 hub configurations such that |H|=2. The only reported solution was the one already reported by EA-BnB. Then, an analysis of 3 hub configurations shows that there are2003=1,313,400of them. Again, CPLEX was used to solve all 1.3million models of CSAHLP(H), |H|=3, with the upper bound value of 242,000 and there were no such solutions. This test took 10 days to complete. It is important to note that for most hub configurations CPLEX ends almost immediately because of the upper bound. Finally, another search using EA-BnB was conducted for this one test instance only, using a total of 30 random seeds and with a limitation that each individual in the population must have at least 4 hubs. The best solution reported by this test was 251,369.643675 and indeed it had 4 hubs. A summary of this exhaustive testing of the test instance hub200LL is:•An exact method, an exhaustive search of all hub configurations, proved that the best possible feasible solution with 1, 2 or 3 hubs is 241,992.9734, when the hubs are established at locations 43 and 159.The best solution with 4 or more hubs obtained by EA-BnB is 251,369.643675 and it is 8.8% worse than the solution 231,069.50 reported in [8].For all test instances EA-BnB proved to be very stable with very low average gaps. From our point of view it is highly unlikely that a solution with 4 or more hubs which would be 8.8% better than the solution reported by EA-BnB could exist. Any particular hub configuration H with any number of hubs can be relatively quickly checked by solving CSAHLP(H) with CPLEX. For these reasons, we contacted the authors of the paper [8] asking for clarification of the best solution that they obtained for the test instance hub200LL and also for the files for test instances with 60–90 and 125–175 nodes, which they generated and used in [8]. Unfortunately, to the present day we have not received a response from them.In Table 8we present comparisons of the results of existing methods for solving the CSAHLP on AP data set with 10≤n≤50 nodes. We compare the results of the proposed EA-BnB approach with:•Solution obtained by better of the two Lagrangean relaxation methods proposed in [8], denoted as LR2. The computational tests with LR2 were performed on an HP mobile workstation with a processor Intel(R) Core(TM)2 T7600 with 2.33GHz and 3.37GB of RAM memory.Random descent heuristic (RD) from [11], also tested on the DEC 3000/700 (200MHz).Simulated annealing heuristic (SA), which is also proposed in [11] and tested on the same platform as the RD.Genetic algorithm approach (GA), presented in [23] and run on an AMD Athlon K7/1.33GHz machine with 256MB RAM memory.In the first column related to the LR2 method, we indicate the optimality of the solution obtained as the best upper bound by LR2. In the second column, we present duality gap gap(%) relative to the lower bound provided by LR2. The third column shows the running time tLR2 (in seconds) that the LR2 needed to obtain upper bounds.For the heuristic methods RD and SA, we give the average gaps from the optimal solution agapRD(%) and agapSA(%), respectively, as well as total running times, tRD(s) and tSA(s), respectively. The best solution obtained by the GA approach is marked with opt, in cases when it coincides with the optimal solution. The average gap of the GA's best solution from the optimal one is presented in the column agapGA(%), while total running time of the GA method is given in the column CPUGA(s). The last three columns of Table 8 are related to the proposed EA-BnB method and contain: the best solution of EA-BnB, with mark opt when it is equal to the optimal one, total EA-BnB running time CPUend(s), and average gap of the best solution of EA-BnB from the optimal one agap(%), respectively.The results presented in Table 8 indicate that all considered methods reached optimal solutions for all considered instances. The CPLEX 4.0 used in [11] could not confirm the optimality of the solution for instance 50TT. The same solution was reached by LR2 method as the best upper bound in [8]. However, our implementation in CPLEX 12.1 solver, used for testing in this study, confirmed the optimality of the solution for 50TT, as it was mentioned above. Calculating the average gaps on the considered AP instances in Table 8, we obtain the values of 0.301%, 0.158%, 0.283%, 0.884%, and 0.067% for the LR2, RD, SA, GA, and EA-BnB methods, respectively. This means that the proposed EA-BnB method has the most stable performance on this data set, compared to heuristic approaches LR2, RD, SA, GA for solving the CSAHLP.Since different machines were used in computational studies presented in [11,23,8], and in this paper, total running times are not directly comparable. According to the data presented at www.spec.org, the configuration AMD Athlon K7/1.33GHz with 256MB RAM used for GA tests is [23] has around 8 time slower performance compared to the Intel Core i5-3470 3.2GHz with 8GB RAM, which is used for EA-BnB experiments in this study. If we calculate the average values through columns CPUGAand CPUendin Table 8, we obtain that the average GA and EA-BnB running times on AP instances with 10≤n≤50 nodes are 4.2210 and 0.578s, respectively. If we multiply CPUendby the factor of 8, we may conclude that the average EA-BnB running time is about the same as the running time of GA on small and medium size AP data sets.The average total running times of RD and SA heuristics on AP instances with 10≤n≤50 nodes are 3.3035 and 1.9895s, respectively. However, these CPU times cannot be precisely compared to the corresponding GA and EA-BnB running times, since the performance of platforms used for RD and SA tests in [11] are not directly comparable with the ones from [23] and this study. The average running time of LR2 for obtaining the lower and upper bounds is 10.5885s on this AP data set. Since the experiments have been run on different computers, the LR2 and EA-BnB running times are not directly comparable, but it is evident that EA-BnB average CPU time is considerably smaller than the average CPU time of LR2 method.In Table 9we present comparisons of the LR2 method and existing heuristics RD, SA and GA with the proposed EA-BnB approach for the AP instances with 100≤n≤300 nodes. On these instances, CPLEX was not able to provide exact solutions, due to memory limit. The results are given in a similar way as in Table 8. The best known solutions, obtained by LR2 and considered heuristic methods, are bolded in columns Best Sol. Note that in computational study in the paper [11], the best solution of the RD and SA methods is presented, together with corresponding RD and SA gaps from the best solution. Since the worse solution of the RD and SA is not given in [11], we are not able to present the solutions of RD and SA methods separately, and to directly compare the gaps from the best-known solutions in Table 9.As it can be seen from the results presented in Table 9, the proposed EA-BnB method outperforms all other heuristic methods for solving the CSAHLP in the sense of solution quality. The EA-BnB additionally provides solutions for the newly generated modified AP instances with n=300 nodes. From Table 9 we can see that the proposed EA-BnB also produces better solutions compared to the best solution (upper bound) obtained by the LR2 method. The exception is the case of 200LL, which is discussed above in details.If we calculate the average running times for LR2, RD, SA, GA and EA-BnB for AP instances with n=100 and n=200 nodes, we obtain the values of tLR2=6421.875, tRD=205.121, tSA=99.736, CPUGA=233.580 and CPUend=15.250s, respectively. Since only EA-BnB was tested on AP instances with n=300 nodes, these instances are excluded when calculating average time for the EA-BnB. By multiplying the average CPUendfor EA-BnB by the factor of 8, we obtain the value of 122s, which means that the EA-BnB is around two times faster compared to the GA on large-scale AP data set. As it was explained above, LR2, RD and SA running times are not directly comparable with the GA and EA-BnB running times.Based on the results presented in Tables 8 and 9, we may conclude that the advantages of the proposed EA-BnB method are more obvious as the problem dimension increases. Its efficiency and reliability in obtaining high-quality solutions show that the developed EA-BnB represents a valuable addition to existing methods for solving the CSAHLP.

@&#CONCLUSIONS@&#
This paper considers the capacitated single allocation hub location problem CSAHLP, which arises from many practical situations. Encouraged by promising results when applying evolutionary-based approaches to USAHLP and other hub location problems, we design a hybrid evolutionary algorithm with parallel branch-and-bound for solving the CSAHLP. The evolutionary part uses binary encoding, fine grained tournament selection, two-point crossover and mutation with frozen bits. The initial EA population is pseudo-randomly generated with a positive bias for hubs with large capacities and low fixed costs, providing good and diverse initial solutions. Once the hubs are established, the parallel branch and bound efficiently allocates non-hub nodes to hubs.The presented empirical study indicates excellent performance, reliability and efficiency of the described hybrid algorithm. 10 parameters of the EA-BnB were tuned in the preliminary testing, for a total of 76 different settings of the parameters, including the testing of the contribution of different strategies of the BnB algorithm. The hybrid EA-BnB method is extremely efficient in reaching optimal solutions on small and medium size AP hub problem instances. For larger problem dimensions, the presented EA-BnB has found best known solutions for AP instances with loose capacity constraints, and has improved three solutions for AP instances with tight capacity constraints.Future work will be directed to adapting the proposed EA-BnB to solving some other capacitated, as well as uncapacitated hub location problems in order to solve large problem dimensions in an efficient manner.