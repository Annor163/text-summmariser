@&#MAIN-TITLE@&#
An adaptable navigation strategy for Virtual Microscopy from mobile platforms

@&#HIGHLIGHTS@&#
The JPEG2000 standard is very suitable to access and interact with WSIs.The decoding strategy allows a granular, independent and efficient decompression.Index files enable a fast access to specific JPEG2000 data regardless the WSI size.This architecture permits to adapt content to user, device and network bandwidth.This model exploits the client resources and lightens the server loading.

@&#KEYPHRASES@&#
Virtual Microscopy,Whole Slide Images,Visualization,JPEG2000,Mobile devices,Telepathology,

@&#ABSTRACT@&#
Real integration of Virtual Microscopy with the pathologist service workflow requires the design of adaptable strategies for any hospital service to interact with a set of Whole Slide Images. Nowadays, mobile devices have the actual potential of supporting an online pervasive network of specialists working together. However, such devices are still very limited. This article introduces a novel highly adaptable strategy for streaming and visualizing WSI from mobile devices. The presented approach effectively exploits and extends the granularity of the JPEG2000 standard and integrates it with different strategies to achieve a lossless, loosely-coupled, decoder and platform independent implementation, adaptable to any interaction model. The performance was evaluated by two expert pathologists interacting with a set of 20 virtual slides. The method efficiently uses the available device resources: the memory usage did not exceed a 7% of the device capacity while the decoding times were smaller than the 200ms per Region of Interest, i.e., a window of256×256pixels. This model is easily adaptable to other medical imaging scenarios.

@&#INTRODUCTION@&#
Virtual Microscopy (VM) may be thought of as a collection of techniques that facilitate a set of Whole Slide Images (WSIs) can be examined from any place and at any time. Typically, a histopathological specimen is digitized at the higher possible magnification to provide the pathologist with the required information for diagnostic, research, training or educational tasks [1]. During the last decade, the dynamic interpretation of WSIs has been integrated with many pathology activities such as teaching, research, digital archiving, teleconsultation, and quality assurance testing [2]. Different works have studied the viability and agreement of diagnoses by using WSIs, reporting promising results [3,2,4]. Recently, medical schools in the United States have introduced digital pathology courses and virtual slide laboratories, promoting a generation of pathology trainers who may prefer digital pathology imaging over the traditional hands-on light microscopy [5]. A large variety of technical solutions supported these studies, e.g., Aperio ImageScope [3], home systems such as U-DPS [2], DMetrix Digital Eyepiece [5] or WebScope [4], indicating little agreement has been so far accomplished.Several technical and logistical barriers have delayed WSI becomes a widely accepted pathology modality [6]. A proper management of the number of files generated by a WSI demands large memory, processing and storage resources since the size of a WSI is typically on the order of gigabytes. Furthermore, since there is not a common image format for virtual slides, a large number of proprietary or vendor-specific formats has been constantly modified as long as new scanners have been introduced [7]. Standardization not only allows an user to perform certain functions in an optimal way, but it also offers quality guarantees, interoperability, independency from vendors and equipments, access to new technologies and possibilities to scale applications according to new requirements. A wider VM use will require full integration with laboratory information systems, seamless connectivity over broadband networks, efficient workstations, cost-effective storage solutions and standards-based informatics transactions for integrating information with WSI [5,6,8]. Lately, image quality improvements, smaller scan times and image-viewing browsers have converted digital pathology into an actual opportunity [6]. Overall, actual clinical scenarios require access to these files from any location, reason by which mobile devices might be considered as the support nodes of a VM network. However, such devices are still very resource limited [9] and, yet communication channels have remarkably improved, network bandwidths are frequently insufficient.This problem has been addressed using a variety of approaches, the most common consisting in constructing pyramidal data structures that deal with different image scales that are stored as independent files [10]. For a requested Region of Interest (RoI) to be displayed, a complex combination of pyramidal files must be composed and this is usually computationally expensive. These pyramidal approaches have been evaluated from a VM standpoint, HD View, Zoomify, Gigapan and Google Earth, reporting pleasant interaction experiences when navigating a single WSI from a conventional computer [10]. Nevertheless, these approaches might be very limited when displaying a WSI from a low resource mobile device since in such a case, applications should deal with variable storage requirements, low compatibility, high processing demand and poor adaptation to different displays. Likewise, limited devices may have trouble managing a large number of files since their cache space may be easily overflowed. Aperio [11], a commercially available software allows an user to pan and zoom in and out virtual slides, but this system is computationally very demanding and requires a powerful infrastructure. Similar approaches are OpenSlide [12], NYU Virtual Microscope [13] and Deep Zoom (formerly called Seadragon) [14], among them, Openslide is an open source library devised to display WSIs and is compatible with different image formats. The NYU Virtual Microscope uses the Google Maps API and Deep Zoom is part of the Microsoft Silverlight platform, a proprietary software with a very limited mobile version. These last three applications are based on a pyramidal structure and share the limitations aforementioned for mobile devices. A different approach was proposed by Hadwiger et al. who introduced a multi-resolution virtual memory that performs dynamic updates and deals with missing data [15]. This system is not based on any standard, uses the lossy JPEG version and was devised to display data at a full resolution, a bottleneck in limited devices.VM demands highly flexible, efficient, manufacturer independent and standard-based tools [7,16]. An alternative to the artificial pyramidal approach is the JPEG2000 standard, founded on the concept of making available any piece of required information, i.e., a particular spatial region at any desired quality and magnification. The standard appears to be flexible enough as to address the issue of streaming and visualizing demanding content in mobile devices [17], such as WSIs. This standard was smartly conceived to be granular, i.e., an image can be decomposed and compressed in small independent parts (grains) of information at different levels of magnification, several degrees of quality and independent spatial representation, facilitating a separated access and process of specific regions of the image, while also supporting large file sizes and a larger dynamic range of the pixel representation [18]. In addition, by the JPIP (JPEG2000 Interactive Protocol) standard, the client may demand specific RoIs from the server, instead of remotely accessing the whole JPEG2000 content [19]. Nevertheless, the JPEG2000 standard complexity may make it very expensive in computational terms [7] and therefore unrealistic at supporting a VM network. Basically, data allocation can be an actual burden of the navigation while the decoding process may be on the order of 2–5s, even when decoding a small VS of9000×12,000pixels. There exist some applications using different JPEG2000 implementations, all of them decompressing data at the server side and leaving to the client a purely passive role at receiving the raw decoded information to be displayed, for instance IIPImage [20], Djatoka [21], JVSMicroscope [7] and Web Microscope [22], being the latter a reference in certain academic and clinical institutions. This strategy throws away the JPEG2000 high compression rates since only uncompressed data are transmitted and ignores the potential processing improvement at the client side. Other works have explored the JPEG2000 as an interaction tool for VM by modifying the decoder implementation, retrieving and decompressing specific portions of the codestream [23–25], unfortunately, this tightly-coupled solution could be hardly extended to different platforms. Finally, Rosenbaum et al. proposed to send only the RoI encoded information and to complete the missing codestream (untransmitted) at the client side with a pre-defined template [17], but then the decompression times result equivalent because of the size of data.This work introduces an adaptable and low computational cost VM framework that exploits the JPEG2000 potentiality at both the server and client sides. The possibility of meeting any requirement, i.e., any spatial region at any size, with a desired magnification and quality, makes this proposal adaptable to new scenarios, in particular to the training and educational VM. In that case, a group of pathologists or students, might simultaneously access the same WSI and therefore saturate the network. The main contributions of this work are:•Unlike most existent solutions, this strategy has been devised to maximally exploit the processing resources at both the client and the server so the server sends compressed data and the client decompresses data, even under very limited computational capacity.A smart decoding strategy addressed to construct any RoI by setting the requested region to an image which can then be decompressed by any standard decoder.A flexible and scalable data management strategy that efficiently retrieves JPEG2000 compressed data at the server side, independently of the image size, by a coupled designed meta level index file.A loosely-coupled architecture, web service oriented, providing functionalities that support interoperable and standard interaction over the network. This highly adaptable architecture adjusts the content to the user requirements, the device capacity and the network bandwidth, while it offers a progressive lossless visualization.JPEG2000 is a highly flexible image coding standard that optimizes interaction with compressed data [26,27]. A key feature of this standard is that it encodes multiple resolution levels and quality layers. Resolution is related with the number of pixels that are needed to ensure that, at a particular image size, the displayed information is maximum. In contrast, the quality is a function of the number of bits that are used to represent a pixel. Resolution flexibility implies that an image can be retrieved at a low resolution (a small version of the image) and can be enlarged (by a factor of two) by adding the missing data and only these data [28]. The quality is connected with the concept of progressive user interaction and consists in displaying a very basic version of the image, with few details, that are progressively added as long as the user demands more information, until reaching a full lossless visualization, if needed [28].The JPEG2000 norm is based on the Discrete Wavelet Transform (DWT) and the Embedded Block Coding with Optimal Truncation (EBCOT), both endowing the data representation with high granularity [29] (see Fig. 1). The DWT decomposes the input image into frequency subbands, producing a natural multi-resolution decomposition, with basically two wavelets: the Daubechies 9-7 for lossy compression, and the reversible Daubechies 5-3 for lossless compression [30]. The DWT image is divided into tiles that allow random access to spatial regions with different frequential information. The EBCOT compresses the image into small blocks (code-blocks) that encode the DWT coefficients of each subband. Each of the codeblocks, composed of a set of bit-planes, is ordered by levels of relevancy known as the quality layers, each containing a part of the whole information. Finally, the packet, the basic JPEG2000 information unit, is responsible for storing compressed data at a particular resolution level, a single spatial region and a unique quality level. The standard allows a progressive reconstruction of the original image by dynamically adding missing packets, improving the visualization of the image until a perfect reconstruction is obtained [18].The JPEG2000 decompression process is expensive because of the decoding and the inverse transforming processes, a fact that has limited the JPEG2000 application in VM. A partial remedy to this bottleneck has consisted in assigning the processing responsability to a server which decodes the codestream and sends the resultant raw data [20,21,7,22]. The client acts as a simple information receptor and the potential client resources are never used, overloading the communication channel by transporting uncompressed data. Furthermore, the transmission of raw data necessarily reduces the possibility of storing relevant information at the client side and thus the potentiality of implementing effective cache policies that may reduce the network traffic. The option of decoding at the client side has been introduced either by decompressing the whole image, a real problem with the WSI sizes, or by adapting the decoder implementation to decompress specific packets [24,25]. The main drawback of this last solution is the inevitable dependence on the decoder implementation, or the problem of managing the dynamic organization of data, which in some cases has been approximated by completing the requested codestream with zeros [17], but then the decompressing times result to be equivalent to those obtained with the whole image. In summary, most of the existent VM applications have ended up by using JPEG2000 as a simple compression format, without exploiting its flexibility at representing the data.Unlike previous approaches, the proposed strategy effectively integrates the client to the processing by generating, for each requested RoI, a new small JPEG2000 coded image that meets the desired RoI, i.e, same dimensions, resolution levels and quality layers. This is achieved by modifying the image main header and assembling that header with the packets associated with the RoI. In this way, an efficient decompression is accomplished by processing exactly the required image portion, at any desired quality and magnification. A resultant side advantage of this strategy is the independence of the implementation, i.e., any decoder can be used (see Fig. 2).In an actual navigation scenario, the retrieval of specific data from a JPEG2000 file demands an intensive search within the codestream to localize the desired packets, whose location is coded in structures known as tag-trees [30]. Any individual query requires these structures to be decoded [30], a process that may take about 2s for a single packet of a large WSI. This problem has been overcome by using index files [29]. The herein used index files are based on the JPIP standard specification [31] and they are simple text files that provide an organized structure of the general image data at two different levels (see Fig. 3), the global image information (width, height, progression order, number of components, number of quality layers, number of decomposition levels, etc.) and the particular local configuration at the level of packets (quality layer, component, resolution, precinct number and byte ranges), thereby facilitating any application to identify and to extract bytes directly from the JPEG2000 files and therefore to meet complex user requirements.In general, when navigating an image, a user requests Windows of Interest (WoI) that are identified by their image location, size (weight and height), resolution and quality. The system must therefore use a parser that maps the user request to the specific packets in the compressed image or codestream, after the image information box in the index file (see Fig. 3). Using the WoI coordinates, the parser computes the identifiers of those precincts1Precincts are a JPEG2000 image spatial partition.1associated to the spatial query. This information, together with the specific requested resolution and layer, is used to calculate the corresponding packet IDs. Once these IDs are found, a search in the index file determines the initial and final locations in the codestream of the specific bytes, i.e., the position of this packet in the compressed file. Finally, these bytes are extracted directly from the compressed file.While these index files are very important to accelerate the time required to locate a packet within the codestream, they require an associated efficient access technique. Depending on the WSI size, the index files may result as large as a WSI and the search process may become as slow as to become an actual navigation bottleneck. For this reason, indexation was herein optimally managed by designing a hash-based structure composed of multiple small index files that may be selectively loaded to meet a client request. Each file stores data from a given set of packets. When a packet information is required, its identification number is used to determine the index file containing the necessary data. This strategy provides scalability and proper performance regardless the image size, since just one index file must be accessed and loaded in memory.The proposed strategy exploits and extends the benefits of both the JPEG2000 and JPIP standards, adapting the content to the device capacity and user needs (see Fig. 4). Basically, any navigation request may be assembled and resources may be optimized if a flexible architecture is capable of implementing the standard granularity [32,17]. In particular, the level of quality is a variable of the user needs and hence the navigation might be speeded up by setting a maximum quality. Likewise, navigation may also be accelerated if the decoding policies, at both the server and client sides, are completely adaptable to the bandwidth. Any architectural approach must then be flexible enough as to cope with all these different scenarios.The proposed architecture is loosely coupled and allows integration of different caching and prefetching models, which speed up the browsing performance [33,25]. Furthermore, the transmitted content can be adapted to the screen size, supporting several devices with different capacities (not only mobile ones). This architecture consists of three loosely coupled layers, described hereafter. Fig. 5illustrates the information flow through the different modules of the proposed architecture.This layer is the repository of the JPEG2000 compressed images and their respective index files, which facilitate access to such image files. When a new compressed image is stored, its index file is constructed using the information of the main header and the packet markers in the codestream. The proposed approach is independent of any database engine since data are stored as files. This layer is platform independent, i.e., it can be run from any operating system (Windows or UNIX based) and the required storage space depends exclusively on the image sizes. The application that generates the index files was developed using the Java SE platform, which is also platform independent.This layer provides web service interfaces for a client accesses to data in the storage layer. The web services were developed using the Java EE platform and run over any Java Enabled Application Server. Such web services are interoperable and may be consumed by any client application. Four main services are available: List sends a list of the available images. Header receives an image name and returns the image main header. Metadata takes as input an image name and sends specific information, namely dimensions, progression order, number of precincts, number of components, number of quality layers, number of resolution levels, among others. Finally, for the Packets service, given an image name and a list of packet IDs, it sends the bitstream of each packet. The Data Manager module is an intermediate between the web services and the storage layer.Alternatively, the Pixels service takes an image name and a WoI request (coordinates, resolution and layer), and returns the pixels of that window. This service may be suitable when decoding cannot be performed at the client side, for example devices with very low capacities or for web-based applications, which generally have no support for the JPEG2000 standard. This service connects to a Server Processor module which is responsible for packet calculation and generates a compliant codestream to be uncompressed using a JPEG2000 decoder.It is composed of several modules for a user may visualize and interact with the WSI. A first module is a graphic user interface (GUI) with panning, zooming-in/out and quality operations. A second module is the cache manager that administrates the memory where previously requested data may be stored. This module removes old/unused data when this is full and takes advantage of spatial, resolution and quality scalability. The size of this cache memory is configurable according to the device capacity and adaptable to different models, for example, the Least Recently Used or the Least Frequently Used. The fact that the data representation is so granular facilitates the design of more complex cache policies that are constructed, after the principle of storing only what is relevant and will be used in the future. A third module is the Request Processor that demands the required data either to the cache manager (if they were previously requested) or to the corresponding web service. This module uses the Packet Calculator to identify the packets that are requested. In the smart decoding module, the retrieved data from the codestream are mapped to a JPEG2000 image which then can be decompressed using any standard decoder. Finally, raw data (pixels) are displayed by the GUI.From any mobile device the first view is a dynamic list of the available WSIs. The user then selects that one to be examined and may easily switch between different WSIs of the dataset, as illustrated in Fig. 6(a) and (b). Each thumbnail image is associated to a list of metadata, containing clinical information, that is pop out when long pressing the thumbnail image. If the pathologist picks a WSI, the navigation starts by displaying two views, a guide window that displays a low magnification version of the WSI and serves for the expert to be oriented within the WSI, and an exploration window showing a RoI (Fig. 6(c)). At each WSI, the expert may pan, zoom in or out and refine the quality by using some gestures and interface elements.Experiments were performed with a dataset consisting of twenty skin biopsies of patients, stained with Hematoxylin–Eosin. Most of these cases are skin basal cell carcinomas, two were lentigines, a melanocytic nevus and an irritated seborrheic keratosis. The diagnosis difficulty was considered as moderate by our expert pathologist and, in general, they took less than a minute to perform a diagnosis. The WSIs were JPEG2000 compressed using 10 quality layers, 4 decomposition levels (5 resolutions), the lossless filter (W5x3) and precinct sizes of64×64for the first resolution level and dyadic increasing sizes for the other levels. The WSI resolutions vary from 104 to 340 mega pixels, and their sizes range between 630MB and 972MB. The proposed approach was compared with two baseline approaches: the lossy and lossless versions of the JPEG standard, constructing two pyramidal structures with different scale (spatial scalability) and quality (Signal-to-noise ratio scalability) versions of the original image, based on the Google Earth API documentation [34]. Images were JPEG and JPEG-lossless (JPEG-LS) compressed using 10 quality layers, 5 resolution levels, and tiles of64×64for the first resolution level and dyadic increasing sizes for the other levels. Finally, the experiments were run using a 1Mbps network. Table 1shows a quantitative comparison of some representative WSIs in terms of formats, resolution, file size and number of files.The server application was developed using the Java EE 1.5 platform and was deployed on the GlassFish Application Server. The storage and data provider layers run on a computer with 4GB RAM memory and 2.4GHz quad core processor. The client application for a single user navigation was implemented in the Android platform. The tests were performed using the Samsung GT-i9100 (Galaxy S2) device, with operating system Android 4.1.2,800×480display size, 1024MB RAM memory and 1.2GHz dual-core processor. Decoding was carried out using the Kakadu library [35] version 2.2.3 and the JasPer library [36] version 1.900.1, under the Java Native Interface.Simultaneous access experiments were run on a desktop client device that randomly executed recorded requests of actual expert navigations. The client application was developed in the Java platform and tests were performed on a computer with 4GB RAM memory and 2.71GHz dual core processor, using The Kakadu library version 2.2.3 as the decoder.

@&#CONCLUSIONS@&#
