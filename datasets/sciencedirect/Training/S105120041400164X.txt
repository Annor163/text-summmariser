@&#MAIN-TITLE@&#
A fast and scalable hybrid FA/PPCA-based framework for speaker recognition

@&#HIGHLIGHTS@&#
The hybrid FA/PPCA system is presented.Two approaches, termed AN and AC, are proposed to speed up the i-vector estimation during testing in a speaker recognition.Significant speed ups are obtained for each proposed approach.The scalability of the hybrid system is demonstrated using two suitable features (MFCC and MFS).Fusion of systems that use AC-type approximation perform similar to that of the corresponding Hybrid system baseline.

@&#KEYPHRASES@&#
Speaker recognition,i-vectors,PPCA,Fast i-vector extraction,

@&#ABSTRACT@&#
A text-independent speaker recognition system using a hybrid Probabilistic Principal Component Analysis (PPCA) and conventional i-vector modeling technique is proposed. In this framework, the total variability space (TVS) is estimated using PPCA while the i-vectors of target speakers and test utterances are extracted using the conventional method. This leads to appreciable decrease in development time, while the time required for training and testing remains unchanged. In this a paper, an algorithmic optimization to the PPCA's EM algorithm is developed. This is observed to provide a speed up of 3.7×. To simplify the testing procedure, two different approximation procedures are proposed to be used in this framework. The first approximation assumes a covariance matrix computed based on the PPCA framework. The second approximation proposes an optimization to avoid inverting the precision matrix of the i-vector. The comparison of time taken by these approximations with the baseline i-vector extraction procedure shows speed gains with some deterioration in performance in terms of the Equal Error Rate (EER). Among the proposed techniques, a best case trade-off is obtained with a speed up of 81.2× with deterioration in performance by0.7%in absolute terms. Speaker recognition performances are studied on the telephone conditions of the benchmark NIST SRE 2010 dataset with systems built on the Mel Frequency Cepstral Co-efficient (MFCC) feature. A trade-off in the performance is observed when the proposed approximations are used. The scalability of these trade-offs is tested on the Mel Filterbank Slope (MFS) feature. The trade-offs observed with the approximations are reduced when the two systems are fused.

@&#INTRODUCTION@&#
The total variability space model for speaker recognition has become an integral part of state-of-the art speaker recognition systems today [1]. The zeroth and the first order statistics of an utterance with respect to a Universal Background Model (UBM) is used to represent the entire utterance using a low dimensional vector. This low dimensional vector is called the i-vector. The mathematical model is described as follows(1)s=m+Twwhere s is the supervector obtained from an utterance of speech, m is the model bias, T is the matrix containing the basis vectors of the total variability space and w is the i-vector corresponding to s.The success of this modeling framework has been well documented [2]. It is an integral part of state-of-the-art speaker recognition systems today. Its success lies in its ability to obtain a low and fixed dimensional representation of a speech utterance making it convenient for model level channel compensation. Techniques such as Linear Discriminant Analysis (LDA) [1,3], Within Class Covariance Normalization (WCCN) [4], and Probabilistic LDA (PLDA) [5,6] are applied on the i-vectors to obtain superior performance compared to their Universal Background Model–Gaussian Mixture Model (UBM-GMM) counterparts [1].In this framework for speaker recognition, the i-vectors are obtained with respect to the TVS (Total Variability Space) defined by T for every utterance of speech. They are further subject to channel compensation using the earlier mentioned techniques. A log-likelihood score is obtained in the PLDA domain between the train and test i-vectors to evaluate the veracity of a claim in the speaker recognition task. The scores are further subject to typical score normalization techniques such as z-norm, t-norm or s-norm [7]. This constitutes a typical speaker recognition system. Throughout this paper, the conventional system is referred to as the Factor Analysis (FA) approach.The presence of large amounts of auxiliary data for development has played a critical role in the success of the TVS model for speaker recognition. Typically, 1000s of hours of data are used to estimate the hyperparameter T in Eq. (1)[2]. The development data is also used to obtain the projection matrices for LDA, WCCN and PLDA. Unlike channel compensation techniques, the development time taken to estimate the hyperparameter is long. This is primarily due to the dimension of the supervector s and the first order statistics (defined later), which is dependent on the number of mixtures in the UBM and the dimension of the feature used. If an F dimensional sequence of vectors are obtained from an utterance of speech and are then aligned with a C-mixture UBM, a CF dimensional supervector is obtained. Considering that the number of mixtures is typically 1024 or 2048, and that the conventional features such as MFCC (Mel Frequency Cepstral Co-efficients) have around 19 to 22 dimensions that are further appended with velocity and acceleration parameters, the dimension of the supervector becomes large.In an earlier work in [8], the hyperparameter estimation process is simplified with use of the Probabilistic Principal Component Analysis (PPCA) algorithm instead of using the conventional EM algorithm as done in [1] providing considerable speed ups. However, the i-vectors are extracted just as in the FA system. A 4× speed up in the development time is observed with a trade-off in the performance of the speaker recognition system. This technique of applying PPCA instead of the conventional EM algorithm stems from the observation with respect to the importance of encoding made in [9]. As the hyperparameter is intended to capture the subspace in which the supervectors lie, it would be better to use a computationally less expensive algorithm to estimate it, while retaining the i-vector extraction procedure (encoding) in the FA system. The speedups obtained are as a result of the differences in the computational complexities of the PPCA and FA's EM algorithms to estimate T. The computational complexities of the E- and M-steps of the conventional and the PPCA techniques for each iteration are summarized in Table 1. In this table, R refers to the number of basis vectors chosen andNdevrefers to the number of supervectors in the development data set. Typically,F<R<C<Ndev. Consider a speaker recognition system built for male speakers in this paper, MFCC-based systems haveF=44,R=500,C=1024andNdev≈22000. Thus, the 2nd and the 3rd terms in the summation of the computational complexity of the E-step in the conventional method (in Table 1) are large. These terms are avoided by the PPCA algorithm, providing a speed up in estimation time.The hybrid system's motivation can be realized by viewing the TVS framework as consisting of a dictionary learning step and an encoding step. Fig. 1shows the framework split into these two stages. The dictionary learning step corresponds to the hyperparameter (T) estimation, which is the set of basis vectors defining the TVS. The encoding phase corresponds to the extracting i-vectors for the utterances with respect to the dictionary T. Based on the observation made in [9], the importance of the encoding method used is clear. However, this is shown only with respect to sparse encoding techniques and need not necessarily apply to probabilistic methods. The results in [8] show the importance of extracting i-vectors the conventional way even when the dictionary is estimated using PPCA. The differences in speaker recognition performances arise due to the different assumptions made by the techniques. The conventional i-vector extraction technique assumes that the supervector is formed from an utterance generated by a GMM, whereas the PPCA technique assumes that the supervector follows a normal distribution. This fundamental difference in the assumption of the generative model of a supervector leads to the poor performance of the conventional PPCA framework (where PPCA is used for both dictionary learning and encoding) compared to the FA framework (where the conventional modeling approach is used for both dictionary learning and encoding). Thus, extracting i-vectors using the conventional encoding technique even when the model parameter is estimated using the PPCA technique leads to better performances of the speaker recognition system. This system shall be referred to as the hybrid system throughout this work — a system in which the dictionary is leaned using the PPCA technique while the i-vectors are extracted using the conventional method. We shall use the term hybrid i-vector for the i-vectors estimated using the conventional extraction technique from the matrix T estimated using PPCA. The term PPCA i-vector shall be used for vectors w extracted using the PPCA i-vector extraction technique. The conventional TVS method (as used in [1]) shall be termed FA throughout this paper.

@&#CONCLUSIONS@&#
