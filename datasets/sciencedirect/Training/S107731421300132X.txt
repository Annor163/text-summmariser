@&#MAIN-TITLE@&#
Multi-spectral dataset and its application in saliency detection

@&#HIGHLIGHTS@&#
A multi-spectral dataset is constructed containing RGB and near-infrared images.The incorporation of near-infrared is proved to be valuable for saliency detection.The best model for integrating RGB and near-infrared clues is analyzed.

@&#KEYPHRASES@&#
Multi-spectral,Near-infrared,Saliency,Regression model,

@&#ABSTRACT@&#
Saliency detection has been researched a lot in recent years. Traditional methods are mostly conducted and evaluated on conventional RGB images. Few work has considered the incorporation of multi-spectral clues. Considering the success of including near-infrared spectrum in applications such as face recognition and scene categorization, this paper presents a multi-spectral dataset and applies it in saliency detection. Experiments demonstrate that the incorporation of near-infrared band is effective in the saliency detection procedure. We also test the combinational models for integrating visible and near-infrared bands. Results show that there is no single model to effect on every saliency detection method. Models should be selected according to the specific employed method.

@&#INTRODUCTION@&#
Saliency detection has been a promising topic recently [1–4]. The goal of saliency detection is to extract salient areas from an input image and present the result as a gray scale image. The whiter the pixel seems, the more possible it might be salient. Since the detected saliency map can be utilized in various applications, such as recognition [5], segmentation [6], and tracking [7], research towards this subject has attracted much attention [8–10].Generally, methods for saliency detection can be categorized into local based and global based schemes [11]. Local based methods calculate a region’s saliency according to the contrast to a small neighborhood [12–14]. Global based methods evaluate saliency with respect to the whole image’s statistical characteristic [15,16]. Whatever the case is, saliency detection is mostly conducted on natural images taken by ordinary cameras. These cameras can respond to wavelengths from about 390 to 700nm, which is called the visible spectrum [17]. The obtained images are regular RGB images. As for the electromagnetic spectrums beyond this scope, their information is lost during the imaging process. However, the lost spectrums might be also valuable for vision tasks because the more supporting information we have, the more rationale decisions will be made. This judgment is not only the common sense for humans, but also proved by other applications in computer vision field. For example, after the proposition of SIFT descriptor [18] on gray scale images, CSIFT [19,20] was developed to incorporate the color bands into the descriptor. Then not long ago, MSIFT [21] was presented to include the near-infrared band for a richer descriptor. As for the face recognition research, early work primarily focus on the gray or RGB images. Later, other light bands besides the visible spectrum [22] are involved to eliminate the lighting problem. The same is true for boundary detection [23] and tracking [24] that incorporating more clues will improve the performance. In remote sensing, the spectrum is not limited to one or several bands, but up to a level of tens and hundreds [25–27].Considering the success of including other light bands besides the visible light in many applications, we construct a multi-spectral dataset containing both near-infrared (NIR) and regular RGB images in this work. Several dataset containing NIR images have been presented before. For example, the PolyU-NIRFD dataset [22] for face recognition, the NIR–RGB dataset [21] for scene categorization. But these datasets are designed for specific purpose. They cannot be readily utilized for saliency detection. To this aim, the presented dataset is constructed in the hope of providing a new platform for saliency research.The rest of this paper is organized as follows. Section 2 presents the proposed multi-spectral dataset. Section 3 introduces the distinguishable properties of near-infrared band. Section 4 applies the presented dataset in saliency detection. Finally, conclusion is made in Section 5.Since more clues are prone to provide richer information, we hope that a camera can capture the NIR and RGB spectrums simultaneously. However, most existing datasets contain images captured from only RGB bands. We cannot get the information of the four bands at the same time. Though the NIR–RGB dataset [21] has images of both bands, each pair of them are taken consecutively with two cameras. This makes the contents of image pairs not the same. When these images are employed, they have to be accurately registered. But the obtained results are still not satisfying because some objects exist in one image but not in the other. Considering this problem, we employ a multi-spectral camera to simultaneously capture the images of the four bands.The camera we employed is a prism based 2-CCD progressive area scan one, the configuration of which is shown in Fig. 1(a). We can see clearly that the prisms in the camera spit the input light into two channels. One is 400–700nm visible spectrums of red, green and blue, and the other is 700–1000nm NIR spectrums. This separation is accurately ensured by the dichroic coatings of the prisms. The splitted spectrums are then responded by two distinct CCDs, each of which is sensitive to a range of wavelengths. Their response curves are shown in Fig. 1(b) and (c). The advantage of this camera is that it can capture two images at the same time and the obtained image pair are with the same scope and content.With this camera, we took 40 pairs of 512×384 images of indoor and outdoor scenes and each image contains one or several salient objects within it. Then the salient objects in each pair were labeled by 5 graduate students major in computer vision. In this procedure, few instructions were given to the participants except segmenting the salient ones they thought as. This ensures the minimum amount of influence on the participants’ labelings due to the unnecessary instructions. Since every individual’s perception is different, their labelings differ with each other. To get an unbiased ground truth, we select the common areas of each participant’s labeling as the final results. Typical examples are shown in Fig. 2.The NIR spectrum is between the visible light band and the thermal infrared band. It has the properties of both visible light and thermal infrared light, but is different from any of them. Firstly, unlike thermal infrared, objects can reflect the NIR light the same way as they do to visible light. Secondly, it is invisible to human eyes like the thermal infrared and reflects an “unseen” characteristic different from visible light.In order to know the relationship and difference between the RGB and NIR spectrums, we plot their pairwise cooccurrence distributions on the 40 image pairs in the 2D plane. All the RGB and NIR values are normalized to [0,1] and different occurrence frequencies are denoted by different colors. From Fig. 3, it is obvious that the distributions of RG, RB and GB are different from those of RN, GN and BN. The latter ones spread more widely in the 2D plane. This implies that the original visible light of red, green and blue are much higher correlated in a pairwise manner than the NIR with them. The NIR spectrum can provide more different information than the visible spectrum.To justify this point, we calculate the joint entropy [21] of each two bands as(1)H(X,Y)=∑i,j-p(xi,yj)log2p(xi,yj),where X and Y are the examined spectrums, xiand yjare the pixel values of the corresponding spectrum image, and p(xi,yj) is the probability density. According to the information theory, the entropy is a measure of unpredictability and reflects the information content. The higher H(X,Y) is, the more information is contained in a message. The calculated joint entropy is shown in Table 1. From the table, we can see that the joint entropies with the NIR band are generally higher than those without it. This result demonstrates that the NIR band can provide much abundant information. Trying to utilize it in applications is reasonable.To demonstrate the effectiveness of the presented dataset, we conduct experiments in the application of saliency detection. Saliency maps are firstly extracted from RGB images and NIR images. Then the obtained maps are combined together to get the final results. The purpose of these experiments is to answer the two following questions: 1) whether or not the incorporation of NIR band can improve the saliency detection performance; 2) which kind of models is the best to combine the saliency maps from the two channels.To answer the first question, we compare the results generated with only RGB band and the results with both RGB and NIR bands. Algorithms employed in this process are all canonical ones in saliency detection fields. They are AC [29], CA [13], FT [16], HC [11], IT [12], LC [30], MSS [31], RC [11], SR [32] and SUN [33]. To answer the second question, it is more difficult because a traversal test of comparative models is impossible. Considering the initial success of [34], we concentrate on the regression models in this work.To compare experimental results, an evaluation measure should be firstly specified. In saliency detection field, three metrics are usually employed: precision, recall, and F-measure. They are defined as follows(2)precision=TPTP+FP,recall=TPTP+FN,F-measure=precision×recall(1-α)×precision+α×recall,where TP is true positive, FP is false positive, and FN is false negative. These three metrics are usually utilized in information retrieval community and each of them reflects a different aspect. Precision represents the accuracy, recall represents the detectability, and F-measure is a balance between them. When precision and recall contradict with each other, F-measure is usually employed to represent a compromised measurement [35].In our processing, the aim is to infer each pixel’s saliency value according to its obtained saliency maps from the RGB and NIR bands. Suppose the RGB and NIR saliency are denoted as Xrgband Xnir, respectively. The question is how to determine the mapping function f: (Xrgb,Xnir)→Y, where Y is the desired saliency value. Three commonly used regression models are employed here. They are linear regression, polynomial regression and logistic regression.In linear regression [36], the output variable is a linear combination of input variables. To be specific, the model can be expressed as(3)Y=α0+α1Xrgb+α2Xnir.The task is to estimate {αi}i=0,1,2 from the observed N training points{Xrgbn,Xnirn,Yn}n=1,…,N. A special case of linear regression is that the constant coefficient α0 equals 0. In this case, the output is only the proportional combination of Xrgband Xnir, with no translation. The two models are abbreviated as LinearR-I and LinearR-II in later discussion.In polynomial regression, the independent variables include not only linear terms, but also quadratic and interactive terms. The model is expressed as(4)Y=α0+α1Xrgb+α2Xnir+α3XrgbXnir+α4Xrgb2+α5Xnir2.The processing is the same as linear regression. According to the known input and output pairs, get an estimation of {αi}i=0,…,5 that best fit the training data. This model is denoted as PolyR to facilitate the representation.For logistic regression [37], the model is defined as(5)f(X)=eXeX+1=11+e-X,where X represents some set of independent variables, which in this work is defined as(6)X=α0+α1Xrgb+α2Xnir.The model reflects the nonlinear relationship between the input and output variables, especially emphasizing an approximately linear mapping in the mid-range of input variables and stretching out the extremes exponentially. It is denoted as LogisticR.

@&#CONCLUSIONS@&#
