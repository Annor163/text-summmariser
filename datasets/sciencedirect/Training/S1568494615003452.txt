@&#MAIN-TITLE@&#
Hindrances for robust multi-objective test problems

@&#HIGHLIGHTS@&#
Five hindrances are employed to improve and propose challenging robust multi-objective test problems.12 robust multi-objective test problems have been proposed.Five robust multi-objective algorithms have been compared on the proposed test functions.Deceptive robust multi-objective test functions are proposed for the first time.Biased robust multi-objective test functions are proposed for the first time.

@&#KEYPHRASES@&#
Benchmark problem,Robust optimisation,Uncertainties,Multi-objective robust optimisation,Robust benchmark problem,Multi-objective optimisation,

@&#ABSTRACT@&#
Despite the significant number of benchmark problems for evolutionary multi-objective optimisation algorithms, there are few in the field of robust multi-objective optimisation. This paper investigates the characteristics of the existing robust multi-objective test problems and identifies the current gaps in the literature. It is observed that the majority of the current test problems suffer from simplicity, so five hindrances are introduced to resolve this issue: bias towards non-robust regions, deceptive global non-robust fronts, multiple non-robust fronts (multi-modal search space), non-improving (flat) search spaces, and different shapes for both robust and non-robust Pareto optimal fronts. A set of 12 test functions are proposed by the combination of hindrances as challenging test beds for robust multi-objective algorithms. The paper also considers the comparison of five robust multi-objective algorithms on the proposed test problems. The results show that the proposed test functions are able to provide very challenging test beds for effectively comparing robust multi-objective optimisation algorithms. Note that the source codes of the proposed test functions are publicly available at www.alimirjalili.com/RO.html.

@&#INTRODUCTION@&#
Real world problems include and are surrounded by a variety of uncertainties. Such uncertainties are considered undesirable inputs for a system. Unfortunately, undesirable inputs often have significant negative impacts on the outputs of a system. Frequently, a system designed under laboratory conditions shows one set of outputs, while the same system provides very different outputs in a real environment. Failure in many projects originates from overlooking such uncertainties. Uncertainties can be classified into four types [1,2]: operating conditions, inputs, outputs, and constraints.In the field of optimisation, the process of considering uncertainties when finding optimal solutions is called robust optimisation. In robust optimisation, the ultimate goal is to obtain an optimal design for a particular problem while achieving the least sensitivity to possible perturbations of any kind. In the field of evolutionary optimisation, there are two main methods of robust optimisation. We will discuss them in detail in Section 2. The general concept is to employ a robustness measure to evaluate the robustness of search agents over the course of iterations [3–5]. Then appropriate actions are taken to guide the search agents of evolutionary algorithm towards the robust optimum [6–8].In addition to uncertainties, another important characteristic of real problems is that of multiple objectives. It is quite common in real problems that there is more than one objective to be optimised. Multi-objective optimisation is a popular and recent field of study [9]. It deals with finding a set of solutions for a particular problem which represent the best possible trade-offs between the problem's objectives [10]. Although there are studies in the literature for converting a multi-objective problem to a single-objective problem [11–13], it has been proven that maintaining multi-objective formulation of problems allows designers to optimise problems with different conflicting/non-conflicting objectives across a wide range of design parameters [14].Robust optimisation in a multi-objective search space is more challenging than in a single-objective search space. In this case, an optimiser should search for the best trade-offs between the objectives and consider their sensitivity to possible perturbations. Despite the importance of robust optimisation, unfortunately there is little in the literature. Comparing the theoretical and practical studies in the literature of single and multiple objective optimisation, there is a negligible number of publications in robust optimisation. So, it seems robust optimisation (specifically robust multi-objective optimisation) is still in its early stages. This paper identifies a substantial gap in the literature of robust multi-objective optimisation, which is the extreme simplicity of the majority of test problems. Challenging test problems are essential tools for developing and benchmarking algorithms in the field of evolutionary optimisation. Lack of such difficult test functions may result in premature comparison between different algorithms. In addition, challenging diverse test beds allow us to effectively test the performance of algorithms from different perspectives. This motivates our attempts to investigate the characteristics of the current robust multi-objective test problems, introduce five hindrances, and propose a set of 12 diverse robust multi-objective test problems. The contribution of the paper is the proposal of deceptive robust test functions, multi-modal robust test functions, and flat robust test functions. The use of biased search spaces in the field of robust optimisation is another contribution of the paper. Since the paper describes the process of designing robust multi-objective test functions in detail, it can be considered as a practical tutorial for constructing robust test problems as well. The rest of the paper is organised as follows.Section 2 discusses the concepts of robust optimisation in a multi-objective search space and current methods of handling uncertainties using evolutionary multi-objective optimisation algorithms. Section 3 analyses the current test problems in the literature of robust multi-objective optimisation and identifies their weaknesses. The hindrances are introduced and employed to design new test problems in Section 4. In addition, Section 4 investigates the characteristics of the proposed test functions theoretically and by generating random solutions. To provide a comprehensive study, five robust multi-objective algorithms are employed in Section 5 to approximate the robust fronts of the proposed test functions. Finally, Section 6 concludes the work and suggests some directions for future studies.As mentioned in the preceding section, four elements of a system that may face uncertainty are: operating conditions, inputs, outputs, and constraints. In the first type of uncertainties, environmental and operating conditions vary when the system is operating in the real environment [15]. Operating conditions are considered as secondary inputs for a system (indirect), so these uncertainties can also be considered secondary. Examples of this type are temperature or pressure of water when a submarine is navigating underwater. Another example would be the angle of attack, temperature of air, or wind speed when an aircraft is flying. Such operating conditions sometimes become very important, especially for systems that are critical to the safety of human operators.The second type of uncertainties occurs in the inputs of the systems [15,16]. Inputs refer to the primary inputs of the systems (design parameters). Examples of design parameters are the number of coils in a tension spring, number/length of blades in a propeller, or shape of airfoils along an aircraft's wing. The parameters may diverge from design values, which mostly happens during manufacturing processes. In this case, the designed parameters vary during production and directly affect the outputs of a system.Outputs of a system also have the potential to face uncertainties [17,18]. Although fluctuation of other components of a system perturbs the outputs, the system itself may produce noisy outputs as well. This type of uncertainty is mostly due to the usage of meta-models, approximated models, or simulators that are used to calculate the outputs of a system. Obviously, real problems are modelled in computers, so the model itself has a slight discrepancy from reality. An example of this type is the simulation's tolerances in Computational Fluid Dynamics (CFD) problems. The difference between this type and others is its deterministic nature. Although using more accurate approximated models or meta-models can reduce the perturbations’ intensity, the system always produces intrinsic noise. There is also another kind of system worth mentioning, called dynamic systems. Such systems’ outputs dynamically change over time, which cause different outputs for similar inputs and operating conditions [19]. In other words, time is a key input that defines the outputs of dynamic systems.The last type of uncertainty is applied to the constraints of a system [1]. Designing a system is usually undertaken while considering several constraints and limitations. The constraints are not distinct from other components of a system and may face perturbations. Uncertainty in constraints does not have direct impact on the system, yet it varies the boundaries of the system. As a result of perturbation here, the outputs of a system may become invalid due to the violation of constraints.In this paper we concentrate on the uncertainty in parameter, which is, indeed, one of the most common concerns in engineering design problems. As discussed in the introduction, this type of uncertainty detrimentally varies the inputs of a system. In a single-objective search space, robust optimisation can be formulated as a minimisation problems as follows (without loss of generality):(2.1)Minimise:f(x→+δ→)(2.2)Subject to:gi(x→+δ→)≥0,i=1,2,…,m(2.3)hi(x→+δ→)=0,i=1,2,…,p(2.4)Li≤xi≤Ui,i=1,2,…,nwherex→is the set of parameters,δ→indicates the uncertainty vector corresponding to each variable inx→, m is the number of inequality constraints, p is the number of equality constraints, and [Li, Ui] are the boundaries of ith variable.Due to the nature of single-objective optimisation problems, there is one robust global optimum for a certain level of uncertainty. The robust optimum may change for different degrees of uncertainty. Therefore, the ultimate goal of a robust evolutionary algorithm is to find the optimum that has the least sensitivity to perturbation of parameters. The robust optimum obtained can be either the global optimum or one of the local optima in the search space.Robust optimisation in a multi-objective search space is different and can be formulated as a minimisation problem as follows:(2.5)Minimise:f(x→+δ→)={f1(x→+δ→),f2(x→+δ→),…,fo(x→+δ→)}(2.6)Subject to:gi(x→+δ→)≥0,i=1,2,…,m(2.7)hi(x→+δ→)=0,i=1,2,…,p(2.8)Li≤xi≤Ui,i=1,2,…,nwherex→is the set of parameters,δ→indicates the uncertainty vector corresponding to each variable inx→, o is the number of objective functions, m is the number of inequality constraints, p is the number of equality constraints, and [Li, Ui] are the boundaries of ith variable.It may be observed in these equations that the only difference is the number of objectives to be optimised, while all of them receive perturbation as undesirable inputs. Due to the multiple objectives, robust optimisation has a different meaning here. In this case, robust optimisation refers to the process of finding a set of solutions representing the best trade-offs between the objectives with the lowest susceptibility to perturbations of all of the parameters [20]. In addition, the comparison of results cannot be done based on inequality comparison operators anymore. A solution in a multi-objective search space is better than another, if it shows equal or better results in all of the objectives (and is at least better in one objective) while considering given perturbations. This is called robust Pareto dominance and defined as follows [20]:Definition 1Robust Pareto DominanceVectorx→=(x1,x2,…,xk)dominates vectory→=(y1,y2,…,yk)(denote as x≺y) iff:∀i∈{1,2,…,k},[f(xi+δi)≤f(yi+δi)]∧[∃i∈1,2,…,k:f(xi+δi)<f(yi+δi)],In a multi-objective search space, there are solutions that do not robustly dominate each other. These solutions are called non-dominated Pareto optimal solutions. In other words, they are robustly Pareto optimal with respect to each other. The definition of robust Pareto optimality is as follows:Definition 2Robust Pareto OptimalityA solutionx→∈Xis called Pareto optimal iff:{∄y→∈X|F(y→+δ→)≺F(x→+δ→)}As discussed above, a set of solutions representing the best possible trade-offs between the objectives while considering perturbations in parameters is the answer for a robust multi-objective problem. This set is called the robust Pareto optimal solution set and defined as follows [20]:Definition 3RPS: Robust Pareto optimal solution SetThe set all robust Pareto optimal solutions with respect to uncertainties:RPS={x→∈X|∄y→∈X,F(y→+δ→)≺_F(x→+δ→)}The robust Pareto optimal solution set shows the location of robust non-dominated solutions in the parameter space. The corresponding objective values of each solution in the RPS are assumed to be in a set called the robust Pareto optimal front. This set is defined as follows:Definition 4RPF: Robust Pareto optimal FrontA set that contains the value of objective functions for members of the robust Pareto optimal solution set:RPF={F(x→)|x→∈RPs}The definition of robust Pareto optimality allows the robust Pareto optimal solutions to be in any part of the search space. In other words, a dominated solution in multi-objective optimisation can be chosen as a robust non-dominated solution because of its robustness. Therefore, the robust Pareto optimal front can be shaped in four situations with respect to the true Pareto optimal fronts: [4,21–23]: (a) the Pareto front is totally robust, (b) a part of the Pareto front is robust, (c) the Pareto front is partially robust, and (d) the RPF is completely dominated by the Pareto front.Generally speaking, there are two main methods for handling robustness in the literature of evolutionary algorithms: utilising a measure for evaluating robustness of solutions and optimising a measure of robustness in addition to the objectives of the problem. In the former method, two classes of robustness indicators are generally employed to confirm the robustness of algorithms: expectation and variance. In the latter methods expectation or variance measures are employed as another objective to be optimised by robust algorithms. In this case the algorithm would approximate trade-offs between objectives and robustness. The disadvantage of this approach is increasing the difficulty of the problem by adding a new objective.Robust optimisation using an expectation measure was first proposed by Deb and Gupta [21] and named type I. Without loss of generality, this type of robust optimisation can be formulated as a minimisation problem as follows:(2.9)Minimise:F(x→+δ→)=E1(x→+δ→),E2(x→+δ→),…,Eo(x→+δ→)(2.10)Subject to:x→∈S(2.11)gi(x→+δ→)≥0,i=1,2,…,m(2.12)hi(x→+δ→)=0,i=1,2,…,p(2.13)Li≤xi≤Ui,i=1,2,…,n(2.14)where:Ei(x)=1H∑j=1Hfi(x→+δj→)where S is the feasible search space, H is the number of samples, and o is the number of objectives.In type I, the objectives (f1, f2, …, fo) of a given problem are first replaced by expectation measures (E1(x), E2(x), …, Eo(x)). Eq. (2.14) shows that an expectation measure applies possible perturbations to the parameters and returns an average of variations of objectives accordingly. Technically speaking, H number of randomly generated solutions are considered around the solutionx→, and then the expectation measure is calculated using Eq. (2.14). According to Deb and Gupta [21], this method approximates the integration of the main objective(s) along the perturbations (δ) by the Monte Carlo method. If the analytical integration of the search space is known, however, robustness can be confirmed by a real integration over perturbation. In this case robust optimisation using an expectation measure can be formulated as a minimisation problem as follows (without loss of generality):(2.15)Minimise:F(x→+δ→)={E1(x→+δ→),E2(x→+δ→),…,Eo(x→+δ→)}(2.16)Subject to:x→∈S(2.17)gi(x→+δ→)≥0,i=1,2,…,m(2.18)hi(x→+δ→)=0,i=1,2,…,p(2.19)Li≤xi≤Ui,i=1,2,…,n(2.20)where:Ei(x)=1Bδ(x)∫y∈Bδ(x)fi(y)dywhere S is the feasible search space, Bδ(x) is the neighbourhood of the solution x within δ radius, andBδ(x)is the hypervolume of the neighbourhood.Since the mathematical formulations of real search spaces are usually unknown, the Monte Carlo-based method is more practical.The type II robustness handling method is different from type I, in which the original objectives are maintained. A variance measure is employed to confirm the robustness of solutions and treated as a constraint for a given problem. Robust optimisation using a variance measure was first proposed by Deb and Gupta [21]. Without loss of generality, this type of robust optimisation can be formulated as a minimisation problem as follows:(2.21)Minimise:f(x→+δ→)={f1(x→+δ→),f2(x→+δ→),…,fo(x→+δ→)}(2.22)Subject to:x→∈S(2.23)V(x→+δ→)=fp(x→+δ→)−f(x→)f(x→)≤η→(2.24)gi(x→+δ→)≥0,i=1,2,…,m(2.25)hi(x→+δ→)=0,i=1,2,…,p(2.26)Li≤xi≤Ui,i=1,2,…,nwhere S is the feasible search space,fp(x→+δ→)can be selected as effective mean or worst function value among the H selected solutions in the neighbourhood, and η is a threshold in [0,1] that defines the level of robustness for solutions.Eq. (2.23) shows that the variance measure is a normalised measure and should be less thanη→. The vectorη→includes values in [0,1] which define the intensity of allowed variation in each of the objectives. Whenη→=1,1,…,1, the variance measure is always satisfied, so the robust optimisation converts to a normal global optimisation. Robust optimisation is favoured and becomes stricter asη→decreases. The variance measure can also be defined asfp(x→+δ→)−f(x→). In this case the maximum valid fluctuation for each objectives should be included in theη→vector.Since the proposal of type I and type II robust optimisation, this field has attracted much attention. In 2004, Wang proposed a method based on rough sets to detect subspaces in a multi-objective search space and formulate robust optimisation problems as two-objective problems [24]. Despite the merits of this method, it suffers from some drawbacks: limitation of subspaces, extra function evaluations due to re-sampling, and inefficiency of the LHS method employed for high dimensional problems. In 2007, Egorov et al. employed Indirect Optimisation based on Self-Organizing (IOSO) for finding robust solutions[53]. In 2006, two evolutionary strategies were proposed by Beyer and Sendhoff for finding robust solutions, but their methods needed extra function evaluation [25]. Other relevant robust optimisation techniques using multi-objective algorithms can be found in [26–29]. Since the contribution of this paper is the proposal of new test problems, we have not reviewed the literature of robust optimisation techniques in detail and refer the interested readers to two main survey papers by Jin and Branke [2] in 2005 and Beyer and Sendhoff [1] in 2007.There are not many test functions in the field of robust multi-objective optimisation but we have found some sets of test functions in the literature. The next subsection first theoretically analyses and reviews these test functions. The current gaps are then identified and the contributions of this paper are highlighted.The first attempt to construct robust multi-objective test problems was made by Deb and Gupta [21]. The main focus was the proposal of test functions with different robust Pareto optimal fronts compared to the global Pareto optimal front. Deb and Gupta discussed the possibility of four different types of robust Pareto fronts, as discussed in the introduction. The details of these test functions are provided in the Appendix (RMTP1 to RMTP6). The robust and global Pareto optimal fronts are identical in RMTP1. The RMTP2 test function simulates the second type of robust front, in which a part of the global Pareto optimal front is robust. The robust Pareto optimal front of RMTP3 is completely dominated by the global Pareto optimal front. Finally, RMTP4 has a robust Pareto optimal front which is partially identical to the main Pareto optimal front and local fronts. The rest of the test functions are the extended three-objective version of RMTP1 and RMTP3. These test functions provide very challenging test beds, as investigated in [30]. The test functions have been designed with known analytical integration of their Pareto optimal fronts. Therefore, they can be employed to benchmark the performance of both type I and type II robustness handling methods.The second set of test function was proposed by Gaspar-Cunha et al. in 2013 [22]. The main contribution was the proposal of test functions with non-convex shapes for robust Pareto optimal front and separated robust regions along the front with similar or different degrees of robustness. The details of these test functions are provided in the Appendix (RMTP7 to RMTP11). There is only one front in all of the test functions. Therefore, the search space is unimodal and the robust Pareto optimal solutions are located on the front. The shape of the Parato optimal fronts are very different than those of Deb and Gupta. The robust regions of the main Pareto optimal front are on the convex section of RMTP7, whereas the robust areas lie on concave regions of the Pareto optimal front in RMTP9. RMTP10 and RMTP11 were proposed in order to design separated robust regions in the robust Pareto optimal fronts. The robustness of the separated regions are decreased from left to right in RMTP10, while the robustness is equal for the three discontinuous parts in RMTP11. RMTP10 has been designed for testing convergence of an algorithm towards more robust regions of a search space. In addition, RMTP11 is suitable for benchmarking the ability of an algorithm in terms of converging to distinct regions in the Pareto optimal front.There is also a recent set of test functions (BZ) proposed by Bader and Zitzler [31]. The lack of specific multi-objective test problems in the literature was reported and an early attempt made to design a standard set. Bader and Zitzler proposed six test functions with different robust characteristics. The focus was mostly on the proposal of a multi-modal parameter space and multi-frontal search space. The shapes of the robust Pareto optimal fronts were linear, concave, or convex in the proposed test functions. However, other difficulties such as bias, deceptiveness, and flatness are still missing in the literature of robust multi-objective tests functions, which are the main motivations and contributions of the current paper.Another set of robust multi-objective test functions was proposed by Goh et al. [20], in which a Gaussian landscape generator integrated different parametric sensitivities to deterministic search spaces. Goh et al. [20] proposed five test functions called GTCO and proved that they can provide challenging and biased search space for robust multi-objective optimisation algorithms. Three frameworks have also been proposed recently that allow designers to generate robust multi-objective test problems with different levels of difficulty [32]. Shifted robust multi-objective test functions were also proposed to improve the difficulty of the current test functions [33].Despite the merits of the proposed test functions so far, few of them are multi-modal. Although two of Deb and Gupta's functions are bi-modal, a challenging test bed should have more than two local fronts. Another drawback of the current test problems is the bias of the search space towards robust fronts as also recommended by Goh et al. [20]. When the search space is biased towards the robust front, it becomes difficult to distinguish whether the robust measure assists an algorithm to approximate the robust front, or the robust front is obtained because of the failure of the algorithm in finding the global Pareto optimal front.The shape of the robust front is also very important especially for benchmarking the coverage of a robust multi-objective algorithm. Convexity and concavity of a robust front cause an intrinsic robustness bias towards some regions of the robust front, so a linear robust front is better for benchmarking the coverage of a robust multi-objective algorithm. In the literature there is no linear front for benchmarking the coverage of algorithms. In addition, the literature lacks robust test functions with deceptive search spaces, while such test functions are the most difficult ones. Last but not least, there is no test function with a dominant flat, or featureless, region.The contribution of this paper is to fill these gaps by integrating a variety of hindrances to the current test problems and propose new test functions.According to Deb [34], a multi-objective optimisation process utilising meta-heuristics deals with overcoming many difficulties such as infeasible areas, local fronts, diversity of solutions, and isolation of optima. Difficulties dramatically increase when searching for robust Pareto optimal solutions. A robust multi-objective algorithm has to be equipped with proper operators to handle several difficulties in addition to the above-mentioned challenges: robust local fronts, multiple non-robust fronts, non-improving search spaces, isolation of robust fronts, deceptive non-robust fronts, different shapes of robust fronts, and robust fronts with separate robust regions. Designing an algorithm to handle all these difficulties in a real search space requires challenging test beds during development.The process of designing a test problem includes two goals. On one hand, a test problem should be simple and modular in order to allow researchers to observe the behaviour of meta-heuristics and benchmark their performance from different perspectives. On the other hand, a test function should be difficult to provide a challenging environment similar to those of real search spaces. These two characteristics are in conflict where high simplicity makes a test function readily solvable for meta-heuristics and the relevant comparison inefficient. In contrast, although a very difficult test function is able to effectively mimic a real search space, it may be very difficult to solve so that the performance of algorithms cannot be clearly observed and compared. These two conflicting issues make the development of test problems challenging.In the literature there are many papers that propose multi-objective test functions with diverse characteristics for benchmarking the performance of multi-objective algorithms. For instance, scalable test problems proposed in [35], test problems with mixed encoding proposed in [36], vaious difficulties for multi-objective test problems proposed in [37], and linkage integrated into multi-objective test problems in [38]. There are also several recommendations for creating standard single-objective test functions [39,40]. However, there little advice for making multi-objective test beds in the literature. In this paper we refer to the guidelines provided in [35,41]. According to Deb et al. [35,41], simplicity (in structure), desired number of variables, desired number of objectives, availability of the shape and location of the Pareto optimal front, availability of the shape and location of the Pareto optimal set, controlling parameters for adjusting difficulty of test problems, and different shapes for the Pareto optimal front are the essential characteristics of test problems in a standard test set.According to Huband et al. [42], capturing all combinations of these difficulties in a single test function and in a test set is impractical. In this section, therefore, five types of hindrances are introduced and employed to design robust multi-objective test functions with diverse challenging characteristics. It should be noted that we combine characteristics whenever possible to increase the difficulty of test problems.The first and simplest method of increasing the difficulty of a multi-objective test function is to bias its search space [37]. Bias refers to the density of the solutions in the search space. Almost all of the current test beds in the literature of robust multi-objective optimisation suffer from a biased search space towards robust regions [20]. Fig. 1(a) illustrates 50,000 randomly generated points in the first two dimensions of the RMTP10 to illustrate the bias of the search space. This figure shows that the bias is towards to right corner of the front. Therefore, it is hard to determine whether the robust measure assists an algorithm to find the robust front or the robust front is obtained because of the failure of the algorithm to find the global front.In order to prevent such issues, the following equation is introduced for the function g(x) in the test functions to bias the search space away from the robust front:(4.1)g(x)=1+10∑i=2nxin−1ψwhere ψ defines the degree of bias (ψ<1 causes bias away from the PF) and n is the maximum number of variables.In Eq. (4.1), ψ is responsible for defining the bias level of the search space. Fig. 1(b) shows 50,000 random solutions in the same search space of Fig. 1(a) but with ψ=0.3. This figure shows that density of solutions is very low close to the robust Pareto front, and increased further from the front. This behaviour in a test function assists us to effectively benchmark the performance of robust algorithms in approximating the robust Pareto optimal solutions.To further observe the effect of ψ on the density of solutions in the search space, 50,000 random solutions with different values for ψ are illustrated in Fig. 2. This figure shows that the search space is biased inversely proportional to ψ. In other words, the density of solutions is increased as ψ decreases.According to Deb [37], there are at least two optima in a deceptive search space: the deceptive optimum and the true optimum. The search space should be designed in such a way to entirely favour the deceptive optimum. Such problems are very challenging for evolutionary algorithms since the search agents are directed automatically towards the deceptive optimum by the search space while the global optimum is somewhere else [43,44]. To date there has been no deceptive robust multi-objective test problem: the first is proposed in this subsection.The proposed mathematical formulation for generating deceptive test functions is as follows:(4.2)Minimise:f1(x)=x1(4.3)Minimise:f2(x)=H(x2)×{G(x)+S(x1)}(4.4)Where:H(x)=12−0.3e−x−0.2/0.0042−0.5e−x−0.5/0.052−0.3e−x−0.8/0.0042+sin(πx)(4.5)G(x)=∑i=3N50xi2(4.6)S(x)=1−xβIt may be observed that the framework is similar to those of ZDT [45] and DTLZ [35,41]. However, the function H is modified as shown in Fig. 3. This figure shows that the proposed H function has two non-robust deceptive local optima, two non-robust global optima, and one true robust (which is local) optimum. The element sin(πx) at the end of this function causes deceptiveness of the search space, in which the entire search space deceptively favours the non-robust optima.The combination of H, G, and S functions constructs a deceptive multi-objective test problem, as illustrated in Fig. 4. It should be noted that we also modify the function S to define the shape of non-robust and robust fronts. The newly added parameter β defines the shape of the fronts. It may be observed that the fronts are concave when β<1 and convex when β>1. Fig. 4 also shows that the proposed test function has two overlapped non-robust global fronts, two non-robust local fronts, and one robust local front. The entire search space favours the non-robust regions, so the non-robust fronts are highly deceptive.The deceptive non-robust fronts are very attractive for the search agents of meta-heuristics. Therefore, these test problems have the potential to challenge robust algorithm significantly. The ability of an algorithm to avoid deceptive non-robust regions can be benchmarked. Also, the performance of an algorithm in approximating robust fronts with convex, linear, and non-convex shapes is benchmarked.Although the first two introduced hindrances can mimic the difficulties of real search spaces and challenge robust algorithms, there is another important characteristic called multi-modality. Real search spaces may have many local solutions that make them very challenging to solve. In the field of evolutionary single-objective and multi-objective optimisation, there is a considerable number of test problems with local optima. However, there is no multi-modal robust multi-objective test problem in the literature. We propose the following test function in order to fill this gap:(4.7)Minimise:f1(x)=x1(4.8)Minimise:f2(x)=H(x2)×{G(x)+S(x1)}(4.9)Where:H(x)=32−0.5e−x−0.5/0.042−∑i=0M0.8e−x−0.02i/0.0042+0.8e−x−0.6+0.02i/0.0042(4.10)G(x)=∑i=3N50xi2(4.11)S(x)=1−xβwhere N is the number of variables, M indicates the number of non-robust valleys in the parameter space and non-robust fronts in the objective space.It may be seen in the formulation that the framework is again similar to those of ZDT and DTLZ, yet the function H is different. To see the search space, the shape of function H is shown in Fig. 5. This figure shows that the robust optimum is a local optimum, while there are many non-robust global fronts. Note that the number of global fronts can be defined by adjusting the parameter M in the H function.To see how the parameter space and objective space of the proposed multi-modal test problem look like, Fig. 6is provided. This figure shows that the same shape and number of optima are created along x2 (f2). So, the parameter space has many non-robust global valleys and one robust local valley. The objective space shows that the global and local valleys create only two fronts: a local front and a global front. It should be noted that there are actually more than two fronts, all the global fronts are overlapped. Obviously, the local front is the robust front, which should be approximated by robust algorithms.Similarly to the deceptive test functions, the function S is required to define the shape of the fronts as well. There is again a parameter β that is able to change the shape of search space and Pareto optimal fronts as shown in Fig. 7. This mechanism challenges robust algorithms to approximate different shapes for non-robust and robust Pareto optimal fronts.This set of test functions provides non-robust fronts as hindrances for robust multi-objective test functions. The search agents of robust algorithms should avoid all the local fronts to entirely approximate the robust front.The last difficulty is the flatness of search space. A large portion of such landscapes is featureless, so there is no useful or deceptive information about the location of optima. Although a flat search space might look very simple, the majority of evolutionary algorithms fail in solving such problems especially if the first random individuals are all located on the flat regions. It this case, all the individuals are assigned equal fitness values so the majority of evolutionary operators become ineffective. For instance, the PSO algorithm fails to update Gbest and Pbest effectively for guiding particles.For creating a robust multi-objective test function with a flat search space, we propose the following equations:(4.12)Minimisef1(x)=x1(4.13)Minimise:f2(x)=H(x2)×G(x)+S(x1)(4.14)Where:H(x)=1.2−0.2e−x−0.95/0.032−0.2e−x−0.05/0.012(4.15)G(x)=∑i=3N50xi2(4.16)S(x)=1−xβThe function H is modified to construct this test function. As illustrated in Fig. 8, this function has two global optima close to the boundaries. This function deliberately provides two optima to challenge robust algorithms in terms of favouring fronts with different degrees of robustness. In addition, a large portion of the function H is flat, so no information about the location of fronts can be extracted from the search space. Another challenge here would be the robustness of the flat region. Since the variation is consistent in the second objective, a robust algorithm may be trapped in the flat region, assuming it as the robust optimum, and failing to approximate the actual robust front.Again the test function is equipped with a parameter called β, which is responsible for defining the shape of the fronts. We construct three variations of this test function as shown in Fig. 9. Therefore, different shapes for both fronts are also another challenge for robust algorithms when solving these test functions.In summary, the proposed test functions are provided in Fig. 10. This set of benchmark problems provides very challenging test beds with a variety of hindrances for robust multi-objective meta-heuristics. Although the characteristics of the majority of test functions were investigated and confirmed theoretically and observed by creating 50,000 random points, we compare five well-known algorithms on these test function to further investigate their effectiveness in practice.

@&#CONCLUSIONS@&#
