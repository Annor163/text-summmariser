@&#MAIN-TITLE@&#
Efficient feature tracking of time-varying surfaces using multi-scale motion flow propagation

@&#HIGHLIGHTS@&#
Present a multi-scale geometry motion flow for feature tracking of time-varying surfaces.We can track features on the time-varying surfaces in large deformation.We can process both mesh-based and point based time-varying surfaces.

@&#KEYPHRASES@&#
Multi-scale filtering,Time-varying surfaces,Geometry feature tracking,Geometry motion flow,Gaussian mixture model,

@&#ABSTRACT@&#
This paper presents a framework for efficient feature tracking of time-varying surfaces. The framework can not only capture the dynamic geometry features on time-varying surfaces, but can also compute the accurate boundaries of the geometry features. The basic idea of the proposed approach is using the multi-scale motion flow and surface matching information to propagate the feature frame on time-varying surfaces. We first define an effective multi-scale geometry motion flow for the time-varying surfaces, which efficiently propagates the geometry features along the time direction of the time-varying surfaces. By combining both the approximately invariant signature vectors and geometry motion flow vectors, we also incorporate the shape matching into the system to process feature tracking for time-varying surfaces in large deformation while with low frame sampling rate. Our approach does not depend on the topological connection of the underlying surfaces. Thus, it can process both mesh-based and point-based time-varying surfaces without vertex-to-vertex correspondence across the frames. Feature tracking results on different kinds of time-varying surfaces illustrate the efficiency and effectiveness of the proposed method.

@&#INTRODUCTION@&#
Time-varying surfaces, also called animated objects or dynamic shapes, are given as a sequence of surface frames, each of which is a static geometry model (mesh based surface or point based surface). Recently, with the progress of advanced scanning technologies, it is possible to reconstruct time-varying surfaces from the point clouds scanned for deformed or animated objects  [1]. Time-varying surfaces are more expressive compared with static geometry models, and they are now a popular data representation method with wide applications in various fields, such as virtual reality, computer games, 3D animated films, product design and scientific computation visualization. As a promising data representation, a large number of research works on time-varying surfaces have been proposed, such as segmentation  [2–4], geometry reconstruction [1,5,6], geometry editing and modeling  [7,8].In this paper, we aim at tracking geometry features of time-varying surfaces, namely, tracking the features’ motion paths of time-varying surfaces. Similar to video object tracking  [9], efficient feature tracking of time-varying surfaces is one of the critical tasks in many geometry processing applications such as geometry editing and modeling, geometry transmission, feature detection, and geometry description. However, unlike video tracking, where there are pixel-to-pixel correspondences among the consequent image frames, time-varying surfaces such as point-based geometry usually do not hold point-to-point correspondence among adjacent surfaces. Feature tracking of time-varying surfaces is a challenging job considering the following aspects:•Capturing the dynamic geometry features with accurate boundaries over time-varying surfaces is difficult, especially when the boundaries of time-varying feature are fuzzy.Time-varying surfaces usually do not hold point-to-point correspondence among adjacent surfaces, especially for point sampled geometry sequences, which increases the complexity of feature tracking of time-varying surfaces.Data amount of time-varying surfaces is usually much larger than a single static object, thus the efficiency of feature tracking is one performance bottleneck which needs to be addressed.To address aforementioned problems, we present a novel framework for efficient feature tracking of time-varying surfaces. The basic idea of the presented approach is to compute an efficient multi-scale geometry motion field for time-varying surfaces, which propagates the current geometry feature to the next frame according to the motion field variation. For time-varying surfaces with large deformation while with low frame sampling rate, we first perform surface matching between the neighboring frames, and then combine both the surface matching results and geometry motion flow vectors for accurate feature tracking. We build localized classifiers based on GMMs (Gaussian Mixture Models) over initial boundaries of the tracked feature to compute accurate and smooth feature boundaries. Our approach does not depend on the topological connection of the underlying surfaces, thus, it can process both mesh-based and point-based time-varying surfaces.This paper introduces the following contributions:•Present a multi-scale geometry motion flow for efficient feature tracking of time-varying surfaces, which can process both mesh-based and point-based time-varying surfaces without vertex-to-vertex correspondence across the frames.Integrate shape matching in the feature tracking system to process time-varying surfaces in large deformation with low frame sampling rate.The rest of our paper is organized as follows. Section  2 reviews related work. Section  3 gives single-frame features and a multi-frame propagation method. In Section  4, we show experimental results and discussions. Finally, we conclude our paper in Section  5.

@&#CONCLUSIONS@&#
