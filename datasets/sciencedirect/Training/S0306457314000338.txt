@&#MAIN-TITLE@&#
Soft-constrained inference for Named Entity Recognition

@&#HIGHLIGHTS@&#
Named Entity Recognition is addressed by constraining inference in CRF.An two phases integer linear programming approach is proposed.Complex relationships among labels are automatically extracted from data.Extracted relationships are introduced as soft constraints in the ILP formulation.The proposed method significantly outperforms the state of the art approach.

@&#KEYPHRASES@&#
Conditional Random Fields,Named Entity Recognition,Rule extraction,Integer linear programming,

@&#ABSTRACT@&#
Much of the valuable information in supporting decision making processes originates in text-based documents. Although these documents can be effectively searched and ranked by modern search engines, actionable knowledge need to be extracted and transformed in a structured form before being used in a decision process. In this paper we describe how the discovery of semantic information embedded in natural language documents can be viewed as an optimization problem aimed at assigning a sequence of labels (hidden states) to a set of interdependent variables (textual tokens). Dependencies among variables are efficiently modeled through Conditional Random Fields, an indirected graphical model able to represent the distribution of labels given a set of observations. The Markov property of these models prevent them to take into account long-range dependencies among variables, which are indeed relevant in Natural Language Processing. In order to overcome this limitation we propose an inference method based on Integer Programming formulation of the problem, where long distance dependencies are included through non-deterministic soft constraints.

@&#INTRODUCTION@&#
The data used by Decision Support Systems are assumed to be structured and quantifiable. However, thanks to the growing of the web and the spread of Document Management Systems, most of the valuable information are embedded in textual documents that need to be processed to extract relevant information in a machine readable form to become actionable. In most of the cases this activity involves the analysis of human language texts by means of Natural Language Processing (NLP) techniques. Named Entity Recognition (NER) is the task aimed at identifying and associating atomic elements in a given text to a set of predefined categories such as names of persons, organizations, locations, dates, and quantities.Early NER systems have been defined as rule-based approaches with a set of fixed and manually coded rules provided by domain experts (Rau, 1991; Lehnert et al., 1993; Riloff, 1993; Appelt, Hobbs, Bear, Israel, & Tyson, 1993). Considering the costs, in terms of human effort, to reveal and formulate hand-crafted rules, several research communities ranging from Statistical Analysis to Natural Language Processing and Machine Learning have provided valuable contributions for automatically derive models able to detect and categorize pre-defined entities. The first tentatives, aimed at deriving these rules under the form of boolean conditions, are based on inductive learner where rules can be learnt automatically from labeled examples. The inductive rule learning approach has been instantiated according to different learning paradigm: bottom-up (Califf & Mooney, 2003; Califf & Mooney, 1999; Ciravegna, 2001), top-down (Soderland, 1999; Quinlan, 1990; Landwehr, Kersting, & Raedt, 2007; Ho & Nguyen, 2003) and interactive rule learning (Khaitan, Ramakrishnan, Joshi, & Chalamalla, 2008; Bohannon et al., 2009; Beckerle, Martucci, & Ries, 2010).An alternative approach to inductive rule learners is represented by statistical methods, where the NER task is viewed as a decision making process aimed at assigning a sequence of labels to a set of either joint or interdependent variables, where also complex relationships may hold among them. This decision making paradigm can be addressed in two different ways: (1) at segment-level (Sarawagi & Cohen, 2004; Daumé & Marcu, 2005; Galen, 2006), where the NER task is managed as a segmentation problem in which each segment corresponds to an entity label and (2) at token level (Takeuchi & Collier, 2002; Seymore, McCallum, & Rosenfeld, 1999; Ratnaparkhi, 1999; Richardson & Domingos, 2006; Lafferty, McCallum, & Pereira, 2001), where an entity label is assigned to each token of the sentence. In the first case the output of the decision process is a sequence of segments. More formally, a segmentation s of an input sentencex=x1,…,xNis a sequence of segmentss1…spwithp⩽N. Each segmentsjconsists of a start positionlj, an end positionuj, and a label y belonging to a set of entity labelsY. The second decision making paradigm is represented by token-level models, where the unstructured text is tackled as a sequence of tokens and the output of the decision process is a sequence of labelsy=y1,…,yN.Nowadays, the state of the art to model a NER problem is represented by Linear Chain Conditional Random Fields (Lafferty et al., 2001). This model, thanks to its advantages over generative approaches, has been extensively investigated to extract named entities from different unstructured sources such as judicial transcriptions (Fersini, Messina, Archetti, & Cislaghi, 2013; Fersini & Messina, 2013), medical reports (Cvejic, Zhang, Marx, & Tjoe, 2012; Deléger et al., 2013), and user generated contents (Qi & Chen, 2010; Shariaty & Moghaddam, 2011). The efficiency of Linear Chain Conditional Random Fields (CRF) is strictly related to the underlying Markov assumption: given the observation of a token, the corresponding hidden state (label) depends only on the labels of its adjacent tokens. In order to efficiently enhance the description power of CRF, during the last ten years several approaches have been proposed to enlarge the information set exploited during training and inference. In particular, two main research directions have been investigated: (1) relaxing the Markov assumption (Sarawagi & Cohen, 2004; Galen, 2006) to model long distance relationships and (2) introducing additional domain knowledge in terms of logical constraints during the inference phase (Kristjansson, Culotta, Viola, & McCallum, 2004; Roth & Yih, 2005; Chang, Ratinov, & Roth, 2007; Chang, Ratinov, & Roth, 2008). Considering that the relaxation of the Markov assumption implies an increasing computational complexity related to the training and inference phase, in this paper we focused our attention on an integer linear programming (ILP) formulation of the inference problem by including soft constraints obtained by learning declarative rules from data.The introduction of constraints allows us to improve the global label assignment by correcting mistakes of local predictions. The label assignment problem is therefore solved through a constrained optimization problem where the extra-knowledge related to complex relationships among variables is represented through a set of logical rules easily introduced as linear inequalities. This approach, as shown by the experimental results, makes it possible to significantly improve the performances of CRF in NER tasks.The outline of the paper is the following. In Section 2 a brief review of CRF is presented along with a background overview of the training phase, together with the most relevant inference approaches able to include domain constraints. In Section 3 the proposed soft-constrained inference approach is detailed by focusing on learning constraints from data and by presenting its mathematical programming formulation. In Section 4 the experimental investigation on both benchmark and datasets is described, while in Section 5 conclusions and ongoing research are summarized.A Conditional Random Field is an indirected graphical model that defines the joint distributionP(y|x)of the predicted labels (hidden states)y=y1,…,yNgiven the corresponding tokens (observations)x=x1,…,xN. Now, consider X as the random variable over data sequences (natural language sentences) to be labeled, and Y is the random variable over corresponding label sequences over a finite label alphabetY. The joint distributionP(X,Y)is represented by a conditional modelP(Y|X)from paired observation and label sequences, and the marginal probabilityp(X)is not explicitly model. The formal definition of CRF (Lafferty et al., 2001) is given below:Definition 1Conditional Random FieldsLetG=(V,E)be a graph such thatY=(Yv)v∈V, so that Y is indexed by the vertices of G. Then(X,Y)is a Conditional Random Field, when conditioned on X, the random variablesYvobey the Markov property with respect to the graph:p(Yv|X,Yw,w≠v)=p(Yv|X,Yw,w∼v), wherew∼vmeans that w and v are neighbors in G.Thus, a CRF is a random field globally conditioned on the observation X. Throughout the paper we tacitly assume that the graph G is fixed. A Linear-Chain Conditional Random Field is a Conditional Random Field in which the output nodes are linked by edges in a linear chain. The graphical representation of a general CRF and a Linear-Chain CRF is reported in Fig. 1. In the following, Linear-Chain CRF are assumed.According to the Hammersley–Clifford theorem (Hammersley & Clifford, 1971; Clifford, 1990), givenCas the set of all cliques in G, the conditional probability distribution of a sequence of labels y given a sentence x can be written as:(1)p(y|x)=1Z(x)∏C∈CΦC(xC,yC)whereΦCrepresents the set of maximal cliquesC∈C, the verticesxCandyCof the clique C correspond to hidden states y and observations x, andZ(x)∈[0,1]is the partition function for global normalization. FormallyZ(x)is defined as:(2)Z(x)=∑y|Y|∏C∈CΦC(xC,yC)In order to compute the joint probability distribution (Eq. (1)), a set of potential functions must be defined over configurations of the maximal cliques in the underlying graph. The potential functions, which state the prior probability that elements of the clique C have certain values, can be conveniently simplified as inner products between a parameter vectorωand a set of feature function f. Considering that each cliqueΦC(·)∈Ccan encode one or more potential functions (in this case we consider the log-linear ones), the probability of a sequence of label y given the sequence of observations x can be rewritten as:(3)p(y|x)=1Z(x)exp∑t=1N∑k=1Kωkfk(yt,yt-1x,t)wherefk(yt,yt-1x,t)is an arbitrary feature function over its arguments andωkis a feature weight that is a free parameter in the model. Feature functions are fixed in advance and are used to verify some properties of the input text, while the weightsωkhave to be learned from data and are used to tune the discriminative power of each feature function. In particular when for a tokenxta given feature functionfkis active, i.e. a given property is verified, the corresponding weightωkindicates how to take into accountfk: (1) ifωk>0it increases the probability of the tag sequence y and (2) ifωk<0it decreases the probability of the tag sequence y; (3) ifωk=0has no effect whatsoever.The partition functionZ(x)assumes the form:(4)Z(x)=∑y|Y|exp∑k=1Kωkfk(yt,yt-1,x,t)The conditional probability distribution of Linear-Chain CRF can be estimated by exploiting two different kinds of feature functions such thatp(y|x)can be rewritten as follows:(5)p(y|x)=1Z(x)exp∑t=1N∑i=1|I|λisi(yt,x,t)+∑j=1|J|μjtj(yt-1,yt,x,t)where I and J represent the given and fixed set of state feature functionsi(yt,x,t)and transition feature functiontj(yt-1,yt,x,t), whileλiandμjare the corresponding weights to be estimated from training data. State feature function and transition feature function model respectively the sequence of observations x with respect to the current stateytand the transition from the previous stateyt-1to the current stateyt. The parametersλiandμjare used to weight the corresponding state and transition feature function.The choice of the feature functions strongly depends from the application context. For instance, an example of state feature function issi(yt,x,t)=1ifyt=PERSONandxt=John0otherwisewhile a transition feature function could betj(yt-1,yt,x,t)=1ifyt-1=PERSONandyt=DATE0otherwiseIn our case, where the CRF are assumed in a linear form, transition feature functions are assumed to verify dependencies between a label y at time t and its previous y values, while state feature functions evaluate Word Features to check whether a given token is present in the dictionary in a particular state, Start Features and End Features to check if a given label is a start and/or an end label.The learning problem in CRF relates to the identification of the best feature functionssi(yt,x,t)andtj(yt-1,yt,x,t)by unrevealing the corresponding weightsλiandμj. These parameters can be quantified either by exploiting some background domain knowledge or by learning from training data. When no background knowledge is available, several learning approaches can be adopted for estimatingλiandμj. Among them a widely used approach consists of maximizing the conditional log-likelihood of the training data. Given a training setTcomposed of training samples(x,y), with y ranging in the setYof entity labels, the conditional (penalized) log-likelihood is defined as follows:(6)L(T)=∑(x,y)∈Tlogp(y|x,λ,μ)-∑i=1|I|λi22σλ2-∑j=1|J|μj22σμ2=∑(x,y)∈T∑t=1N∑i=1|I|λisi(yt,x,t)+∑j=1|J|μjtj(yt-1,yt,x,t)-logZ(x)-∑i=1|I|λi22σλ2-∑j=1|J|μj22σμ2where the terms∑i=1|I|λi22σλ2and∑j=1|J|μj22σμ2map a Gaussian prior onλandμused for avoiding over-fitting.The objective functionL(T)is concave, and therefore both parametersλandμhave a unique set of global optimal values. A standard approach to parameter learning computes the gradient of the objective function to be used in an optimization algorithm (Lafferty et al., 2001; Sutton, 2008; Nocedal & Wright, 2000; Malouf, 2002). Among them we choose the quasi-Newton approach known as Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) (Malouf, 2002) due the main advantage of providing a dramatic speedups in case of huge number of feature functions.The inference problem in CRF corresponds to find the most likely sequence of hidden statey∗, given the set of observationx=x1,…,xN. This problem can be solved approximately or exactly by determiningy∗such that:(7)y∗=argmaxyp(y|x)The most common approach to tackle the inference problem is represented by the Viterbi algorithm (Baum & Petrie, 1966). Now, considerδt(yt=y|x)as the probability of the most likely path of generating the sequencey∗=y1,y2,…,yt. This path can be derived by one of the most probable paths that could have generated the subsequencey1,y2,…,yt-1. Formally, givenδt(yt=y|x)as:(8)δt(yt=y|x)=maxy1,y2,…,yt-1p(y1,y2,…,yt|x)we can derive the induction step as:(9)δt+1(yt+1=y′|x)=maxy∈Yδt(y|x)Φt+1(x,y,y′)=maxy∈Yδt(y|x)exp∑k=1Kωkfk(yt=y,yt+1=y′,x,t)The recursion terminates iny∗=argmaxy[δT(y)], allowing the backtrack to recovery∗.CRF, in their native form, are able to capture some local properties through the definition of transition and state feature functions. However, some more complex relationships among output variables (labels to be predicted) could exist when addressing NER problems. For instance, when annotating scientific citations the label Author should appear anywhere before the label Title.Two different strategies are suitable to include relationships in the probabilistic model: the feature way and the constraint way. The first one is concerned with the training phase by the definition of feature functions able to capture different kinds of relationships (Sarawagi & Cohen, 2004). The second one relates to the introduction of constraints during the inference phase for preserving the necessary relationships over the output prediction (Kristjansson et al., 2004; Roth & Yih, 2005; Chang et al., 2007; Chang, Ratinov, & Roth, 2012). While the first strategy might lead to intractable training and inference due to the necessity of learning additional parameters or defining higher order models, the second paradigm allows us to keep the model simple by enclosing expressive constraints directly during the inference phase. In this context we can distinguish between constraining the Viterbi algorithm (Kristjansson et al., 2004; Culotta, Kristjansson, McCallum, & Viola, 2006) and formulating the inference process as a constrained optimization problem.The main idea underlying the Constrained Viterbi algorithm is concerned with the clamping of some hidden variables to particular values. The resulting algorithm alters the induction step outlined in Eq. (9) such thaty∗is constrained to pass through a given sub-path C. The related constraintC^can be encoded in the induction step as follows:(10)δt+1(yt+1|x)=maxy∈Yδt(y)exp∑k=1Kωkfk(yt,yt+1,x,t)ifC^issatisfied0otherwiseFor time steps not involved in C Eq. (8) is used instead, restricting the algorithm to only consider paths that respect the defined constraint.Although the Constrained Viterbi algorithm is suitable to deal with short distance relationships in an efficient way, the introduction of non-local and non-sequential constraints makes this solution no longer applicable. In order to deal with more complex relationships, the inference process can be formulated as a constrained optimization problem and in particular as a shortest path problem. A simple representation of a labeling shortest path problem is given in Fig. 2.Given n tokens and m labels that each token can take, we can define a graphΩ=(Φ,Ψ)as composed ofnm+2nodes and(n-1)m2+2medges.1Two special nodes denoting the start and end positions of the path are additionally introduced.1The label of each token is represented by a nodeϕty, where0⩽t⩽n-1and0⩽y⩽m-1, while the arc connecting two adjacent nodesϕ(t-1)yandϕty′is denoted by a directed edgeψt,yy′with the associated costcyy′,t=-log(Mt(yy′|x)).2The weight of each edge corresponds to the exponential in Eq. (5).2The problem consists in minimizing the cost of visiting the nodesϕty′along the entire path:(11)argminy-∑t=0n-1log(Mt(y,y′)|x)=argmaxy∏t=0n-1log(Mt(y,y′)|x)The goal defined in Eq. (11), which corresponds to find the shortest path along the graphΩ, can be formulated as an integer linear programming problem that allow us to introduce additional background knowledge in terms of constraints. Letet,yy′denote a decision variable restricted to be 1 if the edgeψt,yy′is in the shortest path and 0 otherwise. The ILP formulation for the shortest path problem3The shortest path problem solution corresponds to the output of the Viterbi algorithm.3can be formalized as follows:(12)maxZ(e)=∑0⩽t⩽n-10⩽y,y′⩽m-1logMt(y,y′)·et,yy′(13)s.t.:∑0⩽y1⩽m-1et-1,y1y-∑0⩽y2⩽m-1et,yy2=0(14)∑0⩽y⩽m-1estart,0y=1and∑0⩽y⩽m-1eend,y0=1(15)estart,0y,et,y1y,eend,y0∈{0,1}(16)∀t,ys.t.0⩽i⩽n-1,0⩽y,y1,y2⩽m-1Any relationships that should be preserved over the output prediction could be smoothly represented as Boolean function and therefore introduced as linear inequalities constraints (Zuev, 1985). Nevertheless, this approach is based on two main assumptions: (1) constraints must be manually defined by a domain expert and (2) constraints must be satisfied, i.e. they are hard constraints. The implications arisen are concerned with the time consuming activity on defining boolean functions and the satisfiability of constraints with respect to training and testing data (otherwise possible infeasible solutions could be obtained). In order to overcome the mentioned weak points, a combination of learning constraints from data and a two-stages ILP approach is proposed.In this section we outline in detail the approach proposed in this paper. First we describe a general approach to extract from the available data additional knowledge in the form of logic rules. Then we describe how such knowledge can be embedded in a mathematical model as soft constraints, by relaxing the inference procedure and using a set of additional constraints whose violation is minimized in the objective function.In order to provide a completely automated Named Entity extraction process, with no need of human effort to define and include domain specific complex relationships, we defined a procedure for learning constraints from data. In a sequential labeling issue, the problem of finding out valuable knowledge can be viewed as a discovery process aimed at revealing common patterns within training data and a subsequent extraction of logical relationships from the identified patterns. The identification of some common patterns and their extraction from data in the form of logic rules is formulated, as originally proposed in Felici and Truemper (2002, 2005), as a sequence of minimum cost satisfiability problems. These problems are solved efficiently with an ad hoc algorithm based on the decomposition strategies presented in Truemper (2004). The method adopts a standard learning paradigm where the different tag labels are the classes and the logic rules that are found are able to separate the samples of one class from the samples of the other classes optimizing the information used to define the logic rules with the aim of controlling the performances of the system in a desired direction. The formulas so obtained are in disjunctive normal form (DNF), i.e. they are composed by the disjunction of one or more conjunctive clauses. A specific characteristic of this method is that these clauses have decreasing discrimination power and thus they can be pruned according to their power and to the importance that is given to the rules that explain the outliers that may be present in the training data. Moreover, each conjunctive clause can be easily associated with an integer linear constraints with standard techniques.Interesting logic relationship that are extracted from data may fall into one of the following categories:•Adjacency: if label A is associated to tokenxt, then label B must be associated to tokenxt+1(17)∑0⩽y1⩽m-1et-1,y1A-∑0⩽y2⩽m-1et,By2⩽0Precedence: if label A is associated to tokenxt, then label B should be associated to tokenxt+z(18)∑0⩽y1⩽m-1et-1,y1A-∑0⩽y2⩽m-10⩽z⩽n-tet+z,By2⩽0State Change: ifxtis a given delimiter punctuation mark (d), then label A and label B should be associated to tokenxt-1andxt+1respectively(19)∑0⩽y1⩽m-12(et-1,y1d)-∑0⩽y2⩽m-1et-2,y2A-∑0⩽y3⩽m-1et,By3⩽0Begin-End: if label A is associated to tokenx0, then label B should be associated to tokenxn-1(20)∑0⩽y1⩽m-1e1,Ay1-∑0⩽y2⩽m-1en-1,y2B⩽0Presence and Precedence: if label A appears, then label B cannot appear before label A(21)m(t-2)et,Ay1-∑1⩽z⩽t-20⩽y2⩽m-1(1-ez,y2B)⩽0with2⩽t⩽nand0⩽y1⩽m-1These rules are not necessarily satisfied by all training sentences and a fortiori by data during the inference phase. Therefore introducing these constraints could easily lead to feasibility problems. For this reason we enclosed in each linear equality constraint h a variableσh∈{0,1}, which will indicate when a given logical relationships could not be preserved over the output prediction. The constraints associated with the rules can thus be represented in a compact way with the notation:L·e-σ⩽0where L is a matrix composed of H rows containing the coefficients of the components of vector e for each of the H constraints, andσis the binary vector of size H representing the violation of the constraints.In order to introduce the automatically learned logical rules for constraining the inference phase without occurring in feasibility problems, a twofold approach is proposed. The first step is aimed at determining the optimal solution of the shortest path by solving the problem formulation presented in Eqs. (12)–(14), i.e. to determine the optimal solutionet,yy′∗equivalent to the one solved by Viterbi algorithm. Concerning the second step, we introduce a set of constraints in order to identify a labeling solution consistent with the logical rules previously extracted, while ensuring a good approximation first step Viterbi solution. In order to ensure feasibility we allow for a violation of this constraints, which however must be penalized. The second step, is therefore targeted at minimizing the cost of violating these of constraints, and is formulated as follows:(22)minZ(σ)=∑hchσh(23)s.t.:∑0⩽i⩽n-10⩽y,y′⩽m-1logMt(y,y′|x)·et,yy′⩾τZet,yy′∗(24)∑0⩽y1⩽m-1et-1,y1y-∑0⩽y2⩽m-1et,yy2=0(25)∑0⩽y⩽m-1e-1,0y=1and∑0⩽y⩽m-1en,y0=1(26)L·e-σ⩽0(27)e-1,0y,et,y1y,en,y0∈{0,1}(28)∀t,ys.t.0⩽t⩽n-1,0⩽y,y1,y2⩽m-1(29)σh∈{0,1},h=1,…,HThe objective function (22) is penalized whenever a logical relationship is violated, i.e. whenσh=1. Constraints (24)–(29) play the same role as in the shortest path problem, while constraint (23) states that the variablesetyy′should assume values to guarantee a solution close to the shortest path one. This lower bound ensures the current solution ofZ(σ), which originates a novel configuration ofet,yy′, to be coherent to the solution determined at the first step according to the threshold0⩽τ⩽1. The parameter vector c represents the cost of violating a given constraint. In particular, the elementchis proportional to the occurrence of a clause in the training data and represents the (log) probability that the corresponding constraint h is violated. Given a clause l representing the logical relationship among labels (for instance label A should appear before label B), the cost of violating all the constraints related to l is computed as follows:(30)cl=logP|D(l)||D(l)|+|D(l)|‾whereD(l)denotes the set of true clauses andD(l)‾represents the set of clauses that are not satisfied in training data.

@&#CONCLUSIONS@&#
