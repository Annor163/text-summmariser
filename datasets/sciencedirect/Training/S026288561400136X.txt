@&#MAIN-TITLE@&#
Half-sweep imaging for depth from defocus

@&#HIGHLIGHTS@&#
We propose a novel imaging approach, “Half-sweep imaging”, for depth from defocus.Novel PSF engineering by focus changes during each exposure time.Complementary responses of the PSFs help image restoration and depth estimation.Increasing the quantity of the incident light affects the quality of DFD estimation.We built the prototype camera and confirmed the effectiveness of our approach.

@&#KEYPHRASES@&#
Computational photography,Depth from defocus,Image deblurring,

@&#ABSTRACT@&#
Depth from defocus (DFD) is a technique that restores scene depth based on the amount of defocus blur in the images. DFD usually captures two differently focused images, one near-focused and the other far-focused, and calculates the size of the defocus blur in these images. However, DFD using a regular circular aperture is not sensitive to depth, since the point spread function (PSF) is symmetric and only the radius changes with the depth. In recent years, the coded aperture technique, which uses a special pattern for the aperture to engineer the PSF, has been used to improve the accuracy of DFD estimation. The technique is often used to restore an all-in-focus image and estimate depth in DFD applications. Use of a coded aperture has a disadvantage in terms of image deblurring, since deblurring requires a higher signal-to-noise ratio (SNR) of the captured images. The aperture attenuates incoming light in controlling the PSF and, as a result, decreases the input image SNR. In this paper, we propose a new computational imaging approach for DFD estimation using focus changes during image integration to engineer the PSF. We capture input images with a higher SNR since we can control the PSF with a wide aperture setting unlike with a coded aperture. We confirm the effectiveness of the method through experimental comparisons with conventional DFD and the coded aperture approach.

@&#INTRODUCTION@&#
There are many methods, referred to as depth from defocus (DFD) techniques [1,2], for estimating scene depth using a single camera. The methods use defocus blur (i.e., blurring that depends on the scene depth) present in the captured images. DFD usually employs a pair of images, one near-focused and the other far-focused, to determine differences in the size of defocus blur resulting from depth differences in the scene. However, the circular shape of the aperture of a regular camera is not beneficial for DFD estimation, since the blurred pattern is not unique for different depths. For more robust DFD estimation, many researchers have investigated coded aperture techniques [3–6], which use special patterns for the camera aperture to control the shape of the point spread function (PSF). Additionally, it is well known that the shape of the PSF directly affects the frequency response of an imaging system, which is described by the optical transfer function in the field of optics. We can select aperture patterns that drastically change the PSF shape in the image domain or its frequency response in the Fourier domain according to scale changes in the PSF due to object depth differences, thereby achieving more accurate DFD estimation in discriminating scene depths. However, the use of a coded aperture attenuates the intensity of captured images, since incident light from the scene is blocked in engineering the PSFs. The attenuation decreases the signal-to-noise ratio (SNR) of the images and limits improvement in DFD estimation.On the other hand, wavefront coding [7] and a lattice focus lens [8] have been proposed so that incident light is not attenuated. In these cases, special optical elements, called phase plates or lattice lenses, are inserted at the position of the camera aperture to alter the PSFs. Although these methods have an advantage in terms of the image SNR over using a coded aperture, they require specially crafted and expensive optical elements. They are not adaptive to captured scene depths or contexts, since the property of the PSF is fixed and must be predefined before using the camera. It is also difficult to achieve compatibility with regular imaging using a normal circular aperture.In this paper, we propose a new imaging operation, called half-sweep imaging, for DFD estimation. DFD sometimes ignores the quality of the restored image. We focus on achieving high quality all-in-focus image restoration as well as robust DFD estimation in order to consider visualization of computational photography. The technique, inspired by focus sweeping [9,10], is extended to DFD applications. Half-sweep imaging obtains two images by sweeping the focus during the image exposure time. It has the advantage of a higher SNR for captured images, since we can engineer the image PSFs even if the camera aperture is open. The operation requires continuous changing of the lens focus or sweeping of an image sensor, which is easy to implement since we can utilize the auto-focusing mechanism or an actuator for image stabilization, which current commercial cameras already possess. Moreover, the method is completely compatible with regular imaging and adaptive to scene depth when we stop the sweeping motion or freely adjust the sweeping length and position. Employing the proposed method, we integrate multiple PSFs with different focus settings obtained by focal sweeping to control the frequency responses of imaging PSFs. We split a sweep into half regions to capture images. Thus, two images are obtained for the same scene, but with different PSFs (i.e., transfer functions of imaging). As a result, one of the PSFs and captured images has zero-crossings in its frequency response, which help with depth estimation, while the sum of the PSFs has a broadband spectrum, which allows restoration of a better all-in-focus image. This paper is an extended version of the paper [11], which appeared in PSIVT2011.

@&#CONCLUSIONS@&#
