@&#MAIN-TITLE@&#
Real user evaluation of a POMDP spoken dialogue system using automatic belief compression

@&#HIGHLIGHTS@&#
Application of E-PCA for automatic belief compression in a spoken dialogue system.First real user evaluation comparing manual and automatic belief compression.Promising results, keeping in mind the advantage of advanced design automation.Crowdsourced evaluation of spoken dialogue systems using CrowdFlower.

@&#KEYPHRASES@&#
Spoken dialogue systems,Dialogue management,Belief compression,

@&#ABSTRACT@&#
This article describes an evaluation of a POMDP-based spoken dialogue system (SDS), using crowdsourced calls with real users. The evaluation compares a “Hidden Information State” POMDP system which uses a hand-crafted compression of the belief space, with the same system instead using an automatically computed belief space compression. Automatically computed compressions are a way of introducing automation into the design process of statistical SDSs and promise a principled way of reducing the size of the very large belief spaces which often make POMDP approaches intractable. This is the first empirical comparison of manual and automatic approaches on a problem of realistic scale (restaurant, pub and coffee shop domain) with real users. The evaluation took 2193 calls from 85 users. After filtering for minimal user participation the two systems were compared on more than 1000 calls.

@&#INTRODUCTION@&#
One of the main problems for a spoken dialogue system (SDS) is to determine the user's goal (e.g. plan suitable meeting times or find a good Indian restaurant nearby) under uncertainty, and thereby to compute the optimal next system dialogue action (e.g. offer a restaurant, ask for clarification). Recent research in statistical SDSs has successfully addressed aspects of these problems through the application of Partially Observable Markov Decision Process (POMDP) approaches (Thomson and Young, 2010; Young et al., 2010). In these approaches, system responses are computed on the basis of a distribution over possible user goals, called the belief space, rather than the most likely user goal. However, in order to keep belief state monitoring and action selection tractable, various techniques are used to reduce the size of the space. For learning action selection policies in particular, current systems rely on system designers hand-selecting a sub-set of the features of the belief space and action set.This paper proposes the use of automatic belief compression (ABC) techniques in POMDP dialogue systems. Automatic belief space compression is attractive in that it reduces the knowledge required when constructing statistical SDSs and allows for greater automation of the design process (see Section 7.1). The aim of this paper is to demonstrate that automatic belief compression is competitive from an end user viewpoint, without which the potential reduction in design effort is of little value. To evaluate this a comparison is made between an existing state-of-the-art POMDP SDS that uses a hand-coded belief space compression, and a variant that uses an automatically compressed belief space. The evaluation is done both in simulation and with a real users.The compressed belief space used for dialogue management in the variant system was generated by applying Exponential Family Principal Components Analysis (E-PCA) (Roy and Gordon, 2002; Roy et al., 2005) to the belief space to automatically select a reduced set of summarising features. However, where Roy and Gordon (2002), Roy et al. (2005) require knowledge of the original POMDP model in order to train a policy in the compressed belief space we use reinforcement learning (RL) to avoid having to know the precise POMDP transition and observation probabilities, since approximations required in scaling up state-of-the-art statistical SDS models mean that they are not directly available.The main contribution of this work is that it is the first empirical comparison of manual and automatic approaches to SDS belief state compression on a problem of realistic scale (restaurant, pub and coffee shop domain) and with real users. In addition, to the best of our knowledge, this is the first work to demonstrate the feasibility of using E-PCA as a feature selection procedure in RL scenarios, which also strengthens the potential of E-PCA belief compression in practical applications (see Section 2.2 for a more expanded discussion).POMDPs are Markov Decision Processes where the system's state is only partially observable, i.e. there is uncertainty as to what the true state is. The ability to account for uncertainty is crucial for SDSs because their knowledge about the state is uncertain due to speech recognition errors and the fact that the user's goals are not directly observable. In POMDP models of spoken dialogue (Williams and Young, 2005; Thomson and Young, 2010; Young et al., 2010) the dialogue policy (what the system should say next) is based not on a single view of the current state of the conversation, but on a probability distribution over all possible states of the conversation (this is denoted as the system's belief b). The optimal POMDP SDS dialogue act thus automatically takes account of the uncertainty about the user's utterances and goals.Formally, a POMDP is defined as a tuple〈S,A,O,T,Ω,R〉where S is the set of states that the environment can be in, A is the set of actions that the system can take, O is the set of observations which it can receive, T is a set of conditional transition probabilities which describe the likelihood of transitioning between states given a selected action (i.e. P(s′∣s, a), where s, s′∈S and a∈A), Ω is a set of conditional observation probabilities which describe the likelihood of each observation occurring (e.g. P(o′∣s′, a), where o′∈O), andRis the reward function (R:A,S→ℝ).For a SDS dialogue manager (DM) we say that the user's utterance after it has been rendered into the form of a semantic act (or the list of semantic acts11In the case of a system that considers N-best lists of ASR output.) is the observation o which the POMDP receives. We assume that the dialogue has a discrete number of states which it can be in and these are represented by the set of POMDP states S. Finally the DM action is equated to the POMDP act a. Now given a set of transition matrices, observations vectors, and an initial belief b0 the POMDP DM can monitor and update its belief b over the possible states of the dialogue.Even considering limited domains, POMDP state spaces grow very quickly. For example the domain ontology used by the Hidden Information State (HIS) (Young et al., 2010) dialogue systems evaluated in this paper contains three types of entities (restaurant, pub and coffee shop) and both the entity type and between four and six further attributes (depending on the entity type) are searchable by the user, e.g. restaurant has the attributes cuisine, city area, near a landmark, price range, whereas pub has attributes children allowed, has Internet, has TV, city area, near a landmark, price range. There are 28 cuisines, 15 city areas, 52 landmarks, and 4 price ranges, and the remaining searchable attributes are Boolean. Even without considering negation of attribute values or that an attribute can reference a conjunction or disjunction of values (Gašić and Young, 2011) the user goal space can represent 87,360 states.22Allowing disjunctions and negation increases this user goal space to around 2100.The dialogue hypothesis space is larger again as in addition to the user goal various attributes which summarise the dialogue state are also tracked, e.g. whether a hypothesised user goal is confirmed, not confirmed, or rejected, and has been mentioned by the user, system or both, etc. Focusing only on the user goal space a POMDP belief is a probability distribution over these possible states, i.e. a 87,360 dimensional real valued (ℝ) space.In order to render such large belief spaces tractable, the current state of the art in POMDP SDS uses a variety of handcrafted compression techniques, such as making several types of independence assumption. For example, a dialogue system designer might decide that users are only ever interested in one type of food or one location, and that their interests in food type, price range, quality, etc. are independent.33These are not the assumptions used in the HIS systemThe real valued user goal space distribution can then be reduced to a much smaller “summary space” (Williams and Young, 2005) consisting of around100×ℝvalues.44By considering only the maximum marginal likelihood for each of the user goal attributes.However such assumptions limit the expressiveness of the user goal space and thus what the dialogue manager can infer. This can have a detrimental effect on the quality of the dialogues and hence the user experience.The tight coupling between some dialogue states and actions (e.g. a user's goal state travel-from-London and system act confirm-from-London) has led some researchers to conclude that compression techniques, such as state aggregation, are not useful in the dialogue domain (Williams and Young, 2007). However, such tight coupling may not exist for all states, indeed Value Directed Compression (VDC) has already been applied to a small spoken dialogue system problem (Poupart, 2005) where it was shown that compressions could be found; losslessly compressing a test problem of 433 states to 31 basis functions.The current state-of-the-art in POMDP SDSs uses a variety of handcrafted compression techniques, such as making several types of independence assumption as discussed above.Poupart (2005) and Crook and Lemon (2010) propose replacing handcrafted compressions with automatic compression techniques. The idea is to use principled statistical methods for automatically reducing the dimensionality of belief spaces, but which preserve useful distributions from the full space, and thus can more accurately represent real users’ goals.A POMDP is defined as a tuple〈S,A,O,T,Ω,R〉, see Section 1.1. Uncertainty in the current dialogue state is expressed as a distribution b that is maintained over the states s∈S. Automatic belief compression consists of finding a some mapping fromb→b˜whereb˜is expressed using a smaller number of bases (U) than used by b, i.e. |U|<|S|.One approach to automatic belief compression is to use knowledge of the tuple〈S,A,O,T,Ω,R〉in order to determine an appropriate mapping. This is what the VDC algorithm (Poupart, 2005) does. Roughly speaking it uses knowledge of the transition and observation probabilities, T and Ω, to compute projections of the rewardsRinto the future and discover a minimum set of bases which preserve the value function (the discounted future reward of state-action pairs). The mapping to this minimum set of bases can be used to compress b and theoretically guarantee55Unfortunately numerical stability issues which occur when the VDC algorithm is implemented on a digital computer mean that this guarantee is difficult to realise in practice, see (Wang et al., 2013).that an optimal policy can be represented.For HIS this approach is not easily applied as the state transition probabilities T and observation probabilities Ω are not available ahead of runtime. This is due to the approximations adopted in the HIS framework to keep the framework tractable, e.g. the mixing of bi-gram and rule-based models in computing transition likelihoods or the approximation of the observation likelihood as the series of N-best confidence scores produced at runtime by the ASR-SLU pipeline (Young et al., 2010).A sample-based approach to determining theb→b˜mapping is thus more appropriate for HIS and one of the most popular and successful forms of dimensionality reduction given sampled data is principal components analysis (Roy and Gordon, 2002; Roy et al., 2005). Given that the sampled HIS belief space is unlikely to lie on a linear manifold we use the Exponential Family of PCA to compute the belief space mapping.Conventional principal components analysis assumes a linear transformation between some original data X and the projection of that data V in the reduced dimensional space. The assumption that X lies on a lower dimensional linear manifold is not always valid and Exponential Family PCA adds a link function f which performs a non-linear projection of the linear mapping of basis vectors U with V (Roy and Gordon, 2002; Roy et al., 2005), i.e.(1)Xˆ=f(UV)whereXˆis the recovered approximation of the original data X.In this application our original data X is a collection of column vectors bi, where each birepresents an uncompressed POMDP belief state. If X≡B=[b1b2b3 ⋯ bK], where K is the number of sampled belief states, then(2)Bˆ=f(UB˜)=exp(UB˜)whereB˜=[b˜1b˜2b˜3…b˜K]are the compressed belief states andBˆis the recovered approximation of B, i.e.Bˆ≈B. Since beliefs are probability distributions, the exponential link function shown in Eq. (2) appears the most appropriate choice (as per Roy and Gordon, 2002; Roy et al., 2005), which corresponds to a Poisson error model for each component of the reconstructed belief. In addition, if the E-PCA parameters U andB˜are obtained by maximising the log-likelihood of the data with respect to the exponential link function, it is equivalent to minimising the unnormalised Kullback-Leibler (KL) divergence between the original beliefs B and their reconstructionsBˆ. Once the matrix U has been computed for a given sample B then new compressed beliefs can be found by solving Eq. (3) for each new vector b.(3)b˜=argminb˜′UKL(b∥f(Ub˜′))=argminb˜′(∑eUb˜′−b·Ub˜′+b·lnb−∑b)=argminb˜′(∑eUb˜′−b·Ub˜′)where UKL is the unnormalised KL divergence and the summations are over the elements of the vectorseUb˜′and b (and for the purposes of minimising this function any terms not involvingb˜′can be ignored).

@&#CONCLUSIONS@&#
