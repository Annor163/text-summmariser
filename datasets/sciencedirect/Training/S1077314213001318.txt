@&#MAIN-TITLE@&#
Elastic shapes models for improving segmentation of object boundaries in synthetic aperture sonar images

@&#HIGHLIGHTS@&#
SAS imagery exhibits high levels of background noise and ambiguous target boundaries.Segmentation algorithms without prior shape knowledge typically fail.We model shapes as elements of a Riemannian manifold with an elastic metric.Such elastic shape models serve as shape priors in a Bayesian active contour model.We show improvement in boundary segmentation with shape prior versus without prior.

@&#KEYPHRASES@&#
Riemannian geometry,Shape analysis,Bayesian active contours,Synthetic aperture sonar,

@&#ABSTRACT@&#
We present a variational framework for naturally incorporating prior shape knowledge in guidance of active contours for boundary extraction in images. This framework is especially suitable for images collected outside the visible spectrum, where boundary estimation is difficult due to low contrast, low resolution, and presence of noise and clutter. Accordingly, we illustrate this approach using the segmentation of various objects in synthetic aperture sonar (SAS) images of underwater terrains. We use elastic shape analysis of planar curves in which the shapes are considered as elements of a quotient space of an infinite dimensional, non-linear Riemannian manifold. Using geodesic paths under the elastic Riemannian metric, one computes sample mean and covariances of training shapes in each classes and derives statistical models for capturing class-specific shape variability. These models are then used as shape priors in a variational setting to solve for Bayesian estimation of desired contours as follows. In traditional active contour models curves are driven towards minimum of an energy composed of image and smoothing terms. We introduce an additional shape term based on shape models of relevant shape classes. The minimization of this total energy, using iterated gradient-based updates of curves, leads to an improved segmentation of object boundaries. This is demonstrated using a number of shape classes in two large SAS image datasets.

@&#INTRODUCTION@&#
An object of interest in an image can be characterized to some extent by the shape of its external boundary. It is therefore important to develop procedures for boundary extraction in problems of detection, tracking, and classification of objects in images. Certain methods for extraction make use of only the image data itself to define target boundaries while others additionally assume the availability of prior knowledge about the shape of the target to be segmented. A large body of research exists on the former approach (see for example [1,2] and papers that followed) whereas the latter is relatively less explored, with a few exceptions [3–5]. As segmentation algorithms become more sophisticated, they are tested in more difficult imaging environments of real-world scenarios where images do not have enough contrast to provide crisp, clear boundaries. One example of this scenario is when images are collected in a spectrum outside the visible domain. Here, images are typically of low contrast and contain excessive clutter, causing standard boundary extraction algorithms to fail. For instance, Fig. 8 shows some examples of synthetic aperture sonar (SAS) images that are difficult to segment automatically. Thus, it is of increasing importance that boundary extraction algorithms make use of prior knowledge about expected targets in order to help compensate for the bad data quality. Our goal is to present a method for representing, modeling, and incorporating prior information about shapes of closed curves in a boundary extraction algorithm and demonstrate its effectiveness in imaging scenarios outside the visual spectrum. We clarify that our goal is not to develop a general purpose image segmentation algorithm, but to use the contextual knowledge to determine expected object shapes and to use this information in boundary extraction. Here, one must provide prior knowledge in the form of training shapes that are representative of the target boundary desired to be segmented.One particular example of interest to us is boundary extraction in synthetic aperture sonar (SAS) imagery in military undersea reconnaissance, although our procedure can be applied to a wide variety of applications such as medical diagnosis and infrared surveillance. The task of automatically extracting object contours in SAS imagery is challenging due to the following reasons.1.These images are typically low contrast due to a low signal-to-noise ratio (SNR), i.e. the background and target can be quite similar in intensity levels and boundaries are not clear. (By SNR we mean the ratio of average target pixel intensity to average background pixel intensity.)The SAS imagery used here comes from a side scan sonar, where an autonomous underwater vehicle travels in a straight line and sends out a series of sound chirps from its side. Since one target side faces away from the sonar, the target is partially occluded in sound shadow, which introduces missing boundaries and causes the shape of a highlighted target to vary widely with its aspect angle.The resolution of sonar images is often much lower than those obtained in the visible spectrum, resulting in relatively fewer pixels on targets.Underwater imaging environments normally contain high speckle clutter due to rough seabed backgrounds.These factors make it difficult to perform boundary extractions on SAS imagery using standard active contour and other boundary segmentation methods, and methods that can incorporate additional information are required. We will utilize manually-extracted boundaries of different known classes of sea-floor targets imaged via SAS as prior knowledge to the algorithm.The term active contour, or snake, refers to a dynamic curve that evolves to capture desired features in an image domain. There are two broad categories of active contour methods: parametric and geometric, each with their own set of advantages and drawbacks. Parametric active contours are explicitly defined parameterized curves, and the forces that drive the snake evolution are applied to the curve directly; whereas, geometric active contours are implicitly defined as zero level sets of higher-dimensional functions across the entire image domain. Here, we provide a brief survey of past and present work in these two areas.Many of the past and current parametric snake models are based on the ideas presented in the seminal paper of Kass et al. [6]. They define an energy function comprised of two parts, external and internal energy, whereby an explicitly parameterized snake evolves towards local minima corresponding to desirable solutions (edges, boundaries, etc.). The external energy is made from the pixel intensity values across the image domain, and the internal energy is designed as a regularization term that applies a smoothing force to maintain continuity of the curve itself. In order to allow for a more general initialization, Cohen and Cohen in [7] introduce an internal balloon force derived from the finite element method that instead of drawing a snake inward towards a boundary edge, it inflates the snake outward. Xu and Prince in [8] introduce a new type of external force called Gradient Vector Flow (GVF), which is not based on the negative gradient of an energy function, but rather it diffuses the vectors from the Gaussian smoothed image gradient by solving a pair of decoupled linear PDE’s. Li et al. [9] propose an Edge Preserving GVF (EPGVF) that maintains the benefits of GVF while improving the ability to detect weak edges. It also allows for topological change in a parametric active contour setting, a quality that arises much more naturally in geometric models.A geometric active contour is described by a curve evolution equation that does not depend on the explicit parametrization of the contour but rather on the intrinsic geometric properties or quantities of the contour, such as curvature and normal vector, that are independent of parametrization. Most geometric active contour methods stem from the ideas presented in Osher and Sethian’s work on front propagation with curvature-dependent speed [10]. They represent a front, or an interface, as the zero level set of a higher-dimensional signed distance function called the level-set function. The front is evolved according to hyperbolic conservation laws acting on the level set function itself, where the velocity field is defined by its curvature (geometric term) as well as possible external flows (advection term). A desirable property of this method is that it can naturally handle topological change, i.e. splitting and merging, of the evolving front with no additional effort. Malladi et al. [2] and Caselles et al. [11] independently applied Osher and Sethian’s ideas to the problem of boundary extraction in images in order to make use of topological change in the segmentation of not just one but potentially many object boundaries. In addition to any curvature smoothing term, Malladi et al. define a speed function based on image data to be applied to the propagating front, which provides a halting criterion at potential boundaries. Caselles et al. use a similar approach but consider the advection term to drive active contours towards minimal distance curves or geodesics in a Riemannian space derived from the image, a popular method called “geodesic active contours.” Kichenassamy et al. [12] modify slightly the work defined in [2,11] by deriving their model from basic differential geometric principles. Common to all geometric active contour models is the notion of evolution according to Euclidean curve shortening, which defines the gradient direction in which the Euclidean perimeter shrinks the fastest. This velocity vector is determined by the geometric heat equation and is equivalent to the inward normal direction scaled by the signed curvature [13,14]. Such an evolution is a very desirable component of a snake model because it simultaneously shrinks the curve and smooths it without inducing any cross-overs. Li et al. [15] also describe a level set approach for image segmentation.In many applications the image information alone is seldom enough to drive the contour towards the desired target boundary, and it is necessary to incorporate prior knowledge about the type of shape. Sonar imagery is a good example of a scenario where without an energy term to help guide the snake to a set of high probability prior shapes, background clutter, occlusion, and overall inhomogeneity of the target intensity can give rise to false segmentation results. For this reason, many current methods employ a Bayesian framework to apply a shape prior, an energy term based on the statistics of a set of training shapes, to the active contour model. The nature of the shape prior depends on the type of active contour model in use, parametric or geometric. In a parametric model, the shape prior is a statistical model on closed or open contours inR2; whereas, in a geometric model, the shape prior is a statistical model on level-set functions, i.e. surfaces, inR3or higher.Past Bayesian methods have been applied almost exclusively to geometric models where most efforts follow the ideas presented in Leventon et al. [16]. Here, a set of signed distance functions are obtained from previously known training shapes, and an arithmetic mean is computed. PCA is then performed inL2space to create a multivariate Gaussian distribution on the subspace defined by the top n principal components. Fang and Chan in [17] incorporate such a Gaussian density for use as a shape prior in a geodesic active contour framework based on [11]. Cremers et al. in [3] and Rousson and Cremers in [18] improve on [16] by applying a kernel density estimation technique to model general distributions of level-set functions beyond that of just Gaussian. They modify the Mumford–Shah based segmentation in [1] to include the shape prior term from this density estimation. Kim et al. in [4] also estimate densities of level-set functions nonparametrically inL2space.One major limitation of these approaches is that the shape theory used here to develop priors is not as powerful as the state-of-the-art methods. The latest methods utilize the differential geometry of shape spaces and develop efficient algorithms for computing statistical modes of variations in training shapes. For example, [19] makes use of “landmark-based” shape analysis [20] to impose a shape prior. While this method involves proper shape spaces and geodesic distances, it is not ideally suited to active contours since it was developed primarily for landmarks denoting salient points on a shape. For this reason it cannot handle the shape analysis of full contours in generality. There has been a recent push to exploit the shape space of closed, planar curves represented as continuous, parameterized functions using ideas from differential geometry [21–24]. To complement this work, there has also been substantial research efforts dedicated to developing techniques to calculate intrinsic shape statistics on such manifolds [25]. Joshi and Srivastava [5] use ideas from elastic shape analysis of closed, planar curves to create a shape prior from an intrinsic density on shape space to help evolve a curve in a parametric active contour model. Although the method presented in [5] incorporates robust intrinsic shape statistics, it uses EPGVF [9] to calculate its image energy term, which does not perform well in images with ambiguous target boundaries, high speckle noise, and low SNR as in SAS imagery. Additionally, the shape representation used in [5], taken from [22], results in a computationally expensive algorithm, and simplifications for elastic shape analysis provided in [23] (explained later) promise a much cheaper solution.The main contribution of this research is to apply the latest technique in shape analysis of contours, termed elastic shape analysis, in developing the shape prior in an active contour framework, and investigate its use in extraction of shapes in SAS images. The problem of boundary extraction in the context of this model can be posed as a maximum a posteriori (MAP) estimation via the energy minimization(1)βˆ=argminβ∈BEimage(β)+Esmooth(β)+Eprior(β),where the minimization is over a setBof appropriately chosen curves. The termsEimageandEsmoothare common energy terms based on given image pixel data and the smoothness of the evolving boundary curve, respectively, while the termEprioris the novel term representing the shape prior energy. Due to the nature of the background noise in SAS imagery, common gradient vector field techniques to formEimage, such as EPGVF, typically fail to produce good results, even with the addition ofEprior. Therefore, we design a model that makes use of not only prior shape information but also prior image information; that is,Eimageis formed based on prior knowledge of typical target and background pixel intensities. We use the well-known idea of “region competition” presented in [26] in our parametric framework to ensure a more robust performance in a noisy imaging environment.This general formulation is inspired by Joshi and Srivastava in [5], where the authors define a prior shape density on a manifold of closed curves. This explicit shape model allows for greater accuracy in capturing appropriate variation within a shape class compared to previously implemented level-set methods. The functional representation of curves automatically removes the desired shape invariants of scale and translation while the remaining invariants are removed by forming a quotient space of the manifold modulo their group actions. Shapes are analyzed as members of this quotient space of closed curves rather than as entire level-set functions, thus facilitating a conceptually simple and natural way of comparing shapes invariant to all similarity transforms. These shape comparisons are made by imposing an elastic Riemannian metric [27,28,22,29] on the quotient space to allow for natural bending and stretching of shapes in the formation of minimum length geodesic paths. The main difference between our formulation ofEpriorand that of [5] is in the functional representation of shape; the current representation greatly simplifies the cost of elastic shape analysis and drastically improves shape modeling. In fact, it allows for a ten-fold increase in the computational speed for evaluating shape models.To summarize, the main advantages of our Bayesian active contour model are1.The use of prior shape and prior intensity information to drive the contour to a target boundary in noisy imaging environments.A shape analysis framework that studies curves directly as continuous, parameterized functions rather than as higher-dimensional level-set functions or a series of finite, expertly selected landmarks.An attractive elastic metric to compare shapes under an appropriate combination of bending and stretching. This metric is invariant to all the shape-preserving transforms: rotation, scale, and translation, as well as re-parameterization.The use of a formal statistical prior on shape space of planar, closed curves, learned from the given training shapes.The computation of gradients of energy terms as vector fields on the current curves for efficient updates.The main limitations of this framework are as follows. First, it does not allow for topological change of the evolving contour. In our particular application, we are only concerned with segmenting one target consisting of one closed boundary curve, so we do not consider the splitting and merging of closed curves in our model design. Second, it is application specific, in that it does not provide a method for boundary extraction in a general image. One must have a preconceived notion of the set of potential classes to which the target of interest may belong in order to make use of our Bayesian framework.The remainder of the paper is organized as follows. Section 2 provides an overview of elastic shape analysis of planar contours, including the basic mathematical framework and methods of computing intrinsic shape statistics on the space of closed curves. Section 3 outlines our active contour model, describing each of the three energy terms in Eq. (1) and explaining how to obtain the MAP estimationβˆ. Section 4 shows experimental results on SAS imagery from two databases. Section 5 is the conclusion and description of future work.In this section we briefly summarize a Riemannian framework for elastic shape analysis and modeling of closed planar curves. This framework results in metrics, statistics, and models that are invariant to arbitrary rotation, scaling, translation, and re-parameterization of individual curves. For more detailed information, refer to [23]. The most important advantage of this framework is that it performs simultaneous registration (of points across curves) and comparisons of the shapes of curves. This has the effect of stretching/compressing and bending parts of curves to match each other as well as they can. Consequently, the resulting shape models are more compact and parsimonious as compared to models obtained without registration.Consider absolutely continuous, parameterized curves of the typeβ:S1→Rn. We will use‖β‖to denote theL2norm‖β‖=∫S1|β(t)|2dt, and where|·|is the Euclidean norm inRn. Let the set of all re-parameterizations be the set of all re-parameterizations ofS1:(2)Γ=γ:S1→S1|γis an orientation-preserving diffeomorphism.A re-parameterization of the curveβis given by the composition(β∘γ)(t)=β(γ(t)), whereγ∈Γ. Since, for any two curvesβ1andβ2, theL2norm of their difference changes with the parameterizations, i.e.‖β1-β2‖≠‖β1∘γ-β2∘γ‖, one cannot use this difference as a metric to compare shapes of curves. Instead, the curves are represented by their square-root velocity function (SRVF) given byq(t)=β̇(t)/|β̇(t)|. The SRVF of a reparametrized curveβ∘γis given by(q,γ)≡(q∘γ)γ̇. Given an SRVF q, one can recover the curveβup to a translation usingβ(t)=∫0tq(s)|q(s)|ds. In Joshi and Srivastava in [5], a curve is represented by a pair of functions that represent the norm and the direction of the vectorβ̇(t), respectively, as functions of time.As described in [23], there are several reasons for selecting the SRVF representation for analyzing the shape of a curve. First, with respect to theL2metric, it can be shown that‖q1-q2‖=‖(q1,γ)-(q2,γ)‖for allγ∈Γ. This property allows us to compute distances not between individual curves but between different re-parameterizations of curves. Second, since|q(t)|2=|β̇(t)|, theL2-norm of any q-function is the length of its corresponding curveβ. Thus,L2norm of SRVF’s of unit-length curves is one and the space of such curves is a convenient unit sphere! Lastly, an important elastic Riemannian metric – a metric that measures a combination of stretching and bending to optimally deform one curve into another – becomes the standardL2metric under the change of variable fromβto q. This interpretation allows us to obtain at least a 10-fold increase over previous methods that use the elastic metric but not SRVF representation, e.g. Joshi and Srivastava in [5]. Since we are concerned with extracting the closed boundary of an object in an image, we consider the corresponding closure condition on SRVF’s. It can be shown that if the curveβis closed, then∫01q(t)|q(t)|dt=0. In summary, the subset of all SRVF’s denoting unit-length closed curves is given by:(3)C=q∈L2(S1,R2)|∫S1|q(t)|2dt=1,∫S1q(t)|q(t)|dt=0.This subset is shown to be a submanifold ofL2and inherits a standardL2metric to make it a Riemannian manifold. We denote the Riemannian manifoldCas preshape space of unit length, closed curves.The main tool in comparing curves in this framework is to use the geodesic distance between them inCas a measure of their difference. This requires computation for geodesics inCunder the chosen metric (L2). Since the geometry ofCis not straightforward – it is a complicated submanifold of a unit sphere – one uses a numerical technique for computing geodesics inC. One such numerical technique is called path straightening. It initializes an arbitrary path between any two points inCand iteratively straightens it until the path becomes a geodesic, i.e. locally the shortest path. This ideas was introduced in [30] but particularized toCin [23]. Letq1,q2∈Cdenote SRVF’s associated with two unit-length, closed curves, and letαbe the geodesic between them found using the path straightening algorithm. The length of this pathα, denoted byd(q1,q2), provides a formal distance – geodesic distance – between elements ofC.The actions of translation and scaling groups are already removed in this representation, but the rotation and re-parameterization variability are yet to be removed. In other words, any two curves that differ in only the rotation and re-parameterization have different SRVF’s but the same shapes. We need to unify all the elements ofCthat represent the same shape. This is done using the algebraic operation of forming orbits – all possible rotations and re-parameterizations of a curve form a set called an orbit of that curve, and membership of an orbit defines an equivalence class. For a curveβwith the SRVF q, its orbit is given by:[q]=closureO(q,γ)|q∈C,O∈SO(n),γ∈Γ. The original orbits are not closed sets, and, for a technical reason, they are fixed to be closed by taking the closure of the original sets. The set of all such orbits is called the shape space, denoted byS={[q]|q∈C}. Elements of the shape space are compared using the shortest geodesic distance between the elements of the corresponding orbits. That is, the shape distance is defined to be:(4)ds([q1],[q2])=minγ∈Γ,O∈SO(2)d(q1,O(q2,γ)).In this computation, one fixes the first curve and searches over all possible rotations and re-parameterizations of the second curve so that the geodesic distance between them is minimized. Since each orbit represents a shape uniquely,dsis a proper shape metric for analysis and modeling of shapes.This framework also helps us evaluate two quantities that are important in statistical analysis. First, given any two shapes,[q1]and[q2], this framework can help compute the starting or shooting direction v such that a geodesic from[q1]with the initial velocity v reaches[q2]in unit time. Notationally, this is written asv=exp[q1]-1([q2]), the inverse exponential map. Second, it computes the final resting point of the geodesic that starts at some arbitrary point[q]and has an arbitrary initial velocity as v. Notationally, this is denoted byexp[q](v), the exponential map.Given a set of n shapesQ={qi}i=1,…,n, where each[qi]∈S, we wish to find the mean and covariance of the setQ. Together, these two statistics fully define a Gaussian-type distribution that approximates a model from whichQcan be assumed to be observed. These distributions are approximate sinceSis an infinite-dimensional space and one, in practice, imposes density on a certain subset ofS. The ability to define densities of shapes onS, even approximately, is an important tool that allows us to perform hypothesis tests, create stochastic models, and create prior shape densities for our Bayesian active contour model. Since the data lie on a non-linear Riemannian manifold rather than in a standard vector space, the notions of addition and subtraction are void. Thus, one must define new intrinsic ways of obtaining statistics aside from the typical sample (arithmetic) mean and sample covariance calculations.A popular intrinsic mean calculation is the “Karcher mean.” In general, for the setQonS, the Karcher meanμis defined as the point that minimizes the sum of square geodesic distances between all points in the set. That is,(5)μ=argmin[q]∈S∑i=1nds([q],[qi])2,wheredsis the geodesic distance in the shape space. An iterative algorithm to find the Karcher mean of a set of shapes is outlined below. The general idea is to update the current estimateμjin the direction of the average shooting vector fromμjto each of the shapes inQ.Algorithm 1Karcher MeanLetμ0∈Sbe an initial estimate of the mean of the shape classQ. A typical selection is to letμ0=[q1]. Setj=0.1.For eachi=1,…,n, solve for the shooting vectorvi=expμj-1([qi]).Compute the average directionv¯=1n∑i=1nvi.If‖v¯‖is small, stop. Else, updateμjin the directionv¯usingμj+1=expμj(∊v¯)where∊>0is small, typically 0.1.Setj=j+1and return to step (i).Fig. 1shows two examples of mean shapes for two shape classes taken from our SAS application. The example on the left side shows target shapes of 20 imaged cylinders and their mean, while the example on the right shows the target shapes of 20 imaged boxes and their mean.Once we have found a Karcher meanμfor the set of shapesQ, we obtain the Karcher covariance matrix via(6)K=1n-1∑i=1nviviT,where thevi’s are shooting vectors fromμto the respective[qi]’s inQ. While in theoryv:[0,1]→R2is a vector valued function, in practice it is computed using T equally spaced samples on the interval[0,1]. Therefore,v∈R2×Tor re-arranged to beR1×2Tand K is a2T×2Tcovariance matrix.Algorithm 2Karcher CovarianceGiven a set of shapesQand its Karcher meanμ.1.Fori=1,…,n, calculate the shooting vectorvi=expμ-1([qi]).Compute the Karcher covariance matrix K as in Eq. (6) with the shooting vectorsvi.Define a “shape class” to be the set of shapesQalong with its Karcher meanμand its covariance K, and henceforth, we use the notation(Q,μ,K)to refer to a shape class.There are many densities one can define onSwith the shape class(Q,μ,K), but for this research we only consider a “truncated wrapped-normal density” [31]. A wrapped-normal density in this case is a multivariate Gaussian density defined on the tangent space of the mean, which is then mapped to the manifold via the exponential mapping. Since the range space of this mapping is a subset of a unit sphere, one needs to truncate the Gaussian density in the tangent space so that the exponential map is a bijection. We choose to define a Gaussian density on the tangent space because it is simple to implement, and it has an analytic formula that we can use in future applications such as likelihood ratio tests and defining a shape prior energy in our active contour model. SinceSis an infinite dimensional space, in practice we define a multivariate Gaussian on a finite, m-dimensional subspace of a tangent space ofSby selecting the m dominant principal components of K (corresponding to the largest m singular values{σi2}i=1,…,mof K). We refer to this subspace as the m-dimensional principal subspace ofTμ(S). The truncation allows us to have a invertible mapping from this subspace to the shape spaceS. In practice we truncate the subspace by restricting to a disk of sizeπaround the origin in that subspace.After obtaining the m dominant principal components of K, we can visualize shapes inSthat are up to two standard deviations on either side of the mean in the kth principal direction of varianceuk; that is, we can visualize an analogy of the confidence intervalμ±2σkukon the shape spaceSaccording to the wrapped-normal density. Fig. 2shows an example of the topm=5directions of variance in each of the two shape classes shown in Fig. 1 respectively. In each row the center shape is the Karcher mean, and the path of shapes on either side represents the path traversed onSalong the shooting vectorvk=±2σkuk. It is also straightforward to obtain a random sample from a truncated wrapped-normal density onS. Given a shape class(Q,μ,K), and an integer m, let[U,Σ,V]=msvd(K), and selectukas the kth column ofU,k=1,…,m. Obtain{zk}k=1,…,m,mi.i.d. samples from the standard normal densityN(0,1). Compute the linear combinationv=∑k=1mzkσkuk. If‖v‖<π, then compute the random sampleq=expμ(v)and its coordinate functionβ. Fig. 3shows an example of 12 random samples obtained from the densities learned from the two shape classes shown in Fig. 1.We summarize steps for defining a truncated wrapped-normal Gaussian density on shape spaceSfor different shape classes. Assuming we are given a priori a set of training shapesQthat represent a certain shape class, we compute a Karcher meanμand covariance K to form a shape class(Q,μ,K). First, obtain the singular value decomposition of K as[U,Σ,V]=svd(K), and let M be the m-dimensional principal subspace ofTμ(S)defined as the first m columns of U. The prior density of this shape class is given as the exponential mapping offM(v), the multivariate Gaussian density on M.(7)fM(v)=1Ze-12v‖TΣm-1v‖+‖v⊥‖2/(2δ2)1‖v‖<π,wherev=expμ-1(q),v‖is the projection of v intoM,v⊥=v-v‖,Σmis the diagonal matrix containing the first m singular values, and Z is the normalizing constant. The scalar valueδis chosen to be less than the smallest singular value inΣm. For the final expression onS, please refer to the paper [31]. As described later, the densityfMsuffices for the purposes of this paper.Earlier we posed the problem of boundary extraction as a MAP estimation in Eq. (1), where the final solution is a closed curve that minimizes an energy functional defined by three terms,Eimage,Esmooth, andEprior. In order to minimize this expression, we introduce a time variable s and search for a steady state solution of the differential equation(8)∂∂sβ(t,s)=-λ1∇Eimage(β)(t,s)-λ2∇Esmooth(β)(t,s)-λ3∇Eprior(β)(t,s),where theλi’s are user defined weighting coefficients for each energy term. Since the contour evolution is in the direction of the negative gradient of the three energy terms, the steady state solution results in a local minimization of Eq. (1). The weightsλigreatly affect the performance of the contour evolution, and for this model we leave their selection up to the discretion of the user. The following subsections describe the formulation of the three energy gradients.Our image energy term is based on the work presented in [26,18,32,33]. In these papers, the authors propose an image energy that is not based on the gradient of a Gaussian smoothed edge map, as in for example EPGVF in [9], but rather instead a region-based energy term that is more robust to noise and diffuse object boundaries. The active contour model assumes a set of training shapes/images, and we use our training data to form this region-based image energy term in the following manner.LetItrainbe the pixel information in a training image and letβtrain(t)be a parameterized closed curve on the image domainΩ. For our application the region-based approach assumes that any image domain is partitioned into two regions via a closed curve representing the target boundary. The target regionΩinlies inside the curve, and the background regionΩoutlies outside the curve. Using training shape dataβtrain(t), one obtains a priori two estimated probability densities,pin(I)andpout(I), from the normalized histograms of intensity values inΩinandΩoutrespectively. These two learned densities will be used to calculateEimageduring an active contour evolution on a test image.LetI(x)∈[0,1]be the pixel intensity value of the test image at locationx∈Ω. Paragios and Deriche [33] show that for a curveβ(t,s)defining the two regionsΩinandΩout, the minimization of the following energy function is equivalent to the maximization of the image-based a posteriori segmentation probability.(9)Eimage(β)=-∫Ωinlog(pin(I(x)))dx-∫Ωoutlog(pout(I(x)))dx.Using functional differentiation and Green’s Theorem, as shown in [26], we calculate the gradient of the image energy at a point(t,s)on the curve as(10)∇Eimage(β)(t,s)=-logpin(I(β(t,s)))pout(I(β(t,s)))n(t,s),wheren(t,s)is the outward unit normal vector to the curveβ. For brevity we will defineℓβ(t,s)≡logpin(I(β(t,s)))pout(I(β(t,s))).Notice that contour evolution according to the negative gradient will be along the outward normal direction ifℓβ(t,s)>0and along the inward normal direction ifℓβ(t,s)<0. This evolution will therefore push any part of the contour more likely lying in the target out towards its most likely boundary, and it will pull any part lying outside of the target in towards its most likely boundary. Refer to Section 4 on experimental results for an example of forming the functionspin,pout, andℓfor a dataset of SAS imagery.The proposed image energy gradient has many advantages.1.Assuming at least part of the target lies within the contour, and assuming that there is only one target in the image (as is the case for our SAS datasets), “capture range” is only limited to the size ofΩ. This is because any part of the contour that lies outside of the target boundary will be drawn towards it no matter how far away it is.In practice, one computes the log-likelihoodℓ(I(x))for allx∈Ωonce before initialization of the active contour evolution. At each evolution time s, one only needs to calculate the unit normal vector field on the contour, then sample fromℓ(I(x))at the appropriate points of the curve in the domain to obtainℓβ(t,s). This results in considerable computational efficiency.There is no need for an added “balloon force” since the contour is automatically pushed out of the target if inside and pulled into the target if outside.Evolution along the normal direction provides a simpler flow compared to that which is given by a gradient vector field on the image directly. Such opposing techniques can produce erratic flows because it will detect edges throughout the entirety of a background that contains high speckle noise.The smoothing gradient described next is also formulated as a scalar times the unit normal, so these two energy terms can be combined for added computational efficiency.Figs. 4 and 5highlight many of the above advantages of segmenting SAS data with the log-likelihood image energy gradient flow compared to EPGVF [9], which was used in the work of Joshi and Srivastava in [5]. In Fig. 4 we show a SAS test image of a cylinder to be segmented and the EPGVF on a subset (enlarged for visualization purposes) of the image containing a piece of the target. It is apparent from this visualization that capture range is a significant issue with EPGVF. The target boundary in this particular image is rather pronounced, as it is not a difficult image to segment compared to other SAS images, and we see that in close range to the target, EPGVF will draw a contour to the boundary rather nicely. But farther away the target boundary’s influence becomes weaker, and background noise dominates the direction of the gradient vector flow creating many confusing sources and sinks. Another major downside of the EPGVF compared to the log-likelihood energy flow is its chaotic nature within the target boundary. Since the SAS target is by nature highly texturized, the vector flow inside the boundary finds edges nearly everywhere and cannot point outward towards the true target boundary. Thus an active contour flow according to EPGVF will draw the contour towards the boundary in short range but will not necessarily stop exactly on the target boundary and most certainly will not expand any part of the contour that lies within the boundary outward.Fig. 5 shows the segmentation results on this test image from each image gradient term combined with a smoothing penalty (defined in Section 3.2). Many of the aforementioned downsides of EPGVF in this setting are illuminated by the poor result shown in (b). Although the log-likelihood imageℓ(I(x))in (c) shows an apparently large amount of speckle noise in the background, as seen in (d) this background noise is not strong enough to keep the contour from finding the true target boundary when segmenting with the proposed image energy gradient combined with the smoothing penalty. As mentioned before, this particular SAS image is relatively friendly to segment and does not require a shape prior to achieve satisfactory results. In general this will not be the case, and a shape prior energy term will be necessary to find the correct boundary.A common feature of all active contour models is a smoothness penalty that prevents the evolving contour from becoming too jagged. Kass et al. [6] propose an energy functional in the form of a regularization term on the first and second order derivatives of the curve in order to enforce a certain level of smoothness. This term while effective, usually depends on the parameterization of the curve, and thus we wish to use an energy term invariant to parameterization to complement our shape analysis framework. We follow a common approach from geometric active contours as proposed in [12,11], which is based on the idea of Euclidean heat flow. Define the smoothing energy functional asEsmooth(β)=∫01|β̇(t)|dt, which is equal to the length of the curve and is naturally invariant to any re-parameterization. It is shown in [12] that the gradient ofEsmoothis given by the Euclidean heat flow equation∇Esmooth(β)(t,s)=κβ(t,s)n(t,s), whereκβ(t,s)is the curvature ofβ(t)at evolution time s. It has been shown (see [13,14]) that this penalty on a curve’s length automatically leads to smoothing of a curve by forcing the curve to become convex over time. Eventually, the curve evolves to a circle and shrinks to a point as time s goes to infinity. Fig. 6shows some illustrations of the evolution under the gradient ofEsmooth.The shape prior energy term is one of the novel contributions of this paper and is derived from a probability density function on the shape space formed by SRVF’s of unit length closed curvesS. Notice that the statistical methods described in Section 2 are based on SRVF’s of curves rather than the curves themselves; however, the proposed shape prior energy gradient in Eq. (8) is expressed in terms of the curveβ, and therefore, one needs a change of variable from q toβin the prior energy term to be compatible. This change of variable can be derived analytically but we use a convenient numerical approach. This involves computing a shape prior gradient vector for evolution onS, i.e. a shooting vector, and then converting it to a gradient vector field on the curveβ, taking special care to preserve the nuisance variables of scale and translation that are lost in the conversion fromβto SRVF with unit norm. We categorize scale and translation as nuisance variables because they are not important to the definition of shape – in fact they are shape invariants – but in a segmentation algorithm, it is clearly necessary to maintain the location and size of the active contour. Let the curve length represent the scale variable, and let the centroid represent the translation variable. At any iteration time s, we follow this general procedure to apply our shape prior energy gradient toβ:1.Calculate and save the length and the centroid of the current curveβ.Convertβto SRVF representation q and re-normalize such thatq∈S.Calculate the shape prior gradient atμin the form of a shooting vectorAw∈Tμ(S). Parallel translate it toTq(S)to obtain a vector v.Obtain a first order numerical approximation of∇Eprior(β)from v, in terms of a vector field onβ, using curves restored to the original scale and translation.We now explain in more detail steps 3 and 4 in the above procedure. In step 3, we wish to obtain a vectorv∈Tq(S)that represents the gradient of the shape prior energy onSgiven a shape class(Q,μ,K)and the multivariate densityfM(v)described in Eq. (7). We first obtain the shooting vectorw∈Tμ(S)signifying the initial direction of travel to reach q from the mean shapeμalong a geodesic; that is, calculatew=expμ-1(q). LetUmbe the first m columns of U in the SVD of K, and letΣmbe as in Eq. (7). DefineEprior(w), the shape prior energy as a function of the shooting vector w, as(11)Eprior(w)=12wT(UmΣm-1UmT)w+12δ2‖w-UmUmTw‖2,whereδis a number smaller than the smallest singular value inΣm. This energy term is the negative of the argument of the exponent infM(w)for that shape class. The gradient vector of this prior energy is therefore∇Eprior(w)=Awwhere A is the matrixA=UmΣm-1UmT+(I-UmUmT)/δ2. We wish to define the shape prior gradient on the tangent space at q rather than atμ, so the final step is to parallel transport Aw fromμto q, denoted byv=Π(Aw;μ,q)∈Tq(S). The vector v represents the shape prior gradient with respect to q; an evolution of q according to the negative gradient will result in an energy minimization precisely at the meanμ.In step 4, we convert this shape prior gradient vector v defined onTq(S)to a gradient vector field defined on the explicit curveβusing a simple numerical approximation of the chain rule. The idea is to travel a short distance∊from q along the geodesic defined by the shooting vector-v, and then convert the resulting shape into its curve representation with the original nuisance variables obtained in step 1. Subtracting the original curveβfrom the new curve as in a finite difference approximation defines a vector field onβthat represents a first order numerical approximation of the negative shape prior gradient. That is, let-∇Eprior(β)(t,s)=(βnew(t,s)-β(t,s))/∊, whereβnewis obtained as follows: (i) calculateqnew=expq(-∊v), (ii) convertqnewto its curve representationβ̃new(t)=∫0tqnew(u)|qnew(u)|du, and (iii) scale and centerβ̃newto obtainβnewwith the same length and centroid asβ.An important advantage of this shape prior formulation beyond that of its highly desirable intrinsic nature is that it makes use of the information given in the first momentμas well as the second moment K. An often used prior energy takes the formd([q],[μ])2, that is, squared distance from the current shape to the mean. Although this energy does incorporate prior knowledge in driving the active contour toward the mean of a training shape class, it does not allow for evolution along any directions of variance that may be more important than others. In other words, the prior energy does not incorporate any additional structure to account for these important directions of variability inherent to the shape class; instead, it allows for only a simple isotropic flow. Consequently, adding toEpriorthe information given from the second moment K will drive an evolving active contour towards the prior mean in a much more efficient and natural manner according to the underlying variation within the shape class. Fig. 7gives an example of this phenomenon.The total energy of the active contour model is given as the weighted sum of the three individual energies presented in the preceding subsections. Thus the differential equation in (8) governing the active contour evolution becomes(12)∂∂sβ(t,s)=(λ1ℓβ(t,s)-λ2κβ(t,s))n(s,t)-λ3∇Eprior(β)(t,s).In our implementation, we use a forward difference approximation of the time derivative on the left hand side, and, after dropping the arguments(t,s)for brevity, Eq. (12) becomesβ(n+1)=β(n)+(λ1ℓβ(n)-λ2κβ(n))n-λ3∇Eprior(β(n)).Note that the time stepping constantΔsis implicitly multiplied to eachλi. That is, an appropriate time step for numerical stability can be taken into account in the user’s selection of theλi’s, so we do not includeΔsin the written equation.Since the above evolution seeks a local minimum of total energy rather than a global minimum, the final result is highly dependent on the initializationβ(0), and until now we have yet to discuss any techniques to implement this key step of the segmentation process. There are many ways to automatically plant an initial seed that encloses the objective target. For all data we work with in the scope of this paper, there is only one target in each image, and the target is the brightest part of the image; thus, a simple automatic initialization would be to draw a circle of a sufficiently large radius centered at the pixel with the highest intensity value. In order to start the active contour closer to the final desired boundary, a more sophisticated approach is to apply an image filter, such as a Gaussian or median filter, and then threshold the image at a certain intensity value to create a binary image. A boundary curve is then placed around the connected region containing the brightest pixel value, which serves as the initialization to the active contour algorithm. Automatic seed initialization of any level of sophistication quite often fails in noisy imaging environments such as SAS, so a commonplace approach is to request a user input of a manual initialization. Any manual initialization is performed in a crude manner, i.e. such that the seed is generally close to the apparent target boundary but not directly on it in order to reduce the effect of any human bias to the results.There are also many options for a stopping criterion. In this algorithm we have direct access to the total energy, and thus we make use of this information to stop the active contour appropriately. We stop the algorithm when|Etotal(n)-Etotal(n-1)|<τ, whereτis some small tolerance, that is, when the total energy does not change much between time iterations. Often times the energy gradient oscillates on an order greater thanτas n increases, so it is beneficial to apply some smoothing to the sequence ofEtotal’s before checking the difference. Of course, it is also necessary to impose a maximum number of iterations in case the energy function does not converge.

@&#CONCLUSIONS@&#
