@&#MAIN-TITLE@&#
Simultaneous dynamic optimization: A trajectory planning method for nonholonomic car-like robots

@&#HIGHLIGHTS@&#
Our trajectory planner can tackle different requirements or constraints uniformly.Our proposal is systematically tested on a wide range of simulation cases.A Hamiltonian-based index is utilized to judge the optimality of an obtained solution.Differences between min-time and min-length trajectories are investigated.

@&#KEYPHRASES@&#
Car-like robot,Trajectory planning,Time-optimal control,Simultaneous dynamic optimization,Interior-point method,Computational guidance and control,

@&#ABSTRACT@&#
Trajectory planning in robotics refers to the process of finding a motion law that enables a robot to reach its terminal configuration, with some predefined requirements considered at the same time. This study focuses on planning the time-optimal trajectories for car-like robots. We formulate a dynamic optimization problem, where the kinematic principles are accurately described through differential equations and the constraints are strictly expressed using algebraic inequalities. The formulated dynamic optimization problem is then solved by an interior-point-method-based simultaneous approach. Compared with the prevailing methods in the field of trajectory planning, our proposed method can handle various user-specified requirements and different optimization objectives in a unified manner. Simulation results indicate that our proposal efficiently deals with different kinds of physical constraints, terminal conditions and collision-avoidance requirements that are imposed on the trajectory planning mission. Moreover, we utilize a Hamiltonian-based optimality index to evaluate how close an obtained solution is to being optimal.

@&#INTRODUCTION@&#
Robotic trajectory planning refers to the process of finding a motion law to enable a robot to move from its initial configuration to a desired terminal configuration by simultaneously considering some predefined requirements [1]. Trajectory planning has become a critical aspect of automation science; the applications of this process range from satellite orbit transfer [2], missile guidance [3], unmanned aerial vehicle navigation [4–6], anti-submarine search [7,8], hazardous environment exploration [9] and autonomous parking assistance [10,11]. In this work, we focus on the trajectory planning of car-like robots.A car-like robotic model can represent a wide range of vehicles with steering wheels and power motors [12], which may be the reason why such robots have been widely studied in the past two decades [13,14]. Although some relevant commercial productions are available, they can still be improved substantially regarding smartness and autonomy. In fact, many key parts of real-world deployment phases are ad hoc and manual [15]. Ref. [16] even pointed out that there had been few artificial systems that could outperform an experienced human driver (who also can be regarded as a system, although imperfect, yet the best one known). Therefore, further investigations are necessary to develop smart decision-making capability in robots.Typically a car-like robot is a nonholonomic system [17]. A system is said to be holonomic if all the system constraints can be expressed in the form off(q,t)=0, where q denotes the system states. By contrast, if the system constraints are written asf(q,q̇,q¨,t)=0but cannot be reduced tof(q,t)=0, then the system is nonholonomic [18]. In a non-holonomic system, the differential equations that describe robotic kinematics are non-integrable, which causes the total degrees of freedom to become greater than the controllable ones and eventually increases the difficulty of the trajectory planning scheme [19].A considerable number of studies have been undertaken to plan trajectories for mobile robots. Studies utilize geometrics originate from the pioneering works of Dubins [20] and Reeds & Shepp [21], where admissible trajectories consist of circle arcs with minimal turning radii and line segments. In general, those geometric approaches calculate reference paths during the first step; then, additional effort is required to generate control motions following the obtained reference paths [22,23]. Apart from the geometric methods, knowledge-based approaches have also been developed. Gorinevsky et al. introduced neural network technology to generate autonomous parking motions [24], whereas Marin applied reinforcement learning technique to grasp the kinematic principles and then to generate driving behaviors [25]. Zhao and Collins developed a fuzzy logic approach for parallel parking [26]. Khoukhi trained a neuro-fuzzy inference system to capture the dynamic behaviors of a robot [27]. In addition to the aforementioned studies, sampling-based and search-based methods have also caught the interest of researchers. Sampling-based methods compute trajectories through random sampling; two typical examples of these methods are the probabilistic roadmap method [28] and the rapidly exploring random trees [29–31]. Search-based methods, on the other hand, look for admissible paths or trajectories in predefined solution spaces [32–35]. Moreover, there have also been some previous studies that planned trajectories through control theories. Kim and Kim utilized the bang–bang control principle to induce satisfactory trajectories under the two-corner scenarios [36]. Barraquand and Latombe applied differential geometric control theory to compute maneuver-optimal solutions [17]. Balkcom and Mason applied Pontryagin’s maximum principle to calculate time-optimal trajectories [37].According to prevailing and emerging literature related to trajectory planning, judging whether one approach is better than another is difficult mainly because different methods are applied in certain scenarios or based on various kinematic models. Despite these differences, the authors believe that studying optimal trajectories based on a given optimization criterion is better than merely generating feasible trajectories [11]. Moreover, transforming the original trajectory planning scheme into another kind of problem is inappropriate if they are not equivalent. In this study, we regard trajectory planning as a dynamic optimization problem, in which robotic kinematics and additional requirements (mechanical constraints and collision-avoidance conditions) are strictly described. At present, numerical methods may be the only efficient approach to solve a complicated dynamic optimization problem.The simultaneous approach is a numerical method that addresses dynamic optimization problems. Through discretization, all state and control profiles in time are described by collocations in a finite number of elements. In this manner, the original infinite-dimensional dynamic optimization problem is transformed into a finite-dimensional nonlinear programming (NLP) formulation. The simultaneous approach is equivalent to a fully implicit Runge–Kutta method with high order accuracy and excellent stability. It possesses various merits over its competitors when tackling dynamic optimization problems, especially ones with complicated constraints and with input instabilities [38]. Since the resulting finite-dimensional NLP problem is in large scale, it calls for a highly efficient NLP solver. The interior-point method (IPM) is an effective solver that addresses high-dimensional NLPs. IPM applies a logarithmic barrier method to inequality constraints in an NLP, solves a set of equality constrained optimization problems for a monotonically decreasing sequence of the barrier parameter, and then rapidly converges to a solution [39]. This mechanism enables IPM to solve NLPs with up to several million variables, constraints, and degrees of freedom. The IPM-based simultaneous approach has been widely used in many chemical engineering applications; however, its applications in robotics are relatively scarce.In this work, we choose terminal moment as the minimization criterion in the formulated dynamic optimization problem with kinematics and other constraints that are strictly described. The IPM-based simultaneous approach is applied to solve this problem. Several sets of benchmark scenarios are systematically designed to test the performance of the dynamic optimization formulation and the solver. A Hamiltonian-based index is also proposed to reflect how close the obtained solutions are to optimality.This section focuses on describing the original trajectory planning scheme through differential equations and algebraic equalities/inequalities. The kinematic principles of a car-like vehicle are presented, along with the interior constraints (i.e., the physical and mechanical restrictions of a robot) and the exterior constraints (e.g., collision-free and two-point boundary conditions) that should be satisfied during the entire movement of a car. At the end of this section, we provide an overall framework of the formulated dynamic optimization problem, which we believe, is identical to the original trajectory planning mission.The kinematics of a front-steering car-like vehicle can be expressed as follows [11]:(1)dx(t)dt=v(t)·cosθ(t)dy(t)dt=v(t)·sinθ(t)dv(t)dt=a(t)dθ(t)dt=v(t)·tanϕ(t)ldϕ(t)dt=ω(t),t∈[t0,tf],where t refers to time,tfindicates the terminal moment of the entire dynamic process (which is unknown in advance),(x,y)shows the location of the midpoint of the rear wheel axis,θis the orientation angle, v refers to the linear velocity of point P, a refers to the corresponding acceleration,ϕis the steering angle of the front wheels andωrefers to the corresponding angular velocity. Moreover,l,n,mand2bdenote the wheelbase length, front overhang length, rear overhang length and car width respectively (see Fig. 1).In the preceding equation,ω(t)anda(t)are selected as control variables, whereas the remaining five variables, i.e.,x(t),y(t),v(t),θ(t)andϕ(t), are regarded as state variables. Given their initial values, those state variables can be determined successfully one after another through integral provided thatω(t)anda(t)are known.Apart from the vehicle kinematics described through differential equations in the preceding subsection, the bounded constraints on state/control variables should be also considered. These variables reflect the mechanical and physical constraints in a robotic system. The constraints are described in detail as follows:(2)|a(t)|⩽amax|v(t)|⩽vmax|ϕ(t)|⩽Φmax|ω(t)|⩽ωmax,for allt∈[t0,tf].The reasons for imposing boundaries ona(t),v(t)andϕ(t)are evident. To avoid the undesirable wearing of tires [40–42], many studies have planned continuous-curvature trajectories. One way to generate continuous-curvature trajectories is imposing bounds onω(t)[35]. The rationale behind this issue as follows. Given that the instantaneous curvatureκ(t)=tanϕ(t)land its derivativedκ(t)dt=ω(t)l·cos2ϕ(t), we expectκ(t)to be continuous. Ifω(t)is bounded, thendκ(t)dtwill be bounded, thenκ(t)will be continuous, which eventually guarantees the generation of a continuous-curvature trajectory.Mechanical and physical constraints associated with robotic kinematics have been identified. Moreover, some environmental constraints and terminal conditions must be considered when a robot moves in space, which are introduced in the next subsection.This subsection mainly focuses on two issues: (1) how collision-free requirements are described and (2) how terminal conditions are defined.In this work, we consider two kinds of collision-avoidance constraints. The first kind of constrain restricts a car inside a box region whereas the second kind of constraint is about avoiding obstacles in the environment.Assume that a car-like robot is rectangular. The inside-box requirement is equivalent to that the four edge points, i.e.,A(t),B(t),C(t)andD(t)in Fig. 2, should remain inside the box whenevert∈[t0,tf]. Here, the four edge points are given by(3)A=Ax,Ay=x+(l+n)·cosθ-b·sinθ,y+(l+n)·sinθ+b·cosθB=Bx,By=x+(l+n)·cosθ+b·sinθ,y+(l+n)·sinθ-b·cosθC=Cx,Cy=x-m·cosθ+b·sinθ,y-m·sinθ-b·cosθD=Dx,Dy=x-m·cosθ-b·sinθ,y-m·sinθ+b·cosθ.The aforementioned inside-box condition restricts a robot from colliding with the barriers. Besides that, we consider some small obstacles in the space that a car-like robot should not collide with. Assuming that the obstacles are circular, the four edge points of the robot should remain outside the obstacle region (see Fig. 3a). This necessary condition is described through Eq. (4).(4)(Ax-CP1x)2+(Ay-CP1y)2⩾r12(Bx-CP1x)2+(By-CP1y)2⩾r12(Cx-CP1x)2+(Cy-CP1y)2⩾r12(Dx-CP1x)2+(Dy-CP1y)2⩾r12,whereCP1x,CP1yshows the location of the center of the circle andr1refers to the corresponding radius. However, Eq. (4) alone is insufficient to guarantee that the car will not collide with an obstacle (see the counter example in Fig. 3b). In the remainder of this part, we focus on how to judge and then to avoid the possibility shown in Fig. 3b.To judge whether a car will hit the circular obstacle while its four edges remain outside, first, we establish a car body axis coordinate systemX′GY′(see Fig. 3b), where pointG=Ax+Bx+Cx+Dx4,Ay+By+Cy+Dy4denotes the geometric center of rectangle ABCD. Thereafter, the coordinates of the circle center in theX′GY′frame is computed through a simple translation and rotation from its locationCP2x,CP2yin the originalXOYframe, i.e.,(5)CP2x∗=CP2x-Ax+Bx+Cx+Dx4·cosθ-CP2y-Ay+By+Cy+Dy4·sinθCP2y∗=CP2x-Ax+Bx+Cx+Dx4·sinθ+CP2y-Ay+By+Cy+Dy4·cosθ,where(CP2x∗,CP2y∗)denotes the coordinate of the center of the circle in theX′GY′frame. Then, to avoid the possibility of the collision depicted in Fig. 3b, the following is required:(6)CP2x∗-m+l+n2⩾r2,ifCP2y∗⩽bCP2y∗-b⩾r2,ifCP2x∗⩽m+l+n2.To briefly conclude, the necessary and sufficient condition for a car-like robot to avoid colliding into a circular obstacle is the satisfaction of Eqs. (4) and (6).In addition to the kinematics and constraints, terminal conditions should be satisfied at momentt=tf.For example, a parking process should end with a full stop, that is,v(tf)=0. However, for a general trajectory planning scheme, various user-specific terminal requirements can emerge, such as requiring the car to stop in a specified box region. It should be emphasized that, although we introduce merely some simple terminal conditions in this work, our dynamic optimization model is capable of handling other complicated ones provided that they can be explicitly expressed through equalities or inequalities.In this work, we aim to find the trajectory associated with minimumtf. Aside from the minimization criterion (i.e., minimum driving time), other optimization criteria can also be considered whenever they are explicitly described through polynomials. Hence, our formulated dynamic optimization problem is not a specific optimization model but a unified framework that can cater to different optimization demands, conditions, or constraints. Fig. 4schematically illustrates the unification of this framework [43].We believe that the established optimization framework is equivalent to the original trajectory planning mission. However, this framework may be far beyond the capability of analytical methods to solve such a dynamic optimization problem uniformly. Thus, using numerical methods may be the only approach to provide the required solutions. Before introducing our concerned IPM-based simultaneous approach in Section 4, Section 3 discusses the necessary condition to judge whether an obtained trajectory is optimal.This section provides a criterion to determine whether a calculated trajectory is an optimal solution (either local or global) to the formulated dynamic optimization problem. First, we analyze the necessary conditions that should be satisfied by an optimal solution of our concerned min-time dynamic optimization problem. Then, we propose a criterion as an optimality evaluator.The formulation illustrated in Fig. 4 can be generalized as follows:(7)mintf,s.t.dz(t)dt=f(z(t),k(t),u(t))g(z(t),k(t),u(t))⩽0,t∈[t0,tf],wherez(t)represents the differential state variables (i.e.,x(t),y(t),v(t),θ(t)andϕ(t)in Section 2),k(t)denotes the algebraic state variables (i.e.,Ax(t),Bx(t),Cx(t), etc.) andu(t)represents the control variables (i.e.,ω(t)anda(t)). The equalities and boundary conditions can be covered byG(z(t),k(t),u(t))⩽0(e.g.,z(t0)=1is identical toz(t)-1⩽0and-z(t)+1⩽0at a specific momentt=t0). We assume that the state equations (f andg) are smooth functions inz(t),k(t)andu(t)[44].Based on Eq. (7), the final timetfis not specified and the system is not autonomous. For the convenience of subsequent analysis, time can be normalized ast=pf·χ, whereχ∈[0,1]is regarded as an additional state variable andpfdenotes a scalar decision variable. Through this, Eq. (7) can be rewritten as an autonomous system with a “specified” final time as follows:(8)minpf,s.t.dzdχ=pf·f(z(χ),k(χ),u(χ))g(z(χ),k(χ),u(χ))⩽0dχdχ=10⩽χ⩽1,which can be further simplified as(9)minpf,s.t.dzdχ=fz(χ),k(χ),u(χ),pfgz(χ),k(χ),u(χ)⩽0.To obtain the optimality conditions, we form the Hamiltonian(10)H(χ)=pf+f(z,k,u)·λ+g(z,k,u)·γ,where the adjoint variablesλandγare functions ofχ. In this case,λ(χ)serves as the multipliers for the differential equations, whereasγ(χ)serves as the multipliers for all the algebraic constraints.Next, we have(11)dHdχ=∂H∂zdzdχ+∂H∂λdλdχ+∂H∂kdkdχ+∂H∂γdγdχ+∂H∂ududχ+∂H∂pfdpfdχ.Pontryagin’s minimum principle yields the following necessary optimality conditions [44,45]:(12a)dzdχ=∂H∂λ,(12b)dλdχ=-∂H∂z,(12c)∂H∂u=0,(12d)∂H∂k=0,(12e)γ⊥gz,k,u=0.According to Eq. (12e), it is interesting to note thatg·dγdχ≡0because ifg<0, thenγ(χ)≡0, which yieldsdγdχ=0; on the other hand, wheng=0, itemg·dγdχis directly equal to zero. Therefore,(12f)∂H∂γdγdχ=g·dγdχ≡0.Moreover, as a scalar variable,pfis not time-varying, thus(12g)dpfdχ=0.Substituting Eqs. (12a), (12b), (12c), (12d), (12f) and (12g) into Eq. (11) yields(13)dHdχ=0,for anyχ∈[0,1],which indicates that even for a non-autonomous system with a not specifiedtf, the corresponding Hamiltonian H is constant over timet∈[t0,tf]when optimality is achieved.In our concerned trajectory optimization problem, the Hamiltonian H can be written as(14)H(t)=1+λ1(t)·v(t)·cosθ(t)+λ2(t)·v(t)·sinθ(t)+λ3(t)·a(t)+λ4(t)·v(t)·tanϕ(t)+λ5(t)·ω(t),whereλ1(t),λ2(t),λ3(t),λ4(t)andλ5(t)denote the adjoint variables. Notably, the formulated Hamiltonian in Eq. (14) has no inequalities because of a prior assumption that the feasibility of any obtained solution must be strictly guaranteed. According to Eq. (12b), the adjoint variables are computed by(15)dλ1dt=0dλ2dt=0dλ3dt=-λ1(t)·cosθ(t)-λ2(t)·sinθ(t)-λ4(t)·sinϕ(t)dλ4dt=λ1(t)·v(t)·sinθ(t)-λ2(t)·v(t)·cosθ(t)dλ5dt=-λ4(t)·v(t)·1cos2ϕ(t),along with the terminal conditionH(tf)=0[45].Considering that the Hamiltonian should be constant over time when an optimal control profile is obtained, we propose a simple index in Eq. (16) to reflect the optimality of a solution. Perfectly we expectCHto be equal to zero. The closerCHis to 0, the closer the obtained control profile should be to being optimal.(16)CH=max∀t∈[t0,tf]H(t)-min∀t∈[t0,tf]H(t)1tf-t0∫t0tfH(t)dt.In this section, the IPM-based simultaneous approach is presented to solve the dynamic optimization problem formulated in Section 2.The IPM-based simultaneous approach consists of two phases: the discretization and programming phases. In the former, all the state and control profiles in time are discretized through the collocation of finite elements. In this manner, the original dynamic optimization problem is transformed into an NLP formulation. The resulting NLP problem is then solved during the second phase. Here, the resulting NLP problem is usually in large scale (because an infinite-dimensional dynamic optimization problem has been converted into a finite-dimensional programming problem in the first phase), thus, a highly efficient NLP solver is required. IPM is an efficacious large-scale NLP solver, which is capable of solving an NLP with up to several million variables, constraints and degrees of freedom. The remainder of this section is organized as follows. First, we present the principles of the two phases respectively. Then, we focus on how this approach can be utilized to solve the dynamic optimization problem that we have formulated.Without losing generality, we consider the following general dynamic optimization problem [38]:(17)minφz(tf),s.t.dz(t)dt=f(z(t),ψ(t),u(t))g(z(t),ψ(t),u(t))⩽0,t∈[t0,tf],wherez(t)refers to differential state variables,ψ(t)denotes the algebraic state variables,u(t)denotes the control variables andφz(tf)represents the minimization objective which is relevant to the terminal momenttf. The unknown variables in Eq. (17) includez(t),ψ(t),u(t)andtf.First, the time domain[t0,tf]is divided into Nfe finite intervals{[ti-1,ti]|i=1,2,…,Nfe}, wheretNfe=tf. The duration of each element can be written ashi=ti-ti-1,i=1,2,…,Nfe. This work considers equidistant division in[t0,tf]. Thus, the duration h of each interval is equal totf-t0Nfe. For consistency with the previous studies in the field of computational science, we refer to such intervals as “finite elements”.Next, we choose(K+1)interpolation points in theithelement and approximate the state using the following Lagrange polynomial:(18)z(t)=∑j=0Kzij·∏k=0,≠jK(τ-τk)(τj-τk),wheret=ti-1+h·τ,τ∈[0,1],τ0=0and0<τi⩽1(j=1,2,…,K). Eachτirefers to either Gauss or Radau points, which can be calculated off-line according to Gaussian quadrature accuracy theorem [44] when K is determined.The Lagrange polynomial representation in Eq. (18) possesses a desirable property thatz(tij)=zij, wheretij=ti-1+h·τj. That is, the polynomial function directly passes the(K+1)interpolation points once they are determined on theithfinite element. This property considerably simplifies the optimization procedure in the subsequent phase.In addition, sincez(t)refer to states that should be differentiated, the continuity of the differential state variables across element boundaries should be guaranteed; otherwise, the derivative at element boundaries will not exist. Thus, we have(19)zi+1,0=∑j=0Kzij·∏k=0,≠jK(1-τk)(τj-τk),i=1,2…,Nfe-1.Similarly, control variablesu(t)and algebraic statesψ(t)can be represented by Lagrange interpolation profiles at K collocation points, that is,(20)u(t)=∑j=1Kuij·∏k=1,≠jK(τ-τk)(τj-τk),and(21)ψ(t)=∑j=1Kψij·∏k=1,≠jK(τ-τk)(τj-τk).Unlike in Eq. (19) for differential statesz(t), variablesu(t)andψ(t)can be discontinuous at the finite element boundaries. That means, we do not enforceui+1,0=ui,Korψi+1,0=ψi,K(i=1,2,…,Nfe-1).By substituting Eqs. (19)–(21) into Eq. (17), we obtain(22)∑j=0Kdςj(τ)dττ=τk·zik-h·f(zik,ψik,uik)=0,i=1,2…,Nfe,k=1,2,…,K,whereςj(τ)=∏k=0,≠jK(τ-τk)(τj-τk).Given a fixed number of elements, the NLP formulation originated from the original dynamic optimization problem, i.e., Eq. (17), can be written in the form of Eq. (23) as follows:(23)minzij,ψij,uijφ(z(tf)),s.t.∑k=0Kdςj(τ)dττ=τk·zik-hi·f(zij,ψij,uij)=0g(zij,ψij,uij)⩽0zi1+1,0=∑j=0Kzi1j·∏k=0,≠jK(1-τk)(τj-τk),i=1,2…,Nfe,i1=1,2…,Nfe-1,j=1,2,…,K.Through this equation, the original dynamic optimization problem is converted into an NLP formulation during the discretization phase.In this phase, IPM is adopted to optimize the discretized variableszij,ψijanduij(i=1,2…,Nfe,j=1,2,…,K)in the converted NLP formulation (i.e., Eq. (23)). The details of IPM are not discussed here for reasons of length and the focus of our paper. Interested readers may refer to [39].The two preceding subsections present the two phases in the IPM-based simultaneous approach. This subsection mainly focuses on how this IPM-based simultaneous approach is used to solve the dynamic optimization problem we have formulated in Section 2.Notably, the formulated dynamic optimization problem (illustrated in Fig. 4) can be directly expressed in the form of Eq. (17). First, since we mainly pursue for time-optimal trajectories, the minimization criterionφz(tf)refers totf. Apart from this, other criteria can also be optimized in our formulated model easily. For example,φ=∑i=1Nfe∑j=1Kxij2+yij2implies that min-length solutions are pursued. Second,z(t)represents all the differential state variables in Eq. (1), i.e.,x(t),y(t),v(t),θ(t)andϕ(t). Third, the variableψ(t)stands for all the state variables that are not differentiated, e.g.,Ax(t),Bx(t),Cx(t), etc. Fourth,u(t)represents the control variablesω(t)anda(t). Fifth,g(z(t),ψ(t),u(t))⩽0covers the other equalities/inequalities and boundary conditions in Section 2.Based on the aforementioned analyses, we manage to bridge the gap between our model and our adopted method. The overall flowchart of the IPM-based simultaneous approach is illustrated in Fig. 5[43].Several sets of simulations were conducted. We adopted an IPM software package called IPOPT version 3.8.0 [39]. All the simulations were executed using an Intel Core 2 Duo CPU with 2GB RAM running at 2.53GHz under Microsoft Windows 7. The critical parametric settings are listed in Table 1. Other parameters involved were chosen based on their default settings.In this study, 7 cases have been designed to test the efficiency of our proposal. The scenario details are listed in Table 2. The “inside-box” requirement for Cases 3–5 means that a car-like robot should remain inside a predefined rectangular region during the entire moving process (Fig. 6). The optimization results are respectively depicted in Figs. 7–13.Cases 1 and 2 present two scenarios in the free space. In Case 1, there is not a clearly specified terminal configuration; instead, onlyy(tf)=2.5is required. Viewing Fig. 7a, we find that the concerned trajectory planning process is terminated once the car exactly reachesy=2.5. In Fig. 7b, all the optimized state/control variables remain strictly inside their predefined bounds without violation, which indicate the efficiency of our optimization method. Case 2 contains a carefully designed scenario, where the bounds imposed on the sate variables are sufficiently loose. Thus, the control profiles are more likely to be on the boundary of the control region, which causes a bang–bang control profile (Fig. 8b). Cases 3–5 are about driving in constrained rectangular regions with increasing difficulty. For example, in Case 5 the car goes back and forth repeatedly due to the tiny admissible space (Fig. 11a). The optimized state/control profiles shown in Fig. 11b can be intuitively understood with ease. Cases 6 and 7 focus on avoiding circular obstacles in the environment. In Case 6, that car passes close to but remains exactly outside the obstacle region. Case 7 is commonly regarded as a parallel parking scenario. The optimized trajectory indicates that the car needs two maneuvers (i.e., takes two halts before the terminal stop) to reach the final configuration (see Fig. 13a). Although the aforementioned simulation results are intuitively understandable and are generally in accord with common sense, yet they are computed in a fully automatic way without any human intervention.Notably, all the collision-avoidance cases we have designed (i.e., Cases 3–7) are based on a fundamental assumption that the locations of the obstacles in the environment are fully known in advance. However, planning local trajectories (i.e., making plans dynamically according to locally sensed obstacles) seems to be relatively suitable and practical because the environment may be complex and/or time-varying [46]. At this point, we believe that the future developments in high-precision sensors and high-speed processors will make it easy to capture the time-varying environment with accuracy. In that case, the complex moving obstacles can be regarded as “static” ones at every single processing moment. When a full knowledge of the environment is available, it is better to do optimization rather than provide merely feasible solutions. In this sense, our proposal will be greatly meaningful when the relevant hardware techniques are well developed. In the remaining of this section, further discussions about the simulated results are provided.In Table 2, it is notable that when the tested cases are relatively complicated, the computed solutions are unlikely to achieve optimality, because the smoothness of the corresponding Hamiltonian is reduced. In this subsection, we investigate how the selection of Nfe can affect the optimality of a solution.Taking Case 4 for example, we conducted simulations under the condition of different Nfe values. When all the optimization solutions (which are converged by the solver IPOPT) are available, we illustrate their corresponding Hamiltonian functions simultaneously in Fig. 14. Detailed results are listed in Table 3.In Table 3,CHgradually reduces towards zero as Nfe grows. This observed phenomenon indicates that the solution optimality is gradually guaranteed when Nfe increases. Moreover, interested readers may wonder why the optimizedtfslightly changes also. Here, it is worthwhile to notice that the finite-dimensional programming problem is similar but distinct from the formulated infinite-dimensional dynamic optimization problem. A larger Nfe implies that more efforts are made to portray the infinite-dimensional profiles so as to get closer to the original problem. In this sense, Nfe determines at what precision level is the original dynamic optimization problem solve numerically. Specially, we illustrate the optimized trajectory and the corresponding control/state profiles whenNfe=200in Fig. 15. In contrast with the profiles shown in Fig. 10b (whenNfe=20), the profiles in Fig. 15b present more regular bang–bang control profiles. Regarding the computation efficiency issue, we notice that in general the computational time increases with the growth of Nfe but a clear relationship is not found. For instance, the computation time is 58.173s whenNfe=60while it is merely 13.019s whenNfe=100. This fact implies that for the gradient-based solver IPM, to handle a larger-scale programming problem does not necessarily add to the solving difficulty. Regarding the largest-scale problem in Table 3 (i.e., the case whenNfe=200), there are 11,787 variables to optimize along with 19,176 equality/inequality constraints. So complicated an optimization problem might be beyond the ability of the emerging and prevailing computational methods to provide even feasible solutions in a same amount of time [47,48].In this work, the gross driving time is chosen as our minimization criterion. However, there have been also studies pursue for minimum path lengths. Since our formulation does accommodate other optimization objectives thantf, in this subsection, min-length optimizations are conducted based on Cases 1 and 2 respectively, aiming to preliminarily investigate the difference between a min-time and a min-length solution.With regarded to the case shown in Fig. 16, the min-length path is 0.517 meters shorter than the min-time path. Interestingly, to execute the min-length trajectory, a car-like robot should first slow down (see Fig. 16b). This phenomenon is understandable: since a largerϕenables a car turn around more easily, and that the formulated optimization mission no longer cares about the driving time, thus, it is willing to “wastes” time to wait for the steering wheels reach the left bound. A similar simulation result is obtained based on Case 2 (see Fig. 17). During its entire moving process, the car moves slowly (at a speed of10-3m/sor so) while the steering angle changes relatively fast. This makes the whole min-length path nearly a combination of three circular arcs. At this point the simulated result shown in Fig. 17a is in accord with Reeds & Shepp’s analysis [21]. If a min-length solution takes far longer time to implement, it may be better to choose a min-time solution to follow (in our concerned case, we do not mind going that 3.926 meters farther).

@&#CONCLUSIONS@&#
