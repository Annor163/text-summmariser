@&#MAIN-TITLE@&#
An exact approach to Bayesian sequential change point detection

@&#HIGHLIGHTS@&#
Algorithm quickly updates its inference in linear time with each new observation.Derives uncertainty bounds on the number and location of change points in a data set.Explores potential detection criteria associated with posterior distribution.Simulation studies show high detection rate, low false positive rate.Analysis of two real data sets illustrate wide range of potential applications.

@&#KEYPHRASES@&#
Dynamic programming,Exact Bayesian inference,Global temperature anomalies,Multiple change point,Piecewise regression,

@&#ABSTRACT@&#
Change point models seek to fit a piecewise regression model with unknown breakpoints to a data set whose parameters are suspected to change through time. However, the exponential number of possible solutions to a multiple change point problem requires an efficient algorithm if long time series are to be analyzed. A sequential Bayesian change point algorithm is introduced that provides uncertainty bounds on both the number and location of change points. The algorithm is able to quickly update itself in linear time as each new data point is recorded and uses the exact posterior distribution to infer whether or not a change point has been observed. Simulation studies illustrate how the algorithm performs under various parameter settings, including detection speeds and error rates, and allow for comparison with several existing multiple change point algorithms. The algorithm is then used to analyze two real data sets, including global surface temperature anomalies over the last 130 years.

@&#INTRODUCTION@&#
Long time series are often heterogeneous in nature. As Chopin (2007, p. 349) notes, ‘the assumption that an observed time series follows the same fixed stationary model over a very long period is rarely realistic.’ Since the inability to recognize a regime change in a data set can have a detrimental effect on an algorithm’s predicative performance, the ultimate goal of change point analysis is to fit a piecewise regression model to a data set where the exact timing of these regime changes is unknown. A ‘change point’ is defined as an abrupt shift in the parameters of a model. Common examples include detecting a change in the mean, variance or trend of the response variable. Ideally, one would want to identify exactly when this ‘change point’ occurs so that each regime can be separately fit by an appropriate model.Change point models have been applied in a wide range of settings including finance (Chopin, 2007), climate (Ruggieri et al., 2009; Gallagher et al., 2012; Ruggieri, 2013), biology (Fearnhead and Liu, 2007), earthquake data (Grigg and Spiegelhalter, 2008), DNA segmentation (Liu and Lawrence, 1999), historical time series such as average annual wage growth (Western and Kleykamp, 2004), and in other areas where long sequences of data are available. A Bayesian approach to the change point problem is particularly appealing for two reasons. First, a Bayesian approach does not rely on the asymptotic assumptions about test statistics that are present in frequentist algorithms, which can be problematic in situations where the parametric models considered are restricted to a finite, possibly small interval of time (Chopin, 2007). Second, a Bayesian approach will allow one to quantify uncertainty both in the number and the positioning of the change points.Here, we seek to describe an efficient and exact Bayesian change point model that can quickly update itself as each new observations is recorded (known as sequential change point detection). Each data point will require an update that has linear time complexity, giving the algorithm an overall complexity that is quadratic in the length of the data set. This stands in stark contrast to the exponential time required by a brute force approach. Once a new change point has been detected, the algorithm samples directly from the exact posterior distribution on the number of change points, their locations, and the parameters of the regression model, yielding uncertainty estimates for each of these quantities.The rest of the article is organized as follows. Section  2 describes some of the existing change point techniques, with a special focus on sequential Bayesian methods. Following the literature review, Section  3 presents an overview of the Bayesian Change Point algorithm of Ruggieri (2013) that will be used as the foundation for the sequential method presented in this paper. In Section  4, we describe how the Bayesian Change Point algorithm of Ruggieri (2013) can be modified to handle sequential observations. In Section  5, the new sequential change point detector tested on simulated data sets as well as two real data sets and compare the results to several existing multiple change point algorithms. Section  6 provides discussion and conclusions.

@&#CONCLUSIONS@&#
The ideal change point algorithm would have a minimal number of false positives combined with the quickest possible detection rate, giving us two obvious measures of performance: rate of false positives and delay in detection. However, there is an obvious trade-off between these two measures of performance as quick detection is often linked with a high rate of false alarms. Monitoring the posterior distribution of the number of change points appears to be the best way to detect the existence of a new change point in a data set. Three detection criteria were proposed and studied in this paper, namely the mean, median, and mode of this posterior distribution. Of the three, the mean of the posterior distribution appears to be the least desirable of the detection criteria as it had the highest error rate and slowest detection speed. While the median had a slightly higher error rate than the mode, the two were nearly equivalent in terms of their ability to detect actual change points.One potential difficulty in monitoring the posterior distribution of the number of change points is that it is not a monotonic function. For example, outliers or even random variation in the data set can make it appear that a change point has occurred, when in fact further data collection would indicate otherwise. Thus, a delicate balance has to be struck between the speed and accuracy of detection if the algorithm is going to prove itself useful.Section  5.1 described simulations used to study the false alarm rate of the Sequential Bayesian Change Point algorithm. Errors in detecting change points are a product of the random variation in the data sets and often resulted from a small number of consecutive data points that are all significantly above or significantly below the baseline signal. In this situation, the addition of more data eliminates this spurious change point. Of the 20,000 simulations summarized in this section, only 11 were erroneously determined to contain a change point once the full data set was revealed. Of these, the vast majority [9/11] were in the simulation of the constant mean whenk0was set to its largest value. The other two occurred in the simulation of the constant mean whendminwas set to its smallest value. In general, both error rates and discovery rates were consistent with those of existing change point algorithms, and the algorithm was found to be conservative in its change point detection. For a given set of parameter values, a lack of false positives was accompanied by less than perfect detection.If these simulations are placed in the context of a classification problem (change point vs. no change point), then each choice of parameter settings would represent a different classifier with its own ‘discovery rate’ and ‘false alarm rate’. The Receiver Operator Characteristic (ROC) curve specifies the maximum detection rate for a given false alarm rate. Real-world classifiers will never have 100% detection without any false alarms, so it should not be surprising that the algorithm proposed in this paper has both false alarms and less than perfect detection ability. See Fawcett (2006) for more information on ROC curves.The efficient algorithm described here can update itself in linear time with each new observation. However, for very long data sets, even a linear update can become computationally prohibitive. One approach to addressing this problem is to expand upon the product partition model that forms the foundation of this algorithm. The product partition model assumes that segments separated by a change point are independent of each other (Barry and Hartigan, 1993). If the locations of the change points are also assumed to be independent of one another, then the complexity of the algorithm can be reduced from linear to the average segment length. However, by doing this the exact nature of the algorithm is sacrificed. Work is ongoing to study the effects of this assumption.For the purpose of illustration, the simulated and real data sets presented in Section  5 highlight only the simplest types of change point analysis, namely a change in mean and a change in linear trend. For example, including sinusoidal predictor variables in the regression model would allow a user to search for change points in a periodic data set (e.g. Ruggieri et al., 2009; Ruggieri, 2013); a multinomial model allows examination of a genomic data set (e.g. Liu and Lawrence, 1999). In short, the applicability of the Sequential Bayesian Change Point algorithm extends far beyond these two scenarios and is appropriate for any data set in which the likelihood of the data can be calculated for a given predictive model.Finally, as written the Sequential Bayesian Change Point algorithm assumes an independent error structure. This is a common assumption in change point analysis (e.g. Barry and Hartigan, 1993; Stephens, 1994; Western and Kleykamp, 2004; Adams and MacKay, 2007; Ruggieri et al., 2009; Ruggieri, 2013; Ruggieri and Lawrence, 2014; among others), especially when the goal is to detect a shift in the mean signal (Lucas and Saccucci, 1990; Carlin et al., 1992; Siegmund and Venkatraman, 1995; Lavielle and Lebarbier, 2001; Fearnhead and Clifford, 2003; Hawkins et al., 2003; Whiteley et al., 2011). Future work will consider models with a correlated error structure.While many of the existing sequential change point algorithms only approximate the posterior distribution of the location of the change points, the efficient and exact Sequential Bayesian Change Point algorithm draws samples directly from the posterior distribution without imposing any assumptions on the distance between adjacent change points. The algorithm has the ability to quickly update itself with each new observation and can provide uncertainty bounds both on the number and locations of the change points in a data set. Simulation studies show a low rate of falsely detected change points while at the same time giving confidence that existing change points will quickly be detected. The well-log and global surface temperature anomalies data sets give a small indication as to the many possible applications of this algorithm.Availability: Matlab code for the Sequential Bayesian Change Point algorithm and the associated data sets described in this manuscript can be obtained by contacting the first author, Eric Ruggieri, at eruggier@holycross.edu