@&#MAIN-TITLE@&#
GaFinC: Gaze and Finger Control interface for 3D model manipulation in CAD application

@&#HIGHLIGHTS@&#
A multi-modal control method using finger and gaze for 3D manipulation is proposed.Independent gaze pointing interface increases the intuitiveness of the zooming task.The performance of GaFinC is applicable to actual CAD tools.Interviews of user experience report higher intuitiveness than a mouse.

@&#KEYPHRASES@&#
User interface,Multi-modal,Gaze tracking,Hands tracking,Gesture recognition,Manipulation,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Recently much research into HCI: human–computer interaction has been conducted and its developments for better interfaces have been directed towards making HCI more natural and intuitive. Also in the CAD field, many HCI interfaces have been actively developed, of which the hand gesture control interface for CAD modeling tasks is one. There have been studies using wearable hardware, sensing hand coordinates and gestures  [1,2]. But as special wearable hardware was an obstacle to becoming popular, vision based gesture tracking control  [3–5] became one of the main topics. Recently, hand tracking and skeleton recognition studies using depth sensing cameras such as ‘Kinect’ have been introduced  [6–9]. These hand gesture control interfaces are generally designed based on the metaphor of the real world and its intuitiveness makes it user friendly. However, in spite of its intuitiveness and familiarity, its usability for actual 3D CAD modeling applications is not that comfortable compared with a conventional interface such as a mouse. Most importantly, previous hand gesture control interfaces were not applicable for long time operation in the aspect of increasing users’ physical fatigue. In this paper, we suggest an improved gesture control interface showing conventional interface level usability with low fatigue while maintaining a high level of intuitiveness. As an order of priority, we focused on 3D model manipulation tasks, which are among the most frequent in conducting 3D CAD modeling. Through analyzing problems of previous hand gesture control in manipulation tasks, we achieved our approaches as follows.(1)Precise hand and finger tracking control.Easy application control with finger gestures.Gaze tracking as an independent pointing interface.To achieve these, we developed the multi-modal hand gesture control interface ‘GaFinC’: Gaze and Finger Control interface. The problems in the analysis of previous works and our approaches will be mentioned in detail in the next section.

@&#CONCLUSIONS@&#
We proposed a multi-modal interface GaFinC: Gaze and Finger gesture Control for 3D model manipulation tasks. It contains a precise hand tracking and finger gesture recognition interface and an independent gaze tracker for setting the point of interest. In tests to verify the performance, the GaFinC interface demonstrated insufficient performance in accuracy and time compared to the mouse. Although the GaFinC scored better in overall intuitiveness in user interviews, it still needs to be improved in comfort. However, even if these results are not as good as the conventional interfaces, we need to experiment much before we will find new efficient interfaces for CAD applications. For future works, to enhance comfort of the GaFinC, we plan to apply the one-hand gesture control interface based on the participant interviews indicating a two-hand interface interfered with comfort. Recently, various tools optimized for tracking fingers, such as ‘leap motion’  [20], have been introduced. Because of its high tracking resolution and speed, the integration of this finger tracking technology into the GaFinC can be expected to improve performance as well. Finally, owing to the success of the multi-modal interface using gaze tracking for point of interest selection, we will continue to improve this component of the interface using a fixed type commercial gaze tracker for user convenience and high resolution and speed.