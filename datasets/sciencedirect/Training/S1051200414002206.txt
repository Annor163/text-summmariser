@&#MAIN-TITLE@&#
A noise resistant image matching method using angular radial transform

@&#HIGHLIGHTS@&#
A new improved distance measure for angular radial transform (ART) is developed.Recognition performance of the proposed method is better than the Euclidean distance measure.The proposed similarity measure provides excellent recognition performance on noisy images.The performance of ART is comparable or better than the Zernike moments (ZMs) features.ART is very fast and simple to implement than ZMs.

@&#KEYPHRASES@&#
Angular radial transform,Image matching,Image recognition,Noise robustness,Rotation invariance,

@&#ABSTRACT@&#
In this paper, we extend the concept of the optimal similarity measure, originally developed for Zernike moments (ZMs) which belong to a class of orthogonal rotation invariant moments (ORIMs), to angular radial transform (ART) which is non-orthogonal. The proposed distance measure not only uses the magnitude of the ART coefficients but also incorporates phase component unlike the existingL1-distance andL2-distance measures which use only the magnitude of ART in image matching problems. Experimental results show that the new distance measure outperformsL2-distance measure. The performance of the proposed method is highly robust to Gaussian noise and salt-and-pepper noise even at very high level of noise. The results are compared with the ZMs-based optimal similarity measure. It is shown that the recognition rate of the proposed distance measure is comparable to that of the ZMs, however, at very low computational complexity.

@&#INTRODUCTION@&#
Angular radial transform (ART) [1] is a region-based shape descriptor among several rotation invariant descriptors such as Zernike moments (ZMs) [2], pseudo-Zernike moments (PZMs) [3], orthogonal Fourier-Mellin moments (OFMMs) [4], polar harmonic transforms (PHTs) [5], and several other rotation invariant moments and transforms (RIMTs) [6–8]. Although it is non-orthogonal unlike the other stated moments and transforms, it has two major advantages over others: its low computation complexity and better numerical stability. In addition to providing rotation invariance, it can be made translation and scale invariant after some geometric transformation. Being a region-based shape descriptor, it provides noise resilience capability. Due to its several attractive characteristics, MPEG-7 has adopted it as a region-based shape descriptor for image retrieval [9]. Also, these properties of ART have led to its wide applications in many image processing and pattern recognition domains, such as shape retrieval [10], video security systems [11], logo recognition system [12], and image watermarking [13]. In order to reduce its computational complexity, fast algorithms [14,15], have been developed to make it most suited for several real time applications where rotation invariant global shape descriptors are required.A shape matching or image retrieval problem requires an effective similarity measure for its good performance. The existing similarity measures for the RIMTs features are based on the magnitude of the moments because they are rotation invariants. Normally,L1-distance,L2-distance (Euclidean distance), Chi-square distance and other similarity measures are used for the classification purpose. These are very fast and simple to use. However, the magnitude based similarity measures do not involve the phase component because it is not rotation invariant. It has been observed by Oppenheim and Lim [16] and Shao and Celenk [17] that the phase information is more effective than the magnitude of a signal in shape representation. Keeping this observation in view, many attempts have been made to incorporate phase information in representing features for pattern matching applications [18–21]. In particular, the approach developed by Revaud et al. [18] is very effective as compared to the classical and new similarity measures. In their approach, a new similarity measure, called optimal similarity measure, involving ZMs of two images being matched is obtained. This is based on the minimisation process of an error function representing distance between the reconstructed signals of the two images. Although the theory developed for the optimal similarity measure is based on the orthogonality of moments, we show that the method can be extended to non-orthogonal moments as well. In this paper, we derive an improved distance measure which involves both the magnitude and phase of ART coefficients following the concepts contained in the optimal similarity measure. The proposed distance measure is sub-optimal because it is not based on the orthogonality property of image signals. Motivated by the high recognition performance of optimal similarity measure for ZMs and the attractive features of the ART, the performance of the improved distance measure of the ART is compared with the commonly used classicalL2-distance measure. The performance of the new distance measure is also compared with ZMs features using optimal similarity measure for which the algorithm was originally developed. The performance of the proposed distance measure is observed to provide excellent recognition rates on noisy images corrupted by white Gaussian noise (on grayscale images) and salt-and-pepper noise (on binary images). Detailed experiments are performed to analyse the performance of ART and compare its results with ZMs. A note on its extension to color images is also presented.The rest of the paper is organised as follows. An overview of ART is discussed in Section 2. The optimal similarity measure for ART is developed in Section 3. Detailed experimental analysis is carried out in Section 4. Section 5 presents conclusion.The ART of a functionf(r,θ)of order n and repetition m on a unit disk is defined by [1](1)Anm=1π∫02π∫01f(r,θ)Vnm⁎(r,θ)rdrdθ,where n is a non-negative integer, m is an integer,Vnm⁎(r,θ)is the complex conjugate of the kernel functionVnm(r,θ)which itself is defined by(2)Vnm(r,θ)=Rn(r)ωm(θ).The kernel functionsVnm(r,θ)are separable into radial functionRn(r)and angular functionsωm(θ)with(3)ωm(θ)=ejmθ,wherej=−1. The radial functionsRn(r)are defined by(4)Rn(r)={1,ifn=02cos⁡(πnr),otherwise.We observe that the angular functionsωm(θ)are orthogonal while the radial functions are not orthogonal, because(5)∫02πωm(θ)ωm′⁎(θ)dθ=2πδmm′and(6)∫01Rn(r)Rn′⁎(r)rdr={14,ifn=n′12π2[(−1)n+n′−1(n+n′)2+(−1)n−n′−1(n−n′)2],otherwise,whereδmm′=1, ifm=m′and 0, otherwise.ART for digital images: The ART coefficients defined by Eq. (1) pertain to a continuous signal. On the other hand, the image signals are digital and defined over a rectangular domainM×Nwith M rows and N columns. For simplicity we take a square image of sizeN×N. Since the transform coefficients are computed on a unit disk, the following mapping converts the digital domain into a unit disk:(7)xi=2i+1−ND,yk=2k+1−ND,i,k=0,1,...,N−1whereD={N,for inner unit diskN2,for outer unit diskThe coordinate of the centre of the pixel(i,k)is given by(xi,yk)which occupies the area(8)[xi−Δx2,xi+Δx2]×[yk−Δy2,yk+Δy2],whereΔx=Δy=2D.A choice of D depends whether one uses inner unit disk (D=N) or the outer unit disk (D=N2). Figs. 1(a), 1(b) and 1(c)show an8×8pixel grid, the inner unit disk mapping and the outer unit disk mapping, respectively. In many pattern recognition problems it is observed that the outer unit disk mapping provides better performance than the inner unit disk mapping [22,23]. In our experiments, we have not observed much difference in the performance between the two mappings, therefore, we use inner unit disk mapping in all our experimental setups.Since it is difficult to find an analytical solution to the double integration involved in Eq. (1), the zeroth order approximation is generally used to find transform coefficients after converting the polar form of Eq. (1) into its Cartesian equivalent, i.e.(9)Anm=1π∑i=0N−1∑k=0N−1xi2+yk2≤1f(xi,yk)Vnm⁎(xi,yk)ΔxΔy=4πD2∑i=0N−1∑k=0N−1xi2+yk2≤1f(xi,yk)Vnm⁎(xi,yk),whereVnm⁎(x,y)is the complex conjugate ofVnm(x,y)which can be obtained from Eq. (2) by replacingr=x2+y2andθ=tan−1⁡(y/x).Normally, a distance-based measure such as theL1-distance and theL2-distance (Euclidean distance) are used to measure similarity between two patterns. For this purpose the magnitude of the transforms are used because they are rotation invariant. LetAnmandAnmrdenote the transform coefficients of the original and rotated images, then it can be shown that(10)Anmr=Anme−jmθ,where θ is the angle of rotation. The relationship between the magnitude and phase components are given by(11)|Anmr|=|Anm|,ϕnmr=ϕnm−mθ,whereϕnm=arg⁡(Anm), andϕnmr=arg⁡(Anmr)are the phase components.It is given by:(12)dE2=∑n=0nmax∑m=−mmaxmmax(|Anm|−|Anmr|)2.wherenmaxandmmaxare the maximum order and repetition of moments/transforms.The optimal similarity measure for ORIMs is a recently developed similarity measure which considers both the magnitude and phase of ZMs while matching two patterns [18]. The method is developed for ZMs feature based on their orthogonal property, but it can be applied to any orthogonal rotation invariant moments and the transforms. We show that the concept of the method can be extended to non-orthogonal rotation invariant moments (non-ORIMs) and transforms as well, such as the ART. Let I and J denote two images. If J is a rotated version of I with rotation angle θ between them, then the ART coefficients between them will have the relationship(13)AnmJ=AnmIe−jmθ.Therefore, if we know the rotation angle θ, we can modify transform coefficients of the image J, represented byAnmJC:(14)AnmJC=AnmJejmθ.Now, let us define a distance measured(θ)(15)d(θ)=∑n=0nmax∑m=−mmaxmmax|AnmI−AnmJC|2.We view the distance functiond(θ)in Eq. (15) from another perspective as follows. The transform coefficientsAnmIandAnmJCare vector quantities. The quantity (AnmI−AnmJC) is also a vector representing the difference in the transform coefficients. The quantitiesAnmJCare the transform coefficients of the image J which is being rotated by an angle θ to provide the best alignment with the image I. Therefore, our objective is to find the angle θ which minimises the sum of squares of the magnitude of these differences. It is further observed that the form of Eq. (15) for the ART (which is non-orthogonal) is the same which is obtained for ZMs (which is orthogonal) (refer first line of Eq. (8) of Ref. [18]). Since the distance functiond(θ)for the ART has been obtained intuitively without considering the orthogonality, the distance measure is sub-optimal. The only noticeable difference between the distance function obtained for ART and ZMs is the presence of the termπp+1in the distance function of the ZMs which arises because of the normalisation process of ZMs to make them orthonormal.In essence, Eq. (15) determines the distance between ART coefficients of two images which is a function of the rotation angle θ for a givennmaxandmmax. We minimise the value ofd(θ)for finding the minimum distance between the two images. It is shown by [18] that there exist several local minima and our objective is to find the global minimum. Letθ=θ0denote the global minimum. Therefore, if the two images are the same (but rotated versions of each other), thend(θ0)will be very small as compared to its value when the two images are dissimilar. Thus, the problem is to find the global minimum which is obtained as follows.Finding global minimum: Using the property of a complex number Z, that is|Z|2=ZZ¯, and by expressing Z in the polar form, the functiond(θ)from Eq. (15) is expanded as [18]:(16)d(θ)=∑n=0nmax∑m=−mmaxmmax[|AnmI|2+|AnmJ|2−2|AnmI||AnmJ|cos⁡(mθ+ϕnmJ−ϕnmI)].It is noted that Eq. (16) reduces to Eq. (12), the Euclidean distance measure, ifmθ=ϕnmI−ϕnmJwhich is same as Eq. (11).The derivative ofd(θ)is(17)d′(θ)=4∑n=0nmax∑m=1mmaxm|AnmI||AnmJ|sin⁡(mθ+ϕnmJ−ϕnmI).The global minimum is obtained by solving Eq. (17) for all possible roots ofd′(θ)=0which are2nmaxin numbers [18],nmaxroots each belonging to the local minima and local maxima. It is shown in [18] that these roots lie in the intervals[θn,θn+1]whereθn=nπ2nmax,n=0,1,...,4nmax−1.The following steps are followed to find the global minimum.i)Findd′(θ)forθn=nπ2nmax,n=0,1,...,4nmax−1.Compute the rootθrootin the interval[θn,θn+1].θroot=θn+π2nmax×d′(θn)(d′(θn)−d′(θn+1)).It is mentioned here that a root exists in the interval[θn,θn+1]ifd′(θn)d′(θn+1)≤0.Find the value of the functiond(θ)atθroot, i.e.d(θroot).Repeat Steps ii) and iii) for each interval.The global minimum will lie at that root for whichd(θroot)is the minimum.The above procedure is very simple to implement. It is observed that the actual number of roots of Eq. (17) is very small. It is observed empirically that this value lies between 8 and 10 fornmax=mmax=8. Therefore, the computational cost can be reduced by testing the conditiond′(θn)d′(θn+1)≤0.The ART coefficients can be computed efficiently using recurrence relations for the radial and angular kernel functions and by using their 8-way symmetry/anti-symmetry property in a way as used for polar harmonic transform [24] and ZMs [25]. The recurrence relations for the radial kernel functions are given bycos⁡(πnr)=cos⁡(π(n−1)r)cos⁡(πr)−sin⁡(π(n−1)r)sin⁡(πr)sin⁡(πnr)=sin⁡(π(n−1)r)cos⁡(πr)+cos⁡(π(n−1)r)sin⁡(πr),wheren=1,2,3,…,nmaxandcos⁡(0)=1,sin⁡(0)=0. This needs computation ofcos⁡(πr)andsin⁡(πr)using trigonometric functions only once and the higher order radial functions are computed without the involvement of the trigonometric functions which are very expensive as compared to these recurrence relations. The angular functionsejmθ=cos⁡(mθ)+sin⁡(mθ)can also be evaluated in a similar way as used for the radial functions. An 8-way symmetry/anti-symmetry property of these kernel functions enhances the speed of computation upto 87.5% approximately [24].We conduct various experiments to demonstrate the effectiveness of the proposed distance measure developed for ART. Its performance is compared with theL2-distance-based (Euclidean distance) measure. Since the optimal similarity measure was originally developed for ZMs features based on the orthogonality property of kernel functions, the comparison of the proposed method with the performance of ZMs based measure will provide an insight into its effectiveness. Also theL2-distance measure using ZMs magnitude is also included in the comparative performance analysis. Thus, we implement four approaches to compare their recognition performance. These four approaches are:i)ZM_MAG: TheL2-distance of ZMs magnitude similarity measure.ZM_OPT: The optimal similarity measure using ZMs features [18].ART_MAG: TheL2-distance of ART magnitude similarity measure.ART_SUBOPT: This is the proposed method based on the improved distance measure.The above approaches have been implemented in Microsoft's Visual C++ 6.0 under Windows environment on a PC with 2.13 GHz CPU and 3 GB RAM. The various experiments are conducted on two databases (DBs): COIL-20 which consists of grayscale images and MPEG-7 which represents binary images. The description of these two DBs and the constructed DBs for performing recognition tests on different subjects, rotation invariance and robustness to noise, are given as follows.i)COIL-20 DB[26]: The COIL-20 database is one of the best known benchmarks for grayscale object recognition algorithms. It consists of 1440 grayscale images of 20 objects, each of size128×128pixels. The objects have a wide variety of complex geometric and reflectance characteristics. The objects have been captured by placing them on motorised turntable against a black background. The turntable was rotated through 360 degrees to vary object pose with respect to a fixed camera. Images of the object were taken at pose intervals of 5 degrees. This corresponds to 72 images per object.MPEG-7 DB[27]: The MPEG-7 DB used in our work is MPEG-7 CE Shape-1 Part B. It is a shape database consisting of 70 subjects of different shapes (shape categories). There are 20 images of each subject, thus resulting into a database of 1400 images. All images are binary images with variable size. We normalise the size of each image to128×128pixels for our experimental set up.The following DBs have been created to perform the experiments for recognition of objects in normal condition (subject DBs), under rotation (rotation DBs) and under noisy conditions (noise DBs).a)Subject DBs: Both the DBs are divided into test and training DBs. The number of images in training and test DBs is equal. Thus the test and training DBs of COIL-20 and MPEG-7 consists of 720 and 700 images, respectively. The selection of images in these DBs is performed randomly.Rotation DBs: We rotate all the test images (720 for COIL-20 and 700 for MPEG-7) from 10° to 90° with an interval of 10° and also include the rotation at 45°. The training DBs consists of all non-rotated images as used in the subject DBs (720 for COIL-20 and 700 for MPEG-7).Noisy DBs: Since the nature of images are different in both the DBs (grayscale images of COIL-20 and binary images of MPEG-7), the type of noise added in both the DBs is also different. We add Gaussian noise in grayscale images of COIL-20 and salt-and-pepper noise is added to binary images of MPEG-7. All the test images of COIL-20 DB are corrupted by additive white Gaussian noise with zero mean and five levels of variance:σ=0.01,0.02,0.10,0.20,and0.30. The test images of MPEG-7 DB are corrupted by salt-and-pepper noise with noise densities 5% through 25% at an increment of 5%. All the training images of both the DBs are noise free images as used in subject DBs.The selection of optimum number of ART and ZMs coefficients which provides a “good” tradeoff between recognition rate and computation complexity is a very important task. The higher is the number of ART/ZMs coefficients, the better will be the recognition rate. However, after reaching a certain number of transform/moments coefficients, the improvement in recognition rate is marginal. It is so because the low order transform/moments coefficients represent the gross aspects of the image while the high order coefficients represent the fine details. Moreover, the high order coefficients are numerically unstable and susceptible to image noise. Therefore, only a few number of low order ART/ZMs coefficients are selected for image description. For this purpose, we conduct experiments on the subject DBs of COIL-20 and MPEG-7, for the classical magnitude based similarity measure (ART_MAG) and the improved distance measure (ART_SUBOPT). Fig. 2represents the recognition rate as a function of ART order and repetition for COIL-20 subject DB. The experiments are repeated for MPEG-7 subject DB and the results are shown in Fig. 3. It is observed from Fig. 3 that the recognition rate increases sharply in the beginning as the order and repetition increase and it reaches a plateau beyondnmax=mmax=6. Therefore, we takenmax=mmax=6for all our experiments involving ART features. For the selection of ZMs features, we plot the recognition rate versus ZMs features for both the COIL-20 subject DB and MPEG-7 DB which are shown in Figs. 4 and 5, respectively. We have also noted that in most of the pattern matching problems using ZMs, the moment ordernmax=12is considered [18,19] for selecting features. We also observe from these figures that the recognition rate atnmax=12for ZMs reaches to its saturation. Thus, we takenmax=12for ZMs features. Moreover, the number of the ART coefficients atnmax=mmax=6is the same as that of ZMs coefficients which is 49. Therefore, when we compare recognition results between ART and ZMs features, we will have the same number of features for the comparison.The recognition performance on the subject DBs of COIL-20 and MPEG-7 are performed and the results are shown in Table 1.It is observed that the three algorithms: ZM_MAG, ZM_OPT, and ART_SUBOPT provide 100% recognition results rates on COIL-20 subject DB. The algorithm ART_MAG is slightly less efficient and provides a recognition rate of 99.86%. The reason for the high recognition rate is due to the fact that there are only 20 subjects in the DB and each subject has 36 different views both in the training and test DBs. Therefore, a high recognition rate is expected to be achieved by these effective region-based descriptors. When the recognition rates are compared for MPEG-7 DB, we observe that the recognition rates for all four algorithms (ZM_MAG, ZM_OPT, ART_MAG, and ART_SUBOPT) are almost the same, i.e. between 83.43% to 83.86%. However, the optimality/sub-optimality based similarity methods provide slightly better recognition results.The additive white Gaussian noise with zero mean and the five levels of noise varianceσ=0.01,0.02,0.10,0.20,and0.30are added with the 720 test images of COIL-20 DB. The four sample images with these noise levels are shown in Fig. 6. The recognition rates for the four methods are depicted in Fig. 7. It is shown in the figure that the proposed similarity measures provide very good recognition rates even under very high levels of noise. For example, the method ART_SUBOPT provides recognition rates of 80.83% at noise levelσ=0.3, whereas the method ART_MAG provides recognition rates of 24.03% at the same level of noise. At the same level of noise these values for ZM_OPT and ZM_MAG are 87.36%, and 32.33%, respectively. This demonstrates the robustness of the proposed similarity measure against Gaussian noise.The experiment is repeated for MPEG-7 noisy DB. The noise-free images are binary images. Therefore, we add salt-and-pepper noise in test images with noise densities 5% to 25% at an increment of 5%. Four MPEG-7 noise-free and noisy images with different noise densities are shown in Fig. 8. The recognition rates are shown in Fig. 9. It is observed that the drop in recognition rate at various noise levels using proposed similarity measure is less than theL2-distance based measure. The recognition rate obtained by ART_MAG drops from 83.43% to 65.14%, while for ART_SUBOPT the recognition rate drops from 83.86% to 78.14%. That is, the percentage drop for ART_MAG is 18.29% and for ART_SUBOPT it is only 5.72% at noise level of 25%. The trend in the drop in the recognition rate using ZM_MAG and ZM_OPT is similar. However, the respective decrease in recognition rates is slightly lower than ART.We perform two sets of experiments: one on the rotated DB of COIL-20 and the other on the MPEG-7's rotated DB. The recognition rates for COIL-20 rotated DB are shown in Fig. 10. It is observed from the figure that all four methods provide 100% recognition rate except for the method ART_MAG which has a slightly less recognition rate of 99.86%. It is also observed that all methods are rotation invariant and on the COIL-20 DB, the rotation angle does not affect their performance. The recognition results for MPEG-7 rotation DB are shown in Fig. 11. It is observed from the figure that the proposed similarity measure provides better recognition rates than theL2-distance-based similarity measure for all angles of rotation.We can compute the order of time complexity in terms of image sizeN×N, maximum order and repetition,nmaxandmmax, when all transform coefficients are required to be computed. It is clear from Eqs. (1) and (2) that the time complexity of all transform coefficients isO(N2nmaxmmax). The computation of the radial functionsRn(r)and angular functionse−jmθare straightforward. If 8-way symmetry/anti-symmetry of the kernel functions and their recursive relations are used, then the total time requirements can be reduced by 87.5% approximately. For this purpose, a method similar to that developed in [24] for polar harmonic transforms can be used. On the other hand, the computation of all ZMs up to a maximum ordernmaxhas a time complexity of the orderO(N2nmax3). If fast algorithms are used for the computation of ZMs, then its time complexity reduces toO(N2nmax2)which is one order less innmaxthan the non-recursive method [25]. In addition, the derivation of the radial kernel functions of ZMs involves much more operations than that of the ART. We compute all ZMs and all ART coefficients as a function of number of moments/transform L, whereL={∑n=0nmax∑m=0n−m=evenn(1)forZMs∑n=0nmax∑m=0mmax(1)forART.We further assumenmax=mmaxfor ART while computing L. Since the computation time does not depend on image contents, only one database (COIL-20) is considered for the time analysis. The fast algorithms with 8-way symmetry/anti-symmetry are used for both ART and ZMs. The moments and transform are computed for 1440 images each of them are of the size128×128. The total CPU elapse time is plotted as a function of L in Fig. 12. It is observed that the computation of ART is much faster than ZMs. Therefore, ART can be used for fast image matching applications in comparison to ZMs using the proposed similarity measure.The proposed method works well for the binary and grayscale images. The method can be extended to color images by deriving the ART coefficients for each component of the color image and then defining distance function as the sum of the three distance functions applied on each component. Let the color images be represented in the RGB color space, then the distance functiond(θ)is defined by(18)d(θ)=∑n=0nmax∑m=−mmaxmmax(|AnmI−AnmJC|R2+|AnmI−AnmJC|G2+|AnmI−AnmJC|B2)Rest of the steps of the computation would be similar to the ones used for the binary or grayscale images. It is worth mentioning here that the major time in the whole process is taken for the derivation of the minimum of the functiond(θ)as compared to the time taken for the computation of the ZMs. Hence, its straightforward extension to color image will not be much computation intensive.Another promising novel approach could be to first deriving a gradient image of a color image using the De Zenzo method [28] for the derivation of gradient of a vector quantity, where each pixel of a color image represents a vector having three components, say, R,G, and B. This approach would reduce the computation of the ART coefficients from three components to one. However, it is a matter of experimental analysis to find the effect of noise on the gradient image and thereby its impact on the matching performance.The method can also be extended to other color spaces such asHSV,YCbCr,L⁎a⁎b, and XYZ whose description and conversion from one space to another are given in [29]. The relative performance of color image matching in these color spaces is a matter of further exhaustive investigation and experimentation and our future work will be focused in this direction.

@&#CONCLUSIONS@&#
