@&#MAIN-TITLE@&#
Participant retention in an automated online monthly depression rescreening program: Patterns and predictors

@&#HIGHLIGHTS@&#
A total of 2,539 participants enrolled in monthly screening study.Of the participants, 33.8% completed 1+ follow-up, and 22.9% completed 2+ follow-ups.Completion of early follow-ups predicts future completions; reverse is also true.Predictors of follow-ups included depression, employment, help seeking, and education.

@&#KEYPHRASES@&#
Online screening,Mental health,International,Attrition,

@&#ABSTRACT@&#
Internet-based mental health resources often suffer from low engagement and retention. An increased understanding of engagement and attrition is needed to realize the potential of such resources. In this study, 45,142 individuals were screened for depression by an automated online screener, with 2,539 enrolling in a year-long monthly rescreening study; they received a single monthly reminder e-mail to rescreen their mood. We found that, even with such a minimal cohort maintenance strategy, a third of the participants completed 1 or more follow-ups, and 22% completed 2 or more follow-ups. Furthermore, completion of earlier follow-ups was highly predictive of future completions. We also found a number of participant characteristics (e.g., current depression status, previous depression treatment seeking, and education level) predicted follow-up rates, singly or in interactions.Internet-based resources for mental health, such as interventions, screening, and other similar services, are proliferating rapidly, providing individuals with opportunities to access mental health resources and services even in places where traditional services are not available or accessible. Compared to traditional face-to-face mental health resources, their online counterparts are inexpensive to develop, highly scalable, and widely accessible (Muñoz, 2010), with an ability to offer personalized information that is responsive to individuals' needs and preferences (Leykin et al., 2012c). Importantly, Internet-based resources can be effective. Recent meta-analyses have demonstrated the effectiveness of Internet interventions for mental disorders, such as depression and anxiety (Andersson and Cuijpers, 2009; Andrews et al., 2010; Griffiths et al., 2010; Spek et al., 2007a,b; Van't Hof et al., 2009); evidence for efficacy also exists for a variety of other conditions such as substance abuse (Chiauzzi et al., 2005; Strecher et al., 2005; Muñoz et al., 2009), obesity (McConnon et al., 2007), diabetes (McKay et al., 2001), insomnia (Ritterband et al., 2009), chronic pain (Nevedal et al., 2013), and irritable bowel syndrome (Hunt et al., 2009).Most Internet-based resources, especially interventions, rely on consistent engagement from participants, both for evaluation of their efficacy (usually via a clinical trial) as well as for overall effectiveness. As with most interventions, more engagement likely leads to greater effectiveness (An et al., 2008; Palmqvist et al., 2007; Richardson et al., 2013). However, concern about poor retention has dampened the enthusiasm about Internet-based interventions (Christensen et al., 2005; Farvolden et al., 2005; Danaher et al., 2006; Eysenbach, 2005), with some researchers suggesting that high attrition may be inherent in eHealth trials (Eysenbach, 2005); attrition is especially problematic with “unguided” interventions, that is, interventions with little to no human interaction (Christensen et al., 2004, 2005; Muñoz et al., 2012). Attrition is certainly not unique to the online medium—the modal number of therapy session is low (Connolly Gibbons et al., 2011), and dropout is considerable (Hamilton et al., 2011).For Internet-based services to remain relevant and useful, increasing retention and adherence rates is essential. To counteract attrition in efficacy trials, researchers often use either financial incentives or live (e.g., phone-based) follow-up as cohort maintenance strategies (Carlbring et al., 2006; Muñoz et al., 2009). However, both of these approaches introduce significant undesirable confounds. Paying participants to visit the site or to provide data exposes participants to powerful extrinsic motivators which will not be present when the intervention is widely deployed. Indeed, the introduction of such motivators can result in undesirable behaviors, such as attempts to “cheat” by registering multiple fake accounts (Prince et al., 2012). Thus, with financial incentives, the ecological validity is reduced and engagement (and efficacy) of an un-incentivized intervention remains unknown. The same argument applies to the provision of phone-based follow-ups: although these may be effective (Fridrici et al., 2009; Leykin et al., 2012a; Muñoz et al., 2009), they once again introduce variables that will not be present when an intervention is deployed. Instead of relying on these problematic strategies, improving retention should be achieved through attaining a better understanding of it (Eysenbach, 2005; Geraghty et al., 2012) and through offering useful and appealing products.The present report describes retention in an Internet-based mood and depression screener, where participants were asked to return to the site monthly for the next 12months to rescreen their mood. In an attempt to understand the naturalistic rate of retention, participants were offered no incentives, financial or otherwise, no “live” contact, and no reminders to return beyond the single monthly invitation e-mail. Although many participants did not return for a follow up screening, as expected, a considerable proportion did return at least once. We examine the pattern of retention, as well as explore the predictors of greater retention, with an overall goal of offering data that could be helpful for the designers of Internet-based services who wish to improve retention and adherence.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
