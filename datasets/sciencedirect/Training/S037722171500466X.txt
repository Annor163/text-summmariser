@&#MAIN-TITLE@&#
Fast local search for single row facility layout

@&#HIGHLIGHTS@&#
We consider the single row facility layout problem (SRFLP).Neighborhood exploration procedures with time complexity O(n2) are proposed.Insertion-based local search (LS) algorithm is embedded into the VNS framework.Numerical results are reported for SRFLP instances of size up to 300 facilities.Results show that the speedup provided by our LS algorithms is rather spectacular.

@&#KEYPHRASES@&#
Combinatorial optimization,Single row facility layout,Local search,Variable neighborhood search,

@&#ABSTRACT@&#
Given n facilities of prescribed lengths and a flow matrix, the single row facility layout problem (SRFLP) is to arrange the facilities along a straight line so as to minimize the total arrangement cost, which is the sum of the products of the flows and center-to-center distances between facilities. We propose interchange and insertion neighborhood exploration (NE) procedures with time complexity O(n2), which is an improvement over O(n3)-time NE procedures from the literature. Numerical results show that, for large SRFLP instances, our insertion-based local search (LS) algorithm is two orders of magnitude faster than the best existing LS techniques. As a case study, we embed this LS algorithm into the variable neighborhood search (VNS) framework. We report computational results for SRFLP instances of size up to 300 facilities. They indicate that our VNS implementation offers markedly better performance than the variant of VNS that uses a recently proposed O(n3)-time insertion-based NE procedure.

@&#INTRODUCTION@&#
An active line of research in the area of combinatorial optimization is concerned with developing various algorithms for a wide set of problems whose solutions are permutations. An important member of this set is the single row facility layout problem (SRFLP for short). Given a number of facilities and the flows between them, the SRFLP is to arrange the facilities along a straight line so as to minimize the total arrangement cost, which is the sum of the products of the flows and center-to-center distances between facilities. Suppose that there are n facilities having lengthsL1,…,Ln,respectively. LetW=(wij)be a symmetric n × n matrix whose entry wijrepresents the flow of material between facilities i and j. Our intention in this paper is to deal with a version of the SRFLP where clearances between facilities, denoted as γij,i,j∈{1,…,n},i ≠ j, are not all equal to a (nonnegative) constant value. We emphasize that our approach to the SRFLP is applicable even when the matrix of clearances,Γ=(γij),is not assumed to be necessarily symmetric. Because of this, and also to avoid losing the generality of the SRFLP formulation, we do not require symmetry in the matrix Γ. Certainly, the main diagonal of Γ is zero, and all other entries are nonnegative. With these notations, the SRFLP can be expressed as(1)minp∈ΠF(p)=∑k=1n−1∑l=k+1nwp(k)p(l)dp(k)p(l),where Π is the set of all permutations of{1,…,n},p(k) is the facility in the k-th position of permutation p, and dp(k)p(l) is the distance between the centroids of facilities p(k) and p(l). Let us assume that k < l. Then the distance is calculated according to the following equation:(2)dp(k)p(l)=Lp(k)/2+∑m=k+1ifl>k+1l−1Lp(m)+Lp(l)/2+∑m=kl−1γp(m)p(m+1).We note that the formulation (1)–(2) was used by Datta, Amaral, and Figueira (2011) in their paper on a genetic algorithm approach to single row facility layout.The SRFLP is a challenging research problem which has several real-life applications. In the area of flexible manufacturing systems, it models the linear layout of machines within manufacturing cells. In this type of layout, the machines are placed along a straight path travelled by an automated guided vehicle (Heragu & Kusiak, 1988). Other applications of the SRFLP include arranging a number of rooms on one side of a corridor in supermarkets, hospitals and office buildings (Simmons, 1969), arranging books on a shelf in a library (Picard & Queyranne, 1981), and design of warehouse layouts (Picard & Queyranne, 1981).Because of the practical importance of the SRFLP, considerable attention has been given to the development of algorithms for its solution. Existing exact methods for the SRFLP include branch-and-bound (Simmons, 1969), dynamic programming (Picard & Queyranne, 1981), mixed-integer linear programming (Amaral, 2006, 2008; Heragu & Kusiak, 1991), cutting plane (Amaral, 2009), branch-and-cut (Amaral & Letchford, 2013), and semidefinite programming approaches (Anjos & Vannelli, 2008; Hungerländer & Rendl, 2013). Branch-and-bound (Palubeckis, 2012) and semidefinite programming (Hungerländer, 2014) algorithms were also applied for solving a special case of the problem in which all facilities have the same length. A computational comparison of the state-of-the-art exact methods for the SRFLP is given in the paper by Hungerländer and Rendl (2013). They report that the largest SRFLP instance solved to prove optimality involves 42 facilities. For the purpose of finding good but not necessarily optimal solutions for larger instances of the problem, a number of heuristic algorithms have been developed.The fastest methods to generate feasible solutions for large-scale SRFLP instances are construction heuristics. Among them, a greedy-like algorithm of Heragu and Kusiak (1988) and an iterative construction procedure of Djellab and Gourgand (2001) can be mentioned. However, it is widely acknowledged that construction heuristics are not able to produce solutions of high quality. They can be applied in situations where computation time is a critical factor.Another group of heuristic algorithms construct a permutation of facilities from the results obtained by solving either a mixed-integer or a semidefinite program (SDP). In particular, an algorithm relying on a mixed-integer programming model was presented by Heragu and Kusiak (1991). Recently, Amaral and Letchford (2013) have proposed an approach which allows obtaining a suboptimal solution as a byproduct of the branch-and-cut method. The crux of their approach is the use of a multi-dimensional scaling technique. Anjos, Kennings, and Vannelli (2005) were the first who proposed an SDP-based heuristic to produce a single row facility layout. The same strategy to obtain solutions to the SRFLP was followed by Anjos and Yen (2009) and Hungerländer and Rendl (2013).The other way to approach the problem is to use metaheuristic search methods. The application of metaheuristics for the SRFLP dates back at least to Romero and Sánchez-Flores (1990) and Heragu and Alfa (1992), who developed simulated annealing algorithms for the problem. de Alvarenga, Negreiros-Gomes, and Mestria (2000) proposed another simulated annealing implementation for the SRFLP. The same authors also presented a tabu search algorithm and tested both metaheuristics on a small set of instances of size n ≤ 30. More recent variants of tabu search strategy were proposed by Samarghandi and Eshghi (2010) and Kothari and Ghosh (2013a). Solimanpur, Vrat, and Shankar (2005) developed an ant algorithm for the SRFLP. Teo and Ponnambalam (2008) investigated a hybrid approach, combining ant colony optimization and particle swarm optimization (PSO) techniques. A pure PSO algorithm for the problem was proposed by Samarghandi, Taabayan, and Jahantigh (2010). Recently, Kothari and Ghosh (2013b) presented an insertion-based Lin–Kernighan heuristic for producing good quality layouts. The heuristic was shown to be competitive with other high-performance algorithms. There are also several layout methods available which follow the genetic paradigm. These include genetic algorithms of Ficko, Brezocnik, and Balic (2004) and Datta et al. (2011) as well as hybrid genetic algorithms of Ozcelik (2012) and Kothari and Ghosh (2014a). A similar evolutionary technique called the imperialist competitive algorithm was presented by Lian, Zhang, Gao, and Shao (2011). Single row layout algorithms based on the scatter search metaheuristic were proposed by Kumar, Asokan, Kumanan, and Varma (2008) and Kothari and Ghosh (2014b). The second of them was reported to yield very good solutions for popular benchmark SRFLP instances. For recent surveys on the single row facility layout problem, the reader is referred to Anjos and Liers (2012), Hungerländer and Rendl (2013), Keller and Buscher (2015), and Kothari and Ghosh (2012).From the literature, it can be seen that many algorithms for the SRFLP incorporate a local search procedure (Amaral & Letchford, 2013; Heragu & Alfa, 1992; Heragu & Kusiak, 1991; Kothari & Ghosh, 2013a, 2014a, 2014b; Kumar et al., 2008; Ozcelik, 2012; Samarghandi & Eshghi, 2010; Samarghandi et al., 2010; Solimanpur et al., 2005; Teo & Ponnambalam, 2008). Two main types of local searches have been used for this problem (Kothari & Ghosh, 2013b). The first of them is based on pairwise interchanges of facilities (Amaral & Letchford, 2013; Heragu & Alfa, 1992; Heragu & Kusiak, 1991; Kothari & Ghosh, 2013a; Samarghandi & Eshghi, 2010; Samarghandi et al., 2010; Solimanpur et al., 2005; Teo & Ponnambalam, 2008), whereas the second one proceeds by executing insertion moves, where a facility is moved from one position to another in the permutation (Kothari & Ghosh, 2013a, 2014a, 2014b; Kumar et al., 2008; Ozcelik, 2012). The performance of local search (LS) algorithms greatly depends on the neighborhood exploration (NE) procedures (Kothari & Ghosh, 2013a). A straightforward implementation of such a procedure for each type of LS has time complexity O(n4) (Kothari & Ghosh, 2013a). Indeed, for example, in the case of interchange-based LS, there aren(n−1)/2pairs of facilities, and computation of the objective function value for a permutation obtained by interchanging two facilities takes O(n2) operations. Recently, Kothari and Ghosh (2013a) developed NE procedures (for both interchange and insertion neighborhood structures) whose time complexity is O(n3). The algorithms of Kothari and Ghosh (2013a, 2013b, 2014a, 2014b) use these procedures and show good performance compared to other methods in the literature.Many studies on the SRFLP (Amaral and Letchford, 2013; Anjos et al., 2005; Kothari and Ghosh, 2013a, among others) assumed that the clearance between each pair of facilities is equal to a constant value. In such a situation, by adequately adjusting the length of the facilities, zero clearances can be achieved. In this paper, however, our intention is to consider a more general model in which clearances between adjacent facilities are not necessarily all equal. There are two main reasons for such a choice. First, as emphasized by Solimanpur et al. (2005), allowing different clearances is important in real life manufacturing. Solimanpur et al. (2005) listed several factors that affect the clearance spaces required between facilities. They mentioned that an analytic approach, e.g. queuing models or simulation study, can be used to obtain the required data. Second, the assumption of different clearances between facilities adds no principal difficulties to our approach to constructing fast local search algorithms for the SRFLP.The primary motivation of this paper is to develop more efficient neighborhood exploration algorithms than those presented by Kothari and Ghosh (2013a). We propose three NE procedures, one for searching pairwise interchange neighborhoods and the other two for searching insertion neighborhoods. The time complexity of each procedure is O(n2). We present empirical results comparing the performance of our NE procedures against those of Kothari and Ghosh (2013a). We embed these procedures in the variable neighborhood search algorithm for solving the SRFLP. We report on computational experiments on SRFLP instances of size up to 300 facilities.The outline of the rest of the paper is as follows. In Section 2, we rephrase the objective function of the problem and introduce some preliminary notations. In Sections 3 and 4, we propose interchange-based and, respectively, insertion-based local search algorithms for the SRFLP. Their experimental evaluation is presented in Section 5. In Section 6, we provide a case study focused on the application of the variable neighborhood search metaheuristic for the considered problem. Concluding remarks are given in Section 7. Proofs of some results appear in Appendix A.The SRFLP (1)–(2) can be restated using an alternative form of the objective function. To present this form, we fix a permutation p ∈ Π and consider a family of cuts induced by subsets of facilitiesVm={p(k)∣k=1,…,m},m∈{1,2,…,n−1}. Letm∈{1,2,…,n−1}. We call the sumcm=∑k=1m∑l=m+1nwp(k)p(l)the cut value and the vectorC=(c1,…,cn−1)indexed by cuts the cut vector. We defineλr=Lr/2to be the half-length of the facility r,r∈{1,…,n}. With these definitions, the objective function in (1) can be rewritten as follows.Proposition 1For p ∈ Π,(3)F(p)=∑m=1n−1cm(λp(m)+λp(m+1)+γp(m)p(m+1)).Form∈{1,…,n},let us denote byλp(m)left(respectivelyλp(m)right) the left half length (respectively, right half length) of the facility placed in the m-th position in the permutation p. Then F(p), given by (1) and (2), can be rewritten as (for notational simplicity, we assume here and in what follows that a sum is zero if the lower limit of the summation index is greater than the upper limit)(4)F(p)=∑k=1n−1∑l=k+1nwp(k)p(l)×(λp(k)right+∑j=k+1l−1(λp(j)left+λp(j)right)+λp(l)left+∑j=kl−1γp(j)p(j+1))=∑k=1n−1∑l=k+1nwp(k)p(l)×(∑j=k+1lλp(j)left+∑j=kl−1λp(j)right+∑j=kl−1γp(j)p(j+1)).We combine all the terms in (4) containingλp(m)left,m∈{2,…,n}. It can be checked that the resulting expression is(5)λp(m)left∑k=1m−1∑l=mnwp(k)p(l),m∈{2,…,n}.Similarly, all the terms withλp(m)rightcan be combined into a single term:(6)λp(m)right∑k=1m∑l=m+1nwp(k)p(l),m∈{1,…,n−1}.Finally, the terms withγp(m)p(m+1)contribute(7)γp(m)p(m+1)∑k=1m∑l=m+1nwp(k)p(l),m∈{1,…,n−1}.The double summation in (6) (as well as (7)) is equal to the cut value cmand that in (5) is equal to the cut valuecm−1. Thus we can write(8)F(p)=∑m=2nλp(m)leftcm−1+∑m=1n−1(λp(m)rightcm+γp(m)p(m+1)cm).The first summand in (8) is equal to∑m=1n−1λp(m+1)leftcm. Hence(9)F(p)=∑m=1n−1cm(λp(m)right+λp(m+1)left+γp(m)p(m+1)).After getting rid of the “right” and ”left” superscripts in (9), we arrive at (3).□For a permutation p ∈ Π, the components of the cut vector C can be computed using the following recurrence:(10)cm=cm−1−∑k=1m−1wp(m)p(k)+∑l=m+1nwp(m)p(l),m=1,…,n−1,with the initial conditionc0=0. To show (10), we assume that m > 1. From the definition of cm, we have(11)cm=∑k=1m−1∑l=m+1nwp(k)p(l)+∑l=m+1nwp(m)p(l).Adding to and subtracting from the right-hand side of (11) the sum∑k=1m−1wp(k)p(m)gives(12)cm=∑k=1m−1∑l=mnwp(k)p(l)−∑k=1m−1wp(k)p(m)+∑l=m+1nwp(m)p(l).By replacing the double summation in (12) withcm−1we obtain (10).Given a cut vectorC=(c1,…,cn−1),we denote byC−=(c1−,…,cn−)the n-vector with componentsc1−=c1,cm−=cm−cm−1form=2,…,n−1,andcn−=−cn−1. We similarly define a vectorC+:c1+=c1,cm+=cm+cm−1form=2,…,n−1,andcn+=cn−1. We will also use two n × n matrices computed from the lengths of facilities:(λrs−)with entriesλrs−=λr−λs=(Lr−Ls)/2and(λrs+)with entriesλrs+=λr+λs. We will writeD=(drs)to denote the distance matrix, where drsforr=p(k)ands=p(l)is given by (2). The components of the vectorsC−,C+and entries of the matrices(λrs−),(λrs+)are used in formulas to calculate the change in the objective function value resulting from applying a pairwise interchange or insertion move (see (15) and (24)–(27) in the next two sections). In fact, the purpose of the introduction ofC−,C+,(λrs−)and(λrs+)is twofold. First, the above-mentioned formulas become slightly shorter. Second, and more importantly, the usage of the auxiliary arrays and matrices allows us to reduce the execution time of the algorithms based on our approach. For example, at each iteration of interchange-based local search, the vectorsC−andC+are computed only once and then used O(n2) times while examining pairs of n facilities. When vectorsC−andC+are not maintained, then extra addition/subtraction operations are needed. We also note that the matrices(λrs−)and(λrs+)can be precomputed in advance.In the next sections, we derive some formulas related to the LS algorithms. In order to keep them compact, we make the following conventions:p(0)=0,p(n+1)=0,c0=0,cn=0,andγ0r=γr0=0for eachr=1,…,n.In this section, we describe an implementation of the local search algorithm based on a fast procedure for exploring the pairwise interchange neighborhood of a SRFLP solution in the search space. Our aim is to provide an efficient way to compare the quality of two solutions differing in the positions of precisely two facilities. For this purpose, a couple of auxiliary matrices along with some other data are used.For p ∈ Π, let Δ(p, k, l) denote the change in the objective function value that will result from swapping positions of the facilities p(k) and p(l) in the permutation p. Formally, let p′ be the permutation obtained by performing this swapping operation. ThenΔ(p,k,l)=F(p′)−F(p). In order to present a fast method for computing Δ(p, k, l) we introduce two n × n matrices denoted byA=(auj)andB=(buj). Both matrices are associated with a permutation of facilities, say p ∈ Π. The rows of the matrices correspond to facilities and the columns correspond to permutation positions. To define the matrices A and B, we suppose that the facility u is assigned to the m-th position of the permutation p, that is,u=p(m). The entry aujof the matrix A represents the total flow of material between facility u and facilities in the segment of p from position m exclusively to position j inclusively. Formally, foru,j∈{1,…,n}(13)auj={∑i=jm−1wup(i)ifj<m∑i=m+1jwup(i)ifj>m0ifj=m.The entries of the matrix B are computed by summing over the same permutation positions as in the case of the matrix A. The summand for i ≠ j is a product of auiand the distance between the centroids of facilities p(i) and eitherp(i−1)orp(i+1)depending on whether p(i) is to the left or the right of the facility u. Ifi=j,then calculations are performed assuming that u substitutes forp(i−1)(orp(i+1)). Thus, the entry buj,u,j∈{1,…,n},of the matrix B is defined as follows:(14)buj={auj(λu+λp(j)+γup(j))+∑i=j+1m−1aui(λp(i−1)+λp(i)+γp(i−1)p(i))ifj<mauj(λp(j)+λu+γp(j)u)+∑i=m+1j−1aui(λp(i)+λp(i+1)+γp(i)p(i+1))ifj>m0ifj=m.The matrices A and B arise when manipulating the expression for Δ(p, k, l). They also play an important role in constructing fast insertion-based local search algorithms for the problem (see Section 4).Next we provide a formula to calculate the value of Δ(p, k, l).Proposition 2For p ∈ Π,k∈{1,…,n−1},l∈{k+1,…,n},r=p(k),ands=p(l),(15)Δ(p,k,l)=(cl−−ck−+2wrs)(drs+γ1+γ2)+2(br,l−1+bs,k+1)+λrs−(cl+−ck+)+ck−1(γp(k−1)s−γp(k−1)r)+ckγ1+cl−1γ2+cl(γrp(l+1)−γsp(l+1)),whereγ1={γsp(k+1)−γrp(k+1)ifl>k+1γsr−γrsifl=k+1,γ2={γp(l−1)r−γp(l−1)sifl>k+10ifl=k+1.The proof of this result can be found in Appendix A. Notice that in the case of zero clearances between neighboring facilities the right-hand side of (15) becomes much simpler. Indeed, in this case, the last four terms as well as γ1 and γ2 in its first term vanish.Armed with the formula for Δ(p, k, l), we are now ready to present our first local search algorithm for the SRFLP. We start with a description of its main ingredient, a neighborhood exploration procedure, called NE1 (we add the digit 1 at the end of NE to distinguish between this and two other procedures which are provided in the next section).NE1(p,C,C−,C+,A,B,D)1.Set h* ≔ 0.For each pair (k, l),k=1,…,n−1,l=k+1,…,n,do the following:2.1.Computeh=Δ(p,k,l)by Eq. (15).Check whether h < h*. If so, then set h* ≔ h, k′ ≔ k and l′ ≔ l.Ifh*=0,then return with ρ set to 1. Otherwise, perform pairwise interchange of facilities p(k′) and p(l′) in the permutation p, update matrices A, B, D and vectors C,C−,C+used in Δ calculations, and return withρ=0.LS1(p)1.Initialize matrices A, B, D and vectors C,C−andC+.Apply NE1(p,C,C−,C+,A,B,D). Let ρ denote the local optimality flag returned by NE1.Check whetherρ=1. If so, then stop with the solution p. Otherwise, go to 2.An important question that remains to be addressed is how efficiently the entries of the matrices A, B and D can be updated (Step 3 of NE1) after the replacement of p by a permutation p′ chosen from the neighborhood N2(p). Suppose that p′ is obtained from p by interchanging the facilities r and s. Letr=p(k),s=p(l),k < l, andu=p′(m),m∈{1,…,n}. Then, we can write the following formulas that are involved in updating the matrices A, B and D:(16)auj=au,j−1+wup′(j),j>m,(17)auj=au,j+1+wup′(j),j<m,(18)buj=bu,j−1+au,j−1(λp′(j)u−+γp′(j−1)p′(j)−γp′(j−1)u)+auj(λp′(j)u++γp′(j)u),j>m,(19)buj=bu,j+1+au,j+1(λp′(j)u−+γp′(j)p′(j+1)−γup′(j+1))+auj(λp′(j)u++γup′(j)),j<m,(20)dup′(j)=dup′(j−1)+λp′(j−1)p′(j)++γp′(j−1)p′(j),j>m.To show (16), we decompose the right-hand side of (13):auj=∑i=m+1jwup′(i)=∑i=m+1j−1wup′(i)+wup′(j)=au,j−1+wup′(j).Eq. (17) is derived similarly (the first case of the right-hand side of (13) is used). To obtain (18), we apply the same trick with respect to (14):(21)buj=auj(λp′(j)+λu+γp′(j)u)+∑i=m+1j−2aui(λp′(i)+λp′(i+1)+γp′(i)p′(i+1))+au,j−1(λp′(j−1)+λp′(j)+γp′(j−1)p′(j)).Adding to and subtracting from (21) the termau,j−1(λu+γp′(j−1)u)givesbuj=au,j−1(λp′(j−1)+λu+γp′(j−1)u)+∑i=m+1j−2aui(λp′(i)+λp′(i+1)+γp′(i)p′(i+1))+au,j−1(λp′(j)+γp′(j−1)p′(j)−λu−γp′(j−1)u)+auj(λp′(j)+λu+γp′(j)u)=bu,j−1+au,j−1(λp′(j)u−+γp′(j−1)p′(j)−γp′(j−1)u)+auj(λp′(j)u++γp′(j)u).To show (19) we proceed analogously and obtainbuj=auj(λu+λp′(j)+γup′(j))+∑i=j+2m−1aui(λp′(i−1)+λp′(i)+γp′(i−1)p′(i))+au,j+1(λp′(j)+λp′(j+1)+γp′(j)p′(j+1)).Continuing as in the previous case, we find thatbuj=au,j+1(λu+λp′(j+1)+γup′(j+1))+∑i=j+2m−1aui(λp′(i−1)+λp′(i)+γp′(i−1)p′(i))+au,j+1(λp′(j)+γp′(j)p′(j+1)−λu−γup′(j+1))+auj(λu+λp′(j)+γup′(j))=bu,j+1+au,j+1(λp′(j)u−+γp′(j)p′(j+1)−γup′(j+1))+auj(λp′(j)u++γup′(j)).Finally, we prove (20). Using (2), we can compute the distance between facilities u and p′(j)dup′(j)=λu+∑i=m+1j−1Lp′(i)+λp′(j)+∑i=mj−1γp′(i)p′(i+1).Equivalently, we can write(22)dup′(j)=λu+∑i=m+1j−2Lp′(i)+2λp′(j−1)+λp′(j)+∑i=mj−2γp′(i)p′(i+1)+γp′(j−1)p′(j).Replacingλu+∑i=m+1j−2Lp′(i)+λp′(j−1)+∑i=mj−2γp′(i)p′(i+1)in (22) bydup′(j−1),we arrive at (20).The procedure for updating entries of A, B and D related to facilityu=p′(m)is summarized below:1.If m < k, then compute auj,j=k,…,l−1,by (16), buj,j=k,…,n−1,by (18), anddup′(j)=dp′(j)u,j=k,…,n,by (20). Go to 4.If m > l, then compute auj,j=l,l−1,…,k+1,by (17) and buj,j=l,l−1,…,2,by (19). Go to 4.If k < m < l, then set j1 ≔ k and j2 ≔ l. Otherwise, setj1:=m−1,j2:=m+1,aum≔ 0 and bum≔ 0. Compute auj,j=j1,j1−1,…,1,by (17) and buj,j=j1,j1−1,…,2,by (19). Also, compute auj,j=j2,…,n,by (16), buj,j=j2,…,n−1,by (18), anddup′(j)=dp′(j)u,j=j2,…,n,by (20).Stop.Additionally, in Step 3 of NE1, the cut vector C is updated. The computation is based on the following variation of (10):(23)cm=cm−1+ap′(m)n−ap′(m)1,wherem=k,…,l−1.Another remark is that the formulas (16)–(19) and (23) (with p′ replaced by p) can also be used to initialize the matrices A, B and vector C in Step 1 of LS1. Notice that, before applying (16)–(19), the entries ap(j)jand bp(j)jfor eachj=1,…,nmust be set to zero. It is easy to see that the initialization step of the local search algorithm takes O(n2) time.Example 1Let us consider the 5-facility SRFLP instance taken from Simmons (1969). The flows of material between facilities are given by the following matrix:W=[0210120022100630260412340].The vector of lengths of facilities is (1, 3, 4, 6, 7). In order to avoid fractional numbers, we multiply its components by 2. Thus,L1=2,L2=6,L3=8,L4=12,andL5=14. There are no clearances between facilities specified in this instance, so the formula (15) for calculating Δ values becomes simpler.Suppose that LS1 is applied to the permutationp=(3,5,1,2,4)(the corresponding layout is depicted in the left part of Fig. 1). Taking into account the fact that we doubled the length of each facility, the objective function value of the solution p is 386. Step 1 of LS1 initializes the data needed for the procedure NE1. Starting withap(j)j=0for all j and using (16) and (17), the matrix A for p is constructed:A=[210224420203441012622030137].Then, using (18) and (19), the entries of the matrix B can be computed:B=[218083288568018033446817621010222180330834122].The distance matrix corresponding to p is as follows:D=[041913840239121923032111393202181211210].The cut vector isC=(10,14,14,12). From it, we obtain the vectorsC−=(10,4,0,−2,−12)andC+=(10,24,28,26,12). Now, using (15), the value of Δ for each pair of facilities can easily be calculated. For example, consider the second and fifth facilities in the permutation p. In this case,k=2,l=5,r=5,s=4,andλ5,4−=7−6=1. From (15), we obtainΔ(p,2,5)=(−12−4+2·4)21+2(34+22)+1·(12−24)=−68. Other Δ values are calculated similarly:Δ(p,1,2)=−42,Δ(p,1,3)=−16,Δ(p,1,4)=−60,Δ(p,1,5)=16,Δ(p,2,3)=8,Δ(p,2,4)=16,Δ(p,3,4)=12,Δ(p,3,5)=−24,Δ(p,4,5)=−12. The maximum decrease in objective function value is achieved by interchanging the second and fifth facilities in p (the obtained layout is shown in the right part of Fig. 1). In Step 3 of NE1, the matrices and vectors are updated to correspond to the new permutationp=(3,4,1,2,5). This is done using the above given four-step procedure based on formulas (16)–(20). The matrix A takes the following form:A=[100234420206771060026107320].A relevant part of the matrix B is given below (the entries of B in the first and last columns, except bp(1)1 andbp(n)n=bp(5)5,are not used in (15) and are not recalculated by the algorithm; therefore, we replace them by asterisks):B=[*008**5080*06077119**0018**12032200].The new cut vector isC=(10,10,12,10). In the next iteration, NE1 explores the interchange neighborhood of the updated permutation p. This is done in the same way as we have described above.We end the section with the following statement concerning the effectiveness of our approach.Proposition 3The computational complexity of the procedure NE1 is O(n2).First, notice that the vectors C,C−,C+and matrices B and D remain unchanged during execution of Step 2 of NE1. These vectors and matrices are passed as parameters to the procedure. Thus, using (15), Δ(p, k, l) can be computed in Step 2 in constant time. Hence, the complexity of Step 2 of NE1 is O(n2). If h* < 0, then NE1 updates the data used in Δ calculations. These data will be returned to NE1 at the next call to this procedure in Step 2 of LS1. In order to update the matrices A, B and D, Step 3 of NE1 applies the above-described four-step method based on equations (16)–(20). It is clear that, for each facility, this method runs in O(n) time. Therefore, in total, it performs O(n2) operations. Since the vectors C,C−andC+can be updated in linear time using (23), the overall complexity of Step 3, and hence of the entire procedure, is O(n2).□Another strategy in the development of local search techniques for the SRFLP is to use the insertion neighborhood structure. We will describe two practical procedures for exploring this neighborhood. The first one takes advantage of the matrices A and B introduced in the previous section. The second procedure is somewhat simpler because it does not use these two auxiliary matrices. However, this procedure suffers from the restriction imposed on the order in which solutions are explored.For p ∈ Π,k,l∈{1,…,n},k ≠ l, let p′ be the permutation obtained from p by removing the facility p(k) from position k and inserting it at position l. Let us denote the resulting change in the objective function value byδ(p,k,l)=F(p′)−F(p). An efficient way to compute δ(p, k, l) is provided by the proposition stated below and proved in Appendix A.Proposition 4Let p ∈ Π,k,l∈{1,…,n},k ≠ l, andr=p(k). Then, for l > k,(24)δ(p,k,l)=2brl−ck−(dp(k+1)p(l)+λp(k+1)p(l)+)+Lr(cl−ck)+ck−1(γp(k−1)p(k+1)+γp(l)r−γp(k−1)r)−ck(γrp(k+1)+γp(l)r)+cl(γp(l)r+γrp(l+1)−γp(l)p(l+1))and, for l < k,(25)δ(p,k,l)=2brl+ck−(dp(l)p(k−1)+λp(l)p(k−1)+)+Lr(cl−1−ck−1)+cl−1(γp(l−1)r+γrp(l)−γp(l−1)p(l))−ck−1(γrp(l)+γp(k−1)r)+ck(γrp(l)+γp(k−1)p(k+1)−γrp(k+1)).We will refer to the neighborhood exploration and local search algorithms based on (24) and (25) as NE2 and LS2, respectively. The former is similar to NE1 with a few differences. First, Step 2 is executed for all pairs (k, l) such thatk,l∈{1,…,n}and k ≠ l. Second, of course, Δ is replaced by δ calculated using either Eq. (24) or (25) depending on whether l > k or l < k. Third, in Step 3, the permutation p is updated by relocating the facility p(k′) from position k′ to position l′. Fourth, the vectorC+is eliminated. The LS2 algorithm is almost identical to LS1. The only differences are that the procedure NE2 instead of NE1 is invoked and the vectorC+is not used.The routine for updating the matrices A, B and D is slightly more complicated than in the case of pairwise interchanges. For their entries corresponding to facilityu=p′(m),it goes as follows.1.Letj1=min(k,l),j2=max(k,l).If m < j1, then compute auj,j=j1,…,j2−1,by (16), buj,j=j1,…,n,by (18), anddup′(j)=dp′(j)u,j=j1,…,n,by (20). Go to 6.If m > j2, then compute auj,j=j2,j2−1,…,j1+1,by (17) and buj,j=j2,j2−1,…,1,by (19). Go to 6.Ifm=l(that is,u=p′(l)=p(k)), then perform the following operations. Set aum≔ 0 and bum≔ 0. Forj=l−1,l−2,…,1,compute aujby (17) and bujby (19). Also, forj=l+1,…,n,compute aujby (16), bujby (18) anddup′(j)=dp′(j)uby (20). Go to 6.If k < l, then setj1:=k−1,j2 ≔ l andauj:=au,j+1,buj:=bu,j+1forj=k,…,l−1. Otherwise, set j1 ≔ l,j2:=k+1andauj:=au,j−1,buj:=bu,j−1forj=k,k−1,…,l+1. In both cases, forj=j1,j1−1,…,1,compute aujby (17) and bujby (19). Also, forj=j2,…,n,compute aujby (16), bujby (18), anddup′(j)=dp′(j)uby (20).Stop.We note that the cut vector C can be updated in the same way as it is done in the procedure NE1. However, unlike NE1, the procedure NE2 does not maintain the vectorC+. Owing to the similarity between NE1 and NE2, the following result should be clear.Proposition 5The computational complexity of the procedure NE2 is O(n2).Consider the same SRFLP instance as in Example 1. Suppose that LS2 and NE2 are applied to the same permutation as before, that is,p=(3,5,1,2,4). To illustrate Proposition 5, we compute the value of δ for the case when the last facility in p is moved to the first position (the layouts corresponding to p as well as to the new permutation are shown in Fig. 2). In this case,k=5,l=1,r=4,andλp(l)p(k−1)+=λ3,2+=7. The initial matrices A, B, D and vectors C andC−are the same as in Example 1. Therefore, using (25), we haveδ(p,5,1)=2·210+(−12)(23+7)+12(0−12)=−84. Other δ values are as follows:δ(p,1,2)=−42,δ(p,1,3)=−40,δ(p,1,4)=−68,δ(p,1,5)=−68,δ(p,2,1)=−42,δ(p,2,3)=8,δ(p,2,4)=8,δ(p,2,5)=−32,δ(p,3,1)=14,δ(p,3,2)=8,δ(p,3,4)=12,δ(p,3,5)=36,δ(p,4,1)=44,δ(p,4,2)=56,δ(p,4,3)=12,δ(p,4,5)=−12,δ(p,5,2)=−84,δ(p,5,3)=−28,δ(p,5,4)=−12. Since δ(p, 5, 1) ≤ δ(p, k, l) for allk,l=1,…,5,k ≠ l, facility 4 is moved to position 1. Then, using the above given six-step procedure based on (16)–(20), the matrices A and B are updated:A=[2210264420603440610101273013],B=[4521808154885680600334468060196216294121330834].The new cut vector isC=(12,10,6,6). The resulting layout is shown in the right part of Fig. 2. The corresponding objective function value with respect to original (not doubled) facility lengths is 151. We notice that the obtained layout is optimal (see Amaral (2006)).Another efficient method for exploring the insertion neighborhood rests on the idea to include the value of δ, calculated in the previous step, in an expression for δ(p, k, l). In the following, we present our realization of this idea.Proposition 6Let p ∈ Π,k∈{1,…,n},andr=p(k). Then, forl=k+1,k+2,…,n,(26)δ(p,k,l)=δ(p,k,l−1)+Lr(wrp(l)+cl−)+Lp(l)(el−1+el−ck−)+2wp(l)rγp(l)r+(2el−1−ck−)(γup(l)+γp(l)r−γur)−cl−1(γur+γrp(l)−γup(l))+cl(γp(l)r+γrp(l+1)−γp(l)p(l+1)),whereel=el−1+wrp(l),u=p(k−1)ifl=k+1,u=p(l−1)ifl≠k+1,and initiallyδ(p,k,k)=0andek=0.Forl=k−1,k−2,…,1,(27)δ(p,k,l)=δ(p,k,l+1)+Lr(wrp(l)−cl−)+Lp(l)(el+el+1+ck−)+2wrp(l)γrp(l)+(2el+1+ck−)(γrp(l)+γp(l)u−γru)+cl−1(γp(l−1)r+γrp(l)−γp(l−1)p(l))−cl(γp(l)r+γru−γp(l)u),whereel=el+1+wrp(l),u=p(k+1)ifl=k−1,u=p(l+1)ifl≠k−1,and initial conditions are as in (26).The proof of Proposition 6 is given in Appendix A. When the clearance matrix Γ is zero, Eqs. (26) and (27) take simplified forms. In this case, the right-hand side of each of them, besides the previous value of δ, has only two terms.Let Aq,q∈{1,…,n},denote the q-th column vector of the matrix A. Our third neighborhood exploration procedure for the SRFLP can be described as follows.NE3(p,A1,An,C,C−)1.Set h* ≔ 0.Fork=1,…,ndo the following:2.1.Set δ(p, k, k) ≔ 0 and ek≔ 0.Forl=k−1,k−2,…,1,perform the following operations. Setel:=el+1+wp(k)p(l). Computeh=δ(p,k,l)by Eq. (27). If h < h*, then set h* ≔ h, k′ ≔ k and l′ ≔ l.Forl=k+1,…,n,perform the following operations. Setel:=el−1+wp(k)p(l). Computeh=δ(p,k,l)by Eq. (26). If h < h*, then set h* ≔ h, k′ ≔ k and l′ ≔ l.Ifh*=0,then return with ρ set to 1. Otherwise, first remove the facility p(k′) from position k′ and insert it at position l′. Then update the vectors A1 and Anas well as the vectors C andC−used in δ calculations, and return withρ=0.We apply NE3 to the same SRFLP instance as in the previous examples. Again, the initial layout is defined by the permutationp=(3,5,1,2,4). From Example 1, we know thatC−=(10,4,0,−2,−12). The execution of Step 2 of NE3 is illustrated in Table 1, in which eprevious stands forel−1if l > k, and forel+1if l < k. Furthermore, δadded is used to denote the sum of the second and third terms on the right-hand side of (26) (or (27)), which is added toδ(p,k,l−1)(orδ(p,k,l+1)) to obtain δ(p, k, l). Let us consider the variants of relocating the facilityr=4in more detail. The loop in Step 2.2 of NE3 starts withk=5andl=4. Using (27), we getδadded=δ(p,5,4)=12(2−(−2))+6(2+0+(−12))=−12. Whenk=5andl=3,we haveδadded=12(0−0)+2(2+2+(−12))=−16andδ(p,5,3)=−12−16=−28. Similarly, forl=2,δadded=12(4−4)+14(6+2+(−12))=−56andδ(p,5,2)=−28−56=−84. Finally, forl=1,δadded=12(6−10)+8(12+6+(−12))=0andδ(p,5,1)=−84. The results of these calculations are summarized in the last four rows of Table 1. By moving facility 4 to either position 1 or 2 we obtain an optimal solution.It is important to note that NE3 requires significantly less data to calculate δ in comparison with NE2. Indeed, no permutation-dependent matrix is involved in δ calculations (see (26) and (27)). Instead, only four vectors, C,C−,A1 and An, need to be maintained. Let us assume that h* < 0 in Step 3 of the procedure NE3, and let the permutation obtained by shifting the facilityr=p(k′)to position l′ be denoted by p′. Having p′, the procedure first updates au1 and aunfor each facilityu=p(m)such that its position m in p′ belongs to the interval [min (k′, l′), max (k′, l′)]. Suppose that k′ < l′ (the case of k′ > l′ can be processed similarly). If m ≠ l′, then au1 is decreased by wurand aunis increased by the same value. Clearly, NE3 spends constant time per facility in this case. If howeverm=l′,thenu=r,and au1 is increased (and aundecreased) by the sum∑j=k′l′−1wup′(j). Since summation is performed only once, the computational complexity of updating vectors A1 and Anis O(n). Once A1 and Anare ready, the procedure can use (23) to update the cut vector C (or more precisely, its components with indices in the range min (k′, l′) throughmax(k′,l′)−1). Finally, the vectorC−is computed. Updating C andC−has linear-time complexity in the worst case. Summarizing, we can state that Step 3 of NE3 takes only O(n) time. The efficiency of the entire procedure is determined by that of Step 2, where a double loop is performed. Thus, we have the following result.Proposition 7The computational complexity of the procedure NE3 is O(n2).In what follows, we let LS3 denote the local search algorithm relying on the procedure NE3. Its structure is the same as that of LS1 and LS2.The main difference between two approaches described in this section is the order in which the algorithms examine candidate positions for facilities. In the case of NE3, for each facility, there are generally two ordered sequences of positions, and the algorithm is forced to follow them. Meanwhile, in NE2, the pairs of type (facility, its new position) are allowed to be considered in an arbitrary order. However, such flexibility in the search process is achieved at the expense of an increase in the amount of computation due to the necessity of maintaining the matrices A, B and D.The goal of this section is to provide empirical evidence of the effectiveness of our local search algorithms for the SRFLP. For comparison purposes, we also implemented two local search methods of Kothari and Ghosh (2013a). One of them minimizes the objective function of the SRFLP by performing pairwise interchanges of facilities, while another does the same using the insertion neighborhood structure. By adopting the same naming style as in Kothari and Ghosh (2013a), we refer to these two algorithms as LS-2OPT and LS-INSERT, respectively. The method of experimentation is quite straightforward: we run each of the algorithms in a multi-start mode. An initial permutation of facilities for each restart is generated randomly. The main metric used for comparison is the cumulative CPU time of all restarts.All the algorithms have been coded in C++ using a uniform programming style. The source code of LS1, LS2 and LS3 is publicly available in Palubeckis (2013). The tests have been carried out on a PC with an Intel Core 2 Duo CPU running at 3.0 GHz. As a testbed for the algorithms, two sets of SRFLP instances from the literature as well as additional instances of our own were considered. The first set of benchmark instances was introduced by Anjos et al. (2005). It consists of four subsets, each of cardinality 5. The size of the instances in the first to fourth subsets is 60, 70, 75 and 80, respectively. The second dataset is composed of 20 QAP (quadratic assignment problem)-based sko instances (Skorin-Kapov, 1990) tailored for the SRFLP in Anjos and Yen (2009). Their size ranges from 64 to 100 facilities. Both datasets have been used in several recent studies, including Anjos and Yen (2009), Hungerländer and Rendl (2013), Kothari and Ghosh (2013a, 2013b, 2014a, 2014b) and Ozcelik (2012).In order to test the algorithms more thoroughly, we generated a set of 20 SRFLP instances of larger size (withn∈[110,120,…,300]). In these instances, the lengths of facilities and the nondiagonal entries of the flow matrix are integer numbers drawn uniformly at random from the intervals [1, 10] and [0, 10], respectively. Of course, the flow matrix is symmetric. The clearances between facilities are assumed to be zero. This choice is conditioned by our intention to compare our algorithms with those of Kothari and Ghosh (2013a, 2013b). These latter algorithms, together with the underlying formulas, are presented for the SRFLP formulation where the clearances between facilities are not taken into account. The third set of SRFLP instances can be found in Palubeckis (2013).As already mentioned before, the experiments were conducted by running the algorithms in a multi-start mode. For each algorithm, the number of restarts was limited to 500, 1000 and 100 for problem instances in the first, second and third set, respectively. The choice of a smaller number of restarts for the first set, as compared to the second one, is justified by the fact that 500 restarts of insertion-based LS algorithms are sufficient to achieve the best known objective function values for all instances in this set (see Supplementary Appendix B). In order to obtain robust results, we run the algorithms 10 times on each instance in the datasets. Thus, for example, for a benchmark instance of Anjos et al. (2005), we performed 500 restarts of each tested algorithm 10 times, and averaged the results over these 10 runs.Table 2 shows the performance comparison of the tested algorithms on the dataset of Anjos et al. (2005). Its first column contains the instance names. The first integer in the name gives the problem dimension, that is, the number of facilities. The second column presents the average time taken by multi-start LS-2OPT. The average is computed over 10 runs of this heuristic. Each run consisted of 500 restarts of LS-2OPT. The standard deviation of the running time for LS-2OPT is displayed in the third column. The remaining columns report the same type of information for other local search algorithms. The overall results, averaged over 20 instances, are presented in the bottom row. The main message of Table 2 concerns the amount of time required to arrive at a locally optimal solution. The table shows that our algorithms run much faster than both LS-2OPT and LS-INSERT. We find that LS3 achieves the best performance in terms of computational time. This algorithm took less than 40 seconds for the whole dataset. On average, this is less than the time required by each of LS-2OPT and LS-INSERT (55 seconds and 72.3 seconds, respectively) for only one problem instance in the table. We can also see from the table that the standard deviation of the running time is very small. The values of this measure for LS1, LS2 and LS3 are constantly less than 0.05.The results of solving SRFLP instances in the second dataset are summarized in Table 3. The information in this table is organized in the same manner as in Table 2. The first column contains the instance names in which the integer following sko indicates the number of facilities. From Table 3, we notice that again LS3 is faster than other algorithms involved in the comparison. We also see that LS-2OPT and LS-INSERT are many times slower than the local search techniques described in this paper.In Table 4, we report the results of experiments on larger scale SRFLP instances. The number of facilities is encoded in the instance name. As Table 4 indicates, our local search algorithms are appropriate when dealing with higher-dimensional problem instances as well. They are much more efficient than previous approaches. In particular, the best of our procedures, LS3, is two orders of magnitude faster than the existing insertion-based algorithm LS-INSERT. Supplementary Appendix B contains the comparison of the local search algorithms in terms of solution quality. The results show that such a simple technique as multi-start local search is not suitable if one aims at achieving satisfactory results for problem instances with more than 100 facilities. In such a case, more sophisticated approaches are required. An example of such an approach is given in the next section.The proposed local search procedures can be incorporated into various heuristic algorithms for solving the SRFLP. In order to illustrate the benefits of using our procedures, we have developed a variable neighborhood search (VNS) algorithm for this problem. Different LS techniques can be embedded into the VNS framework. Our purpose is to compare the best of the techniques presented in Sections 3 and 4 with the LS-INSERT method of Kothari and Ghosh (2013a). We prefer LS-INSERT because, as Kothari and Ghosh discovered, this method performs better than LS-2OPT.The variable neighborhood search metaheuristic is a general-purpose optimization method which combines a neighborhood change rule and solution perturbation component with a local search technique. In recent years, algorithms based on the VNS metaheuristic have been successfully applied to a variety of combinatorial optimization problems. The general schemes of VNS and their applications are reviewed by Hansen and Mladenović (2001) and by Hansen, Mladenović, and Moreno Pérez (2008, 2010).Before presenting our VNS algorithm for the SRFLP, we need to first define the neighborhood structures with respect to the solution space. Let p ∈ Π be fixed. We say that the permutation p′ belongs to the neighborhood Ni(p) of p if p and p′ differ on exactly i entries. Our algorithm makes use of the neighborhoodsN2,N4,N6,…. It generates a permutation p′ ∈ N2k(p) by performing k pairwise interchanges of facilities under the restriction that no facility may be relocated more than once. By changing the value of k, the algorithm can select neighborhoods of different sizes. An important feature of the algorithm is that, at each iteration, it uses a neighborhood of the best solution found so far. Our implementation of the variable neighborhood search method for the SRFLP can be described as follows.VNS1.Randomly generate an initial solution p to the given instance of the SRFLP. Apply a local search procedure to p. Let p′ denote the solution returned by it. Initialize p* with p′ and F* with F(p′).Set k ≔ kmin.While k ≤ kmax do the following:3.1.Set p ≔ p* andR:={1,…,n}.Generate a permutation in N2k(p*) by repeating k times the following steps:3.2.1.Randomly select facilities i, j ∈ R and interchange their positions in p.Remove both i and j from R.Calculate the distance matrix D corresponding to the permutation p.Apply a local search procedure to p and let p′ denote the resulting solution.Check whether F(p′) < F*. If so, then set p* ≔ p′, F* ≔ F(p′) and k ≔ kmin. Otherwise, increase k by kstep.Check if the termination condition is satisfied. If so, then stop with the solution p* of value F*.Go to 2.It is clear that the quality of solutions produced by VNS greatly depends on the local search procedure employed in the optimization phase of the algorithm. Within the VNS framework, we have tested the procedures proposed in the current paper as well as the LS-INSERT procedure from Kothari and Ghosh (2013a). In what follows, we will refer to the obtained configurations of VNS as VNS-LS1, VNS-LS2, VNS-LS3 and, respectively, VNS-LS-INSERT.We conducted computational experiments with VNS on three datasets: the QAP-based sko instances (Anjos & Yen, 2009), three instances of size 110 taken from Amaral and Letchford (2011), and the set of larger scale instances introduced in Section 5.1. The results summarized in the current section were obtained by running variations of VNS 10 times on each problem instance in these datasets. Maximum CPU time limits for a run were as follows: 10 seconds for sko instances, 100 seconds forn∈{110,120,…,200},and 600 seconds forn∈{210,220,…,300}. After some preliminary testing, the parameterkmax′of VNS was fixed at 0.4. Two other parameters, kmin and kstep, were set to 1.In the experiments on the sko instances (Anjos & Yen, 2009) and the dataset of Amaral and Letchford (2011), we compare the results of the VNS algorithm with the best known values reported in the literature. For the third dataset, the situation is slightly different. For each test case, we need a reference point as a basis of comparison. In this regard, we decided to perform one long run of VNS-LS3 for each instance in the set {p110, p120,… , p300}. We preferred VNS-LS3 to VNS-LS1 and VNS-LS2 because this variation of VNS produced the best results in our preliminary experiments. The cutoff time for each long run was 5 hours.In Table 5, we compare the performance of our LS algorithms when used as search intensification components within the VNS framework. For each VNS variation, we provide two statistics: the average value of the objective function and the success rate, which is defined to be the number of runs (out of 10) in which the algorithm obtained the best solution (the best values are displayed in the second column of Tables 6and 8). Table 5 discloses that the VNS-LS3 algorithm performs slightly better than both VNS-LS1 and VNS-LS2. We content ourselves by presenting results on a small sample of instances. As a matter of fact, the same conclusion on the superiority of VNS-LS3 could have been reached by considering the full set of results. We, thus, choose VNS-LS3 as a representative of a group of VNS algorithms that are based on our local search procedures.We note that the main goal of experiments with VNS algorithms was to test their performance in terms of solution quality. A secondary objective was to compare the average time taken by each of the tested algorithms to first find a solution that is best in the run (these statistics are presented in Supplementary Appendix B). The main results of solving SRFLP instances in the sko dataset (Anjos & Yen, 2009) are reported in Table 6. The best known solution values are given in its second column. They are taken from various recent studies. The third column shows the gap, Gbest, of the value of the best solution out of 10 runs (in parentheses, the gap, Gaver, of the average value of 10 solutions) found by VNS-LS3 to the best known value displayed in the second column. The fourth column provides the standard deviation of solution values for VNS-LS3. The last two columns stand for VNS-LS-INSERT. The bottom row of the table gives the averages of solution gaps and standard deviation over the whole dataset. As we can see from Table 6, the combination of VNS with our local search procedure competes very favorably with VNS-LS-INSERT. Specifically, VNS-LS3 obtained best known results in 197 runs out of 200. It did not reach the best solution three times for the last instance in the set. The performance of VNS-LS-INSERT is less impressive. All 10 runs of this algorithm were successful in two test cases only. For two instances of size 100, VNS-LS-INSERT failed to match the best value in all runs.Table 7shows the results of the VNS algorithms on the instances from Amaral and Letchford (2011). The size of each instance is 110. The second column displays the best known values reported in the paper by Ozcelik (2012). The obtained results indicate that VNS-LS3 again significantly outperforms VNS-LS-INSERT.We have made an attempt to improve the best known solution for each problem instance in the sko dataset by Anjos and Yen (2009) as well as for each instance introduced by Amaral and Letchford (2011). To accomplish this task, the VNS-LS3 algorithm has been used. We have limited the computational time for each run to one day. However, for each instance, VNS-LS3 produced a solution with precisely the same objective function value as that shown in Table 6 or 7. One can reasonably conjecture that the best known solutions reported in these tables are optimal.The results achieved in Table 6 suggest that SRFLP instances in the sko dataset do not pose a perceptible challenge to the VNS-LS3 algorithm. The benchmark instances of Amaral and Letchford are relatively easy for this algorithm as well. Therefore, we have carried out a computational study on larger problem instances, which have already been used in the investigation of LS strategies in Section 5. The results of the tested algorithms on these instances are summarized in Table 8. We remind that the second column of this table contains solution values obtained by letting VNS-LS3 run for 5 hours. The best solutions for instances in Table 8 as well as for other SRFLP instances used in our computational experiments can be found in Supplementary Appendix B. By contrasting columns 3–4 of Table 8 with the last two columns we ascertain that VNS-LS3 is unequivocally superior to VNS-LS-INSERT. The former algorithm was successful in finding the best solutions for all instances in the dataset. We note, however, that in three cases (p250, p280, p290) the best value was obtained only once. From the table, we also see that the VNS-LS-INSERT algorithm had low performance relative to VNS-LS3. It was able to produce the best quality solutions for the first four problem instances only. As a more general conclusion from the numerical experiments, we can state that the VNS metaheuristic is a viable alternative that can provide a basis for the development of effective algorithms for solving the SRFLP.

@&#CONCLUSIONS@&#
The main contribution of this work is fast and easy to implement neighborhood exploration (NE) procedures for the single row facility layout problem. Their time complexity is O(n2). Because the objective function of the problem involves the summation ofn(n−1)/2terms, it is not reasonable to expect any NE procedure to be (asymptotically) faster than those presented in this paper. The local search (LS) algorithms based on the developed NE procedures appear to provide markedly better performance than existing state-of-the-art LS approaches for the SRFLP. We tested our LS algorithms on a range of previously studied SRFLP benchmark instances, and have found that they are capable of obtaining good solutions in a short period of time, even when they operate in the stand-alone mode.We have shown that the usefulness of the proposed LS algorithms significantly increases when they are embedded into a VNS metaheuristic scheme. We carried out computational experiments on three sets of SRFLP instances of size up to 300 facilities. The results indicate that the speedup provided by using the fastest of our LS algorithms is rather spectacular. The VNS based on this algorithm offers much better performance than the variant of VNS that uses an O(n3)-time NE technique from the literature. This finding underscores the importance of utilizing an effective LS heuristic within a VNS framework.The approach we have presented affords opportunities to develop high-performance algorithms for the SRFLP. Besides VNS, there are other metaheuristics and their hybrids which contain a local search component. An attractive way to implement such a component is to use neighborhood exploration procedures proposed in this paper.Throughout the proofs, we will, mostly tacitly, use the following equation obtained from (23)(28)cm−=ap(m)n−ap(m)1.Proof of Proposition 2To get an initial expression for Δ(p, k, l), we rewrite (3) asF(p)=∑m=1n−1fm(p)where fm(p) stands for the m-th term in the right-hand side of (3). Let p′ denote the permutation obtained from p by interchanging the facilitiesr=p(k)ands=p(l)in positions k and, respectively, l > k. Denoting the differencefm(p′)−fm(p)by Δmand taking into account the fact thatfm(p′)=fm(p)form=1,…,k−2andm=l+1,…,n−1we can write(29)Δ(p,k,l)=F(p′)−F(p)=∑m=k−1lΔmwhereΔ0=0ifk=1andΔn=0ifl=n.Now letc1′,…,cn−1′be the cut values for the solution p′. To continue, there are five cases which need to be handled.(i)m=k−1,k > 1. It is easy to see thatfk−1(p′)=ck−1′(λp(k−1)+λs+γp(k−1)s)andfk−1(p)=ck−1(λp(k−1)+λr+γp(k−1)r). Sinceck−1′=ck−1it follows that(30)Δk−1=fk−1(p′)−fk−1(p)=ck−1(λs−λr+γp(k−1)s−γp(k−1)r).m=l,l < n. Similarly as in case (i) we have(31)Δl=cl(λr−λs+γrp(l+1)−γsp(l+1)).m=k. In this case(32)ck′=ck+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−wrs)+∑i=l+1nwsp(i)−(∑i=1l−1wsp(i)−∑i=k+1l−1wsp(i)−wrs)+∑i=k+1l−1wsp(i).By using the definition of the matrix A and Eq. (28) with respect tor=p(k)ands=p(l),(32) can be rewritten asck′=ck+ar1−arn+asn−as1+2as,k+1+2wrs=ck+cl−−ck−+2as,k+1+2wrs.Now suppose thatl>k+1. Then we have(33)Δk=fk(p′)−fk(p)=(ck+cl−−ck−+2as,k+1+2wrs)×(λs+λp(k+1)+γsp(k+1))−ck(λr+λp(k+1)+γrp(k+1))=(cl−−ck−+2as,k+1+2wrs)(λs+λp(k+1)+γsp(k+1))+ck(λs−λr+γsp(k+1)−γrp(k+1)).Ifl=k+1,thenas,k+1=asl=0,and the expression for Δkis slightly different:(34)Δk=(ck+cl−−ck−+2wrs)(λs+λr+γsr)−ck(λr+λs+γrs)=(cl−−ck−+2wrs)(λs+λr+γsr)+ck(γsr−γrs).m=l−1. By the same derivation as in case (iii), we havecl−1′=cl−1+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−∑i=k+1l−1wrp(i)−wrs)+∑i=k+1l−1wrp(i)+∑i=l+1nwsp(i)−(∑i=1l−1wsp(i)−wrs)=cl−1+ar1−arn+asn−as1+2ar,l−1+2wrs=cl−1+cl−−ck−+2ar,l−1+2wrs.Notice thatl>k+1since otherwise we get case (iii). Therefore(35)Δl−1=(cl−1+cl−−ck−+2ar,l−1+2wrs)×(λp(l−1)+λr+γp(l−1)r)−cl−1(λp(l−1)+λs+γp(l−1)s)=(cl−−ck−+2ar,l−1+2wrs)(λp(l−1)+λr+γp(l−1)r)+cl−1(λr−λs+γp(l−1)r−γp(l−1)s).m∈[k+1,…,l−2]. Nowcm′=cm+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−∑i=k+1mwrp(i)−wrs)+∑i=k+1mwrp(i)+∑i=l+1nwsp(i)−(∑i=1l−1wsp(i)−∑i=m+1l−1wsp(i)−wrs)+∑i=m+1l−1wsp(i)=cm+ar1−arn+asn−as1+2arm+2as,m+1+2wrsand hence(36)Δm=(cl−−ck−+2arm+2as,m+1+2wrs)×(λp(m)+λp(m+1)+γp(m)p(m+1)).The obtained expressions for Δm,m=k−1,…,l,can be combined to calculate the value of Δ(p, k, l). First assume thatl>k+1. Substituting (30), (31), (33), (35) and (36) into (29) and making some minor rearrangements, we haveΔ(p,k,l)=T1+T2+T3+T4+T5,where(37)T1=(cl−−ck−+2wrs)[∑m=k+1l−2(λp(m)+λp(m+1)+γp(m)p(m+1))+λs+λp(k+1)+γsp(k+1)+λp(l−1)+λr+γp(l−1)r∑m=k+1l−2],T2=2[∑m=k+1l−2ar,l−1(λp(l−1)+λr+γp(l−1)r)+∑m=k+1l−2arm(λp(m)+λp(m+1)+γp(m)p(m+1))],T3=2[∑m=k+1l−2as,k+1(λs+λp(k+1)+γsp(k+1))+∑m=k+1l−2as,m+1(λp(m)+λp(m+1)+γp(m)p(m+1))],(38)T4=(λr−λs)(cl+cl−1−ck−ck−1),T5=ck−1(γp(k−1)s−γp(k−1)r)+ckγ1+cl−1γ2+cl(γrp(l+1)−γsp(l+1)).To simplify the term T1, we notice thatλr+λp(k+1)+γrp(k+1)+∑m=k+1l−2(λp(m)+λp(m+1)+γp(m)p(m+1))+λp(l−1)+λs+γp(l−1)s=drs.ThusT1=(cl−−ck−+2wrs)(drs+γ1+γ2). Next, from the definition of the matrix B, the case of j > k, it can be immediately seen thatT2=2br,l−1. A similar conclusion can be reached for the term T3. Indeed, by replacingm+1by i, the sum in (37) can be written as∑i=k+2l−1asi(λp(i−1)+λp(i)+γp(i−1)p(i)). Now, remembering thats=p(l),it should be clear thatT3=2bs,k+1. Finally, the term T4 is equal toλrs−(cl+−ck+). Putting T1, T2, T3, T4 and T5 together yields (15).Ifl=k+1,then Δ(p, k, l) is obtained by summing up (30), (31) and (34). Keeping the same notations as in the general case, we find thatT1=(cl−−ck−+2wrs)(λr+λs+γsr),T2=T3=0,T4=(λr−λs)(cl−ck−1),and T5 is given by (38). Sinceλr+λs+γsr=drs+γsr−γrsandcl−ck−1=cl+−ck+forl=k+1it follows that the sum of T1, T4 and T5 is equal to the right-hand side of (15). Notice that, in the case ofl=k+1,br,l−1=brk=0andbs,k+1=bsl=0.□Let p′ denote the permutation obtained from p by relocating the facilityr=p(k)from position k to positionl∈{1,…,n}∖{k}and letc1′,…,cn−1′be the cut values for p′. First consider the case where l > k. Like in the proof of Proposition 2, we can writeδ(p,k,l)=F(p′)−F(p)=∑m=k−1lΔmwhereΔ0=Δn=0as before.We proceed by deriving expressions for Δm,m=k−1,…,l. To this end, we distinguish between the following five cases.(i)m=k−1,k > 1. Obviously,ck−1′=ck−1. Hence(39)Δk−1=ck−1(λp(k−1)+λp(k+1)+γp(k−1)p(k+1))−ck−1(λp(k−1)+λr+γp(k−1)r)=ck−1(λp(k+1)−λr+γp(k−1)p(k+1)−γp(k−1)r).m=l,l < n. In this case, we have(40)Δl=cl(λr−λp(l)+γrp(l+1)−γp(l)p(l+1)).m=k. The k-th cut value for p′ isck′=ck+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−wrp(k+1))+∑i=k+2nwp(k+1)p(i)−(∑i=1kwp(k+1)p(i)−wrp(k+1))=ck+ar1−arn+ap(k+1)n−ap(k+1)1+2wrp(k+1)=ck+ck+1−−ck−+2wrp(k+1).We remark that ifl=k+1,then case (iv) is considered. So we can assume thatl>k+1. Then(41)Δk=(ck+ck+1−−ck−+2wrp(k+1))×(λp(k+1)+λp(k+2)+γp(k+1)p(k+2))−ck(λr+λp(k+1)+γrp(k+1))=(ck+1−−ck−+2ar,k+1)(λp(k+1)+λp(k+2)+γp(k+1)p(k+2))+ck(λp(k+2)−λr+γp(k+1)p(k+2)−γrp(k+1)).m=l−1. In this case(42)cl−1′=cl−1+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−∑i=k+1l−1wrp(i)−wrp(l))+∑i=k+1l−1wrp(i)+∑i=l+1nwp(l)p(i)−(∑i=1l−1wp(l)p(i)−wrp(l))=cl−1+ar1−arn+ap(l)n−ap(l)1+2(ar,l−1+wrp(l))=cl−1+cl−−ck−+2arl.Using (42) we get(43)Δl−1=(cl−1+cl−−ck−+2arl)(λp(l)+λr+γp(l)r)−cl−1(λp(l−1)+λp(l)+γp(l−1)p(l))=(cl−−ck−+2arl)(λp(l)+λr+γp(l)r)+cl−1(λr−λp(l−1)+γp(l)r−γp(l−1)p(l)).m∈[k+1,…,l−2]. As before, we first identify the cut value:cm′=cm+∑i=1k−1wrp(i)−(∑i=k+1nwrp(i)−∑i=k+1mwrp(i)−wrp(m+1))+∑i=k+1mwrp(i)+∑i=m+2nwp(m+1)p(i)−(∑i=1mwp(m+1)p(i)−wrp(m+1))=cm+ar1−arn+ap(m+1)n−ap(m+1)1+2(arm+wrp(m+1))=cm+cm+1−−ck−+2ar,m+1.Then we can write(44)Δm=(cm+cm+1−−ck−+2ar,m+1)×(λp(m+1)+λp(m+2)+γp(m+1)p(m+2))−cm(λp(m)+λp(m+1)+γp(m)p(m+1))=(cm+1−−ck−+2ar,m+1)×(λp(m+1)+λp(m+2)+γp(m+1)p(m+2))+cm(λp(m+2)−λp(m)+γp(m+1)p(m+2)−γp(m)p(m+1)).Following the same strategy as in the proof of Proposition 2, we combine (39)–(41), (43) and (44) in a way that is suitable for performing further manipulations:(45)δ(p,k,l)=T1−T2+T3+T4+T5+T6where in the case ofl>k+1(46)T1=2∑m=kl−2ar,m+1(λp(m+1)+λp(m+2)+γp(m+1)p(m+2))+2arl(λp(l)+λr+γp(l)r),T2=ck−[∑m=kl−2(λp(m+1)+λp(m+2)+γp(m+1)p(m+2))+λp(l)+λr],(47)T3=∑m=kl−2cm+1−(λp(m+1)+λp(m+2))+cl−(λp(l)+λr),(48)T4=ck−1(λp(k+1)−λr)+cl(λr−λp(l))+ck(λp(k+2)−λr)+cl−1(λr−λp(l−1))+∑m=k+1l−2cm(λp(m+2)−λp(m)),(49)T5=∑m=kl−2cm+1−γp(m+1)p(m+2)+∑m=k+1l−2cm(γp(m+1)p(m+2)−γp(m)p(m+1)),(50)T6=(cl−−ck−)γp(l)r+ck−1(γp(k−1)p(k+1)−γp(k−1)r)+cl(γrp(l+1)−γp(l)p(l+1))+ck(γp(k+1)p(k+2)−γrp(k+1))+cl−1(γp(l)r−γp(l−1)p(l)).Ifl=k+1,then (48) and (50) must be adjusted by removing the third and, respectively, the fourth term.We now simplify the above expressions. First of all, observe thatT1=2brl. Next, it is easy to see that the sum over m in (46) is equal todp(k+1)p(l). Therefore,T2=ck−(dp(k+1)p(l)+λp(l)+λr). Further, it is not hard to check that, using equationscm+1−=cm+1−cm,m=k,…,l−1,(47) can be rewritten as(51)T3=ck+1−λp(k+1)+cl−λr+∑m=k+2l(cm−cm−2)λp(m).Similarly, simplifying (48) we get(52)T4=(cl+−ck+)λr−∑m=k+1l(cm−cm−2)λp(m).Notice that (52) holds also forl=k+1,since in this case only the first two terms in (48) can be nonzero andck+1+−ck+=ck+1−ck−1. Summing (51) and (52) givesT3+T4=(2cl−ck+)λr−ck−λp(k+1). Suppose thatl>k+1. Then by expanding the sums in (49), we find thatT5=cl−1γp(l−1)p(l)−ckγp(k+1)p(k+2). SubstitutingT1,…,T6in (45), and performing minor manipulations yields (24). In the case ofl=k+1,T5=0and the terms of (24) containing γ values are deduced from T6 alone (with the adjustment mentioned right below (50)).To finish the proof, we address the case where l < k. Our strategy is to take advantage of formula (24) we have just derived. For a permutation p ∈ Π, letp˜be its reverse defined byp˜(m)=p(n−m+1),m=1,…,n. Denote the transpose of the matrix Γ byΓT=(γijT),whereγijT=γji. We will writeδ˜for the δ values (andb˜for the entries of the matrix B) defined with respect to the SRFLP instance given by the triplet (W, L, ΓT),L=(L1,…,Ln). We will usec˜1,…,c˜n−1to refer to the cut values for the solutionp˜. By applying (24) toδ˜,we haveδ(p,k,l)=δ˜(p˜,n−k+1,n−l+1)=2b˜r,n−l+1−c˜n−k+1−(dp˜(n−k+2)p˜(n−l+1)+λp˜(n−k+2)p˜(n−l+1)+)+Lr(c˜n−l+1−c˜n−k+1)+c˜n−k×(γp˜(n−k)p˜(n−k+2)T+γp˜(n−l+1)rT−γp˜(n−k)rT)−c˜n−k+1(γrp˜(n−k+2)T+γp˜(n−l+1)rT)+c˜n−l+1(γp˜(n−l+1)rT+γrp˜(n−l+2)T−γp˜(n−l+1)p˜(n−l+2)T),wherec˜n−k+1−=c˜n−k+1−c˜n−k. Making use of the identitiesb˜r,n−l+1=brl,c˜n−l+1=cl−1,c˜n−k+1=ck−1,c˜n−k=ck,c˜n−k+1−=−ck−and translating back to the permutation p and matrix Γ, we arrive at (25).□First we show that (26) holds. We start with the following equality:(53)δ(p,k,l)=δ(p,k,l−1)+Δl−2+Δl−1+Δl,whereΔm=fm(p′)−fm(p′′),m=l−2,l−1,l,and p′ (respectively, p′′) is the permutation obtained from p by relocating the facilityr=p(k)from position k to position l (respectively, to positionl−1). It is assumed thatp′′=pifl=k+1. Lettingci′,i=1,…,n−1,denote the cut values for p′, we consider the following three cases.(i)m=l. Sincecl′=clit follows that(54)Δl=cl(λr−λp(l)+γrp(l+1)−γp(l)p(l+1)).m=l−1. The cut value for p′ iscl−1′=cl−1+∑i=1l−1wrp(i)−(∑i=lnwrp(i)−wrp(l))+∑i=l+1nwp(l)p(i)−(∑i=1l−1wp(l)p(i)−wrp(l))=cl−1+ar1+ar,l−1−(arn−ar,l−1−wrp(l))+ap(l)n−(ap(l)1−wrp(l)). Simplifying, we get:(55)cl−1′=cl−1−ck−+cl−+2arl.Making use of (55) gives(56)Δl−1=(cl−1−ck−+cl−+2arl)(λp(l)+λr+γp(l)r)−cl−1(λr+λp(l)+γrp(l))=(cl−−ck−+2arl)(λp(l)+λr+γp(l)r)+cl−1(γp(l)r−γrp(l)).m=l−2. First suppose thatl>k+1. Since swapping the facilities r and p(l) does not affect the cut valuecl−2′,we can writeΔl−2=cl−2′(λp(l−1)+λp(l)+γp(l−1)p(l))−cl−2′(λp(l−1)+λr+γp(l−1)r)=cl−2′(λp(l)−λr+γp(l−1)p(l)−γp(l−1)r).Using an analogue of (55) forl−2,we obtain(57)Δl−2=(cl−1−ck−+2ar,l−1)(λp(l)−λr+γp(l−1)p(l)−γp(l−1)r).Ifl=k+1,thenΔl−2takes a simpler form:(58)Δl−2=cl−2(λp(l)−λr+γp(k−1)p(l)−γp(k−1)r).Substituting (54), (56) and (57) in (53) yields(59)δ(p,k,l)=δ(p,k,l−1)+2λp(l)(ar,l−1+arl−ck−)+2λr(wrp(l)+cl−)+T,where(60)T=2arlγp(l)r+2ar,l−1(γup(l)−γur)−ck−(γup(l)+γp(l)r−γur)−cl−1(γur+γrp(l)−γup(l))+cl(γp(l)r+γrp(l+1)−γp(l)p(l+1))with u as defined in the formulation of the proposition. We emphasize that (59) and (60) also cover the case ofl=k+1. This can be checked by combining (54), (56) and (58) and taking into account the following identities, valid forl=k+1:ar,l−1=0,arl=wrp(l),ck−=cl−1−cl−2.Using the equationarl=ar,l−1+wrp(l),the first three terms in (60) can be rewritten as2wrp(l)γp(l)r+(2ar,l−1−ck−)(γup(l)+γp(l)r−γur). Now substituting the value of T in (59) and, for ease of exposition, renamingar,l−1toel−1and, respectively, arlto elwe get (26).Forl=k−1,k−2,…,1,we apply the same trick as in the proof of the case l < k of Proposition 4. In terms of the notations used there, from (26) we have(61)δ(p,k,l)=δ˜(p˜,n−k+1,n−l+1)=δ˜(p˜,n−k+1,n−l)+Lr(wrp˜(n−l+1)+c˜n−l+1−)+Lp˜(n−l+1)(e˜n−l+e˜n−l+1−c˜n−k+1−)+2wp˜(n−l+1)rγp˜(n−l+1)rT+(2e˜n−l−c˜n−k+1−)(γup˜(n−l+1)T+γp˜(n−l+1)rT−γurT)−c˜n−l(γurT+γrp˜(n−l+1)T−γup˜(n−l+1)T)+c˜n−l+1(γp˜(n−l+1)rT+γrp˜(n−l+2)T−γp˜(n−l+1)p˜(n−l+2)T),wheree˜n−l+1=e˜n−l+wrp˜(n−l+1),u=p˜(n−k)ifn−l+1=n−k+2,andu=p˜(n−l)ifn−l+1≠n−k+2. Now (27) follows from (61) by applying the identitiesp˜(m)=p(n−m+1),c˜m=cn−m,c˜m−=−cn−m+1−,e˜m=en−m+1,m=1,…,n,andγijT=γji,i,j=1,…,n.□Supplementary material associated with this article can be found, in the online version, at 10.1016/j.ejor.2015.05.055