@&#MAIN-TITLE@&#
GeoTree: Using spatial information for georeferenced video search

@&#HIGHLIGHTS@&#
A new indexing method, called GeoTree, is proposed to support an efficient search of georeferened videos.Georeferenced videos are the videos with location and direction information captured by smartphones or vehicle blackboxes.GeoTree is faster and more efficient than R-tree for searching georeferenced videos.An online demo is available at ”http://dm.postech.ac.kr/geosearch”.

@&#KEYPHRASES@&#
Georeferencing,Geotagging,Video search,Spatial indexing,R-tree,

@&#ABSTRACT@&#
With the rapid popularization of video recording devices, more multimedia content is available to the public. However, current video search engines rely on textual data such as video titles, annotations, and text around the video. Video recording devices such as cameras, smartphones and car blackboxes are nowadays equipped with GPS sensors and the ability to capture videos with spatiotemporal information such as time, location, and camera direction. We call such videos georeferenced videos. This paper proposes an efficient spatial indexing method, called GeoTree, which facilitates rapid searching of georeferenced videos. In particular, we propose a new data structure, called MBTR (Minimum Bounding Tilted Rectangle) to efficiently store the areas of moving scenes in the tree. We also propose algorithms for building MBTRs from georeferenced videos and algorithms for efficiently processing point and range queries on GeoTree. The results of experiments conducted on real georeferenced video data show that, compared to previous indexing methods for georeferenced video search, GeoTree substantially reduces index size and also improves search speed for georeferenced video data. An online demo of the system is available at “http://dm.postech.ac.kr/geosearch”.

@&#INTRODUCTION@&#
With the rapid popularization of video recording devices, more multimedia content is available to the public. Both media made by professionals and those made by ordinary users called UCC (User-Created Contents) comprise a large portion of the web. However, unlike the search for textual data which is effectively executed by existing search engines, there is yet no effective method of searching for video. While search engines utilize document contents to identify related documents, identifying related video requires an understanding of video contents, which is a very demanding and complex process. Thus, current video search engines rely on textual data such as video titles, annotations, and text around the video.1http://www.youtube.com.1,2http://video.search.yahoo.com.2Video capture devices such as cameras, smartphones, and car blackboxes are nowadays equipped with GPS sensors and the ability to capture videos with spatiotemporal information such as time, location, and camera direction. We call such videos georeferenced videos. For some applications, such spatiotemporal information plays key roles in the querying of georeferenced videos. For example, some people may want to find videos of a specific event that occurred at a particular time and in a particular location, e.g., videos of a traffic accident captured by car blackboxes, videos of a goal scene in a soccer game captured by users, or videos of a concert with celebrities captured by users. Also, some compound applications, such as path recommendation or tour guide program annotated with videos, utilize spatial information to search for relevant videos. Note that, although many devices can capture the geo-data with videos, YouTube does not tag the geo-data on videos, as it does not utilize it for search. The search system must inherently support tagging and utilizing the geo-data. There are several sites doing that3http://www.you4wd.com.3,4http://geovid.org.4including our own search system.5GeoSearch: http://dm.postech.ac.kr/geosearch.5This paper proposes an efficient spatial indexing method, called GeoTree, which enables rapid searching of georeferenced videos. In particular, we propose a new data structure, called MBTR (Minimum Bounding Tilted Rectangle) to efficiently store the areas of moving scenes in the tree. While traditional MBR (Minimum Bounding Rectangle) is popularly used to describe an area in spatial indexes such as R-Tree, MBR is not suitable for describing the areas of moving scenes in which location and direction are continuously changing. On the other hand, MBTR is designed to describe an area (or scenes) of moving location and direction. GeoTree specifically adopts MBTR in the leaf nodes of R-Tree to efficiently store meaningful parts of moving scenes, which leads to substantial reductions in index size. MBTR also enables efficient pruning of unpromising parts of videos and thus saves query processing time.There have been several approaches to the problem of search in georeferenced videos. SA Ay et al. [4] proposed a model to represent a camera viewable scene and basic search mechanisms for it. They expressed the camera viewable scene using four parameters – location, direction, viewable angle, and object distance. They also proposed metrics for evaluating and ranking the relevance of videos along with a search algorithm [2]. Our index adopts their scene model but substantially improves the search efficiency. Related works are further discussed in Section 2.Our major contributions are summarized as follows.•We propose a new data structure, MBTR, to efficiently store the areas of moving scenes, and develop algorithms for building MBTRs from georeferenced videos to construct a GeoTree, a kind of R-Tree with MBTRs in the leaf nodes.We develop efficient algorithms for processing point and range queries on GeoTree.We demonstrate the effectiveness of GeoTree by performing experiments on real georeferenced video data. We compare our search methods with the previous georeferenced video search algorithm [2] and an R-Tree-based algorithm. GeoTree substantially reduces index size and also improves search speed for georeferenced video data. An online demo of the system is available at “http://dm.postech.ac.kr/geosearch”.The rest of this paper is organized as follows. Section 2 discusses related work. Section 3 presents our proposed indexing methods for georeferenced video. Section 4 presents experimental results. Section 5 concludes this paper.

@&#CONCLUSIONS@&#
This paper proposed a new efficient indexing method, called GeoTree, which enables an efficient search of georeferenced video data. GeoTree adopts a new data structure, MBTR (Minimum Bounding Tilted Rectangle), in the leaf nodes of R-Tree, in order to efficiently store sequences of moving scenes and efficiently prune out unpromising parts of videos in query processing. Our experiments show that, compared to recent methods based on MBR pruning and R-Tree, GeoTree significantly reduces the index size and also the query processing time. Future work will include the generalizing of GeoTree to support searching for videos with adjustable viewable angles and distances.