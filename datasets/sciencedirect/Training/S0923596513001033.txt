@&#MAIN-TITLE@&#
Multi-symbol QIM video watermarking

@&#HIGHLIGHTS@&#
Theoretical framework for the binary m-QIM (multi-symbol quantization index modulation).Detection method optimized with respect to the minimization of the average error probability.Expected benefit: for prescribed transparency and robustness constraints, the data payload is increased by a factor of log2m.Experimental validation: robust and semi-fragile MPEG-4 AVC watermarking.

@&#KEYPHRASES@&#
m-QIM,MPEG-4 AVC watermarking,Robustness,Semi-fragility,

@&#ABSTRACT@&#
This paper introduces the theoretical framework allowing for the binary quantization index modulation (QIM) embedding techniques to be extended towards multiple-symbol QIM (m-QIM, where m stands for the number of symbols on which the mark is encoded prior to its embedding). The underlying detection method is optimized with respect to the minimization of the average error probability, under the hypothesis of white, additive Gaussian behavior for the attacks. This way, for prescribed transparency and robustness constraints, the data payload is increased by a factor of log2m.m-QIM is experimentally validated under the frameworks of the MEDIEVALS French national project and of the SPY ITEA2 European project, related to MPEG-4 AVC robust and semi-fragile watermarking applications, respectively. The experiments are three-folded and consider the data payload–robustness–transparency tradeoff. In the former case, the main benefit is the increase of data payload by a factor of log2m while keeping fixed robustness (variations lower than 3% of the bit error rate after additive noise, transcoding and Stirmark random bending attacks) and transparency (set to average PSNR=45dB and 65dB for SD and HD encoded content, respectively). The experiments consider 1h of video content. In the semi-fragile watermarking case, the m-QIM main advantage is a relative gain factor of 0.11 of PSNR for fixed robustness (against transcoding), fragility (to content alteration) and the data payload. The experiments consider 1h 20min of video content.

@&#INTRODUCTION@&#
Digital watermarking can be defined as the process of embedding a pattern of information into a cover digital content (image, audio, video, etc.) [1,2], as illustrated inFig. 1. While such a procedure can be public, the very insertion of the mark is always controlled by some secret information referred to as a key. Once watermarked, the host data can be transmitted and/or stored in a hostile environment, i.e. in an environment where changes (attacks) attempting to remove the watermark are likely to occur. The subsequent watermark detection can serve to a large variety of applications, from property and/or integrity proof to augmented reality.Although there are no universal requirements to be satisfied by all watermarking applications, some main directions are generally considered by the research studies [1,2].In order to be effective, the watermark should be perceptually invisible for a human observer (i.e. the transparency property) and its detection should be successful even when the watermarked content is attacked (i.e. the robustness property). Moreover, it should allow the insertion of the amount of information (referred to as data payload) required by the targeted application (e.g. a serial number identifying a user, a time stamp, etc.). In order for the watermarking techniques to be easily integrated into practical applications, the watermark insertion/detection should be achieved at a low computational cost.The actual level of each of these four requirements is set according to the targeted application. For instance, let’s consider the two examples of video ownership (e.g. ensure copyright protection) and of video authentication (e.g. ensure video surveillance integrity).The former example relies on the so-called robust watermarking. Such a system should feature ideal transparency (i.e. human imperceptible visual differences between the original and the marked content) and robustness (i.e. the mark can be successfully recovered after each and every attack which still preserves the commercial value of that content). The mark itself may represent the owner/legal user identity, a time stamp, etc. The latter example can be based on the so-called semi-fragile watermarking, with weaker transparency constraints but with the possibility of discriminating between content-alteration attacks (e.g. object deletion, spatio-temporal cropping, …) which should destroy the mark and mundane video processing applications (noise addition, transcoding, …) which should allow the mark to be detected. The mark carries some content authentication information (a signature).Fig. 2 illustrates the difference between the robust and the semi-fragile watermarking. A frame sampled from the watermarked video is presented in Fig. 2a. Fig. 2b presents a compressed version of the marked frame; the mark should be detected by both robust and semi-fragile watermarking. Assume now the case in which a region in the watermarked and compressed frame was modified by introducing a person (a content alteration attack), as illustrated in Fig. 2c. On the one hand, the robust watermark method should be insensitive to such an attack and the mark should be detected. On the other hand, the semi-fragile watermark should be sensitive to such an attack: the authentication mark should no longer be detected, thus demonstrating the content modification. Real life applications consider more elaborated use-cases, in which the modified area should be discriminated from the genuine one. For instance, out of processing the frame in Fig. 2c, the mark should be detected in area where the content was altered only by compression but not from the area in which the person was added (see the legal/fake areas in Fig. 2d).In practice, video sequences are stored and distributed in compressed bit stream formats. Consequently, watermarking a video content would require to decode the sequence, then to insert the watermark and, finally, to re-encode that video. Such an approach would result into a large computational time, mainly spent on encoding/decoding. These two operations are intrinsically avoided if the watermarking is performed directly in the compressed video domain.When approaching the compressed domain watermarking, the main deadlock relates to the conceptual contradiction between compression and watermarking: while watermarking exploits visual redundancy to hide the mark, compression eliminates the same visual redundancy in order to reduce the size of the stream. Therefore, compressed video stream leaves very little (virtually any) space to hide data. The challenge is to embed the prescribed amount of information (set by the targeted application) directly into the compressed stream while maintaining prescribed robustness and transparency levels.The present paper takes this challenge and advances a theoretical framework for the multi-symbol embedding, based on QIM (quantization index modulation) [3]. In this respect, the insertion rule is extended from a binary alphabet [4] to an m-ary alphabet; the underlying optimal detection rule, in the sense of minimizing the average error in mark detection under additive white Gaussian noise attacks is derived. Hence, it is thus demonstrated that the data payload can be increased by a factor of log2m, for prescribed transparency and additive Gaussian noise power.The advanced method was experimentally validated under the frameworks of the MEDIEVALS French national project and of the SPY ITEA2 European project, related to robust and semi-fragile watermarking applications, respectively.The paper has the following structure. Section 2 details the state of the art on compressed domain video watermarking (both robust and semi-fragile). Section 3 presents the advanced m-QIM theoretical framework. Sections 4 and 5 are devoted to the applicative validation for robust and semi-fragile watermarking, respectively. Section 6 concludes the paper and discusses the future work directions.Current days, a special attention in watermarking is paid to the MPEG-4 Part 10 (a.k.a. MPEG-4 AVC or, alternatively H.264) [5] compressed stream. As its ancestors, this standard contains four basic functions: prediction, transformation, quantization and entropic encoding, denoted inFig. 3 by P, T, Q and E, respectively. In order to achieve higher compression efficiency, MPEG-4 AVC deploys particular compression features such as variable block-size motion estimation, directional spatial prediction, DCT (discrete cosine transform) approximation and context-adaptive entropic encoding. Consequently, the watermarking techniques devoted to uncompressed or to earlier compressed domains (MPEG-2 or MPEG-4 Part 2) are likely to fail in reaching the same performances in the MPEG-4 AVC domain and specific methods should be devised in this respect, [4,6–16]. Such different studies cover issues related to both robust [4,6–8] and semi-fragile watermarking systems [9–16]; they are benchmarked inTables 1 and 2. Note that two methods reported in the literature as robust [14,16] can be considered, at least from their properties point of view, as semi-fragile.Golikeri et al. [6] advance a binary QIM (quantization index modulation) watermarking method applied to MPEG-4 AVC DCT coefficients. The watermark is inserted into the perceptual projection (according to a psycho visual mask) of the selected block. Although it is transparent (a value of PSNR=32.4dB) and robust against transcoding and filtering, this method does not meet either the robustness to geometrics attacks or the real time constraints.In [7], Noorkami et al. present a method devoted to the MPEG-4 AVC stream but performed during the encoding step (hence, the uncompressed data should be available during the insertion). The watermark, a bipolar message, is inserted into the quantized AC coefficients, selected according to a perceptual cost. When compared to the method in [6], this technique increases the data payload to 160bit/min while keeping the same transparency. The experiments show robustness against linear filtering, fragility to geometrical attacks and does not consider transcoding. The watermark insertion during the encoding process makes this method computationally complex.Zou et al. [8] tackle the issue of watermarking the MPEG-4 AVC stream by a substitution method applied at the stream level. This study demonstrates that such a controlled modification of the stream elements is possible while keeping a transparency expressed by a PSNR=32dB. However, the paper does not evaluate the watermarking system performances.Belhaj et al. [4] introduce a binary ST-DM for MPEG-4 AVC stream watermarking which combines QIM principles, a new perceptual shaping mechanism devoted to the MPEG-4 AVC syntax peculiarities, and an information-theory driven selection criterion. This way, a transparency expressed by a PSNR=42dB and a NCC=0.99 is obtained. The robustness was checked against transcoding and random geometric attacks (BER lower than 10%). The data payload is 279bit/5min of video.Xu and Wang [9] perform the watermarking at the MPEG-4 AVC entropic encoding level. In this respect, the Exp-Golomb code elements which are eligible to be watermarked without destroying the stream synchronization are first detected. Then, a mapping rule between these elements and the watermark bits is established. The detection is performed by directly parsing the Exp-Golomb code words of the watermarked stream. The performance evaluations show perfect transparency (no quality degradation being induced) but a total fragility to transcoding.Kim et al. [10] embed the watermark bits in the motion vectors of the inter blocks or in the intra mode number of the intra blocks. The advanced method features a high data payload with small image quality degradation (a PSNR=40dB is reported). Nevertheless, a large sensitivity to transcoding is featured.Wang and Hsu [11] present a fragile watermarking algorithm to authenticate MPEG-4 AVC stream. The mark is computed as the MD5 (message digest algorithm) hash function of a random generated binary sequence and embedded by changing the parity of the high-frequency quantized DCT coefficients of I frames. While such a technique provides the ideal case of fragility and features low complexity (only the MPEG-4 AVC entropic decoding being required), it is conceptually unable to make any distinction between mundane and malicious attacks.Zang and Ho [12] adopt the same principles and insert the mark in the P frames. The overall results show good transparency (PSNR>35dB), a very good sensitivity to spatio-temporal alterations, low complexity but no robustness to content preserving attacks (e.g. transcodage).Chen and Leung present a semi-fragile watermarking scheme based on chaotic systems for the authentication of individual frames in the MPEG-4 AVC stream [13]. The authentication information is represented by both the GOP index and the frame index in that GOP. This information is modulated in a chaotic signal and inserted in the DCT transformed blocks of each frame by imposing local intensity relationships into a group of adjacent blocks. The insertion requires the entropic decoding, the de-quantizing and the reverse of the prediction operations, thus becoming computationally complex. Experiments carried out on a 795 frames video sequence proved a transparency expressed by a PSNR=40dB and robustness against JPEG compression (quality factor QF of 30) and median filtering. This method also detects the temporal modifications (with one frame accuracy) but the spatial modification properties were not assessed.Thiemert et al. [14] advance a semi-fragile watermarking system devoted to the MPEG-1/2 video sequences. The mark computation is based on the properties of the entropy computed at the 8×8 block levels. The mark is embedded by enforcing relationship between the DCT coefficients of some blocks. The experiments are run on one sequence (whose length is not précised) encoded at 1125kbps. The method proved both robustness (against JPEG compression with QF=50) and fragility against temporal (with 2 frame accuracy) and spatial (with a non-assessed accuracy) content changing. However, the main drawback of this method remains its inner computation complexity: beyond the complete MPEG decoding/encoding, it also requires sophisticated entropy estimation at frame levels.Proforck et al. [15] propose an integrity authentication schema of MPEG-4 AVC. The authentication information which consists of the encrypted hash value and a certificate with public key is embedded by reactivating some skipped macroblocks. The advantage of the method is the possibility of erasing the watermark, but the considered hash algorithm increases the computation cost of the scheme. The transparency was evaluated at a PSNR>50dB.Chen et al. [16] compute the authentication data as the block sub-index. Then, the obtained signature is embedded by modifying the number of nonzero DCT AC coefficients of I frames. The experimental results show that the proposed system can detect the illegally altered area. However, neither the transparency nor the robustness against non malicious alteration has been evaluated.Tables 1 and 2 show that the large variety of state of-the-art methods allow each particular constraint (transparency, robustness, data payload, computational cost) to be individually reached for particular applications. However, none of these studies is able to jointly reach these four requirements. For instance, for the robust watermarking, the method in [4], based on binary QIM, seems to provide the best robustness, transparency and computational trade off but leaves room for data payload improvement. Moreover, to the best of our knowledge, no watermarking method is able today to serve both the purposes of robust and semi-fragile watermarking.Our previous studies [17–19] represent some first steps in this respect: they followed an application oriented approach and brought to light the utility of m-QIM for increasing the data payload with respect to the QIM methods. These studies are resumed and extended in the present paper. The m-QIM theoretical framework is first advanced. Then, its performances are evaluated under the frameworks of the MEDIEVALS French national project (robust watermarking) and of the SPY ITEA2 European project (semi-fragile watermarking).Consider the case in which some binary informationα=0.84is to be inserted in some (floating point) original dataΔ=70by means of binary QIM methods [6,4]. To do so, x is quantized using multiple quantizers whose indexes are chosen based on the message to be embedded [3].To implement such quantizers, dither modulation (DM) can be used [3], thus obtaining the watermarked signaly:(1){q=QΔ(x−Δ(b/2+k))−(x−Δ(b/2+k))y=x+αqwhereΔis a fixed quantization step size,ka random key (sampled from a white, uniform noise,0<k≤1) andαa fixed parameter,0<α≤1.The quantizerQΔis defined as follows:(2)QΔ(x)=ΔRound(x/Δ)whereRound()is the approximation to the closest integer.The practical balance between the transparency and the robustness can be reached by adjusting theαandΔparameters: the lower theαandΔvalues, the lower the difference betweenxandyand, consequently, the greater the transparency but the worse the robustness.At the decoder, the embedded message bits are recovered by a scalar quantization of the received signal sample r which represents the y signal after its corruption by attacks.The Y (b) decision variable is computed as follows [3,4]:(3)Y(b)=QΔ(r−kΔ)−r+kΔThe aim is to decide whether the inserted bit wasb=0orb=1. The optimal decision rule, assuming the attacks are modelled by additive white Gaussian noise is (seeFig. 4) [3]:(4){|Y(b)|<(1−α)Δ/2→b^=0|Y(b)|≥(1−α)Δ/2→b^=1In order to generalize the insertion technique, be there the same binary messagebto be inserted in the same original datax.Prior to its insertion, the messagebis encoded into a messagedbelonging to an m-ary alphabetD; assumingmis an odd valueD={−m−12,−m−22,…0,…m−22,m−12}.On average, eachdsymbol corresponds tolog2mbits from the messageb[20].By following the principles above, the m-QIM insertion can be expressed as(5){q=QΔ(x−Δ(dm+k))−(x−Δ(dm+k))y=x+αqas in the binary case, the lower theαand theΔ, the lower the difference betweenxandyand the greater the transparency but the worse the robustness. However, this time, eachxsample bears onedm-ary symbol, thus increasing the data payload by a factor oflog2m, with respect to the binary case.While keeping practically the same insertion rule, see (1) vs. (5), the multi-symbol generalisation requires the modification of the decision rule. In the present paper, a decision rule minimising the probability error in mark detection under the white additive Gaussian noise hypothesis is derived.Let us consider first the case in which no attack occurs. The decision is based on the value of theY(d)variable(6)Y(d)=QΔ(x+αq−kΔ)−(x+αq−kΔ)Y(d)is a quantization error belonging to the[−Δ/2;Δ/2]interval. Hence, specifying a decision rule means to divide the decision region[−Δ/2;Δ/2]into m non-overlapping intervals. These intervals are computed based on a three-steps development presented below. First, theY(d)expression is reformulated so as to no longer depend on the original datax. Second, the decision intervals are computed by expressing the quantization error as a function ofα,d,mandΔ. Finally, the value of theαparameter ensuring non-overlapping intervals is computed.Step 1:Y(d)reformulation.We denote:A=x−Δ(d/m+k)andB=x+αq−kΔ.The expression ofAas a function ofBis obtained as follows:(7)B=x+α(QΔ(x−Δ(dm+k))−(x−Δ(dm+k)))−kΔ=x+αQΔ(A)−α(x−Δ(dm+k))−kΔ=(1−α)(A−QΔ(A))+QΔ(A)+Δdm=(α−1)q+QΔ(A)+ΔdmThen,Y(d)can be written as follows:Y(d)=QΔ(B(d))−B(d)=QΔ((α−1)q+QΔ(A)+Δdm)−(α−1)q−QΔ(A)−ΔdmasQΔis by its definition a multiple ofΔ,Y(d)can be simplified as follows:Y(d)=QΔ((α−1)q+Δdm)−(α−1)q−ΔdmLetC(d)=(α−1)q+Δd/mthen(8)Y(d)=QΔ(C(d))−C(d)Note that while (6) and (8) are equivalent from the mathematical point of view, the right-hand term of (8) does no longer depend on the original (unmarked) datax.Step 2: Decision intervals as a function ofα,d,mandΔ.We have−Δ/2<q<Δ/2and0<α≤1; this implies(9)Δ((α−1)m+2d)/2m<C(d)<Δ((1−α)m+2d)/2mBe there(10){Isup,α(d)=Δ((1−α)m+2d)2mIinf,α(d)=Δ((α−1)m+2d)2mFrom Eqs. (5) and (6) we obtain(11)−Isup,α(d)+QΔ(C(d))<Y(d)<−Iinf,α(d)+QΔ(C(d))QΔ(C(d))is the quantized value ofC(d)with quantization stepΔ; hence(12){QΔ(C(d))=lΔ,l∈Z(l−12)Δ≤C(d)<(l+12)ΔEqs. (9) and (12) imply(13){((1−α)m+2d)2m<l+1/2((α−1)m+2d)2m>l−1/2asdis a symbol from the m-ary alphabet D, we have|d|≤(m−1)/2Hence, Eq. (13) gives(14)|l|<|(m−1)/m−α|2then:l=0and consequentlyQΔ(C(d))=0. According to (10) we get(15)−Isup,α(d)≤Y(d)≤−Iinf,α(d)Eq. (15) demonstrates that the insertion of thedsymbol results inY(d)values belonging to the[−Isup,α(d)−Iinf,α(d)]interval.Iα(d)depends onΔ,α, andm: whileΔandmare fixed for an application,αis a parameter which can be chosen so as to ensure non-overleaping decision intervals.Step 3: Computing the optimalαvalue.For a fixed value ofαparameter,Isup,αandIinf,αdefined in Eq. (10) are positive slope affine functions, i.e. increasing functions ofd. Hence, if each two successive symbols (d, d+1) have non-overlapping decision intervals, then we will have m non-overlapping decision intervalsIsup,α(d)−Iinf,α(d+1)≤0This yields to(16)Δ((α−1)m+2d)2m−Δ((1−α)m+2(d+1))2m≤0Eq. (16) implies that the condition for obtaining non-overleapingIα(d)intervals isα≥(m−1)/m; beα⁎=(m−1)/m. The influence ofαon theIα(d)intervals is illustrated inFig. 5 form=5(hence,α⁎=0.8) andΔ=70. Three particular cases are considered, namelyα=0.76<α⁎(see Fig. 5 up-left),α=0.8=α⁎(see Fig. 5 up-right) andα=0.84>α⁎(see Fig. 5 bottom). In these three plots, the abscissa corresponds to the value ofd, while the ordinate stands for theIinf,α(in blue diamond) andIsup,α(in red square).Theα⁎can be considered as the optimalαvalue for computing the decision intervals: it ensures non-overlapping intervals (hence ideal robustness, assuming no attack occurs) and the best transparency (the minimal differences between the host and the marked signals). Consequently, the optimal decision rule associates to each inserteddsymbol a detection intervalIα⁎(d)=[−Isup,α⁎(d)−Iinf,α⁎(d)]. In other words, when a particularY(d)value is computed at the watermarking detection side, we decide that the inserted symbol wasd^, where(17)ifY(d)∈Iα⁎(d^)=>d=d^Assume now the case in which the attacks are present: the insertion of adsymbol can result now in a valueY(d)outside theIα⁎interval. Intuitively, in order to decrease the errors induced by such a situation, a valueα>α⁎should be considered at insertion/detection, i.e. a lower transparency should be accepted in order to grant some additional robustness against attacks, see Fig. 5. TheIα⁎andIαobtained for m=5 (henceα⁎=0.84),α=0.84andΔ=70are illustrated inFig. 6.As usual in the watermarking studies [21], we shall assume that the attacks are independent with respect to the inserted symbol and that they can be modelled by a white, Gaussian noise which is added to theY(d)value computed for a fixedα>α⁎parameter; theY˜(d)variable becomesY˜(d)=Y(d)+nY˜(d)can fall between twoIα(d)decision regions or even outside the[−Δ2;Δ2]interval. Consequently, the optimal decision rule defined in Eqs. (6) and (17) should be extended so as to cope with such a situation, as follows. First, although the insertion is performed for anα>α⁎value, the decision regions will be computed on theIα⁎basis: this way, all the values inside the[−Δ2;Δ2]are considered. Moreover, in order to avoid the cases in whichY˜(d)would fall outside the[−Δ2;Δ2]interval, a modulo operator is applied prior to the detection. The corresponding decision variableY˜Δ(d)and the underlying decision rule are(18)Y˜Δ(d)=Y˜(d)moduloΔ−Δ2ifY˜Δ(d)∈Iα⁎(d^)=>d=d^The error probability associated to the decision rule in Eq. (18) and its optimality are discussed in the following section.In the sequel, we shall incrementally express the probability density function for theY(d),Y˜(d)andY˜Δ(d)decision variables.TheY(d)variable is computed as the result of a quantization error and belongs to theIα(d)=[−Isup,α(d)−Iinf,α(d)]intervals, cf. (6) and (17). Consequently, the probability density function of theY(.)variable conditioned on the insertion of theΔ=90symbol is denoted bypY(u/d)and can be modelled by a uniform law in that interval [20]:pY(u/d)={1(1−α)Δ,ifu∈Iα(d),0,ifnotThe noise probability density function, denoted bypn(n), is assumed to follow a normal (Gaussian) law ofμ=0mean andσstandard deviationpn(n)=12πσe−n2/2σ2AsY˜(d)=Y(d)+n, its probability density function conditioned on the insertion of thedsymbol can be expressed as the convolution between thepY(y/d)andpn(n)pY˜(y/d)=(pY(u/d)⊗pn(n))(y)=1(1−α)Δ∫−Isup,α(d)−Iinf,α(d)12πσe−(y−t)2/2σ2dtThus,pY˜(y/d)can be expressed by using theerfcfunction(19)pY˜(y/d)=12(1−α)Δ(erfc(−Isup,α(d)+y2σ)−erfc(−Iinf,α(d)+y2σ))whereerfc(⋅)is the complementary error function function defined byerfc(x)=2π∫x∞e−t2dtAsY˜Δ(d)=Y˜(d)moduloΔ−Δ/2, its conditional probability on the insertion of thedsymbol was computed in our study from thepY˜(y/d), by following basic principles in non-linear random variable filtering:(20)pY˜Δ(y/d)=∑ipY˜((iΔ2+y)/d),i=2j+1,j∈ZEqs. (19) and (20) show that irrespective to thedsymbol,pY˜Δ(y/d)has a maximal value corresponding the centre of theIα(d)and symmetrically decreases from that point, as illustrated inFig. 7 form=5,Δ=70andα=0.84.In its widest acceptation, specifying a decision rule means to define a partition of the interval in which the detection variable takes values [21]. In the m-QIM case, this means to define a partitionΔi,i∈{0,1,…,m−1}of the[−Δ/2,Δ/2]interval(21)UiΔi=[−Δ/2,Δ/2]and∩iΔi=∅Consider now the case in which a symboldiis inserted. A correct decision is made when theY˜Δ(di)variable belongs to theΔiinterval. On the contrarily, an error occurs when the attacks act in such a way that theY˜Δ(di)variable belongs to aΔj, withi≠j;i,j∈{0,1,…,m−1}.Table 3 illustrates the correct/erred decisions form=5: the rows correspond to the inserted symbols, while the columns to the decision; C stands for a correct decision while E stands for an erred decision.The probability of the correct decision when inserting thedisymbol is denoted byPc(di) and can be computed as follows:(22)Pc(di)=∫ΔipY˜Δ(y/di)dyThe average probability of a correct decision is denoted byPcand can be computed by averaging thePc(di)values(23)Pc=∑diP(di)Pc(di)The optimal detection rule should ensure the maximalPcvalue over all possibleΔipartitions of the[−Δ/2,Δ/2]interval.For watermarking applications, the inserted symbols are equally likely:P(di)=P(dj),i,j∈{0,1,…,m−1}. Hence, at the detection side, the probabilities of correct detection of the inserted symbols should also be equal(24)Pc(di)=Pc(dj),i,j∈{0,1,…,m−1}Eqs. (22) and (24) yield to(25)∫ΔipY˜Δ(y/di)dy=∫ΔjpY˜Δ(y/dj)dywherei,j∈{0,1,…,m−1}.Eq. (25) demonstrates that the optimal decision rule should ensure at the same time maximal and equal∫ΔipY˜Δ(y/di)dyvalues over all possibleΔipartitions.When coming now back to the expression ofpY˜Δ(y/d), see Eq. (20), it can be stated that:(1)equal values for the left and right side expressions in (25) can be obtained when theΔiintervals have the same length (i.e. a fifth of theΔvalue;for a given length of a decision intervalΔi,i∈{0,1,…,m−1}, a maximal value for∫ΔipY˜Δ(y/di)dyis obtained whenpY˜Δ(y/di)is centred within theΔiinterval.The two observations above demonstrate that the decision rule in (18) is an optimal decision rule, in the sense of maximizing the probability of correct decision, hence of minimizing the probability of error.Assume now the case in which adisymbol is inserted and a wrong decisiondj(dj≠di)is made. The probability of such an error, denoted byPe(di,dj), can be computed asPe(di,dj)=P(di)∫Iα⁎(dj)pY˜Δ(y/di)dyThe average error probability, when considering all the possible symbols to be inserted and all the possible errors in detection can be computed as the sum of the individual error probabilities(26)Pe=∑di,djdi≠djPe(di,dj),i,j∈{0,1,…,m−1}The error probability expressed by Eq. (26) corresponds to the error in detecting a symboldfrom an m-ary alphabet. Should we be interested in the error of detecting a symbol from the initial binary messageb, the general conversion formula can be applied [22,23](27)Peb=12mm−1PeFig. 8 illustrates the average probability error expressed by Eq. (26) as a function of the Gaussian noise standard deviationσ(presented on the abscissa), forΔ=70. Four alphabet sizes have been considered, namelym=2,m=3,m=5andm=7. In each case, 11 values for theαparameter are illustrated; these values are evenly distributed with a step 0.02 and are centered on the correspondingα⁎value; the case ofα⁎is plotted in red.By analyzing these plots, the following conclusions are brought to light:•whenα<α⁎,Pe>0even in the absence of attacks (i.e. even whenσ=0); this is a consequence of the overlapping between the decision intervals, see Fig. 5;whenα=α⁎and in the absence of attacks (i.e.σ=0),Pe=0; this result derives from the fact that in the absence of attacks, the decision rule in (17) is deterministic andα=α⁎ensures the best robustness–transparency trade-off;ifα=α⁎andσ>0, thenPe>0; consequently, theα⁎value ensuring the best transparency cannot be exploited in practical applications: in order to grant some robustness to the attacks, anα>α⁎should be considered, thus impacting in the transparency;if the practical application requires a valuePe<0.1forσ<Δ/(4m)(i.e. for a Gaussian noise covering at 95% a particular decision intervalIα⁎(d), seeFig. 9), then valuesα≥α⁎+0.04should be considered. This lower limitα=α⁎+0.04will be further considered for the theoretical investigation of thePevariation as a function ofΔ(seeFig. 10) and for the experimental validations in Sections 4 and 5;all thePeplots converge towards(m−1)/m, whenσ→Δ/2(i.e. in the case of a very strong Gaussian noise, covering practically all the[−Δ2;Δ2]interval), see Fig. 9.Fig. 10 illustrates the average probability error expressed by Eq. (26) as a function of the Gaussian noise standard deviationσ(represented on the abscissa), forα=α⁎+0.04; the same four values for m have been investigated: m=2, m=3, m=5 and m=7 . In each case, seven Δ values are illustrated, namely Δ=40 , Δ=50, Δ=60, Δ=70, Δ=80, Δ=90, and Δ=100. By analyzing these plots, we can see thatPeis a decreasing function of Δ, at a fixed value ofσ. Hence, the increase of Δ means a priori a stronger robustness, obtained at the expense of a weaker transparency. In the sequel, we shall consider Δ values between 50 and 90 and we shall discuss their practical relevance.

@&#CONCLUSIONS@&#
