@&#MAIN-TITLE@&#
Multi-objective evolutionary algorithms for energy-aware scheduling on distributed computing systems

@&#HIGHLIGHTS@&#
Heterogeneous, energy-aware precedence constrained (DAG) scheduling problem.Three multi-objective algorithms schemas are adapted: MOCell, NSGAII and IBEA.A representation with corresponding mutations and grouping crossover operators.Experimentation on a diversified and large set of real and synthetic applications.MOCell schema is the most versatile and the best performing one.

@&#KEYPHRASES@&#
Evolutionary algorithms,Multi-objective optimization,Scheduling,Energy efficiency,Dynamic voltage scaling,

@&#ABSTRACT@&#
The ongoing increase of energy consumption by IT infrastructures forces data center managers to find innovative ways to improve energy efficiency. The latter is also a focal point for different branches of computer science due to its financial, ecological, political, and technical consequences. One of the answers is given by scheduling combined with dynamic voltage scaling technique to optimize the energy consumption. The way of reasoning is based on the link between current semiconductor technologies and energy state management of processors, where sacrificing the performance can save energy.This paper is devoted to investigate and solve the multi-objective precedence constrained application scheduling problem on a distributed computing system, and it has two main aims: the creation of general algorithms to solve the problem and the examination of the problem by means of the thorough analysis of the results returned by the algorithms.The first aim was achieved in two steps: adaptation of state-of-the-art multi-objective evolutionary algorithms by designing new operators and their validation in terms of performance and energy. The second aim was accomplished by performing an extensive number of algorithms executions on a large and diverse benchmark and the further analysis of performance among the proposed algorithms. Finally, the study proves the validity of the proposed method, points out the best-compared multi-objective algorithm schema, and the most important factors for the algorithms performance.

@&#INTRODUCTION@&#
The energy efficiency of Information Technologies (IT) is one of the biggest current issues in the field of computing. The global data center power is estimated as 38.9GW, and increased by 19% in 2012, and consecutively by 7% in 2013 [1]. The rapid increase of energy consumption of IT infrastructures, caused by growing scale and power of computing systems, resulted in development of a new discipline of IT – called commonly as GreenIT. Researchers and engineers make advances in every aspect of the domain to ensure increasing energy efficiency, with an important distinction between two categories of energy usage optimization, called static and dynamic power management [2]. The difference between them is that static power management takes place during the design time of the IT element on which it is applied. Oppositely, dynamic power management is a technique, which is executed during running of such element. One of the main dynamic management methods to optimize performance in computing systems is to use the best schedulers.Classically, the optimal schedule is the one that executes the workload minimizing one of the execution time functions, e.g. minimizing total execution time. However, an energy-efficient scheduling algorithm has to minimize consumed energy. Such algorithms exploit power management technologies available in hardware to achieve this aim. As the biggest influence for power consumption of a server is its processor [3], this study focuses on minimizing its energy consumption. The processors manufacturers offer two main technologies: resource hibernation and Dynamic Voltage Frequency Scaling (DVFS) [2,4].In this work, we focus on DVFS technology that exploits the characteristics of power function of electronic circuits. The most common modern circuit technology, complementary metal-oxide-semiconductor (CMOS), has a convex power function of supplied voltage and frequency. Additionally, frequency in such circuit is linear function of voltage. Therefore, using low voltage levels leads to energy savings. This technique may also result in decreased Quality of Service (hereinafter, QoS), as decreasing processing speed may increase total execution time. However, this technique is much more adaptable to changes than resource hibernation, as DVFS transition time (30–150μs) is much shorter than hibernating a resource (few seconds, which decreases system responsiveness and thus QoS) [5]. Such elasticity of DVFS enables its direct incorporation into the scheduling process for each task. The only requirement needed to successfully and meaningfully apply that technique is that single task execution times are significantly bigger than DVFS transition time.The most common state-of-the-art technique using DVFS is called slack reclamation [6]. It is a post-processing algorithm, which takes an already constructed schedule and uses tasks’ slack times to reduce performance of processors whenever it is possible without increasing total completion time. It has been adopted in many algorithms as it is easy to apply and gives considerable energy savings (see Section ‘Energy-aware scheduling: related work’). The main assumption that leads to the next generation of algorithms using DVFS is that involving it into the scheduling step itself will lead to greater energy savings. This work follows this direction, as used methods allow to apply DVFS at each step of a schedule creation.The problem of precedence constrained task scheduling is NP-hard in the simplified case of equal length tasks, homogeneous processors, and no communication costs [7]. This work tackles a generalization of the problem, with precedence constraints, heterogeneous processors using DVFS technology, communication costs, and another objective – the energy consumption.The contributions of this paper are threefold. (1) We propose three scheduling algorithms to solve the heterogeneous multiprocessor multi-objective scheduling problem. They based on state-of-the-art multi-objective (MO) algorithms schemas, with new grouping crossover and mutation operators. (2) We do a thorough empirical study of the problem, evaluating the performance of different operators in the algorithms and the influence of instance parameters on the solutions obtained. Finally, (3) we identify the most important factors of the problem, as well as the best performing algorithm for the problem, with statistical confidence.The remainder of the paper is structured as follows: in Section ‘Problem description’ the tackled problem is described. The state of the art on energy-aware scheduling is presented in Section ‘Energy-aware Scheduling: Related Work’. Section ‘Algorithms description’ describes the proposed solution for the problem and Section ‘Experimentation’ analyses the results of simulations over the large set of instances. Section ‘Conclusions and future work’ includes conclusion and presents future research directions.The addressed scheduling problem deals with the optimal allocation of a set of tasks that compose a parallel application to the set of processing elements in a distributed system. The target is minimizing both the total execution time and energy consumed by the execution of the application.The distributed computing system consists of a set R of m heterogeneous processors. For each processor rl, a set of DVFS pairs Dlis defined. A DVFS pair k, denoted as dk, is a tuple(vk,sk), wherevk∈ℝ+is the operational voltage of the processor andsk∈ℝ+is the ratio of the operational speed to the maximal processor's speed, further called as relative speed.We consider a parallel application represented by a Directed Acyclic Graph (DAG) G=(T, E, pil, cij), where T denotes the set of t tasks, and the set E of directed edges indicates the precedence relation between tasks. Each node ni∈T is associated with one non-divisible task tiof the parallel application. The processing time or weightpil∈ℝ+of task tidenotes its computation time on processor rl∈R. For each edge eij∈E there is a costcij∈ℝ+to communicate data between tasks tiand tj. The partial order ti≺tjmodels precedence constraints, i.e. if there is an edge eij∈E. In this case, tiis said to be an immediate predecessor of tj, and Γ+(tj) denotes the set of immediate predecessors of tj. Also, tjis said to be an immediate successor of ti, and Γ−(ti) represents the set of immediate successors of task ti. A task tiwithout predecessors, Γ+(ti)=∅, is called an entry task. If it does not have any successors, when Γ−(ti)=∅, it is a sink task.A scheduling is defined as a tuple of functions (σ, π, λ, γ), such thatσ:T↦ℝ+, π:T↦R, λ:T↦Dl, and γ:R×X↦D, where σ(ti) represents the time at which task tistarts its execution, π(ti) provides the processor rlon which tiis executed, λ(ti) supplies the relative speed slito run ti, and γ(rl, x) provides the DVFS pair dkused by the processor l at time x. The real execution time of a task i scheduled on a processor l with a DVFS pair k is defined as: pilk=pil/sk.A schedule is feasible if the following conditions are fulfilled for all tasks in G.1.The Processor Constraint. For any pair of tasks ti, tj∈T, one processor may not execute more than one task at a time. That is, if π(ti)=π(tj)=rl, then σ(ti)+pilλ(i)≤σ(tj) or σ(tj)+pjlλ(j)≤σ(ti).The Precedence Constraint. ∀ (eij∈E), the task tjcannot be executed before task tihas finished its execution: σ(tj)≥σ(ti)+pilλ(i) if π(ti)=π(tj). Otherwise, if π(ti)=rkand π(tj)=rland rk≠rl, σ(tj) =maxti∈Γ+(tj)σ(ti)+pikλ(i)+cij, the time when all communications from tj's predecessors have arrived at rl.The DVFS Constraint. For any time, a processor rlhas allocated exactly one DVFS pair, i.e. ∀ (x∈X) ∀ (rl∈R) ∃! (dk∈Dl) such that γ(rl, x)=dk, where X represents the time when the system is used.The completion time of each task ti∈T is defined byCtj≡σ(tj)+pjlλ(tj). The makespan of the schedule is defined as:Cmax≡maxtj∈TCtjand is the maximum completion time of a task of G. The first objective of the optimization is to find a schedule for G on the processors R with the minimum makespan: minCmax.The second objective is related to the energy consumed by the system. It is based on the equation of dynamic power consumed by the CMOS circuit (the prevalent technology used in modern integrated circuits) [6]:(1)P=ACefV2f=αV2f,where A is the number of switches per clock cycle, Cefis the total capacitance load, V is the supplied voltage, and f is the corresponding frequency. Relative speed rsjis proportional to frequency f, so we use directly rsjas reported by processor manufacturers instead of f. As A and Cefare constant for a machine, we simplify them to single coefficient α. The value of α is always set to 1 to normalize the voltage-frequency tables. Finally the consumed energy is defined as:(2)Et=∑j=0m∫0CmaxPl(x)dx=∑l=0m∫0Cmaxvl(x)sl(x)2dx,where x is time, Pl(x) is the power of machine rlover time,vl(x)is the voltage of machine rlover time, and sl(x) is the relative speed of the machine rlover time. The second objective is to minimize the consumed energy: minEt.The problem of scheduling DAGs with minimum makespan and energy is a trade-off between schedule length and energy consumption. The reduction in energy consumption in DVFS-enabled processors is made by decreasing supply voltage and frequency, resulting in a slower tasks execution and an increase in the schedule length. As energy is a convex function of relative speed, running a task using lower frequency results in lower total energy consumption.An important number of scheduling algorithms have been proposed for energy consciousness. These algorithms differ on the assumptions they consider [4]. However, the most common technique to save energy they exploit is DVFS with slack sharing or slack reclamation.Zhu et al. present in [8] slack reclamation-based scheduling algorithms. The algorithms adopt a global scheduling in which all tasks wait in a global queue and are dispatched based on their priorities. Zhang et al. [9] report a scheduling algorithm based on a two-phases process. The first phase aims to optimize the possibilities for selecting different voltages based on the priority of tasks. Then, the voltage scaling problem is modeled as an integer programming problem in the second phase. The authors considered continuous supply voltage selection and showed that the integer programming problem is solvable in polynomial time. To solve the discrete version of the problem, the authors proposed an approximation algorithm.Aupy et al. [10] study the problem of scheduling precedence-constrained applications aiming to minimize energy consumption while considering a given bound on the makespan and a reliability threshold. The target architecture is a set of homogeneous processors. The authors propose several polynomial time scheduling algorithms under the continuos speed model.Wang et al. exploit the idea of extending the execution time of non-critical jobs by lowering the speed of processors without extending the makespan's application [11]. Two scheduling algorithms are proposed. The first algorithm exploits the best-effort idea: it first optimizes makespan under maximum voltage and speed assumption using a list scheduling algorithm and then energy is optimized in a second step with a voltage scaling algorithm, by lowering the processor's voltage for extending the execution time of non-critical jobs, or when it is in idle time. The second algorithm is a clustering-based scheduling algorithm that gather tasks into clusters according to the edge zeroing policy. It is guided with aim of reducing power consumption.Baskiyar and Palli [12] use the heterogeneous earliest finish time (HEFT) heuristic as a best-effort scheduling algorithm, then it performs voltage scaling without performance degradation. The authors considered continuous voltage. In [13] the authors combined the Decisive Path Scheduling (DPS) list scheduling algorithm and dynamic voltage scaling with dynamic power technique.Rizvandi et al. report in [14] a heuristic called Multiple Frequency Selection DVFS. The algorithm exploits the idea of executing tasks using a linear combination of processors’ frequencies so that the utilization of all slack times is optimized. For each task its energy consumption is formulated as a constrained optimization problem. Then, the authors show that a combination of two frequencies lead to minimum energy consumption.Some recent approaches incorporate DVFS during the scheduling process. Shekar and Izadi develop in [15] an algorithm that schedules tasks to processors with low-power capability. The authors proposed a weighted cost function that considers the energy consumptions while taking scheduling decisions. Lee and Zomaya [6] report a set of Dynamic Voltage Scaling (DVS)-based heuristics to optimize a summation of two objectives: schedule length and energy consumption. After the heuristic computes the schedule of the application the arrangement is improved by using a local search algorithm. The local search only applies changes if it does not increase the schedule length and energy is minimized.Some researchers address the energy issue in a Pareto based approach. Mezmaz et al. proposed in [16] a parallel bi-objective hybrid genetic algorithm that is improved with the heuristics reported in [6]. The parallelization is based on the cooperative approach of the island and multi-start parallel models using the farmer-worker paradigm. The goal of the multi-start parallel model is to reduce the running time of a resolution. Pecero et al. developed in [17] a bi-objective greedy randomized adaptive search procedure (GRASP). The GRASP algorithm starts by generating a feasible solution using a greedy evaluation function at maximum voltage. Then, the solution is improved by a post-processing bi-objective local search. The bi-objective local search exploits the DVS technique.This section presents the algorithms used to solve the considered problem in this study. They are three state-of-the-art algorithms with different features that have been specialized for the problem at hands with a novel representation and operators. The source code of the implementation is published as an open source greenMetal project and available online.11http://greenmetal.gforge.uni.lu/download.html.The chosen three state-of-the-art techniques to find accurate solutions to the investigated problem are: NSGA-II [18], MOCell [19], and IBEA [20]. Their pseudocodes are shown in Fig. 1. The selection was guided to include algorithms with diversified features, like solutions ranking, feedback of non-dominated solutions from the archive into the population, or indicator based search, in which the quality indicator is a function which maps a Pareto set approximation into a real number [20]. Therefore, the search process is guided by a metric representing quality of a solution instead of its value.NSGA-II [18] is, probably, the most referenced algorithm in MO optimization. It uses a dominance depth ranking, which means that solutions are ranked according to the order of Pareto front to which they belong. The whole set of solutions is divided into Pareto fronts in recursive manner: first, the best Pareto front is created. After that, this front is removed from the population and the next Pareto front is created from the remaining solutions. Each consecutive front is one order higher than the previous one. The whole population is classified in this way and then fitness is distributed according to the order of solutions – the lower the order, the higher the fitness. Those solutions with higher fitness are preserved for the next generation. If there are additional solutions with the same fitness, crowding distance is used to preserve diversity.MOCell [19] uses external archive and spatial division of solutions. The archive is used to store the best found solutions as well as to provide feedback, i.e. to randomly replace solutions from the main population with solutions from the archive. The spatial division is done as in the canonical cellular GA [21]: each individual has its own place in a toroidal mesh and only the solutions from the certain neighborhood have chance to compete during the selection procedure. MOCell uses typical C9 neighborhood (including solution and its 8 closest neighbors). The spatial distribution of population provides more exploration possibilities by creating distinct areas, where different good solutions may emerge and by slowing down the convergence. When the archive is full, the crowding distance is used to remove the solutions from the most crowded regions.IBEA [20] implements hypervolume, a quality indicator, to assign fitness to solutions. Each solution is compared with all others in the population by hypervolume and its final fitness is set according to its aggregated performance against the others. Then, during the environmental selection phase, the worst solutions are removed until population reaches its allowed size.Despite all mentioned differences, all three algorithms share large part of their characteristics. They all use binary tournament selection as mating selection mechanism, which creates new individuals for the population. In the implementations in this work, they share the representation (presented in Section ‘Representation’), the grouping recombination operator, and the bit-flip mutation (both described in Section ‘Operators’). The probability for crossover and mutation has the same influence for all of them. Finally, they use the same concepts of individual, population, generation, and evaluation.The selected algorithms ensure that different state-of-the-art approaches were used to explore the problem, to avoid possible biased or unexpected behavior of one of the algorithms. Using the same parameters and operators of the algorithms ensures a fair comparison and is intended to neglect the impact of auxiliary factors. Additionally, the algorithms schemas were implemented using the jMetal [22] framework which was extended by a new GreenMetal set of libraries, which implements the studied MOP as well as the representation and operators described in further sections.There exist three main groups of representing multiprocessor scheduling problems [23]: node list, processor allocation, and direct representation. In the first approach only the task priority is given, in the second one each task is assigned to a machine. These two representations must be combined with an external method that will create the final schedule. The direct representation includes both assignment and the priority, resulting in the exact mapping, however at expense of increasing complexity, and complex genetic operators.The representation of a solution designed for this work is based on the processor allocation approach. A solution is composed of two vectors: the first contains information about the processors allocation, while the second one determines the DVFS pair that must be used by the allocated processor to run the task. The usage of the processor allocation model is motivated by the possibility of the usage of the structure of the DAG during the schedule creation, which guides the algorithm that sets the tasks priority. While restricting the set of available solutions, this approach removes regions of search space with clearly infeasible or low quality solutions. This restriction is additionally useful, as the problem becomes more complex because of adding the second vector of the decision variables to the solution representation. The vectors length is equal to task number and a greedy heuristic is used to create final scheduling. Examples in this section are based on the application presented in Fig. 2, which is run on processors presented in Table 1. Note that processors may have different available DVFS pair, which may have different mapping to used voltage and relative speed.A sample solution encoded in this form is presented in Fig. 3. The first row shows the position of a gene, which binds this gene to a task with a given number. The second row represents the processor assignment, by indicating the processor identifier to which a task is assigned. The third row determines the voltage level on the indicated processor. For instance, we can see in the figure that task 7 is assigned to processor 2 with the DVFS pair 3.The addition of the DVFS pair component makes the search space growing exponentially, which in case of DVFS-disabled system is mt(for m machines and t tasks), while in DFVS-enabled system it is(∑j=0mpairs(j))t(pairs(j) represents the number of available DVFS pairs for machine j) [24].There are two operators, which were implemented in problem specific form: crossover and mutation. These operators are explained in detail in the following sections.The crossover selected for this study is a grouping crossover [25,26]. It does not work on the tasks alone, but rather on groups of tasks. Such crossover is also able to merge whole groups of tasks, working on higher level than simple single or double point crossovers. As a result it is more likely that the whole groups of allocated tasks will merge and be executed on a single machine, which consequently leads to the decreased communication time and makespan minimization. The selected DVFS pair is not modified by this operator.In the first stage, the operator randomly selects a subset of all processors used in a solution. It is done by using an auxiliary group part for each solution. A group part is a random permutation of the list of processors used in a solution. The pseudo code of low complexity group part generation function is presented in Algorithm 1. The loops execution numbers are bounded by processor number m or length of solution equal to task number t. Complexity of this algorithm is therefore O(t+m), which can be simplified to O(t) under the assumption that t>m.Algorithm 1Group part generationRequire solution S, processor number proc_num1   aux_array ← create_array(integer,proc_num);2   for alli in 0:get_length(aux_array)−1 do3aux_array[i] ←−1;4   end for5   processors←0;6   for alli in 0:get_length(S)−1 do7gene←get_gene(S, i);8pa←get_processor_assignment(gene);9ifaux_array[pa] ==−1 then10aux_array[pa] ← pa;11     processors ← processors +1;12end if13   end for14   group_part ← create_array(integer,processors);15   j←0;16   for alli in 0:get_length(aux_array)−1 do17ifaux_array[i] !=−1 then18group_part[j]← aux_array[i];19j←j+1;20end if21   end for22   for alli in 0:processors−1 do23r←random(i, processors);24swap(group_part[i],group_part[r]);25   end for26   returngroup_part;After group part generation, a random point is selected in the group part and processors from this point until the end of group part form the subset used further in the crossover operation. All genes with assignments to the processors from this subset are then copied from the second parent to the first one. The pseudo code of this operator is presented in Algorithm 2. The length of group part and consequently the number of repetitions of outer loop is equal to m and inner loop always iterates t times. Complexity of this algorithm is O(tm).Algorithm 2Grouping crossover operatorRequire parent solutions: S1, S21S1′←S1;2   group← generate_group_part(S2);3   gl← get_length(group);4   r←random(0, gl−1);5   for alli in r:gl−16for allj in 0: get_length(S1′)−17tmp_gene ← get_gene(S2, j);8ifget_processor_assignment(tmp_gene) == group[i]9set_gene(S1′,j,tmp_gene);10end if11end for12   end for13   returnS1′;A sample operation of the crossover is presented in Fig. 4. Offspring is initialized as a copy of a first parent. The group part is generated from the second parent. A randomly chosen crossover point separates a section from the group part, which has in this case one element: 2. Then, all occurrences of separated elements in the group part are copied to the offspring on the same positions as they occur in second parent (1, 2, 4, 5).The two proposed mutation operators are in general forms of bit-flip mutation, adapted to the problem. As the grouping recombination work on high-level, the selected mutation is simple and intended to introduce random behavior, maintaining the diversity in the population. In the first type, both processor and DVFS pair assignments are changed. As processor determines valid DVFS pairs, it is selected randomly in the beginning. The processor may be changed to any other processor in the system. After that, the DVFS pair is chosen among the ones available for the processor. In the second type, only the DVFS pair assignment is changed. The DVFS pair may be changed only to one available for the given processor. New values are chosen randomly using a uniform distribution. In this work, both types of mutation are independent and occur with the same probability.Sample applications of mutation are presented in Fig. 5. Mutation Type 1 changes the processor allocation and then selects a new DVFS pair: mutation occurring on position 4 modifies task allocation from processor 0 to 1 and from voltage level 0 to 6. Mutation Type 2 changes only DVFS pair selection, from 0 to 4. Note that the available range of DVFS pairs varies among processors.

@&#CONCLUSIONS@&#
This study investigated the problem of scheduling precedence-constrained applications on heterogeneous, DVFS-enabled, distributed computing systems, considering simultaneously two independent objectives: schedule length and minimization of the energy consumption. Three algorithms are proposed and evaluated, based on state-of-the-art MOCell, NSGA-II and IBEA algorithms. Results show that MOEAs are able to provide accurate solutions for the addressed problem and confirm the effectivity of the method in which processor assignment and DVFS pair setting are done simultaneously, which is proven by the comparison with the HEFT algorithm. The MOEAs perform especially well in scheduling the DAGs that represents real applications. MOCell is the MOEA schema identified as the most suitable for this problem.The results present also an exploration of the problem by testing the algorithms on the large and diversified benchmark. The difficulty of solving the energy-efficiency scheduling problem by MOEAs is dependent mainly on processor number and CCR, with minor influence of task number. These observations are supported by Wilcoxon and Friedman statistical tests performed on the values of three quality indicators: Epsilon, IGD and Spread.There are three main directions of development, which can follow up this work. First of them is addressing the scalability issues and increasing the quality of solution for harder and bigger instances. This includes improving the algorithmic part by such steps as seeding the initial population, adding local search step, or optimizing the algorithm runtime. Advances in these fields could facilitate addressing scheduling problems with more than two objectives: for this problem the robustness and flexibility of a schedule could be additional objectives. The last proposed research direction is refining the algorithm energy model, to include more factors such as memory energy consumption and networking system components, as well as the heat dissipation issue.