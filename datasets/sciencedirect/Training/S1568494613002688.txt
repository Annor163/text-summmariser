@&#MAIN-TITLE@&#
Binary particle swarm optimization (BPSO) based state assignment for area minimization of sequential circuits

@&#HIGHLIGHTS@&#
State assignment for finite state machines is one of the main optimization problems in the synthesis of sequential circuits.PSO is a non-deterministic heuristic that optimizes a problem by having a population of candidate solutions called particles.An improved binary PSO algorithm is proposed and its effectiveness is demonstrated in solving the state assignment problem.One of the objective of state assignment problem is to synthesize sequential circuits targeting area optimization.Better results are achieved comparing to BPSO variants, genetic algorithm, simulated evolution and deterministic algorithms.

@&#KEYPHRASES@&#
State assignment (SA),Area minimization,Non-determinism,Heuristics,PSO,Binary PSO,

@&#ABSTRACT@&#
State assignment (SA) for finite state machines (FSMs) is one of the main optimization problems in the synthesis of sequential circuits. It determines the complexity of its combinational circuit and thus area, delay, testability and power dissipation of its implementation. Particle swarm optimization (PSO) is a non-deterministic heuristic that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. PSO optimizes a problem by having a population of candidate solutions called particles, and moving them around in the search-space according to a simple mathematical formulae. In this paper, we propose an improved binary particle swarm optimization (BPSO) algorithm and demonstrate its effectiveness in solving the state assignment problem in sequential circuit synthesis targeting area optimization. It will be an evident that the proposed BPSO algorithm overcomes the drawbacks of the original BPSO algorithm. Experimental results demonstrate the effectiveness of the proposed BPSO algorithm in comparison to other BPSO variants reported in the literature and in comparison to Genetic Algorithm (GA), Simulated Evolution (SimE) and deterministic algorithms like Jedi and Nova.

@&#INTRODUCTION@&#
We are living in an era of smart phones and smart devices that have the computing power of desktop PCs of few years back, yet, they can be occupied in our palms. This shrinking of area is still continuing, posing challenges to the design of efficient synthesis tools. Digital systems are comprised of a data path unit and a control unit. The data path unit is concerned with arithmetic and logic operations and the movement/storage of data among registers in the digital system. The control unit is the brain of any digital system and it controls what operations should occur at which point in the life cycle of a digital system. Control units are designed based on Finite state machines (FSMs). Subsequent to the design of a FSM from an given specification, each state in the FSM is binary encoded. Encoding plays a vital role in the design of digital systems. Different assignment of state codes will result in different combinational logic implementations and different cost values. It has been observed that minute changes in state codes have a significant effect on area, power and testability of a circuit. Automated design of FSMs to optimize a given cost such as area, power, performance and delay, etc. has been of considerable interest to the Computer Aided Design (CAD) community. This has not only posed new challenges but also opened new avenues of research for Very Large Scale Integrated (VLSI) CAD industry.The state assignment (SA) of an FSM is a problem that maps f:S→Bn, where n is the code length, n≥⌈log2|S|⌉, Bnis an n-dimensional Boolean hypercube and |S| is the number of states. To encode S states using k bits, the number of possible state assignment combinations is given by Eq. (1).(1)(2k)!(2k−|S|)!For example, if we have an FSM with 10 states, then each state will require 4 bits for unique encoding. The number of possible encodings will be 29,059,430,400. Exhaustively assigning each combination of code and looking for the one that will optimize the given objective will require large computational time. The SA of FSM is an NP (nondeterministic-polynomial time)-hard problem [15], which implies exponential complexity in the worst case.In area optimization of two-level circuits, the objective is to reduce the number of Sum of Product (SOP) terms, while in multi-level circuit optimization the objective is to reduce the number of literals (i.e. variables in true or complement form) in the expressions of the synthesized circuit. Several optimization techniques have been proposed to solve the SA problem. Previous research on two-level combinational realization of FSMs using deterministic heuristics for area minimization employed mechanisms such as implicit merging, code covering and disjunctive coding [9]. Finding a state assignment which resulted in common expressions and maximum literal savings was one of the objectives in state assignment problem. Devadas et al. proposed two algorithms [3,8], the first one is fan-out oriented and assigns close codes, from the perspective of minimum hamming distance, to the state pairs that have similar next state transitions. The second algorithm, that is fan-in oriented (also called Mustang), looks for state pairs with higher number of incoming transitions from the same states. Higher weights are given to the state pairs that are assigned close codes in order to maximize the frequency of common cubes in the encoded next-state functions. Deterministic algorithms for area minimization of two-level circuits are also proposed in Jedi [2] and Nova [5]. SIS: Sequential Interactive Synthesis [28] is an interactive tool for the synthesis and optimization of sequential circuits. SIS can synthesize combinational, synchronous and asynchronous circuits generating optimized two-level (Sum of Products form) or multi-level (factorized) equations, which can then further be mapped onto a user-defined component library representing gates, flip-flops, standard cells, etc. In a nutshell, SIS can be used as a framework to test and compare different algorithms, as a cost evaluator and also as a tool for automatic synthesis and optimization of sequential circuits. The focus in this paper is to optimize the area of multi-level circuits, and for that matter SIS tool has been utilized to compute the area requirements.Additional efforts have been made to to solve this problem deterministically using various objective functions. Sagahyroon et al. formulated the SA problem as an integer linear programming (ILP) problem for power minimization of FSMs [27]. Another approach for low power design is proposed by Salauyou et al. [23] which is based on sequentially assigning states with highest tranition probability state codes with Hamming distance of 1. In [4,5,7] multi-level area minimization has been modeled as constrained graph-embedding problem on Boolean hypercubes.Due to the complexity of SA problem, and the limitations of existing deterministic algorithms, there has been a flurry of interest in the use of non-deterministic heuristic algorithms like Genetic Algorithm (GA) [10,12,16,18,20], Simulated Annealing [2,26], Tabu Search (TS) [19], Simulation Evolution (SimE) algorithm [30] and using other Evolutionary Algorithms [17,21]. The GA has been used to optimize power consumption by dividing a state machine into sub FSMs, and then in each partition, the states have code with minimum hamming distance [24]. Later on, power consumption is reduced by selectively activating the FSM partitions. In another approach, Chaudhury et al. [25] proposed GA-based methodology to minimize area, leakage (static) power as well as dynamic power during synthesis of finite state machines. A multi-objective GA is proposed [29] to minimize the power and area requirements of completely and incompletely specified sequential circuits. Amaral et al. [12] used GA with cost function proposed by Armstrong [1]. Armstrong measure combines fan-in, fan-out and output costs for measuring literal savings. Amaral proposed a matrix representation as genotype, and a desired adjacency graph (DAG) as a tool for applying heuristic rules on FSM [6]. The obvious benefit of these algorithms is that they search for an optimal solution in a large search space and tend to produce promising solutions for hard combinatorial optimization problems given the tuning parameters are chosen carefully. The element of randomness in these algorithms tries to avoid local minima.In this work, the use of particle swarm optimization, a non-deterministic evolutionary algorithm based on the movements of birds, to solve SA for FSM problem is explored. An improved binary particle swarm optimization is proposed and SA of FSM is taken as a test case to compare the results of the proposed method with other variants of PSO, evolutionary and deterministic algorithms. The comparison criterion is the literal count in synthesized multi-level circuits. The rest of the paper is organized as follows. Section 2 discusses a simple example to illustrate the concept and importance of state assignment problem. In Section 3, we give a brief background of PSO and its evolution. In Section 4, we discuss our proposed binary PSO (BPSO) algorithm. An illustrative example is discussed in Section 5 to give a gist of particles evolution with time/iterations. Experimental setup and simulation results are discussed in Section 6, while conclusions are given in Section 7.To understand the state assignment problem, we now discuss a simple example. Fig. 1describes the states of an FSM, their transition to the next state and the output produced during transition from one state to the other depending on the input value. To understand the table in Fig. 1, consider a case when PresentState=S2. If input X=0 then NextState=S3 and Output=0 but if X=1 then NextState=S1 and Output=1.Since there are 5 states, a 3-bit code is required for encoding each state. Table 1shows two different state assignment codes labeled as “Code 1” and “Code 2”. The resulting area cost i.e., the number of literals computed using SIS [28], is 22 for “Code 1”. However, “Code 2” has significantly smaller area, resulting in 12 literals as compared to “Code 1”. The number of literals is a cost measure that correlates with the number of transistors in the circuit. For example, the equationy=ab+a¯chas 4 literals (a,a¯,b,c).This example demonstrates the significant impact of state assignment on the area of a synthesized sequential circuit.Particle swarm optimization proposed by Kennedy and Eberhart [11], is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. PSO optimizes a problem by having a population of candidate solutions called particles, and moving these particles around in the search-space according to simple mathematical formulae. The movements of the particles are guided by their own best known position (solution) in the search-space as well as the swarm's entire best known position. As improved positions are being discovered, they will be employed to guide the movements of the swarm.Initially, PSO algorithm was developed for problems that were continuous in nature. Later on, due to the discrete intrinsic nature of most of the real life problems, the original authors proposed discrete version of PSO [14]. In the following, we will take a brief look into both the continuous and discrete versions of PSO.The continuous PSO consists of the following two equations:(2)Vi(t+1)=ωt×Vi(t)+c1r1(pBesti−Xi(t))+c2r2(gBest−Xi(t))(3)Xi(t+1)=xi(t)+Vi(t+1)In the above equations, Vi(t+1) and Xi(t+1) are the new velocity and the new position of particle i at time (t+1), respectively; c1 and c2 are arbitrary constants, and r1 and r2 are random variables ∈(0, 1) of uniform distribution. pBestiis the best solution of particle i until time t while gBest is the overall global best solution among all the particles until time t. The pBestiof a particle is the exploitation factor, while gBest helps in the exploration of the solution space. This way particles try not only to come closer to their own best solution, but also to the global best solution with a certain probability and weight factor. ω is a linearly decreasing inertia factor that gives less weight to the previous velocity over the period of iterations. An upper bound on velocity Vmaxis normally placed to make sure that particles remain in a finite search space. In continuous PSO, large value of Vmaxtends to perform more exploration, while in binary PSO small value of Vmaxis preferred. The next position of a particle is computed by the addition of newly computed velocity and the previous position.Proposed by Kennedy and Eberhart [14], the binary version of Particle Swarm Optimization implements the decision making of a particle based on discrete decision i.e., “true” or “false”. In contrary to the continuous PSO, this algorithm represents each state of a particle in the form of discrete binary “0” and “1” numbers. The velocities in binary version are defined as probabilities with which a certain bit of particle's solution will change to “0” or to “1”. This way, velocity is clamped between the range [0,1]. Sigmoid function is used to map the continuous valued velocity given by Eq. (4) to the range [0,1] [14], as shown in Eq. (5).(4)Vij(t+1)=ωt×Vij(t)+c1r1(pBestij−Xij(t))+c2r2(gBestj−Xij(t))(5)Vij′(t+1)=sig(Vij(t+1))=11+e−Vij(t+1)The subscript i, j refers to particle number i and the particular bit j of that particle's velocity, respectively. The equation used to update position of a particle, originally proposed, is given below.(6)Xij(t+1)=1ifrij<sig(Vij(t+1))0otherwise.where rijis a uniformly distributed random number in the range (0,1).To understand the functionality of this approach, consider a case when velocity is limited in a range from [−4, 4], with Vmax=4 and Vmin=−4. The velocity component defines the probability with which a particle's bit should change its bit value. For example, if Vij=4, then using Eq. (5) will imply sig(Vij)=0.98, which is the probability that Xijwill have bit value “1”. Similarly, Vij=−4 implies sig(Vij)=0.018, which is the probability that Xijwill have bit value “1”. Finally, for Vij=0 we have sig(Vij)=0.5, in this case the search turns into pure random search and Xijcan be changed to either “1” or “0” with equal probability.Now, consider the case when pBestij=gBestj=1 and Xij=0 at time t, then Eq. (4) will increase the velocity of the jth bit of particle i, i.e., the probability of Xij(t)=1 is increased. For a second case where pBestij=gBestj=0 and Xij=1 at time t, then Eq. (4) will decrease the velocity of the jth bit of particle i, i.e., the probability of Xij(t)=0 is increased. Both of these cases are working well as expected i.e., when a certain bit in a particle is different from both the local best and the global best solutions, the velocity should either increase or decrease to maximize the probability of getting a bit similar to that of the global and local best solutions. This not only highlights the importance of velocity in PSO, but also quantifies the importance of constraining the velocity to a certain range.The limitations to the original algorithm occurs when either the current bit is the same as the local and global best solutions bits or when the global and local best solutions bits are different. When Xij=pBestij=gBestjat time t, in that case the velocity becomes a mere function of its previous velocity component, whereas, the velocity component should have been either decreased or increased depending on whether pBestij=gBestj=0 or pBestij=gBestj=1, respectively. The other limitation is when pBestij≠gBestj. In that case, if Xij=pBestijor Xij=gBestjthen the particle will end up following either its personal best or global best solution without improving the overall solution quality.In this paper, we propose an improved BPSO algorithm that will rectify the drawbacks of the original BPSO, discussed above. We then compare our approach to another modification proposed by Khanesar et al. [22] that uses the concept of “rate of change of velocity”.We propose a formulation that will utilize binary PSO (BPSO) algorithm to solve the SA problem. In our formulation, each particle will hold a complete solution i.e., each particle possesses codes for all states of a circuit. Fig. 2shows the contents of a particle, where for the purpose of illustration, a 4−bit code is assigned to each state. The size of a particle is the number of states in a circuit times the number of bits required to encode each state.In our proposed BPSO algorithm, we have modified the original algorithm to overcome its drawbacks. The following equation computes the velocity of the proposed algorithm. The velocity equation is separated into three different cases, which are mentioned below.(7)Vij(t+1)=ωt×Vij(t)+c1r1+c2r2ifgBj=pBij=1ωt×Vij(t)−c1r1−c2r2ifgBj=pBij=0ωt×Vij(t)otherwisewhere gBjand pBijare bits of global best and local best solutions of a particle. The position of a particle is updated using Eq. (6), whereas, ωtis a linearly decreasing inertia factor calculated using Eq. (8). ωt=maxand ωt=mindefine the maximum and minimum value of ω respectively, with t being the iteration number.(8)ωt=ωt=max−ωt=max−ωt=mint=max×tAs can be observed, Eq. (7) presents three different scenarios of updating the velocity component. These will rectify the problems of the original BPSO algorithm. For the cases when gBestj=pBestij=1 or gBestj=pBestij=0, the velocity component should be increased or decreased respectively, as both the global and local best solutions have a consensus. For the case when gBestj≠pBestij, the velocity remains unchanged and depends only on the previous velocity. This is justified as there is no agreement between the global best and local best solutions and hence none of them is favored.Algorithm 1 shows the pseudo-code of BPSO. It starts with initialization of particles and then successively updating velocity, position, local best and global best solution with each iteration. We did not specifically employ any local minima avoidance scheme and rely on the intrinsic random behavior of BPSO to avoid any such situation.Algorithm 1Binary PSO (BPSO)Require: No. of Particles, MaxIter, InputFile1:Read Input FileInitialize Particleswhile (iter≤MaxIter) dofor all (Particles i) doUpdate Velocity Viof Particle iUpdate Position Xiof Particle iValidateXifor duplicate codesif (currentSolutioni<pBesti) thenpBesti= currentSolutioniend ifend forgBestiter=min∀i(pBesti,gBestiter−1)iter++end whileThe algorithm takes as an input three arguments, No. of Particles, MaxIter and InputFile. Particles velocity and positions are then randomly initialized. Newly initialized positions are a set of codes that can be assigned to the states of a circuit under optimization. Before computing cost, state codes must be validated. In validation we check for duplicate codes, which are highly possible due to random initialization, and if any duplicate code is found then it is replaced with an unused code. Minimum Hamming Distance criterion is used to pick a code from a set of unused codes. For example, if we have 10 states in a circuit then we require 4 bits at minimum to encode them. So in this case we have 10 codes that are assigned to states and the remaining 6 codes unassigned. The personal best of each particle is the initial cost computed by random initialization. The global best is the minimum cost among personal bests.The velocity and positions are then updated using Eqs. (5), (6) and (7). Post processing is performed every time a position changes in order to replace any duplicate codes.We now discuss a simple example to illustrate the functionality of the proposed algorithm. The proposed algorithm is used to minimize the area of a small benchmark circuit. Our example consists of a case where number of particles=3, Max. iterations=20, c1=c2=1.5. The considered benchmark is bbara.kiss2 which has 10 states; therefore 4 bits are required to encode each state. The abbreviations used in the example are shown below along with their definitions.CVi,j: current velocity of jth bit of a particle i computed using Eq. (7).PVi,j: Previous Velocity of jth bit of a particle i.Xi,j: jth bit of current solution of a particle i.pBi,j: jth bit of personal best of a particle i.gBj: jth bit of global best among all particles.Expr: sgn(CVij).The initial state of particles is shown in Fig. 3. Since, there are 10states and 4bits are required to encode each state, therefore, the size of the particle is 40 bits. The current velocity CVi,jand previous velocity PVi,jvectors also have size 40 and are initialized to “0”. As evident from Fig. 3, each item in a particle has a binary value of either “0” or “1” and four items in sequence collectively form the code of a state.After random initialization, Particle 2 holds the global best solution and the personal/local best solution of each particle is its initial solution. We will now go through few iterations to observe the evolution of particles more closely.The state of particles after first iteration are shown in Fig. 4. To elaborate the computation of current velocity vector, consider encoding of state0(S0) of Particle 1. From Fig. 3 we can observe that X1,3=1, PB1,3=1, GB3=1, PV1,3=0. The ω has a range between 0.9→0.1. Therefore, using Eq. (8), ω=0.82 in first iteration. In the first step of a particle's evolution we compute the velocity, and in the proposed algorithm each bit in a particle's solution has an individual velocity component. In order to compute CV1,3 i.e., current velocity of bit at index 3 of particle 1, Eq. (7) will be utilized. Here, we have a condition GB3=PB1,3=1, therefore,V1,3(1)=ωt×V1,3(0)+c1r1+c2r2=c1r1+c2r2=1.69forr1=0.91,r2=0.86Then, sig(V1,3(1.69))=0.85. And finally, r13 a random number, is generated and gets a value of 0.64. Since r13<0.85, therefore X1,3=1, otherwise it would be X1,3=0. This way we compute the current velocity of each bit of a particle's current position and in the next iteration the current velocity of particle becomes its previous velocity. One important thing to discuss here is that after we change the current position of a particle, more than one states might end up with having the same code. To solve this, a validation check is performed each time a particle changes it position. In validation check, we seek for the duplicate codes and replace them with the unused codes with which they have minimum hamming distance. In current example, 4bit codes are used, so the set of codes that can be assigned are 16, ranging from 0000→1111. Since, there are 10states, a set of 6 unassigned codes is available to replace the duplicate codes based on minimum hamming distance criterion. After first iteration there is no change in the overall best solution, therefore the global best solution retains its initial solution.Figs. 5 and 6show the second and third iterations. After second iteration there is no change in the global best solution but the local best solutions of Particle 0 and Particle 1 are improved. After third iteration, the local best solutions of Particle 0 and Particle 2 are improved, resulting in Particle 2 holding a new global best solution with Cost=76. Continuing in this fashion, after 20 iterations Particle 1 holds the best solution with best Cost=70.To augment the discussion on the severity of state assignment problem in Section 2, Fig. 7shows the evolution of two randomly chosen particles for the first 50 iterations. The spikes in the figure show a sudden change in the cost with a slight change in state assignments.

@&#CONCLUSIONS@&#
