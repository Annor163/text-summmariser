@&#MAIN-TITLE@&#
A new heuristic based on local best solution for permutation flow shop scheduling

@&#HIGHLIGHTS@&#
We presented a new population-based heuristic (HLBS) for flow shop scheduling problems.HLBS is incorporated with a trace-model, a filter strategy, and a jump strategy.The proposed algorithm outperforms state-of-the-art population-based search algorithms.

@&#KEYPHRASES@&#
Scheduling,Heuristic,Permutation flow shop scheduling,Makespan,

@&#ABSTRACT@&#
This paper proposes a population-based heuristic based on the local best solution (HLBS) for the minimization of makespan in permutation flow shop scheduling problems. The proposed heuristic operates through three mechanisms: (i) it introduces a new method to produce a trace-model for guiding the search, (ii) it modifies a filter strategy to filter the solution regions that have been reviewed and guide the search to new solution regions in order to keep the search from trapping into local optima, and (iii) it initiates a new jump strategy to help the search escape if the search is trapped at a local optimum. Computational experiments on the well-known Taillard's benchmark data sets demonstrate that the proposed algorithm generated high quality solutions when compared to existing population-based search algorithms such as genetic algorithms, ant colony optimization, and particle swarm optimization.

@&#INTRODUCTION@&#
This paper proposes a population-based heuristic based on the local best solution, denoted as HLBS, for the minimization of makespan in a permutation flow shop scheduling problem (PFSP-makespan). The candidate problem determines the best sequence of n jobs that are to be processed on m machines in the same order in order to minimize the completion time of the last job on the last machine (makespan). It has proven to be one of the most studied NP-hard scheduling problems in the strong sense [1] and requires much computational time to find the optimal solution. Therefore, the development of heuristics that find near-optimal solutions in a reasonable computational time has attracted the attention of many researchers in recent decades.Framinan et al. [2] proposed a classification framework of heuristics for PFSP-makespan. The framework states that the development of a heuristic may consist of three phases: Phase I – index development, Phase II – solution construction and Phase III – solution improvement. A heuristic may consist of one or more of these phases which are generally independent of each other.In the index development phase, jobs are arranged according to a certain property such as the processing times of each job on each machine. The output of this phase is a ranking of jobs that might be employed either as the input for the next phase or as a solution itself. Dispatching rules such as largest processing time (LPT) and shortest processing time (SPT) are typical of this phase.In the solution construction phase, a solution is generated in a recursive manner inserting one or more unscheduled jobs in one or more positions of a partial schedule until the solution is completed; therefore, this phase consists of a number of loops. Palmer [3], CDS [4], Gupta [5], DAN [6], NEH [7] and CDSD [8] are well-known Phase II heuristics. It is worth noting that the NEH heuristic is currently one of the best constructive heuristics. Taillard [9] developed a fast NEH heuristic (NEHT) for PFSP-makespan. Recently, several NEH variants were developed to solve PFSP-makespan [10–13].In the solution improvement phase, an existing solution is improved by means of some procedures. The two main characteristics of this phase are: (1) an initial solution (input solution) is required and (2) the quality of the final solution is always equal to or better than the quality of the initial solution. Usually, improvement approaches are classified into descending local searches and meta-heuristics. Additionally, Framinan's classification framework shows that heuristics in the solution improvement phase have the longest computation time when compared to the solution construction and index development phases. Phase III heuristics include genetic algorithm (GA) [14–18], ant colony optimization (ACO) [19,20], particle swarm optimization (PSO) [21–25], differential evolution (DE) [26–28], iterated greedy algorithm (IG) [29,30], iterated local search (ILS) [31], simulated annealing (SA) [32–34], tabu search (TS) [35–39] and hybrid metaheuristics [40,41]. Several research papers reviewing heuristics for PFSP-makespan can be found in Framinan et al. [2], Hejazi and Saghafian [42], and Ruiz and Maroto [43].The proposed HLBS can be regarded as a type of Phase III heuristic. It generates a solution using the heuristic NEHT [9] in the initial iteration and lets the solution be the local best solution. A new trace-model generating rule is applied to the local best solution to generate a trace-model of the local best solution, and a solution construction method is applied to the trace-model to construct a population with a pre-specified number of solutions. A modified filter strategy is applied to the solutions in the population to generate an updated local best solution, and a new jump strategy is applied to help the search escape if the updated local best solution shows that the search traps into a local optimum. The major idea of the proposed algorithm is that the local best solution in an iteration possesses important information about the solution regions searched, so a trace-model generated based on the local best solution should provide valuable information for guiding the search to promising solution regions. In addition, the purpose of the modified filter strategy is to filter the solution regions that have been searched and guide the search to new solution regions. Computational experiments on the well-known Taillard's benchmark data sets [44] will be performed to evaluate the effects of the trace-model, the modified filter strategy, and the jump strategy on the performance of HLBS, and compare the performance of HLBS with other population-based heuristics such as genetic algorithms (GA), ant colony optimization (ACO) and particle swarm optimization (PSO).The remainder of this paper is organized as follows. Section 2 gives the problem statement, the proposed algorithm HLBS is described in Section 3. Section 4 provides computational experiments, and conclusions and further research of this study are summarized in Section 5.PFSP-makespan can be denoted as Fm||Cmax as first described by Graham et al. [45], where Fmrepresents a flow shop environment of m machines and Cmax refers to the makespan. We use the notation proposed by Graham et al. [45]; given a set J of n jobs, a set M of m machines and processing times pijfor each job j on each machine i, the problem consists of scheduling all n jobs at each one of the m machines. All the jobs must be processed in the same processing order and each job j can only start its execution on a machine i if both the previous job on the same machine i and the same job j on the previous machine i−1 have already been processed. The objective of this problem is to determine a job ordering that minimizes the completion time of the last job in the last machine, called the makespan. Although Garey et al. [1] showed that the problem with two-machine can be solved in polynomial time, the general case with m machines is known to be NP-hard. Given a permutation schedule j1,…,jnfor an m-machine flow shop, the completion time of job jkat machine i, Ci,jk, can be computed easily through a set of recursive equations:(1)Ci,j1=∑l=1ipl,j1,i=1,2,…,m(2)C1,jk=∑l=1kp1,jl,k=1,2,…,n(3)Ci,jk=max(Ci−1,jk,Ci,jk−1)+pi,jk,i=2,…,m;k=2,…,nThen makespan, Cmax, is obtained byCmax=Cm,jn.Many heuristics based on GA, ACO and PSO have been developed for solving PFSP-makespan. Different population-based heuristics propose different strategies to improve the solutions iteration by iteration. This research proposes a population-based heuristic based on the local best solution, denoted as HLBS, to solve PFSP-makespan. The strategy of HLBS is based on an idea that the local best solution in an iteration possesses important information about the solution regions searched. The basic process of HLBS is presented as follows:Set t=0. Generate an initial solution using NEHT [9] and let it be the local best solution and the best-so-far solution.do {Generate a trace-model based on the local best solution for iteration t.Generate a new population (M new solutions) by applying a solution construction method to the trace-model.Apply the modified filter strategy to the M solutions in the new population; update the local best solution.Launch the jump strategy if the search traps into a local optimum.t=t+1} while (Not Termination)Return best-so-far solution.The HLBS algorithm differs from general population-based heuristics in that it produces only a solution using the heuristic NEHT [9] in the initial iteration and sets the solution to be the local best solution and the best-so-far solution. The major loop in HLBS (do while loop) generates a trace-model based on the local best solution, constructs a new population with M new solutions by applying a solution construction method to the trace-model, and updates the local best solution with the solution produced by applying the modified filter strategy to the M new solutions. If the local best solution is not able to improve the best-so-far solution in a certain number of iterations, it is assumed that the search has trapped into a local optimum. Then the new jump strategy is launched to find a new initial solution as the local best solution and the same loop (do while loop) is performed on the new initial solution. The major components of HLBS: the trace-model generating rule, the solution construction method, the modified filter strategy, and the jump strategy are discussed in detail in the following sections.The new trace-model generating rule is applied to generate a trace-model when the local best solution is updated in every iteration. The following example illustrates the procedure of the generating rule. Given that the updated local best solution in an iteration is Π′=(3, 1, 2, 5, 4) and let τ(i, u) denote the trace-value of job u on position i, the generating rule first assigns a trace-value τlto each job on its position in Π′, that is τ(1, 3)=τ(2, 1)=τ(3, 2)=τ(4, 5)=τ(5, 4)=τl. Then, for each job, the new rule assigns a trace-value τpto the positions prior to its position in Π′ and assigns a trace-value τsto the positions succeeded to its position in Π’. Given that τp=1, τl=50 and τs=100, Table 1presents the trace-values for all the jobs on different positions. These three trace-values are set to be τp<τl<τsand have to be properly determined to allow the trace-model to keep a job as close as to its position in the local best solution while constructing new solutions so as to keep the valuable information of the sequence of the jobs in every iteration. The following solution construction method will clearly illustrate this idea.A solution construction in an iteration is composed of job-selections from the first position to the last position for the solution. A revised job-selection rule based on the probabilistic action rule of Dorigo and Gambardella [46] is proposed in HLBS. Given a parameter value q0 (0≤q0≤1), to select a job for position i, the job-selection rule first generates a random number q from a uniform distribution ranged [0,1]; if q is less than or equal to q0, then Eq. (4) is used to select the job; otherwise, a probabilistic action rule (Eq. (5)) is applied to select the job(4)j=argmax{τ(i,u)}u∈S(i),ifq=q0(5)P(i,j)=τ(i,j)∑u∈S(i)τ(i,u),ifq>q0where S(i) is the set of unscheduled jobs considered for position i and P(i, j) is the probability for placing job j on position i.The previous local best solution Π′=(3, 1, 2, 5, 4) and the trace-model in Table 1 are used to explain the procedure of the solution construction method. The method constructs a new solution by applying the job-selection rule to the first row of the trace-values in Table 1 to select a job for the first position, to the second row of the trace-values in Table 1 to select a job for the second position, and so on. The procedure for applying the job-selection rule for position 1 is presented as follows. Table 2summarizes the needed data; it includes the trace-values of the first row in Table 1 and the probabilities for placing the unscheduled jobs on position 1. The probability for placing an unscheduled job on position 1 is calculated by using Eq. (5). Since this is the first position, the unscheduled-job set S(1)={1, 2, 3, 4, 5} and the sum of the trace-values of the jobs in S(1) is∑u∈S(1)τ(1,u)=τ(1,1)+τ(1,2)+τ(1,3)+τ(1,4)+τ(1,5)=54. The probability for placing job 3 on position 1 is P(1, 3)=τ(1, 3)/54=50/54=0.925926, and for placing the rest of the jobs on position 1 are P(1, 1)=P(1, 2)=P(1, 4)=P(1, 5)=1/54=0.018519. Using the data in Table 2, the job-selection rule is implemented: it first randomly generates a number q from a uniform distribution ranged [0,1]; if q≤q0, since S(1)={1, 2, 3, 4, 5}, and τ(1, 3)=50 and τ(1, 1)=τ(1, 2)=τ(1, 4)=τ(1, 5)=1, job 3 (j=argmax{τ(i,u)}u∈S(i)=3) is selected for position 1; if q>q0, each job j will be selected with the probability P(1, j) respectively, and the commonly used roulette wheel selection [14] is applied to select a job for position 1. The P(1, j)s in Table 2 show that job 3 still has a high probability, P(1, 3)=0.925926, to be selected for position 1. As a result, the probability that job 3 will be retained on position 1 is q0+(1−q0)×P(1, 3); if q0=0.5, this probability is equal to 0.5+0.5×0.925926=0.962963.Although the probability to keep job 3 on position 1 is high, there still is about a 4% probability that one of the other four jobs may be selected for position 1. If job 5, instead of job 3, is selected for position 1, the job-selection rule is applied to select a job for position 2 using the trace-values of the second row in Table 1. Table 3presents these trace-values and the probabilities for placing unscheduled jobs (S(2)={1, 2, 3, 4}) on position 2. If a randomly generated number q≤q0, since τ(2, 3)=100 and τ(2, 1)=50, job 3 (j=argmaxτ(i,u)u∈S(i)=3) is selected for position 2; this is the purpose that the trace-values, τland τs, are set to be τl<τsin the trace-model. The probability that job 3 will be selected for position 2 is equal to q0+(1−q0)×P(2, 3)=0.5+0.5×0.657895=0.828948. This result shows that if job 3 is not selected for position 1, its position in Π′, it will be selected for position 2 with the highest probability. This illustrates the idea of the trace-model that a job will be placed as close as possible on its position in the local best solution while constructing a new solution.This simple example reveals that the effects of the trace-model and the solution construction method are highly influenced by the q0value and the ratio of τp, τland τs. A high q0 value and a large ratio of τland τpwill cause the job-selection rule to highly retain the job sequence in the local best solution. On the contrary, a low q0value and a small ratio of τland τpwill cause the job-selection rule to drastically change the job sequence in the local best solution and lose the important information embedded in the local best solution. In order to investigate this problem, a study on the relationship among the τl, τpand τsvalues and a variable q0 setting method are considered in HLBS. The relationship among the τl, τpand τsvalues can be described using two simple equations: τl=τp×x and τs=τl+τp×y=τp×x+τp×y=τp×(x+y), so the relationship among the τl, τpand τsvalues can be determined by the two parameters x and y. As the values of these two parameters x and y become larger, there exists a higher possibility that the job sequence in the local best solution will be retained in constructing new solutions. Therefore, a number of the combinations of x and y will be considered in order to study the effect of the trace-model on the performance of HLBS.In addition, a block property of PFSP-makespan is applied in the construction method. Several recent works [39,47,48] have shown that the block property of the PFSP-makespan can be developed and used to reduce the size of neighborhood. Therefore, the block property of PFSP-makespan will be considered in the construction method to improve the efficiency of HLBS. A solution of a PFSP-makespan problem can be presented as a PERT graph, and the length of the critical path of the graph is the makespan of the solution. A block is a sequence of consecutive jobs on a machine in a critical path; therefore, if a PFSP-makespan has m machines, the critical path of a solution will have m blocks. To apply the block property in the construction method for a PFSP-makespan problem with m machines, the HLBS will construct m solutions in each iteration. The first solution is constructed by choosing the first block from the local best solution and applying equations (4) and (5) to determine the jobs for the rest of the positions in the solution; the second solution is constructed by choosing the second block from the local best solution and applying equations (4) and (5) to determine the jobs for the rest of the positions in the solution and so forth. Since the number of positions to be filled out while constructing a solution is decreased, applying the block property in the construction method will improve the efficiency of the HLBS.Local search methods are crucial for improving the effectiveness of population-based heuristics. They usually are applied to the best solution in an iteration or the global best solution to improve the quality of the solution; however, this may cause a search trap into the local optima. Tzeng et al. [49] proposed a filter strategy to address this problem. The filter strategy is applied when all the members (M) finish constructing their solutions in an iteration. Its purpose is to filter the solution regions that have been reviewed and guide the search to new solution regions in order to keep the search from trapping into local optima. A filter-list, defined as a first-in, first-out queue, is used to store the makespan of the chosen solution in each iteration and a parameter, f-size, is defined as the size of the queue. The queue is set to be empty initially. When all the M solutions are constructed, the solutions are sorted according to their makespans in ascending order, and the filter strategy is applied from the top of the M solutions until the first solution, whose makespan is different from all the makespans in the filter-list, is found and store the makespan of the solution in the filter list. If none of the M solutions has a different makespan from the makespans in the filter-list, the last of the M solutions is chosen (but the makespan will not be stored in the filter-list). The purpose of comparing makespans instead of job-sequences of solutions while using the filter strategy is two-fold. Firstly, it may guide the search to the solution regions which have not been examined. Secondly, it can significantly reduce computation time by comparing the solution constructed by a member and the solutions stored in the filter-list; this is especially critical when the number of jobs considered in a problem is large. In addition, the idea of choosing the solution with the largest makespan when none of the M solutions has a different makespan from the makespans in the filter-list is that it may prevent the search of HLBS from quick convergence.Once a solution is chosen using the filter strategy, the local search method (denoted as NEHT_LS) is applied to improve the makespan of the solution. NEHT_LS integrates Taillard's Modified-NEH method [9] with Ruiz and Stützle's [29] iterative improvement method. Given that Π is the job sequence of the chosen solution, NEHT_LS first randomly chooses a job k and removes it from Π; then it inserts job k into the first position, the last position, and the positions between every two consecutive jobs in Π to generate n different solutions, and lets Π″ be the best of the n generated solutions. If the makespan of Π″ is smaller than that of Π, NEHT_LS will update Π with Π″ and will repeat the same procedure until Π cannot be further improved. If the makespan of Π is smaller than that of the local best solution, it will update the local solution with Π; if the makespan of Π is smaller than that of the best-so-far solution, it will update the best-so-far solution with Π. The procedure integrating the filter strategy and NEHT_LS is denoted as filtered local search (FLS) in this research.The modified filter strategy first implements FLS, then determines if the makespan of the schedule generated by FLS dominates the best-so-far solution. If so, it will stop; otherwise, it will implement FLS one more time by using the filter strategy to find a solution different from the one found by the filter strategy in the first FLS.The main idea of the jump strategy is to guide the search to jump to another solution region when the search is trapped in a local optimum. We define the search trapped in a local optimum when the search is not able to improve the best-so-far solution in a number of iterations. The solution generated by the jump strategy is considered to be a new initial solution, and the search procedure is restarted.The jump strategy proposed in this paper first applies the Destruction and Construction Operation [29] to the detected local optimum M times to generate M new solutions. The solution with the minimum makespan, which satisfies the following conditions: (i) the makespan is less than or equal to a pre-determined objective-value distance and (ii) the job sequence of the solution is different from the job sequence of the local optimum, is chosen and used as the new initial solution. The objective-value distance is defined to be the distance of a jump from the objective value of the current local best solution and is calculated by multiplying the objective value of the current local best solution with a parameter, jump-rate. If none of the M solutions satisfies the conditions, the same procedure will be implemented until a solution is produced. In order to apply the Destruction and Construction Operation to a schedule, S, first randomly choose n1 jobs from S and let the job sequence of the n1 jobs be s1 and the job sequence of the rest of the jobs in S be s2. Then, insert the first job in s1 into the first position, the last position and the positions between every two consecutive jobs in s2 and choose the sequence with the smallest makespan; repeat the same process until all the n1 jobs in s1 are inserted in s2. In this paper, the Destruction and Construction Operation is implemented three times with n1=5.The well-known Taillard's test problems for PFSP-makespan [44] are used to evaluate the performance of HLBS. The test problems are composed of 12 different problem sets with different numbers of jobs (n) and different numbers of machines (m) and 10 instances are included in each problem set. Due to computational burden, twelve instances, selecting the first instance from each of the 12 problem sets, denoted as Test1, are used to investigate the effects of the major components of HLBS: the trace-model generating rule, the solution construction method, the modified filter strategy, and the jump strategy. Note that the parameters defined for these components are: q0, x, y, f-size and jump-rate, respectively. Therefore, experiments will be designed based on the parameters to investigate the effects of the components. Then, HLBS with the best combination of the parameters will be applied to solve all the test problems, and its performance will be compared with promising population-based heuristics such as genetic algorithms (GA), ant colony optimization (ACO) and particle swarm optimization (PSO). All the algorithms in this paper are coded in C language and executed on the Linux operating system.Table 4summaries the three levels considered for each of the five parameters of HLBS: 0.5, 0.7, 0.9 for q0; 1, 50 and 100 for x; 200, 400 and 600 for y; none, 7 and 14 for f-size; none, 0.02 and 0.04 for jump-rate. Note that none for f-size refers to no modified filter strategy is applied and none for jump-rate refers to no jump strategy is applied. The remaining parameters of HLBS are the number of iterations without improvement for defining trapping at a local optimum and the termination criterion. The first parameter is determined by trial-and-error and set to be the number of machines of the instances solved, and the execution time, like most of the other researches, is chosen to be the termination criterion. Therefore, there are a total of 243 different combinations of the five parameters.The HLBS is applied with each of the 243 combinations to solve the 12 instances in Test1 with limited computation times, n×(m/2)×30 milliseconds [16], for thirty trials. The average relative performance (ARP) is used to measure the performance of the HLBS. The formula of ARP is as follows:ARP=∑i=1Rsolutioni−BestsolBestsol×100/R; given an instance, solutioniis the makespan obtained by trial i of the HLBS with a combination of the parameters for the instance, and Bestsolis the best makespan that all the research has found for the instance provided by Zobolas et al. [40]. The computation time for applying HLBS with a combination of the parameters to solve the instance, 500×20, with 30 trials is 4500s and is 9877.5s for solving all the 12 instances; therefore, the computation time for executing HLBS with all the 243 combinations of the parameters is approximately 28 days.The analysis of variance (ANOVA) is applied to analyze the ARPs produced. Table 5presents the results of the ANOVA table. The results show that all the parameters, except q0, significantly affect the ARP of the test problems. Therefore, the Duncan's test is applied to test all the significant parameters. Table 6summarizes the results of the Duncan tests: the minimum average ARP for each parameter is: x=50, y=600, f-size=7 and jump-rate=0.04. This condition is very close to the condition that generates the best solution: q0=0.9, x=50 and y=600, f-size=7 and jump-rate=0.04. Since the difference between the average ARP of q0=0.7 (0.546257) and the average ARP of q0=0.9 (0.546344) is negligible, the best combination of the five parameters for HLBS is determined to be q0=0.9, x=50, y=600, f-size=7 and jump-rate=0.04.A further experiment is performed to evaluate the effect of the trace-model generating rule and the solution construction method on HLBS. We replace the trace-model generating rule and the solution construction method with the commonly used SWAP or INSERT operation in HLBS. Given a job-sequence, a SWAP operation randomly chooses two jobs from the job-sequence and interchanges their positions, and an INSERT operation randomly chooses a job from the job-sequence and randomly inserts the job into the first position, the last position, or a position between every two consecutive jobs in the job-sequence. The HLBS using SWAP operation is denoted as H_SWAP and The HLBS using INSERT operation is denoted as H_INSERT. The HLBS, H_SWAP and H_INSERT are applied to solve all the 120 instances in the 12 problem sets with limited computation times, n×(m/2)×30ms, for ten trials, and a nonparametric test, Wilcoxon Signed Ranks, is applied to compare the performance of HLBS, H_SWAP and H_INSERT. Table 7presents the average ARPs produced by HLBS, H_SWAP and H_INSERT for the twelve problem sets and Table 8presents the results of all the Wilcoxon Signed Ranks tests. The results show that HLBS significantly dominates H_SWAP at a significance level of 0.011 and significantly dominates H_INSERT at a significance level of 0.02. This is especially true for larger size problems such as 100×20, 200×20 and 500×20.HLBS with the best combination of the parameters is then applied to solve all the 120 test problems, and its performance is compared with a ACO algorithms, PACO [19], a PSO algorithm, PSOvns and two hybrid GA related heuristics, NEGAvns [40] and HGA_RMA [16], which reported promising solutions for PFSP-makespan. Ruiz et al. [16] compared the performance of PACO and HGA_RMA based on the same number of replication runs (R=5) and the same computation times: n×(m/2)×30, n×(m/2)×60, and n×(m/2)×90ms. All the algorithms were run on a PC with Intel Pentium IV at 2.8GHz. Therefore, we compare the performance of HLBS with PACO and HGA_RMA based on the same computation times using a PC with the same computing power. Tables 9–11present the average ARPs produced by PACO, HGA_RMA and HLBS for the twelve problem sets with each of the three computation times respectively.The Wilcoxon Signed Ranks test is applied to test if the performance of HLBS significantly dominates PACO and HGA_RMA respectively. Table 12summarizes the results of all the Wilcoxon Signed Ranks tests. The results show that HLBS significantly dominates PACO and HGA_RMA under all the different computation times.Table 13presents the average ARPs generated by NEGAvns, PSOvns and HLBS on a PC with Intel Pentium IV at 2.4GHz under the same computation time, n×m/10s, and the same number of replication runs (R=10) [40]. The Wilcoxon Signed Ranks test is also applied to compare the performance between HLBS and each of the algorithms: NEGAvns and PSOvns. Table 14summarizes the results of all the Wilcoxon Signed Ranks tests. The results show that HLBS significantly dominates NEGAvns and PSOvns.This paper proposes a population-based heuristics based on the local best solution, HLBS, for the permutation flow shop scheduling problem (PFSP-makespan). The computational results have shown that HLBS is an effective heuristic for PFSP-makespan. It dominated all the promising population-based heuristics related to ACO, PSO and GA (PACO, PSOvns, HGA_RMA, NEGAvns). The results also showed that the proposed trace-model, solution construction method, modified filter strategy and jump strategy significantly influence the performance of HLBS. Furthermore, since the flow shop problem is a special case of the flexible flow line problem and the job shop problem, the proposed heuristic can also be applied towards these two problems. Additionally, the proposed algorithm can be applied to single machine problems.In addition, a few important observations made in this research should be noted. First, although HLBS with q0=0.9, x=50, y=600 performed well for solving all the test problems, its performance was not stable for solving hard test problems (50×20, 100×20 and 200×20) [50]. Computational results show that the parameter set for producing the best average ARP for each of the hard test problems differs from each other. Future studies focused on optimizing these parameters using metaheuristics such as genetic algorithms [51] are warranted. Second, although the jump strategy worked effectively for HLBS, it could not guarantee that a jump could jump out of the region of a local optimum. This would cause a search to converge to the same local optimum after the jump strategy was applied. This apparent limitation should be further investigated in order to develop novel mechanisms that can guarantee escape from the local optimum thus improving the effectiveness and efficiency of HLBS.

@&#CONCLUSIONS@&#
