@&#MAIN-TITLE@&#
Multiobjective memetic algorithm based on decomposition

@&#HIGHLIGHTS@&#
The algorithm uses the concept of decomposition borrowed from traditional mathematical programming to handle the approximation to the PF of the overall problem.It also uses two different search operators, namely DE and PSO to generate new solutions; hence the hybridization idea.The two used operators compete for resources; this is achieved through a dynamic resource allocation.Standard benchmarks, ZDT problems and the recently formulated CEC’09 test set have been used for testing.Performance results based on the IGD metric show that the hybrid algorithm is overall superior to versions with single search operators.

@&#KEYPHRASES@&#
Multiobjective optimization,Pareto optimality,Memtic algorithm,MOEA/D,DE,PSO,

@&#ABSTRACT@&#
In recent years, hybridization of multi-objective evolutionary algorithms (MOEAs) with traditional mathematical programming techniques have received significant attention in the field of evolutionary computing (EC). The use of multiple strategies with self-adaptation manners can further improve the algorithmic performances of decomposition-based evolutionary algorithms. In this paper, we propose a new multiobjective memetic algorithm based on the decomposition approach and the particle swarm optimization (PSO) algorithm. For brevity, we refer to our developed approach as MOEA/D-DE+PSO. In our proposed methodology, PSO acts as a local search engine and differential evolution works as the main search operator in the whole process of optimization. PSO updates the position of its solution with the help of the best information on itself and its neighboring solution. The experimental results produced by our developed memtic algorithm are more promising than those of the simple MOEA/D algorithm, on most test problems. Results on the sensitivity of the suggested algorithm to key parameters such as population size, neighborhood size and maximum number of solutions to be altered for a given subproblem in the decomposition process are also included.

@&#INTRODUCTION@&#
In this paper, we consider the following general continuous multiobjective optimization problem (MOP) which can be mathematically formulated as(1)minimizeF(x)=(f1(x),f2(x)…,fm(x))where x=(x1, …, xn)T∈X⊆Rnis an n-dimensional vector of the decision variables, X is the decision (variable) space, and F is the objective vector function that contains m real valued functions.In the last few decades, various types of multiobjective evolutionary algorithms (MOEAs) have been developed and they are considered a natural choice for solving MOPs (1). All MOEAs are population-based nature-inspired and operate on sets of candidate solutions (population). An MOEA generates a set of solutions in each of its generations during the whole course of evolution while moving towards the real Pareto front (PF) of (1).Despite the current widespread use of evolutionary algorithms dealing with test and real world problems, their computational cost remains a big issue among others. However, hybridization is a good way forward to address these issues when dealing with complicated and diverse sets of standard test problems and practical ones. The main positive effect of hybridising evolutionary algorithms is fast convergence towards the Pareto front, but with an increase in the overall computation cost. For instance, the number of generations is decreased when the available computation time is fixed or limited. As a result, the global search ability of an MOEA is not fully utilized. These positive and negative effects are experimentally studied in [1].Multi-objective evolutionary algorithm based on Decomposition (MOEA/D) was first proposed by Zhang et al. [2]. This paradigm decomposes a MOP into several single-objective optimization problems and then uses a population-based method to optimize these subproblems simultaneously. In this way, a set of approximate solutions to the Pareto optimal set is generated by minimizing each subproblem. Different search operators suit different optimization problems. It is, therefore, very crucial to chose an ideal operator in a particular evolutionary optimization algorithm for solving complicated optimization problems. More recently, these kind of issue and study has been carried out in [3].Memetic algorithms (MA) represent one of the recent growing areas of research in evolutionary computation. They are population based meta-heuristic search methods inspired by Darwinian principles of natural evolution and Dawkins notion of a meme defined as a unit of cultural evolution that is capable of local refinements [4–6]. They are also called genetic local search, hybrid genetic algorithms, and cultural algorithms. They can be derived with the use of multiple components/stratgies/operators/local search engines in the framework of the particular evolutionary algorithms. In this paper, we have proposed a new multiobjective memetic algorithm by employing particle swarm optimization (PSO) [7] and differential evolution (DE) [8] in the framework of MOEA/D [2]. This algorithm is called MOEA/D-DE+PSO. MOEA/D [2] is employed as a global search algorithm, while PSO and DE are employed as local search operators in this new algorithm. In case of stagnation of any of the search operators, we relocate them to a number of subproblems/solutions to keep them switched on during the whole process of evolution.Keeping in mind the principle of Ockham's Razor, the reader can see later the benefits of MOEA/D-DE+PSO on ZDT [9] and CEC’09 test instances [10]. The Proposed algorithm is more robust in finding the set of optimal solutions to almost all test problems.The following issues are addressed in this paper:1How each search algorithm be rewarded in MOEA/D-DE+PSO ?How each search algorithm is chosen and used in the next generation ?What are the effects of different population sizes on the performance of MOEA/D-DE+PSO?In the following we describe the basic ideas of DE [8], and PSO [7].It is a reliable and versatile optimizer proposed by Storn and Price [8,11]. It has very few control parameters and has been successfully applied to diverse sets of test and real-world optimization problems. DE uses vector differences for perturbing the population vector.In DE, a parent vector from the current generation is called a target vector, a mutant vector obtained through the differential mutation operation is called a donor vector and the final offspring formed by recombing the donor and target vectors is called a trial vector [12–14].DE has few mutation strategies. It generates an offspring by perturbing the solutions with a scaled difference of randomly selected population members.DE has attracted a lot of attention since 1995. A detailed review can be found in [12–14]. We have listed some different DE-mutation strategies in Table 1.In Table 1, the indices r1, r2, r3, r4 and r5 are mutually exclusive integers randomly chosen within [1, N] and are different from the index i. xbestis the best solution in the current generation, (xrj−xrk) is the difference vector, and F>0 is a positive control parameter that controls the amplification of the difference between two individuals, called scaling or mutation factor. F controls the balance between exploration and exploitation. A large value of F encourages exploration and a small value of F favors exploitation [13].A mutant vectory˜is uniformly crossed with the base individual xiand as a result a new solution y is generated.(2)y=y˜ifur≤CRxiotherwisewhere ur∈[0, 1] is a uniformly random number, CR is the crossover rate.•Mutation strategy “DE/current-to-best/1” is similar to the crossover operator employed by some genetic algorithms (GAs) [15].Mutation strategy “DE/rand/1” is derived from “DE/current-to-best/1”, whereas the best individual xbestof the previous generation is replaced with a random individual xr1.Mutation strategies (i.e., “DE/rand/2”, “DE/best/2”, “DE/current-to-best/2”) are the modified forms of the mutation strategies, (i.e., “DE/current-to-best/1”, “DE/rand/1”, DE/rand to best/1).PSO was first developed in 1995 by Kennedy and Eberhart in [7] for solving global optimization problems. Its mechanism is mainly inspired by the social behavior of bird flocking or fish schooling and animal societies. PSO shares many similarities with evolutionary algorithms. However, it does not normally use variation operators (i.e., crossover and mutation).PSO starts optimization search with a group of random solutions (particles). Each particle has its updating position vector and updating velocity and moves through the search space. In recent years, many interesting and important modifications are made to the original PSO [7] and its latest review can be found in [18–21]. One important modified version of PSO has been developed in [22]. In this modified PSO, the velocity and position of each particle is calculated as follows:(3)vt+1=w×vt+c1×r1×(pt−xt)+c2×r2×(gt−xt)(4)xt+1=xt+ξ×vt+1,(5)xt+1=xt+1+ur×xt+1where•r1 and r2 are two uniformly distributed random numbers;vtis the current velocity of the particle;xtis the current position of the particle;wis the inertia factor which lies in [0.8, 1.2];c1 and c2 are the two acceleration constant or acceleration coefficients that usually lies between 1 and 4;ur∈[−1, 1] is a continuous uniform random number.Algorithm 1Pseudocode of MOEA/D-DE+PSOINPUT:•MOP: the multiobjective optimization problem;N: population (i.e., the number of subproblems);Feval: the maximal number of function evaluations;a uniform spread of N weight vectors, λ1, …, λN;T: the number of weight vectors in the neighborhood of each weight vector;Output:{x(1), x(2), …, x(N)} and {F(x(1)), …, F(x(N))};Step 1 Initialization:0.1:Uniformly randomly generate a population of size N, P={x(1), …, x(N)} within search space Ω;Initialize a set of N weight vectors, {λ1, λ2, …, λN};Compute the Euclidian distances between any two weight vectors and then find the T closest weight vectors to each weight vector. For the ith subproblem, set B(i)={i1, …, iT}, where λi1, …, λiTare the T closest weight vectors to λi;Compute the F-function value of each member in P, F(xi), i=1, 2, …, N;Initialize z=(z1, …, zm)Tby problem-specific method;Set ⌈ζ1=0.5N⌉; ζ2=N−ζ1; where ζ1, is the number of subproblems which will deal with PSO, and ζ2, is the number of new solutions which will deal with DE;Set t=0;Step 2: Evolving Scheme of MOEA/D-DE+PSO:1:whilet<FEVALdo2:Randomly divide I={1, 2, …, N} into two subsets, IAand IB, such that IAhas ζ1 indices and IBhas ζ2 indices at t;3:fori=1:Ndo4:ifi∈IAthen5:Apply PSO to IAto produce yi;6:else7:Apply DE to IBto produce yi;8:end if9:Compute the F-function value of yi, F(yi);10:Updating z: For each j=1, …, m, fj(yi)<zj, then set zj=fj(yi);11:Updating Neighboring Solutions:12:For each index k∈B(i)={i1, …, iT}13:ifgte(yi|λk, z)≤g(xk|λk, z) then14:xk=yiand F(xk)=F(yi)15:end if16:end for17:Updateζ1andζ2(Details in Algorithm2.)18:t=t+119:end whileAlgorithm 2Resources Allocation to DE and PSOStep 1: Compute ζ1, the number of subproblems deal with PSO [7], and ζ2 is number of subproblems deal with DE [8].Step 2: Compute the probability success (i.e., τ1) of PSO [7] applied to ζ1 subproblems.(6)τ1=κ1/ζ1κ1/ζ1+κ2/ζ2where κ1 are total successful solutions in ζ1 subproblems allocated to PSO [7]. A new solution of PSO is successful if it replaces successfully at least one solution in T neighboring solutions. A successful get reward 1 and unsuccessful gets 0.Step 3: Replace ζ1=⌈N×τ1⌉ and ζ2=N−ζ1.In the initialization step of Algorithm 1, B(i) contains the indices of the T closest weight vectors denoted by λi. We have used the Euclidian distance to measure the closeness between two weight vectors. Therefore, λi's closest vector is itself, and then i∈B(i). If k∈B(i), then the kth subproblem can be regarded as a neighbor of the ith subproblem.Initially, the values of ζ1 and ζ2 are kept fixed and then updated in the evolutionary process of the Algorithm 1. Whereas ζ1 denotes the number of subproblems in subset of IA, ζ2 denotes the number of subproblems in subset IB.In Step 2 of Algorithm 1, we divided N subproblem indices into two different index sets, IAand IB. The index set IAcontains ζ1 subproblems which are dealt with with PSO. The index set IBcontains ζ2 subproblems that are dealt with with DE. The values of ζ1 and ζ2 are updated based on implementation steps described in Algorithm 2.Finally, we can say that the combined use of PSO and DE establishes the trade-off between exploration and exploitation ability of MOEA/D. The dynamic use of DE and PSO enable MOEA/D-DE+PSO to get better approximate solutions in all 30 independent runs the results of which will be seen later in this paper.In this section, we present parameter settings that we used in our experiments for solving two types of test problems, the ZDT problems [9] and the CEC’9 test instances [26]. The range of the search space and characteristics of the Pareto front of the ZDT test problems are given in Table 2. All these problems have two objective functions. None of these problems have any constraint.•N=100: population size for bi-objective test instances.T=0.1N: the neighborhood size for each subproblem;F=0.5: scaling factor of the DE;CR=0.5: crossover probability for DE;Feval=25, 000: maximum function evaluations;λ1, …, λNare weight vectors dealing with bi-objective problems. Each individual weight takes a value form:(7){0H,1H,…,HH},whereH=N−1;The parameter settings used in MOEA/D-DE+PSO when applied to CEC’09 test instances [10] are as follows.•N=600: population size for bi-objective test instances;N=1000: for 3-objective test instances;T=0.1N: the neighborhood size for each subproblem;F=0.5: scaling factor of the DE;CR=1: crossover probability for DE;Feval=300, 000: maximum function evaluations;The set of weight vectors dealing with 3-objective test instances are generated according to criteria which are described in [3,26]. The weight vectors for bi-objective CEC’09 test instances are generated by formula (7);In general, the quality of the non-dominated sets of solutions should be assessed in terms of convergence and diversity. Convergence depicts the closeness of the final non-dominated solutions to the true PF, whereas diversity aims at the distribution of the final solutions along the true PF.Inverted generational distance abbreviated as IGD [27] has been used as a performance indicator to measure the performance of the developed algorithms. Let P* be a set of uniformly distributed points along the PF. Let A be an approximate set to the PF, the average distance from P* to A is defined as [2,26]:D(A,P)=∑v∈P*d(v,A)|P*|whered(v,A)is the minimum Euclidean distance betweenvand the points in A. If P* is large enough to represent the PF very well, D(A, P) could measure both the diversity and convergence of A in a sense.In the algorithm of MOEA/D-DE+PSO, Step 2(10) performs O(m) comparisons and assignments, and Step 2(11) needs O(mT) basic operations since its major cost is to compute the single objective optimization subproblem values for T solutions and computation of one such solution requires O(m) basic operations. Therefore, the computational complexity of Step 3 in MOEA/D-DRA algorithms is O(m[N]T) since it has [N] passes. We have implemented all algorithms in Matlab and we have carried out experiments on the same computer machine. We have recorded the average CPU time elapsed by respective algorithm as given in Table 3. We have used the tic and toc command (a Matlab built-in function). Table 3 records the average CPU times used by MOEA/D-DE+PSO and MOEA/D. This table shows that the proposed algorithm used more time than MOEA/D. The extra computational overhead of our proposed algorithm is due to the fact that PSO needs a global guide in each generation which requires more time than DE.Benchmark problems are used to bring out the capabilities, important characteristics, and possible pitfalls of the algorithm under investigation. The detailed definition of the CEC’09 test instances is presented in [10], and the set P*∈PF for IDG calculation is also available there. The ZDT test problems [9] are presented in Table 2. These two suites of problems are picked out to validate the effectiveness of MOEA/D-DE+PSO in this paper. We applied IGD [27]) to evaluate the performance of MOEA/D-DE+PSO over both test suites of problems against MOEA/D [2]. To calculate the IGD-metric values, we have taken P of uniformly distributed points in the PF of size 1000 for ZDT test problems [9]. All parameters are kept same in the experiments of the MOEA/D [2] and MOEA/D-DE+PSO.Here, we discuss some observations over the results obtained by MOEA/D-DE+PSO and MOEA/D [2]. Table 4records the IGD-metric values after 25,000 function evaluations in 30 independent runs. The five columns refer to best (i.e., minimum), median, mean, standard deviation (sdt), and worst (i.e., maximum) of the IGD values obtained by MOEA/D [2] and MOEA/D-DE+PSO for each ZDT problem. The experimental results clearly indicate that MOEA/D-DE+PSO has performed much better than MOEA/D [2] on ZDT1, ZDT2, ZDT4, and ZDT6. MOEA/D-DE+PSO ranks first on four ZDT problems out of five used in this paper. MOEA/D [2] has performed better on ZDT4 than MOEA/D-DE+PSO. This weak performance of the MOEA/D-DE+PSO on ZDT3 could be attributed to the fact that the objective functions of this problem are disparately scaled in its PF.Figs. 1 and 2demonstrate the location of the final set of solutions in the objective space achieved by MOEA/D-DE and MOEA/D-DE+PSO after executing 30 times each algorithm over ZDT problems [9]. The Left panel of Figs. 1 and 2 is for MOEA/D [2] and the right panel is for MOEA/D-DE+PSO.Figs. 1 and 2 clearly indicate the approximate PF generated by MOEA/D-DE+PSO for each ZDT problem are uniformly distribution along the real PF of ZDT problems. In Figs. 3 and 4, we have also plotted the PFs of 30 independent runs altogether. It can be seen from these figures that MOEA/D-DE+PSO has produced solutions in better distribution ranges than MOEA/D [2] on each ZDT problem. As recorded and explained in Table 2, ZDT4 has many local Pareto fronts. This good performance of the MOEA/D-DE+PSO on ZDT4 could be a good addition to the existing literature of memetic algorithms.Fig. 5displays the evolution of the average IGD-metric values versus the number of generations over 30 independent runs of MOEA/D [2] and MOEA/D-DE+PSO on each ZDT problem. These figures exhibit that MOEA/D-DE+PSO is much better in reducing IGD values on almost all ZDT test problems, especially, on ZT4 and ZDT6. Initially, the converging ability of the MOEA/D-DE+PSO is much better than MOEA/D [2] over ZDT3, however, in the final few generations MOEA/D [2] has shown good performances in terms of reducing IGD-metric values.In this subsection, we discuss the effectiveness of MOEA/D-DE+PSO in comparison with MOEA/D [2] over CEC’09 test instances [10]. Table 5collects the IGD values including minimum, median, mean, standard deviation and maximum obtained by MOEA/D [2] and MOEA/D-DE+PSO. We carried out our experiments by executing MOEA/D [2] and MOEA/D-DE+PSO for 30 times. Each algorithm was allowed 300, 000 function evaluations in each run on each CEC’09 test instance [10]. A bold figure in Table 5 denotes best results regarding the algorithms used in this paper. As can be seen in Table 5, MOEA/D-DE+PSO ranks first on eight (i.e., UF1-UF4 and UF7-UF10) out of ten CEC’09 test instances [10]. MOEA/D-DE+PSO has shown weaker performance than MOEA/D [2] on UF5 and UF6 in terms of reducing IDG values. This weak performance of our algorithm could be due to the fact that UF5 has 21 local Pareto fronts and UF6 one isolated point and two disconnected parts. The presence of many local PFs in UF5 may hinder the convergence ability of MOEA/D-DE+PSO toward its real PF. A problem, UF6, has piecewise PF that hinders MOEA/D-DE+PSO in finding a good diverse set of solutions. The allowed function evaluations might not be good enough to deal with such complicated problems.Figs. 6–9depict the approximated Pareto front of UF1–UF10 generated by MOEA/D [2] in the best of 30 independent runs. The Left panel is MOEA/D [2] and the right panel is for MOEA/D-DE+PSO. It can be seen in these figures that MOEA/D-DE+PSO has produced better approximated PF than MOEA/D [2] on most CEC’09 test instances. MOEA/D-DE+PSO has generated “a good looking PF” as per the parlance of multiobjective optimization.To show the distribution ranges of all 30 PF's covered with 30 different sets of non-dominated final solution in the objective space of each respective CEC’09 test instance, we have displayed them in Figs. 10–13. In these figures, a Left panel is for MOEA/D [2] and right panel is for MOEA/D-DE+PSO. From these figures, it can be seen that MOEA/D-DE+PSO has produced much better PFs on most CEC’09 test problems as compared to MOEA/D [2].Fig. 14displays the evolution of the average IGD-metric values in 30 independent runs versus the number of generations of the MOEA/D-DE+PSO and MOEA/D [2] over each CEC’09 test instance. These figures demonstrate that MOEA/D-DE+PSO had performed better than MOEA/D [2] in terms of reducing the average IGD-metric values in almost all CEC’09 test instances [10].Fig. 15depicts the evolution of the best IGD values in the best run among 30 independent runs of the MOEA/D [2] and MOEA/D-DE+PSO on each CEC’09 test instance [10]. From these figures, one can conclude that the convergence of the MOEA/D-DE+PSO is much better than that of MOEA/D [2].To study the sensitivity of MOEA/D-DE+PSO to different population sizes and neighborhood sizes T on CEC’09 test instances [10], we examined the following values of N: 100, 200, 300, 400, 500, 600 as well as the following values of T: 10, 20, 30, 40, 50, 60 for 2-objective CEC’09 test instances. For 3-objective test instances, we assigned the following values to N: 250, 500, 600, 1000 and the following values to T: 25, 50, 60, 100 in the framework of MOEA/D-DE+PSO.Table 6summarizes the IGD values with different population sizes and neighborhood sizes, aforementioned, on each CEC’09 test instance obtained by MOEA/D-DE+PSO. This tables shows that the search ability of MOEA/D-DE+PSO is not much effected with different population sizes and neighborhood sizes settings.Fig. 17 demonstrates the evolution of the average IGD-metric values versus the population size with different values created by MOEA/D-DE+PSO. These visual results and Table 6 indicate that MOEA/D-DE+PSO is not much sensitive to population sizes on most CEC’09 problems. Furthermore, the above figures establish that MOEA/D-DE+PSO has much better options to accommodate any population sizes N within 200–600 dealing with UF1-UF7 and within 400–1000 to tackle UF8–UF10.Fig. 16exhibits the evolution of the average IGD-metric values versus different settings of T. T is one of the important control parameter in the MOEA/D paradigm. Therefore, we plotted the different values of T versus the average IGD-metric values for the purposes of their appropriate settings in MOEA/D-DE+PSO. However, MOEA/D-DE+PSO, like its competitor, performs poorly on UF5 and UF6. Both these problems are more complicated than the others. MOEA/D-DE+PSO gets stuck in its local optimal basin of attraction and, therefore, no further improvement is observed on these problems (Fig. 17).In this paper, a multiobjective memetic algorithm based on MOEA/D [2], called MOEA/D-DE+PSO is developed. MOEA/D-DE+PSO used two well established search algorithms, namely differential evolution (DE) [8] and particle swarm optimization (PSO) [7]. The number of subproblems dealt with by DE and PSO are dynamically changed based on their particular success reward obtained in the evolutionary process of MOEA/D-DE+PSO. Based on experimental study, we found that DE works well globally while PSO acts as a local search operator.We analyzed the performances of the MOEA/D-DE+PSO on two sets of continuous multiobjective optimization problems, the ZDT [9] and the CEC’09 unconstrained test instances [10]. We found that MOEA/D-DE+PSO works better in terms of reducing IGD-metric values on most of the test problems. We would like to point out that:•We have used a simple implementation of MOEA/D [2] in the study of this paper.We have selected parent solutions randomly from the neighborhood scheme only for the DE operation.In MOEA/D-DE+PSO, each new solution has an option to replace any number of old solutions. The restriction of maximum replacement strategy that is already used in [28] might deprive some good solutions from taking part in further evolutionary steps. We did not use any restricted strategy in MOEA/D-DE+PSO.The use of open maximal replacement strategy in MOEA/D-DE+PSO is a good idea because each subproblem or solution has the opportunity to make full use of its neighborhood information.Overall, MOEA/D-DE+PSO has performed reasonably well on both test suits problems used in the study of this paper. The inclusion of PSO has helped a lot in finding the best final set of optimal solutions to most test instances. Moreover, PSO has speeded up the search process toward the PF.MOEA/D-DE+PSO has performed better than the original MOEA/D [2] with different population sizes and neigborhood sizes. This paper also reports the analysis of useful parameters of the MOEA/D-DE+PSO.In the future, we intend to test our proposed algorithm on an industrial design problem, namely, the tubular permanent magnet linear synchronous motor which takes into account multiple conflicting objectives.

@&#CONCLUSIONS@&#
