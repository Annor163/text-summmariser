@&#MAIN-TITLE@&#
Rough-fuzzy clustering and multiresolution image analysis for text-graphics segmentation

@&#HIGHLIGHTS@&#
A new method is proposed for text-graphics segmentation.M-band wavelet packet is used to extract scale-space features for document image.Unsupervised feature selection method is proposed to select relevant and non-redundant features.Rough-fuzzy clustering is used to address uncertainty problem of document segmentation.The approach is invariant under font size of text, scanning resolution and type of layout.

@&#KEYPHRASES@&#
Text-graphics segmentation,M-Band wavelet packet,Feature selection,Rough-fuzzy clustering,Texture segmentation,

@&#ABSTRACT@&#
This paper presents a segmentation method, integrating judiciously the merits of rough-fuzzy computing and multiresolution image analysis technique, for documents having both text and graphics regions. It assumes that the text and non-text or graphics regions of a given document are considered to have different textural properties. The M-band wavelet packet analysis and rough-fuzzy-possibilistic c-means are used for text-graphics segmentation problem. The M-band wavelet packet is used to extract the scale-space features, which offers a huge range of possibilities of scale-space features for document image and is able to zoom it onto narrow band high frequency components. A scale-space feature vector is thus derived, taken at different scales for each pixel in an image. However, the decomposition scheme employing M-band wavelet packet leads to a large number of redundant features. In this regard, an unsupervised feature selection method is introduced to select a set of relevant and non-redundant features for text-graphics segmentation problem. Finally, the rough-fuzzy-possibilistic c-means algorithm is used to address the uncertainty problem of document segmentation. The whole approach is invariant under the font size, line orientation, and script of the text. The performance of the proposed technique, along with a comparison with related approaches, is demonstrated on a set of real life document images.

@&#INTRODUCTION@&#
With the advances in information technology, automated processing of documents has become an imperative need. As the world moves closer to the concept of the paperless office, more and more communication and storage of documents are performed digitally. In this background, there is a great demand for software that automatically extracts, analyzes, and stores information from physical documents for later retrieval. However, the documents in digitized form require a large amount of storage space, after being compressed using advanced techniques. Text-graphics segmentation partitions a document image into distinct regions corresponding to the text and non-text parts. In effect, it facilitates efficient searching and storage of text parts of the documents.Many techniques have been proposed to segment the document image into text and non-text regions [1,2]. Most popular among them are top-down and bottom-up approaches. The top-down techniques are based on the difference in contrast between the foreground and background to split the document into columns, paragraphs, text lines, and may be in words. Projection profiles [3,4] are popular top-down approaches that work by identifying the white spaces by vertical and horizontal projections. On the other hand, bottom-up methods, which are similarity based document segmentation approaches, tend to cluster pixels with similar intensities to obtain higher level descriptions. The run length smoothing algorithm [5,6] is an example of bottom-up approach, which applies region growing approach to detect text regions. The Docstrum proposed in [7] is another bottom-up method, which groups connected components of the same type using nearest neighbor information, starting from the pixel level to obtain higher level descriptions of the document such as words, text lines, paragraphs, and so on. Each of these methods assumes rectangular blocks of text and graphics, and is sensitive to different textural properties such as font size, text line orientation, and inter-character spacing. Hence, these methods are not effective when any a priori knowledge about the content and attributes of the document image is unavailable.Nicolas et al. [8] extracted the text from document image using 2-D conditional random field model by integrating contextual knowledge and machine learning technique. Another approach for the binarization of a document image was proposed based on a Bayesian framework using Markov random field model of the image [9]. Junga et al. [10] achieved text segmentation by applying region growing procedure based on the response of stroke filter and then improved the segmentation by using an OCR feedback procedure. Chen and Wu [11] developed a document segmentation approach, which integrates multiplane segmentation and multilevel thresholding method. Su et al. [12] proposed a method to segment the degraded document image by combining contrast map and canny edge detector, followed by thresholding.Recently, wavelet techniques have become powerful tools in document image analysis domain. It is particularly good at describing a scene in terms of the scale of textures in it. Li and Gray [13] have used features based on distribution characteristics of wavelet coefficients in high frequency bands to segment document images into four classes, namely, background, photograph, text, and graph. While Kundu and Acharyya [14] proposed a text-graphics segmentation method based on wavelet scale-space features followed by k-means clustering algorithm, Deng et al. [15] have used cubic b-spline wavelet for feature extraction and k-means for text-graphics segmentation. On the other hand, Lee et al. [16] proposed an algorithm, which is based on local energy estimation in wavelet packet domain and k-means algorithm. Kumar et al. [17] used globally matched wavelet filters and Markov random field model to segment the document images into text, background, and picture components. Haneda and Bouman [18] combined cost optimized segmentation and connected component classification into multiscale framework in order to improve the text-graphics segmentation accuracy for compression.In this background, this paper presents a text-graphics segmentation method, integrating judiciously the merits of rough-fuzzy clustering and multiresolution image analysis. The proposed method decomposes a composite image into multiresolution multidirectional feature subbands using wavelet analysis. According to Chang and Kuo [19], most of the significant textural features are more prevalent in the intermediate frequency subbands [20]. In this regard, the M-band wavelet packet transform is used in the proposed method for feature extraction. It recursively decomposes both the high frequency and low frequency bands at each scale. However, the complete decomposition tree is usually not required by decomposing all the subbands at each scale. Hence, an appropriate method of selecting the significant and relevant features is required. Subsequently, features are computed from this set of selected bases by using nonlinear energy estimation followed by a smoothing filter. The use of M-band wavelet packet decomposition gives rise to a large number of features, which incurs redundancy. Therefore, selection of the appropriate features using some basis selection algorithms is required. Since any a priori knowledge about the image is not available, an unsupervised approach is proposed for feature selection. Finally, the rough-fuzzy-possibilistic c-means (RFPCM) algorithm [21] is used to segment the document image using feature vectors. It adds the concept of fuzzy membership (both probabilistic and possibilistic) of fuzzy sets, and lower and upper approximations of rough sets into k-means or c-means algorithm. While the membership of fuzzy sets enables efficient handling of overlapping partitions, the rough sets deal with uncertainty, vagueness, and incompleteness in cluster definition. Due to integration of both probabilistic and possibilistic memberships, the RFPCM avoids the problems of noise sensitivity of fuzzy c-means [22] and the coincident clusters of possibilistic c-means [23]. Also, the concept of crisp lower bound and fuzzy boundary of a cluster, introduced in rough-fuzzy-possibilistic c-means, enables efficient selection of cluster prototypes. The performance of the proposed method, along with a comparison with other related approaches, is demonstrated both qualitatively and quantitatively on a set of real life document images.The structure of the rest of this paper is as follows: Section 2 describes the proposed text-graphics segmentation method based on rough-fuzzy-possibilistic c-means and M-band wavelet packet. An unsupervised feature selection algorithm is introduced to select relevant and non-redundant features for segmentation. Section 3 presents the experimental results on several document images and a comparison among different methods. Finally, concluding remarks are given in Section 4.The proposed text-graphics segmentation algorithm based on M-band wavelet packet and rough-fuzzy-possibilistic c-means is illustrated in Fig. 1. The algorithm proceeds as follows:1.The input image is decomposed using M-band wavelet packet into m number of subbands based on energy estimation of each subband with respect to two threshold values.These outputs are subjected to nonlinear operation followed by smoothing operation.The unsupervised feature selection algorithm is applied to the feature images obtained from the previous step. It transforms m-dimensional measurement space into a d-dimensional feature space.The obtained feature images are then clustered using rough-fuzzy-possibilistic c-means.Each of the above steps is elaborated next in detail one by one.Wavelets mean small waves, that is, short duration finite energy functions. In multiresolution analysis, a scaling function is used to create a series of approximations of a function or image, each differing by a factor from its nearest neighboring approximation. Additional functions, called wavelets, are then used to encode the difference in information between adjacent approximations [24], [25]. In dyadic wavelet, scaling function ϕ(t) and wavelet function ψ(t) are defined as(1)ϕj,k(t)=2j/2ϕ(2jt−k);(2)ψj,k(t)=2j/2ψ(2jt−k);for allj,k∈ℤ, whereℤrepresents the set of integers. Here k determines the position along x-axis and j determines function's width, that is, how broad or narrow it is along x-axis.The M-band orthonormal wavelet bases are constructed as a direct generalization of the dyadic wavelets. The dyadic wavelet transform decomposes a signal into frequency subbands that have the same bandwidth on a logarithmic scale, whereas M-band wavelets, in addition, focus on narrow band high frequency components of a signal, thereby, simultaneously having a logarithmic and a linear decomposition of frequency channels. Let ϕ(t) be the scaling function satisfying(3)ϕ(t)=∑khϕ(k)Mϕ(Mt−k).Additionally, the M−1 wavelets can be expressed as(4)ψl(t)=∑khψl(k)Mψ(Mt−k);l=1,…,M−1,where hϕ(n) andhψl(n)are scaling and wavelet function coefficients, respectively. Scaling and translating the scaling function ϕ(t) and wavelet function ψl(t), the ϕj,k(t) and ψl,j,k(t) functions are obtained, respectively(5)ϕj,k(t)=Mj/2ϕ(Mjt−k);(6)ψl,j,k(t)=Mj/2ψl(Mjt−k);l=1,…,M−1.The subspaces spanned by the functions ϕj,k(t) and ψl,j,k(t), respectively, can be defined as(7)Vj=Spank{ϕj,k(t)}¯;(8)Wjl=Spank{ψl,j,k(t)}¯;l=1,…,M−1.It follows from (3) that the Vjsubspaces have the nested property. If the scaling and wavelet functions satisfy orthonormality condition, then the subspaces{Wjl};l=1,…,M−1form an orthogonal decomposition of theL2(ℝ)function space and are related to the Vjnested subspace by(9)Vj+1=Vj⊕⊕l=1M−1Wjl;l=1,…,M−1.Fig. 2showsL2(ℝ)function space decomposition using M(=4)-band wavelet transform. The M-band wavelet contains a set of basis functions, (M−1) wavelets ψl(t), with l=1, …, M−1, associated with the scaling function ϕ(t). For these basis functions, given any functionf(t)∈L2(ℝ), it can be shown that(10)f(t)=∑k∈ℤ<f(t)ϕj,k(t)>ϕj,k(t)+∑l=1M−1∑j∈ℤ∑k∈ℤ<f(t)ψl,j,k(t)>ψl,j,k(t)where l=1, …, M−1,j,k∈ℤ, and <., .> represents the inner product.An M-band orthogonal wavelet transform decomposes a document image into M2 subbands. Since in M-band wavelet packet, at each decomposition level, every subband of that level is further decomposed, each of these M2 subbands gives rise to another M2 number of bases. So, if the decomposition depth is p, then an M-band wavelet packet decomposition results in M2pnumber of subbands. This large number of bases is required for obtaining good segmentation quality.The notion of M-band wavelet packet is used here to extract multiscale wavelet features of document images. The proposed methodology includes a feature extraction method that uses multiresolution M-band wavelet packet filtering of a document image followed by adaptive basis selection to identify most significant subbands. In the filtering stage, an eight-tap, four-band, orthogonal wavelet as shown in Table 1[26] is used to decompose the document images into M×M channels. The scaling and wavelet functions, denoted by ϕj,k(t) and ψl,j,k, with l=1, …, M−1, respectively, are the sequences of lowpass and bandpass filters. The filter length is increased with the increasing level of decomposition. The filters are expanded by inserting appropriate number of zeros between taps of filters, thereby, satisfying the quadrature mirror filter condition.The M-band wavelet packet decomposition gives M2pnumber of channels, for a decomposition depth of p, without downsampling (overcomplete). The overcomplete representation of a signal is convenient over the subsampled methods as subsampling reduces the size of the subbands at each increasing level of decomposition and hence may possibly bias the decomposition at higher levels.For extraction of textural features of a document image, the most significant frequency bands contained in the image are highly desirable. In order to find out a suitable basis without going for a full decomposition, an adaptive decomposition algorithm using a maximum entropy or information content criterion extracted from each of the subbands is used [27]. After first level decomposition of the image into M×M channels, energy for each subband is evaluated. Among them, the subbands having energy values exceeding a threshold value (ϵ1) of the parent band energy are considered and decomposed further. A subband at second decomposition level is further decomposed if its energy value is more than another threshold value (ϵ2) of the total energy of all the subbands at the current scale. Hence, the number of subbands can be generated in the range of 16 to 4096 in this feature extraction method with M=4. Empirically, it is seen that the values of ϵ1=0.01 and ϵ2=0.10 are good choice for the images considered in the experiment.After selection of the significant bases, a local estimator, which constitutes a nonlinear operator followed by a smoothing filter, is applied to each subbands [14]. It gives high energy value for the regions in each subbands where frequency components are strong, otherwise low energy value is obtained where it is weak.In the current feature extraction method, standard deviation is used as the nonlinear operator, calculated over small overlapping windows around each pixel. The local energy Eb(x, y) around the (x, y)th pixel of bth subband is given as(11)Eb(x,y)=1R∑m=1w∑n=1wFb(m,n)2−F¯b(x,y)2wherewis the window size andR=w×w.F¯b(x,y)is the mean around the (x, y)th pixel and Fb(m, n) is the filtered image. The nonlinear transform is followed by a smoothing filter. Gaussian lowpass filter is used as the smoothing filter, which is of the form(12)HG(u,v)=12πσe−1/2σ2(u2+v2)where σ determines the passband width or spatial extent of the averaging filter. Formally, the feature image Featb(x, y) corresponding to subband image Fb(x, y) is given by:(13)Featb(x,y)=1G2∑(m,n)∈GxyΓ(Fb(m,n))HG(x−m,y−n)where Γ(.) gives the energy measure and Gxyis a G×G window centered at pixel with coordinates (x, y). The value of G for the smoothing window is an important parameter. It is found that an averaging window of size 9×9 is appropriate in most of the segmentation experiment.The above step results in a set of feature images Featb(x, y), from which a set of feature vectors are derived. These feature vectors corresponding to the decomposed images at different resolutions are assumed to capture and characterize effectively different scales of texture of the document image.The unprocessed wavelet coefficients do not convey enough information for efficient representation of texture cues. A nonlinear energy estimator is needed in order to discriminate texture pairs. In case of document image, highly active image means the image has predominantly high frequencies, so the image requires a smaller window for nonlinear operation. An image with low spectral content would require larger window size. Hence, the choice of the window of nonlinear operation is very crucial.In the present work, the energy window size is decided based on the measure of the edge density of the image. The edge density gives the measure of overall image busyness. Here, edge density is computed using Sobel edge detector. It can be evaluated by the ratio between the number of pixels from extracted edges, that is, Neand image area A, that is, total number of pixels in region image matrix and is given by:(14)Dene=NeA.The edge density Denehas a dynamic range of values between [0, 1]. For highly active image, Deneis close to 1, so a smaller window for nonlinear operation is required. Moderately active images having the value of Denewithin [0, 1] would require a moderate window size for good feature extraction. It has been found experimentally that the energy window size, for these different categories of image activities, ranges from 5×5 to 19×19.Although the adaptive basis selection is done at the time of feature extraction stage of the proposed methodology, the number of extracted features from a given image using M-band wavelet packet is too large. Among all the extracted features, some of them are non-relevant and redundant. Hence, dimension reduction in feature space becomes an imperative need in terms of computational complexity. Since class labels of the data are unknown, thereby indicating the significance of unsupervised feature selection. There exist many approaches to select a reduced set of relevant subbands for texture segmentation [28,29,19,30,31]. While Coifman and Wickerhauser [28] proposed entropy for the selection of best subbands, Saito et al. [29] used empirical probability density estimation and a local basis library for the extraction of discriminant features. On the other hand, Huang and Aviyente used mutual information in [30] for computing dependence among subbands to discard redundant or insignificant features, while both dependence and energy measures are used in [32] to select relevant and non-redundant subbands for texture classification.The proposed feature selection algorithm first identifies the features with high variances, and then similarities among all these identified features are calculated. If the similarity measures of these features exceed some predefined threshold value δ, then those features are considered as similar with respect to the threshold value δ. The feature with maximum variance among the similar features is assigned in the reduced feature set. Let Feati={x1i, …, xki, …, xni}, i=1, 2, …, m, be the ith feature vector, where m is the number of features and n is the number of samples, that is, the total number of pixels in the input image. Let Vari, i=1, 2, …, m, be the variance of each feature vector computed over n samples and R is the reduced feature set. The similarity measure ϒijof two feature vectors Featiand Featjcan be calculated as follows:(15)ϒi,j=1n∑k=1n1−|xki−xkj||maxk−mink|wheremaxkandmink,k=1,2,…,n, are the maximum and minimum values of features computed for all the data present. The value of ϒijrepresents the similarity between two feature vectors Featiand Featj. The main steps of the proposed unsupervised feature selection algorithm proceed as follows:1.Initialize F←{Feat1, …, Featk, …, Featm} and the reduced set R←∅.Calculate variance Varkof each feature vector Featk∈F.Select Feati∈F that has highest variance, and then performR←R∪{Feati};F←F\{Feati}.Compute similarity measure ϒi,jbetween Featiand each of the feature vectors Featj∈F using (15).If ϒij≥δ, that is, Featjis similar to Featiwith respect to δ, thenF←F\{Featj}.Repeat steps 3 to 5 until F=∅.Output R.Let X={x1, …, xj, …, xn} be the set of n objects andV={v1,…,vi,…,vc}be the set of c centroids and βiis the ith cluster, wherexj∈ℝmandvi∈ℝm. In rough-fuzzy-possibilistic c-means algorithm [21], each cluster βiis represented by three parameters, namely, a cluster prototype or centroidvi, a crisp lower approximationA_(βi)and a fuzzy boundary B(βi). The centroid is calculated based on the weighting average of the crisp lower approximation and fuzzy boundary, and is given by(16)vi=w×C1+w˜×D1ifA_(βi)≠∅,B(βi)≠∅C1ifA_(βi)≠∅,B(βi)=∅D1ifA_(βi)=∅,B(βi)≠∅(17)whereC1=1|A_(βi)|∑xj∈A_(βi)xj;(18)D1=1ni∑xj∈B(βi){a(μij)m1´+b(νij)m2´}xj;(19)andni=∑xj∈B(βi){a(μij)m1´+b(νij)m2´}.Herem1´∈[1,∞)andm2´∈[1,∞)are the probabilistic and possibilistic fuzzifiers, respectively,viis the ith centroid corresponding to the cluster βi, μij∈[0, 1] and νij∈[0, 1] are the probabilistic and possibilistic membership functions, respectively, of the object xjto the cluster βi. The parameterswandw˜(=1−w)correspond to the relative importance of lower approximation and boundary region. The constants a and b(=1−a) define the relative importance of probabilistic and possibilistic memberships. The probabilistic and possibilistic membership values of an object xjare calculated as(20)μij=∑k=1cdij2dkj21/m1´−1−1;wheredij2=||xj−vi||2(21)νij=11+E;whereE=bdij2ηi1/m2´−1.The scale parameter ηirepresents zone of influence or size of cluster βi. In rough-fuzzy-possibilistic c-means, the probabilistic and possibilistic membership values of objects in lower approximation are μij=νij=1, while those in boundary region are the same as (20) and (21), respectively. The main steps of rough-fuzzy-possibilistic c-means algorithm are as follows:1.Assign initial centroidsvi, i=1, 2, …, c. Choose values for fuzzifiersm1´andm2´, and calculate threshold value δ, which determines the class labels of all objects, that is, δ represents the size of granules of rough-fuzzy clustering, as follows:δ=1n∑j=1n(uij−ukj),where n is the total number of objects, uijand ukjare the highest and second highest memberships of xj, and uij={aμij+bνij}. Set iteration counter t=1.Compute μijand νijby (20) and (21), and finally uijfor c clusters and n objects.If uijand ukjare the two highest memberships of xjand (uij−ukj)≤δ, then xj∈B(βi) and xj∈B(βk). Furthermore, xjis not part of any lower approximation region.Otherwise,xj∈A_(βi).Modify μijand νijconsidering lower approximation and boundary regions for c clusters and n objects. The values of μijand νijare set to 1 for the objects in lower approximations, while those in boundary regions are remain unchanged.Compute new centroid as per (16).Repeat steps 2 to 6, by incrementing t, until no more new assignments can be made.

@&#CONCLUSIONS@&#
