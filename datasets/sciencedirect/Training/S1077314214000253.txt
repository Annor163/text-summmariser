@&#MAIN-TITLE@&#
Projective Matrix Factorization with unified embedding for social image tagging

@&#HIGHLIGHTS@&#
A general formulation for matrix factorization with unified embedding is proposed.It jointly learns the projection from the visual space to the unified space.The proposed algorithm enables to address the out-of-sample problem.The local geometrical properties of image space and tag space are preserved.Experiments on several datasets show the superior performance of our work.

@&#KEYPHRASES@&#
Projective Matrix Factorization,Unified embedding,Structure preserving,Social tagging,

@&#ABSTRACT@&#
This paper presents a general formulation, named ProJective Matrix Factorization with unified embedding (PJMF), by which social image retagging is transformed to the nearest tag-neighbor search for each image. We solve the proposed PJMF as an optimization problem mainly considering the following issues. First, we attempt to find two latent representations in a unified space for images and tags respectively and explore the two representations to reconstruct the observed image-tag correlation in a nonlinear manner. In this case, the relevance between an image and a tag can be directly modeled as the pair-wise similarity in the unified space. Second, the image latent representation is assumed to be projected from its original visual feature representation with an orthogonal transformation matrix. The projection makes convenient to embed any images including out-of-samples into the unified space, and naturally the image retagging problem can be solved by the nearest tag-neighbors search for those images in the unified space. Third, local geometry preservations of image space and tag space respectively are explored as constraints in order to make image similarity (and tag relevance) consistent in the original space and the corresponding latent space. Experimental results on two publicly available benchmarks validate the encouraging performance of our work over the state-of-the-arts.

@&#INTRODUCTION@&#
With the permeation of Web 2.0, there are explosive photo sharing websites with large-scale image collections available online, such as Flickr and Picasa. The Web 2.0 websites allow users not only share their photos, but tag and comment their interested ones. Due to the subjectivity and diversity of such social tagging behaviors, noisy and missing tags for images are inevitable, which limits the performance of tag-based image retrieval system. Thus, it is necessary and challenging to retag the large-scale images precisely by leveraging those possibly imprecise tagging information.Image annotation as a special case of image retagging is a classical task of computer vision and pattern recognition and numerous studies have been exploited [1–6]. Despite being studied extensively, most of regular image annotation approaches fail to handle large-scale social image tagging tasks since they are usually designed on small-scale manually-labeled data. Besides, due to the diversity of knowledge and cultural background of users, social tagging is often subjective and inaccurate. Moreover, existing studies reveal that many tags provided by Flickr users are imprecise and there are only around 50% tags actually related to the image [7,8]. Consequently, the tags associated with social images could be noisy, irrelevant and incomplete, which may severely deteriorate the performance of text-based image retrieval [8]. Some previous image retagging methods [9,8,10,11] have been proposed to refine and complement the tagging information of social images in a transductive learning manner. That is, most of them cannot directly handle the new images, i.e., the out-of-sample problem. Therefore, how to retag large-scale social images with noisy or missing tags while make the learned model competent for the new image tagging problem, is an urgent task.To this end, in this paper, we propose a novel matrix factorization approach, named ProJective Matrix Factorization with unified embedding (PJMF) for tag relevance learning, and apply it to social image retagging task. The framework of our solution is illustrated in Fig. 1. During the learning process, the original tagging information of social images is used to calculate the image-tag correlation matrix. The two low-dimensional latent representations in a unified space for images and tags respectively are learned to reconstruct the observed correlation matrix with minimum errors in an optimization problem. Different from the traditional matrix factorization approaches, the embedding makes image points and tag points in the unified space comparable, and naturally transforms the image tagging problem to the nearest tag-neighbors search. We also formulate another two issues into the optimization problem for social image tagging task. We assume that the latent image representation is an explicit projection from original image representation to the unified space via an orthogonal transformation matrix. This provides a solution to the out-of-sample representations for images. Besides, to preserve the local geometric information for image space and tag space, two constraints are imposed on the corresponding factor matrices. Obtaining the learned transformation matrix and the tag latent representation, we can easily annotate any image even an untagged image by first embedding it into the unified space via the transformation matrix and then searching its neighbors among the tag latent representations. Finally, we conduct extensive experiments on two publicly available benchmarks, and demonstrate the superiority of the proposed PJMF over the state-of-the-art methods.In summary, our main contributions are given as follows.•A general formulation for matrix factorization is proposed, by which the two latent representations for images and tags are embedded into a unified space. This makes the latent points comparable and transforms the image tagging problem by nearest tag-neighbors search.The projection from the original image feature space to the unified embedding space is incorporated into the matrix factorization framework, which provides an entrance to the out-of-sample problem.The local geometrical properties of image space and tag space respectively are preserved for discovering the latent embedding space.The remaining content is organized as follows. Section 2 overviews related work. We present the proposed matrix factorization approach in Section 4. Section 5 discusses data sets and experimental settings. In Section 6, experimental results and analysis are reported. Conclusions are discussed in Section 7.The goal of Matrix Factorization (MF) is to decompose the data as the product of two low-dimensional factor matrices. Various proposals about MF differ in the constraints that are imposed on the factorization, and the measures of approximate error.The most common form of MF is finding a low-rank approximation to a fully observed data by minimizing the sum-squared difference to it. The two best-known approaches are PCA and SVD, which restrict the factor matrices to be orthogonal. Another popular MF is Non-negative MF (NMF) [12], which requires the data and the factor matrices to be non-negative. There are a number of variants of NMF methods [13–16]. In [17], Projective NMF (PNMF) was introduced which approximates a data matrix by its nonnegative subspace projection. Recently, Probabilistic Matrix Factorization (PMF) [18] is proposed to handle the sparse and imbalanced datasets, which is based on the Gaussian (normal) assumption for both the prior and the likelihood term. Multi-correlation PMF (MPMF) [4] and Correlation Consistent PMF (CCPMF) [10] are proposed to jointly exploit multiple correlations simultaneously. Maximum Margin MF (MMMF) [19] is another MF approach, which adopts low-norm instead of low-rank factorization.The above approaches all approximate the observed matrix by the product of two factor matrices. Different from the above MF algorithms, PJMF embeds the factors in a unified space and adopts the distance to approximate the observed values. Besides, it integrates MF and linear projection, which can deal with the out-of-sample problem and incorporate new samples into the model.Image tagging can be solved by learning tag relevance to images. Many approaches have been proposed to tackle the tag relevance learning problem [20,21,7,9,22,8,23,24]. In [20], a neighbor voting algorithm is proposed to estimate a tag’s relevance by exploiting tagging redundancies among multiple users. The tag relevance is determined based on the number of such votes from the nearest neighbors. Tag ranking [7] further exploits pair-wise similarity between tags by random walk to refine the ranking score. In [9,8], the image similarity and tag correlation are exploited simultaneously to discover the tag relevance. Matrix factorization [25,26,4] is another mechanism to tackle the image tagging problem, which usually has the same start-point to our work. Liu et al. [25] presents a semi-supervised multi-label learning method based on constraint NMF, which exploits unlabeled data as well as category correlations. In [26], NMF is adopted as a method to create a latent semantic space where data of different modalities can be associated to create a synergy. In [4], image-tag relation, image similarity and tag correlation are exploited simultaneously by the shared matrices. Some other methods fucus on how to identify better features for image tagging. A biased random sampling strategy in bag-of-words models is proposed to represent images and a kernel multi-task learning method is proposed to improve ranking performance for the image annotation task [5]. A feature subset is selected from the original features by exploring the label correlation or sparsity [27] to solve the web image annotation problems [24,23].Different from the above methods, PJMF learns the linear transformation matrix and the latent tag matrix by social images with noisy or incomplete tags, while exploiting image similarity and tag correlation to preserve the local geometric structures. The images and tags are embedded in the unified space and the Euclidean distance can be used to measure their relevance.In this section, we present a brief overview of traditional MF. Throughout this paper, we use bold uppercase characters to denote matrices, bold lowercase characters to denote vectors. For any matrixM,mimeans the ith column vector ofM,Mijdenotes the(i,j)th entry ofMandTr[M]is the trace ofMifMis square.Given a data matrixY∈Rm×n, a low-rank MF approach seeks to approximate it by a multiplication of p-rank factors.(1)Y≈UTVwhereU∈Rp×mandV∈Rp×nare the latent low-rank matrices withp<minm,n.‖·‖Fdenotes the Frobenius norm. To avoid overfitting, two regularization terms are added into Eq. (1), we have(2)minU,V12Y-UTVF2+λ12UF2+λ22VF2Hereλ1andλ2are two positive parameters. Gradient based algorithms can be applied to find a local minimum. It has a nice probabilistic interpretation with Gaussian observation noise as detailed in [18].The basic intuition behind our work is to factorize the observed image-tag correlation matrix into two latent representations within a unified space for images and tags respectively, while image similarity and tag correlation are also explored to preserve the consistence between the original space and the corresponding latent space. To this end, we formulate the image tagging task as a PJMF-based optimization problem, and attempt to tackle the following three issues: (1) How to embed images and tags into a unified space. (2) How to obtain the latent representation of any image in the unified space. (3) How to formulate the consistence preservations into the optimization problem. The details about our solution following the notations will be presented in the section.Throughout this paper, we use bold uppercase characters to denote matrices, bold lowercase characters to denote vectors. For any matrixM,mimeans the ith column vector ofM,Mijdenotes the(i,j)th entry ofMandTr[M]is the trace ofMifMis square.Assume we have n tagged images and m tags. LetX=[x1,x2,…,xn]denote the data sample set, in whichxi∈Rddenotes the feature descriptor of the ith sample.Y∈Rm×ndenotes the tag-image associated matrix, such thatYij=1ifxjis tagged by the ith tag, and 0 otherwise. We are given the intra similarities among images and tags, denoted asS∈Rn×nandC∈Rm×mrespectively. Letting p denote the dimension of the desired latent unified space, the task of MF is to derive two factor matricesU=[u1,u2,…,um]∈Rp×mandV=[v1,v2,…,vn]∈Rp×n, which are adopted to approximateY.First of all, we assume that all images and tags are embedded in a unified space, which is a legitimate assumption since there are two similar applications to embedding people and items in a space [28]. The locations of images and tags reflect their characteristics. If a tag is close to an image, it is relevant to the image. As a consequence, there is a negative correlation between the distance and the relevance.In this paper, we employ the Gaussian kernel to obtain the relevance between an image and a tag from their Euclidean distance in the embedding space. Therefore, the approximation can be written as(3)Yij≈Y^ij=e-‖ui-vj‖22σ2where‖ui-vj‖2=(ui-vj)T(ui-vj)andσis a free parameter to control the decay rate. If they are close in the unified space, that is,Y^ijis close to 1, the tag is relevant to the image. By adopting Gaussian kernel, the estimated values are within[0,1]. For all images and tags, the objective function to approximateYis as follows.(4)minU,V12∑i=1m∑j=1n(Yij-Y^ij)2To avoid overfitting, due to the distance depends on the relative position ofuitovjin the embedding space rather than the absolute position of them, we restrict the magnitude of(ui-vj)instead of individual points. Therefore, the objective function for nonlinear matrix factorization with unified embedding is given as follows.(5)minU,V12∑i=1m∑j=1n[(Yij-Y^ij)2+γ‖ui-vj‖2]γ>0is a trade-off parameter. In our MF framework, the interpretation of latent image feature vectors and latent tag feature vectors are the same, since an image is tagged by a tag when their Euclidean distance is zero. However, although the dimension of latent spaces of images and tags are the same in the standard MF, the spaces are not unified.To solve the out-of-sample problem, it is necessary to bridge the gap between the visual space and the embedding space. We assume that the embedding space is the essential space of high dimensional visual space by linear transformation. That is, the latent image feature vectorvjis obtained by linear transformation from the visual feature vectorxjas follows.(6)vj=ATxjwhereA∈Rd×pdenotes the projection matrix to transform a d-dimensional feature vector into a p-dimensional latent space. To reduce redundancy, we impose orthogonality constraints on the projection directions, which couples with unit-norm assumption and leads to the constraint ofATA=I.Iis anp×pidentity matrix. Thus,Y^ij=e-‖ui-ATxj‖2/(2σ2). The objective function can be rewritten as(7)minU,A12∑i=1m∑j=1n[(Yij-Y^ij)2+γ‖ui-ATxj‖2]s.t.ATA=ITheoretically, geometric information can benefit the discovery of the latent space, since data points do not fill the whole feature space but embed in a subspace. Under this assumption, geometric information can be viewed as a regularization term to penalize the distortion of the mapping function.There are two kinds of geometric information: local visual geometry and semantic geometry. The image similarity graphSand tag affine graphCare adopted as prior information. We takeSto sketch the details.Sijmeasures the visual similarity between any two imagesxiandxj. A reasonable criterion for choosing a “good” map is to minimize the following objective function:(8)12∑i=1n∑j=1nSijviDii-vjDjj2=Tr[VLSVT]Dii=∑j=1nSijis engaged for normalization purpose.LSis the normalized graph Laplacian matrix defined as(9)LS=D-1/2D-SD-1/2whereD=diag(D11,D22,…,Dnn)is a diagonal matrix.Similarly, the graph Laplacian matrixLCin the semantic space is computed and the corresponding objective function for local semantic geometry preservation is to minimizeTr[ULCUT]. Thus, to preserve the local geometric information in both visual space and semantic space, we should combine the above two formulations to obtain the following optimization problem.(10)minU,VαTr[VLSVT]+βTr[ULCUT]whereαandβare two positive parameters to control the trade-off between visual information and concept information.Note that for image graph,Sijis computed as(11)Sij=e-‖xi-xj‖2/d¯2(12)d¯=∑i≠j‖xi-xk‖(n(n-1))Based onSij, a K-nearest-neighbor graph is constructed. For tag graph, we estimate the correlation between any two tagstiandtjby(13)Cij=corr(ti,tj)corr(ti,ti)+corr(tj,tj)-corr(ti,tj)wherecorr(ti,tj)is the number of images where the two tags co-occur.Combining the above three aspects, we obtain a unified objective function:(14)minU,A12∑i=1m∑j=1nYij-e-‖ui-ATxj‖22σ2+γ‖ui-ATxj‖2+α2TrATXLSXTA+β2Tr[ULCUT]s.t.ATA=IThe solution for above optimization problem is not unique, since the original objective function is invariant if we replaceUandVbyU+bandV+b(b is a constant), respectively. To fix this uncertainty, the points in the unified space are centered around 0. That is, we consider a new constraint as follows.(15)[UV][e1Te2T]T=0wheree1=(1,…,1)T∈Rm×1ande2=(1,…,1)T∈Rn×1. Considering this extra constraint, we obtain the final objective function as(16)minU,A12∑i=1m∑j=1nYij-e-‖ui-ATxj‖22σ2+γ‖ui-ATxj‖2+α2Tr[ATXLSXTA]+β2Tr[ULCUT](17)s.t.ATA=I(18)Ue1+ATXe2=0Since the above optimization problem is convex inA(while holdingUfixed) and convex inU(while holdingAfixed), but not convex in both simultaneously, we iteratively optimized the above objective by alternately optimizing with respect toAandUwhile holding the other fixed. Modeling such a constrained optimization problem involving constraints will result in a LagrangianL(A,U)with Lagrange multipliersλandξas follows.(19)L(A,U)=12∑i=1m∑j=1n(Yij-Y^ij)2+γ‖ui-ATxj‖2+α2TrATXLSXTA+β2TrULCUT+λ4Tr(ATA-I)T(ATA-I)+ξ2‖Ue1+ATXe2‖2The derivations ofL(A,U)with respect toAandUare as follows.(20)∂L∂A=∑i=1m∑j=1n[(Yij-Y^ij)Y^ij/σ2+γ]xj(ATxj-ui)T+αXLSXTA+λA(ATA-I)+ξXe2(Ue1+ATXe2)T(21)∂L∂ui=∑j=1n[(Yij-Y^ij)Y^ij/σ2+γ](ui-ATxj)+β∑j=1mLjiCuj+ξ(Ue1+ATXe2)Algorithm 1 summarizes the entire procedure for PJMF. A local minimum can be found by alternately performing gradient descent inAandU.Algorithm 1Projective Matrix Factorization with unified embeddingInput:Image feature matrixX; Tag assignment matrixY; Image similarity matrixS; Tag correlation matrixC; Parametersα,β,γandσ; Lagrange multipliersλandξ; The set sizeη; The dimension of the unified space p.Output:Projection matrixAand latent tag feature matrixU.1: CalculateLSandLCbased onSandCby Eq. (9);2: The iteration stept=1;3: InitializationAt=rand(d,p)andUt=rand(p,m);4: repeat5: Compute∂L(At,Ut)∂Atbased on Eq. (20);Compute∂L(At,Ut)∂Utbased on Eq. (21);6: UpdateAandU:At+1=At-η∂L(At,Ut)∂At;Ut+1=Ut-η∂L(At,Ut)∂Ut;7: t=t+1;8: until convergence criterion satisfiedAt last, we briefly present the process of automated image tagging by the learned projective matrixAand embedded tag featuresU.Given an imagexowhether has tagging information or not, its latent feature vectorvoembedded in the unified space can be easily obtained by(22)vo=ATxoThen, the image can be annotated with the tags which are the top-t nearest neighbors of the image in the embedding space. Specially, the Euclidean distance is calculated for the nearest neighbor search.In this section we first present the data sets used in our experiments and then present the previous method used for comparison. Finally we discuss the experimental setups.We consider two publicly available data sets that have been used in previous work. Table 1summarizes some statistics of these data sets.MIRFlickr[29]. It contains 25,000 images from Flickr. It contains 1386 tags and provides the groundtruth annotation of 38 labels. We kept the tags that appear at least 50 times, resulting in a vocabulary of 457 tags, which only contains 18 labels of those 38 labels. Thus, we adopt these 18 labels to validate the performance. We adopt two types of global image descriptors: Gist features and color histograms with 16 bins in each color channel for LAB and HSV representations and one type of local feature: SIFT feature. The features are available at http://lear.inrialpes.fr/data/.NUS-WIDE[30]. It is a social image dataset with images from Flickr. It contains 269,648 images with 5018 tags. To reduce too noisy tags, we removed those tags whose occurrence numbers are below 125. Consequently, 3137 unique tags were obtained. NUS-WIDE-Lite, a subset of NUS-WIDE, consists of 55,615 images with 5018 tags. We removed tags which occurs less than 25 and obtained 2892 unique tags. The data set provides the ground-truth annotations of 81 concepts, which are employed to evaluate the performance. The features are used as in [31].For MIRFlickr, we randomly selected 5000 images to learnAandU, and the rest images are utilized to validate the performance. For NUS-WIDE and NUS-WIDE-Lite, we randomly selected 10,000 images as training data and the rest are used as the testing data.To evaluate the performance of the proposed PJMF method, for tag refinement and social image tagging tasks, we compare it with related previous methods, which are listed as follows.(1)OT: the Original Tags associated with images, which is employed as the baseline for tag refinement.KNN: the tag relevance learning by neighbor voting learning algorithm [20].MPMF: the Multi-correlation Probabilistic Matrix Factorization method in [4], which factors image-tag, image–image and tag–tag correlation matrices simultaneously.CCPMF: the proposed Correlation Consistent Probabilistic Matrix Factorization method in [10] by considering the inter-correlations as consistent constraints.TWTV: the two-view Tag Weighting method that combines the local information both in Tag space and Visual space [8].LRES: tag refinement based on Low-Rank approximation and Error Sparsity proposed in [9].For the above methods, new images are tagged based on image reconstruction. For a new imagexo, we reconstruct it by the training images based onℓ1norm as done in [32]. Once we obtain the reconstruction coefficientwo, we use it to estimate the relevance of the new image to tags. For the jth tag, letyˆjdenote the relevancies of training images to it. For KNN, TWTV and LRES,Y^jo=yˆjTwo. For MPMF and CCPMF, the latent feature of the new image is computed byvo=Vwo. And thenY^jo=uˆjTvo. HereVandujare the latent features of training images and the jth tag learned by MPMF (CCPMF), respectively.In our method, there are several parameters to be set in advance, namely, the dimension of the unified space p, the number of nearest neighbors in visual graph K, the five regularization parametersα,β,γ,λandξ, the decay rateσand the step lengthη. The parametersp,α,βandσmainly affect the performance. A “grid-search” strategy [33] can be used to setα,βandσ. In the experiments, we setK=50andγ=λ=ξ=0.005by 10-fold cross-validation.σis searched in the set{2-8,2-7,…,28}. The step lengthηwas set to 0.005. We test the sensitiveness of parametersα,βand p in the next section.To evaluate the performance of the proposed PJMF algorithm for social image tagging, the standard performance measures are adopted. The image tagging performance is evaluated based on the relevance of the top 5 ranked tags. Following [1], the mean Precision (P) and mean Recall (R) over tags are adopted as performance measures. F1 is also calculated byF1=2×P×R/(P+R). For image retrieval, the criteria to compare the performance is Mean Average Precision (MAP), which is obtained by computing for each keyword the average of the precisions measured after each relevant image is retrieved.In this section we systematically evaluate the effectiveness of the proposed method and compare to the baselines. We first discuss the effects of parameters and then present the performance of our method for image retagging.The proposed method has several free parameters. The most important ones may beα,βand p. Thus we test their sensitiveness. Fig. 2presents the results on the MIRFlickr and NUS-WIDE-Lite data sets.αandβcontrol the trade-off between the local information of visual space and tag space. As shown in [8], the ratioα/βaffects the performance. Thus, we set them in the set{0,0.2,…,1.0}. The F1 results on the MIRFlickr and NUS-WIDE-Lite data sets are shown in Fig. 2(a) (I) and Fig. 2(b) (I), respectively. The results indicate the robustness of our method. Whenα=0orβ=0, the performance is poor. It means that the local geometric information of visual and tag space is important and only preserving one of them cannot result in satisfied performance. Whenα=0.6andβ=0.4, PJMF achieves the best performance on the MIRFlickr data set. The corresponding values on the NUS-WIDE-Lite data set areα=0.8andβ=0.6. This indicates the two constraints are complementary and the contribution from the local geometric information in the visual space is more salient. It is reasonable because tag information is noisy and incomplete.The proposed PJMF model is a low-rank factor model. The dimension of the low-rank space is essential to discover a “good” embedding space. We conduct experiments to investigate its influence and present the results on the MIRFlickr and NUS-WIDE-Lite data sets in Fig. 2(a) (II) and Fig. 2(b) (II), respectively. From the results, we can see that the performance is improved by increasing the rank of factor matrices to some extent and arrive a relatively stable MAP whenp>250. Considering high dimension corresponds to expensive computing cost, for both data sets we setp=300to leverage the performance and the cost.Since the NUS-WIDE-Lite data set is a subset of the NUS-WIDE data set, the parameter settings on the NUS-WIDE data set are same to that on the NUS-WIDE-Lite data set. That is,α=0.8,β=0.6andp=300.In a first set of experiments we compare the proposed PJMF method to the compared schemes for social image tag refinement. The results in terms of P, R and F1 are presented in Table 2. From the results, we can draw several observations. First, KNN-based tag refinement does not outperform the original tags. In fact, the visual similarity always accompanies the problem of semantic gap. The other reason is that the image associated tags are not sufficient, which limits the advantages of KNN method. Second, the low-rank factor models achieve significant improvements over the baseline. Further, TWTV is competitive with the low-rank factor models. Because they all exploit the local information in tag space and visual space simultaneously while discover the latent image-tag relevance. Finally, compared with the other methods, the proposed PJMF method achieves the best performance although the improvement is marginal. This shows that the proposed method is effective for tag refinement. Over and above, our method is more intuitively understandable for humans. The related tags can be found efficiently by nearest neighbor searches.To validate the effectiveness for the out-of-sample problem, we conduct experiments to evaluate the performance of tagging new social images. The results are also shown in Table 2. It is observed that our method is significantly superior to the other approaches for processing out-of-samples. This validates the benefits of our motivation towards out-of-samples. PJMF provides a general way to map new images into the model.The ranking order of the resulted relevance scores is ignored in the task of image tagging. To address this problem, we evaluate the proposed method in semantic retrieval task. The MAPs are listed in Table 2. It produces very competitive results with low-rank models and TWTV (actually PJMF is the best on this data set) for tag refinement. In accordance with image tagging, the retrieval performance of PJMF outperforms others. It demonstrates that our method can rank the relevant tags at the top positions.In summary, the proposed method is effective for image retagging. The representations of images and tags in the embedding space are more understandable. Their Euclidean distance can demonstrate their relevance. The images can be tagged by searching the nearest tags. Therefore, our method can be identified as the most promising, and we use it below for the NUS-WIDE data set.Next we present experimental results on the NUS-WIDE data set and its subset NUS-WIDE-Lite data set. The results in terms of tag refinement, new image tagging and semantic retrieval are shown in Tables 3 and 4, respectively. Compared to the state-of-the-arts, again we find that our model significantly improve the performance for tagging new images and can rank the related tags at the top positions while it is competitive for tag refinement. The effectiveness of our method for tag refinement and image tagging tasks is validated again.

@&#CONCLUSIONS@&#
We have introduced a new matrix factorization approach for social image tagging. First, the latent image features and the latent tag features are embedded in a unified space. The Euclidean distance in the unified space is adopted to measure the relevance. Second, the latent image features in the unified space are the essential features of high dimensional images by linear transformation. Third, to discover a “good” embedding space, the local geometry information in the visual space and the tag space are preserved. Finally, extensive experimental results on three data sets were reported, which demonstrated the effectiveness of the proposed method. In the future work, we will consider extending the model to learn effective metrics in the latent space and map new tags into the model.