@&#MAIN-TITLE@&#
Enhancing texture descriptors by a neighborhood approach to the non-additive entropy

@&#HIGHLIGHTS@&#
Local non-additive entropy is used to enhance descriptors of texture images.The entropy enriches the descriptors by measuring the local information.The proposal improved the performance of all of the analyzed methods.The gain was more significant for the neighborhood-based descriptors.The proposal can be applied to other descriptors in real-world problems.

@&#KEYPHRASES@&#
Non-additive entropy,Texture analysis,Pattern recognition,Image features,

@&#ABSTRACT@&#
This work proposes to enhance well-known descriptors of texture images by extracting such descriptors both directly from pixel intensities as well as from the local non-additive entropy of the image. The method can be divided into four steps. 1) The descriptors are computed for the original image according to what is described in the literature. 2) The image is transformed by computing the non-additive entropy at each pixel, considering its neighborhood. 3) Similarly to step 1, the descriptors are computed from the transformed image. 4) Descriptors from the original and transformed images are combined by means of a Karhunen–Loève transform. Four texture descriptors widely used in the literature were considered: Gabor wavelets, Gray-Level Co-occurrence Matrix, Local Binary Patterns and Bouligand–Minkowski fractal descriptors. The proposal is assessed by comparing the performance of the descriptors alone and after combined with the non-additive entropy. The results demonstrate that the combination achieved the best results both in image retrieval and classification tasks. The entropy is still more efficient in local-based methods: Local Binary Patterns and Gray-Level Co-occurrence Matrix.

@&#INTRODUCTION@&#
Texture analysis is one of the most important tasks in pattern recognition and computer vision. Despite the usefulness and importance of textures in image representation, it has no formal and consensual definition in the literature. Here, we have adopted the definition presented in [1]. It is stated that the textures are complex visual structures composed of sub-patterns, which show the characteristic properties such as roughness, granularity and uniformity among others. Texture analysis employs pattern recognition methods to identify the objects based on their visual patterns. In this way, this kind of analysis is capable of capturing meaningful information even in the most complex images, when other approaches like contour or color analysis may fail.Despite its importance, texture analysis still is a great challenge, mainly when it is applied to real-world problems where a reliable extraction of information from the analyzed objects depends on the complex relationships amongst patterns in the image representation. Faced with these difficulties, the literature provides a number of approaches in an attempt to represent the richness enclosed in a texture image in the most faithful manner.Among the authors of the first works on texture analysis, Haralick is best known for his co-occurrence matrix [2]. By exploring the statistical relationship among pixel neighborhoods, such approach has become the standard method for texture analysis in the 1970's. A contemporary approach that also gathered attention in the literature is the Random Markov Fields [3], which was used mainly for segmentation purposes. At the end of the same decade Laws [4] proposed to compute the energy of the image after the application of several filters. During the 1980's, fractal geometry emerged as a powerful theory to obtain the texture features. This approach was first presented by Mandelbrot [5], which was later rigorously tested by Pentland [6]. More recently, important advances were made on the basis on this approach, by proposals like multifractals [7] and fractal descriptors [8]. Moreover, a recent contribution was made by Local Binary Patterns [9], which describes the pixel neighborhood in a quite simple but powerful way based on the position-dependent weights for the pixel intensities.Nevertheless, most of the proposed methods obtain the features from the image in a direct manner, without considering the complementary information that cannot be expressed by the intensities of pixels, but only through particular operations over those pixels. In an attempt to fill this gap, some authors have proposed the extraction of features from other domains, like wavelets [10], discrete cosine transform [11], Hough transform [12], and others. On the other hand, other works have been proposed to extract the complementary information from the set of descriptors by means of transforms, which try to emphasize some particular characteristics of those features [13–15]. Even though such methods are efficient to reduce the redundancy in the original data, most of them do not provide any truly different viewpoint other than the pixel intensities.In this context, this work proposes a method to increase the performance of well-known texture descriptors by using information from the non-additive entropy [16] in each local neighborhood of the image. In addition to measure the level of disorder in the local pixel distribution, the non-additive property of this entropy ensures a more suitable processing of complex non-linear structures commonly found in real-world images.The non-additive entropy is computed for each pixel considering its 8-neighborhood. The descriptors from the original image and from the entropy values are combined by a concatenation followed by a Karhunen–Loève transform to identify the most meaningful features. The combined descriptors are compared to the conventional approaches, using different values for the q parameter in the non-additive entropy.Many types of entropy were created after the studies developed by Boltzmann–Gibbs–Shannon. One of them to be highlighted is the non-additive entropy [16]. Based on the idea that different systems require different tools of analysis, which are appropriate to the particularities contained in each system, Tsallis devises its own informational tool named as the non-additive entropy of Tsallis or just q-entropy. The non-additive entropy is the generalization of the standard entropy (Shannon entropy). It is created to extend the scope of applications of classical statistical physics, which is defined by:(1)Sq=∑p(x)lnq⁡(1/p(x)),wherelnqis the q-logarithmic function given by:lnq⁡(x)=(xq−1−1)/(q−1). The entropic index q is real, can be freely chosen and characterizes the generalization. Whenq→1we have the standard logarithm function and consequently the standard entropy is retrieved.The generalized non-additive entropy maintains the character of irreversibility, formulated by Boltzmann's H theorem. However, unlike the standard entropy, this entropy is non-additive. Since(2)lnq⁡(x1x2)=lnq⁡(x1)+lnq⁡(x2)+(1−q)lnq⁡(x1)lnq⁡(x2),then:(3)Sq(A+B)=Sq(A)+Sq(B)+(1−q)Sq(A)Sq(B).The parameter(1−q)of equation gives a measure of the non-additivity, ifq<1the system is called super-additive and whenq>1then the system is sub-additive. This entropy is a good candidate to describe the systems long-range interactions, long-term memory and phase spaces with the fractal structure.Particularly, in this analysis of signals and images, the (Shannon) entropy plays an important role in describing how predictable is a sequence of measures acquired from the real world. The non-additive entropy adds an important parameter to the entropy with a goal of quantifying the non-additive function of the system. Such a property is of great importance in natural textures where multifractal structures can be found quite easily [17–19].Textures are images characterized by the presence of spatial or statistical patterns. These patterns are not necessarily periodic. As these are complex images, the textures present great challenges to techniques of pattern recognition and image analysis. Examples of textures include zebra's fur, a pile of rocks, wood, tissues of clothes, details on walls, a chessboard, marble, and others. Literature presents a large number of methods to analyze these kinds of texture images [1]. These methods can be classified in four types as a) structural, b) statistical, c) spectral and d) based on models.a)Structural methods: These methods treat textures as hierarchical arranges of well defined elements, providing a symbolic description of the image. Morphological operations like opening and closing and detectors of points of interest are applied with the aim of finding and describing the arrangement of elements.Statistical methods: Here, textures are described by statistical properties of their gray-levels. The first methods of this category proposed calculations based on the histogram of the images. Since these are very simple approaches, they were replaced by more efficient statistical methods such as Gray-Level Co-occurrence Matrix [2] or Local Binary Patterns [9].Spectral methods: The purpose of these methods is to represent the texture images using their spectral information. In order to do this it is necessary to estimate the spectral frequency of pixel intensity and correlate finer textures with high frequencies and rough textures with low frequencies. Hence in order to describe textures, methods in this category are based on filters like Gabor and decomposition in sub-bands like wavelets [20].Methods based on models: These methods based on models use a built model and feature extraction based on the model to represent textures. The models are usually fractal based or stochastic. Besides this, fractal usage presents good results when one uses local fractal dimension and multiscale fractal dimension [8,13,21].Once texture patterns are not necessarily periodic, the application of structural methods use to be restrict, because this kind of method assumes that all textures have well defined elements, and this is not always true. On the other hand, the other three methods are able to deal with this challenge of non-periodic patterns. From this point, four of the most relevant methods (two Statistical, one Spectral and the last one based on models) are showed in details on this paper.The statistical methods that we chose were Gray-Level Co-occurrence Matrix and Local Binary Patterns, because both approaches are much more effective compared to traditional methods of this category (simple calculations based on the histogram of the images). From Spectral methods we decide to work with Gabor wavelets since this filter/sub-band decomposition has the most common usage on the literature [20].The last method was given in “based on models” category: named as the multiscale fractal approach Bouligand–Minkowski. The reason to use this method is the success that previous studies obtained using this tool [8,13,21].The following sections give us a brief introduction to these four widespread texture descriptors. These are also the methods chosen to be enhanced in our proposed approach.Although, this is a simple and consolidated method, it is capable of providing remarkable results in many texture analysis problems. It is based on the famous experiments conducted on the human visual perception carried out by Julesz in the seventies [22]. Such experiments showed that “no texture pair can be discriminated if they agree in their second-order statistics”. Despite counterexamples found subsequently for this statement, this result demonstrated the importance of the second-order statistics for texture characterization.Haralick defined a second order histogram of the image named co-occurrence matrix, which depends on a distance d between two pixels and a direction (angle) θ. Given an imagef(x,y), its co-occurrence matrixhd,θ(i,j)is defined by the number of pairs of pixels with coordinates(x1,y1)and(x2,y2)satisfying at the same time the following constraints:(4){(x2,y2)=(x1,y1)+(dcos⁡θ,dsin⁡θ),f(x1,y1)=i,f(x2,y2)=j.For each d and θ,hd,θis a square matrix whose dimensions are the number of gray-levels in the image. The ideal number of angles and maximum distance depend on the textures being analyzed. Generally speaking, if a local neighborhood within the texture gives us enough information to describe it, distances greater than 5 pixels and more than four directions are not necessary. Very large distances use to result in very similar values in the matrix making the descriptors useless. An excessive number of angles also produce redundant information. In practice, as the computation of this matrix may have a high computational cost, most studies use only distancesd=1andd=2pixels and anglesθ=0∘,45∘,90∘and135∘. There are still two types of co-occurrence matrices: symmetric, for which both pairs of pixels at distance d and −d in the direction θ are considered and asymmetric, where only pairs at distance d are counted. The joint probability distribution of pixel pairspd,θ(i,j)is obtained by dividing the co-occurrence matrixhd,θ(i,j)by the total number of neighbor pixelsR(d,θ).To obtain useful texture features from the co-occurrence matrix, Haralick has proposed 14 features to be extracted from p. From those ones we selected three of the most commonly used in the literature, to know, Angular Second Moment, Correlation and Entropy. They are defined in the following, assuming thatμx,μyandσx,σyare, respectively, the mean and standard deviation on x and y columns in p.Angular Second Moment:∑i=0G−1∑j=0G−1[p(i,j)]2;Correlation:∑i=0G−1∑j=0G−1ijp(i,j)−μxyyσxσy;Entropy:−∑i=0G−1∑j=0G−1p(i,j)log2⁡[p(i,j)].Other features extracted from the co-occurrence can be found in the literature [2].This is another local approach to texture analysis that has demonstrated to be a powerful descriptor of images, achieving remarkable results in tasks such as image discrimination, segmentation, retrieval, etc. This method starts from the definition of a local binary pattern at each pixel of the image. To compute such patterns, we have to consider a3×3neighborhood around the pixel and one “walks” through this neighborhood assigning one if the neighbor is greater than the reference (central) pixel and zero otherwise. Thus each pixel is associated to a binary number with eight digits and such binary value can be easily translated to a decimal representation providing therefore a single value for each pixel. Larger neighborhood sizes and more complex procedures involving interpolation can be used in this method. However, here we employed the simplest version described in [29], as our main goal is to verify the impact of the non-additive entropy instead of checking any possible fine-tuning over the original descriptor.In this way, the described procedure ends up with a matrix having the same dimension of the image. The texture descriptor is provided by the values of a histogram of such matrix. More details regarding the basic procedures and the other enhancements to deal with rotation invariance and multiscale characteristics can be seen in [9].Gabor wavelets [20] are based on the spectral analysis of the image. Roughly speaking, the features are obtained by processing the analyzed image by Gabor wavelets two-dimensional filters and compute the energies of the transformed images.Two-dimensional Gabor filterg(x,y)is defined by:(5)G(x,y)=(12πσxσy)e−0.5(x2/σx2+y2/σy2)+2πjWxGabor wavelets filters have been proposed to include spatial localization information in the Gabor filters. Such new family of filters has two extra parameters, the scale m and the rotation θ, and is denoted bygmn:(6)gmn=a−mG(x′,y′),wherex′=a−m(xcos⁡(θ)+ysin⁡(θ)),y′=a−m(−xcos⁡(θ)+ysin⁡(θ)),θ=nπ/K, K is the total number of rotations and S the number of scales.To obtain the texture descriptors, the imagef(x,y)is convoluted with filtersgmn, providing the transformrmn:(7)rmn=f(x,y)⁎gmn(x,y).Thus for each combination of(m,n), the energiesEmnare computed:(8)Emn=1pq∑u,v‖Rmn(u,v)‖2,where p and q are the dimensions of the image andRmn(u,v)is the Fourier transform ofrmn(x,y).Finally, the values of energy are concatenated to compose the feature vector of the image.Bouligand–Minkowski descriptors [8,13,21] are obtained from the Bouligand–Minkowski fractal dimension. This method of estimation of dimension maps the texture represented in a digital image I onto a three-dimensional surface S, where each pixel with coordinates(x,y)is mapped onto a point with coordinates(x,y,I(x,y))in the surface, whereI(x,y)is the gray-level of the pixel.In the following, each point in the surface is dilated by a sphere and the volume of the union of spheres should be computed. To make such computation possible, the setgr(S)of points at a distance r from S is defined by:(9)gr(S)={(x,y,z)|[(x−Sx)2+(y−Sy)2+(z−Sz)2]1/2=E(r)},whereSx,Sy,Szare the coordinates of points in the surface.Thus the dilation volumeV(r)is obtained by:(10)V(r)=∑i=1rQ(i),whereQ(i)is given by:(11)Q(i)=∑(x,y,z)∈Uχgr(x,y,z),where χ is the indicator function.V(r)and r are related by a power-law. The descriptors u are obtained from the values of dilation volumes:(12)u:log⁡(r)→log⁡(V(r)).

@&#CONCLUSIONS@&#
This work proposed a new approach to texture analysis based on combining classical texture descriptors directly applied to the image with the same descriptors applied over the values of the local non-additive entropy on the image.The proposed combination was tested in tasks of image retrieval and classification, followed by a comparison between the results achieved by the original descriptors and the combination with non-additive entropy. Such comparison demonstrated that this combination enhanced the results of the classical methods, yielding higher rates of images correctly retrieved and discriminated. Actually, the non-additive entropy measures the organization of the pixels within its neighborhood. This is a relevant information that complements the information enclosed in the pixel intensities. Combining the texture descriptors under these two perspectives results in more robust and meaningful features capable of achieving great results in image analysis. Particularly, in the classification of Brodatz and Vistex data sets, higher relative gains were achieved when using local-based methods, like LBP and GLCM. Similar fact is observed in the image retrieval of Brodatz. The best performance in this case is justified by the nature of those methods, which consider the local information in a direct fashion. As here the non-additive entropy is also a local measure, its contribution only complements the original descriptors.In short, the proposal presented here has great potential to be used in a number of problems involving image analysis. The related parameters can be adjusted to each situation. For example, considering a training data, and the obtained features can provide reliable outcomes even in difficult cases where the classical approaches use to fail.