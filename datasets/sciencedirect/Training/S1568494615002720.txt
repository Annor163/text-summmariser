@&#MAIN-TITLE@&#
Software defect prediction using cost-sensitive neural network

@&#HIGHLIGHTS@&#
Software defect prediction model was built by Artificial Neural Network (ANN).ANN connection weights were optimized by Artificial Bee Colony (ABC).Parametric cost-sensitivity feature was added to ANN by using a new error function.Model was applied to five publicly available datasets from the NASA repository.Results were compared with other cost-sensitive and non-cost-sensitive studies.

@&#KEYPHRASES@&#
Machine learning,Software defect prediction,Artificial Neural Network,Artificial Bee Colony,Software quality,Cost-sensitive classification,

@&#ABSTRACT@&#
The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction.

@&#INTRODUCTION@&#
Worldwide software spending amounted to $3.7 trillion in 2013 according to one published report [1]. A survey indicated that 23% of this cost was spent on quality assurance and testing [2]. A notorious example of the importance of testing would be the $125 million NASA spacecraft which was lost in space because of a small data conversion bug [3]. The Department of Defense in the U.S. spends $4 billion every year because of software failures [4]. All these numbers show the importance of software testing and quality assurance, and the need to do it carefully and effectively. Fixing a software bug after deployment is 100 times more costly than fixing it during development [5]. Despite these facts, only 30% of companies allocate a testing and quality assurance budget for their projects [3].Software quality discipline was introduced with the growth of software systems complexities and user expectations. ISO/IEC 9126 is an international standard for the evaluation of software quality. According to this standard, quality characteristics of a software product are gathered from internal and external metrics. Six quality characteristics defined in the standard are functionality, reliability, usability, efficiency, maintainability, and portability. Internal metrics are measured by considering only the product itself, without dealing with its behavior. External metrics, on the other hand, are related to the behavior of the product only. The focus of this study is internal metrics: the source code of software systems, but not its behavior or functionalities. Software defect prediction activities can be discussed as part of software quality discipline. More quality software means less defect-prone software. For more than two decades software defect prediction models have been of considerable interest to researchers. These models are used to detect defect-prone modules in an automated way before manual testing. The project test team could then spend their time and budget more effectively based on the results of the model. Defect predicted modules are required to have more focus than non-defect predicted modules. Fig. 1represents the overview role of defect predictors on testing facilities. Classification of modules is done according to their software quality metrics, which will be explained in later sections. Software quality metrics contain information about defect proneness of a module [6]. All research papers written in this area including this study are proofs of this idea.Most machine learning algorithms assume that the misclassification cost of each class is equally important. However, the misclassification cost of a minority class is higher than that of a majority class in most cases. For example, predicting a defective module as non-defect prone (ndp) can cause more expensive fixing activities, since the related software may have been deployed for field use with this defect. On the other hand, predicting a non-defective module as defect prone (dp) can cause wasteful testing activities for the project, but that is generally more acceptable than the previous case. Cost-sensitive classifiers take into consideration both of these cases and try to minimize total misclassification costs, but not total misclassification error.This paper makes the following contributions: (1) a hybrid model, “Artificial Neural Network (ANN) optimized by Artificial Bee Colony (ABC)”, is introduced for the software defect prediction domain, and (2) a cost-sensitivity feature is added to ANN by using a parametric fitness function. A trade-off can be made between the classification performance of minority and majority classes by the change of cost coefficients.The validation of the proposed hybrid model is presented using the following: (1) Commonly used Area Under Curve (AUC), probability of detection (pd), probability of false alarm (pf), balance (bal), and accuracy (acc) performance results are shown, as well as Receiver Operating Characteristics (ROC) curves. (2) AUC results are compared with some other algorithms. (3) The pd, pf, and acc results are shown for different cost values. (4) Normalized Expected Cost of Misclassification (NECM) results are shown according to different cost ratios and compared with some other cost-sensitive neural networks.The remainder of this paper is organized as follows: The related work is summarized in Section 2. In Section 3, the datasets used in this paper are described. Section 4 explains the algorithms and the proposed prediction model. A brief description of performance indices and the results of the study are given in Section 5. Research conclusions are presented in Section 6.

@&#CONCLUSIONS@&#
This paper proposes a hybrid classifier for the software defect prediction problem. ANN connection weights are optimized by the ABC algorithm, which is a modeling of the foraging behavior of honey bee swarms. The parametric cost-sensitivity feature is added to ANN by the introduction of a new error function. The costs of misclassifying Positive and Negative classes are set with related coefficients. The value of these costs has an effect on performance of pd, pf and acc. Cost-adverse and risk-adverse businesses may define appropriate cost coefficients for their own software projects.The performance of the proposed classifier is compared with other algorithms on five NASA datasets and the obtained results show its performance is better than the others. However, the performance difference is not significant. There should be more focus on data preprocessing, feature selection, or other data mining techniques instead of finding a better classifier.