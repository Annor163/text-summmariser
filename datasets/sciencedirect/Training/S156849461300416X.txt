@&#MAIN-TITLE@&#
Differential evolution based 3-D guidance law for a realistic interceptor model

@&#HIGHLIGHTS@&#
This paper solves the real world problem of tactical missile guidance, in which optimality is sought to be achieved using the evolutionary computing method of differential evolution.A valid criticism against optimization by evolutionary computing methods is that they are computationally intensive, as compared to gradient based methods.By posing the problem as that of finding the coefficients of a third order polynomial, the dimensionality of the problem is so greatly reduced that online implementation in real time is shown to be possible.The results so obtained are compared against conventional methods in the guidance literature.

@&#KEYPHRASES@&#
Missile guidance,Optimal control,Optimal trajectory,Genetic algorithm,Online control,Real-time,

@&#ABSTRACT@&#
This paper presents a novel, soft computing based solution to a complex optimal control or dynamic optimization problem that requires the solution to be available in real-time. The complexities in this problem of optimal guidance of interceptors launched with high initial heading errors include the more involved physics of a three dimensional missile–target engagement, and those posed by the assumption of a realistic dynamic model such as time-varying missile speed, thrust, drag and mass, besides gravity, and upper bound on the lateral acceleration. The classic, pure proportional navigation law is augmented with a polynomial function of the heading error, and the values of the coefficients of the polynomial are determined using differential evolution (DE). The performance of the proposed DE enhanced guidance law is compared against the existing conventional laws in the literature, on the criteria of time and energy optimality, peak lateral acceleration demanded, terminal speed and robustness to unanticipated target maneuvers, to illustrate the superiority of the proposed law.

@&#INTRODUCTION@&#
Interception of an aerial target by missiles or interceptors is an important practical problem. However, this is far from amenable to any easy solutions due to the inherent complexities of the problem. Realistic models of missile dynamics must include the effect of time-varying missile speed, thrust, drag and mass, besides gravity. The drag in turn is a function of the missile speed, atmospheric density, and lateral acceleration (latax). Another important practical constraint is the upper bound on the latax. Two simplifications resorted to in the literature are (i) consider only the kinematics, and (ii) separate the three dimensional (3-D) engagement into two planar (or two dimensional, or 2-D) kinematic models in the horizontal and vertical plane. Enabled by such gross simplifications, analytical or closed form guidance laws that can be easily implemented at every time instant, and with minimum computation, are formulated or derived, as in [56,38]. Given the much higher complexity of analysis and design in the 3-D space, guidance papers pertaining to 3-D engagements are far fewer in number, as compared to those for 2-D engagements, in spite of the fact that the first paper on 3-D guidance was published as early as in the 1950s itself [1].Even for the simpler planar kinematic model, interception is not an easy task if the initial engagement geometry has high heading errors. Determination of the guidance law in a high heading error engagement, subject to the kinematic equation alone, has been the subject of many papers and techniques, and some of these techniques are based on methods of nonlinear control design. Some examples are: feedback linearization [2], relative heading error angle concept [22], state-dependent Riccati equation technique [9], extended proportional navigation [54], variable structure control [18,17], and, a combination of LOS rate and heading error [49]. Of these, only Cloutier and Stansbery [9] and Taur [49] deal with 3-D kinematic engagements; the rest consider only 2-D kinematic models.The scenario becomes even more complicated if one imposes the additional requirement of optimality. Analytical optimal guidance laws derived from kinematic models require time-to-go parameter for their implementation, due to the free final-time nature of the problem. Consequently, accurate estimation of time-to-go itself has been another continuing topic of research, as in Ryoo et al. [35,36] and Tahk et al. [48].The nonlinear optimal control problem applicable to high heading error initial geometries is a two point boundary value problem that is amenable to only numerical solutions and demand considerable computational effort, thereby not being implementable in real-time. Further, the performance of these numerical solutions deteriorates for even small deviations between the model assumed for design and the actual plant on which they are applied, due to the inherently open loop nature of these solutions. This makes the case for finding closed loop solutions or guidance laws, that are implementable in real-time, using a more realistic dynamic model, without resorting to the unrealistic simplifying assumptions for the sake of mathematical tractability.The present paper formulates and studies the performance of an online-implementable optimal guidance law based on a realistic model of engagement that explicitly includes all the constraints mentioned in the beginning of Section 1, in 3-D physical space, for high initial heading errors. Except for treating the missile and target as point masses, no other approximations are made. The large number of inequality constraints in the formulation itself makes it very difficult to obtain an analytical or closed form solution, making numerical solution the only option. Any optimal control problem, linear or nonlinear, with any number of compatible equality and inequality constraints on state and controls can be solved by dynamic programming [28]. Another method of solution of the nonlinear optimal control problem is by converting it to a nonlinear programming (NLP) problem and solving the NLP problem, as in Cruz et al. [10]. A method that has been applied in optimal missile guidance, for a realistic model – though only 2-D – is Imado, Kuroda and Miwa [16]. However, as has been acknowledged sometimes by the authors themselves [16], all these are too computationally intensive for implementation in real-time.In this paper, the optimal guidance problem is posed as a low dimensional polynomial optimization problem, and a numerical solution to this problem, computable in real-time, is obtained. The basic pure proportional navigation (PPN) law is augmented with a polynomial function of the heading error, and optimization is achieved by using DE to find the values of the coefficients of the polynomial. The proposed law is then compared with the all-aspect proportional navigation (AAPN) [39], and PPN laws on the following criteria: energy and time optimality, the peak latax demanded, terminal speed, and robustness to off-nominal conditions in the form of unanticipated target maneuvers. The AAPN law of Sim et al. [39] used the same structure as in the guidance law proposed in the present paper, but the solution proposed was applicable for the given initial conditions only, and needed to be recomputed for every different set of initial condition, as pointed out by the authors themselves. It also assumed the kinematic model of engagement. Moreover, the solution methodology was time consuming and hence unsuitable for online implementation. The law proposed in the present paper is applicable to any initial conditions, for a realistic dynamic model of engagement, and is also online implementable.In the previous work of the authors [31], a DE based optimal guidance law was proposed for a two dimensional (2-D) kinematic model of missile–target engagement. It was a proof of concept that, for optimal missile guidance, evolutionary algorithms like the DE could serve as an alternative to the optimal control based methods, thereby circumventing the various difficulties posed by these methods. The work described in the present paper is much more elaborate, since it uses a 3-D realistic engagement model that includes missile dynamics and aerodynamic effects.Compared to the previous work of the authors [31] which considered engagements with a simple, planar kinematic model, the present work assumes a 3-D realistic model that introduces the following complications: First, the state variables are subject to numerous interdependent equality and inequality constraints. Since these are indirect functions of the altitude, they depend on the vertical position of the missile in the inertial frame of reference. Secondly, the latax is applied by the missile in its own body frame of reference, and the LOS rates are measured and heading error angles are readily computed in the LOS frame of reference. This entails conversion from one frame of reference to another. Thirdly, unlike in the kinematic model in which the missile speed is constant, missile speed also enters the state as a variable, and is characterized by sharp discontinuities as the missile thrust switches from boost to sustain, and sustain to coast phases.Fourthly, a very serious practical difficulty is that, with the dynamics also taken into account in the realistic model, the critical constraining factor is the thrust that is available only for a limited time period. The missile speed that is highly dependent on the thrust begins to fall off from the end of the boost phase, especially if the missile is still applying a large latax. Any practical interception is considered to be successful only if the missile speed is high enough just before interception, so that the missile is in a position to engage the target in the end game scenario. Hence, for a successful interception, the missile thrust should still be in the sustain phase, or at least not be too long into the coast phase.The guidance law designed must take into account all these factors, and hence moving from a 2-D kinematic model to a 3-D realistic model is far from a mere extension of the guidance law designed for the 2-D kinematic model. The fifth and final complication that is of crucial importance is, the solution or the guidance law that involves the four complications described above, has to be available or computable in real time, to be of any practical relevance. The main contribution of this paper is in providing a real-time solution that is online implementable to this challenging problem, using differential evolution as the enabling method. Since the problem is a real world one, there is no generic, elegant solution; problem specific knowledge has to be incorporated, and real world complications have to be addressed, as described in the paper.The paper is organized as follows: Section 2 presents the mathematical preliminaries, the 3-D PPN, and all-aspect proportional navigation (AAPN) laws, and the development of the 3-D counterpart of the 2-D differential evolution tuned all-aspect proportional navigation (DEPN-2D) law. Section 3 explains the DE algorithm used in the paper, Section 4 describes the design of the proposed 3-D guidance law using DE, Section 5 presents the simulation results and comparison of the proposed law with the other guidance laws, and is followed by concluding remarks in Section 6.Using a Cartesian co-ordinate representation in an inertial frame of reference, the three dimensional (3-D) point-mass equations of motion for the missile and the target are modelled as follows:Missile:(1)xm˙ym˙zm˙ϕm˙γm˙Vm˙=VmcosγmcosϕmVmcosγmsinϕmVmsinγmaym/(Vmcosγm)(apm−gcosγm)/Vm(Γ−D)/m−gsinγm(2)aym2+apm2≤a¯m2Target:(3)xt˙yt˙zt˙ϕt˙γt˙=VtcosγtcosϕtVtcosγtsinϕtVtsinγtayt/(Vtcosγt)apt/VtΔx=xt−xm,Δy=yt−ym,Δz=zt−zmr=(Δx2+Δy2+Δz)2)γL=tan−1(Δz/(Δx2+Δy2)),ϕL=tan−1(Δy/Δx)where Vmis the missile speed, Γ the time-varying thrust, D the drag, m the mass of the missile, and g the acceleration due to gravity. aym, apm, aytand aptare the yaw and pitch latax's of the missile and target, respectively, anda¯mrepresents the maximum permissible latax of the missile. The angles ϕm, γm, ϕt, γtare Euler angles made by the missile and the target (Fig. 1). The target speed Vtis assumed to be constant.A guidance law that has been proved to guarantee interception of the target, whether maneuvering or non-maneuvering, – for the kinematic model – is the pure proportional navigation (PPN) law [13,14]. The 3-D PPN law is given by [41](4)aM=NΩL×VMwhere aMis the missile latax vector, N the navigation constant, ΩLthe angular velocity of the LOS, and VMthe missile velocity vector.In the LOS frame of reference,(5)ΩL=λx˙iL+λy˙jL+λz˙kL(6)VML=VmxLiL+VmyLjL+VmzLkLwhereλx˙,λy˙,λz˙are the XL, YL, ZLcomponents, respectively, of the LOS angular velocity vector, iL, jL, kLare the unit vectors along, respectively, to XL, YL, ZLaxes,VMLis the missile velocity vector VMin LOS frame of reference, andVmxL,VmyL,VmzLare the missile velocity vector components, respectively, along XL, YL, ZLaxes, in the LOS frame of reference, and given byVmxL=Vmcosθmcosψm,VmyL=Vmcosθmsinψm,VmzL=Vmsinθm, with the angles θmand ψmdefined with respect to the LOS (Fig. 1).However,λx˙cannot be measured by the conventional on-board seeker [41]. Hence, using only the last two terms of (5), and (6) in (4),(7)aML=N{(VmzLλy˙−VmyLλz˙)iL+VmxLλz˙jL−VmxLλy˙kL}whereaMLis the missile latax vector in the LOS frame of reference.For practical implementation, this latax needs to be converted to the missile body frame of reference by using(8)aMm=TLmaMLwhere the co-ordinate transformation matrix TLmthat achieves the transformation from the LOS frame of reference to the missile body frame of reference is given by(9)TLm=cosψmcosθmsinψmcosθmsinθm−sinψmcosψm0−cosψmsinθm−sinψmsinθmcosθmThe lataxaMmin (8) has two components in the yaw and pitch plane of the missile:(10)aMm=aymjm+apmkm(11)aym=−NVmλy˙sinθmsinψm+NVmλz˙cosθm(12)apm=−NVmλy˙cosψm(13)λy˙=Vmsinθm−Vtsinθtr(14)λz˙=Vtcosθtsinψt−Vmcosθmsinψmrwhere aymand apmare along the Ymand Zmaxes of the missile frame of reference, and the angles θtand ψtare defined with respect to the LOS frame of reference (Fig. 1).The PPN law that meets the essential requirement of interceptability can be modified to meet the desirable requirement of optimality by augmenting it with an additional term for this purpose, leading to the AAPN law. The AAPN guidance law for 2-D engagement is given by [39](15)am,2D=NVmλ˙+f(h,Vratio)Vm2rwhere f is a polynomial function of the heading error angle  h, and  Vratio=Vt/Vm. Since f is far less sensitive to Vratioas compared to h[39], f reduces to(16)f=ah+bh2+ch3With this, interception-guaranteed optimality was sought to be ensured, for the assumed kinematic model. However, the issue of determining a, b, and c was not a simple task that could be achieved in real-time. It was calculated offline in Sim et al. [39], using a protracted three step procedure. A simple one step procedure that was implementable online was proposed by Raghunathan and Ghose [31], and named the DE-AAPN law, and referred to as the DEPN-2D law, to distinguish it from the 3D counterpart proposed in this paper. The DEPN-2D law uses DE to find out the values of the coefficients a, b and c.As with the latax vector in the 3-D PPN law given by (10), the 3-D equivalent of the DEPN-2D law is given by two components(17)AM=Aymjm+ApmkmThe assumption made here is the same as in (10): the missile acceleration comprises only lateral acceleration (latax), and contains no component along the longitudinal direction.The pitch and the yaw latax components Aymand Apmin (17) are given by(18)Apm=apm+fp(hp)Vm2r(19)Aym=aym+fy(hy)Vm2r(20)fp=aphp+bphp2+cphp3(21)fy=ayhy+byhy2+cyhy3where hpand hyare the heading errors in the pitch and yaw planes in the LOS frame of reference. This is in contrast to the 2-D case, in which only a single heading error exists (16). As in the 2-D case, the DEPN-3D law involves finding out the values of the coefficients ap, bp, cp, ay, byand cyusing DE.The angles θm, ψm, θt, ψt, hyand hpin (11)–(14) and (18)–(21) are in the LOS frame of reference, whereas the states of the missile and the target being subject to altitude dependent practical constraints like density and temperature, have to be obtained by integration of (1) and (3) in the inertial frame of reference. This needs co-ordinate transformation from inertial to the LOS frame to be done at every time instant of the simulation.(22)VML=TILVMI(23)VTL=TILVTIwhereVMIandVTIare the missile and target velocity vectors VMand VTin the inertial frame of reference, given by(24)VMI=VmxIiI+VmyIjI+VmzIkI(25)VTI=VtxIiI+VtyIjI+VtzIkIwhere iI, jI, kIare the unit vectors along XI, YI, ZIaxes, respectively, andVmxI,VmyI,VmzIare the missile velocity vector components, respectively, along XI, YI, ZIaxes, in the inertial frame of reference, and given byVmxI=Vmcosγmcosϕm,VmyI=Vmcosγmsinϕm,VmzI=Vmsinγm. Similarly,VtxI=Vtcosγtcosϕt,VtyI=Vtcosγtsinϕt,VtzI=Vtsinγt.The co-ordinate transformation matrix that achieves the transformation from inertial to the LOS frame of reference TILis given by(26)TIL=cosϕLcosγLsinϕLcosγLsinγL−sinϕLcosϕL0−cosϕLsinγL−sinϕLsinγLcosγLand(27)TLI=TIL′(28)VTL=VtxLiL+VtyLjL+VtzLkLwhereVtxL=Vtcosθtcosψt,VtyL=Vtcosθtsinψt, andVtzL=Vtsinθt. The angles hp, hyin (18) and (19) are given by (Fig. 2(a) and (b))(29)hp(t)=θm(t)−Lp(t)(30)hy(t)=ψm(t)−Ly(t)(31)θm(t)=tan−1(VmzL(t)VmxyL(t))(32)VmxyL(t)={VmxL(t)}2+{VmyL(t)}2(33)Lp(t)=sin−1(VtzL(t)Vm(t))(34)ψm(t)=tan−1(VmyL(t)/VmxL(t))(35)Ly(t)=sin−1VtyL(t)Vm(t)cosLp(t)A later addition to the EA family, the differential evolution (DE) was proposed by Price and Storn [45,46,42,30,47,29,43]. A popular member of the evolutionary algorithm (EA) family, the DE owes its popularity to its simplicity of implementation, and performance in terms of reproducibility of results, and relative insensitivity to change in its tuning parameters, that have been proven at several congress on evolutionary computation (CEC) competitions [12]. An empirical study of some basic versions of the particle swarm optimization (PSO), genetic algorithm (GA) and DE algorithms, found DE to be the best performer on a test suite of static optimization benchmark problems, and regarded the DE as an excellent first choice when faced with a new (static) optimization problem [51]. Another comparison of the evolutionary computation (EC) algorithms of the GA, DE, evolutionary programming (EP), evolutionary strategy (ES), ant colony optimization (ACO), PSO, and the other algorithms of Tabu search, simulated annealing, and hybrid approach (HA) is found in Kannan et al. [19]. These methods have been applied to the real-world, highly constrained, nonlinear, discrete optimization problem of generation expansion planning, and it was found that, excepting the HA, the DE outperformed all the others in terms of success rate (SR), defined as the number of times the optimal solution was achieved to the total number of test runs. It was opined that this was due to the nature of mutation employed by DE. This provides DE with one of its main assets, ‘contour matching’ [44], which refers to the self-adaptive property of the vector population to automatically explore the most promising regions of the solution space, once they are detected. A good survey of DE and the state-of-the-art including its major variants, application to difficult optimization problems and engineering applications is covered in Das and Suganthan [12] and Chakraborthy [4]. A generic explanation of how the DE algorithm works and the pseudocode can be found in Raghunathan and Ghose [31].Given the inherent advantages of EC over other gradient based optimization methods, the rich potential of EC methods for solving optimal control problems were recognized in the 1990s itself [26], [25] and [21]. As these were simply demonstrations of proof of concept, most of the problems solved in these were simple optimal control problems for which analytic solutions existed. This was followed by problems of increasing sophistication like in Seywald et al. [37] and Sim et al. [39], in which the GA was used to provide good initial guess solution for the methods used therein. Other than those of the authors of the present paper, probably the only applications of DE to optimal control problems are Chiou and Wang [7] and Cruz et al. [10], in which DE is applied to get offline solutions to multimodal problems for which the solutions are known beforehand. In Sim et al. [39], the optimal control problem solved was an optimal missile guidance problem for a kinematic model. Here too, the solution was obtained offline, based on an existing solution obtained by a different method. To the best of our knowledge, the first online implementable solution to the optimal missile guidance problem obtained by an EA was in Raghunathan and Ghose [31]. In this work, the problem solved offline in Sim et al. [39] was solved online in real-time using DE, since it was felt that, given the inherent simplicity of the DE, it would be the most suitable EA for online implementation. The present work too uses DE for the same reason, but for the more complex, realistic, 3-D missile–target engagement model.Several empirical studies on the performance of the different DE variants have appeared in the literature over the years. Different DE variants, both classic and more sophisticated, are applied to a suite of benchmark functions, and the results summarized. These functions varied in parameter dependence, dimensionality, modality and noise. This is the approach followed in, for instance, Mezura-Montes et al. [24], Brest et al. [3], Das et al. [11] and Zhang and Sanderson [57]. But these are all static optimization problems, and applications of DE to dynamic optimization or optimal control problems itself are very few (cited in Section 3.1), and no such study has been performed for optimal control problems, to the best of the authors’ knowledge.Obviously, no optimization method can perform equally well on all optimization problems, as explained by the No Free Lunch (NFL) Theorem [52]. Consequently, the method that works best for any particular problem has to be found by trial and error by trying out all the methods. Applying this to the DE variants, the variant that works best for the optimal control problem or optimal missile guidance has to be found out empirically, by trying out all of them. This is outside the scope of the present work, and may be considered for some future work. The scope of the present paper is limited to application of classic DE to optimal missile guidance using a realistic 3-D model.To apply DE to the missile guidance problem, the values of the DE parameters are first determined. Several claims and counter-claims are found in the DE literature concerning the rules for tuning of the DE parameters, but these are not backed by experimental justifications [12]. Hence the approach adopted here is to begin with a few guidelines available in DE literature, and fine-tune the algorithm by executing a few initial sample runs.A detailed study of the best values of F and Crwould call for a theoretical analysis as well as empirical study, as in Zaharie [55]. Since such a study is out of the scope of this paper, a more practical and immediate way is adopted. Storn [44] gives a ‘rule of thumb’ guideline of the approximate range from which to begin while trying to solve a problem by DE: mutation (or differentiation) constant F∈[0.5, 1.0], crossover ratio/constant Cr∈[0.8, 1.0], population size NP=10D, where D is the number of unknown variables, or the dimensionality of the problem. There also exist the default values from which to begin [43]: Cr=0.9, and F=0.8. Given the unknown solution surface topology, this default, high value of F that leans towards exploration, rather than exploitation, is retained. The high value of Cralso implies that the trial vector is more of a mutant than parent, but the problem is found to work well for this default value as well. As it was observed that the problem was not sensitive to reasonably small variations in the values of these DE parameters, the default values were used, without any further study of this aspect of the algorithm.The suggested value of NP=10D necessitates 10D cost function evaluations in each generation. Since an indispensable requirement of the missile guidance problem is online implementability, and cost function evaluation is found to be the most computationally intensive of all steps in the whole procedure, the population size NPis sought to be reduced as the first step. The mutation and crossover operators of DE impose an absolute lower limit (NP≮4), but since this is too low for a multi-point directed random search algorithm like DE, NP=4D, arrived at by trial and error, and traded off against the maximum number of generations Gmax, as in Raghunathan and Ghose [31].The classic DE variant used is DE/best/1/bin, as against DE/rand/1/bin, another choice that works equally well for the problem in this paper. Here the ‘best’ or ‘rand’ in the above notation [44] refers to the base vector that is perturbed in mutation. ‘best’ means the fittest in the generation, and ‘rand’ means that the vector is chosen randomly. The ‘1’ refers to the number of difference vectors used, and ‘bin’ refers to the binomial crossover scheme. More details and comparison of these variants can be found in Storn [44] and Price [29].The use of [0,1] as the bounds for |a|, |b| and |c| in the AAPN law of Sim et al. [39] assumes that the scaling factorVm2/rin (15) scales the values of a, b and c to within ±1. Through simulations, it was found that better and faster solutions are obtained by enlarging the solution space to beyond ±1, probably because the above assumption does not always hold, especially when large heading errors are involved. On the other hand, too large a range would mean needlessly enlarging the search space, something that is not in the interest of online implementation. By trial and error, the bounds for the solution space is fixed as [−5, 5].The DEPN-3D law solves the following optimal control problem(36)mina,b,cJ=12∫t0tf(Am2+Wt)dtsubject to(1)–(3)whereAm=∥AM∥=(Apm2+Aym2), with Apmand Aymreplacing apmand aym, respectively, in (1) and (2). In EA terminology, the J used in (36) is the fitness function used for evaluation of the trial solutions.The latax saturation that is represented by the inequality constraint (2) has to be implemented on two separately computed components (18) and (19). A practical way of implementing it that is used in this paper is(37)Apm(Aym)=Apmc(Aymc)if(Apmc)2+(Aymc)2≤a¯ma¯m(Apmc)2+(Aymc)2Apmc(Aymc)otherwisewhereApmcandAymcare the pitch and yaw latax components computed by (18) and (19).The initial zeroth generation population PG=0 of NPtrial solutions or individuals are sextuples of (ap, bp, cp, ay, by, cy), generated randomly within the range ±5.(38)PG=0={x¯1,0,x¯2,0,...x¯i,0,...,x¯NP,0}wherex¯i,0={x1,i,0,x2,i,0,x3,i,0,x4,i,0,x5,i,0,x6,i,0}={ap,i,0,bp,i,0,cp,i,0,ay,i,0,by,i,0,cy,i,0}pi,G=0=−5+randj[0,1]×(+5−(−5))p=ap,bp,cp,ay,byorcy,i=1,2,...,NPThe mutant vectorvi,G+1is produced with F=0.8:(39)vi,G+1=pr1,G+0.8(pr2,G−pr3,G)wherevi,G+1=(aˆp,bˆp,cˆp,aˆy,bˆy,cˆy),ps,G=(ap,bp,cp,ay,by,cy),s=r1,r2,orr3,andr1≠r2≠r3≠iThe trial vector ui,G+1 is generated with Cr=0.9:(40)jrandi=int(randi[0,1]×6)(41)api,G+1=aˆpi,G+1if(rand[0,1]≤0.9orjrandi=1)api,Gotherwise(42)bpi,G+1=bˆpi,G+1if(rand[0,1]≤0.9orjrandi=2)bpi,Gotherwise(43)cpi,G+1=cˆpi,G+1if(rand[0,1]≤0.9orjrandi=3)cpi,Gotherwise(44)ayi,G+1=aˆyi,G+1if(rand[0,1]≤0.9orjrandi=4)ayi,Gotherwise(45)byi,G+1=bˆyi,G+1if(rand[0,1]≤0.9orjrandi=5)byi,Gotherwise(46)cyi,G+1=cˆyi,G+1if(rand[0,1]≤0.9orjrandi=6)cyi,Gotherwise(47)ui,G+1=(api,G+1,bpi,G+1,cpi,G+1,ayi,G+1,byi,G+1,cyi,G+1)If the trial vector produced violates any bound on the variables, it is fixed at the bound violated.uj,i,G+1=+5ifuj,i,G+1≥+5−5ifuj,i,G+1≤−5,uj=ap,bp,cp,ay,byorcyThe values of J that the trial vector ui,G+1 and the target vector pi,G=(api,G, bpi,G, cpi,G, ayi,G, byi,G, cyi,G) produce are computed. The one that produces lower J becomes pi,G+1, that is, a part of the next generation, and the other is discarded. By using this kind of tournament (‘knockout’) selection between every pair of parent and child, DE ensures two things. One is that the diversity of the population is never lost, as may happen if the whole of the parent population is replaced by the child population, as in some evolutionary algorithms like the GA. The second is that, elitism, or the practice of preserving the best trial solution in a population is automatically ensured: if the best target vector is better than the competing trial vector, it gets passage to the next generation child population. If not, it is replaced by the new best (trial) vector in the whole population.Mutation, crossover and selection are sequentially carried out for G=1, 2, ...Gmaxgenerations. The Gmaxth generation individual(apl,Gmax,bpl,Gmax,cpl,Gmax,ayl,Gmax,byl,Gmax,cyl,Gmax)that produces the least J is the best solution obtained from the procedure.The cost or fitness function J is computed as follows: a trial solutionx¯i,G=(api,G,bpi,G,cpi,G,ayi,G,byi,G,cyi,G)is substituted in (20) and (21) to find fpand fy, and these are substituted in (18) and (19) to obtain the latax AM(t) given by (17) for the time period [t0, tf]. For the constrained input case, the latax is fixed at±a¯M, for the time segments in which the latax exceeds the maximum bound±a¯M. This constrained latax is used to integrate (1) and (3) until the miss distance is less than the lethal radius assumed. The integration is done numerically using a fourth order Runge-Kutta method. J is calculated with the help of the tfthus determined, and Am(t), using (36).The application of DE to the missile guidance problem is shown in the form of a flowchart in Fig. 3. It is worth noting that this procedure is general enough to determine an optimal missile guidance law for any missile–target engagement problem, whose structure consists of a set of tunable parameters that have to be arrived at by trial and error.As cited in Section 3.1, the previous application of DE to optimal control [10] was offline, and took more than a hundred seconds to compute the control for a dynamic process that was of less than one second duration. The solution process for AAPN too, proposed by Sim et al. [39] was offline. Consequently, computation time was not a constraint in these references. As explained in Thangavelu and Pradeep [50] and Raghunathan and Ghose [31], for dynamic optimization or optimal control applications, EAs could be employed for finding solutions online, under any of the following circumstances: (i) the plant or system model is available, and the dynamics is slow enough to allow the computation time needed by the EA to arrive at the solution, (ii) a ‘good enough’ solution, not necessarily the best, is all that is needed for the application and (iii) massively parallel implementation is possible, so that the best solution is obtained in a small interval of time.However, the missile guidance problem falls in none of the above three categories. The dynamics is very fast, and the best solution, the one that produces minimum J with acceptable miss distance, is the one that is acceptable. Though computing capacities of computers have been increasing rapidly, the onboard computing power on the missile is still not sufficient to allow massively parallel implementation. To overcome the above difficulties, this paper proposes a two loop hybrid control.Fig. 4shows the two loop hybrid control scheme for the online-implementable DE tuned AAPN (DEPN-3D) law, first proposed in Raghunathan and Ghose [31], and also used in the present work. The upper loop that includes the PPN would be in action until some intermediate, discrete time instants ti, i=1, 2, ..., ti<tf, where tfis the flight time computed from the model used in the lower loop. Within this time instant, the DEPN-3D law would compute the best solution. In case no convergence is achieved within t1 for some reason, the upper loop would continue to be applied until ti, i=2, 3, ..., at which convergence occurs. Thus, there is a backup guidance law in the upper loop, even if no convergence occurred for the entire duration of the engagement, thereby ensuring at least the primary requirement of capturability, even if the optimization fails and the secondary requirement of optimality cannot be achieved. This addresses the practical problem of failure of convergence of the optimizer, or algorithm adopted for optimization.The basic methodology of online implementation is adapted from Raghunathan and Ghose [31]. This computationally challenging task of calculating the DEPN-3D guidance law in real-time is accomplished by the following steps:(i) Increasing the number of coefficients in the polynomial functions fpand fygiven by  (20) and  (21) does show a marginal improvement in the value of J. However, since fpand fytoo need to be calculated for every individual in every generation, the number of coefficients in each of these equations is restricted to 3, as in (16). On the other hand, reducing the number of coefficients to 2 leads to results that either vary over too wide a range to be acceptable or takes too long to arrive at results that are within acceptable range.(ii) Even after using only 3 coefficients in each polynomial function, there are six unknown coefficients ap, bp, cp, ay, byand cy(D=6) to be computed in the cost function evaluation. The number of unknowns is reduced to half by making ap=ay=a, bp=by=b, and cp=cy=c, to reduce the computation time for online implementation.This also reduces the population size, NP=4D from 24 to 12.(iii) Since it was found that there is reasonably good convergence within 20 generations of the DE, the DE simulation run is terminated after 20 generations. The best solution triple (a, b, c) obtained after 20 generations is used to calculate the DEPN-3D law. Keeping the total number of cost function evaluations for solving the problem NP×Gmaxconstant, one could also interchange the values used for NPand Gmax, without increasing the total computational effort. While this does produce the same result for this particular problem, it is conjectured that it is better to have the higher value for Gmaxthan for NP, since the possibility of premature convergence is better avoided by doing so, given that the topography of the solution space is unknown, and is different for different missile trajectories, due to differences in altitude, drag, and time duration of the trajectories.(iv) The numerical solution of (1) and (3) that needs to be solved as a part of fitness evaluation of every solution vector in every generation is time consuming. To alleviate this, the step size in the RK-4 function used to solve  (1) and (3) is increased to 0.1s, and the miss distance for terminating the simulation is also increased to 25m.The coding and simulation is done in MATLAB® version 6.5.0 and SIMULINK® version 5 on a pentium IV, 3GHz computer with 512MB RAM and 4GB virtual memory. To achieve fast execution, the integration of (1) and (3) is done in the SIMULINK environment, running in accelerator mode. Further, the in-built features of SIMULINK accelerator that enable even faster execution are made use of. The rest of the simulation that includes applying DE to the missile guidance problem is done in the MATLAB environment.The basic dynamic model for the missile that includes aerodynamic effects is adapted from Cheng and Gupta [6], Kee, Dong and Siong [20], Ratnoo and Ghose [33,34].The aerodynamic drag D that appears in (1) is modelled as D=D0+Di, where the zero-lift drag D0=Cd0Qs, the induced dragDi=Km2am2/(Qs), the induced drag coefficient K=1/(πAre), the dynamic pressureQ=12ρVm2, where s is the planform reference area, Arthe aspect ratio, e the efficiency factor, the atmospheric density, ρ(h)=1.5579−1.058×10−4h+3.725×10−9h2−6.0×10−14h3, where h∈[0, 20, 000] is the altitude.The coefficient Cd0=0.02, M<0.93;Cd0=0.02+0.2(M−0.93), 0.93≤M<1.03;Cd0=0.04+0.06(M−1.03), 1.03≤M<1.10;Cd0=0.0442+0.007(M−1.10), M≥1.10 where M is the Mach number, and the reference area s is 1 m2. The computed values of K are: K=0.2, M<1.15;K=0.2+0.246(M−1.15), M≥1.15. The Mach number,M=Vm1.4RT,R=288, where the temperature variation with altitude is given by T=288.16−0.0065hK, h≤11, 000 m;T=216.66K, h>11, 000m.The thrust profile and the mass are assumed to be: Γ=12, 000 N, m=165−4t kg, for 0≤t≤10 s; Γ=2000 N, m=125−1t kg, for 10<t≤40 s; Γ=0 N, m=95 kg, for 40 s<t.The proposed method is implemented on the following problem:Without loss of generality, for simplicity and convenience of calculation, the initial LOS is assumed to be along the XIaxis (γL=ϕL=0). The other initial conditions of the engagement are: xm=ym=yt=0, zm=zt=3000, xt=3000, Vm=400, Vt=200.The time-weight Wt=104, the value used in Raghunathan and Ghose [31] and Sim et al. [39]. Though practical values of the navigation constant N, is usually set at between 2 and 4 (p. 361, Lin [23]), this value is chosen to be 3, since this value has been proven to be optimal at least under some conditions [4]. The lethal radius of the missile is assumed to be 10 m in the simulations used for validation. The other nominal conditions assumed are a lag-free guidance system (T=0), and a 15g constraint on latax (a¯M=147m/s2). The interception or capture is deemed to be successful only if the miss distance falls to less than 10 m without the missile terminal speed (Vm(tf)) falling to less than a cutoff speed of 350 m/s, and the integration of (1) and (3) is stopped at this time instant.Following in the footsteps of Morgan et al. [27], Choi et al. [8] and Hossain et al. [15], the guidance law used for comparison against the DEPN-3D law of this paper is the PPN, which is a ready benchmark, and one that has been extensively studied in the literature and believed to have been widely implemented in practice. As the law superior to even the PPN when target maneuver is known [56], the augmented PPN (APPN) (covered in the Appendix for the sake of completeness) too has been used as another benchmark for comparison in this paper. The final benchmark used in this paper is the AAPN of Sim et al. [39], since it is the original law upon which the past [31] and present works of the authors are loosely based on.Although the method proposed in this paper is online-implementable, the results of the offline-implementation of the proposed method are also shown, for a fair comparison with the AAPN, since the AAPN is an offline law.22The classic laws, PPN and APPN are online implementable, as indicated in Tables 1 and 2.This may also be useful in the scenario that, if the target variables are known prior to interception, the optimal control and trajectories may be calculated in advance.The time required for computing the online version of the DEPN-3D law (the lower loop in Fig. 4) is found to be mostly just over 5s, and always under 6s, for D=3, NP=12, Gmax=20 (the values arrived at in Section 4.3.1). Hence, the first intermediate time instant t1 (discussed in Section 4.3) is fixed at 6s. For the problem in this paper, since convergence always occurred within 6s, there was no need to consider further intermediate time instants (t2, t3, ...).A non-maneuvering (ayt=apt=0), receding target is assumed to be flying away from the missile in an exact tail chase initially (γt=ϕt=0°), and the missile has very high initial heading errors of hp=−30°, hy=125°.The performance of the various guidance laws under nominal conditions are shown in Table 1(Case 1(a)) and Fig. 6(a) and (b). The DEPN-3D law is labeled as DEPN in all the graphs, owing to space constraint. The performance index J of the PPN law is shown as the base value of 100% for easy comparison. It is seen from Table 1 that, both the online and offline implementations of the DEPN-3D perform better than the other laws, with respect to three of the five criteria used for comparison: tf, J and Vm(tf). The performance of all laws as per the fourth criterion, the am(max) is the same: all laws demand the limiting value of the latax,a¯m. This is because of latax saturation which occurs since the heading error is very high. The fifth criterion of the limiting values of target maneuver for which capture takes place is inapplicable in the nominal case.Comparing the online implementable laws, the online implementation of DEPN-3D is constrained from performing even better by the fact that it is applied only from t1= 6s, and it is the PPN that is applied until then. In spite of this, it is a better performer than the PPN and AAPN. Fig. 6(a) shows how this is achieved. For the same latax saturation limit of 15g=147m/s2 that is reached by all the laws, it applies more pitch latax from t1 onwards, thus making the missile rise to a higher altitude in the atmosphere. This enables the missile to take advantage of the reduced drag at higher altitude. However, this has to be traded off against the continuous loss of kinetic energy due to drag on account of the longer flight duration of the longer path involved in doing so. Thus, the climb has to be only to an optimal height, as has been noted in the literature [6,53,32,40]. The DEPN-3D law accomplishes this automatically, given the model of the atmosphere, and the aerodynamic model of the missile. The offline DEPN-3D faces the least drag, and the PPN the most, as may be deduced from Fig. 6(b).The offline implementation of DEPN-3D is the best performer of all laws, since the guidance algorithm can be applied from the beginning of the engagement (t=0), and the tuning of the coefficients a, b, and c is much better than the default values of these coefficients in the AAPN law, which is also an offline implementation.It is seen from Table 1 that the terminal speed Vm(tf) of the missile is inversely related to the flight time tf, since the missile loses its speed at every instant of flight time due to aerodynamic drag. Due to the shorter flight times, the DEPN-3D laws are the best performers in this respect as well.A complicating factor with the use of Euler angles in 3-D engagement scenarios is the singularity that arises for some values of the variables. This complication arises in the integration of (1) and (3), as for instance, when the angles γtand γmcross 90°, makingϕ˙tandϕ˙mshoot to very high values at these points. This difficulty is tackled by limiting these values to |0.2| at these points.The trajectories of the missile and the target have been included for better understanding and visualization of the performance of the guidance laws, for all the cases in this paper.A typical convergence curve of the solution for the online-implementable DEPN-3D is shown in Fig. 5. The variation in the values of J obtained in repeated trials, after 20 generations, was less than 0.1 %, obviating the need for any detailed statistical analysis.Fig. 6.The true test of any guidance law is when it faces off-nominal conditions. By far the most important off-nominal condition that causes performance degradation is the target maneuver. Unsurprisingly then, one of the first improvements to PN towards optimizing its performance was to address this issue by coming up with an augmentation term involving target maneuver, leading to the APPN law (see Appendix A).The robustness of the guidance laws in this paper is tested by letting the target undertake unanticipated maneuvers. The target is assumed to be undertaking the two most common evasive maneuvers in practice: bank-to-bank (B-t-B), and step. Further, for ease of comparison, the target is assumed to be maneuvering equally in the pitch and the yaw planes.The performance of all the laws to a B-t-B maneuvering target is considered first. The results are shown in Table 1 as Case 1(b). The maximum target maneuver magnitude for which all laws intercept the target is determined to be 1.52g. As can be expected, the performance of all the laws is poorer when compared with the nominal case (Case 1(a)). However, the pattern of results for the nominal case is seen to be repeated in this case too. The least values of J is for the offline DEPN-3D, and the maximum value is for APPN, which are slightly more than that for PPN. This prima facie surprising result is readily explained by the fact that, armed with target maneuver information, it compensates the target maneuver from t0 itself, a futile effort that is more costly in terms of J in the more practical world that the aerodynamic model represents – when the target is far away. The maximum value of Vm(tf) is for offline DEPN-3D, and the minimum value is for PPN. This is explained by the fact that the DEPN-3D has the least flight time, and hence suffers the least energy loss due to drag. Similar reasoning applies to PPN.The maximum magnitude of the unanticipated target maneuver for which the target can be intercepted is the minimum for PPN (1.52g), and more than double this value for online DEPN-3D (3.93g). Interestingly, the corresponding value for the offline DEPN-3D law (3.73g) is lower than for the online DEPN-3D law. This is explainable by the fact that, for a sinusoidal maneuvering target, a guidance law that applies higher latax from t0 itself is applying too much latax too soon, expends energy in vain, and finds itself weaker in the later stages of the engagement. The missile–target trajectories for this case are shown in Fig. 7.Through simulations, the B-t-B maneuver that is least unfavorable to interception is found to be: both aytand aptnegative for the first 6s, of the opposite sign for the next 6s, and so on. This case is shown as Case 1(c) in Table 1. For comparison with the most unfavorable case (Case 1(b)), the magnitude of the maneuver is restricted to the same magnitude of 1.52g in each plane. The performance of all the laws is expectedly poorer than for the nominal case (Case 1(a)), but better than that for the most unfavorable case. The pattern of the best results for offline DEPN-3D and poorest results for APPN is again seen to be repeated in this case too. By compensating for a downward moving target from t0 itself, the APPN law loses altitude and hence requires even more time and energy in the later stages of the engagement than PPN for interception. This is reflected in the values of tfand J. Since this case is less unfavorable than Case 1(b), all laws except the APPN can intercept with higher target maneuver levels than for Case 1(b). For instance, the PPN can intercept up to 3.07g for this case, as against 1.52g for Case 1(b), and the offline DEPN-3D can intercept up to 4.62g for this case, as against 3.93g for Case 1(b). The corresponding figures for most unfavorable maneuver and least unfavorable maneuver are 3.73g and 4.35g for the online DEPN-3D. These figures suggest that, when faced with an unanticipated B-t-B target maneuver, the PPN is more sensitive to the direction and magnitude of the maneuvers than the DEPN-3D, and having target maneuver information that is compensated from t0 itself like the APPN does, is either no advantage at all (Case1(b)), or a disadvantage (Case1(c), in a realistic scenario. The AAPN is seen to be less sensitive than the PPN, and more sensitive than DEPN-3D, as per this criterion. With its performance against PPN itself not being so favorable, the APPN is definitely a poor performer against the DEPN-3D laws, as per four out of the five criteria chosen for comparison, the exception being the maximum latax that is same for all laws.The logical conclusion is that, in a realistic scenario, a more intelligent law like the DEPN-3D law is needed for optimal performance, rather than a basic law like the APPN that merely nullifies target maneuver without any means of knowing whether doing so is beneficial or not.The performance of the laws for a step maneuvering target is studied next. By trying out all combinations as for the B-t-B maneuver cases, the most unfavorable step maneuver for the PPN law is determined to be a negative value of ayt, and a positive value for apt.The maximum magnitude for which all laws intercept for this case (Case 1(d) in Table 1) is found to be 0.39g, which is just more than a fourth of the 1.52g, the magnitude in the most unfavorable B-t-B case (Case 1(b)). This would suggest that the step maneuver is more effective than a B-t-B maneuver for the target. Examining the case in which the step maneuver actually favors interception by the PPN (Case 1(e)), the maximum maneuver magnitudes that allow interception are less than those for Case 1(b) or Case 1(c). This suggests that, at least for the high heading error scenarios considered in this paper, the step maneuver is more effective than the B-t-B maneuver from the target's point of view. Conversely, from the missile point of view, all the guidance laws including the DEPN-3D law are more robust to B-t-B maneuver than the step maneuver. The optimal APPN law performs marginally better than PPN law for Case1(d), since the compensation term in the latax includes an upward pitching component that proves beneficial later on. But in Case1(e), this compensation for downward maneuver makes the missile lose height initially, resulting in a performance that is poorer than even the PPN as per four out of the five criteria for comparison. The best two performers are the offline DEPN-3D and the online DEPN-3D for the step maneuver too. The missile–target trajectories for this case are shown in Fig. 8.The scenario of an approaching target, that arises more often in tactical missile guidance than that of a receding target, is considered next. The optimal solution for the AAPN of Sim et al. [39] has been obtained for the receding target, but it is still a better performer than the PPN even for the approaching target. Hence it is retained in this paper for comparison, as a useful benchmark. The nominal case of a non-maneuvering (ayt=apt=0),  approaching target flying exactly head-on to the missile initially (γt=0°, ϕt=180°) is considered, as in Raghunathan and Ghose [31]. The initial position of the missile is same as in the beginning of Section 5.2. The only change is the initial separation xt, which is assumed to be 9000m, instead of 3000m. The initial heading errors are assumed to be hp=−45°, hy=45°.The performance of all the laws are shown in Table 2and Fig. 9(a) and (b). In this case, the online DEPN-3D is a poorer performer than the AAPN by all the criteria, since it uses a slightly lower latax than the AAPN until t1 (Fig. 9(a)), and the flight time remaining after t1 is less, as compared to Cases 1(a)–(e). This does not allow it the scope to improve further. This is also seen in Fig. 9(b); the online DEPN-3D trajectory dips as low as that of the PPN, before rising somewhat to improve on the PPN. Between the two offline methods, the offline DEPN-3D is expectedly a much superior performer by four of the five criteria (tf, J, Vm(tf) and the max. aT0 up to which target capture occurs), since its design uses the same initial engagement geometry with the same realistic engagement model with which it is tested. Whereas, the AAPN was designed for tail chase condition, for a kinematic model. This superior performance is due to the much higher latax (equal to the saturation limita¯m) employed by the offline DEPN-3D from initial time t0 itself (Fig 9(a)).As with Case 1(b), the most unfavorable B-t-B target maneuver for the PPN law is determined by trial and error. For this case (Case 2(b)), the optimal APPN does not even intercept the target since, in a limiting case, it nullifies an initially beneficial target maneuver that could actually facilitate interception, disadvantaging itself by losing height in the process of doing so. This is reversed in Case 2(c), in which the missile guided by APPN gains height initially, and hence, achieves interception. For the remaining three laws, the pattern of results for the nominal case of 2(a) is repeated, with the performance ranking between these being offline DEPN-3D, AAPN, and online DEPN-3D, in descending order.The same pattern of results is repeated for step target maneuver, with the APPN in Case 2(e) being similar to Case 2(b) in failing to achieve interception, The logical explanations of why these happen are also similar Case 1(e): faced with an initial target maneuver that favors interception, the APPN nullifies this, since it has no means of knowing that the maneuver is actually a beneficial one. It expends extra energy in the process than the PPN, and hence is not able accomplish what the PPN does, for what are limiting values of target maneuvers for the PPN. Case 2(d) is somewhat like Case 2(c), in being able to achieve interception: the latax that includes the compensation term for enables it to rise in altitude initially. Between the remaining three laws, the offline DEPN-3D law is again the best performer like in the rest of the cases considered, followed by AAPN, and online DEPN-3D.In conclusion, the APPN does not have any edge over the PPN by virtue of its having the extra information of target maneuver. This edge would be available only if even more extra information of whether the maneuver is beneficial or otherwise is available for use. The DEPN-3D laws have this edge, and are naturally the best performers of the lot.

@&#CONCLUSIONS@&#
A completely new approach to optimal missile guidance, based on a 3-D realistic dynamic model, and using an evolutionary algorithm that is online implementable has been presented. By and large, the DEPN-3D laws designed by using this approach are shown to be best performers, and the most robust to target maneuver, in the overall analysis of all the laws studied in this work.A comparison of the proposed laws with the optimal APPN reveals that, in a realistic scenario, a more intelligent law like the DEPN-3D law is needed for optimal performance, rather than a basic law like the APPN that merely nullifies target maneuver with no means of knowing whether doing so is beneficial or not.Unlike the closed form optimal guidance laws that require time-to-go information, the DEPN-3D laws presented here does not require time-to-go information for its implementation.A detailed study of the effects of the variation in the tuning parameters of DE may be conducted as future investigation, for issues like speed of convergence and faster implementation.Given the fact that no optimization algorithm can work equally well on all classes of problems, it is felt that there exists considerable scope for studying whether there can be a better match between the optimization problem in the paper and the DE variant used to solve it. The problem can be studied for specific features that can be exploited for faster optimization by the state-of-the-art DEs that have appeared in the literature. Expanding the scope further, would be interesting to compare the performance of other metaheuristic methods against the results presented in this paper.