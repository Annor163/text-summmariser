@&#MAIN-TITLE@&#
An entropy-based query expansion approach for learning researchers’ dynamic information needs

@&#HIGHLIGHTS@&#
Proposing an entropy-based query expansion with a reweighting (E_QE) approach.The E_QE used to learn the researchers’ evolving information needs at different levels of topic change.Adopting a simulation pseudo-relevance feedback process to evaluate the proposed approach.The results show that the proposed E_QE approach can achieve better search results than the TFIDF.

@&#KEYPHRASES@&#
Query expansion,Pseudo-relevance feedback,Term weighting,Topic change,Entropy,

@&#ABSTRACT@&#
Literature survey is one of the most important steps in the process of academic research, allowing researchers to explore and understand topics. However, novice researchers without sufficient prior knowledge lack the skills to determine proper keywords for searching topics of choice. To tackle this problem, we propose an entropy-based query expansion with a reweighting (E_QE) approach to revise queries during the iterative retrieval process. We designed a series of experiments that consider the researcher’s changing information needs during task execution. Three topic change situations are considered in this work: minor, moderate and dramatic topic changes. The simulation-based pseudo-relevance feedback technique is applied during the search process to evaluate the effectiveness of the proposed approach without the intervention of human effort. We measured the effectiveness of the TFIDF and E_QE approaches for different types of topic change situations. The results show that the proposed E_QE approach achieves better search results than the TFIDF, helping researchers to revise queries. The results also confirm that the E_QE approach is effective when considering the relevant and irrelevant pages during the relevance feedback process at different levels of topic change.

@&#INTRODUCTION@&#
Information overload is a common problem faced by scholars. Search engine techniques urgently require the means to assist researchers in efficiently exploring and extracting useful information from the massive volumes of scientific data. Hence, search engines such as Google scholar, IEEE explore, and ACM digital library have been launched to support researchers’ information needs. Despite the fact that keywords may not describe researchers’ information needs, such search engines primarily rely on keyword matching techniques to determine which documents to return. However, novice researchers without sufficient prior knowledge often lack the skills to determine the proper keywords for investigating their topics. Therefore, a single search session cannot accurately fulfill the user’s information needs.The anomalous state of knowledge (ASK) hypothesizes posits that a searcher’s information needs arise from an anomaly in the state of knowledge, a gap between the searcher’s knowledge about a task and the perceived requirements of the task [5,6]. Generally speaking, the process of academic research can be divided into three stages: pre-focus, focus formulation, and post-focus [33]. Wu et al. [44] have conducted a small-scale empirical experimental study to confirm that incorporating the three task-stages into the search process model is a practical and effective means to enhance search results. However, previous studies did not present an automated approach to help researchers revise queries during the search process. In this work, we devise a query expansion technique that addresses researchers’ evolving information needs when retrieving articles at different stages of the research process.Query expansion (QE) techniques can be exploited to help researchers better formulate their queries. QE supplements the original query with additional keywords. The core of QE comprises two fundamental steps: the selection of keywords to expand and a re-weighting scheme applied to the keywords in the query. QE techniques can compensate for user inability to determine suitable keywords (i.e., short and simple queries) that express their information needs, improving the quality of the search results by overcoming these shortcomings through a query reformulation process [11].QE can be divided in two approaches: Automatic Query Expansion (AQE) and Interactive Query Expansion (IQE) [10]. AQE technique can achieve better performance when a user’s subject knowledge is high. In addition, it does not require users to evaluate the relevance of documents. In this work, we use the AQE technique to revise the user’s query during the relevance feedback process. For academic research, a proper QE should consider evolving information needs over the course of the process of academic research. For example, in the pre-focus stage, QE may include more synonyms of the query in order to broaden the scope of the survey, while a QE technique should eliminate keywords that deviate from the main direction of the research topic in the post-focus stage. Evolving information needs bring new challenges to QE techniques, including (1) how to automatically detect the evolution of information needs and (2) how to determine the keywords to be added, removed or reweighted. Accordingly, this paper has the following specific objectives:1.To devise a QE scheme that delivers researchers’ queries based on their information-seeking behaviors.To propose a QE technique with a reweighting approach that learns the evolving information needs of researchers through an entropy-based approach.To simulate the evolution of information needs by changing from broader research subjects to a focused subject. The proposed framework is evaluated through this simulation.Consequently, we propose an entropy-based query expansion with a reweighting (E_QE) approach that can consider the level of change in the researchers’ topics and learn their information needs effectively. We will evaluate whether the proposed E_QE approach can be incorporated into the relevance feedback process to design a better search system for academic researchers based on their problem stages.The word mismatch problem is one of the most important and fundamental issues of information retrieval (IR) research [20]. That is, users and authors may use different words to describe the same concepts. Thus, it is hard to match queries with documents to retrieve the relevant documents. Global and local document analysis methods have been proposed to tackle this problem [47]. Query expansion (QE) is a global analysis method that can build a new query from the original one by adding synonyms, conceptually related terms, or semantically related terms, [9,20]. Relevance feedback technique (RF) is a local analysis method that adjusts a query relative to the documents that are retrieved in the initial query. The concept of the RF is that once the users have made their initial queries, the system will examine relevant and irrelevant documents guided by the RF technique to modify the original query to be the next query [22,41]. Both QE and RF techniques can compensate for users’ inability to input suitable keywords (i.e., short and simple queries) that express their information needs, improving the quality of the search results by overcoming these shortcomings through a query reformulation process [10,34].Query expansion can be divided in two methods: Automatic Query Expansion (AQE) and Interactive Query Expansion (IQE) [1,11,34]. We can understand IQE as a half-automatic query expansion that requires users to manually evaluate the relevance of document sets and return feedback to the system before the system will modify the initial query according to the feedback. Users can keep interacting with the system until they are satisfied with the retrieval results or their information needs are met. The advantage of IQE is that users can give feedback directly to the system [3]. Since it requires time and effort for users to evaluate the relevance of the returned document sets. IQE will be most effective if a user’s subject knowledge is low and the search topic is complex [34]. However, with increasing subject knowledge, more specific query terms can be used and users will be more able to differentiate between relevant and irrelevant information. When a user’s subject knowledge is high, AQE technique is more effective. In addition, it does not require users to evaluate the relevance of documents. Therefore, QE techniques can be categorized into four types [21]: (1) use of co-occurrence data, (2) use of document classification, (3) use of syntactic context and (4) use of relevance feedback technique.Relevance feedback (RF) improves the search effectiveness of the automatic query reformulation process [25,26]. The literature on information retrieval shows that relevance feedback applied in a vector model is an effective technique in a retrieval environment [25,27]. Compare to the traditional approach in which users need to determine the query for their own for information retrieval, there are three major advantages of RF:•Users do not need to reformulate the query on their own. They only need to evaluate the documents that can modify and reformulate users’ query.RF takes every search as a process of the whole search task, not a single search result. Thus, the search results are more precise after one or more iterations.RF treats search as a controlled process, allowing users to evaluate the relevant and irrelevant documents.The classic relevance feedback method proposed by Rocchio [26] and theIde_Dec_Hi (1971) method, which use a vector space model to derive the modified queryq→m, are formulated in Eqs. (1) and (2) respectively [4].(1)Standard-Rocchio:q→m=αq→+β1|Dr|∑∀d→j∈Drd→j-γ1|Dn|∑∀d→j∈Dnd→j(2)Ide-Dec-Hi:q→m=αq→+β∑∀d→j∈Drd→j-γmaxnon-relevant(d→j)where Dris the set of relevant documents and Dnis the set of not relevant documents, both of which are determined by the user; |Dr| and |Dn| denote the number of documents in the sets Drand D, respectively; and α,β,γ are tuning constants. In Eq. (2),maxnon-relevant(d→j)denotes the highest non-relevant document. The two methods yield similar results [4]. The Rocchio method sets α=1, Ide sets α=β=γ=1, and Harman (1992) sets β=0.75,γ=0.25. Salton and Buckley (1990) showed that the Ide_Dec_Hi algorithm performs slightly better than the Rocchio algorithm.Generally, there are two approaches to the RF process. The first reweights terms based on the distribution of the terms in the relevant and irrelevant documents. The second involves adding or removing terms in the course of the query expansion process. The latter approach can more efficiently improve retrieval performance because the adjustment of terms can change the search results more significantly than by adjusting the weights of the original terms. These two approaches suggest three different kinds of RF techniques: (1) query expansion without term reweighting; (2) term reweighting without query expansion; and (3) query expansion with term reweighting. Each can be applied in different systems for different needs. In this work, we will adopt the third approach to RF processing in support of final QE.To date, researchers in the field of Information Retrieval (IR) have focused on representations of documents for the retrieval of project-relevant information, search strategies, and assessing the relevance of retrieved documents. Comparatively little attention has been paid to users’ information needs and how to support their search activities. Information Seeking (IS) involves searching for and using information for a task when the user does not have sufficient prior knowledge. Several empirical studies have observed and analyzed users’ successive searches and connected them to the task complexities, relevance judgments, and situations of the subjects during the IS process [5–7,18,30,35,38,39]. Saracevic [28] proposes the broadest sense of IR, under which it is important to simultaneously consider messages for decisions, cognitive processing, and the context of search. Accordingly, the concept of the integration of user-oriented and system-oriented IR research is considered in IR. Recently, however, user-oriented Information Seeking (IS) research methods rooted in the social sciences have been integrated with computer science-based Information Retrieval (IR) approaches to capitalize on the strengths of both fields. This concept is called the Information Seeking and Retrieval (IS&R) framework. The IS&R framework provides a useful background for understanding the evolution of the IIR system and its evaluation approaches [13,17].Kuhlthau’s search process model (1993) divides a task into six stages with their associated characteristics. It describes the information search process from the three perspectives which are thoughts, feelings, and actions as being experienced in six stages. The objective is to observe how users locate and interpret information to form a perspective on a topic. During the search process, thoughts evolve from unclear and vague to clear, more focused understanding. The actions taken in the search process also change with the formulation of the focus.Vakkari [32] analyzed the evolution of theories of the information seeking process and task complexity. Vakkari et al. [35] concentrated on a user’s information seeking activities during the execution of a task (such as writing a proposal or completing a project). Vakkari et al., following Kuhlthau’s search process model (1993), divided information seeking activities into three stages: the pre-focus, focus-forming and post-focus stages [35]. Vakkari’s task-oriented IS study is also based on studies of search strategies and tactics [46] and the study of term choices [37]. These empirical studies reveal that users’ information needs vary across different task stages. For example, the types of information needs may vary from general to specific information, and the choice of search terms may vary from broader terms to related or specific terms. That is, a worker’s information needs and information-seeking process depends on their progress in the task performance, or task stages.Byström and Järvelin’s information seeking surface model (1995) explicates the dependencies between task complexity, information needs and information sources via a qualitative empirical study. The authors model information seeking as a process that involves needs analysis, choices of actions, implementation of actions, and evaluations. The model is based on the assumption that personal factors (e.g., attitude, mood, motivation), situational factors (e.g., available time) and the perceived category of the task (e.g., genuine task, normal decision task, normal information processing task) influence the information seeking process. Note that Byström–Järvelin’s model is a static model that relates abstract concepts, i.e., the task’s complexity and the types of information needed. It does not model the search process explicitly [13].Wang and Soergel [38] and Wang and White [39] proposed cognitive models of document usage during research projects conducted in 1992 and 1995, respectively. The results show that, during a research project, document usage is a decision-making process in which decisions are made at three points or stages: selecting, reading, and citing. The above studies contribute to research on the applications of intelligent information retrieval systems, and enhance the use of knowledge retrieval functions to support task execution by professionals. They also offer a comprehensive understanding of human judgment and decision-making during the search process.The above studies also focus on observing users’ search behavior and provide useful suggestions for the design of effective search systems based on the IS&R models. Our objective is to provide an effective means of information search in professional task contexts.The information retrieval (IR) field has evolved rapidly over the past decade, and the Internet is one of the biggest forces driving the development of search engine tools for helping people retrieve information [8]. In many cases, users may only have a general idea about a topic and convert their thoughts into a very short query. After analyzing logs of queries on the Web, Jansen et al. [16] found that the average query length is 2.21 keywords and that less than 4 percent of the queries exceed six terms. Users without sufficient prior knowledge lack the skills to determine proper keywords for their topics. Therefore, a single search session cannot accurately reflect the user’s information needs. To tackle the problem we propose an entropy-based query expansion with a reweighting approach to revise the queries during the iterative retrieval process.Kuhlthau [18], Vakkari [32], and Wu et al. [44] showed that users’ information needs and search behavior patterns vary across different stages of the search process. Researchers believe that making a system aware of a searcher’s information seeking stage and tailoring the results to each stage has the potential to improve the search experiences [2]. Thus, we designed a series of experiments that considers the users’ changing degree of information needs by controlling the changes of topics in the proposed topic ontology. The pseudo-relevance feedback technique is adopted during the search process to evaluate the effectiveness of the proposed approach without the intervention of human efforts. The research problems are summarized below.•Comparing the relative performance of the proposed entropy-based query expansion and reweighting approach with the basic TF-IDF term weighting approach.Adopting a simulation-based pseudo-relevance feedback process to investigate the effectiveness of the proposed approach under different levels of change in the research topic.Investigating the influence of proportions of relevant and irrelevant pages for query expansion under the level of change in the research topic.Fig. 1shows the research framework. There are three main modules: a search module, a relevance feedback module, and a query expansion module.First, we simulate a researcher’s information needs for the assigned task. We test dramatic, moderate, and minor changes in the subject to investigate the effectiveness of the proposed approach. To search web pages, the search function of the system developed connections to Google’s AJAX search API, a JavaScript library that allows users to embed Google Search in applications or web pages. For academic searches, the system retrieves relevant academic articles from journals and conference proceedings from the Citeseer web site.As motioned earlier, a simulation-based pseudo-relevance feedback process was designed as a component of this work. The pseudo-relevance feedback process relies on a topic ontology to determine the relevancy of the returned pages. Notably, our research topic ontology (Fig. 2) is constructed based on our previous work [45]. Generally, users will not read all of the pages retrieved and thus we only consider three pages, or 30 search results, in evaluating a given document as relevant or irrelevant [16]. To determine the degree of relevance between the retrieved pages and the researcher’s information needs (topic), the module will calculate the similarity between the pages and the topics, categorizing the retrieved pages into different levels of relevance based on their similarity values. We will detail this process in Section 5.1. A researcher simulator within the RF module is designed to simulate researchers’ behavior during the search process. Basically, the researcher simulator randomly picks a topic from the topic ontology as the initial concept.The aim of this module is to revise the original query set based on the results of the simulation-based pseudo-relevance feedback process each time it is run. We adopt Discounted Cumulated Gain (DCG) measures [15]. The DCG measure evaluates an IR method’s ability to retrieve highly relevant documents as a ranked list.The overall framework of the associated search process is illustrated in Fig. 1. There are three main modules: a web search module, a relevance feedback module, and a query expansion module, as introduced earlier. First, we simulate a researcher’s information needs for the assigned task. To search web pages, the search function of the system developed connections to Google’s AJAX search API. Furthermore, a simulation-based pseudo-relevance feedback process was designed as a component of this work. The pseudo-relevance feedback process relies on a topic ontology to determine the relevancy of the returned pages. A researcher simulator (RS) within the RF module is designed to simulate researchers’ behavior during the search process. Basically, the RS randomly picks a topic from the topic ontology as the initial concept. Finally, the aim of automatic QE module is to revise the original query set based on the results of the simulation process each time it is run.We generated a domain topic ontology, which is adopted to evaluate the degree of relevance relating retrieved articles to topics. The proposed topic ontology is a simple hierarchical taxonomy that is structured into three levels: fields (broader topics), tasks (specific topics), and documents. A specific topic is also referred to as a task topic. Each topic has an associated corpus that is extracted from a set of task-related documents [44,45]. The topic ontology is used to organize documents around specific research domains ([31,36,45]). As mentioned earlier, an RS in the pseudo-relevance feedback module is designed to simulate the behavior of researchers during the search process. The simulator carried out two tasks: automatically determining whether a document is relevant or irrelevant, and simulating topic change behavior during the search process. The domain topic ontology is used to determine whether a document is relevant. To determine the degree of relevance between the retrieved pages and the researcher’s information needs (topic), the RS will calculate the similarity between the retrieved documents and the corpus of the topic, categorizing the retrieved pages into different relevance degree levels based on their similarity values. We calculated the similarity between the page and the topic by measuring the cosine. The similarity measure is shown in Eq. (3). Furthermore, the system can activate the following pseudo-relevance feedback process.(3)sim(page→,topic→)=page→•topic→|page→|×|topic→|,where→pageis the content of the retrieved article (feature vector of weighted terms), and→topicis the corpus of the topic. We calculated the similarity between the article and the topic by measuring the cosine. We will determine the degree of relevance based on the similarity value which will be introduced in Section 5.4.The well-known TFIDF approach often used for term (keyword) weighting assumes that terms with a higher frequency in one document and a lower frequency in another document are better discriminators for representing the first document [27]. In this work, we present an entropy-based query expansion with a reweighting (E_QE) approach according to the basic concept of the TFIDF approach. Basically, entropy can be used as a feature selection measure for selecting the best feature to discriminate or split data. The main purpose of entropy is to count the average amount of information needed to identify the class label of a training example in the data set. This is mainly based on Claude Shannon’s information theory [29]. The basic equation is listed below.(4)E(Ex,attrj)=-∑i=1npilog2(pi),where piis the probability that an attribute, attrj, is used to classify EX, a set of training examples belonging to classci and is estimated by |Ci,EX|/|EX|. E(Ex, attrj) is also the entropy of Ex. Following this idea, the E_QE approach considers the distribution of a term as it appears in relevant and irrelevant documents to arrive at the discrimination value of the term. In addition, term frequency is also considered, as explained in the entropy-based term weighting approach. Specifically, during the relevance feedback (RF) iteration, if the term always appears in the set of relevant documents, it will have higher discrimination value. Here we consider the proportion of the term’s appearance in relevant and irrelevant documents and calculate the entropy values as shown respectively in (5) and (6). GRindicates the amount of information in the relevant documents, whereasGRNindicates the amount of information in irrelevant ones.(5)GR=-RORlog2ROR-RqRlog2RqR,ROR>121,ROR⩽12(6)GRN=-RNORNlog2RNORN-RNqRNlog2RNqRN,RNORN<121,RNORN⩾12In Eq. (5), R is the number of relevant documents, and RNis the number of irrelevant documents. Ro denotes the number of relevant documents that include a specific term, and Rq denotes the number of irrelevant documents that do not include a specific term. Similarly, RNodenotes the number of irrelevant documents that include a specific term, and RNqdenotes the number irrelevant documents that do not include a specific term. A key characteristic of entropy is that it can estimate the distribution of the examples. Thus, if a term appears in the relevant document 25 times, the entropy value will be the same as if the term appears in the relevant document 75 times. To resolve this problem, we set restrictions in Eqs. (5) and (6). That is, we setRoR>12in (5) to ensure the selection of the term that appears in most of the documents of the relevant document set. In addition, we setRNoRN<12in (6) to ensure that the term does not appear in most of the documents of the irrelevant document set. The discrimination of a term is formulated in the following equation:(7)TGi=1-GR+GRN2,TGimeans the discrimination value for the term i, and the value is between zero and one. Eq. (7) is a normalization process for Eqs. (5) and (6). For example, if a relevant term, i, appears fewer than or equal to half of relevant documents, the value ofGRwill be one. Similarly, if the relevant term, i, also appears in more than or equal to half of irrelevant documents, the value of GRNwill also be one. Based on the Eq. (7), the TGivalue will be zero, which means the term, i, will not be selected due to that fact that it may either belong to the term set of irreverent documents or has a low discrimination value. In addition to considering the discrimination value of each term, we also integrate the frequency of each term in a relevant document. Consequently, the entropy-based term weighting approach is shown in (8). Note thatfiis the term frequency component.(8)TF_TGi=fi×1-GR+GRN2For Eq. (8), the idea is similar to a classic TFIDF term weighting approach [27]. The two factors, the discrimination value and the term frequency, are considered important in most of the term weighting approaches in information retrieval models, e.g., vector space and probabilities models [20].

@&#CONCLUSIONS@&#
Classical RF techniques are designed to revise queries based on the user’s feedback on items without considering the degree of change in information needs. Accordingly, in this work, we considered different numbers of irrelevant documents for minor, moderate, and dramatic changes in the user’s level of interest in a topic. The results confirm that applying the proposed E_QE approach is much better than the traditionalTFIDF term weighting approach. We summarized the performance of each method and suggest the best strategy for query expansion and reweighting under different types of topic changes situations, as shown in Table 8. In addition, we summarize the implications of the preliminary results of this study below.1.We propose an effective approach to learning the user’s information needs depending on the degree of change in a user’s topic of interest. Classical relevance feedback techniques do not consider the user’s dynamic information needs. Thus, well known algorithms such as the Rocchio [26] and Ide [12] methods are designed to revise queries based on the user’s feedback on items without considering any degree of change in information needs. However, users’ information needs, often vague initially, evolve during the search process. Accordingly, minor, major, and dramatic change situations are considered in the proposed approach. The experimental results confirm that the proposed E_QE approach is more effective than the traditional TFIDF term weighting approach.We propose an effective approach to learn the user’s short-term and long-term information needs. A single search session cannot accurately reflect changes in the user’s information needs during the problem-solving process. Information seeking (IS) involves searching for, extracting, and using information for a specific purpose when a person does not have sufficient prior knowledge. IR can be regarded as a process of IS, meaning that the latter may include one or more information retrieval activities [13,35,43,42]. Therefore, we conducted a simulation-based pseudo-relevance feedback process executed in eleven rounds to verify the learning capabilities of each method. The results show that it is important to consider different numbers of irrelevant documents depending on the degree of change in a user’s topic of interest for learning short- or long-term information needs. We summarized the results in Table 8. For minor topic changes, the E_QE(10-5) achieves the best performance for learning both short-term and long-term information needs. For moderate topic changes, the E_QE(10-10) achieves the best performance for learning short-term information needs. However, there is no single method that ensures the best result for learning long-term information needs when the change in topic is moderate. Based on our preliminary observations, the similarity between the query and search results may influence the results. For a dramatic change in topics, the E_QE(10-10) achieves the best performance for learning short-term information needs, while the E_QE(10-20) achieves the best performance for learning long-term information needsWe will implement the approach in an interactive information retrieval situation that allowed for interactive query expansion (IQE). Accordingly, we adopted the DCG method instead of the traditional precision and recall method to evaluate the performance of each approach. However, the results reveal that the performance of each topic is influenced by the degree of relevance to the target set. Thus, we will adopt normalized discounted cumulated gain (nDCG) metrics instead of DCG to overcome this problem and allow thorough comparisons across topics [14,15].Several issues need to be investigated further. First, the results appear to show that the learning performance for differing degrees of change in topic needs is influenced by the degree of relevance to the search results (similarity between the topic and the search results). We will explore the issue of setting a strict threshold in Eqs. (5) and (6) of the proposed E_QE approach for increasing DCG values. That is, we will investigate whether adjusting the number of selection terms by varying the threshold influences the search results. Thus, we will investigate our findings by modifying the proposed approach in future work. Second, the proposed simulation-based pseudo-relevance feedback process relies on topic ontology to determine the relevancy of the returned pages. Accordingly, we will explore the ontology representation and data matching issues in formally describing the information semantics and modeling the user’s informational needs precisely [36]. Third, we will compare the proposed approach with the BM25 weighting scheme and the language model ([23,24]) for demonstrating the effectiveness of the proposed approach. Large scale experiments using an official dataset, TREC, will be considered in future work. Fourth, the experimental results show that no single method ensures better retrieval performance for learning moderate changes of information needs in the long run. We look forward to exploring this issue in the future. In our previous work [44], we took two years to evaluate the effectiveness of the proposed task-stage knowledge support model. Finally, an automatic task-stage identification technique is proposed and implemented for providing effective document support throughout the execution of a task. In our future work, we may incorporate a reweighting (E_QE) approach with the task-stage identification technique into the proposed entropy-based query expansion to support precise interactive document search activities for academic research.