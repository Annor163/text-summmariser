@&#MAIN-TITLE@&#
Nonlinear interactive source-filter models for speech

@&#HIGHLIGHTS@&#
We propose two interactive source-filter models, ISFMs, for speech production.ISFMs have the capability of producing fine details of glottal flow.A parameter estimation method is developed for determining the model parameters.The algorithm yields ISFMs performing better than linear source-filter model.

@&#KEYPHRASES@&#
Speech production,Source-filter theory,Source-filter interaction,Speech modeling,

@&#ABSTRACT@&#
The linear source-filter model of speech production assumes that the source of the speech sounds is independent of the filter. However, acoustic simulations based on the physical speech production models show that when the fundamental frequency of the source harmonics approaches the first formant of the vocal tract filter, the filter has significant effects on the source due to the nonlinear coupling between them. In this study, two interactive system models are proposed under the quasi steady Bernoulli flow and linear vocal tract assumptions. An algorithm is developed to estimate the model parameters. Glottal flow and the linear vocal tract parameters are found by conventional methods. Rosenberg model is used to synthesize the glottal waveform. A recursive optimization method is proposed to find the parameters of the interactive model. Finally, glottal flow produced by the nonlinear interactive system is computed. The experimental results show that the interactive system model produces fine details of glottal flow source accurately.

@&#INTRODUCTION@&#
The human speech production system involves lungs, trachea, vocal cords, pharynx, oral tract, nasal tract, tongue and lips. The brain controls the production process, while other organs form the time-varying aerodynamic and acoustic subsystems. Based on the physics of speech production, the aerodynamic and acoustic subsystems are the basis of current articulatory speech synthesizers which mimic the human vocal system.The aerodynamic part of the speech production system involves the interaction of airflow and tissue structure of vocal folds. To investigate the interaction effects on the vibration of vocal folds, the Navier–Stokes nonlinear differential equations need to be solved on the complex soft tissue structure of the vocal folds with a set of appropriate boundary conditions (Alipour et al., 2000; Jungsoo and Frankel, 2007, 2008; Zheng et al., 2009). Due to the high complexity of vocal fold tissue dynamics and high time consumption of finite element based methods, instead of using numerical simulation, excised canine vocal folds or kinematic solid physical models of vocal folds have been used to investigate the aerodynamic system (Alipour and Scherer, 1995, 2006; Khosia et al., 2007, 2008). For articulatory speech synthesis, the aerodynamic system is generally modeled by the combination of a bio-mechanical structure that models tissue elasticity and an airflow model. These models work based on the myoelastic aerodynamic theory of phonation (Van den Berg, 1958; Titze, 2006a). They can be classified as low dimensional, such as one mass, two mass, sixteen mass etc, and high dimensional models like point mass models. Their inputs are lung pressure, elasticity, mass and friction of vocal folds, and the output is the glottal area. In addition to these input variables, acoustic loading of vocal tract or supraglottal input pressure can also be used as an input to the aerodynamic system so that the acoustic–aerodynamic interaction can also be taken into account (Zanartu et al., 2007).The acoustical part of the speech production system represents the transmission and radiation of sound generated by the vocal folds or by a turbulence at a constriction in the vocal tract. It is usually assumed that the sound propagation is one dimensional and linear except at the glottis and constrictions where nonlinear effects cannot be neglected (Sondhi and Schroeter, 1999). In the articulatory synthesizers, the vocal tract and trachea are considered as a concatenation of uniform tubes with either equal or different lengths depending on the acoustic simulation type. Since, in linear acoustics, sound propagation in a tube depends on the cross-sectional area and the length, in order to simulate the acoustics in the vocal tract, these parameters are calculated from 3D MRI images of the vocal tract. Therefore, the inputs of acoustic subsystem are pressure or flow sources, cross-sectional areas and tube lengths and its output is acoustic pressure distribution in the vocal tract and radiated speech pressure wave.Most of the current articulatory speech synthesis methods rely on two assumptions, quasi-steady flow at the glottis and linear vocal tract. Simulations based on these assumptions show that glottal flow is affected by the vocal tract acoustic loading if the vocal tract impedance is comparable to the acoustic glottis impedance; in other words, supraglottal pressure is comparable to subglottal pressure (Ananthapadmanabha and Fant, 1982; Titze, 2006a). Studies (Ishizaka and Flanagan, 1972; Ananthapadmanabha and Fant, 1982; Titze, 1984, 2008) showed two major effects of this interaction; superimposed ripple on the glottal flow and skewness of the glottal flow with respect to glottal area. These are called as level-I effects by Titze (2008).Despite the fact that the research on the physics of speech production has been continuing for a considerable amount of time, the acquired knowledge has not been utilized extensively in the development of speech signal models. The linear source-filter model has been used dominantly for about half a century. It is applied in many speech related applications ranging from speech synthesis to speaker recognition. On the other hand, it is a quite simplified approximation of the speech production system. It assumes that glottal flow is independent from vocal tract acoustics. However, this assumption is good only for low pitch male speech (Titze, 2008). The simulations of physical speech production models show that glottal flow waveform is significantly affected by the vocal tract acoustics when the fundamental frequency (F0) of the glottal flow approaches the first formant (F1) of vocal tract. (It is illustrated in Section 2.) For example, these effects might be important especially in emotional speech synthesis due to the fact that depending on the emotional state of the speaker, the fundamental frequency (F0) of voice source can increase (or decrease) while F1 is fixed or even decreases. The physical simulation results suggest that if the fundamental frequency of a speech signal is to be altered, the changes in the glottal flow waveform due to the interaction between the source and the filter should be considered. This knowledge obtained from the physical simulations is not used in fundamental frequency modification methods. It might be one of the reasons why the perceived quality of modified speech decreases when using TD-PSOLA (Bulut and Narayanan, 2008). An interactive source-filter model can make it possible to use this information in speech processing applications.The aim of this study is, based on the existing knowledge of the physics of speech production, to develop an interactive source-filter model that takes the level-I effects of nonlinear interaction of the source and the filter into account. In particular, a way of combining the glottal nonlinearity to the linear model of vocal tract, to produce the glottal flow, is introduced. The proposed nonlinear interactive source-filter model is based on the quasi-steady glottal flow and linear vocal tract assumptions. It is an extension of the linear source-filter model with a capability of producing level-I interaction effects. We show that the proposed nonlinear model can be used in either interactive or non-interactive mode by using a control parameter.The parameters of the interactive system can be estimated by solving a combination of nonlinear blind estimation and parameter optimization problems. We propose a parameter estimation algorithm that yields a stable nonlinear interactive system model, which always performs better than the classical linear model.The literature on source-filter interaction is dominated by the simulation of the speech production system by using the directly measured physical quantities like vocal tract areas and mechanical parameters of vocal folds. The glottal flow waveforms produced by the proposed models are investigated. In this work, a nonlinear discrete-time system model is developed to solve the inverse problem, i.e., estimation of glottal flow from speech. The estimate is evaluated by comparing the estimated glottal flow to that obtained by linear inverse filtering.The rest of this article begins by a review of the source-filter interaction in voiced speech in Section 2. The dependence of the glottal flow on the vocal tract shape and vocal fold vibration frequency (F0) is demonstrated by using simple vocal fold and vocal tract models. Section 3 describes the assumptions on the source-filter model. Section 4 introduces the proposed interactive source-filter model (ISFM). An extended interactive model that takes subglottal loading into consideration is described in Section 4. In Section 5, a parameter estimation algorithm for the interactive model is proposed and, in Section 6, it is applied on a short speech segment. In Section 6, proposed interactive and classic noninteractive source-filter models are compared on a large speech database using Rosenberg+ source model. The Rosenberg+ glottal flow model is extended to an interactive source model that has the capability of producing fine details of glottal flow waveform. The interactive Rosenberg+ model is compared to the non-interactive Rosenberg+ model on the glottal flow estimates obtained from closed phase analysis of a large speech database. Finally, Section 7 provides a conclusion for the study.Nonlinear source-filter interaction has been studied by simulation, using acoustic and/or biomechanical models of vocal system. Due to the nonlinearity of the glottal impedance it can be simulated in time domain (Story, 1995). The one mass and the two mass models of Ishizaka and Flanagan (1972) are among the first models that take into account the source-filter interaction. They solved the transmission line circuit analog (Fant, 1960; Flanagan, 1965; Ananthapadmanabha and Fant, 1982; Birkholz et al., 2007) of vocal system by the finite difference method. Their results demonstrate the acoustic interaction effects, skewness of glottal flow and superimposed ripple on it.Rothenberg (1981) studied the acoustic interaction between the glottal source and vocal tract with a simple impedance based model of vocal tract linearly coupled to the time-varying glottal impedance. The results show that the interaction effects are noticeable when the glottal impedance is comparable to the vocal tract input impedance. In particular, the vocal tract inertia is responsible for skewness of glottal flow with respect to the glottal area while the vocal tract resistance changes the amplitude of the glottal flow waveform.Ananthapadmanabha and Fant (1982) used lumped approximation of vocal tract, trachea and glottis in order to investigate the effects of nonlinear interaction on the glottal flow for different vowels. They use various configurations for the coupling of the vocal tract and trachea and solve the nonlinear system of equations by an iterative algorithm. It is concluded that the waveform of the interactive glottal flow is different for different vowels and depends more on the vocal tract resonances than subglottal resonances. They also proposed a model that approximates the nonlinear source filter coupling by varying vocal tract formants and their bandwidths in accordance with the variation of glottal area in time.In the hybrid time-frequency articulatory speech synthesis method, Sondhi and Schroeter (1987) used a different approach. The impulse response at the input of the vocal tract is found from the frequency response obtained from vocal tract areas (subglottal part is neglected) and then it is combined with the vocal fold acoustics. However, they report that the impulse response of vocal tract is very long and it is not always possible to calculate the interactive glottal flow. Hence, they follow another approach using the input reflectance of the vocal tract (frequency domain representation of reflection coefficients) similar to that in the wave-reflection method.Liljencrants (1985), Titze (1984, 2002, 2004, 2006b, 2008), Titze and Story (1997), Story (1995) and Zanartu et al. (2007) used the wave-reflection method which works based on particle flow and pressure variations along the subglottal, supraglottal tract and glottis. For the coupling at the glottis, Titze proposed a mathematical model based on the quasi steady Bernoulli flow assumption. It is essentially the glottal flow equation used in other approaches (Titze, 1984; Ananthapadmanabha and Fant, 1982), however it represents the glottal flow in terms of particle velocity (instead of volume velocity).The simulation of the interactive system model via wave-reflection method is a time-domain approach. The calculation of the parameter values is easy, and, in particular, the frequency dependent losses of the vocal tract are calculated recursively. It is considered to be a more convenient approach compared to other methods (Kelly and Lochbaum, 1962; Liljencrants, 1985; Story, 1995; Mathur et al., 2006; Zanartu et al., 2007).Titze and Story investigated not only the acoustic interaction but also the aerodynamic interaction of the coupling on more complicated models (Titze, 1984, 2002, 2004; Story and Titze, 1995; Titze and Story, 1997). They show that vocal tract affects the vibration pattern of vocal folds. Zanartu investigates the acoustic loading effect of both vocal tract and trachea on a single mass model of the vocal folds under a quasi Bernoulli flow assumption at the glottis (Zanartu et al., 2007). It is shown that the acoustic loading of vocal tract is dominant against that of trachea in maintaining self-sustained oscillations of vocal folds. Titze has recently introduced a theory of nonlinear source filter coupling (Titze, 2008). It is based on the assumptions of linear vocal tract and a quasi-steady Bernoulli glottal flow. Two levels of interaction effects are demonstrated. The level-I interaction seen in normal speaking consists of the skewness and the ripple on the glottal flow for F0<F1 and the level-II interaction involves instabilities in the vibration pattern of vocal folds when F0 crosses over the formant frequencies. Titze et al. (2008) demonstrate the level-II effects in human voice by varying F0.Howe and McGowan (2012) present a theory of source filter coupling based on aeroacoustic theory. Their model also demonstrates the effects of level-I interaction.In this work, we focus on the level-I interaction observed in normal speaking conditions.In this section, the dependence of glottal flow waveform on vocal tract in two different formant vowel cases, high F1 vowel /a/ and low F1 vowel /i/, for a wide F0 frequency range is demonstrated by using a parametric glottal area model. The vocal system is simulated by the wave reflection method described in Story (1995) and Zanartu et al. (2007) using the areas extracted from 3D MR images provided by Story (1995) and parametric glottal area model proposed by Ananthapadmanabha and Fant (1982) given by(1)ag[n]=A0.5−0.5cosπ2NOn,0<n≤NOAcosπ2NCn,n≤N0−1where A, NOand NCare the peak value of the glottal area, the open phase duration and the closing phase duration, respectively. Particularly, we used the same glottal flow expression obtained by Titze (1984, 2008) based on the quasi-steady Bernoulli flow assumption. It is also equivalent to the interactive glottal flow equation of a single mass system in terms of volume velocity that was used by Fant for the calculation of true glottal flow (Ananthapadmanabha and Fant, 1982).The source-filter interaction depends on the vocal tract input impedance (Rothenberg, 1981; Ananthapadmanabha and Fant, 1982; Titze, 2008). Considering the speech production system, there are mainly two different acoustic cavities, the vocal tract, above the glottis, and trachea, below the glottis. Since the vocal tract has much smaller crossectional area with respect to subglottal tract, its reactance is much larger than the subglottal reactance. Hence, the reactance of the overall system is slightly different than the vocal tract reactance. The impedance relating the glottal flow to the transglottal pressure across the glottis is the sum of the subglottal and supraglottal impedances (Titze, 2008).The vocal tract impedance of vowel /a/ calculated by the impulse response technique using the wave reflection method is plotted in Fig. 1. The magnitude and resistance curves have peaks at resonance frequencies at which the reactance curve has its zeros. It is seen in the figure that the vocal tract input impedance is inertive for frequencies below F1, approximately 0.8kHz, and between 1.1 and 1.2kHz while compliant in the frequency intervals 0.8–1.1kHz and 1.2–1.7kHz.The vocal system is simulated by using constant lung pressure, PL=0.8kPa and the maximum glottal area A=0.15cm2. Since subglottal tract is not used in the simulation, the subglottal pressure, psub, is set to the lung pressure, PL. The glottal area and glottal flow waveforms normalized in time and amplitude obtained for F0 frequencies equally spaced by 40Hz between 80 and 240Hz are plotted in Fig. 2. It is seen from the figure that the glottal flow is skewed to the right with respect to glottal area. This is the first effect of level-I interaction. This behaviour is due to the inertive vocal tract reactance. It increases the spectral slope of the source harmonic peaks. The second effect of level-I interaction is the ripple on the glottal flow waveforms. The interaction ripples can be easily seen in the glottal flow waveforms in Fig. 2(c)–(e). The intensity of the ripples increases as F0 is increased. On the other hand, the frequencies of the ripples are not the same in each case. They result from the variations in the magnitudes of the glottal flow harmonics. The magnitude of each harmonic in the source spectrum is mainly determined by the vocal tract input impedance. The discussion on the cause and effect of the interaction ripple requires both spectral and time domain investigation of the simulated glottal waveforms and output speech signal.The vocal tract impedance of vowel /i/ calculated by the wave-reflection method is shown in Fig. 3. In this case, the first formant, (F1), calculated approximately as 200Hz, is smaller and closer to F0 frequencies used in the simulation. For fundamental frequencies between 80 and 240Hz, the simulations are conducted for /i/ and the resulting glottal flow waveforms are plotted in Fig. 4. As expected, the skewness and ripple effects are observed in each case. However, an important difference between the flow waveforms of F0<F1 (Fig. 4(a)–(c)) and F0>F1 (Fig. 4(e)) is that the former waveforms are skewed to the right while the latter is skewed to the left. This is due to the first source harmonic, when F0=240Hz is inside the negative reactance region (compliant reactance) of vocal tract input impedance of /i/. Furthermore, the size of the interaction ripple is much larger than the ripple seen in the case of /a/. The reason for the large ripple is that the vocal tract impedance has a much stronger effect on the individual harmonic magnitudes compared to that in the case of vowel /a/.The glottal source waveform strongly depends on the vocal tract shape. It is due to the loading effect of the vocal tract on the glottis (Titze, 2008). The following statements summarize the salient aspects of the source-filter interaction;1.There are two major effects of the source-filter interaction on the source, skewness of glottal flow and ripple on the glottal flow (level-I interaction).Glottal flow is affected by the vocal tract input reactance. Positive reactance increases the skewing of glottal flow to the right and increase the energy level of corresponding harmonics (Rothenberg, 1981; Titze, 2008).The vocal tract input reactance is always positive for frequencies below F1. During speech activity, most of the time, the frequencies of source harmonics having the largest energy values are in inertive reactance interval. As a result, the glottal flow is skewed to the right (Titze, 2008). The reactance usually increases up to the first vocal tract formant, F1, except some small variations around the subglottal formants. It may be concluded that for frequencies below F1, increasing F0 increases vocal tract input reactance so that skewness is increased.The resistive part of vocal tract input impedance affects the peak value of the flow. Increasing resistance decreases the amplitude of the glottal flow (Rothenberg, 1981; Titze, 2008). The resistance increases up to F1, then decreases. This implies that the amplitude of the glottal flow decreases as F0 increases up to F1.The interaction ripple is caused by the variations in the magnitudes of the glottal flow harmonics strongly effected by the vocal tract input impedance. The size of the interaction ripple depends on the magnitudes of the corresponding source harmonics. By increasing F0, the dominant harmonics get closer to the zero reactance frequency and the ripple gets larger.For different vowels, the frequency of ripple, the maximum amplitude and the skewness of the glottal flow are different due to the difference of the input impedance.The most widely used assumptions in modeling the glottal aerodynamics are that the glottal flow is incompressible (flow density is constant) and steady during the opening of vocal folds and unsteady during their closing. It is called as quasi-steady Bernoulli flow assumption. Then, the pressure-flow relation can be written by the well known Bernoulli equation (Titze, 2006a):(2)PTG=kt12ρug2ag2where ugis the glottal flow, PTGis the transglottal pressure (the difference between the subglottal and supraglottal pressures, PTG=Psub−Psup), agis the minimum glottal area along the vocal folds, ρ is the density of air and ktis the transglottal pressure recovery coefficient determined experimentally (Titze, 2006a). If the subglottal acoustic impedance is neglected, then Psubis equal to the lung pressure PL. Substituting PLinto Eq. (2) and writing vocal tract input pressure, pIN, instead of Psup, the glottal flow can be written as(3)ug=ag2PL−pINktρ(4)=agβPL−pINwhereβ=2ktρ. Eq. (4) is valid if the glottal flow is downstream. The results of our physical system simulations verified its validity. The experimental results obtained by the simulation of mechanical model of vocal folds show that the quasi-steady Bernoulli flow assumption is valid during almost 70% of a glottal cycle. It has been found that, it is a good approximation of actual glottal flow during the open phase (Jong and Mongeau, 2007).The linear source-filter theory (Fant, 1960) assumes that the glottal flow does not depend on the vocal tract acoustics. Considering Eq. (4), this assumption holds if•The vocal tract input pressure or supraglottal pressure is negligible compared to the subglottal pressure (Psub≫Psupor PL≫pIN).The acoustic impedance of the glottis is very large compared to the vocal tract input impedance (Zg≫ZIN). It also means that the minimum glottal area, ag, is much smaller than the equivalent vocal tract area, Aeqdefined byAeq=AsubAsupAsub+Asup(ag≪Aeq) (Titze, 2008).Noninteractive glottal flow is obtained by neglecting the vocal tract input pressure, pIN, in Eq. (4). It is a linear function of glottal area.Based on the quasi-steady Bernoulli flow assumption, the glottal flow is related to the vocal tract input pressure as given by Eq. (4). As we aim to develop a coupled speech production model, it is needed to have another expression, representing vocal fold dynamics, in terms of the vocal tract input pressure, pIN, glottal flow and vocal tract output.In the hybrid synthesis method (Sondhi and Schroeter, 1987), pIN, is calculated from vocal tract input impedance obtained by the chain matrix method (Sondhi and Schroeter, 1987). The impulse response of the vocal tract is calculated by inverse Fourier transform, and it is convolved with the glottal flow (Sondhi and Schroeter, 1987, 1999) to obtain the output speech. However, it is reported that one drawback of this approach is that when the duration of the impulse response is very long, calculation of convolution gets hard. Hence, instead of using convolution directly, input reflectance of the vocal tract is used. Recently, Howe and McGowan (2012) use three poles and zeros for modeling both subglottal and supraglottal impedance. In this work, in order to accomplish the coupling, the input pressure, pIN, is estimated by a recursive filter determined using the chain matrix method.There are three types of acoustic models for vocal tract; transmission line circuit analog, wave-reflection method and chain matrix method. The first two methods work in time-domain while the last one works in frequency domain. Since it can model the frequency dependent losses due to viscosity and wall vibration, the chain matrix method estimates the vocal tract formants more accurately. The chain matrix for vocal tract is first given in Sondhi and Schroeter (1987, 1999). It depends on the solution of equation of continuity and equation of motion.For a single tube approximation of vocal tract, the chain matrix can be written as(5)UgPIN=AtCtBtDtULIPPLIP=KtULIPPLIPwhere PINand Ugare frequency domain representations of pressure and volume velocity at the glottis side, and PLIPand ULIPare the same quantities at the output side of the tube. At, Bt, Ct, Dt, elements of the matrix Kt, relate the input and output acoustic quantities of a tube in the frequency domain.For a lossless uniform tube, the chain matrix is given as (Sondhi and Schroeter, 1999)(6)AtCtBtDt=z1/212(1+z−1)−A2ρc(1−z−1)−ρc2A(1−z−1)12(1+z−1)Since the matrix for the whole tract is the product of all tube matrices (Sondhi and Schroeter, 1987), the elements of Ktcan be written in terms of an Nth degree polynomial in z−1 as(7)Kt=zN/2∑n=0Nakz−k∑n=0Nckz−k∑n=0Nbkz−k∑n=0Ndkz−kBefore developing the coupled system, in order to see its relationship with the linear predictive (LP) model, let us first derive the LP representation of speech production by using the chain matrix.Assuming that radiation impedance is zero (PLIP=0) the discrete time transfer function from glottis to lips is written as(8)ULIPS(z)Ug(z)=z−N/2∑k=0Nakz−kHere, z−N/2 is a delay term due to the time required for the transmission of the sound from glottis to lips. If the vocal tract filter, H(z), is defined asH(z)=1∑k=0Nakz−k, then(9)ULIPS(z)=z−N/2H(z)Ug(z)By defining s[n]=uLIPS[n] and removing the delay factor in ug[n−N/2], in time domain, Eq. (9) can be written as (Sondhi and Schroeter, 1999);(10)∑k=0Naks[n−k]=ug[n]Eq. (10) is the LP representation of speech signal (Atal and Hanauer, 1971). The parameters ak's are the LP coefficients of speech. It must be noted that it is obtained under the lossless vocal tract, closed glottis and no lip radiation assumptions. In addition, source-filter interaction is neglected, assuming that they are independent. In general, the lip radiation is approximated by a first order high-pass filter (Quatieri, 2001) and applied on the lip velocity to obtain speech, s[n].In order to properly couple the source and the filter, according to quasi-steady Bernoulli equation in Eq. (4), the vocal tract input pressure, pIN, is needed. Now, we will obtain the input impedance of the vocal tract that relates the glottal flow with pINfrom chain matrix and then construct two nonlinear source-filter models for voiced speech.We consider two ways to calculate pINfrom the chain matrix; from lip velocity and from the glottal flow. Let us first write PINin terms of ULIPSusing KTRACTassuming that radiation impedance is zero (PLIP=0),(11)PINULIPS=BTRACT=zN/2∑n=0Nbkz−kDefining the transfer function from lip velocity to vocal tract input pressure asB(z)=∑n=0Nbkz−k, then PIN(z) is(12)PIN(z)=zN/2B(z)ULIPS(z)In time domain,(13)pIN[n]=∑k=0NbkuLIPS[n+N/2−k]Note that in Eq. (13), pIN[n] depends on the future values of uLIPS[n] and it is a noncausal representation for pIN[n].Combining Eqs. (8) and (12), we can write PINin terms of Ugas(14)PIN(z)=B(z)H(z)Ug(z)=∑n=0Nbkz−k∑n=0Nakz−kUg(z)From Eq. (14), the vocal tract input pressure, pIN[n], in terms of glottal flow is(15)pIN[n]=1a0∑k=0Nbkug[n−k]−1a0∑k=1NakpIN[n−k]Eq. (15) is a causal representation for calculating pIN[n]. In order to calculate interactive glottal flow, pIN[n] is added into ug[n] expressed by Eq. (4) as follows(16)ug[n]=βag[n](PL−pIN[n])There are two alternatives for the inclusion of pINin Eq. (16)1.pINin terms ofuLipsnSubstituting equation (13) into (16), we get(17)ug[n]=βag[n]PL−∑k=0NbkuLIPS[n+N/2−k]where uLIPS[n], from Eq. (9) is(18)uLIPS[n]=1a0ug[n−N/2]−1a0∑k=1NakuLIPS[n−k]Note that Eq. (18) is a nonlinear noncausal recursive representation for interactive glottal flow. The current glottal flow, ug[n], depends on future values of the lips flow, uLIPS[n]. Articulatory models solve the non-causality problem by defining s[n]=uLIPS[n+N/2]. However, this simple solution fails in this case because it requires the solution of nonlinear simultaneous equations relating temporally synchronous samples of s[n] and ug[n]. Hence, the system representation is not realizable.pINin terms of ug[n]Normalizing the filter coefficients, akand bkby a0, from Eq. (15), we can write(19)pIN[n]=∑k=0Nbkug[n−k]−∑k=1NakpIN[n−k]Substituting Eq. (19) into (16), we get(20)ug[n]=βag[n]PL−∑k=0Nbkug[n−k]+∑k=1NakpIN[n−k]which can be written as(21)ug2[n]+b0β2ag2[n]ugn−ag2[n]β2PL−p∧IN[n]=0wherep∧IN[n]is(22)p∧IN[n]=∑k=1Nbkug[n−k]−∑k=1NakpIN[n−k](23)=pIN[n]−b0ug[n]Eq. (21), a recursive second order function of ug[n], has to be solved to get two solutions for ug[n] at any time instant n. The solution is(24)ug1,2[n]=βag[n]−b0βag[n]±b02β2ag2[n]+4PL−p∧IN[n]2In order to have a real solution, according to Eq. (16), it is required that PL≥pIN[n]. To avoid any ambiguous solution for ug[n], Eq. (24) must have only one positive result. It is satisfied if(25)b02β2ag2[n]+4PL−p∧IN[n]≥b0βag[n](26)b02β2ag2[n]+4PL−p∧IN[n]≥b02β2ag2[n](27)PL≥p∧IN[n]Eq. (27) is a required condition for unique ug[n]. By combiningPL≥p∧IN[n]and PL≥pIN[n], the required condition for real and unique ug[n] isPL≥max(pIN[n],p∧IN[n]). If b0 is chosen to be positive (b0>0), according to Eq. (23),pIN[n]>p∧IN[n]and the condition for real and unique glottal flow, ug[n], turns out to be PL≥pIN[n].The solution of Eq. (24), is used for the calculation of pIN[n] in Eq. (15). At each time instant n, calculation of the parameters,p∧IN[n],ug[n], and pIN[n] is required.In the previous section, an interactive model considering only vocal tract loading on the source is obtained for voiced speech. This model is nonlinear and its stability depends on the amplitude of the input, glottal area. In order to have a control over the glottal area amplitude, the glottal area function βag[n] in Eq. (20) is represented as a product of a normalized waveform,agUNITY[n], whose maximum value is unity, and an amplitude scale parameter, Amax;(28)ug[n]=Amax.agUNITY[n]PL−pIN[n]This modification helps to develop a robust parameter estimation algorithm.The second modification is related with combining the subglottal tract to the model. In the previous section, we consider only supraglottal tract in calculating the input impedance,ZIN=PINUg. It is known that the impedance relating the glottal flow to the transglottal pressure across the glottis is the sum of the subglottal and supraglottal impedances (Titze, 2008). In other words, if we consider both subglottal and supraglottal impedance, the transglottal pressure can be written as(29)kt12ρug2ag2=PL−Ug*Zsub−Ug*Zsup(30)=PL−Ug*(Zsub+Zsup)By representing Ug*(Zsub+Zsup) in Eq. (30) as pIN, we obtain the same glottal flow equation given by Eq. (28). However, in this case, pINrepresent the pressure drop due to not only the supraglottal impedance but also subglottal impedance. Therefore, if the subglottal impedance is taken into account, overall impedance is the sum of the subglottal and supraglottal impedances. It is shown in the previous section that, by using the chain matrix model, the subglottal and supraglottal impedances can be expressed by rational transfer functions. As a result, the overall system transfer function is the sum of the two rational functions, which is a rational function. Let qk's denote the coefficients of the denominator of input impedance for the combined system and the order of the transfer function be N. Then,(31)pIN[n]=∑k=0Nbkug[n−k]−∑k=1NqkpIN[n−k]Indeed bk's in Eq. (31) are different than those in Eq. (19), however we prefer to keep the notation.Based on the way pIN[n] is calculated, we propose two interactive models. The first model using Eq. (19) together with Eq. (28) is called as interactive source-filter model I (ISFM1) and the second model using Eq. (31) for pIN[n] in Eq. (28) is named as interactive source-filter model II (ISFM2). The proposed interactive models, ISFM1 and ISFM2, are shown in Fig. 5(a) and (b), respectively.The first point in the analysis of the interactive models is the stability. The interactive systems produce bounded output if the vocal tract filter, H(z), is stable and the interactive glottal flow, ug[n], is bounded. Since the ISFMs are nonlinear, the stability of the system depends on the amplitude of the input, particularly the maximum amplitude of glottal area, Amax, and the other model parameters, PL, bk's and ak's. The maximum of the glottal flow amplitude,ug∞, is expressed by(32)ug∞=AmaxagUNITYPL−pIN∞(33)ug∞≤AmaxagUNITY∞PL−pIN∞A finite gain (Marquez, 2003), γ(H)∞, can be defined for the square root nonlinearity as(34)γ(H)∞≥maxPL−pIN∞PL−pIN∞(35)γ(H)∞≥PL−pIN∞PL−pIN∞(36)γ(H)∞PL−pIN∞≥PL−pIN∞By substituting Eq. (36) into Eq. (33),ug∞is written as(37)ug∞≤Amaxγ(H)∞(PL−pIN∞)pIN∞can be expressed by a gain function, Γ(H)∞, aspIN∞=Γ(H)∞ug∞, which is substituted into Eq. (37) to get a closed form expression forug∞as follows,(38)ug∞≤Amaxγ(H)∞PL−Γ(H)∞ug∞ug∞+Amaxγ(H)∞Γ(H)∞ug∞≤AmaxPLγ(H)∞ug∞≤AmaxPLγ(H)∞1+Amaxγ(H)∞Γ(H)∞SincepIN∞=Γ(H)∞ug∞, the closed form expression forpIN∞can be obtained by multiplying Eq. (38) byΓ(H)∞,pIN∞can be calculated as(39)pIN∞≤AmaxPLγ(H)∞Γ(H)∞1+Amaxγ(H)∞Γ(H)∞Some important limiting conditions obtained from Eqs. (38) and (39) forug∞andpIN∞are given in Table 1.The limiting conditions inform about the states of the interactive system. Note thatΓ(H)∞→0is the asymptotical condition that the interactive system is in non-interactive mode and equivalent to linear source-filter model. In this mode, glottal flow is a linear function of the glottal area and vocal tract has no influence on it. Another interesting observation is that ifΓ(H)∞→∞,ug∞→0andpIN∞is bounded by PL. An unstable pINfilter can produce bounded glottal flow, ug[n], and pIN[n] due to the nonlinear feedback in the model. However, in practice when the magnitudes of the poles of the pINfilter are very large and outside the unit circle, pINcan exceed PLin a small fraction of time and ug[n] becomes complex. To avoid this problem, a sufficient condition for the pINfilter isΓ(H)ug∞≤PL. If we rewriteug∞asug∞≤AmaxPL1−pINPL∞, it is easy to show that the maximum value ofug∞is less than or equal toAmax2PLwhen |pIN|≤PL. Substituting it intoΓ(H)ug∞≤PL,(40)Γ(H)ug∞≤PLΓ(H)Amax2PL≤PLΓ(H)≤PL2AmaxEq. (40) is a sufficient condition that the interactive system produces real and bounded glottal flow, ug[n].According to limiting conditions, ifΓ(H)∞→0glottal flow is non-interactive meaning that it is a function of only glottal area and PL, hence, source and filter are independent. Therefore, ifΓ(H)≪PL2Amaxis satisfied, (pIN≪PL), the ISFMs run in non-interactive mode and perform the same as LSFM. Using this property, it is possible to have ISFM performing always equal or better than LSFM. Amax and PLare the control parameters for the mode of the ISFMs.In speech analysis, the estimation of model parameters is a blind estimation problem. We follow the steps below to find the model parameters, Amax, PL, ak, bk, qk.1.Closed – Phase analysisEstimation of glottal flow waveform by removing the vocal tract and radiation filters from speech signal using constrained closed phase analysis (Alku et al., 2009). In this step, both glottal flow waveform, ug[n], and vocal tract filter coefficients, ak's, are estimated from speech.Glottal parameterizationFor pitch synchronous analysis, the glottal closure and the glottal opening instants and, the location and the amplitude of glottal flow maxima are obtained from glottal flow estimate.Glottal area model initializationUsing the glottal parameters, the time sequence denoting the samples of glottal area model, ag[n], is generated. There are parametric glottal area models used for articulatory synthesis and acoustic analysis in the literature (Ananthapadmanabha and Fant, 1982). It is also possible to use parametric glottal flow models instead of glottal area model, such as Rosenberg, LF etc. (Veldhuisa, 1998; Fu and Murphy, 2006)Multi-parameter optimizationA method is developed to estimate the interactive glottal flow model parameters with respect to the error between the target glottal flow, ug[n], obtained by inverse filtering and reconstructed glottal flow,u∧g[n;θ], by the interactive system(41)Eu(θ)=1N0∑n=1N0ug[n]−u∧g[n;θ]2where θ denotes the model parameters. Since the interactive glottal flow is a nonlinear function of the model parameters, Amax, PL, akand bk, minimization of Eu(θ) is a nonlinear optimization problem. Due to the particular nonlinearity, there is no analytical solution for the minimization problem. However, by choosing good initial values, it is possible to solve the problem iteratively. The parameter optimization routines are given in appendix (Fig. 6).Initial parameter values are critical for the success of the nonlinear optimization. Physical insight about the system would be useful in choosing the initial values. As far as the parameters Amax and PLare concerned, a good choice can be obtained by setting PL≫pINand a small value for Amax. For large PL, the interactive glottal flow can be written as(42)u∧g[n]≅AmaxagUNITY[n]PLwhich implies that the maximum value of glottal flow is approximatelyAmaxPL. Hence, the corresponding initial value for Amax is(43)Amax0=max(ug)PLPLgives us a flexibility to choose the operating point for ISFMs. We can operate the system either in interactive or non-interactive mode. This property allows the performance of ISFM be equal or better than the linear source-filter model. At its worst, ISFM would be performing like LSFM.The parameters ak's estimated by closed-phase analysis are the coefficients of the vocal tract filter and its poles define the vocal tract formants. It can be inferred from the spectrum of the vocal tract impedance (see Titze and Story, 1997) that a zero is located between any two consecutive formants. Hence, a suitable initial value for bkcan be ak. Similarly, for ISFM2, the initial value for qkcan be taken as akso that ISFM1 and ISFM2 are equivalent before optimizing ISFM2.The parameter estimation procedure is as follows1.Choose PLas a large positive number, such as 1000*max(ug[n]) in a glottal cycle, so that initially the nonlinear system works in non-interactive mode (Γ(H)∞=1 since bk0=ak).Minimize Eu(θ) (Eq. (41)) with respect to Amax with initial valuesAmax0=max(ug)PL, bk0=akand qk0=ak, obtain the glottal area maximum, Amax. If the error is larger than the error of LSFM increase PLand obtain a new value for Amax. An approximate nonrecursive solution forAmax*is given in the appendix.Minimize Eu(θ) with respect to bkwith initial values bk0=akand qk0=ak, obtain bk*. The parameters of ISFM1 are now estimated!Minimize Eu(θ) with respect to qkwith the initial value bk* and qk0=ak, obtain qk*.Minimize Eu(θ) with respect to bkwith initial values bk* and qk*, obtain bk** and then continue to iterate as it is in steps 4 and 5 until finding a minimum value. Finally, the parameters of ISFM2 are estimated!In the first three steps, the parameters of ISFM1 are calculated. After the iterations in the fourth and the fifth steps, the parameters of ISFM2 are found.

@&#CONCLUSIONS@&#
In this work, we present a framework for modeling nonlinear source filter coupling in voiced speech sounds. Based on this framework, two nonlinear interactive source filter models, ISFM1 and ISFM2, are developed and their relation to the linear source filter model, LSFM, and each other are exposed. It is shown that LSFM is an approximation of the ISFMs under certain conditions. The major difference between the ISFMs and LSFM is that, in the LSFM the source and the filter are assumed to be independent and do not affect each other however in the ISFMs they nonlinearly interact according to Bernoulli equation.A parameter estimation algorithm is proposed for estimating the parameters of ISFMs and tested on speech signals. Experimental results show that proposed nonlinear interactive models exhibit the source-filter interaction effects seen in speech production. Since ISFMs are based on physical modeling, they have the capability of producing the fine ripples on the glottal flow waveform observed in the simulation of speech production. They accurately generate fine ripples on the glottal flow obtained by inverse filtering by the help of the nonlinear interaction between the glottal flow and vocal tract filter. This feature is incorporated into the Rosenberg+ model and used to synthesize glottal flow waveforms obtained from a large speech database. The results indicate that the interactive Rosenberg model is always better than its non-interactive counterpart.Proposed interactive model takes the glottal area waveform as its input. A model based glottal area waveform is synthesized using the glottal flow waveform obtained by inverse filtering assuming that the glottal flow and the glottal area waveforms achieve their peaks synchronously. In this context, the optimization of the skewing quotient of the glottal area can be studied further. In generating the glottal area waveform, Rosenberg+ model has been used mainly due to its suitability in the optimization of its parameters. The generation of the glottal area waveform for natural sounding speech can be a part of future studies. Alternatively, the use of a dynamic system model to generate the glottal flow waveform can be considered. Another way to obtain the glottal area waveform could be the use of High-Speed Endoscopic Video (HSV) of vocal folds. An aim of such a study would be to investigate whether the interactive system enhances the source harmonics and generates non-existing harmonics in the glottal area observed in Titze (2008).Proposed framework can be used in an articulatory speech synthesizer to couple the glottal flow, and sub- and supra-glottal tracts. The transfer function of the combined sub- and supra-glottal tracts has to be calculated from the time-varying areas. They can be parameterized by estimating the pINfilter. Hence, instead of areas, the filter coefficients, bkand qk, can be stored in a codebook to represent the transfer function of the system.ISFMs can be used in speaker identification (SID). For instance, Plumpe and Quatieri use glottal flow waveform in SID (Plumpe et al., 1999). They model both the coarse shape and fine details of glottal flow in a different manner. The coarse shape is modeled by LF model and the fine details are modeled in frequency domain by fitting a second order polynomial to the variation of the frequency of the first formant (F1) in a glottal cycle. Their combination with cepstrum coefficients increases SID accuracy by 3% with respect to using only cepstrum coefficients as a feature. ISFMs may increase SID accuracy more. The LF model can be used as a glottal area to produce interactive glottal flows. Then, its parameters can be combined with both the vocal tract input transfer function parameters and MFCC coefficients as a feature vector for SID. Another branch of future studies can be to investigate better glottal features for applications such as voice quality assessment or emotion recognition. For instance, Fu and Murphy propose a method to extract the LF model parameters for voice quality assessment (Fu and Murphy, 2006). Their method can be a pre-processing method for ISFMS, e.g., the estimated source model can be used as a glottal area for ISFMs. Time, frequency and amplitude based attributes of the coarse and the fine details of glottal flow can be extracted from interactive glottal flow waveform. Their combination as a feature may increase the accuracy of the application.Nowadays people want to combine physically informed models into their existing speech applications. For example, recently, the branch of statistical speech synthesis seeks a solution to the integration of physical speech production models into the statistical parametric speech synthesizers (Tao et al., 2014). The ISFMs are inspired from the physical model of speech production. They can be used in HMM-based speech synthesis by replacing the linear source-filter model in the sound synthesis block (Raitio et al., 2011). The proposed models may be used in the next generation speech processing applications to increase the quality of speech or the accuracy of recognition systems.The coupled system equations are expressed as(A.1)u∧g[n]=ag[n]PL−pIN[n]=Amax.agUNITY[n]PL−pIN[n]and(A.2)pIN[n]=∑k=1Nbku∧g[n−k]−∑k=1NqkpIN[n−k]=∑k=1Nbkag[n−k]PL−pIN[n−k]−∑k=1NqkpIN[n−k]The sample error in glottal flow can be written as(A.3)e[n|θ]=ug[n]−Amax.agUNITY[n]PL−pIN[n|θ]where θ denotes the model parameters Amax, PL, bkand qk. The objective function is the mean squared error(A.4)E(θ)=1M∑n=1Me2[n|θ]=1M∑n=1Mug[n]−Amax.agUNITY[n]PL−pIN[n|θ]2Since the model parameters are nonlinearly related with the error function, this is a nonlinear least squares problem. It can be solved by gradient based iterative algorithms. In vector form, Eq. (A.4) becomes(A.5)E(θ)=1Me−T·e−_wheree−=e1|θe2|θ....eM|θT. The derivative of E(θ) with respect to the elements, θk, of the parameter vector θ is(A.6)∂E(θ)∂θk=2M∑n=1Me[n]∂e[n]∂θkand the Jacobian is(A.7)J−=∂e1∂θ1∂e1∂θ2......∂eM∂θ1∂eM∂θ2Therefore, the gradient can be written in terms of Jacobian and error as follows(A.8)∇θE(θ)=2MJTe−The entries of the Hessian matrix of the cost function is obtained by taking the derivatives of the gradient vector with respect to θ as(A.9)Hk,l=∂2E(θ)∂θk∂θl=2M∑n=1M∂e[n]∂θk∂e[n]∂θl+e[n]∂2e[n]∂θk∂θlin terms of Jacobian(A.10)H=2MJTJ+2M∑n=1Me[n]·e2[n]∂θk∂θlusingS=∑n=1Me[n]·e2[n]∂θk∂θlthe Hessian matrix can be written as(A.11)H=2MJTJ+2MSDepending on the size of S, there are two approaches for the calculation of Eq. (A.11), small residue and large residue algorithms. If S is large with respect to JTJ, it has to be calculated either analyticaly or by using finite difference approximation. This type of approaches is called large residue algorithms. However, if the error, e[n], is small enough to neglect the term S, the Hessian can be calculated by using only the first derivative of the cost function. Algorithms that use this approximation are called small residue algorithms. The Gauss–Newton and Levenberg–Marquardt are the two algorithms that are based on the small error assumption. In the Gauss–Newton method, the Hessian is approximated byH≈2MJTJ, hence during the iterations, the parameters are updated as(A.12)θk+1=θk−ηkJkTJk−1JkTekwhere η is step size that can be chosen either as a constant or computed using line search.The system error in glottal flow, e[n], is defined ase[n]=ug[n]−u∧g[n]. The derivative of the mean squared error, E, with respect to Amax,∂E∂Amaxis(A.13)∂E∂Amax=2M∑n=1Me[n]∂e[n]∂Amax=2MJAmaxe−whereJAmaxande−are the gradient and error vectors of length M, respectively. Using Eq. (A.1), the derivative is expressed as(A.14)∂E∂Amax=∂∑n=1Mug[n]−ag[n]PL−pIN[n]2∂Amax(A.15)=2M·∑n=1Me[n]∂−ag[n]PL−pIN[n]∂Amax(A.16)=−2M∑n=1Me[n]·∂ag[n]∂AmaxPL−pIN[n]+ag[n]∂PL−pIN[n]∂Amax(A.17)=2M∑n=1Me[n]·u∧g[n]2PL−pIN[n]∂pIN[n]∂Amax−u∧g[n]AmaxThe elements ofJAmaxused by Gauss-Newton method in Eq. (A.13) is as follows(A.18)JAmax[n]=u∧g[n]2PL−pIN[n]∂pIN[n]∂Amax−u∧g[n]Amaxwhere∂pIN[n]∂Amaxcan be calculated by taking the derivative of pIN[n] given by Eq. (A.2) with respect to Amax.(A.19)∂pIN[n]∂Amax=∂∑k=0NbkAmaxagUNITY[n−k]PL−pIN[n−k]∂Amax−∂∑k=1NqkpIN[n−k]∂Amax(A.20)=∑k=0NbkagUNITY[n−k]PL−pIN[n−k]+Amax∂PL−pIN[n−k]∂Amax−∑k=1Nqk∂pIN[n−k]∂Amax(A.21)∂pIN[n]∂Amax=∑k=0Nbku∧g[n−k]Amax−bku∧g[n−k]2PL−pIN[n−k]∂pIN[n−k]∂Amax−∑k=1Nqk∂pIN[n−k]∂Amax(A.22)1+b0u∧g[n]2PL−pIN[n]∂pIN[n]∂Amax=∑k=0Nbku∧g[n−k]Amax−∑k=1Nbku∧g[n−k]2PL−pIN[n−k]+qk∂pIN[n−k]∂Amax(A.23)∂pIN[n]∂Amax=11+b0u∧g[n]2PL−pIN[n]∑k=0Nbku∧g[n−k]Amax−∑k=1Nbku∧g[n−k]2PL−pIN[n−k]+qk∂pIN[n−k]∂AmaxWhen ak=bk(Γ(H)∞=1, see in the parameter estimation algorithm Step-1 in the article), which is the usual case in the optimization of Amax, PL≫pIN, hence Eq. (A.23) can be approximated by(A.24)∂pIN[n]∂Amax=∑k=0Nbku∧g[n−k]Amax−∑k=1Nqk∂pIN[n−k]∂AmaxThe gradient vector given by Eq. (A.24) can be considered as an output of a time-invariant IIR filter. Infact, the output is equal to pIN[n]/Amax. Therefore,JAmaxin Eq. (A.13) can be approximated as(A.25)JAmax[n]=u∧g[n]2PL−pIN[n]pIN[n]Amax−u∧g[n]AmaxFurthermore, using the same assumption used in Eq. (A.24),JAmax[n]turns out to be(A.26)JAmax[n]=−u∧g[n]AmaxSubstituting Eq. (A.26) into Eq. (A.13) and equating to zero yields,(A.27)∂E∂Amax=0(A.28)2MJAmaxe−=0(A.29)−∑n=1Mu∧g[n]Amaxug[n]−ag[n]PL−pIN[n]=0(A.30)∑n=1Mu∧g[n]ug[n]=∑n=1Mu∧g[n]ag[n]PL−pIN[n](A.31)∑n=1Mu∧g[n]ug[n]=Amax∑n=1Mu∧g[n]agUNITY[n]PL−pIN[n](A.32)Amax*=∑n=1Mu∧g[n]ug[n]∑n=1Mu∧g[n]agUNITY[n]PL−pIN[n]The optimalAmax*value is obtained by Eq. (A.32).The gradient of E with respect tobll=0Ncan be written as(A.33)∂E∂bl=2M·∑n=1Mug[n]−ag[n]PL−pIN[n]∂−ag[n]PL−pIN[n]∂bl(A.34)=2M·∑n=1Me[n]ag[n]2PL−pIN[n]∂pIN[n]∂blthen, the elements of Jacobian is(A.35)Jbl[n]=ag[n]2PL−pIN[n]∂pIN[n]∂blwhere∂pIN∂blis calculated from Eq. (A.2) as follows∂pIN[n]∂bl=∂∂bl∑k=0Nbkag[n−k]PL−pIN[n−k]−∑k=1NqkpIN[n−k]∂pIN[n]∂bl=u∧g[n−l]−∑k=0Nbkag[n−k]2PL−pIN[n−k]∂pIN[n−k]∂bl−∑k=1Nqk∂pIN[n−k]∂bl1+b0u∧g[n]2PL−pIN[n]∂pIN[n]∂bl=u∧g[n−l]−∑k=1Nbku∧g[n−k]2PL−pIN[n−k]∂pIN[n−k]∂bl−∑k=1Nqk∂pIN[n−k]∂bl(A.36)∂pIN[n]∂bl=11+b0u∧g[n]2PL−pIN[n]u∧g[n−l]−∑k=1Nqk+bku∧g[n−k]2PL−pIN[n−k]∂pIN[n−k]∂blClosed form solution of Eq. (A.34) does not exist. Optimal parameter blis estimated for all l=0, 1, 2, …, N by solving Eq. (A.34) together with Eq. (A.36) iteratively.The gradient of E with respect toqll=0Ncan be written as(A.37)∂E∂ql=2M·∑n=1Mug[n]−ag[n]PL−pIN[n]∂−ag[n]PL−pIN[n]∂ql(A.38)=2M.∑n=1Me[n]ag[n]2PL−pIN[n]∂pIN[n]∂qlthen, the elements of Jacobian is(A.39)Jql[n]=ag[n]2PL−pIN[n]∂pIN[n]∂qlwhere∂pIN∂qlis calculated from Eq. (A.2) as follows∂pIN[n]∂ql=∂∂ql∑k=0Nbkag[n−k]PL−pIN[n−k]−∑k=1NqkpIN[n−k]∂pIN[n]∂ql=−∑k=0Nbkag[n−k]2PL−pIN[n−k]∂pIN[n−k]∂ql−pIN[n−l]−∑k=1Nqk∂pIN[n−k]∂ql1+b0u∧g[n]2PL−pIN[n]∂pIN[n]∂ql=−pIN[n−l]−∑k=1Nbku∧g[n−k]2PL−pIN[n−k]∂pIN[n−k]∂ql−∑k=1Nqk∂pIN[n−k]∂ql(A.40)∂pIN[n]∂ql=11+b0u∧g[n]2PL−pIN[n]−pIN[n−l]−∑k=1Nqk+bku∧g[n−k]2PL−pIN[n−k]∂pIN[n−k]∂blClosed form solution of Eq. (A.38) does not exist. Optimal parameter qlis estimated for all l=1, 2, .., N by solving Eq. (A.38) together with Eq. (A.40) recursively.