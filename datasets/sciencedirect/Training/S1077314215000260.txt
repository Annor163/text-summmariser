@&#MAIN-TITLE@&#
Kernel regression in mixed feature spaces for spatio-temporal saliency detection

@&#HIGHLIGHTS@&#
A spatio-temporal saliency model for salient region detection in video is proposed.Kernel regression in mixed feature spaces and its three entity-models are proposed.Based on kernel regression, a hybrid fusion strategy is proposed.The hybrid fusion strategy performs better than the independent fusion strategy.The proposed spatio-temporal saliency model outperforms existing approaches.

@&#KEYPHRASES@&#
Spatio-temporal saliency,Kernel regression,Mixed feature spaces,Hybrid fusion strategy,

@&#ABSTRACT@&#
Spatio-temporal saliency detection has attracted lots of research interests due to its competitive performance on wide multimedia applications. For spatio-temporal saliency detection, existing bottom-up algorithms often over-simplify the fusion strategy, which results in the inferior performance than the human vision system. In this paper, a novel bottom-up spatio-temporal saliency model is proposed to improve the accuracy of attentional region estimation in videos through fully exploiting the merit of fusion. In order to represent the space constructed by several types of features such as location, appearance and temporal cues extracted from video, kernel regression in mixed feature spaces (KR-MFS) including three approximation entity-models is proposed. Using KR-MFS, a hybrid fusion strategy which considers the combination of spatial and temporal saliency of each individual unit and incorporates the impacts from the neighboring units is presented and embedded into the spatio-temporal saliency model. The proposed model has been evaluated on the publicly available dataset. Experimental results show that the proposed spatio-temporal saliency model can achieve better performance than the state-of-the-art approaches.

@&#INTRODUCTION@&#
Visual saliency modeling has been widely considered to be a promising approach to automatically and efficiently localizing the “important” content in images or videos [1–3]. While saliency detection from still images depends only on spatial information (i.e., the current scene), for the task of saliency estimation from videos, temporal information (i.e., the accumulative information along time) also plays an important role, which is commonly termed as spatio-temporal saliency in the literature [4]. As highlighted in [4], spatio-temporal saliency modeling provides a natural way to identify important regions from dynamic scenes, which can benefit a wide range of computer vision applications, such as action recognition [5], moving object detection in the stationary or dynamic background [6–8], and image/video compression [9].A lot of spatio-temporal saliency models have recently been proposed, which in general fall into two categories, namely the data-driven bottom-up models [2,3,5–15] and the task-oriented top-down models [16–18]. The later category of models usually resorts to supervised learning, with a pre-determined task and the corresponding training data, while the former does not rely on specific tasks. In this paper, we are mainly focused on bottom-up saliency modeling for the purpose of detecting salient moving object (region) from videos, which desirably can facilitate the computer vision tasks such as moving object detection [6–8] and visual tracking [19].The vast majority of existing computational models for spatio-temporal saliency detection [2,3,6,7,10,12–15] follow the paradigm that the spatial saliency and the temporal saliency are first measured separately and then fused to obtain the final saliency map. Neurobiological evidence supporting this paradigm can be found in [20], which suggests that visual information processing in the brain goes along two parallel and concurrent streams, namely the ventral stream and the dorsal stream. The former has high spatial sensitivity and mainly processes appearance information, while the latter has high temporal sensitivity and mainly processes motion information. Consequently, the hypothetical segregation of the two streams naturally raises a question, i.e., the so-called visual integration problem: how does the cortex combine the information from the two streams? In spatio-temporal saliency models, in addition to the spatial and temporal saliency calculation modules which simulate the perceptual functionality of the ventral and the dorsal streams, there should also be a fusion strategy for simulating the visual integration functionality. In previous works [2,3,6,7,10,12–15], the fusion problem is typically addressed by performing multiplicative, additive, or maximum operations over the corresponding perceptual units independently, which totally ignores the connection among the neighboring units. While these fusion strategies might be appropriate for eye fixation prediction as discussed in many previous works, they are disadvantageous for those tasks which require highlighting foreground regions uniformly. In addition, the over-simplicity of existing fusion strategies may be one of the key reasons why existing computational models underperform the human vision system in predicting salient moving objects. These facts motivate us to develop a more effective approach for fusing the spatial and the temporal saliency.Our proposed spatio-temporal saliency model follows the aforementioned paradigm while being mainly focused on the fusion strategy. Due to its computational efficiency and perceptual superiority [21–23], superpixel is taken as the basic computational unit in our model. Similar to [24], each unit is represented by a feature vector defined in the mixed feature space, that is, the Cartesian product of the location feature subspace, the appearance feature subspace and the temporal feature subspace. Spatio-temporal saliency can then be treated as a function value of the mixed feature, which can be learnt by means of regression. In order to accommodate the locality and multi-modality of the mixed feature space, we first propose the model of kernel regression in mixed feature spaces (KR-MFS), which includes three variants: kernel regression using local constant approximation in mixed feature space (KR-LC-MFS), kernel regression using local regularized linear approximation in mixed feature space (KR-LRL-MFS) and kernel regression using local regularized kernel approximation in mixed feature space (KR-LRK-MFS). In addition, the relationship between KR-MFS and the classical kernel regression [25–28] is discussed. Then, based on KR-MFS, a hybrid fusion strategy is proposed. Different from the existing fusion strategies treat each unit individually, the proposed fusion strategy is able to exploit the spatial structure of the neighboring units. Finally, by integrating the spatial and temporal saliency calculation modules and the hybrid fusion module, we propose a unified spatio-temporal saliency model, which can outperform the state-of-the-art approaches on the benchmark datasets. To sum up, the contributions of this paper are as follows:•A generic model, i.e., kernel regression in mixed feature spaces (KR-MFS), and its three variants, i.e., KR-LC-MFS, KR-LRL-MFS and KR-LRK-MFS, are proposed, which can be potentially applied to many real-world problems besides the spatio-temporal saliency detection as concerned in this paper.Based on KR-MFS, a hybrid fusion strategy is proposed. The key property of the proposed fusion strategy is that it is able to take into account the influences from the neighboring units.By the aide of the hybrid fusion strategy, our proposed spatio-temporal saliency model can outperform the state-of-the-art approaches. Additionally, our model is well modularized and therefore has good extendibility.The remainder of this paper is organized as follows: Section 2 reviews the related work. Section 3 details the proposed KR-MFS model and the variants. Section 4 describes the spatio-temporal saliency model using KR-MFS. In Section 5, our saliency model is comprehensively evaluated and compared against the state-of-the-art algorithms. Section 6 gives the conclusion of this paper.

@&#CONCLUSIONS@&#
In this paper, we first propose kernel regression in mixed feature spaces (KR-MFS) and its entity-models including kernel regression using local constant approximation in mixed feature spaces (KR-LC-MFS), kernel regression using local regularized linear approximation in mixed feature spaces (KR-LRL-MFS) and kernel regression using local regularized kernel approximation in mixed feature spaces (KR-LRK-MFS). It is worthwhile to note that the application of KR-MFS includes but not limited to spatio-temporal saliency detection. For example, KR-MFS can be potentially used in many other applications, such as object poses estimation from multimodal images which are generated by emerging RGB-D (kinect-style) cameras. In our future work, we will attempt to extend our KR-MFS to more applications.Based on KR-MFS, this paper proposes a hybrid fusion strategy for spatio-temporal saliency detection. From the visual organization and statistical analysis perspectives, necessity of the hybrid fusion has been discussed. In addition, experiments show that the hybrid fusion strategy, implemented by KR-LC-MFS, KR-LRL-MFS, and KR-LRK-MFS, can achieve better performance than the existing independent fusion strategy (i.e., the independent multiplicative fusion, the independent additive fusion, and the independent maximum fusion).Benefiting from the hybrid fusion strategy, our proposed spatio-temporal saliency detection model outperforms the state-of-the-art approaches. Followed by the neurobiological findings, our proposed spatio-temporal saliency model is in the aforementioned modular framework (i.e., the spatial and temporal saliency is first computed, and then fused). Therefore, the proposed model could be easily extended by replacing the corresponding module for specific demand.