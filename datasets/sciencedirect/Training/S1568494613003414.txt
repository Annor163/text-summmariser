@&#MAIN-TITLE@&#
ILClass: Error-driven antecedent learning for evolving Takagi-Sugeno classification systems

@&#HIGHLIGHTS@&#
A new evolving Takagi-Sugeno classification system is proposed.Output-feedback is used to supervise antecedent learning.Evolve-hybrid gives optimal performance in short-term and long-term learning.Evolve-hybrid resists well when adding a set of new unseen classes.

@&#KEYPHRASES@&#
Evolving fuzzy classifiers,Online learning,Takagi-Sugeno,Classification,

@&#ABSTRACT@&#
The purpose of this research work is to go beyond the traditional classification systems in which the set of recognizable categories is predefined at the conception phase and keeps unchanged during its operation. Motivated by the increasing needs of flexible classifiers that can be continuously adapted to cope with dynamic environments, we propose a new evolving classification system and an incremental learning algorithm called ILClass. The classifier is learned in incremental and lifelong manner and able to learn new classes from few samples. Our approach is based on first-order Takagi-Sugeno (TS) system. The main contribution of this paper consists in proposing a global incremental learning paradigm in which antecedent and consequent are learned in synergy, contrary to the existing approaches where they are learned separately. Output feedback is used in controlled manner to bias antecedent adaptation toward difficult data samples in order to improve system accuracy. Our system is evaluated using different well-known benchmarks, with a special focus on its capacity of learning new classes.

@&#INTRODUCTION@&#
Classification techniques represent a very active topic in machine learning. They appear frequently in many application areas, and become a basic tool for almost any pattern recognition task. Several structural and statistical approaches have been proposed to build classification systems from data. Traditionally, a classification system is trained using a learning dataset under the supervision of an expert that controls and optimizes the learning process. The system performance is fundamentally related to the learning algorithm and the used learning dataset. The learning dataset contains labelled samples from the different classes that must be recognized by the system. In almost all learning algorithms, the learning dataset is visited several times in order to improve the classification performance which is usually measured using a separated test dataset. The expert can modify the settings of the learning algorithm and restart the learning process until obtaining an acceptable performance. Then, the classification system is delivered to the final user to be used in real applicative contexts. The role of the classifier is to suggest a label for each unlabelled sample provided by the application. Typically, no learning algorithms are available at the user side.The main weakness in the above-mentioned conception paradigm is that the knowledge base is constrained by the learning dataset available at expert side and cannot be extended by the data provided at user side. These drawbacks increase the need for new type of classification systems that can learn, adapt and evolve in lifelong continuous manner. As one can see from Fig. 1, an incremental learning algorithm is used to learn from the data samples provided by the user after sending a validation or a correction signal in order to confirm or change the label suggested by the classifier. Contrary to the traditional paradigm, there is no separation between the learning phase and the operation phase in evolving classification systems. One of the key features in evolving classifiers is that incoming samples may bring in new unseen classes that are learned by the classifier without destroying its knowledge base or forgetting the existing classes.We have proposed in a previous work [1] an evolving Takagi-Sugeno (TS) classification system with an improved antecedent structure. It consists of a set of local linear regression models defined in different sub-spaces localized by the antecedent part of the rules. The rule-based structure of this system allows more flexibility in tuning its knowledge base, which makes it suitable for incremental learning. Recursive antecedent adaptation is coupled with a density-based incremental clustering to build the antecedent structure in the system. Consequent linear coefficients are estimated using recursive least squares method. The proposed learning algorithm has no problem-dependent parameters. In order to optimize the system performance for classification problems, a new method of antecedent learning in which output feedback is employed to supervise the re-estimation of prototype centers and covariance matrices. The goal is to focus on learning critical points and to improve the overall performance.In this paper, we first reformulate and present in details the output-based antecedent learning method (called ILClass-feed). Performance analysis of ILClass-feed is then discussed and compared to the classic statistical antecedent learning (called ILClass-stat). Contrary to ILClass-stat that behaves very well in the short term, ILClass-feed has relative poor performance in the short term, yet offering much better performance on the long term. Therefore, our effort in this paper is focused on proposing a new solution that combines the advantages of both ILClass-feed and ILClass-stat. The main criteria is to obtain the best possible performance for the short- and the long-term of learning. One can take for example the case of an evolving handwritten gesture classifier in which user defines his set of gestures providing few samples for each (short-term learning). It is very important in this example context to have a classifier with fast learning capacity. If user accepts the early system performance, he would continue to use it providing more and more data samples (long-term learning).Besides the focus on both early and late stages, a special emphasis is placed in this paper on the case of adding new classes to an existing classification system. The performance of our methods is studied in this context. It is important to mention that, to the best of our knowledge, it is the first work that evokes the problem of late learning of new classes by an evolving classifier. It can be also mentioned that very few works on evolving TS systems handle multiclass classification problems. Most of existing systems focus on prediction and regression problems.Before presenting our new evolving TS classification approach, we explain in Section 2 the global structure of TS systems and the different elements of most used incremental learning algorithms. We cite in the same section some known evolving TS systems. Our new system, called ILClass-hybrid is detailed in Section 3. Experimental validation of the proposed system using well-known benchmark datasets is then presented in Section 4. Both synchronized and unsynchronized class learning is considered in our experiments.A Takagi-Sugeno system is defined by a set of fuzzy rules in which the antecedent part represents a fuzzy partitioning or clustering of the input space, and the output is calculated using a regression polynomial model over the input vector weighted by the antecedent activation degree. Existing TS systems vary by their structure (antecedent and consequent) or by the learning algorithms. A comparative table between several known TS systems is presented at the end of this section. In order to facilitate understanding of this table, the different structural and algorithmic elements used in TS systems are explained below.As aforementioned, the structure of a TS system is divided into two parts: antecedent and consequent. We explain below the possible variants used in these two parts as well as the inference forward process in TS systems.Different types of membership functions can be used in TS models. The conjunction of the membership functions that are defined on the axes (features) of the input space results in a hyper fuzzy zone of influence associated to the fuzzy rule. The form of this fuzzy zone is related to the used membership function of the antecedent part.Considering the case of Gaussian functions, one can rewrite the fuzzy rules of TS models so that the antecedent part is represented by a fuzzy zone of influence with hyper-spherical shape. This zone of influence can be characterized by a center and a radius value. In the rest of this paper, the word “prototype” will be used to refer to the fuzzy zone of influence of a fuzzy rule.In data-driven design of TS models, the antecedent of fuzzy rules is formed using batch or incremental fuzzy clustering methods over a learning data set. These clustering methods aim at finding the prototypes’ centers and estimating the radius value in order to optimally cover the input data cloud(s).The firing degree of the antecedent part can be expressed by a specific distance that represents the closeness degree between the input vector and the fuzzy prototype (Eq. (1)).(1)Rulei:IFx→isclosetoPiTHENyi1=li1(x→),…,yik=lik(x→)where Pirepresents the fuzzy prototype associated to the rule i, k represents the number of classes andlim(x→)is the linear consequent function of the rule i for the class m.For hyper-spherical [2] or axes-parallel hyper-elliptical [3] prototypes, the firing degree can be computed depending on the prototype centerμi→and the radius value σi(the same value in all the dimensions for the former, and different values for the latter). In our model [1], we went a step ahead in the structure of the antecedent part of TS models. In addition to the use of different variance values in the definition of the fuzzy prototypes in the input data space, the covariance between the features is taken into consideration. Therefore, the fuzzy influence zone of each rule is represented by a prototype with a rotated hyper-elliptical form. Each fuzzy prototype in our system is yet represented by a centerμi→and a covariance matrix Ai:(2)Ai=σ12c12⋯c1nc21σ22⋯c2n⋯⋯⋯⋯cn1cn2⋯σn2iwhere c12(=c21) is the covariance between x1 and x2, and so on.Different multi-dimensional (multivariate) probability density functions can be used to measure the activation degree of each prototype. The most used ones are:•Multivariate normal distribution: the activation is calculated according to this distribution as follows:(3)βi(x→)=1(2π)n/2Ai1/2exp−12(x→−μi→)tAi−1(x→−μi→)Multivariate Cauchy distribution: the activation here is defined as follows:(4)βi(x→)=12πAi1+(x→−μi→)tAi−1(x→−μi→)−((n+1)/2)When using TS models in a classification problem, the inference process, applied to get the class of a given input vectorx→, consists of three steps:•The activation (or firing) degree of each ruleβi(x→)in the model is calculated (using Eq. (4), for example). It must then be normalized as follows:(5)βi¯(x→)=βi(x→)∑j=1rβj(x→)where r represents the number of rules in the model.the sum-product inference is used to compute the system output for each class:(6)ym(x→)=∑i=1rβi¯(x→)yimwhereyim=lim(x→)is the consequence part of the rule i related to the class m.The winning class label is given by finding the maximal output and taking the corresponding class label as response:(7)class(x→)=y=argmaxym(x→)m=1,…,kThree different consequent structures can be used in TS models: binary, singleton [4] or polynomial [5,2,6,1]. The latter is the more sophisticated form used in TS models in order to achieve higher precision. The focus will be placed on first-degree linear consequent. Models with such consequent structure are called “First-order TS models”. Thus, the linear consequent function is written as follows:(8)lim(x→)=π→imx→=ai0m+ai1mx1+ai2mx2+⋯+ainmxnwherelim(x→)is the linear consequent function of the rule i for the class m.It had been proved that zero-order TS models are functionally equivalent to the well-Radial Basis Function Networks (RBFN) [7]. The structures of these two models can be compared so that fuzzy prototypes in TS models are equivalent to the hidden neurons in RBFN, and singleton consequences in TS models are equivalent to the weights in RBFN between the hidden and the output layer. For the purpose of comparison between first-order and zero-order TS, Fig. 2shows a first-order TS model in the form of an RBF network with a second hidden layer.Let's suppose xi, i=1, 2, …, n represent the learning data samples, M refers to the learned system, and f refers to a given learning algorithm. Then, the difference between batch and incremental learning can be simply defined as follows:Batch:Mi=f(x1,x2,..,xi)Incremental:Mi=f(Mi−1,xi)We focus in this section (and all along the paper) on incremental learning algorithms. Batch learning of TS systems is beyond the scope of this paper.The focus is placed on incremental clustering because our classifier is based on fuzzy rule-based system, in which rule creation is usually considered as a clustering problem. In incremental clustering, each new point may either reinforce an existing cluster, and eventually changes its characteristics (i.e. its center and zone of influence), or trigger the creation of a new cluster. The main difference between incremental clustering methods is the criterion used to make the decision between these two choices. According to this criterion, we can categorize incremental clustering methods into distance-based and density-based methods.Most of existing TS models use distance-based incremental clustering [4,5,2]. In these methods, a threshold value is directly or indirectly defined and used to decide whether a new cluster must be created or not depending on the minimum distance between the new data point and the existing cluster centers. Some examples of these methods are ART Networks [8], VQ and its extensions [9,10], ECM [5], etc. The main drawback of these methods is the strong dependence on the minimum inter-clusters threshold value. A bad setting of this threshold may lead to either over-clustering (a data cluster is divided into several small ones), or under-clustering (different clusters are erroneously merged to form one big cluster). Another major disadvantage of distance-based incremental clustering is the sensibility to noise and outlier points. Therefore, we believe that density-based techniques are much more suitable for incremental clustering. Contrary to distance-based ones, density-based techniques do not depend on an absolute threshold distance to create new cluster. They rely on density measures to make a global judgement on the relative data distribution. The representativity of a given sample in a density-based clustering process can be evaluated by its potential value. The potential of a sample is defined as inverse of the sum of distances between a data sample and all the other data samples [11]:(9)Pot(x→(t))=11+∑i=1t−1∥x(t)−x(i)∥2A recursive method for the calculation of the potential of a new sample was introduced in [6] under the name of eClustering method. The recursive formula avoids memorizing the whole previous data but keeps – using few variables – the density distribution in the feature space based on previous data. The potential of each new instance is thus estimated as follows:(10)Pot(x→(t))=t−1(t−1)α(t)+γ(t)−2ζ(t)+t−1where(11)α(t)=∑j=1nxj2(t)(12)γ(t)=γ(t−1)+α(t−1),γ(1)=0(13)ζ(t)=∑j=1nxj(t)ηj(t),ηj(t)=ηj(t−1)+xj(t−1),ηj(1)=0Introducing a new sample affects the potential values of the centers of existing clusters, which can be recursively updated by the following equation:(14)Pot(μi)=(t−1)Pot(μi)t−2+Pot(μi)+Pot(μi)∑j=1n∥μi−x(t−1)∥j2If the potential of the new sample is higher than the potential of the existing centers then this sample will be a center of a new cluster. The potential value of such new center is initialized by 1. This density-based method had been first used for TS systems in [6]. Our system in [1] uses eClustering. Given that our focus here is placed on supervised incremental learning for classification problems, we can suppose that the addition of new classes can be explicitly pointed out by an external signal. A new rule is automatically created in our system for the first data sample from a new class. For the next samples, eClustering is used to detect the emergence of new regions with relative high data density. The data pointx→tthat triggered the creation of new rule (new class or new region of interest) is considered as prototype center (μr+1→=x→t). An initial diagonal variance/covariance matrix is associated to the new prototype. The initial diagonal values are estimated as the average diagonal values of existing prototypes.The antecedent of each fuzzy rule in a FIS is represented by a prototype in multidimensional space, and this prototype can have different shapes (hyper-boxes, hyper-spheres, etc.). While creating new prototypes is done using incremental clustering as explained in the precedent section, the parameters of prototype position and shape should be continuously and incrementally re-estimated in evolving FIS in order to get an up-to-date representation. Antecedent adaptation technique depends on prototype shape. It can be generally divided into two steps: prototype position displacement, and prototype zone of influence re-estimation (box expanding in [4], radius update in [3], etc.). In our system [1], prototype centers are shifted and their covariance matrices are updated according to incoming samples.Weighted Recursive Least Squares method is used in most TS systems for learning consequent parameters in online manner. It is explained below how this method is used for TS consequent recursive estimation.Coefficient estimation of TS consequent functions can be seen as a problem of solving a system of linear equations expressed as follows:(15)(Ψi+δI)Π=Yii=1,2,…,twhere11It is worth mentioning that the term t in this paper has no temporal meaning. Given that the system is fed in discrete manner, t is only incremented at the arrival of a new data.Π is the matrix of all the parameters of system linear consequences.Π=π→11π→12⋯π→1kπ→21π→22⋯π→2k⋯⋯⋯⋯π→r1π→r2⋯π→rkk represents the number of classes and r is the number of fuzzy rules,Ψi=[β1(x→i)x→i,β2(x→i)x→i,…,βr(x→i)x→i]is the input vector (a vector of real values representing the input features) weighted by the activation degrees of prototypes, and Yiis the ground truth output vector (a vector of binary values in classification problems). In order to stabilize and to smooth the solution, a regularization term δ (known as Tychonoff regularization) is added to the equation. Solving this system of linear equations by the least squares method consists in minimizing the next cost function:(16)E=∑i=1tΨiΠ−Yi2+ωΠ2where ω=δ2 is a positive number called the regularization parameter, and I is the identity matrix. The solution that minimizes the cost function of Eq. (16) is:(17)Πt=(∑i=1tΨiΨiT+ωI)−1.∑i=1tΨiYiWe rewrite Eq. (17) by replacing(∑i=1tΨiΨiT+ωI)and(∑i=1tΨiYi)by Φtet Zt, respectively:(18)Πt=Φt−1.ZtBy isolating the term corresponding to i=t, one can rewrite Φtas follows:(19)Φt=∑i=1t−1ΨiΨiT+ωI+ΨtΨtTThus, the matrix Φ is updated using the following recursive formula:(20)Φt=Φt−1+ΨtΨtTIn the same way, a recursive formula to update the matrix Z can be deduced:(21)Zt=Zt−1+ΨtYtIn order to calculate Πtusing Eq. (18),Φt−1need to be calculated. This can be done using the following lemma:Lemma 1Let A=B−1+CD−1CT, the inverse of A is given as follows:(22)A−1=B−BC(D+CTBC)−1CTBTo apply Lemma 1 on Eq. (20), we make the following substitutions:A=Φt,B−1=Φt−1,C=Ψt,D=1Thus, the recursive formula of the inverse of the matrix Φ can be obtained as follows:(23)Φt−1=Φt−1−1−Φt−1−1ΨtΨtTΦt−1−11+ΨtTΦt−1−1ΨtΠ is then calculated as next:(24)Πt=Φt−1Zt=Φt−1(Zt−1+ΨtYt)=Φt−1(Φt−1Πt−1+ΨtYt)=Φt−1((Φt−ΨtΨtT)Πt−1+ΨtYt)=Πt−1−Φt−1ΨtΨtTΠt−1+Φt−1ΨtYt=Πt−1−Φt−1Ψt(Yt−ΨtTΠt−1)The initialization of the algorithm consists in determine two quantities:•Π0: In practice, and when no prior knowledge is available, Π0 is initialized by 0.Φ0−1: GivenΦt=∑i=1tΨiΨiT+ωIand by putting t equals 0, we find thatΦ0−1=ω−1I, where ω is the regularization parameter.Large values of ω−1 (between 102 and 104) are generally adopted when signal-to-noise ratio on input vector is high, which is the case in our system especially at the beginning of learning where significant modifications are applied on the prototypes. The impact of ω−1 value according to input noise level is discussed in [12]. When a new rule is created, its parameters are initialized by the average of the parameters of other rules:(25)Πt=π→1(t−1)1π→1(t−1)2⋯π→1(t−1)kπ→2(t−1)1π→2(t−1)2⋯π→2(t−1)k⋯⋯⋯⋯π→r(t−1)1π→r(t−1)2⋯π→r(t−1)kπ→(r+1)t1π→(r+1)t2⋯π→(r+1)tkwhere(26)π→(r+1)tc=∑i=1rβi(x→t)π→i(t−1)cThe matrix Φ−1 is extended as follows:(27)Φt−1=ρΦt−1−100Ω−1⋯0⋯⋯⋯0⋯Ω−1where ρ=(r2+1)/r2. This recursive least squares (RLS) consequent learning is used in most TS systems.We sum up the main features of the evolving TS systems mentioned in this section in Table 1.It can be noticed that the antecedent is learned independently from the consequent learning in the abovementioned systems. However, few other approaches propose a global learning of fuzzy rule-based models.The authors of [13] proposed an extension of the classic neural networks error back-propagation method based on the gradient descent called ANFIS (Adaptive Neuro-Fuzzy Inference Systems). In this extension, a hybrid learning method that combines the gradient method and the least squares method is used. Each epoch of this hybrid learning procedure is composed of a forward pass and a backward pass. In the forward pass, the parameters (weights) in the output layer are identified using the least squares estimation. Then, the error rates propagate from the output toward the input end and parameters in the hidden layer(s) are updated the gradient descent method. Based on the functional equivalence between adaptive networks and fuzzy inference systems, the hybrid learning method is used to learn a fuzzy inference system of Takagi Sugeno's type. Thus, consequent parameters are first estimated using least squares, and premise parameters are then updated using error-propagation gradient descent. Despite the wide use of ANFIS in different applications, we can note that it cannot be used in an evolving learning context because of its fixed structure. However, it is still a robust learning algorithm for adaptive classification systems.EFuNN (Evolving Fuzzy Neural Networks) [14] is a fuzzy rule-based classification system in which each rule represents an association between a hypersphere from the fuzzy input space and a hypersphere from the fuzzy output space. The pair of fuzzy input-output data vectors (xf, yf) is allocated to a rule riif xffalls in the input hypersphere and yffalls in the output hypersphere. The former condition is directly verified using a local normalized fuzzy distance, whereas the latter is indirectly verified by calculating the global output error. EFuNN algorithm starts by evaluating the local normalized fuzzy distance between the input vector and the existing rules in order to calculate the activations of the rule layer. The activation of the fuzzy output layer is calculated based on the activations of input layer and the centers of hyperspheres in output layer. The centers of input hyperspheres are adjusted depending on the distance between the input vector and rule nodes, and centers of output hyperspheres are also adapted using a gradient descent. However, a supervised adaptation of the input hyperspheres centers is also possible based on a one-step gradient descent method. Although EFuNN structure has been presented differently, it is functionally equivalent to Mamdani fuzzy inference system. The distance-based incremental clustering method used in EFuNN in both input and output space depends strongly on the sensitivity threshold.As mentioned before, we proposed in [1] an evolving TS classification system with first-order consequent structure. We used an enhanced antecedent structure so that each prototype is represented by a center and a covariance matrix.Incremental learning of TS models is generally divided into two independent learning processes: antecedent learning and consequent learning. This work focuses on finding an optimal antecedent structure that can improve the overall system performance.Antecedent learning can be simply done in straightforward recursive statistical manner so that prototype center and covariance matrix are re-estimated after each new data sample in order to give it the rotated hyper-elliptical form. All samples have the same weight and antecedent structure is built in unsupervised way; i.e. system output is not considered in the learning process. Our system with this simple method will be called ILClass-stat and presented in Section 3.1.Looking for new techniques that optimize antecedent structure and enhance system performance, we presented in [1] a global learning paradigm for evolving TS classifiers. The core idea of this paradigm is to learn the antecedent and the consequent part in correlated manner so that the output error is used to supervise the antecedent learning process. The goal of this supervision is to focus learning on samples with high output error and thus to reduce misclassification errors. To the best of our knowledge, this is the first system in which output feedback is employed in antecedent learning. This approach is called ILClass-feed and explained in Section 3.2.Although ILClass-feed had shown good results [1] by improving the long-term system accuracy for several incremental classification problems, it had been systematically outperformed by ILClass-stat in the short-term (at the beginning of learning process where only few data are available). The main purpose of this paper is to cope with this problem by proposing a new solution that can be efficient during the whole learning process, i.e. good performance at the early learning stage coupled with the best possible long-term performance. This new solution will be explained in Section 3.3 and called ILClass-hybrid.For each new samplex→t, the center and the covariance matrix of the prototype that has the highest activation degree are updated.The recursive estimation of the center can be found as follows:(28)μt→=(1−α)μ→t−1+αx→t(29)α=1twhere t represents the number of updates that have been applied so far on this prototype.The covariance matrix can be recursively computed as follows:(30)At=(1−α)At−1+α(x→t−μ→t)(x→t−μ→t)TAll incoming samples are treated equitably in the above formulas that are straightforward statistical mean and covariance calculations.The fundamental idea of the novel approach is to use an output error feedback in the antecedent adaptation (as illustrated in Fig. 3), contrary to existing approaches where the antecedent is learned independently from the consequent learning and the overall output. The purpose of integrating the output signal in the antecedent learning is to bias it towards the incoming points with high output error so that the more the error is high the more will be the influence of this point on the antecedent adaptation. Thanks to this improvement, it becomes possible in the antecedent adaptation to focus on the data points that are misclassified by the system or hardly well-classified, and to put less focus on non-problematic points.To formulate this concept, we introduce in the antecedent adaptation formulas a weight value calculated for each sample so that α is calculated as follows:(31)α=wtwcumul(32)wcumul=∑i=1twiwherewrepresents the “weight” associated to the data pointx→t. The value ofwis related to the output error committed by the system for the current pointx→t.In classification problem, the quality is perceived by the user from the number of misclassification errors committed by the system. The value ofwcan be calculated so that it becomes higher for points with a high risk of misclassification. The risk of misclassification of each sample is estimated by its confusion degree. The confusion degree is inversely proportional to the difference between the score of the true class ofx→, and the highest score within the other (wrong) classes. The confusion-driven antecedent learning is then implemented by calculatingwfor each incoming sample as follows:(33)w=(1−[ycˆ−ync])2w∈[0,1]whereycˆis the system output corresponding tocˆthat represents the true class ofx→t, and(34)ync=argmaxyc;c=1,…,k&c≠cˆThe value ofwtends toward 0 whenx→tis “strongly” recognized, and toward 1 when it is misrecognized. The risk of misclassification associated tox→tis proportional to the confusion degree estimated by the value ofw(see Fig. 4).System quality in regression and time-series prediction problems is related to the difference between system output vector and real output vector, and can be measured using different indications.wcan be calculated in these cases by the distance between system output vectory→and ground truth vectory→ˆ(contains 1 for the true class and 0s for the rest). Thus, the value ofwcan be estimated as follows:(35)w=12∑c=1k∣yˆc−yc∣where k is the number of classes. The proposed idea can be implemented using different quality measures, like R-squared adjusted [2], non-dimensional error index (NDEI) [5], or normalized RMSE [6]. However, the focus in this paper is placed on classification problems and the confusion-based calculation (Eq. (33)) will be employed all along the experimental section.As explained above, ILClass-feed uses system scores to estimate the weight of each sample. Antecedent structure is then highly influenced by system performance. When experimenting it, ILClass-feed was able to outperform ILClass-stat after a specific period of incremental learning. Nevertheless, results have shown the relatively poor performance of ILClass-feed at the early phase of learning so that it is always beaten by ILClass-stat method. Fig. 5(a) (using PenDigits dataset) illustrates this phenomenon and the intersection point of the two curves. These results can be explained by the system instability at the beginning of learning where only few data samples are learned and important fluctuations appear at system output during this early stage. Therefore, antecedent learning in ILClass-feed will suffer from this instability and need a period of time to reach its expected good performance. The more system output gets stable, the more ILClass-feed can enhance its performance, as shown in Fig. 5(a). On the other hand, ILClass-stat copes well at the early stage allowing a stable statistical prototype initialization, but its performance stagnates for the long term. It is worth reminding that achieving acceptable early performance is mandatory in many applications where user is involved in the learning cycle.An ideal solution consists then in proposing a new method that profits of the advantage of ILClass-stat for the short term, and that of ILClass-feed for the long term. The objective is to get the performance illustrated by the black curve in Fig. 5(b).To cope with this problem, we propose a new approach, called ILClass-hybrid, that allows a gradual sliding between ILClass-stat and ILClass-feed. It is worth reminding that one of the main criteria in the learning algorithm is to be completely free of problem-depended parameters. Thus, the sliding mechanism from ILClass-stat to ILClass-feed is automatically controlled by a system stability measure represented by λ, as follows:(36)α=λ1t+(1−λ)wtwcumul(37)λ=nbErrtλ∈[0,1]where nbErr is the accumulated number of misclassification committed on the incoming samples. Early values of λ are close to 1 because of the high number of error at the beginning of incremental learning process. Then, its value tends more-or-less rapidly towards small values close to 0. Using Eq. (36), ILClass-hybrid automatically adjusts the combination of ILClass-stat and ILClass-feed according to the relative error level observed at system output.Thus, the formulas used in ILClass-hybrid can be summed up as follows:Experiments in this paper will be mainly focused on studying the performance of ILClass-hybrid as an optimal compromise between ILClass-stat and ILClass-feed. The three models are evaluated for different incremental classification problems using benchmark datasets. Short- and long-term performance comparisons between the three models are presented in this section.In addition to the validation of ILClass-hybrid, we present in this section another original point of this paper that consists in studying the behaviour of an evolving TS classifier when adding new unseen classes to the system. In this novel evaluation scenario, the aim is to examine the system reaction to the addition of new classes, and to test its performance recovery speed.The benchmark datasets used in our tests are first presented, then some details about our experimental protocol are given. Results are then presented and divided into two parts: results for synchronized class learning, and results for unsynchronized class adding.We evaluate our algorithms on several well-known classification benchmarks form the UCI machine learning repository [15]. We followed two criteria in selecting the datasets:•They should represent multiclass problems. Our learning algorithms are optimized for classification problem with more than two classes.The number of samples per class in each dataset should be large enough for two reasons. The first is to have a large learning dataset that allows continuing the incremental learning as far as possible and to examine the behaviour of the algorithms in the long term. The second reason is to have a large test dataset to be able to correctly evaluate the classifier during the incremental learning process as seen later. The large size of the test dataset helps as well to neutralize as much as possible the order effect on the results.Respecting the last two criteria, the next datasets had been chosen from UCI machine learning repository to be used in our experiments:•CoverType: The aim of this problem is to predict forest cover type from 12 cartographical variables. Seven classes of forest cover types are considered in this dataset. A subset of 2100 instances is used in our experiments.PenDigits: The objective is to classify the ten digits represented by their handwriting information from pressure sensitive tablet PC. Each digits is represented by 16 features. The dataset contains about 11,000 instances.Segment: Each instance in the dataset represents a 3×3 region from 7 outdoor images. The aim is to find the image from which the region was taken. Each region is characterized by 19 numerical attributes. There are 2310 instances in the dataset.Letters: The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. Each letter is represented by 16 primitive numerical attributes. The dataset contains 20,000 instances.JapaneseVowels: The goal is to distinguish nine male speakers by their utterances of two Japanese vowels. Each vector is characterized by 14 values. The dataset contains 10,000 samples.The characteristics of the five datasets are summarized in Table 2. The five datasets used in our experiments vary by both the number of features (number of data space dimensions), and the number of classes, which allows testing our algorithms on different multiclass problems.A repeated 10-folds cross-validation (CV) data partitioning protocol is employed in our experiments. For each CV, the samples of training subset (90% of entire dataset) are sequentially introduced to the system in 10 different random orders. Thus, experiment for each dataset is repeated 100 times and average results are presented in the figures below. The test subset is used to estimate the recognition rate achieved by the classifier during the incremental learning process. The term “learning subset” is used to identify the group of instances learned by the system between each two consecutive tests. When a new class appears in a given learning subset Si, test samples of the same class are added to the test subset Stest. After learning each new Si, a new evaluation point is estimated using Stestand the curves drawn in the next figures represent an interpolation of these points. This incremental learning protocol is called periodic held-out protocol (Fig. 6).We present in Fig. 7the results of the three models for five different benchmark datasets. In these figures, the evolution of the generalization misclassification rate of the three models is presented, from the very beginning of the incremental learning process (few samples per class), until a relatively advanced learning state (limited by the size of the used datasets). We show in the same figures the relative reduction of misclassification rate achieved by ILClass-hybrid compared to ILClass-stat and ILClass-feed. All classes in this first part of experiments are introduced to the system in quasi-synchronized manner (random sample orders are applied without any constraint on sample classes).The obtained results are also synthesized in Tables 3–7where the performance is measured at four different moments of incremental learning (i.e. different number of learned samples) that represent short-term and long-term viewpoints. In addition to the ILClass-stat, ILClass-feed and ILClass-hybrid, the performance obtained by the evolving TS approach eClass [3] is given in the tables. Besides, we present in the same tables the misclassification rates obtained by two batch classifiers: radial basis function (RBF) classifier and multilayer perceptron (MLP, one hidden layer with 10 neurons). The implementation of these two classifiers is provided by Tanagra software.The obtained results confirm the analysis given in Section 3.3 about the difficulties that face ILClass-feed in the early learning phases due to high perturbation of antecedent learning. Nonetheless, they approve the considerable gain of performance that can be achieved by ILClass-feed in the long term, compared to ILClass-stat method.More importantly, results show the very good performance of ILClass-hybrid that almost covers the optimal combined performance obtained by ILClass-stat end ILClass-feed at both short- and long-term learning moments. It can be noted that ILClass-hybrid allows in average about 15% of error reduction when compared to ILClass-feed at the early stage of learning. This sizeable gain is very important in many application contexts in which online incremental learning is required to be sufficiently fast. The short-term performance can play a key role in user acceptance of evolving classifiers. The short-term enhancement in ILClass-hybrid does not sacrifice the good performance of the output feedback model (ILClass-feed) and ILClass-hybrid also achieves about 15% of error reduction when compared to ILClass-stat after a long-term incremental learning.The experiments presented so far represent a simple and straightforward incremental learning scenario, in which all the classes are presented to the classifier together from the beginning of the incremental learning process. In addition to the continuous refinement of its knowledge base, one of the main features of an evolving classification system is the capacity of learning new unseen classes without suffering from the “catastrophic forgetting” phenomenon. This feature might be mandatory in several real application areas. Therefore, we present a second experiment that imitates this real context so that the system starts with a subset of classes, and the rest of them are introduced after a specific while of learning. We aim at studying the behaviour of the different evolving systems and their ability to learn new class of data without fully destroying the knowledge learned from old data. We maintain the repeated 10-fold cross-validation data partitioning for this experiment. For each CV, we introduce the first half of the training subset with only 60% of the classes, then all the classes are learned during the second half. Evidently, samples from unseen classes are not considered in the test subset during the first learning phase. Fig. 8shows the results of the experiment (it is useful to remind that these results represent the average of 100 runs). We note that ILClass-hybrid resists better when introducing new classes. Concentrating the antecedent learning on confusing samples results in faster fall in misclassification curve.

@&#CONCLUSIONS@&#
