@&#MAIN-TITLE@&#
Estimating the focus of expansion in a video sequence using the trajectories of interest points

@&#HIGHLIGHTS@&#
Development of an algorithm for the estimation of the focus of expansionAlgorithm based on the cross ratio property applied to interest point trajectoriesThe algorithm gives accurate focus of expansion localization even for low textured scenes.

@&#KEYPHRASES@&#
Focus of expansion,Optical flow,Interest point,Point trajectory,Cross ratio,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
When a camera moves across a rigid scene, the apparent motion of the imaged points can be used to infer the relative shift of the camera with respect to the scene. For the general case, the problem consists in the computation of the translational and rotational vectors, and is called ego-motion [1]. The computation of ego-motion plays an important role in some vision systems, such as Visual Odometry, 3D reconstruction, time-to-impact estimation or obstacle detection and avoidance.When the rotational component is null, that is, the camera moves in a straight line, the problem reduces to the computation of the translational vector, and the image of this vector on the image plane is called the Focus of Expansion (FoE) when the camera moves forwards, or the Focus of Contraction (FoC) when it moves backwards, see Fig. 1. Although FoE and FoC refer to opposite directions, their properties are very similar, and we will only refer to the former, recalling that the differences in the computation of the later are minimal.For its computation, many algorithms have been proposed. In the classic approach, the focus of expansion is computed from the optical flow field between two time-varying frames, which can be obtained from several algorithms [2]. However, technical challenges still exist for general scenes. Typical inaccuracies raise in unconstrained environments, such as road scenes where a large proportion of the image appears untextured, for instance, the sky or a textureless pavement, and optical flow vectors for these areas do not exist or are erroneous. Another source of error can be caused by vibrating platforms. Although many vision benchmarks are available for research, such as the KITTI Benchmark [3] or the CMU Visual Localization Data Set [4], these sequences are recorded with complex camera setups to prevent such problems. For more basic setups, however, any instability can cause the FoE computation to decrease its accuracy.To face these problems, we propose a new method based on the estimation of the vanishing point for multi-frame interest point trajectories. The paper is structured as follows: In Section 2, a brief overview of different FoE estimation approaches is provided. In Section 3 we introduce our algorithm for the FoE computation based on the trajectories of interest points. A comparison of our algorithm with other works is given in Section 4, while Section 5 concludes the paper.

@&#CONCLUSIONS@&#
In this paper, we have proposed a new algorithm for the computation of the focus of expansion for a video sequence. The algorithm uses the trajectories of interest points to compute the vanishing point for each trajectory, by means of the cross ratio property. A number of challenging videos, both virtual ones generated with Blender and real ones recorded with a smart phone, along with some sequences of the public KITTI benchmark have been used to test the algorithm. Results showed that the proposed algorithm can improve the performance of classical algorithms for challenging sequences. This is specially relevant for low textured scenes, for instance, traffic sequences with textureless top (sky) and bottom (road), and for the cases where camera orientation with respect to the moving platform makes the focus of expansion lie outside the image plane. Furthermore, a Java implementation of the proposed algorithm can reach up to 15 fps on WVGA (800×480 pixels) video resolution, showing its viability for real-time applications. Limitations of the proposed algorithm arise when camera motion is not constant. Thus, when camera acceleration is significant, the algorithm starts decreasing its performance.The proposed paper allows us to glimpse the potential of using the trajectories of interest points for ego-motion tasks. Although we have focus our work on the computation of the focus of expansion, thus limiting the applicability to straight trajectories, work will concentrate in widening the study to not straight paths, allowing us to compute not only translation, but also the rotational vector related with the camera ego-motion.