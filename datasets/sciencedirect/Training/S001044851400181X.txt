@&#MAIN-TITLE@&#
Correct resolution rendering of trimmed spline surfaces

@&#HIGHLIGHTS@&#
Tight estimates relate domain resolution to screen resolution of trimmed surfaces.Based on the estimates, sub-pixel accuracy of a display algorithm is proven.The algorithm has been implemented within the standard graphics pipeline.The implementation enables interactive editing of trimmed surfaces.The implementation has a small memory footprint.

@&#KEYPHRASES@&#
Trimming,Spline,Accurate,Real-time,Scan density,

@&#ABSTRACT@&#
Current strategies for real-time rendering of trimmed spline surfaces re-approximate the data, pre-process extensively or introduce visual artifacts. This paper presents a new approach to rendering trimmed spline surfaces that guarantees visual accuracy efficiently, even under interactive adjustment of trim curves and spline surfaces. The technique achieves robustness and speed by discretizing at a near-minimal correct resolution based on a tight, low-cost estimate of adaptive domain griding. The algorithm is highly parallel, with each trim curve writing itself into a slim lookup table. Each surface fragment then makes its trim decision robustly by comparing its parameters against the sorted table entries. Adding the table-and-test to the rendering pass of a modern graphics pipeline achieves anti-aliased sub-pixel accuracy at high render-speed, while using little additional memory and fragment shader effort, even during interactive trim manipulation.

@&#INTRODUCTION@&#
A standard approach to designing geometry in computer aided design is to “overfit”, i.e. create spline surfaces that are larger than needed and subsequently trim the surfaces back to match functional constraints or join to other surfaces (see Fig. 1). This approach persists both for historical reasons and for design simplicity: for historical reasons in that overfitting and trimming pre-dates alternative approaches such as subdivision surfaces  [1,2] and finite geometrically-smooth patch complexes (see e.g.  [3,4]); for practical reasons, in that it is often more convenient to control the shape of a signature piece in isolation than when constraints have to be taken into consideration. For example, a car’s dashboard can be prepared in one piece without consideration of cut-outs for instrumentation and the steering column.The prevailing practice in computer aided design environments is to generate and display a fixed-resolution triangulation on the CPU and transfer it to the GPU. This process interrupts the design process and can yield unsatisfactory results as closeups reveal a jagged or otherwise incorrect approximation. Conversely, an overly fine triangulation wastes resources: there is no need to highly resolve a complex trim curve when the corresponding surface measures only a few pixels on the screen.The computer graphics community has developed a number of clever techniques, reviewed in Section  2, to deliver real-time display of trimmed spline surfaces. The present paper advances the state-of-the-art by carefully predicting how fine an evaluation of the trim curves results in correct trim decisions at screen resolution. This tight prediction makes it possible to construct, as a prelude to each modified view or model rendering pass, a slim and adaptive trim-query acceleration table that supports a light-weight per-fragment trim test. This simple add-on to any rendering pass is efficient enough to allow interactive trim-curve editing.Overview. Section  2 reviews existing techniques for fast rendering of trimmed spline surfaces. Section  3 reviews basic concepts and establishes notation. Section  4 explains how correct resolution can be determined. Section  5 explains how to build and use the trim-query acceleration table. Section  6 measures the performance of a full implementation.The trim decision is to determine to which side, of a set of trim curves, lies theuv-pre-image of a pixel. The underlying challenge is the same as when determining the fill region of a planar decal  [5]—except that in planar filling, the accuracy of rendering is measured in theuv-plane, while for trimmed surfaces, the accuracy is measured in screen space, i.e. after applying the non-linear surface map followed by projection onto the screen.A straightforward approach, used in 2D vector graphics  [6, Section 8.7], is to ray-test: each pixel’suv-pre-image in the domain sends a ray to the domain boundary to determine the number of intersections (and possibly the intersection curve orientation). The intersections decide whether the fragment is to be discarded. For example, Pabst et al.  [7] test scan-line curve intersection directly in the Fragment Shader. Direct testing without an acceleration structure is impractical since the number and complexity of intersections can be unpredictably high so that robustness and accuracy are difficult to assure within a fixed time. It pays to pre-process the trim curves and map them into a hierarchical search structure in order to localize testing to a single trim curve segment. For example, Schollmeyer et al.  [8] break the segments into monotone pieces and test scan-line curve intersection in the Fragment Shader by robust binary search. This pre-processing is view-point independent but becomes expensive for interactive trim-curve manipulation.An alternative is to generate a trim texture: theuv-pre-image of each fragment indexes into a texture that returns whether the point is to be trimmed or not. Such a trim texture can be generated in a separate rendering pass, using the stencil buffer  [9]. The trim-test is highly efficient, requiring only a single texture look-up to classify a domain point. However trim textures need to be recomputed for every viewpoint change and the separate pass can noticeably lower overall performance as each segment of every trim curve generates and atomically inserts a triangle into the stencil buffer. Moreover, the trim-texture represents a uniform, limited resolution sampling of theuv-domain. Projective fore-shortening must be accounted for separately: when rendering a curved surface in 3-space, the non-uniform distortion of the domain caused by the non-linear map of the surface followed by perspective projection can result in low render quality even where the texture resolution is high.Another pre-processing choice is to convert the piecewise rational trim curves into an implicit representation, via resultants (see e.g.  [10–12]). Evaluating the resultant will generate a signed number and the sign can be used to determine whether a pixel is to be trimmed. In principle, this yields unlimited accuracy. However, there are several caveats to this approach. First, the use of resultants increases the degree and the number of variables. The coefficients of the implicit representation are typically complicated expressions in terms of the coefficients of the trim curve segments. Therefore the evaluation in the Fragment Shader can be expensive even if the derivation of the implicit expression is done off-line prior to rendering. There are more efficient approaches than full implicitization, e.g.  [13]. While useful for ray-tracing, these expressions do not presently yield a signed test as required for trimming. Second, implicitization converts the entire rational curve, not just the required rational piece. Use of resultants therefore requires a careful restriction of the test region, for example by isolating bounding triangles in the domain that contain a single indicator function whose zero level set represents the trim. Determining such restrictions is in general tricky since the implicit can have extraneous branches. For conics, the conversion expressions are sufficiently simple and for fixed shapes, such as fonts, determining bounding triangles can be done offline once and for all  [14]. For less static scenarios, also pre-processing of conics and triangulation of the domain is not easily parallelized. Stencil buffers can avoid careful triangulation  [5] but the fixed resolution inherits the challenges of texture-based trimming.Computing the trim curves from CSG operations addresses a related but somewhat different problem than rendering. Here the trim curves (exact intersection pre-images) are not given. For simple CSG primitives such as quadrics the render decision can be based on an implicit in/out test. For more complex B-reps, faceted models are compared and proper resolution of the B-rep into facets remains a challenge. Practical implementations use stencil operations, depth and occlusion testing  [15,16].Coordinates and projection. In the OpenGL graphics pipeline [17, Section 13.6], the non-orthogonal projectionP(xyz1)→(xcyczcwc)≔(P110000P220000P33P3400−10)(xyz1)maps camera coordinates(x,y,z,1)Twith the camera is at the origin pointing in the negativez-direction, to clip coordinates(xc,yc,zc,wc)T. The entriesP33≔(z¯−z¯)/(z¯+z¯)andP34≔2z¯z¯/(z¯−z¯)define two planes at depthz¯(near) andz¯(far) such that any geometry with depth outside the range[z¯,z¯]is clipped. Perspective division converts the clip coordinates into normalized device coordinates(xd,yd,zd)≔(xc,yc,zc)/wc, and the viewport transformation converts normalized device coordinates to screen coordinates:(x̃,ỹ)≔(Wxd/2+Ox,Hyd/2+Oy). HereWandHare the width, respectively height of the viewport in pixels andOxandOyare the screen space coordinates of the viewport center, typicallyOx=W/2,Oy=H/2. Together, the projection fromR3to the rasterized screen isP:R3→R2wx≔P11W2,wy≔P22H2,(1)(x,y,z)→(x̃,ỹ)≔(wxxz+cx,wyyz+cy).Surfaces and trim curves. Models consist of rational parametric surfaces(2)x:U⊊R2→R3(u,v)→x(u,v)≔(x(u,v)y(u,v)z(u,v))defined on a domainU. OftenU≔[0..1]2, the unit square, and the surface (patch) is in tensor-product form with basis functionsbk,x(u,v)≔∑i∑jcijbi(u)bj(v).To trim a patch means to restrict its domain to one side of a piecewise rational trim curve(3)γ:T⊊R→Ut→γ(t)≔(u(t),v(t)).There can be multiple trim curves per patch. When trim curves are nested, their orientation can be used to determine which side is trimmed away. A simplified convention applies an alternating count from a domain boundary.Trim curves are often rational approximationsγ1(t),γ2(t)to the solutions of the surface–surface intersection (SSI) problem,x1(u1,v1)=x2(u2,v2)∈R3. We are not concerned with solving such potentially hard SSI systems of 3 equations in 4 unknowns, whose solution is generically a pair of non-rational algebraic curves. Rather we assume that the trim curves are given as rational curves and address the challenge of efficient accurate display of the resulting trimmed surface.Trim curves can also be artist-defined or they can reference planar shapes. Such shapes, for example fonts, are mapped to the surface reshaped by the curvature of the mapx.Faithful surface tessellation. Ray-casting guarantees that each pixel represents a correctly-placed surface piece and finds each pixel’suv-pre-image. Remarkably, such pixel-accurate rendering can also be achieved using the highly efficient standard graphics pipeline. In  [18], a compute shader determines a near-optimal (minimal) tessellation factorτfor each patchx, so that evaluatingxon aτ×τpartition of its domainUyields a proxy triangulationxˆ∈R3ofxsuch that its image under the screen projectionPof (1) agrees with that of the correct image. That is the differencePx(u)−Pxˆ(u)is below the visible pixel threshold. We callxˆa faithful triangulation ofxand will usexˆto render the trimmed surfaces.Since any screen has a fixed discrete resolution, trimmed surfaces can and need only be resolved up to pixel width (sub-pixel width in the case of subsampling for anti-aliasing). Our approach is to pull back the pixel-grid to the domainUand partitionUintouv-cells—in such a way that no two pixels’uv-pre-images share oneuv-cell (cf. Fig. 3). This guarantees each pixel, in particular of a group straddling the projection of a surface trim, its individual trim test. Next we evaluate the trim curve in the domainUso that the resulting broken line differs from the exact trim curve by less than oneuv-cell. The two discretizations, of the domainUand of the curveγ, provide a consistent, correct resolution in the sense that testing theuv-pre-image of a pixel(x̃i,ỹi)against the broken line yields a correct trim decision up to pixel resolution.For a non-linear surfacexfollowed by a perspective projectionP, pulling the pixel-grid back exactly is not practical since the Jacobian ofPxcan vary strongly. Multi-resolution can accommodate adaptively scaleduv-cells, but a complex hierarchical lookup slows down each fragment’s trim test. We therefore opt for a simple two-level hierarchy. At the first level, we partition the domainUintonVv-stripsVi:(4)Vi≔{(u,v)∈U,νi≤v<νi+1}.Eachv-strip is a ‘fat scan-line’ where theu-coordinate is free while thev-coordinate is sandwiched between an upper and a lower bound. The default choice is to space theviuniformly and setnV=τ, whereτis the surface tessellation factor already computed according to  [18]. At the second level, eachv-stripViis uniformly partitioned once more in thev-direction into a minimal numberμiofv-scan lines that guarantees correct trim resolution (see Fig. 4). The first level partition isolates the impact of any local feature requiring high resolution to just the relevantv-strip(s). To determine the critical numberμithat guarantees that the distance between the screen images of twov-scan lines is less than one pixel, we proceed as follows. By the mean value theorem, for somev∗∈[v,v+h],(5)|x̃(u,v)−x̃(u,v+h)|=h|x̃v(u,v∗)|,x̃v≔∂x̃∂v.If, for allv∈Viand thev-scan line-spacingh>0,(6)hρi(v)<1,v∈[νi..νi+1],ρi(v)≔max{supu|x̃v(u,v)|,supu|ỹv(u,v)|},then thex̃-distance between the screen images of the twov-scan linesx̃(u,vj)andx̃(u,vj+h)is less than a pixel and so is theỹ-distance. Therefore setting(7)μi≔⌈(νi+1−νi)supv∈[νi..νi+1]ρi(v)⌉guarantees correct resolution. Fig. 5(a) shows an artifact whenμiis chosen too small. Fig. 5(c) shows the correct and near-minimal choice. If the projection is orthographic and the surface is a faithful triangulation thenμiis simply the maximum size of thex̃and theỹprojection of the strip in pixels.Estimatingρi. Since for any reasonable view the near-plane of the scene is at some minimal distance to the viewer, i.e.z≥z¯>0, the expansion(8)x̃v=x̃xxv+x̃yyv+x̃zzv=wxz(xv−xzzv)is well-defined, although potentially large for smallz. For our (faithfully) triangulated surface,xandzare piecewise linear maps andxvandzvare piecewise constant. Determining an upper bound onρi(v)over the three vertices(uk,vk),k=1,2,3of each triangle△,ρ△≔maxk|1z|maxk|wx(xv−xzzv)|,and settingμito the per-strip maximum,(νi+1−νi)max△ρ△,△∩Vi≠0̸,typically yields a tight estimate. However, the estimateρ△can include (parts of) triangles outside the viewing frustum so that, if a user zooms in and a part of a triangle approaches the camera,zcan be arbitrarily small. Instead, using the pixel’suv-pre-image sent down through the graphics pipeline, we compute the analog of (8) for each pixelαas(9)ρα≔max{|x̃v(uα,vα)|,|ỹv(uα,vα)|}and set(10)μi≔(νi+1−νi)maxαρα,α∈Vi.Now parts of triangles outside the viewing frustum do not contribute, and if av-stripVilies outside the viewing frustum, it receives no votesραin (10) andμi=0. That is,μiprovides a correct upper bound onρi(v)for all visible samples, and that is exactly what is needed for correct resolution rendering.The overall algorithm is summarized as follows. Each trim curve writes itself, at the correct resolution (determined by thev-scan line densityμidefined in the previous section) into a slimu-intercept table. Each fragment then makes its trim decision by testing against the table entries.Initializing theu-intercept table. The key data structure is theu-intercept table. There is oneu-intercept table per sub-surface, e.g. a tensor-product spline patch complex withℓu×ℓvpieces. Theu-intercept table is an array of sizeμ×nwhereμ≔∑iμiis the total number ofv-scan lines andnis an upper bound on the number of trim curves that may cross av-scan line of the surface piece. The row of the table with index(11)basei+j,basei≔∑k=1i−1μk,j≔v−νiνi+1−νiμi,will contain a sorted list ofu-intercepts: the intersections of the (linear segments of the correctly tessellated) trim curvesγwith thev-scan line(u,v):v=νi+jμi(νi+1−νi). Eachv-stripVihas its own number of rowsμicomputed from the per-pixel densitiesραby a prefix sum and (10). The per-pixel densitiesραare computed via (8) at the end of the rendering pass before the next compute pass: the Fragment Shader has access toxandzand, the Geometry Shader provides the Fragment Shader with the Jacobian of each fragment’s triangle.Filling theu-intercept tables. (see Fig. 4) Intersectingv-scan lines with a piecewise rational trim curve can be tricky. However, the required, correctvresolution of the trim curve,mini(νi+1−νi)/μi, is known. Applying formula (9) withx̃v,ỹvreplaced byx̃u,ỹuyields au-evaluation density that guarantees correct resolution. (Fig. 5(b) illustrates insufficient trim curve tessellation.) The bounds of  [19] could be leveraged, but since the Compute Shader already uses slefe-based bounds to generate the faithful triangulationxˆaccording to  [18], we use the same estimators to determine the curve tessellation factor for correct resolution (as defined in Section  4). For the correct curve tessellation number, the Compute Shader threads calculate, for each trim curve segmentkin parallel, the end pointsγ(tk−1)andγ(tk). Each thread then inserts theu-coordinates of allv-scan line-intersections with the trim curve segment into theu-intercept table. A second generation of threads subsequently sorts all trim curve intersections of av-scan line by theiru-coordinates.Testing against theu-intercept table. To determine whether a fragment with pre-image(u,v)should be discarded, the Fragment Shader reads the row of the table determined fromvby (11) and locatesu, by binary search in the table (see Fig. 4(b)). The complexity of the binary search islog2n, i.e. 4 tests if the number of intercepts isn=16. The Fragment Shader then makes the trim decision based on the parity of the entry just smaller thanu(and possibly orientation hints).Fig. 6shows our mapping of accurate trim display onto the graphics pipeline. The main add-on is the Compute Shader pass, shown as the top row of the flowchart. The trim test is performed in the Fragment Shader. The Geometry Shader can be removed by adding its work to the Fragment Shader.Consistent intersections. Care has to be taken to avoid duplicate or missing intersections where thev-scan line intersects two consecutive trim curve segments at the common end point. If thev-scan line does not cross but just touches the two segments, either two or zero intersections should be recorded, not one. We achieve consistency by treating every segment as a bottom-open top-closed interval (see Fig. 7).Mergingu-intercept tables. To minimize overhead in launching a compute shader and memory allocation we can and do group together theu-intercept tables of several sub-surfaces, such as several tensor-product NURBS patches (see next).Jointly trimming multiple patches. The grouping in the previous paragraph was aimed at improving performance. It also makes sense to have collections of patches in irregular layout share one domain. For example, when patchesxk:Uk⊊R2→R3are joined in a geometrically-continuous fashion their charts are related by a reparameterization(ũ,ṽ):Uk→U⊊R2that maps the individual domains to a joint regionUin the plane. Our approach applies to this scenario with(u,v)replaced by(ũ,ṽ)and the joint trim curve specified inU. Fig. 8illustrates the use of such a joint domain for two multi-spline caps.Treating trim-data mismatches. When a CAD modeling-kernel exports a trim derived from an intersection, the algebraic trim curves are approximated by rational trim curves whose images only match up to system-default or user-set tolerances. It is not the job of the rendering engine to fill such gaps and adjust SSI tolerances: correct resolution should display such gaps and let the designer know. However, pixel dropout can also result from more subtle sub-pixel resolution mismatches. When multiple surfaces partly cover a pixel, the pixel’s sample location(s) may not be covered at all. Fig. 9(a) illustrates the concern. While this type of pixel dropout is tricky to deal with in the general setting  [20], the faithful triangulationxˆof our setup guarantees that these mismatches are of size less than one pixel. To cover these pixel-sized gaps, our algorithm additionally draws the patch trim boundariesxˆ∘γ(as images of the already correctly tessellated trim curves) and so achieves correct coverage Fig. 9(b).Multi-sample anti-aliasing. (m-MSAA) improves silhouettes and (trim) boundaries by testing object coverage atmlocations per pixel (compare Fig. 10(a)–(b) wherem=4). We add sub-pixel trim testing by decreasing the screen spacing ofv-scan lines in (6) so that the trim has sub-pixel accuracy. The Fragment Shader then corrects the coverage mask according to the per sub-pixel trim test result (see Fig. 10(c)). The main cost ofm-MSAA is in creating fineru-intercept tables, not in the Fragment Shader test.Opportunistic optimization. Whenever the view is unchanged, neither the surface tessellation nor theu-intercept table need to be recomputed. Whenever the geometry is unchanged, neither the surface slefe-boxes of the pixel-accurate patch rendering nor the trim curve partition need to be recomputed.

@&#CONCLUSIONS@&#
