@&#MAIN-TITLE@&#
Referral system for hard exudates in eye fundus

@&#HIGHLIGHTS@&#
A referral system for diabetic retinopathy can decrease the load on ophthalmologists.A referral system is developed by using combination of mathematical techniques.Referral system makes treatment of patient cost and time effective.The referral system has been tested on four fundus databases.We have examined the referral system using in two different scenarios.

@&#KEYPHRASES@&#
Exudates,Medical imaging,Eye fundus,Treatment,Vision,

@&#ABSTRACT@&#
Hard exudates are one of the most common anomalies/artifacts found in the eye fundus of patients suffering from diabetic retinopathy. These exudates are the major cause of loss of sight or blindness in people having diabetic retinopathy. Diagnosis of hard exudates requires considerable time and effort of an ophthalmologist. The ophthalmologists have become overloaded, so that there is a need for an automated diagnostic/referral system. In this paper a referral system for the hard exudates in the eye-fundus images has been presented. The proposed referral system works by combining different techniques like Scale Invariant Feature Transform (SIFT), K-means Clustering, Visual Dictionaries and Support Vector Machine (SVM). The system was also tested with Back Propagation Neural Network as a classifier. To test the performance of the system four fundus image databases were used. One publicly available image database was used to compare the performance of the system to the existing systems. To test the general performance of the system when the images are taken under different conditions and come from different sources, three other fundus image databases were mixed. The evaluation of the system was also performed on different sizes of the visual dictionaries. When using only one fundus image database the area under the curve (AUC) of maximum 0.9702 (97.02%) was achieved with accuracy of 95.02%. In case of mixed image databases an AUC of 0.9349 (93.49%) was recorded having accuracy of 87.23%. The results were compared to the existing systems and were found better/comparable.

@&#INTRODUCTION@&#
Diabetes is becoming one of the rapidly increasing health threats in the recent years [1,2]. WHO has suggested that around 347 million diabetes affected people are present in the world today. Among them a large number of people are undiagnosed and untreated [3]. It has been estimated that 80% of these people belong to middle or low income countries which cannot afford expensive treatments. Between 2005 to 2030 the death rate of diabetes affected people will double according to statistics of WHO [3]. The Diabetics׳ Institute of Pakistan has estimated that in Pakistan there are 12.9 million people suffering from this disease. It makes up about 10% of the total population. Around 3.5 million such patients remain undiagnosed due to poor medical conditions [4]. These figures are alarming.Hard exudates are among the most common artifacts found in the eye fundus image in people suffering from Diabetic Retinopathy. In most of the cases the presence of hard exudates suggests that the patient requires immediate referral to an ophthalmologist or medical expert for proper treatment of the disease. Usually the presence of hard exudates in the eye fundus also indicates the existence of other vision threatening anomalies. Manifestation of hard exudates can be exploited for diagnosis of Diabetic Retinopathy or alternatively Diabetes. If left untreated, the disease can seriously affect the patient, causing blurred vision and in the worst case scenario, blindness. The above mentioned statistics provided by WHO elucidates the rapid increase of the disease in the world, especially third world countries. The ophthalmologists are becoming more engaged and overloaded due to increasing number of patients. This problem establishes the need for an automated system for diagnosis/referral. This system will reduce the load on the ophthalmologists and medical experts resulting in more effective utilization of their energies. Digital imaging medical diagnostic tools have proven to be very effective when it comes to providing better medical facilities to low income or poor countries. The digital imaging diagnostic procedures are non-invasive, painless and patient-friendly. Such diagnostic/referral systems have already been launched in The Netherlands [5], United kingdom [6] and Australia [7]. A study conducted in United Kingdom suggests that using automated systems, for screening fundus images, at clinics reduces 36.6% load from the medical experts [8].In this paper a referral system for the condition of hard exudates in diabetic retinopathy has been proposed. The proposed referral system uses SIFT [9] to extract features/descriptors from the images, K-means clustering [10] for making Visual Dictionaries (VD) [11–14] and a simple binary class support vector machine (SVM) [15] for classification. Section 2 gives a brief introduction about hard exudates. In Section 3 the proposed technique consisting of training and testing phases has been discussed. Section 4 explains how the dataset is constructed and experiments are designed. Section 5 gives the details of obtained results. In Section 6 conclusions have been drawn.The hard exudates visible in the eye fundus images are usually of yellow color but may also be found in white color [16]. Hard exudates are formed due to the lipid break down materials which are usually left behind when the localized edema resolves. Usually they have sharp margins, as seen inFig. 1(a)–(d). Often they appear as waxy and shiny structures [17]. Few important works for the detection of hard exudates have been very briefly discussed.Sopharak et al. [18] tried to develop a system using basic image processing algorithms like filtering and contrast enhancement. In the work it has been assumed that the pixels close to exudates can be separated from the normal pixels by using only their intensities. Garcia et al. [19] introduced a extrude detection system by using classifiers and machine learning. In this system the candidate regions for hard exudates were separated. Properties like average and standard deviation of RGB values of candidate regions and normal regions were taken as features. The classifiers were used to find the hard exudates based on these features. In another work by Sopharak et al. [20] a new approach using fuzzy clustering and data analysis algorithms for the detection of hard exudates was suggested. The features used in the system like pixel intensities, standard deviation of pixel intensities and hue etc. were carefully chosen by the medical experts. Another pixel based approach was introduced by Dupas et al. [21]. Sanchez et al. [22] addressed the same problem by using dynamic thresholding and mixture of statistical methods. In addition various algorithms for pre-processing and post-processing were also used. Another system for the detection of hard exudates was introduced by Welfer et al. [23]. This system uses morphological operations and watershed transforms in LUV color space for the detection process. Sanchez et al. [24] introduced another hard exudates detection system by exploiting the patient׳s contextual information. Chen et al. [25] proposed an algorithm which used a combination of histogram operations and morphological operations. The classification was done by using SVM. Garcia et al. [26] made use of logistic regression in combination with multilayer perceptron classifier and radial basis function classifier for the detection of hard exudates from fundus images. His method required proper pre-processing. Kayal et al. [27] employed various basic images basic techniques for the purpose of hard exudates detection. The summary of the stated works and their performance has been given inTable 1.The proposed referral system for hard exudates works by using different techniques like formation of VD, k-means Clustering, SIFT and SVM. SIFT has already proved its superior performance when it comes to recognition systems, object detection systems and target detection systems [9]. This superiority of SIFT comes with a price. SIFT is used for exact matching of data but when it comes to classification in broad or even constrained domain its performance is very poor. SIFT performs well in image retrieval systems where discriminative power is extremely important but when searching in complex categories, generalization power is vital. To solve the problem a method has been employed which uses visual dictionaries [11–14]. The visual dictionary comprises of visual words. Visual words are obtained through K-Means clustering. A single visual word represents a single cluster. A cluster is the collection of a number of points of interest (POI), close to each other, obtained through SIFT. As a consequence a visual word is the center of the cluster and represents the generalized form of many neighboring POIs. The detail description of the training and testing phase of the proposed system is described in the following sections.In images different POIs can be detected. These POIs can be used in recognition, retrieval or referral systems [28]. It has been observed that the features found around these POIs are more useful and robust as compared to global features [28–34]. In the first step of training phase the POIs were detected in the training images. A digital fundus image containing hard exudates is shown inFig. 2(a), whereas Fig. 2(b) indicates few POIs detected in the same image. Three medical experts were engaged to annotate the images. In training phase the optic disc region is also annotated by the experts. The annotations indicated the regions of the images containing artifacts and normal regions. SIFT was used to detect a large number of descriptors around the POIs which acted as low level features. The features obtained from SIFT are termed as low level feature because they require further processing before feeding them to the SVM. Consider an arbitrary training imageIiwherei∈{1,2,3,...,m}. Heremis the total number of training images. Using the SIFT descriptor the low levels featuresdaanddnare found fromIi. Wheredaare the low level features extracted from annotated regions of imageIimarked as containing artifact, anddnare the low level features extracted from annotated regions of imageIimarked as normal. Alsoa∈{1,2,3,...,q}andn∈{1,2,3,...,p}, whereqandpare total low level features extracted from annotated training images andda,dn∈ℝyexists iny-dimensional space. Using the low level featuresdaanddn, a visual dictionaryV={v1,v2,v3,...,vk}is created using a K-means clustering method, wherevkrepresents an arbitrary visual code word from visual dictionaryV. In the next step of training phase the quantization and spooling ofIiis done based on visual dictionaryV. For this, first eachda,dn∈ℝyis mapped onto theV[35]. This step transforms the low leveldaanddnonto a representation bases upon visual codewords ofV. The step can be represented asf:ℝy→ℝk,f(da)=μaandf(dn)=μn, where theμ׳s can be obtained by using the ‘hard assignment’ [36] of low level feature to the closest code word of the visual dictionaryVi.e.μq,k=1ifq=argmink‖vk−dl‖2elseq=0whereμq,kis theqthcomponent of the newly obtained mid-level feature andd={da,dn},μ={μa,μn},l=n+p. These features still require spooling step to be used in SVM. Therefore they are named as mid-level features.In spooling the high level feature vectorτis found using the sum spooling technique, i.e.g({μk})=τ:∀q,τq=∑k=1Nμq,kwhereτ∈ℝkTheτ׳s obtained are considered as high level features which are ready to be fed in the linear binary SVM [15]. In the proposed method a simple linear kernel binary classifier is used due to its observed merits over other classifiers as described in [15]. It should be noted that when it is said that linear kernel is used, it means that no kernel has been employed by the SVM. However the experiments were also repeated using Back Propagation Neural Network [37] instead of SVM to have a comparison between the performances of both classifiers. In the case of Neural Network only one hidden layer was used apart from input and output layers. The learning rate of the network was set to 0.9 and the momentum was set to 0.5.As already discussed that our system applies SIFT to the annotated hard exudates regions to obtaindafrom a low level features of the image and regards other low level features belonging todn. When POIs are found in the fundus images, many of them appear at the edges of the original fundus area and the area of the black filter placed while taking the image. The descriptors obtained by such POIs are useless and can even affect the performance of the system. Similarly during the process of finding POIs many of them may appear in the region of the optic disc. While training, the system may pick the features from these points and may confuse them withda. To remove such POIs from the edges of the filter and optic disc two masks were used. Fig. 2(c) shows the filter used to eliminate POIs from edges and Fig. 2(d) shows the filter used to remove POIs from optic disc. The process flow diagram is shown inFig. 3.The testing phase repeats almost the same steps described in the training phase on test imageIt. SIFT low level featuresdtare found in the test image, wheredt∈ℝy. The low level features on the edges of the filter are removed by the same mask used in the training phase. However in the testing phase the method described in [38] has been used, instead of annotations provided by experts, to locate and remove the low level features present in the regions of optic disc. The test imageItis quantized by using the same visual dictionaryVcreated in the training phase. This step creates the mid-level featureμt=f(dt)and mapsdt∈ℝytoμt∈ℝkusing the method as described in Section 3.1. The final high level featureτtfor the test image is obtained by sum spooling, discussed in Section 3.1. This high level featureτtis fed into the already trained SVM or NN to classify if the image requires referral or not. The process flow diagram of the testing phase is shown inFig. 4.In the presented work four fundus image databases were used namely STARE [39], DR1 [40], DR2 [40] and Diaretdb1 [41].STARE database was created by University of California, San Diego. The images were provided by Shiley Eye Center at the University of California, San Diego, and by the Veterans Administration Medical Center in San Diego. Currently the database contains 400 images from which 78 images were identified to contain hard exudates. The resolution of the images in STARE fundus database is700×605pixels. The images were captured by using TopCon TRV-50 camera which has a 35° field of view.DR1 is a database created by Department of Ophthalmology, Federal University of Sao Paulo (UNIFESP). The database contains 234 images containing hard exudates, which are of our interest. The average resolution of the images in DR1 database is640×480pixels. The images were captured by using TRX-50X, mydriatic camera. The maximum resolution of the camera is one mega-pixel and has a 45° field of view [40].DR2 database has also been provided by Department of Ophthalmology, Federal University of Sao Paulo (UNIFESP). The database has 520 images but there are 79 images of our interest which contain hard exudates artifacts. The resolution of the images is867×575pixels. The images were captured using TRC-NW8 non-mydriatic retinal camera with a Nicon D90 camera [40].The Diaretdb1 is the fourth database used in our experiments. The data base contains 89 fundus images. 46 fundus images were recognized by the medical experts of having hard exudates, which are sometimes very mild. The images were taken in Kuopio University hospital. The images were captured using 50° field of view digital fundus camera. The name and type of the camera has not been described in the dataset. The resolution of the images is1500×1152pixels [41]. Different research works which used DR1, DR2 and Diaretdb1 databases are given inTable 2.

@&#CONCLUSIONS@&#
