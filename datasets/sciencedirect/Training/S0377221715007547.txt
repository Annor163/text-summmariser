@&#MAIN-TITLE@&#
Finding the nucleoli of large cooperative games

@&#HIGHLIGHTS@&#
We propose a new nested-LPs-based approach for finding the nucleolus.We resolve subtle issues in handling multiple optimal solutions in each LP.The approach involves fewer and smaller LPs compared to existing methods.The approach proves to work well in several large combinatorial games.

@&#KEYPHRASES@&#
Nucleolus,Cooperative game,Multi-level programming,Payoff distribution,Constraint generation,Lexicographical minimization,

@&#ABSTRACT@&#
The nucleolus is one of the most important solution concepts in cooperative game theory as a result of its attractive properties - it always exists (if the imputation is non-empty), is unique, and is always in the core (if the core is non-empty). However, computing the nucleolus is very challenging because it involves the lexicographical minimization of an exponentially large number of excess values. We present a method for computing the nucleoli of large games, including some structured games with more than 50 players, using nested linear programs (LP). Although different variations of the nested LP formulation have been documented in the literature, they have not been used for large games because of the large size and number of LPs involved. In addition, subtle issues such as how to deal with multiple optimal solutions and with tight constraint sets need to be resolved in each LP in order to formulate and solve the subsequent ones. Unfortunately, this technical issue has been largely overlooked in the literature. We treat these issues rigorously and provide a new nested LP formulation that is smaller in terms of the number of large LPs and their sizes. We provide numerical tests for several games, including the general flow games, the coalitional skill games and the weighted voting games, with up to 100 players.

@&#INTRODUCTION@&#
The nucleolus is one of the most important solution concepts for cooperative games with transferable utilities. It represents a way to distribute the reward (or cost) among the players involved in a way that lexicographically minimizes the excess values (i.e. dissatisfaction levels) of all coalitions. The nucleolus was introduced in 1969 by Schmeidler (1969) as a solution concept with attractive properties - it always exists (if the imputation is non-empty), it is unique, and it lies in the core (if the core is non-empty). We review concepts in cooperative game theory and their mathematical definitions in Section 2.1. The nucleolus concept has been used in many different applications. For example, in the banking industry, groups of banks enter into an agreement for their customers to use ATM machines owned by any bank in the same group. The nucleolus is then used to suggest how the cost of installing and maintaining those ATM machines can be shared among the banks (see Gow & Thomas (1998)). It has also been applied to insurance premium setting (Lemaire (1991)) and to network cost sharing (Deng, Fang, and Sun (2009)Granot and Huberman (1984)Granot and Maschler (1998)), among many other applications.Despite the desirable properties that the nucleolus has, its computation is, however, very challenging because the process involves the lexicographical minimization of 2nexcess values, where n is the number of players. Kohlberg (1971) provides a necessary and sufficient condition for an imputation to be the nucleolus. However, the criterion requires forming the coalition array of all 2npossible coalitions and then making sure 2nlinear inequalities are satisfied. The analytical form of the nucleolus is only available for games with three players (see Leng & Parlar (2010)). There are a small number of games whose nucleoli can be computed in polynomial time. These include the connected games in Solymosi and Raghavan (1994), the neighbor games in Hamers, Klijn, Solymosi, Tijs, and Vermeulen (2003), the cyclic permutation games in Solymosi, Raghavan, and Tijs (2005), and the flow games with unit capacities in Deng et al. (2009)Kern and Paulusma (2009)Potters, Reijnierse, and Biswas (2006). It has been shown that finding the nucleolus is NP-hard for many classes of games such as the utility games with non-unit capacities (Deng et al. (2009)) and the weighted voting games (Elkind, Goldberg, Goldberg, & Wooldridge (2007)). In fact, finding the core and the least core is NP-hard in supermodular games Schulz and Uhan (2010) and inventory centralization games Chen and Zhang (2009).Kopelowitz (1967) suggests using nested linear programming (LP) to compute the kernel of a game. This encouraged a number of researchers to compute the nucleolus using linear programming. For example, Kohlberg (1972) presents a single LP withO(2n!)constraints. The number of constraints in the LP formulation of Owen (1974) is reduced toO(4n)but the coefficients get larger. The nucleolus can also be found by solving a sequence of LPs. However, the number of LPs involved is exponentially large (i.e.O(4n)in Maschler, Peleg, and Shapley (1979) andO(2n)in Sankaran (1991)). Potters, Reijnierse, and Ansing (1996) present another formulation that involves solving(n−1)linear programs with, at most,(2n+n−1)rows and(2n−1)columns. The authors also develop a prolonged Simplex method for solving these large LPs and conduct numerical experiments for games with 10 players. Derks and Kuipers (1997) improve the implementation of the prolonged Simplex method in Potters et al. (1996) and provide numerical results for games with 20 players. Göthe-Lundgren, Jörnsten, and Värbrand (1996) attempted to apply a constraint generation framework to find the nucleoli of basic vehicle routing games. However, some of results are incorrect as has been pointed out by Chardaire (2001). The issue of having multiple optimal solutions in each LP was not considered in Göthe-Lundgren et al. (1996), but we are able to deal with that in Section 3.3. Fromen (1997) uses Gaussian elimination to improve the formulation of Sankaran (1991) and to reduce the number of LPs in the implementation. Nevertheless, the LPs are still extremely large when the number of players gets large and existing methods become intractable when n exceeds 20. In the nested LPs formulation, subsequent LPs are formed based on the optimal solutions of the previous LPs and the tight inequalities. One needs to be very careful if there are multiple optimal solutions to these LPs and if there are multiple coalitions with the same worst excess values. The paper provides a rigorous treatment of the nested LPs formulation which deals with these issues.For each payoff distribution, there are 2nexcess values that correspond to 2npossible coalitions. The nucleolus is the payoff distribution that lexicographically minimizes its excess values. Thus finding the nucleolus effectively is only possible if one can find the worst coalition(s) for a given imputation efficiently. Faigle, Kern, and Kuipers (2001) show that the nucleolus can be found in polynomial time if finding the worst coalition for a given imputation, i.e. the separation problem, can be done in polynomial time. Their method is based on the ellipsoid algorithm which, although theoretically has a polynomial runtime, does not perform well in practice. Our paper bridges this gap and presents a practical numerical procedure for computing the nucleolus. We test our algorithm with the coalitional skill games and the weighted voting game.The key contributions of our work include:•We present a nested LPs formulation for computing the nucleoli of cooperative games. Although the idea of using a nested LPs framework has been around for more than 40 years ago (Kopelowitz (1967)) with various reformulations having been proposed, these methods face several issues that will be described in detail in Section 2.4. The most critical issue among these is how to handle multiple optimal solutions in each of the large LPs. Dealing with multiple optimal solutions is often needed in multi-level programming and is often very challenging. We provide a concrete method for dealing with these issues in Sections 3.3 and 4.3.The size of our nested LPs formulation is smaller than other nested LPs formulation described in the literature as can be seen in Table 1. The number of LPs to be solved in our method is smaller than that in Maschler et al. (1979) and Sankaran (1991) while the number of columns in each LP is smaller than that in Potters et al. (1996). These features are results of our special way of handling tight coalitions and finding the minimal tight sets (the key idea in Theorem 3 and the main results in Theorem 1).We provide numerical computation for large and structured games with up to 100 players in the weighted voting games Aziz, Paterson, and Leech (2007)Chalkiadakis, Elkind, and Wooldridge (2011) and up to 75 players in the coalitional skill games Bachrach and Rosenschein (2008). This is a significant improvement compared to the literature where numerical results are shown for computing the nucleoli of games with at most 20 players.In addition to these key contributions, we also apply a constraint generation framework for solving the large LPs. This gives hope to solving very large LPs as we don’t have to rely on the simplex method to solve large scale LPs when n ≥ 25. The constraint generation algorithm is not new and has been applied successfully in many areas including finding the solutions of cooperative games (e.g. Caprara & Letchford (2010)). Applying it to solving nested LPs though creates some challenging problems in keeping track of multiple discrete and continuous optimal solutions so that subsequent LPs can be formulated. Our approach is appropriate for large games and for combinatorial games where it is costly to calculate the characteristic values for all the possible coalitions. For example, in the flow games proposed by Kalai and Zemel (1982), the value of a coalition is the maximum flow that can be sent through the subnetwork using edges in the coalition only. In this case, it is time consuming to calculate all the 2npossible values. Instead, we can incorporate the maximum flow problem into the constraint generation problem that is then solved only if needed. We also demonstrate how this can be done in other games such as the voting games and the coalitional skills games.The structure of this paper is as follows: Section 2.1 provides the list of notations used throughout the paper and a review of important solution concepts in cooperative game theory such as the core, the least core, and the nucleolus. We present the idea behind the nested LPs and their formulation in Sections 2.2 and 2.3 with an illustrative example. The focus of this paper starts from Section 2.4 where the subtle issues relating to the nested LPs formulation are discussed in detail. The main contribution of this paper lies in addressing these issues in Section 3. We present the framework for finding the nucleolus in Section 3.2 and the idea of finding optimal solutions with minimal tight sets in Section 3.3. Our algorithm requires solving at most(n−1)large LPs, each having(n+1)columns and(2n+n−1)rows as shown in Section 3.2. For large games, we present methods for solving the exponentially large LPs and for handling large sets of tight constraints. This includes a constraint generation method for solving these large LPs in Section 4.1 and the idea of using representative sets for keeping track of tight constraints in Section 4.3. Various numerical experiments are presented in Section 6 and conclusion is drawn in Section 7.Let n be the number of players and letN={1,2,…,n}be the set of all the players. A coalitionSis a subset of the players, i.e.S∈C. LetC≡2Nbe the set of all the possible coalitions. The characteristic functionv:2N↦Rmaps each coalition to a real number withv(S)representing the payoff that coalitionSis guaranteed to obtain if all players inScollaborate no matter what the other players do. A solution of the gamex=(x1,x2,…,xn)is a way to distribute the reward among the players, with xibeing the share for player i. Let us denotex(S)=∑i∈Sxi. For each imputationx, the excess value of a coalitionSis defined ase(S,x)=v(S)−x(S)which can be viewed as the level of dissatisfaction the players in coalitionSfeel over the proposed solutionx. Solution concepts for cooperative games include:•An imputation is a solutionxthat satisfies∑i∈Nxi=v(N)andxi≥v(i),∀i∈N.The core of the game is the set of all imputationsxsuch thate(S,x)≤0,∀S∈C.The ϵ-core is defined as the set of all imputationsxsuch thate(S,x)≤ϵ,∀S∈C.Least core: The least core is the non-empty ϵ-core with ϵ being the smallest value.Nucleolus: For any imputationx, letΘ(x)=(Θ1(x),Θ2(x),…,Θ2n(x))be the vector of all the 2nexcess values atxsorted in the decreasing order, i.e. Θi(x) ≥ Θj(x) if 1 ≤ i < j ≤ 2n. Let us denote Θ(x) <LΘ(y) if ∃ r ≤ 2nsuch thatΘi(x)=Θi(y),∀1≤i<rand Θr(x) < Θr(y). Thenνis the nucleolus if, Θ(ν) <LΘ(x), ∀x≠ν.Throughout this manuscript, we denoteνas the nucleolus andIas the imputation set. We assume thatIis non-empty. However, the calculation of the prenucleolus can be done using the same method except that we relaxed the constraintx∈Iin calculating the nucleolus. The algorithm for finding the nucleolus presented in this paper involves solving several sub-problems. These sub-problems are referred to throughout the paper by a list of acronyms that are included in Appendix A.This section provides only a brief review of cooperative game theory. We refer the interested readers to Chalkiadakis et al. (2011)Peleg and Sudhölter (2007) for more thorough introduction of the topic.Consider the following minimax problem for finding the least core:minx∈I(maxS∈C{v(S)−x(S)}). This problem finds an imputationxsuch that the worst excess value among all coalitions, i.e.maxS∈C{v(S)−x(S)},is minimized. By definition, the nucleolus must be a solution of this problem. Furthermore, letϵ=maxS∈C{v(S)−x(S)},then the problem can be reformulated as an LP as follows:minx∈I,ϵ{ϵ|ϵ+x(S)≥v(S),∀S∈C}.Before going into further details on the algorithm, we need to define the concept of tight set as it is directly related to the definition of lexicographical minimization and will be crucial in formulating the nested LPs.Definition 1For any given (x, ϵ) and for any set of coalitionsF⊂C,let us denoteTϵ,F(x)as the corresponding tight set of all those coalitionsS∈Fsuch that the constraintsϵ+x(S)≥v(S)is tight, i.e.ϵ+x(S)=v(S),∀S∈Tϵ,F(x).The reformulated LP problem is not easy to solve because there is an exponentially large number of constraints. However, assume for now that we are able to find out an optimal solution (x*, ϵ*). Then the lexicographical ordering of all the excess values of imputationx* will have the form:{ϵ*,ϵ*,…,ϵ*,σ,…},where the first|Tϵ*,C(x*)|elements of the sequence are equal to ϵ* and the subsequent elements are at most σ, which is smaller than ϵ*.Solving this problem can provide us with the worst excess value that the nucleolus will produce. However, the LP problem can have multiple optimal solutions and we are not guaranteed that the optimal solution produced is the nucleolus. In addition, two distinct optimal solutions might have different tight sets and the tight sets might have different sizes. We only know that the nucleolus must correspond to an optimal solutionx* with the smallest tight setTϵ*,C(x*)(here, ‘smallest’ is in terms of size). Elkind and Pasechnik (2009) show that the tight set with the smallest size is unique, i.e. if bothx* andy* produce the setsTϵ*,C(x*)andTϵ*,C(y*)which are smallest in sizes, then the two sets must be identical, i.e.Tϵ*,C(x*)≡Tϵ*,C(y*)(this result can be proved by exploiting the linearity property of the problem). This means that choosing any optimal solutionx* with the smallest tight set would lead to the same minimal tight set, denoted asTϵ*,C*,which will be used to formulate the subsequent LPs. We will show how to find the minimal tight setTϵ*,C*in Section 3.3. In order to find the nucleolus among all the imputationsx* with the same smallest setTϵ*,C*,we must then aim to minimize σ and repeat this procedure until x* is unique. This can be done by solving another LP:minx∈I,σ{σ|ϵ*+x(S)=v(S),∀S∈Tϵ*,C*,σ+x(S)≥v(S),∀S∈C∖Tϵ*,C*}.The first set of constraints ensures that only candidate imputations with the first|Tϵ*,C*|worst excess values equal to ϵ* are considered. The second set of constraints and the objective function aim to minimize the worst excess values among all the remaining coalitions. Solving this LP will produce for us another set of tight coalitionsTσ*,C∖Tϵ*,C**with the excess value σ*. If we keep doing this, we will reach the point where the optimal solutionx* is unique; that is,x* is the nucleolus of the game.The problem of finding the nucleolus can be formulated as nested LPs (a sequence of LP1,2aLP2,…) as follows:1aLP1:=minx∈I,ϵ1{ϵ1|ϵ1+x(S)≥v(S),∀S∈C}.Let(x1,ϵ1*)be an optimal solution. Notice thatϵ1*is unique. However, it is possible to have multiple optimal solutionsx1. Eachx1 will correspond to a setT1(x1):=Tϵ1*,C(x)of all the coalitionsS∈Cfor which the inequality constraintϵ1*+x1(S)≥v(S)is tight. Among all the optimal solutions and their corresponding tight sets, letT1*be the set with the smallest size. Suppose for now that we are able to solve LP1and produce an optimal solution(x1*,ϵ1*)with the minimal tight set, i.e.T1(x1*)≡T1*. We then solve the following LP:2aLP2:=minx∈I,ϵ2{ϵ2|ϵ1*+x(S)=v(S),∀S∈T1*,ϵ2+x(S)≥v(S),∀S∈C∖T1*}.For each k ≥ 2, suppose LPkproduces(xk*,ϵk*,Tk*),whereTk*is the minimal tight set corresponding toxk*. Thenk+1aLPk+1is formulated as follows:(1a)k+1aLPk+1:=minx∈I,ϵk+1ϵk+1,s.t.ϵr*+x(S)=v(S),∀S∈Tr*,∀r∈{1,..,k},(1b)ϵk+1+x(S)≥v(S),∀S∈C∖Hk*,.whereHk*=∪r∈{1,..,k}Tr*. Here, we have denotedTk(x),k=1,2,…as a shorthand notation forTϵk*,C∖Hk−1*(x)as the set of coalitionsS∈C∖Hk−1*such that the corresponding inequalityϵk*+x(S)≤v(S)in LPkis tight. The index k inTk(x)implies that we are referring to LPkwhose optimal value isϵk*and whose set of inequalities is indexed byS∈C∖Hk−1*. We repeat this process of forming the nested LPs until LPkproduces a unique imputationx*. That imputation is the nucleolus.The nested LPs formulation presented in the literature is usually in the form of Model (1) described above. To provide a clearer connection between this nested LPs formulation and our methods for finding the nucleolus (to be described in Sections 3 and 4), we will first reformulate these LPs slightly. Let(xk*,ϵk*)be an optimal solution of LPkthat has the minimal tight setTk(xk*)=Tk*. Let(x,ϵk+1)be an optimal solution ofk+1aLPk+1. Then equality constraints (1a) ink+1aLPk+1requiresϵr*+x(S)=v(S),∀S∈Tr*,∀r∈{1,..,k}.Since(xk*,ϵr*,Tr*)is an optimal solution from LPr, we also haveϵr*+xk*(S)=v(S),∀S∈Tr*,∀r∈{1,..,k}.Subtracting one equality from the other, we obtain(x−xk*)(S)=0,∀S∈Tr*,∀r∈{1,..,k}. Thus,(x−xk*)(S)=0,∀S∈Hk*,i.e. we restrictx∈{xk*+null(Hk*)},wherenull(Hk*)denotes the null space of all the coalition vectors inHk*. From this,k+1aLPk+1can be reformulated as:(2a)k+1aLPk+1:=minx∈I,ϵk+1ϵk+1,s.t.(x−xk*)(S)=0,∀S∈Hk*,(2b)ϵk+1+x(S)≥v(S),∀S∈C∖Hk*.This reformulation provides us with a more elegant form. The storage required in representing the formulation is also smaller, i.e. only needsHk*from previous LPs instead of(ϵr*,Tr*)for all r ∈ {1, .., k}.To demonstrate the nested LPs formulation as well as the issues with using these, we consider the following simple three-player cooperative game example with the characteristic function:v({1})=1,v({2})=2,v({3})=5,v({1,2})=6,v({1,3})=7,v({2,3})=8,v({1,2,3})=12.The set of all imputations is:I={(x1,x2,x3):x1+x2+x3=12,x1≥1,x2≥2,x3≥5},and is shown in the shaded area (the largest triangle) in Fig. 1. The core of the game is:C={(x1,x2,x3):x1+x2+x3=12,x1≥1,x2≥2,x3≥5,x1+x2≥6,x1+x3≥7,x2+x3≥8},and is shown in the shaded trapezoid in Fig. 1. LP1is formulated as:minx,ϵ{ϵ|x1+ϵ≥1,x2+ϵ≥2,x3+ϵ≥5,x1+x2+ϵ≥6,x1+x3+ϵ≥7,x2+x3+ϵ≥8,x1+x2+x3+ϵ≥12,ϵ≥0,x1+x2+x3=12,x1≥1,x2≥2,x3≥5}.The optimal value of LP1isϵ1*=0and the set of all the optimal solutions (the least core solutions) is exactly the core. Solving LP1will produce for us a least core solution. However, depending on the solver we use, we might end up with one of the extreme points (e.g. if we use the simplex method) or a relative interior point (e.g. if we use an interior point method). The tight sets that correspond to these optimal solutions are:T1(x)={{{∅};{1,2,3};{3};{2,3}}ifx=(4,3,5),{{∅};{1,2,3};{2};{1,2};{2,3}}ifx=(4,2,6),{{∅};{1,2,3};{1};{1,2};{1,3}}ifx=(1,5,6),{{∅};{1,2,3};{3};{1,3}}ifx=(2,5,5),{{∅};{1,2,3};{2,3}}ifx=α(4,3,5)+(1−α)(4,2,6),with0<α<1,{{∅};{1,2,3};{1,2}}ifx=α(4,2,6)+(1−α)(1,5,6),with0<α<1,{{∅};{1,2,3};{1,3}}ifx=α(1,5,6)+(1−α)(2,5,5),with0<α<1,{{∅};{1,2,3};{3}}ifx=α(2,5,5)+(1−α)(4,3,5),with0<α<1,{{∅};{1,2,3}}ifx∈int(conv((4,3,5);(4,2,6);(1,5,6);(2,5,5))).In this case, the minimal tight set isT1*={{∅};{1,2,3}}whenxbelongs to the interior of the trapezoid or the interior of the line segmentα(2,5,5)+(1−α)(4,3,5)with 0 < α < 1. The problem of how to find an optimal solution that corresponds to the minimal tight set will be dealt with in Section 3.3. However, suppose for now that we are able to obtain this minimal tight set. Then we useT1*to formulate LP2as follows:minx,ϵ{ϵ|x1+x2+x3=12,x1+ϵ≥1,x2+ϵ≥2,x3+ϵ≥5,x1+x2+ϵ≥6,x1+x3+ϵ≥7,x2+x3+ϵ≥8,x1≥1,x2≥2,x3≥5}.The optimal value isϵ2*=−0.5and the optimal solutions of LP2are those points in the line segment connectingx=(2,4.5,5.5)andy=(3.5,3,5.5),i.e. those points with the formαx+(1−α)ywhere 0 ≤ α ≤ 1. Solving LP2will produce a solution that belongs to this line segment. From the minimal tight setT2*={{3};{1,2}}we can formulate and solve LP3and obtain the optimal value ofϵ3*=−1.25and a unique solution ofx*=(2.75,3.75,5.5)with the tight setT3*={{1,3};{2,3}}. This is the nucleolus and we can stop the algorithm.From the simple example presented in Section 2.3, we have some observations on the properties of LPk. First of all,ϵk*is always unique but there might be multiple optimal solutionsxk. Second, among all the optimal solutionsxk, there might be more than one solution whose tight set is smallest in size. However, all these optimal solutions share the same unique tight set. It is also interesting to notice that, based on the construction of the nested LPs, any optimal solutionxk+1ofk+1aLPk+1is also an optimal solution of LPk,k−1aLPk−1,…LP1. In addition,xk+1produces the smallest tight sets in all these k LPs. The nested LPs formulation provides us with a general procedure for finding the nucleolus. However, there are several practical issues that need to be addressed:Issue 1:The nested LPs presented might require solving as many LPs as there are distinguishing levels ofϵk*and this could be exponentially large for some games. How can we modify it to bound the number of LPs to at most(n−1)?LPkmight have multiple optimal imputationsx, each of which corresponds to a tight setTk(x). How can we find an optimal solutionxwith the smallest|Tk(x)|?For large games, the problem becomes even more challenging when the tight sets have exponential sizes (this occurs in many games such as the weighted voting games). If this is the case, how can we formulate and solve the subsequent LPs given that we might not have the resources to compute the entire setTk*?As far as we have understood, although the nested LPs formulation was formulated by Kopelowitz (1967) in 1967 and various reformulations have been presented, very limited numerical tests have been performed. In addition, all of these experiments are only for small games, i.e. Potters et al. (1996) provide numerical tests for games with at most 10 players, Derks and Kuipers (1997) and Fromen (1997) improve existing methods to provide numerical tests for games with no more than 20 players. We presume that there are two main reasons behind this. First of all, the LPs has 2nconstraints and hence are difficult to solve in practice. The second and more critical reason lies on the difficulty of handling the multiple optimal solutions in each LP (Issue 2).Potters et al. (1996) and Derks and Kuipers (1997) recognize the first two aforementioned issues and attempt to resolve them using a prolonged simplex method. However, their method does not scale well because of the large LPs involved. Issue 1 has been recognized in the literature and the conventional stopping condition is when the tight constraints produce a unique solution. The number of LPs to be solved is bounded by the number of players in Derks and Kuipers (1997)Potters et al. (1996) thanks to their special way of avoiding having to solve redundant LPs. Issue 3 has been recognized by Elkind and Pasechnik (2009). Under these situations, their ellipsoid method requires the assumption that the size ofTk*is known. Our paper deals issue 3 without this assumption. This is done by replacingTk*with a representative set with size at most n. This not only helps to resolve issue 3, but also makes the LPs formulation smaller, and thus easier to store and solve.First, we notice that if we solve the nested LP formulation described in Section 2.3 directly, we might end up solving as many large LPs as there are distinct levels ofϵk*before obtaining a full rankHk*. However, we notice that once the equality constraints in LPkare enforced, i.e.(x−xk−1*)(S)=0,∀S∈Hk−1*,we then obtainv(S)−x(S)=v(S)−xk−1*(S),∀S∈Hk−1*,which is also equivalent tov(S)−x(S)=v(S)−xk−1*(S),∀S∈span(Hk−1*),and hence these excess values corresponding toS∈span(Hk−1*)are constant and there is no reason to minimize them. That is, LPkshould only try to minimize the largest among the remaining (non-constant) excess values. We can, therefore, use the same approach as in Derks and Kuipers (1997)Potters et al. (1996) to reformulate the nested LPs and to show that the total number of large LPs that we need to solve is at mostn−1. To this end, we defineH^0*={N},x^0*=(v(N)/n)e,whereeis the identity vector inRn,and introduce the new nested LPs withLP^k,k=1,2,…,defined as follows(3a)LP^k:=minx∈I,ϵkϵk,s.t.(x−x^k−1*)(S)=0,∀S∈H^k−1*,(3b)ϵk+x(S)≥v(S),∀S∉span(H^k−1*),where(x^k,ϵk*^)is an optimal solution ofLP^kwith the minimal tight setT^k*,i.e.T^k*={S∉span(H^k−1*):ϵk*^+x^k(S)=v(S)},and whereH^k*=H^k−1*∪T^k*. Here, constraint (2b), i.e.ϵk+x(S)≥v(S),∀S∈C∖Hk−1*,has been replaced by constraint (3b) since on solvingLP^k,we do not have to concern about coalitions with constant exceed values as argued above.We highlight the change in notations used in this section and the remaining of the manuscript where a ‘hat’ is added to each of the notation introduced in the previous section; that is, we havex^k,ϵk*^,LP^k,T^k(·),T^k*andH^k*instead ofxk,ϵk*,LPk,Tk(·),Tk*andHk*,respectively, whereT^k(x)≡Tϵk*^,C∖span(H^k−1*)(x).Algorithm 1presents the complete algorithm for finding the nucleolus. The algorithm iteratively solvesLP^kto obtain an optimal solution (i.e. Step 2) and find an optimal solution with the minimal tight set in Step 3. This process is repeated until the minimal tight set has full rank. We show the algorithm involves solvingLP^kat most(n−1)times in Theorem 1 and the algorithm indeed finds the nucleolus in Theorem 2.Theorem 1The total number ofLP^kthat we need to solve inAlgorithm 1is at most(n−1).Due to the construction of constraint (3b),T^k*are not in the span ofH^k−1*. Therefore, the rank ofH^k*is always greater than that ofH^k−1*(unlessH^k−1*has already had full rank). This meansrank(H^k*)≥rank(H^k−1*)+1≥…≥rank(H^0*)+k=k+1.Therefore, unless Algorithm 1 stops at iterationk≤(n−1),we haverank(H^k*)≥(k+1)>nwhich is impossible. Thus, the number of LPs is at most(n−1)beforerank(H^k*)=n,at which point the system of linear equations(x−x^k*)(S)=0,∀S∈H^k*has an unique solution and we stop the algorithm.□The intuition for the correctness of Algorithm 1 in producing the nucleolus has been described in the construction of LPkin Section 2.3 and in the reformulation toLP^kin Section 3.1. However, since these sections only provided a constructive and informal proof and since many existing literature only provided a claim that nested LPs can be used to compute the nucleolus without a formal proof, we take this opportunity to provide a concrete result stated in the following theorem.Theorem 2The solution produced byAlgorithm 1is the nucleolus of the game(N,v).Part of the proof of this theorem is based on the following two lemmas which state that the nested LPs are uniquely constructed despiteLP^kmight produce multiple optimal solutions.Lemma 1All optimal solutions ofLP^kwith tight sets having the smallest size have the same tight setT^k*.We use the similar idea of Elkind and Pasechnik (2009) to prove this result. Let(xa,ϵk*^)and(xb,ϵk*^)be any two optimal solutions with tight sets having the smallest size and suppose on contradiction thatT^k(xa)≠T^k(xb). Letxc=αxa+(1−α)xbfor some α ∈ (0, 1), then(4)(xc−x^k−1*)(S)=α(xa−x^k−1*)(S)+(1−α)(xb−x^k−1*)(S)=0∀S∈Hk−1*,and(5)ϵk+xc(S)=α(ϵk+xa(S))︸≥v(S)+(1−α)(ϵk+xa(S))︸≥v(S)≥v(S),∀S∉span(Hk−1*),with equality occurs atS∈T^k(xa)∩T^k(xb). This means(xc,ϵk*^)is also an optimal solution ofLP^kwith the tight setT^k(xc)=T^k(xa)∩T^k(xb)being strictly smaller than the minimal tight set (due toT^k(xa)≠T^k(xb)and|T^k(xa)|=|T^k(xb)|). This contradicts the assumptions onT^k(xa)andT^k(xb)having the smallest tight sets. Thus, all optimal solutions ofLP^kwith tight sets having the smallest size share the same tight setT^k*.□Result from Lemma 1 is demonstrated in Fig. 2.Lemma 2The nested LPs produced byAlgorithm 1are uniquely constructed, i.e.LP^khas exactly the same form no matter which optimal solution(x^k*,ϵk*)with minimal tight set we choose in Step 2.From Lemma 1, no matter which optimal solution we choose in Step 2 of Algorithm 1, the minimal tight setT^k*is uniquely produced by the end of Step 3 as long asH^k−1is fixed. We can also prove that the setH^k*=H^k−1*∪T^k*is uniquely constructed by an inductive argument givenH^0*={N}is fixed. In other words, the nested LPs produced by Algorithm 1 is uniquely constructed.□The idea of this proof is to show that(ν,ϵk*^),whereνis the nucleolus, is also an optimal solution ofLP^kwith a minimal tight set. If we could do this, then we can use the result from Lemma 2 that the nested LPs are uniquely constructed to show that,νis also a solution of the system of linear equations(x−x^k*)(S)=0,∀S∈H^k*for allk=1,…,n−1. Since this system of linear equations has an unique solution by the end of Algorithm 1, the solution produced by the algorithm is the nucleolus.We will prove that(ν,ϵk*^)is also an optimal solution ofLP^kwith a minimal tight set for allk=1,…,n−1by an inductive argument. It can be seen that(ν,ϵ1*)is an optimal solution ofLP^1by the definition of the nucleolus. In addition, we have|T^1(ν)|≤|T^1(x^1*)|,since otherwiseνwould not have the lexicographically smallest vector of deficits. On the other hand, by the construction in Step 3 of Algorithm 1, i.e.x^1*has the minimal tight set, we have|T^1(x^1*)|≤|T^1(ν)|.Thus,|T^1(x^1*)|=|T^1(ν)|and hence by Lemma 1, bothνandx^1*share the same minimal tight setT^1*. Suppose we have shown thatνandx^k*share the same minimal tight setT^k*for some k ≥ 1, we will show that this result also holds for(k+1).By the inductive argument, the vectors of deficits for bothνandx^k*are lexicographically the same with respect to coalitionsS∈span(H^k*). In addition,(ν,ϵk+1*)is also an optimal solution ofLP^k+1. Finally, similar to the case ofk=1,we have|T^k+1(ν)|=|T^k+1(xk+1*)|sinceνhave the lexicographically smallest vector of deficits whilexk+1*has the minimal tight set. Thus, by Lemma 1, bothνandxk+1*share the same minimal tight setT^k+1*and hence(ν,ϵk+1*)is also an optimal solution ofLP^k+1with a minimal tight set. The proof of the theorem is completed.□The LP formulationLP^know looks like that in Derks and Kuipers (1997) but notice that the key difference is in our method to obtain an optimal solution with the minimal tight set. To improve the optimal solution found, our key contribution is Theorem 3 where we just need to solve small LPs to find another optimal solution with smaller tight set. Our method differs from Potters et al. (1996) in the size of the LPs. In our formulation,LP^khas(n+1)decision variables and(2n+n−1)constraints (since there are(2n−2)non-trivial coalitions, each of which corresponds to a constraint, and there are(n+1)constraints for enforcingx∈I). This means our LPs have(n+1)columns compared to the(2n−1)columns in the LPs of Potters et al. (1996). The number of rows is the same at(2n+n−1)for both our method and Potters et al. (1996).We found many references in the literature that include only Step 2 of Algorithm 1 when presenting the algorithm for finding the nucleolus. This seems to create a common perception within the research community that the nucleolus can be found by solving a nested LPs (without concerning about which optimal solution in each LP to choose). As we have shown in the simple example in Section 2.3 and the list of issues presented in Section 2.4, choosing the right optimal solution with the minimal tight set is crucially needed for formulating subsequent LPs and hence Step 3 described in Algorithm 1 is needed.Let(x^k*,ϵk*^)be an optimal solution ofLP^kwith the minimal tight setT^k*. When solvingLP^kusing a standard LP solver or the constraint generation method (to be described in Section 4.1), suppose we obtain an optimal solution(x,ϵk*^)whose tight setT^k(x)might be larger in size compared toT^k*. If this is the case, we cannot take(x,ϵk*^,T^k(x))to construct the subsequent LPs since this would not lead to a minimum lexicographical ordering of excess values. However, from this solution, we can find an improved imputation with smaller tight set as will be described in Theorem 3. Before presenting this theorem, we first describe some additional notation. Let σ be the smallest excess value that corresponds toxand a coalitionS∉span(H^k−1*)∪T^k(x),i.e.,σ=maxS∉span(H^k−1*)∪T^k(x){v(S)−x(S)}. Then we have:v(S)−x(S)≤σ<ϵk*^,∀S∉span(H^k−1*)∪T^k(x). Letδ=1n+1(ϵk*^−σ)>0. We have the following theorem:Theorem 3Let(x,ϵk*^)be any optimal solution ofLP^kwith the tight setT^k(x),then the following LP:(6a)OSaFBOS:=miny∈I∑S∈T^k(x)[v(S)−y(S)],s.t.(y−x^k−1*)(S)=0,∀S∈H^k−1*,(6b)(y−x)(S)≥0,∀S∈T^k(x),(6c)|yi−xi|≤δ,∀i=1,..,n,always has an optimal solutiony*. In addition, we can conclude that:•(x,ϵk*^)is an optimal solution ofLP^kwith the minimal tight set if the optimal objective value ofFBOSis equal to|T^k(x)|ϵk*^,and(y*,ϵk*^)is an optimal solution ofLP^kwith a smaller tight set compared toxotherwise.The main idea in this theorem is to observe that, if|T^k(x)|>|T^k*|,then there must exist another imputationythat has smaller excess value thanxon at least one coalitionS∈T^k(x),i.e.e(S,y)<e(S,x). This is equivalent to saying thatxis not an optimizer of the following LP:miny∈I∑S∈T^k(x)[v(S)−y(S)],The optimizer of this LP, however, does not guarantee to be better thanxon all coalitions, especially those coalitionsS∉T^k(x). The additional constraints in FBOS are included for this purpose. The first constraint,(y−x^k−1*)(S)=0,∀S∈H^k−1*,guarantees thatydoes not change the excess values for coalitions inspan(H^k−1*)that have been identified byLP^1,…,LP^k−1. The second constraint,(y−x)(S)≥0,∀S∈T^k(x),guarantees that the excess vector Θ(y) is at least as good as Θ(x) for all elements from coalitionsS∈T^k(x). The last constraint,|yi−xi|≤δ,∀i=1,..,n,restrictsyto a polyhedron (a box) that containsxin its interior. From the choice of the box size δ, we can guarantee that the excess valuese(S,y)are smaller thanϵk*^for all the remaining coalitionsS∉span(H^k−1*)∪T^k(x)as shown below.(v(S)−y(S))=(v(S)−x(S))+(x(S)−y(S))≤σ+∑i=1n|yi−xi|≤σ+nn+1(ϵk*^−σ)<σ+ϵk*^−σ=ϵk*^.Combining all the three constraints, we guarantee that any feasible solution of FBOS is at least as good asxlexicographically with regards to coalitions inspan(H^k−1*)∪T^k(x). Since the problem FBOS is bounded with at least one feasible solutionx, it must have an optimal solutiony*. If the corresponding optimal value is smaller than|T^k(x)|ϵk*^,then there must be at least one coalitionS∈T^k(x)such thatv(S)−y*(S)<ϵk*^and hencey* is strictly better thanxlexicographically. To complete the proof of this theorem, we need to prove that, ifxdoes not have a minimal tight set, i.e.|T^k(x)|>|T^k*|,then the optimal objective value must be smaller than|T^k(x)|ϵk*^. Indeed, we can construct a feasible solution of FBOS with an objective value equal to|T^k(x)|ϵk*^as follows.Letx^k*be an optimal solution ofLP^kwith minimal tight set. From Lemma 1, we can see that any pointy=αx+(1−α)x^k*with 0 < α ≤ 1 would be an optimal solution ofLP^kwith the smallest tight set. We also notice thatx^k*satisfies constraints (6a–b) of FBOS. Thus, if we choose a small enough α, we can obtain an optimal solutiony=αx+(1−α)x^k*that satisfies constraints (6c). By linearity,yalso satisfies constraints (6a–b) and henceyis a feasible solution of FBOS. In addition,yhas the smallest tight set sinceT^k(y)=T^k(x)∩T^k(x^k*)=T^k(x^k*). Thus,yis an optimal solution of FBOS and with the minimal tight set. The proof of the theorem is complete.□The geometric view of Theorem 3 is illustrated in Fig. 3.Let the coneKbe defined as the intersection of the setIof all imputations, the affine subspace{x^k−1+null(H^k−1*)}that ensures the worst excess values from previous LPs do not change, and the dual coneC*(T^k(x))≡{y∈Rn|〈y,σ〉≥0,∀σ∈T^k(x)}to ensure thatyis at least as good asxwhen considering coalitions withinT^k(x),i.e.,K=I∩{x^k−1+null(H^k−1*)}∩C*(T^k(x)),thenKcontainsx^k*. Here,null(H^k−1*)denotes the null space of vectors inH^k−1*. LetP(x)be any domain that containsxin its interior. The idea is that once the domainP(x)is small enough, the excess values of all coalitions not belonging tospan(H^k−1*)∪T^k(x)do not change much to exceedϵk*^. The intersection ofP(x)andKprovides us with imputations that are at least as good asxlexicographically with respect to the first k worst excess levels.Remark: Notice that FBOS is an LP with n decision variables and withrank(H^k−1)equality constraints and(3n+|T^k(x)|)inequality constraints11These include n inequality constraintsy∈Ifor individual rationality,|T^k(x)|inequalities from (6b), and 2n inequality constraints from (6c)., and can be solved very efficiently. Notice also that the FBOS algorithm imposes the constraint ofy∈P(x)for a small domainP(x)to provide a theoretical guarantee. However, once we have found an improved solutiony, we should extrapolate it fromxto obtain a new improved solution that is as close to the center of the domain of all the improved optimal solutions as possible. This can be done by performing a line search on ally^=α*y−(α−1)xfor the maximum αmaxsuch thaty^is still an improved optimal solution. Once we have obtained αmax, we can then choose the improved optimal solution asy¯=αmax/2*y−(αmax/2−1)x. This extrapolation step achieves two objectives: First of all, it provides us an improved optimal solution that is far enough fromxto avoid numerical error. Second,y¯is more likely to be closer to the nucleolus and hence can speed up our algorithm.In this section we aim to solveLP^kefficiently. This task is feasible for any cooperative games with the number of players less than around 20 since linear programming solvers such as the Simplex method can handle the LP efficiently. For larger games, since the LP has an exponentially large number of constraints, it is often very difficult to solve. We need to make an assumption that the characteristic function has some special forms that allows us to exploit and solveLP^k. This assumption is quite reasonable in the quest for finding the nucleolus because, without it, even solving for the core or the least core has already proved difficult. We demonstrate this possibility through some combinatorial games to which the well-known constraint generation (CG) approach can be applied to solveLP^k.We notice that most of the constraints inLP^kare non-binding at optimal solutions. In fact, Reijnierse and Potters (1998) show that there exist a set of2(n−1)coalitions that determines the nucleolus. That means we can still find an optimal solution by including only a subset of constraints. The idea of the constraint generation (CG) algorithm is to start with a relaxed problem and then to check whether the optimal solution of the relaxed problem satisfies all the constraints in the original problem. If that is the case, then the solution to the relaxed problem is also an optimal solution of the original problem. Otherwise, we have identified a violating constraint and that can be added to the relaxed problem. LetCr⊂Cbe a subset of all coalitions (ideally|Cr|≪|C|). We relax the inequality constraintϵk+x(S)≥v(S),∀S∈C∖span(H^k−1*)inLP^ktoϵk+x(S)≥v(S),∀S∈Cr∖span(H^k−1*)and introduce the following relaxed problem:PkaRLPk:=minx∈I,ϵk{ϵk|(x−x^k−1*)(S)=0,∀S∈H^k−1*,ϵk+x(S)≥v(S),∀S∈Cr∖span(H^k−1*)}.Once we have obtained an optimal solution (x, ϵ) for the relaxed LP, we will solve the constraint generation problem:aCGk:=maxS∈C∖span(H^k−1*){v(S)−x(S)},and letS*be an optimal solution of the constraint generation problem. Ifv(S*)−x(S*)≤ϵ,then (x, ϵ) satisfies all the constraints ofLP^kand hence it is also an optimal solution ofLP^k. The CG algorithm then terminates and we have found an optimal solution. Otherwise, we can introduceS*to the relaxed constraint setCrand repeat the process. The formal constraint generation algorithm is described below:An attractive property of the constraint generation algorithm is that the lower bounds ϵ(j) are increasing through iterations. We can show that the constraint generation algorithm never enters a loop of reintroducing coalitions intoCr. The proof for the correctness of the stopping condition in the iterative loop is quite standard and we skip it for brevity. In addition, since the setCof all the possible coalitions is finite while the setCrkeeps expanding, the constraint generation algorithm will terminate at an optimal solution. This is independent of the starting imputationx(0).The CG algorithm (sometimes referred to as the delayed constraint generation or cutting plane method) has been successfully applied to problems involving an exponentially large number of constraints and it could potentially be used for finding the least core. It is noted, however, that applying the CG algorithm to find the nucleolus is not straightforward because of the following two main issues(a)How to solve the constraint generation problem efficiently?How to deal with multiple optimal solutions and the tight sets. The CG algorithm often returns only a small subset of all the tight constraints because many of these constraints are relaxed in the restricted problem. How can we assess the size of the tight set of the optimal solution obtained against that of other optimal solutions?Issue (a) is a typical issue when applying the CG framework to solve a generic optimization problem while issue (b) is specific to the case of finding the nucleolus. In the first issue, we want to solve the problemmaxS∈C∖span(H^k−1*){v(S)−x(j−1)(S)}.Each coalitionScan be represented as an indicator vectorz={z1,z2,…,zn}wherezi=1means player i is in the coalitionSandzi=0means otherwise. Then, for each imputationx, we havex(S)=xtz,which is a linear function ofz. Suppose also thatv(S)can be expressed as a function ofz, i.e.v(S)≡v(z). The CG problem is then formulated asmaxz∈C∖span(H^k−1*){v(z)−zTx(j−1)}.Depending on the problem structure and the form of function v(z), the CG problem might have different forms. For example, v(z) can be transformed into a linear function ofzas we will show later in Section 5.2 for the case of the weighted voting game. Method for handling the constraintz∉span(H^k−1*)will be described in detailed in Section 4.3.1.In issue (b), suppose the CG framework has produced an optimal solution(x^k,ϵk*^)for some relaxed setCr⊂C. We can tell which coalitions withinCrbelongs to the tight setT^k(x^k). However, we do not know if there is any remaining tight coalitions withinC∖(Cr∪span(H^k−1*))and we need to find a method for finding out these.Let{z(1),z(2),…,z(K)}be the set of tight coalitions found so far. To find other tight coalitions, we need to solve the following problemmaxz∉span(H^k−1*){v(z)−ztx},z∉{z(1),z(2),…,z(K)}.The constraintz≠z(r) is equivalent to eliminating previous solutionz(r) from the feasible space. This can be done by generating a cut to separate this point from the hypercubez∈ {0, 1}nas follows. We notice thatz≠z(r) is equivalent to(2z−e)≠(2z(r)−e)whereeis the identity vector. Notice that both(2z−e)and(2z(r)−e)have elements equal to−1or 1 and hence they are different if and only if(2z(r)−e)t(2z−e)≤(n−2). This is equivalent to(2z(r)−e)tz≤etz(r)−1,which is a linear constraint onz(notice thatz(r) is given).Thus, the problem of finding the remaining tight constraints can be formulated asmaxz∉span(H^k−1*){v(z)−ztx|(2z(r)−e)tz≤etz(r)−1,∀r={1,…,K}},which is very similar to the CG problem for solvingLP^kexcept for the K additional linear constraints.For each optimal solutionxofLP^k,the tight setT^k(x)might be exponentially large for many games and henceH^k*might be exponentially large too. If this is the case, then the constraint set inLP^k+1will be very difficult to keep track of, andLP^k+1will be even harder to solve. However, the equality constraints can be represented by mkconstraints where mkis the rank ofH^k*(mk≤ n). Thus, if we can replaceH^k*by its mkrepresentative vectors (coalitions), the equality constraints will be tractable. The issue is then how we can create this representative set. The simplest way is to keep introducing new tight coalitions until we can no longer improve the rank ofH^k*. However, this method only works if the size of the tight set is not too large. If the tight set is large, we have no way to check whether the tight constraints found so far can form the representative set unless we have already had a full rank set (but it could be the case thatH^k*does not have full rank and we would not know when to stop). A better way is to introduce only tight coalitions that can increase the rank ofH^k*while undertaking the construction of the representative set as will be described next.Suppose so far we have generated the set of linearly independent tight constraints{z(1),z(2),…,z(s)}. In order to restrictznot to be in the linear combination of{z(1),z(2),…,z(s)},we modify the constraint generation problem to:PaREP:=maxz∈{0,1}n{v(z)−ztx|z∉span{z(1),z(2),…,z(s)}}.The constraintz∉span{z(1),z(2),…,z(s)}is equivalent to the existence of a vectoruwithutz(j)=0,∀j=1,…,sandutz< 0 (similar to Farkas’ Lemma). This is also equivalent to the following set of constraints:{z=ua+ub,ua∈span{z(1),z(2),…,z(s)},ub∈null{z(1),z(2),…,z(s)},ub≠0}.By our construction,{z(1),z(2),…,z(s)}are s independent vectors. Thereforenull{z(1),z(2),…,z(s)}is a subspace inRn−s. LetA=[z(1),z(2),…,z(s)]and letB∈Rn×(n−s)be a set of(n−s)vectors inRnthat spansnull{z(1),z(2),…,z(s)}. Letua=Aωaandub=Bωbfor some vectorsωaandωb. The conditionub≠ 0 is equivalent toωb≠ 0. The conditionz∉span{z(1),z(2),…,z(s)}is equivalent to:z=Aωa+Bωb,ωb≠0. Let us define the domainD={(z,ωa,ωb):z∈{0,1}n,ωa∈Rs,ωb∈Rn−s,z=Aωa+Bωb,ωb≠0,v(z)−ztx=ϵk*^}.Notice thatx,ϵk*^,AandBare known. The constraint generation problem is equivalent to finding a feasible solution(z,ωa,ωb)∈D. In order to find a feasible point inD,we can optimize any arbitrary objective function over that domain. However, it is not straightforward to model the inequality constraintωb≠ 0. Instead, we need to optimize a set of linear objective functions over a domainDrdefined as follows:Dr={(z,ωa,ωb):z∈{0,1}n,ωa∈Rs,ωb∈Rn−s,z=Aωa+Bωb,v(z)−ztx=ϵk*^},where the inequality constraint is removed. We can find a feasible point inDor conclude it empty by using the following Proposition:Proposition 1Letc1,…,cn−sbe any set of(n−s)linearly independent cost vectors. If solving the problemsmin(z,ωa,ωb)∈Drcjtωbandmin(z,ωa,ωb)∈Dr−cjtωb,j=1,…,n,all have optimal values that are equal to zero, thenDis an empty set (which meansREPis either infeasible or the optimal value is not equal toϵk*^). Otherwise, any feasible solution (z, ωa,ωb) of any of these2(n−s)problems with a non-zero objective value will be a feasible point inD. In that case,zwill be a solution ofREP.We notice thatDris a non-empty domain since(z=z(1),ωa=(1,0,…,0)t,ωb=0)is a feasible solution with an objective value equal to zero. Therefore, solving all these2(n−s)optimization problems will return either (a) at least one feasible solution with non-zero objective value or (b) all of them have the same objective values that are equal to zero. In the first case, suppose there exists a feasible solution(z,ωa,ωb)∈Drsuch thatcjtωb≠0. Thenωb≠ 0 and hence(z,ωa,ωb)∈D. In the second case, suppose all feasible solutions of the2(n−s)share the same objective value of zero. We need to prove that the setDis empty to complete the theorem. Suppose for the purposes of contradiction the setDis non-empty, i.e. there exists(z,ωa,ωb)∈D. This means(z,ωa,ωb)∈Dr. We also havecjtωb=0,∀j∈{1,…,n−s}. This is impossible becauseωb≠ 0 whilec1,…,cn−sare linearly independent.□Proposition 1 provides a way to find an optimal solution of REP (or to conclude that it is infeasible). Although the theorem appears to involve solving2(n−s)LPs, an optimal solution of REP is found whenever an LP among them provides us with a feasible solution with non-zero objective value. This means if we are lucky to choose the right set of cost vectors, we do not have to solve all of these LPs. However, this approach still requires solving all the2(n−s)LPs if REP is indeed infeasible. We can speed up the process by using a randomization technique. For a random cost vectorc, the conditionωb≠ 0 is equivalent to either the optimal value of minctωbor that ofmin−ctωbbeing different from zero with probability one (w.p.1).LetRk*be the representative set ofH^k*,i.e.Rk*⊂H^k*and|Rk*|=rank(Rk*)=rank(H^k*). We show that we still can solveLP^k+1even without the full knowledge ofH^k*. Once we have obtained the representative set, we reformulateLP^k+1as follows:LP^^k+1:=minx∈I,ϵk+1{ϵk+1|(x−x^k*)(S)=0,∀S∈Rk*,ϵk+1+x(S)≥v(S),∀S∉span(Rk*)}.In this case, the number of equality constraints has been reduced from|H^k*|to|Rk*|without changingLP^k+1since the remaining equalities are redundant. The inequalities are also the same sincespan(Rk*)=span(H^k*). Therefore,LP^^k+1is exactly the same withLP^k+1and henceT^k*andH^k*are still unchanged. In the constraint generation method, the CG problem,maxS∉span(Rk*){v(S)−x(S)}is also equivalent to CG problem for solvingLP^k. Thus, our constraint generation algorithm still does not change when we replaceH^k*with its representative set. The FBOS problem for finding an improved imputation, however, needs to be changed to:OS2aFBOS2=miny∈I∑S∈Rk*(x)[v(S)−y(S)],s.t.|yi−xi|≤δ,∀i=1,..,n,(y−x^k−1*)(S)=0,∀S∈Rk−1*,(y−x)(S)≥0,∀S∈T^k(x).Notice that FBOS2 is different from FBOS in the objective function and in the equality constraints. Here, we reduce the number of equality constraints from|H^k*|to|Rk*|without changing the problem because the remaining equality constraints are redundant. The constraints(y−x)(S)≥0,∀S∈T^k(x)can be dealt with using the same constraint generation procedure used to solveLP^k. However, we need the following theorem to extend the results from Theorem 3:Theorem 4Let(x,ϵk*^)be any optimal solution ofLP^^kwith the tight setT^(x). Then solvingFBOS2will lead to one of two cases:(a)Ifxis not an optimal solution ofFBOS2, then any optimal solutiony*ofFBOS2would result in a smaller tight set, i.e.|T^k(y*)|<|T^k(x)|,Ifxis an optimal solution ofFBOS2, thenxis also an optimal solution ofLP^^kwith the minimal tight set, i.e.T^k(x)≡T^k*.LetRk*(x)={z(1),z(2),…,z(r)}.(a)Notice thatx,x^k*are feasible solutions of FBOS2. In addition, FBOS2 is bounded and hence it has an optimal solution. Supposexis not an optimal solution of FBOS2. Then any optimal solutiony* of FBOS2 would have a smaller objective value. In particular, there exists a coalitionSinRk*(x)such thatv(S)−y*(S)<v(S)−x(S). Since all other excess values ofy* are less than or equal to those ofxby the construction of FBOS2, y* must have a smaller tight set compared toxinLP^k.Supposexis an optimal solution of FBOS2. We will provexis also an optimal solution ofLP^^kwith the minimal tight set. Suppose, as a contradiction, that there exists another optimal solutiony* ofLP^^kwith|T^k(y*)|<|T^k(x)|. This means there exists at least one coalitionz(0) such thatv(z(0))−y*(z(0))<v(z(0))−x(z(0)). Since any convex combination ofxandy* is an optimal solution ofLP^kwhose tight set is smaller thanT^k(x),we can assumey* is sufficiently close but not equal tox. This meansy* is also a solution of FBOS2. Notice that we can rewrite the objective function as follows:∑S∈Rk*(x)[v(S)−y(S)]=∑S∈Rk*(x)v(S)−∑S∈Rk*(x)y(S)=∑S∈Rk*(x)v(S)−rcty,where r is the size ofRk*(x)andc=z(1)+…+z(r)ris the average of all coalitionszinRk*(x). Since∑S∈Rk*(x)v(S)and r are constants in FBOS2, the problem is equivalent to minimizing−cty. SinceRk*(x)is the representative set,z(0) can be expressed asz(0)=∑i=1rβiz(i). For any α0, letαi=1/r−α0βi,we have:c=1r(z(1)+…+z(r))=∑i=1r(1r−α0βi)z(i)+α0∑i=1rβiz(i)=∑i=1rαiz(i)+α0z0. We can choose α0 > 0 and small enough such that αi≥ 0, ∀i. Thus,ct(x−y*)=∑i=1rαi(z(i))t(x−y*)︸≤0+α0(z(0))t(x−y*)︸<0<0.This meansxis not an optimal solution of FBOS2 and so there is a contradiction. The proof of the theorem is complete.□Algorithm 3presents the complete algorithm for finding the nucleolus. The algorithm iteratively solvesLP^^kto obtain an optimal solution (i.e. Step 2), find its representative set in Step 3, and find an optimal solution with the minimal representative set in Step 4. This process is repeated at most n times until the minimal tight set has full rank. A demonstration of how Algorithm 1 works on a small flow game is presented in Section 6.3.We can prove that Algorithm 3 ends in no more than(n−1)iterations by using a similar proof to that of Theorem 1 since the rank ofRk*keeps increasing through iterations by the construction ofLP^^k. The correctness of Algorithm 3 in producing the nucleolus can be proven in a similar way as that shown in Theorem 2 by noticing the fact thatspan(Rk*)≡span(H^k*)and henceLP^^kis equivalent toLP^k.We demonstrate the applicability of our algorithm to three classes of games. In these games, the entire characteristic functions are costly to be computed for instances with more than 25 players, e.g. it might involve solving up to 2noptimisation problems just for getting the input of the general flow games Kalai and Zemel (1982). We show that by using the constraint generation framework, we can eliminate this stage and only compute some of the characteristic values by searching for the most violating constraints.The flow games were proposed by Kalai and Zemel (1982). Consider a network G(V, E, c, s, t) with verticesV, edgesE, edge capacityc, source s and sink t. Each player owns an edge amongn=|E|number of edges. In the case all the players cooperate, the total payoff (reward) received by all the players will be the maximum flow that can be sent from source s to sink t:v(N)=max-flow(G). The max-flow problem can be formulated as an LP as follows:maxf∑j:(s,j)∈Efsj,s.t.∑j:(j,i)∈Efij−∑k:(i,k)∈Efik=0,∀i∈V∖{s,t},0≤fij≤cij,∀(i,j)∈E.Suppose only a subsetS∈Cof players cooperate among themselves. The total payoff received by players in the setSwill become:v(S)=max-flow(V,E(z),c(z),s,t),which is the maximum flow that can be sent from sources s to sink t by using only the edges in subsetS. Deng et al. (2009) show that finding the nucleolus is NP-hard for general flow games. The nucleolus can only be found in polynomial time if all the edges have unit capacities. Even in that case, the algorithm relies on the ellipsoid method which performs poorly in practice.In order to apply the constraint generation framework, we need to find the worst coalition for a current proposalx, i.e. to solvemaxz∈{0,1}mv(z)−xtz,s.t.z∉span(H^k−1*),wherezis the binary vector that indicates whether an edge is in the subsetS,and v(z) is the payoff of coalitionSwhich can be formulated as follows:(7a)v(S)≡v(z)=maxf∑j:(s,j)∈Efsj,s.t.∑j:(j,i)∈Efji−∑k:(i,k)∈Efik=0,∀i∈V∖{s,t},(7b)0≤fij≤zijcij,∀(i,j)∈E.The set of constraints (7b) forces the flow fijto be zero if an edge (i, j) is not in the coalition. With the characteristic functionv(S)available for each coalitionS,the nucleolus of the game provides a stable reward distribution among the players. In this paper, we are interested in providing a practical computational method for computing the nucleolus of general flow games.By replacing the formulation for v(z) and combine the two max operators together, the CG problem can be reformulated as:maxz,f−xtz+∑j:(s,j)∈Efsj,s.t.∑j:(j,i)∈Efsj−∑k:(i,k)∈Efik=0,∀i∈V∖{s,t},0≤fij≤zijcij,∀(i,j)∈E,z∉span(Rk*),z∈{0,1}n.In the weighted voting games (WVG), each player has a voting weight and a coalition receives a payoff of one if the total voting weight of the coalition’s members exceeds some threshold and a payoff of zero otherwise (see Elkind et al. (2007)Elkind and Pasechnik (2009)Leech (2003) for details). WVGs have many applications in political science, reliability theory and computer science (see Aziz et al. (2007) and the references therein). Let wibe the number of votes that player i has. A coalitionShas a total votes ofω(S)=∑i∈Swi. The coalition will win the game if its total votes exceeds some threshold κ. The characteristic function of the game is defined as:v(S)=1ifω(S)≥κandv(S)=0otherwise. Elkind et al. (2007) and Elkind and Pasechnik (2009) show that computing the least core of the WVG is NP-hard. They also show that the nucleolus can be computed in polynomial time under the assumption that the size of the tight setT^k(x)is known. However, finding the size|T^k(x)|is not straightforward, especially for WVG with exponentially large tight sets. In addition, the polynomial running time property that the authors derived is based on the ellipsoid method which does not perform well in practice. Despite these NP-hardness results, we will show that, by using our method, the WVG can be solved efficiently for instances involving sizes up to 100 players.Since the main routine in computing the nucleolus is to find the coalition with the largest deficitv(S)−x(S)from a given imputationx, we focus our discussion on this problem. The constraint generation problem arisen in solving LPkis:maxz∈{0,1}n{v(z)−ztx|v(z)−x^k−1(z)<ϵk−1*}. We introduce a binary variablez0=v(z)and reformulate the problem as:max(z0,z)∈{0,1}n+1{z0−ztx|ωtz≥z0κ,z0−x^k−1tz<ϵk−1*}.Here, the constraintωtz≥ z0κ ensures thatz0=0whenωtz< κ (the strict inequality can be turned into a normal inequality likeωtz<=κ−miniwiby using the fact thatzis binary and κ is sufficiently large compared to miniwi). However, z0 should be equal to 1 to drive the objective function to optimality if the conditionωtz≥ κ holds. This is an MILP with(n+1)binary variables and with two constraints and can be solved very efficiently. The constraint generation problem arisen in solvingLP^kcan be formulated in a similar way with the constraintz∉H^k*is replaced withz∉span(H^k*).Weighted coalitional skill games (WCSG) were proposed by Bachrach and Rosenschein (2008). In this game, there are n agents, T tasks and K skills. Each agent has a subset of skills and each task requires a subset of skills. Let Ψ be the agent-skill matrix with binary indicator ψikdenoting whether agent i has skill k. Let Φ be the task-skill matrix with binary indicator ϕtkdenoting whether task t requires skill k. For each task t, and the skill vector Φtthat it requires, the coalitionzwill be able to perform the task if there exists at least one agent in the coalition that has skill ϕtk. We consider a weighted average utility function defined as follows. Let Δ(z, t) be the binary indicator on whether coalitionzcan perform task t. Then the coalition value is defined asv(S)=∑t∈1..TωtΔ(z,t)whereΔ(z,t)={1ifΨTz≥Φt,0otherwise.We will show that the constraint generation problem can be solved efficiently in the WCSG games with reasonable size (i.e. n ≤ 500). Let us define variableδt=Δ(z,t). In this case, the constraint generation problem for solving LPkisminz∈{0,1}n[ztx−v(z)]can be reformulated as:minz∈{0,1}nztx−∑t=1mωtΔ(z,t),which is equivalent to:(8a)minz,δztx−∑t∈1..mωtδt,s.t.ΨTz≥δtΦt,∀t∈1,..,m,(8b)z∈{0,1}n,δt∈{0,1}m.The set of constraints (8a) forces δtto be equal to zero if coalitionzdoes not have all the skill required in Φt. Otherwise, δtshould be equal to one to drive the objective function to the optimum. The constraint generation problem is a mixed integer programming problem with(n+m)binary variables and with(m+t)constrains. Although the problem is NP-hard, we will show numerically that CPLEX can handle this class of games for instances with up to 75 players (under various choices of the skills and tasks).In our numerical experiments, we start with a small flow game to demonstrate the steps involved in our algorithm. Simulated large weighted voting games and coalitional skill games with 25 to 100 players are presented to demonstrate the performance of the algorithm in detail.Consider a flow game shown in Fig. 4. There aren=10players (edges) that are numbered according to the figure. The capacities of the edges arec1=c9=3,ci=1,∀i∈{3,…,8}andc2=c10=2. Table 2shows the step involved in computing the nucleolus of this game as described in Algorithm 1. The following three key tasks are undertaken iteratively:(1)SolveLP^^kby using the constraint generation algorithm to produce an optimal solutionx^k,Solve the REP problem to find the representative set of all tight constraints inT^(x^k),Solve the FBOS2 problem iteratively to find an optimal solution with the minimal tight set. If the stopping condition doesn’t hold, formulate the subsequentLP^^kand go back to step (1).The first two columns in Table 2 show the steps and the tasks undertaken. The third column shows the input required. The fourth column shows the output and some remark about it. The rows shows the information for each step taken by the algorithm. For example, the first row shows step 1 of solving LP1. That step producesϵ1*^=0andx^1=[1,1,0,0,1,0,0,0,1,0]. Using the CG algorithm, we obtain an optimal solution after only 16 iterations. The tight set produced by the last relaxed LP outputs only four tight constraints among the total of 135 tight constraints. Instead of iteratively finding all the remaining tight constraints, our method requires finding only 6 other constraints to form the representative tight set by solving problem REP (the third row in Table 2). With this representative set, we solve FBOS2 to obtain an improved optimal solution. First, we obtainx^1=(1,0.5,0,0,1,0,0.5,0,1)with the tight set reduced to|T^1(x^1)|=75andrank(T^1(x^1))=9. Solving the FBOS2 three more times provides us with three new optimal solutions with the tight set sizes being 29, 17 and 11 respectively. The ranks of the tight sets are also reduced from 9 to 6, 5 and 4 respectively (shown in rows 4–7). The optimal solution found isx^1*=(1,0.4375,0,0.125,0.75,0.25,0.5,0,0.875,0.0625). At this point, the tight set has the smallest size and we can proceed to the subsequent LP. Solving LP2, again using the CG algorithm, provides us with the optimal solutionϵ^2*=−0.2andx^2=(0.8,0.2,0,0.2,0.6,0.6,0.6,0,0.8,0.2). We repeat the process of solving the REP and FBOS2 and formulate LP3. After finding the representative set and solving FBOS2, we arrive at an optimal solutionx^2*=(1,0.2,0,0.2,0.4,0.4,0.6,0,1,0.2)with the minimal tight set. SinceH^3*has full rank. We stop the algorithm and conclude thatx^2*is the nucleolus.We generate WVGs with different size and parameters as follows. For eachn={25,50,75,100},we generate random weight vectors using the χ2 distribution with different degrees of freedom ρ, i.e.ρ={1,5,n}. The winning fraction f is set to eitherf=0.5orf=0.75,i.e. eitherκ=⌈0.5etω⌉orκ=⌈0.75etω⌉. For each combination of (n, ρ, f), we generateK=10simulated games. Table 3shows the computational results for these games in details. The first column in Table 3 shows the number of the players, which ranges from 25 to 100. The second and third columns show the distribution function of the weight vector and he winning fraction correspondingly. Columns 4-9 show the computation time (in seconds) required to run the entire algorithm or to complete different subtasks. Column 4 shows the total computational time from the beginning until the nucleolus is found. The total computation time is broken down into three parts; (a) to solve all theLP^^k,(b) to find the representative set, and (c) to find an improved imputation. The computational times for these tasks are shown in column five, six and seven correspondingly. The computation time for solving theLP^^kis further broken down to the time to solve the relaxed LPs and to solve the constraint generation sub-problems. These are shown in columns 8 and 9. Column 10 shows the number ofLP^^krequired and column 11 shows number of iterations required for the constraint generation algorithm to solveLP^^k. Each row shows the average of these computation statistics over K games for each combination of (n, ρ, f). For example, the second row shows all the statistics for games with 25 players; the weight vector is fromχ12and the winning fraction is 50 percent while the last row is for games with 100 players; the weight vector is fromχ1002and the winning fraction is 75 percent.From the third column, we can observe that the total computation time increase with the number of players. The longest computational time is 238.39 seconds for the largest games with 100 players. Most of the time is taken up for solving theLP^^kwhile the total times to find the representative set (REP) and to find improved imputation (FBOS2) are small (note that we have used FBOS2 instead of FBOS because of the exponentially large tight sets). Column 10 shows that these voting games require solving onlyLP^^1. All these LPs require less than 500 iterations in the constraint generation algorithm to find an optimal solution. This means that instead of having to solve a big LP with 2nconstraints, the CG algorithm solves less than 500 small relaxed LPs and 500 constraint generation problems. The small numbers of iterations used is in fact aligns with the results in Reijnierse and Potters (1998) where the authors show that there exists a set of2(n−1)coalitions that determines the nucleolus of an n-players game. Columns 8 and 9 show that the computation times required to solve these relaxed LPs and the CG problems are relatively small. All the numerical results are tested on a personal computer with 2.67 gigahertz CPU, 12 gigabyte RAM, and the Windows 7, 64-bit operating system. We use MATLAB for coding and use IBM CPLEX Studio Academic version 12.4 for solving LPs and MILP problems under default settings.We generate coalitional skill games with different size and parameters as follows. For eachn={25,50,75},we generate random skill matrix Ψ using the binomial distribution with different success ratesρ={0.5,0.7,0.9}. We generate K simulated games withK=20forn={25,50}andK=10forn=75. Table 4 shows the computational results for these games in details. The columns and rows shown in Table 4 have the same interpretation compared to those in Table 3. Overall, the total computational time increases as the number of players increase (the total time variation by changing other parameters are mixed). The total time is broken down into three main tasks for solving the LPs, finding the representative set and for finding solution with the minimal tight set. In most cases except for the second last row with(n,m,k,ρ)=(75,20,10,0.7)the task that took the most time is for solving the large LPs. The second last column shows the number of LPs involved in the nested LPs. This ranges from solving a single LP to up to 8 LPs. Among all the 300 instances generated, the worst instance with the maximum total time is under 30 minutes.

@&#CONCLUSIONS@&#
