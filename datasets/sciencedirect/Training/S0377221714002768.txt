@&#MAIN-TITLE@&#
Convergence of controlled models and finite-state approximation for discounted continuous-time Markov decision processes with constraints

@&#HIGHLIGHTS@&#
Convergence of the optimal values for discounted constrained continuous-time Markov decision processes (CTMDP).Convergence of optimal policies for discounted constrained CTMDP.Finite-state approximation to countable-state discounted constrained CTMDP.Applied examples and convergence rates.

@&#KEYPHRASES@&#
Constrained continuous-time Markov decision processes,Unbounded transition rate,Convergence,Finite approximation,

@&#ABSTRACT@&#
In this paper we consider the convergence of a sequence{Mn}of the models of discounted continuous-time constrained Markov decision processes (MDP) to the “limit” one, denoted byM∞. For the models with denumerable states and unbounded transition rates, under reasonably mild conditions we prove that the (constrained) optimal policies and the optimal values of{Mn}converge to those ofM∞, respectively, using a technique of occupation measures. As an application of the convergence result developed here, we show that an optimal policy and the optimal value for countable-state continuous-time MDP can be approximated by those of finite-state continuous-time MDP. Finally, we further illustrate such finite-state approximation by solving numerically a controlled birth-and-death system and also give the corresponding error bound of the approximation.

@&#INTRODUCTION@&#
Constrained Markov decision processes (MDP) form an important class of stochastic control problems with applications in many areas such as telecommunication networks and queueing systems; see, for instance, Guo and Hernández-Lerma (2009), Hordijk and Spieksma (1989), and Sennott (1991). As is well known, the main purpose of studies on constrained MDP is on the existence and computation of optimal policies, see, for instance, the literature on the discrete-time MDP by Feinberg and Shwartz (1999), Feinberg (2000), Hordijk and Spieksma (1989), Hernández-Lerma and González-Hernández (2000), Hernández-Lerma, González-Hernández, and López-Martínez (2003), and Sennott (1991), and the works on continuous-time MDP by Guo (2007), Guo and Hernández-Lerma (2003), Guo and Hernández-Lerma (2009), Guo and Piunovskiy (2011). On the other hand, from a theoretical and practical point of view, it is of interest to analyze the convergence of optimal values and optimal policies for constrained MDP, and such convergence problems have been considered, see, for instance, Altman (1999), Zadorojniy and Shwartz (2006), Alvarez-Mena and Hernández-Lerma (2002) and so on. Alvarez-Mena and Hernández-Lerma (2006) also consider the convergence problem as in Alvarez-Mena and Hernández-Lerma (2002) for the case of more than one controller. To the best of our knowledge, however, these existing works for the convergence problems are on the constrained discrete-time MDP. Most recently, the convergence problem of controlled models for unconstrained continuous-time MDP has also been considered by Prieto-Rumeau and Lorenzo (2010) and Prieto-Rumeau and Hernández-Lerma (2012) using an approximation of the optimality equations. However, the similar convergence problem for constrained continuous-time MDP has not been considered.This paper studies the convergence problem for constrained continuous-time MDP. More precisely, in this paper we consider a sequence{Mn}of the models of the constrained continuous-time MDP with the following features: (1) the state space is denumerable, but action space is general; (2) the transition rates and all reward/cost functions are allowed to be unbounded; and (3) the optimality criterion is the expected discounted reward/cost, while some constraints are imposed on similar discounted rewards/costs. We aim to give suitable conditions imposed on the models{Mn}, under which the optimal policies and the optimal values of{Mn}converge to those of the limit modelM∞of the sequence{Mn}, respectively.In general, the approaches to study continuous-time MDP can be roughly classified into two groups: the indirect method and the direct method. For the indirect method, the idea is to convert the continuous-time MDP into equivalent discrete-time MDP. This approach has been justified by Feinberg (2004), Feinberg (2012), and Piunovskiy and Zhang (2012). On the other hand, the most common direct method to investigate constrained continuous-time MDP is to establish an equivalent linear program formulation of the original constrained problem, see Guo and Piunovskiy (2011). In this paper, we follow this direct approach without involving discrete-time MDP. First, as in Guo and Piunovskiy (2011), we transform the optimality problem in constrained continuous-time MDP into an equivalent optimality problem over a class of some probability measures by introducing an occupation measure of a policy. Then, we analyze the asymptotic characterization of the occupation measure and the expected discounted rewards/costs, which are used to prove that the optimal values and optimal policies of the sequence{Mn}converge to those ofM∞. Finally, we apply our results to the approximations of the optimal policies and the optimal value of finite-state continuous-time MDP to those of countable-state continuous-time MDP. More precisely, for a modelM∞′of constrained countable-state continuous-time MDP satisfying the usual conditions as in Guo and Hernández-Lerma (2009) and Guo and Piunovskiy (2011), we can construct a sequence of models{Mn′}of constrained continuous-time MDP with finite states such that every accumulation point of a sequence of optimal policies ofMn′is optimal forM∞′and that the sequence of the optimal values ofMn′converge to the optimal value ofM∞′. Furthermore, we further illustrate such finite-state approximation by solving numerically a controlled birth-and-death system, and also give the corresponding error bound of the approximation. The motivation of providing such approximation is from the following facts: (i) there exist many methods to solve the optimal value and optimal policies for unconstrained continuous-time MDP with finite sates, for example, the value iteration algorithm and the policy iteration algorithm by Guo and Hernández-Lerma (2009) and Puterman (1994), the approximation dynamic programming technique by Cervellera and Macciò (2011), and so on. However, these methods, which are all based on the optimality equation, are not applied to constrained continuous-time MDP since the optimality equation no longer exists for the constrained MDP; (ii) the optimal value and optimal policies for finite-state constrained continuous-time MDP with finite actions can be computed by the well known linear programming in Guo and Piunovskiy (2011) and Puterman (1994), whereas in general the optimal value and optimal policies cannot be computed for countable-state continuous-time MDP because the number of states in such MDP is infinite.The rest of this paper is organized as follows. In Section 2, we introduce the models of constrained continuous-time MDP and the convergence problems. In Section 3, we state our main results, which are proved in Section 6, after technical preliminaries given in Section 5. An application of the main results to finite state approximation and a numerable example are given in Section 4. Finally, we finish this article with a conclusion in Section 7.In this section we introduce the models and convergence problems we are concerned with.Notation. If X is a Polish space, we denote byB(X)its Borelσ-algebra, byDcthe complement of a setD⊆X(with respect to X), byP(X)the set of all probability measures onB(X), endowed with the topology of weak convergence. For a finite set D, we denote by|D|the number of its elements. LetN≔{1,2,…}andN‾≔N⋃{∞}.Consider the sequence of models{Mn}for constrained continuous-time MDP:(2.1)Mn≔Sn,(An(i),i∈Sn),qn(·|i,a),cn0(i,a),cnl(i,a),dnl,1⩽l⩽p,γn,n∈N‾,whereSnare the state spaces, which are assumed to be denumerable. The setAn(i)represents the set of available actions or decisions at statei∈Snfor modelMn. LetKn≔(i,a)|i∈Sn,a∈An(i),represent the set of all feasible state-action pairs forMn.In what follows, we assume thatSn↑S∞, andS∞={0,1,…,n,…}without loss of generalization. As a consequence, for eachi∈S∞, we can definen(i)≔min{n⩾1,i∈Sn}. Furthermore, we assume thatAn(i)⊆A∞(i)(n⩾n(i),i∈S∞), and moreover, for eachn∈N‾,An(i)is inB(An), whereAnis a Polish space, the action space forMn. Thus,B(An(i))=B(A∞(i))∩An(i)andP(An(i))⊆P(A∞(i)), for eachi∈S∞andn⩾n(i).For fixedn∈N‾, the functionqn(·|i,a)in (2.1) refers to the conservative transition rates, that is,qn(j|i,a)⩾0and∑j∈Snqn(j|i,a)=0for all(i,a)∈Knandi≠j. Moreover,qn(j|i,a)is a measurable function onAn(i)for each fixedi,j∈Sn. Furthermore,qn(j|i,a)is assumed to be stable, that is,qn∗(i)≔supa∈An(i)|qn(i|i,a)|<∞for eachi∈Sn.Finally,cn0corresponds to the objective cost function, andcnl(1⩽l⩽p)correspond to the cost functions on which some constraints are imposed. The real numbersdnl(1⩽l⩽p)denote the constraints, andγndenotes initial distribution onSnforMn.To complete the specification of{Mn}(n∈N‾), we introduce the classes of policies.A randomized Markov policyπforMnis a family(πt,t⩾0)of stochastic kernels satisfying: (i) for eacht⩾0andi∈Sn,πt(·|i)is a probability measure (p.m.) onAn(i); and (ii) for eachD∈B(An(i)), andi∈Sn,πt(D|i)is a Borel measurable function int⩾0.Moreover, a policyπ=(πt,t⩾0)is called (randomized) stationary forMnif, for eachi∈Sn, there is a p.m.π(·|i)∈P(An(i))such thatπt(·|i)≡π(·|i)for allt⩾0. We denote this policy by(π(·|i),i∈Sn). We denote byΠnthe family of all randomized Markov policies and byΠnsthe set of all stationary policies for eachn∈N‾.For eachn∈N‾and policyπ=(πt,t⩾0)∈Πn, let(2.2)qn(j|i,πt)≔∫An(i)qn(j|i,a)πt(da|i),cnl(i,πt)≔∫An(i)cnl(i,a)πt(da|i)for eachi,j∈Sn,t⩾0, and0⩽l⩽p. Whenπis stationary, we will writeqn(j|i,πt)andcnl(i,πt)asqn(j|i,π)andcnl(i,π), respectively.LetQn(t,π)≔[qn(j|i,πt)]be the associated matrix of transition rates with the(i,j)th elementqn(j|i,πt). As the matrix[qn(j|i,a)]is conservative and stable, so isQn(t,π). Thus, Proposition C.4 in Guo and Hernández-Lerma (2009) ensures the existence of a so-called minimal transition function (see, Definition C.3 in Guo and Hernández-Lerma (2009))pn(s,i,t,j,π)forMnwithi,j∈Snandt⩾s⩾0.To guarantee the regularity condition (i.e.∑j∈Snpn(s,i,t,j,π)=1for alli∈Snandt⩾s⩾0), we impose the following so-called drift conditions.Assumption 2.1There exist a function1⩽ωonS∞andω(i)↑+∞asi→∞, and constantsρ,b,L>0, such that(a)∑j∈Snqn(j|i,a)ω(j)⩽ρω(i)+bfor all(i,a)∈Kn,n∈N‾;qn∗(i)⩽Lω(i)for alli∈Sn,n∈N‾.For eachπ∈Πn,n∈N‾andγn∈P(Sn), under Assumption 2.1, by Proposition C.9 and Theorem 2.3 in Guo and Hernández-Lerma (2009), the correspondingpn(s,i,t,j,π)is unique and regular, and moreover, there exists a unique probability space(Ω,F,Pγnπ)and a state-action process{(xt,at),t⩾0}defined on this space. The expectation operator with respect to the probability measure (p.m.)Pγnπis denoted byEγnπ. Ifγnis concentrated at some state i, then we will writePγnπandEγπasPi,nπandEi,nπ, respectively.Fixed a discount factorα>0. The expected discounted criteriaVnl(π)are defined by(2.3)Vnl(π)≔∫0∞e-αtEγnπcnl(xt,at)dt,for0⩽l⩽p,n∈N‾,andπ∈Πn.The criteria (2.3) are well defined under Assumptions 3.1(c,d) below.Vnl(π)will be denoted asVnl(i,π)if the initial distributionγnis concentrated at statei∈Sn.For everyn∈N‾, letUn≔{π∈Πn|Vnl(π)⩽dnl,1⩽l⩽p},andVn0∗=infπ∈UnVn0(π)be the set of feasible policies and the optimal value ofMn, respectively.For eachn∈N‾, we then consider the following constrained optimality problem:(2.4)MinimizeVn0(π)overπ∈Un.(Ascnl(i,a)is allowed to take positive and negative values for each0⩽l⩽pandn∈N‾, it can be interpreted as rewards rather than “costs” only, and thus the corresponding constrained optimality problem is to maximize theVn0(π)overπ∈Un.)In order to make these problems reasonable, we introduce the following assumption:Assumption 2.2For eachn∈N‾, the setUnis not empty.(i)For anyn∈N‾, a policyπ∗∈Unis called (constrained) optimal forMnifVn0(π∗)=Vn0∗.A sequence{πn}of policiesπn∈Πnsis said to converge weakly toπ∈Π∞s, if, for eachi∈S∞,πn(·|i)→π(·|i)weakly inP(A∞(i))asn(i)⩽n, andn→∞.As is known, the existence of an constrained optimal policy for each fixedn∈N‾is ensured in Guo and Piunovskiy (2011) under suitable conditions. Here, we are interested in the following convergence problems:(1)(Convergence of the optimal values): doesVn0∗converges toV∞0∗asn→∞?(Convergence of the optimal policies): ifπn∗is the constrained optimal policy ofMn(n∈N), is every accumulation point of{πn∗}an optimal policy ofM∞?In this section, we state our main results. Their proofs are postponed to Section 6 below.First, for the existence of an optimal policyπn∗ofMn, we need the following conditions:Assumption 3.1(a)For eachn∈N‾andi∈Sn,An(i)is compact.The discount factorαsatisfies thatα>ρ, withρas in Assumption 2.1.supn∈N‾∑i∈Snω2(i)γn(i)<∞, and∑j∈Snqn(j|i,a)ω2(j)⩽κ1ω2(i)+κ2for alln∈N‾and(i,a)∈Kn, with some constants0<κ1<αand0⩽κ2.|cnl(i,a)|⩽Mω(i)for all(i,a)∈Kn,0⩽l⩽pandn∈N‾, with some constantM>0.The functionsqn(j|i,·)andcnl(i,·)are all continuous ina∈An(i), for each fixedn∈N‾,i,j∈Sn, and0⩽l⩽p.Assumption 3.1(a) implies that the spaceP(An(i))with the topology of weak convergence is also compact for alln∈N‾andi∈Sn. Then, it follows from Tychonoff’s theorem thatΠns=Πi∈SnP(An(i))is compact too. Moreover, it follows from Theorem 3.1(a) in Guo and Piunovskiy (2011) and Assumptions 3.1(b,c,d) that(3.1)Vnl(i,π)⩽M[αω(i)+b]α(α-ρ),Vnl(π)⩽Mα∑i∈Snω(i)γn(i)+bα(α-ρ)for eachn∈N‾,i∈Sn,π∈Πnand0⩽l⩽p.To show our main results, we consider the following assumptions:Assumption 3.2(a)limn→∞supa∈An(i)|qn(j|i,a)-q∞(j|i,a)|=0, for eachi,j∈S∞, wheren⩾max{n(i),n(j)};limn→∞supa∈An(i)|cnl(i,a)-c∞l(i,a)|=0, for alli∈S∞,0⩽l⩽p, wheren⩾n(i);limn→∞γn(i)=γ∞(i), for eachi∈S∞, wheren⩾n(i);limn→∞dnl=d∞l, for each1⩽l⩽p.(a)(Slater condition) There exists a policyπ∈Π∞such that(3.2)V∞l(π)<d∞lforall1⩽l⩽p.For eachi∈S∞,An(i)↑A∞(i)asn→∞, wheren⩾n(i).(a)Assumption 3.2(a) is used to obtain the convergence feature of occupation measure, see Theorem 5.1 below. Assumptions 3.2(b–d) have been used in Alvarez-Mena and Hernández-Lerma (2002) for discrete-time MDP.Assumption 3.3(a) is used to establish the duality between the convex analytic approach and dynamic programming by Guo and Piunovskiy (2011), and the existence of a constrained optimal policy with the structural property by Guo and Hernández-Lerma (2003, 2009) and Sennott (1991). Here, the role of Assumption 3.3 can be concluded in two parts. First, Assumption 3.3 is used to replace Assumption 2.2 for the fact that the setUnfor the “approximating” modelsMnis nonempty for larger enough n, see Proposition 5.1 below. On the other hand, it is used for the existence of feasible policies of{Mn}corresponding any given feasible policy ofM∞. In fact, the role of Assumption 3.3 is the same as Assumption 3.8 in Alvarez-Mena and Hernández-Lerma (2002) and same as Definition 3.1(b) in Prieto-Rumeau and Hernández-Lerma (2012).We next state our main results about the convergence problems:Theorem 3.1UnderAssumptions 2.1 and 3.1, the following assertions hold.(a)If, in addition,Un≠∅for somen∈N‾, then an optimal policy forMnexists.If, in addition,Assumptions 3.2 and 3.3hold, then there exists an integer N such that(b1)for eachn⩾N,Mnhas an optimal policyπn∗∈Πns;every accumulation point of{πn∗}(withπn∗as in(b1)) is an optimal policy forM∞;limn→∞Vn0∗=V∞0∗.See Section 6 below.□In this section, we apply Theorem 3.1 to a finite-state approximation in Section 4.1, that is, we will show that an optimal policy and the optimal value for a countable-state constrained continuous-time MDP can be approximated by those of solvable finite-state continuous-time MDP. Furthermore, we illustrate such approximation by a controlled birth-and-death system in Section 4.2.Consider the modelM∞′of countable-state constrained continuous-time MDP:(4.1)M∞′≔S,(A(i),i∈S),q(·|i,a),c0(i,a),(cl(i,a),dl,1⩽l⩽p),γ,which is a copy ofMnin (2.1). Since S is denumerable, without loss of generalization, we write S asS=:{0,1,…,n,…}. For eachn⩾1, letSn≔{0,1,…,n},An(i)≔A(i)fori∈Sn, andKn≔{(i,a)|i∈Sn,a∈An(i)}. Moreover, for eachi,j∈Sn,a∈An(i), let(4.2)qn′(j|i,a)≔q(j|i,a)ifj∈Sn⧹{n}q(n|i,a)+qSnc|i,aifj=n;and(4.3)γn′(i)≔γ(i)ifi∈Sn⧹{n}γ(n)+γ(Snc)ifi=n;(4.4)c̃nl(i,a)≔cl(i,a),andd̃nl≔dl,foreach0⩽l⩽p.Then, we obtain a sequence of finite-state modelsMn′:(4.5)Mn′≔Sn,(An(i),i∈Sn),qn′(·|i,a),c̃n0(i,a),c̃nl(i,a),d̃nl,1⩽l⩽p,γn′.For each fixedn∈N‾, as in (2.3) and Definition 2.1, we define the corresponding discounted criteriaV∼nl(π), an optimal policyπn′ofMn′, and the optimal valueV∼n0∗ofMn′.Suppose thatA(i)is finite for eachi∈Sin this section, and so isAn(i)for everyi∈Snandn⩾1. Then, to solve an optimal policy and the optimal value ofMn′withn∈N, we can consider the followingLPn′:LPn′:infη1α∑i∈Sn∑a∈An(i)c0(i,a)η(i,a)subjectto∑i∈Sn∑a∈An(i)cl(i,a)η(i,a)⩽αdl,1⩽l⩽pα∑a∈An(i)η(i,a)=αγn′(i)+∑j∈Sn∑a∈An(j)qn′(i|j,a)η(j,a),∀i∈Sn,∑i∈Sn,a∈An(i)η(i,a)=1,η(i,a)⩾0,i∈Sn,a∈An(i).Since theLPn′is a linear program with finite number of variablesη(i,a)(i∈Sn,a∈An(i)), an optimal solution to theLPn′can be solved by many methods such as the well known simplex method.Definition 4.1For each fixedn∈N, a stationary policyπ∈Πnsis called m-randomized if∑i∈Sn(|Anπ(i)|-1)⩽m, whereAnπ(i)≔{a∈An(i)|π(a|i)>0}.For linear programmingLPn′andMn′, we have the following fact:Lemma 4.1For eachn∈N, letηn∗be an optimal solution to theLPn′above. Then,(1)πn′is an optimal policy ofMn′, whereπn′is given by(4.6)πn′(a|i)=ηn∗(i,a)ηˆn∗(i)whenηˆn∗(i)≔∑a∈An(i)ηn∗(i,a)>0anda∈An(i),I{an(i)}(a)whenηˆn∗(i)=0anda∈An(i),for alli∈Sn, wherean(i)∈An(i)is chosen arbitrarily;V∼n0∗=1α∑i∈Sn∑a∈An(i)c0(i,a)ηn∗(i,a);there exists an optimal p-randomized policyπ∈Πnsfor eachMn′.This conclusion follows from Theorem 3.8 in Altman (1999) and Lemma 5.1.□Suppose that there exist a function1⩽ω̃on S andω̃(i)↑+∞asi→∞, and constantsρ′,b′,L′,κ1′,κ2′>0, satisfying the following conditions:(1)∑j∈Sq(j|i,a)ω̃(j)⩽ρ′ω̃(i)+b′, and∑j∈Sq(j|i,a)ω̃2(j)⩽κ1′ω̃2(i)+κ2′for all(i,a)∈K.q∗(i)≔supa∈A(i)|q(i|i,a)|⩽L′ω̃(i),|cl(i,a)|⩽L′ω̃(i)for all(i,a)∈Kand0⩽l⩽p.The discount factorαverifies thatα>ρ′andα>κ1′.∑i∈Sω̃2(i)γ(i)<∞.There exists a policyπ∈Π∞such thatV∼∞l(π)<dlfor all1⩽l⩽p.Then,(a)there exists an optimal policyπn′∈ΠnsofMn′for eachn⩾N, with someN⩾1;every accumulation point of{πn′}(withπn′as in(a)) is an optimal policy ofM∞′;limn→∞V∼n0∗=V∼∞0∗.Fix anyn⩾1. By (4.2), it is obvious that functionqn′(j|i,a)denotes indeed transition rates, which are conservative and stable. Also, Assumption 2.1(b) holds forqn′(j|i,a). Moreover, for each(i,a)∈Kn, sinceω̃(i)is nondecreasing, andq(k|i,a)⩾0for eachk∈Snc, we have∑j∈Snqn′(j|i,a)ω̃(j)=∑j∈Sn⧹{n}qn′(j|i,a)ω̃(j)+qn′(n|i,a)ω̃(n)⩽∑j∈Snq(j|i,a)ω̃(j)+∑k∈Sncq(k|i,a)ω̃(k)⩽ρ′ω̃(i)+b′,which implies Assumption 2.1(a).Similarly, we can deduce Assumption 3.1(c) from the conditions (1,3,4) and (4.3).Obviously, Assumptions 3.1(a,b,d,e) and 3.3 follow from the conditions (2,3,5), (4.2), (4.3) and (4.4) and the definition ofA(i). The rest verifies Assumption 3.2. Leti,j∈Sbe fixed, there exists an integer N such that for eachn>N,i∈Snandj≠n. Soqn′(j|i,a)=q(j|i,a)andc̃nl(i,a)=cl(i,a)for eachn>N,0⩽l⩽panda∈An(i), which, together with (4.3) and (4.4), imply Assumption 3.2.Therefore, Assumptions 2.1 and 3.1–3.3 are verified for the modelsMn′andM∞′, and thus Proposition 4.1 follows from Theorem 3.1.□In this subsection, we illustrate the finite-sate approximation with an example.Example 4.1Consider a controlled birth-and-death system in which the state variable denotes the population size at any timet⩾0. There are natural birth and death rates represented by nonnegative constantsλandμ, respectively. When the state of the system isi∈S≔{0,1,…}, the controller takes an actiona≔(a1,a2)from a given finite setA(i)≔{a1k|1⩽k⩽s,a1k>0}×{a2l|1⩽l⩽m,a2l>0}, in whicha1>0denotes the emigration rate anda2>0denotes the immigration rate, where s and m are given integers. These actions incur two costsc0(i,a)andc1(i,a). Moreover, the controller wishes to minimize the expected discounted cost corresponding toc0(i,a), while the expected discounted cost corresponding toc1(i,a)is maintained bounded above by a given constant d. Letγbe an initial distribution on S.We now formulate this system as a model for constrained continuous-time MDP. With costsc0(i,a),c1(i,a), and the constraint constant d as given in the system, the corresponding transition ratesq(j|i,a)are given as follows. For eachi⩾1anda=(a1,a2)∈A(i),(4.7)q(j|i,a)≔μi+a1ifj=i-1,-(μ+λ)i-a1-a2ifj=i,λi+a2ifj=i+1,0otherwise.andq(j|0,a)≔-a2ifj=0,a2ifj=1,0otherwise.First of all, to show that above model satisfies the hypothesis of Proposition 4.1, we introduce the following conditions.Condition 4.1(a)α>2(λ-μ), whereα>0is the given discount factor.There exists a constantM′>0such that|cl(i,a)|⩽M′(i+1)for all(i,a)∈Kandl=0,1.∑i∈Si2γ(i)<∞.There exists someã∈Asuch thatc1(i,ã)<αd, for eachi∈S.Under the Condition4.1, an optimal policy and the optimal value for the above controlled birth-and-death system can be approximated by those of finite-state birth-and-death systems constructed as in(4.5)(byProposition 4.1).From here and below, we consider the functionω̃(i)≔i+1for eachi∈S. Letθ1≔maxa1k:1⩽k⩽s,θ2≔maxa2l:1⩽l⩽m. By (4.7), it follows that(4.8)∑j∈Sq(j|i,a)ω̃(j)=(λ-μ)i+(a2-a1)⩽(λ-μ)ω̃(i)+μ-λ+θ2,∀i>0,a∈A(i),(4.9)∑j∈Sq(j|0,a)ω̃(j)=a2⩽θ2⩽(λ-μ)ω̃(0)+μ-λ+θ2,∀a∈A(0).Hence, by Condition 4.1(a), the first inequality in condition (1) of Proposition 4.1 holds with(4.10)b′≔max{μ-λ+θ2,0},ρ′≔maxλ-μ,α2.Hence, by Condition 4.1(a), for eachi>0anda∈A(i), we have∑j∈Sq(j|i,a)ω̃2(j)=2(λ-μ)(i+1)2+(3μ-2a1+2a2-λ)(i+1)+a1+a2-μ-λ⩽α2+λ-μ(i+1)2+λ-μ-α2i+1+3μ+2θ22λ-2μ-α2+θ1+θ2+(3μ+2θ2)22(α-2λ+2μ)⩽α2+λ-μω̃2(i)+θ1+θ2+(3μ+2θ2)22(α-2λ+2μ),∑j∈Sq(j|0,a)ω̃2(j)=3a2⩽3θ2⩽α2+λ-μω̃2(0)+3θ2,foreacha∈A(0),which imply, for each(i,a)∈K,(4.11)∑j∈Sq(j|i,a)ω̃2(j)⩽α2+λ-μω̃2(i)+κ2′<αω̃2(i)+κ2′,whereκ2′≔θ1+3θ2+(3μ+2θ2)22(α-2λ+2μ). Hence, the second inequality in condition (1) of Proposition 4.1 holds withκ1′≔α2+λ-μandκ2′above.Moreover, by straightforward calculations and (4.7), we have, for eachj∈Sanda∈A,(4.12)q∗(j)⩽(μ+λ)j+a1+a2⩽L′ω̃(j),whereL′≔μ+λ+θ1+θ2.Thus, from (4.12) and Condition 4.1(b), we see that the condition (2) in Proposition 4.1 holds. The conditions (3,4) in Proposition 4.1 follow from the Conditions 4.1(a,c). Finally, define a policy f by(4.13)f(i)≔ãforeachi∈S,withãasinCondition4.1(d).Hence,V∼∞1(f)<d, and so the condition (5) in Proposition 4.1 is satisfied.□Suppose that Condition4.1holds. Then, for theExample 4.1, there exists an integer N, such that for eachn⩾N,V∼n0∗-V∼∞0∗⩽D∑i=0n-1(i+1)2+α-1κ2′γ(i)(n+1)+∑i=n∞(i+1)γ(i)whereD≔2M′(α+b′)α(α-ρ′)4M′α∑i∈S(i+1)γ(i)+b′θ3α(α-ρ′)+1,θ3≔d-V∼∞1(f), and the constantsM′,b′,ρ′are defined in Condition4.1(b) and(4.10).For eachπ∈Πns, we can define an associated policyπ̃∈Π∞sby(4.14)π̃(·|i)≔π(·|i)ifi∈Sn,νifi∈Snc,whereν∈P(A(i))ischosenarbitrarily.To avoid confusion, we usextπto denote the state process{xt}corresponding to a given policyπ. Then, for eachn∈N‾,π∈Πnsandk∈Sn, letτk(π)≔inft>0:xtπ⩾k=inft>0:xtπ=k(since the population augments at most by one individual at each transition). For eachn∈N‾,π∈Πnsandj∈Sn, it follows from the argument at page 263 in Anderson (1991) thatEj,nπ[τj+1(π)]<∞, which implies thatτj+1(π)<∞a.s.Pj,nπ. Then, for eachn∈N‾,π∈Πnsandj<k∈Sn, by the strong Markov property, we have(4.15)Ej,nπ[τk(π)]=Ej,nπ[τj+1(π)]+Ej,nπ[τk(π)-τj+1(π)]=Ej,nπ[τj+1(π)]+Ej,nπEj,nπ[τk(π)-τj+1(π)|Fτj+1(π)]=Ej,nπ[τj+1(π)]+Ej+1,nπ[τk(π)],whereFτj+1(π)denotes theσ-algebra associated withτj+1(π). Leti<kbe fixed, by summing both sides of the equality (4.15) from i tok-1, we have(4.16)Ei,nπ[τk(π)]=∑m=ik-1Em,nπ[τm+1(π)]<+∞,andsoτk(π)<+∞a.s.Pi,nπ.Recalling thatω̃(i)=i+1, by the similar calculations as in (4.11), we have(4.17)∑j∈Sq(j|i,a)ω̃3(j)=(3λ-3μ)ω̃3(i)+(6μ-3a1+3a2)ω̃2(i)+(3a2+3a1-4μ-2λ)ω̃(i)+(a2+μ-λ-a1)⩽(3λ+4μ+7θ2)ω̃3(i),foreachi>0anda∈A(i),(4.18)∑j∈Sq(j|0,a)ω̃3(j)=7a2⩽(3λ+4μ+7θ2)ω̃3(0),foreacha∈A(0),(4.19)q∗(i)ω̃2(i)⩽(λ+μ+θ2+θ1)ω̃3(i),foreachi∈S.By (4.16)–(4.19), it is legal to use Dynkin’s formula. Hence, by (4.11) and Dynkin’s formula, for eachi<n∈S,Ei,∞π̃e-ατn(π̃)ω̃2xτn(π̃)π̃⩽ω̃2(i)+κ2′Ei,∞π̃∫0τn(π̃)e-αtdt⩽ω̃2(i)+α-1κ2′,which implies that(4.20)Ei,∞π̃e-ατn(π̃)⩽ω̃2(i)+α-1κ2′ω̃2(n).Moreover, for eachi<n∈N, by the strong Markov property, (4.4) and (4.16),(4.21)V∼nl(i,π)=Ei,nπ∫0τn(π)e-αtc̃nl(xtπ,at)dt+Ei,nπ∫τn(π)∞e-αtc̃nl(xtπ,at)dt=Ei,nπ∫0τn(π)e-αtclxtπ,atdt+Ei,nπe-ατn(π)V∼nl(n,π)foreachl=0,1.Similarly, for eachi∈Sandl=0,1,(4.22)V∼∞l(i,π̃)=Ei,∞π̃∫0τn(π̃)e-αtcl(xtπ̃,at)dt+Ei,∞π̃e-ατn(π̃)V∼∞l(n,π̃).Moreover, we haveq∗(i)ω̃(i)⩽(λ+μ+θ1+θ2)ω̃2(i)for eachi∈S, which, together with (4.8)–(4.12) and (4.14), implies the hypothesis of Lemma 3.2 in Guo, Song, and Zhang (2014) holds for the case of a constant discount factor. Hence, it follows from Lemma 3.2(a) in Guo et al. (2014) and Lemma 6.1.5 in Anderson (1991) that, for eachi<n,(4.23)Ei,∞π̃∫0τn(π̃)e-αtclxtπ̃,atdt=Ei,nπ∫0τn(π)e-αtcl(xtπ,at)dt,andEi,nπe-ατn(π)=Ei,∞π̃e-ατn(π̃).LetB≔2M′(α+b′)α(α-ρ′). Then, it follows from (3.1) thatV∼nl(i,π′)⩽B2ω̃(i)for eachn∈N,i∈Sandl=0,1, which together with (4.20)–(4.23) implies that,(4.24)V∼nl(i,π)-V∼∞l(i,π̃)=Ei,∞π̃e-ατn(π̃)V∼nl(n,π)-V∼∞l(n,π̃)⩽Ei,∞π̃e-ατn(π̃)V∼nl(n,π)+V∼∞l(n,π̃)⩽Bω̃2(i)+α-1κ2′ω̃(n),foreachi<n.Hence, using Condition 4.1(c), by (4.3) and (4.24), for eachl=0,1, we have that(4.25)∑i∈SnV∼nl(i,π)γn′(i)-∑i∈SV∼∞l(i,π̃)γ(i)=∑i∈Sn-1V∼nl(i,π)-V∼∞l(i,π̃)γ(i)+V∼nl(n,π)γSn-1c-∑i∈S⧹Sn-1V∼∞l(i,π̃)γ(i)⩽B∑i=0n-1ω̃2(i)+α-1κ2′γ(i)ω̃(n)+B2ω̃(n)γ(Sn-1c)+B2∑i=n∞ω̃(i)γ(i)⩽B∑i=0n-1ω̃2(i)+α-1κ2′γ(i)ω̃(n)+∑i=n∞ω̃(i)γ(i)≔∊(n)→0asn→∞.By (4.25), there exists an integer N such that for eachn⩾N,∊(n)⩽θ32. So(4.26)d-V∼n1(f)=d-V∼∞1(f)+V∼∞1(f)-V∼n1(f)⩾d-V∼∞1(f)-∊(n)⩾θ32>0,which impliesMn′satisfies slater condition for eachn⩾N. Hence, under Condition 4.1, by Proposition 7.1 in Guo and Piunovskiy (2011) and Theorem 3.1(b1), there exist an optimal stationary policyπn′∈Πnsandλn∗⩾0for eachN⩽n∈N‾such that(4.27)Lnπn′,λn∗=minπ∈ΠnsLnπ,λn∗=maxλ⩾0Lnπn′,λ=V∼n0∗=V∼n0πn′,whereLn(π,λ)≔V∼n0(π)+λ(V∼n1(π)-d)for eachn∈N‾,π∈Πnsandλ∈(-∞,∞).LetE≔M′α∑i∈Sω̃(i)γ(i)+b′α(α-ρ′), it then follows from (3.1) and (4.26) that-E⩽V∼n0∗=minπ∈Πns{V∼n0(π)+λn∗V∼n1(π)-d}⩽E-λn∗d-V∼n1(f)⩽E-λn∗θ32,which implies that(4.28)λn∗⩽4Eθ3foreachn⩾N.Similarly,-E⩽V∼∞0∗=minπ∈Π∞sV∼∞0(π)+λ∞∗V∼∞1(π)-d⩽V∼∞0(f)+λ∞∗V∼∞1(f)-d⩽E-λ∞∗d-V∼∞1(f)=E-λ∞∗θ3, which implies that(4.29)λ∞∗⩽2Eθ3⩽4Eθ3.Letπ̃n′denote an extension ofπn′toΠ∞sby replacingπin (4.14) withπn′. Thus, by (4.25), (4.29), and (4.27), we have(4.30)V∼∞0∗-V∼n0∗=minπ∈Π∞sV∼∞0(π)+λ∞∗V∼∞1(π)-d-maxλ⩾0V∼n0πn′+λV∼n1πn′-d⩽V∼∞0π̃n′+λ∞∗V∼∞1(π̃n′)-d-V∼n0πn′-λ∞∗V∼n1πn′-d=V∼∞0π̃n′-V∼n0πn′+λ∞∗V∼∞1π̃n′-V∼n1πn′⩽4Eθ3+1∊(n).Also, define policyπˆn∈Πnsbyπˆn(·|i)≔π∞′(·|i)for eachn∈Nandi∈Sn. By (4.27) and (4.28),(4.31)V∼n0∗-V∼∞0∗=minπ∈ΠnsV∼n0(π)+λn∗V∼n1(π)-d-maxλ⩾0V∼∞0π∞′+λ(V∼∞1π∞′-d)⩽V∼n0(πˆn)+λn∗V∼n1(πˆn)-d-V∼∞0π∞′-λn∗V∼∞1π∞′-d=V∼n0(πˆn)-V∼∞0π∞′+λn∗(V∼n1πˆn)-V∼∞1π∞′⩽4Eθ3+1∊(n),which, together with (4.30) and (4.25), implies the desired result.□Example 4.1(cont.) For a numerical experimentation of Example 4.1, we fix the values of the parameters as follows:(4.32)λ=1.4,μ=1,A≔{1,2}×{1,2},α=1.2,d=0.1.Finally, the cost functions and initial distribution arec0(i,a)=[10+(a2-1.6)2]i,c1(i,a)=(a1-1.1)2,γ(i)≔12i+1,foreach(i,a)∈K.For every1⩽n⩽1000, we calculate the optimal value and an optimal policy ofMn′by solving theLPn′. The optimal values are shown in Fig. 1, and optimal policy forM∞′is given in Tables 1below. By Theorem 4.1, we know thatV∼n0∗-V∼∞0∗=O(n-1).The notation “k-l” in the above table denotes the statesk,k+1,…,l, and every number denotes the corresponding probability of choosing action a at state i. From the table above, we find an optimal 1-randomized policy forM1000′.In order to prove Theorem 3.1 above, we introduce the concept of an occupation measure.Definition 5.1For eachn∈N‾and policyπ∈Πn, the occupation measure ofπassociated toMnis a p.m. onSn×An, denoted byηnπ, is defined by(5.1)ηnπ({i}×Γ)≔α∫0∞e-αtEγnπ[I{i}×Γ(xt,at)]dt{i}×Γ∈B(Sn×An),Under Assumptions 2.1 and 3.1(b–d), by (2.3), (3.1), and (5.1), we have(5.2)Vnl(π)=1α∑j∈Sn∫An(j)cnl(j,a)ηnπ(j,da),for0⩽l⩽p,π∈Πn,n∈N‾.Then, the following theorem collects some properties of occupation measures.Lemma 5.1UnderAssumptions 2.1 and 3.1(b–c), the following assertions hold.(i)For eachn∈N‾and policyπ∈Πn,ηnπsatisfies the following equation and inequality(5.3)η(i,An(i))=γn(i)+1α∑j∈Sn∫An(j)qn(i|j,a)η(j,da)fori∈Sn,(5.4)∑i∈Snω(i)η(i,An(i))⩽α∑i∈Snω(i)γn(i)+bα-ρ<∞.Conversely, for each fixedn∈N‾, if a p.m.ηonKnsatisfies(5.3) and (5.4), then there exists a policyπ∈Πns(depending on n) such thatη=ηnπ, andπcan be obtained from the following decomposition ofη:(5.5)η(i,da)=ηˆ(i)π(da|i),whereηˆ(i)≔η(i,An(i))foreachi∈Sn.For each fixedn∈N‾andπ∈Πns,(ηˆnπ(i),i∈Sn)is a unique solution of(5.6)(5.6)μ(i)=γn(i)+1α∑j∈Snqn(i|j,π)μ(j)∀i∈Sn,in the class of probability measuresμonSnsuch that∑i∈Snω(i)μ(i)<∞.See Theorem 5.1 in Guo and Piunovskiy (2011), or Theorem 2.2.7 in Anderson (1991) for the proof of (iii).□Lemma 5.1 together with (5.2) shows that the problem (2.4) is equivalent to the following linear program problem(LPn):(5.7)LPn:infη1α∑i∈Sn∫An(i)cn0(i,a)η(i,da)(5.8)subjectto∑i∈Sn∫An(i)cnl(i,a)η(i,da)⩽αdnl,1⩽l⩽p,αηˆ(i)=αγn(i)+∑j∈Sn∫An(j)qn(i|j,a)η(j,da),foreachi∈Sn,∑j∈Snω(j)ηˆ(j)<∞,η∈P(Kn).A p.m.ηonKnis said to be a feasible solution to the LPnif it satisfies (5.8). We denote byinfLPnthe optimal value of the LPn. If there exists a feasible solutionηto the LPnsuch that1α∑i∈Sn∫An(i)cn0(i,a)η(i,da)=infLPn, thenηis called an optimal solution to the LPn. The family of all feasible solutions and optimal solutions for the LPnare denoted byFnandOn, respectively. Forn∈N‾, Lemma 5.1 ensures thatFn≠∅.To prove Theorem 3.1, we also need the following results.Lemma 5.2For any sequence ofπn∈Πnsconverging weakly toπ∈Π∞s, the following assertions hold.(i)For anyνn∈P(Sn)andν∈P(S∞), define p.m.μnonKnandμonK∞byμn(i,da)≔νn(i)πn(da|i)andμ(i,da)≔ν(i)π(da|i). Ifνn→νweakly inP(S∞), thenμn→μweakly inP(K∞).Suppose thatAssumptions 3.1(e) and3.2(a–b) hold, thenlimn→∞qn(j|i,πn)=q∞(j|i,π),andlimn→∞cnl(i,πn)=c∞l(i,π),n⩾n(i)∨n(j)for eachi,j∈S∞and0⩽l⩽p.(i)By the similar arguments for the proof of Lemma 4.6(a) in Alvarez-Mena and Hernández-Lerma (2002), we see that part (i) is true.Fix anyi,j∈S∞, and take arbitrarily∊>0. Assumption 3.2(a) implies the existence of an integerL1⩾n(i)∨n(j)such thatUnderAssumptions 2.1, 3.1 and 3.2(a–c), the following assertions hold.(i)Ifηnis a p.m. onP(Kn)(for eachn⩾1) satisfying(5.3) and (5.4), andηn→ηweakly inP(K∞), thenlimn→∞∑i∈Sn∫An(i)cnl(i,a)ηn(i,da)=∑i∈S∞∫A∞(i)c∞l(i,a)η(i,da)for each0⩽l⩽p.Ifπn∈Πnsfor alln⩾1, andπn→π∈Π∞sweakly, thenηnπn→η∞πweakly inP(K∞).(i) Under Assumptions 2.1, 3.1(b–d), (5.2) and Lemma 5.1(i) imply that the sequence∑i∈Sn∫An(i)cnl(i,a)ηn(i,da)is bounded in0⩽l⩽pandn∈N‾. For any fixed0⩽l⩽p, choose any subsequence∑i∈Snk∫Ank(i)cnkl(i,a)ηnk(i,da)of∑i∈Sn∫An(i)cnl(i,a)ηn(i,da)converging to some constant g ask→∞. Under Assumptions 2.1, 3.1(b–c), by Lemma 5.1(ii), there existsπnk∈Πnkssuch thatηnk(i,da)=ηˆnk(i)πnk(da|i)for each k. Under Assumption 3.1(a), by Remark 3.1 and the diagonal process, there exists a subsequence{πnks}of{πnk}such thatπnks→π∈Π∞sweakly. Moreover, sinceηnks→ηweakly, we have(5.10)ηˆnks(i)→ηˆ(i)ass→∞,foreachi∈S∞,wherenks⩾n(i),Thus, it follows from Lemma 5.2(i) and (5.10) thatη(i,da)=ηˆ(i)π(da|i).For eachηˆnks(s∈N), define an associated p.m.η̃nks∈P(S∞)as follows:η̃nks(i)≔ηˆnks(i)ifi∈Snks,andη̃nks(i)≔0ifi∈Snksc.Hence, by Assumption 3.1, it follows from (5.10) and the definition ofη̃nksthat(5.11)∑i∈S∞ω(i)ηˆ(i)⩽lim‾s→∞∑i∈S∞ω(i)η̃nks(i)⩽supn∈Nα∑i∈Snω(i)γn(i)+bα-ρ<∞.By Assumptions 2.1, 3.1(b–c) and (5.11), for eachε>0, there exists an integer N such that(5.12)∑i=N∞ω(i)ηˆ(i)⩽ε3,∑i=N∞ω(i)η̃nks(i)⩽1ω(N)supn∈Nα∑i∈Snω2(i)γn(i)+κ2α-κ1⩽ε3∀s⩾1.Hence, by (5.10) and the definition ofη̃nks, for eachi<N, there exists an integerM(i)(depending on i) such that for eachs⩾M(i),(5.13)|η̃nks(i)-ηˆ(i)|⩽ε3Nω(i).Therefore, it follows from (5.12) and (5.13) that for eachs⩾max{M(i):i⩽N-1},(5.14)∑i∈Snksω(i)ηˆnks(i)-∑i∈S∞ω(i)ηˆ(i)=∑i∈S∞ω(i)η̃nks(i)-∑i∈S∞ω(i)ηˆ(i)=∑i=0N-1ω(i)(η̃nks(i)-ηˆ(i))+∑i=N∞ω(i)(η̃nks(i)-ηˆ(i))⩽∑i=0N-1ω(i)η̃nks(i)-∑i=0N-1ω(i)ηˆ(i)+23ε⩽ε,which, together with the relationship betweenη̃nksandηˆnks, implies that(5.15)∑i∈S∞ω(i)ηˆ(i)=lims→∞∑i∈Snksω(i)ηˆnks(i)⩽supn∈N{α∑i∈Snω(i)γn(i)+bα-ρ}<∞.Therefore, under Assumptions 3.1(e) and 3.2(b), by Lemma 5.2(ii), (5.10), (5.15) and Theorem A.2.6 in Sennott (1999), we have(5.16)∑i∈Snkscnksl(i,πnks)ηˆnks(i)→∑i∈S∞c∞l(i,π)ηˆ(i),ass→∞,(5.17)thatisg=lims→∞∑i∈Snks∫Anks(i)cnksl(i,a)ηnks(i,da)=∑i∈S∞∫A∞(i)c∞l(i,a)η(i,da).As the subsequence∑i∈Snk∫Ank(i)cnkl(i,a)ηnk(i,da)was arbitrarily chosen and (by (5.17)) all such subsequences have the same limit∑i∈S∞∫A∞(i)c∞l(i,a)η(i,da), we havelimn→∞∑i∈Sn∫An(i)cnl(i,a)ηn(i,da)=∑i∈S∞∫A∞(i)c∞l(i,a)η(i,da).(ii) By Lemmas 5.2 and 5.1, it suffices to show thatηˆnπn→ηˆ∞πweakly. Choose any subsequence{ηˆnkπnk}of{ηˆnπn}converging weakly to some measureυonS∞. Then(5.18)limk→∞ηˆnkπnk(i)=υ(i)∀i∈S∞.By Assumptions 3.1(e) and 3.2(b), Lemma 5.2(ii), we have(5.19)0⩽∑i∈S∞υ(i)⩽lim‾k→∞∑i∈Snkηˆnkπnk(i)=1and(5.20)∑j∈S∞q∞(i|j,π)υ(j)⩽lim‾k→∞∑j∈Snkqnk(i|j,πnk)ηˆnkπnk(j),foreachi∈S∞.Then, by Assumptions 2.1 and 3.1(b,c), using Proposition A.3 in Guo and Hernández-Lerma (2009), Lemma 5.1(i) and (5.18), we have(5.21)∑i∈S∞ω(i)υ(i)⩽lim‾k→∞α∑i∈Snkω(i)γnk(i)+bα-ρ⩽supn∈N‾α∑i∈Snω(i)γn(i)+bα-ρ<∞.On the other hand, for eachi∈S∞andnk⩾n(i), by Lemma 5.1(iii) we have(5.22)ηˆnkπnk(i)=γnk(i)+1α∑j∈Snkqnk(i|j,πnk)ηˆnkπnk(j).Then, by (5.20), lettingk→∞in (5.22), we get(5.23)υ(i)=γ∞(i)+1αlim‾k→∞∑j∈Snkqnk(i|j,πnk)ηˆnkπnk(j)⩾γ∞(i)+1α∑j∈S∞q∞(i|j,π)υ(j).Under Assumption 2.1(b), it follows from Fubini’s Theorem and (5.21) that∑i∈S∞∑j∈S∞|q∞(i|j,π)|υ(j)=∑j∈S∞υ(j)∑i∈S∞|q∞(i|j,π)|⩽2∑j∈S∞υ(j)q∞∗(j)⩽2L∑j∈S∞ω(j)υ(j)<∞,(5.24)andsowehave∑i∈S∞∑j∈S∞q∞(i|j,π)υ(j)=∑j∈S∞υ(j)∑i∈S∞q∞(i|j,π)=0.Suppose that there exists somei′∈S∞such that(5.25)υ(i′)>γ∞(i′)+1α∑j∈S∞q∞(i′|j,π)υ(j).Hence, summation of both sides of (5.23) with respect toi∈S∞, together with (5.24) and (5.25), yields that∑i∈S∞υ(i)>∑i∈S∞γ∞(i)=1, which contradicts (5.19). Thus, we haveυ(i)=γ∞(i)+1α∑j∈S∞q∞(i|j,π)υ(j)∀i∈S∞,which, together with Lemma 5.1(iii), implies thatυ(i)=ηˆ∞π(i)for alli∈S∞. As the above subsequence{ηˆnkπnk}was arbitrarily chosen and all such subsequences have the same limitηˆ∞π, we haveηˆnπn(i)→ηˆ∞π(i)for eachi∈S∞, and soηˆnπn→ηˆ∞πweakly.□UnderAssumptions 2.1 and 3.1, the following assertions hold.(i)IfUn≠∅for somen∈N‾, then the correspondingFnis nonempty and compact.If, in addition,Assumptions 2.2 and 3.2hold, and letηn∈Fnfor eachn∈N, then{ηn}is relatively compact inF∞, and any accumulation point of{ηn}is inF∞.(i) For eachn∈N‾, Assumption 2.1 together with 3.1(b–d) implies thatFn≠∅(by Lemma 5.1(i)). Let{ηm}be an arbitrary subsequence ofFn. Then, under Assumptions 2.1 and 3.1(b–c), Lemma 5.1(ii) gives the existence ofπm∈Πnssuch thatηm=ηnπmfor allm⩾1. Moreover, under Assumption 3.1(a), by Remark 3.1, there exist a subsequence{πmk}of{πm}and a policyπ∈Πns, such thatπmk→πweakly ask→∞.Hence, under Assumptions 2.1 and 3.1, it follows from Theorem 5.1(ii) (for the special case that each one of the models in{M1,M2,…}is taken as theMn) thatηnπmk→ηnπask→∞. Hence, the rest verifies thatηnπsatisfies the constraints. Indeed, under Assumptions 2.1 and 3.1, by Theorem 5.1(i) (for the special case above) and (5.2), we haveVnl(π)=1α∑i∈Sn∫An(i)cnl(i,a)ηnπ(i,da)=limk→∞1α∑i∈Sn∫An(i)cnl(i,a)ηnπmk(i,da)⩽dnl,l=1,…,pand so (i) follows.(ii) Let{ηnm}be an arbitrary subsequence of{ηn}. Then by Lemma 5.1(ii) we haveηnm=ηnmπnmfor each allm⩾1, with someπnm∈Πnms. Under Assumption 3.1(a), by Remark 3.1 and the diagonal process, there exists a subsequence{πnmk}of{πnm}such thatπnmk→π∈Π∞sweakly, and thus it follows from Theorem 5.1(ii) thatηnmk=ηnmkπnmk→η∞πask→∞. Moreover, under Assumptions 2.1, 3.1 and 3.2, by Theorem 5.1(i) we have1α∑i∈S∞∫A∞(i)c∞l(i,a)η∞π(i,da)=limk→∞1α∑i∈Snmk∫Anmk(i)cnmkl(i,a)ηnmkπnmk(i,da)⩽limk→∞dnmkl=d∞l,for all1⩽l⩽p. Hence,η∞π∈F∞, and so (ii) is true.□Note that Assumptions 2.2 and 3.3 are both on the existence of a policy satisfying the given constraints. The following proposition ensures some relationship between them.Proposition 5.1Suppose thatAssumptions 2.1, 3.1, 3.2 and 3.3hold. Then, there exist an integer N, a constantδ>0, and policiesπ̃n∈Πnsfor alln⩾N, such thatVnl(π̃n)⩽dnl-δ(henceUn≠∅),foreach1⩽l⩽p,andn⩾N.Letπ∈Π∞be the policy as in Assumption 3.3(a). Then, under Assumptions 2.1, 3.1(b–d) and 3.3, it follows from Lemma 5.1(ii) and (5.2) that there exists a policyπ̃∈Π∞sand a constantC>0, such thatV∞l(π̃)=V∞l(π)⩽d∞l-Cfor each1⩽l⩽p.For eachn⩾1, define a policyπ̃n∈Πnsas follows: For eachi∈Sn, take arbitrarilyan(i)∈An(i),(5.26)π̃n(da|i)≔π̃(da∩An(i)|i)/π̃(An(i)|i)ifπ̃(An(i)|i)>0I{an(i)}(da)ifπ̃(An(i)|i)=0.Then, Assumption 3.3(b) implies thatπ̃(An(i)|i)↑π̃(A∞(i)|i)=1asn→∞, and soπ̃n→π̃weakly. Thus, under Assumptions 2.1, 3.1 and 3.2, by Theorem 5.1 and (5.2), we have(5.27)ηnπ̃n→η∞π̃andlimn→∞Vnl(π̃n)=V∞l(π̃)⩽d∞l-Cforeach1⩽l⩽p.Then, for any fixed0<ε<C2(and soδ≔C-2ε>0), by Assumption 3.2(d) and (5.27), there exists an integer N such that|Vnl(π̃n)-V∞l(π̃)|⩽ε,|dnl-d∞l|⩽ε,forn⩾N,and1⩽l⩽p.Hence,Vnl(π̃n)⩽V∞l(π̃)+ε⩽d∞l-C+ε⩽dnl-C+2ε=dnl-δforeachn⩾Nand1⩽l⩽p,which completes the proof.□The proof of Theorem 3.1 is based on the following proposition, which is similar to Lemma 5.1 in Alvarez-Mena and Hernández-Lerma (2002) for discrete-time MDP. We will prove it here for the sake of completeness.Proposition 6.1UnderAssumptions 2.1, 3.1, 3.2 and 3.3, the following assertions hold.(i)For eachη∈F∞, there exist an integer N andηn∈Fnfor eachn⩾N, such thatηn→ηweakly.There exists an integer N such thatFnfor eachn⩾N. Ifηn∈Onfor alln⩾1, andη∞is an accumulation point of{ηn,n⩾N}, thenη∞∈O∞.(i) Letη∈F∞. Under Assumptions 2.1, 3.1(b–d) and 3.3(a), Lemma 5.1(ii) and (5.2) give the existence ofπk∈Π∞s(k=1,2), such thatη=η∞π1andV∞l(π2)⩽d∞l-Cwith some constantC>0, for all1⩽l⩽p. For each policyπk, replacingπ̃in (5.26) withπk, we define a sequence{πnk,n⩾1}, which converges weakly toπk(by Assumption 3.3(b)). Thus, by Theorem 5.1(ii), we have(6.1)ηnπnk→η∞πk,asn→∞,fork=1,2and so (by Theorem 5.1(i)), for all1⩽l⩽p,(6.2)limn→∞∑i∈Sn∫An(i)cnl(i,a)ηnπn1(i,da)=∑i∈S∞∫A∞(i)c∞l(i,a)η∞π1(i,da)⩽αd∞l,(6.3)limn→∞∑i∈Sn∫An(i)cnl(i,a)ηnπn2(i,da)=∑i∈S∞∫A∞(i)c∞l(i,a)η∞π2(i,da)⩽α(d∞l-C).Letεbe such that0<2ε<αC1+α. By (6.2) and (6.3) and Assumption 3.2(d), there exists an integerNε(depending onε) such that, for eachn⩾Nεand1⩽l⩽p,|dnl-d∞l|⩽ε, and∑i∈Sn∫An(i)cnl(i,a)ηnπn1(i,da)⩽αd∞l+ε,∑i∈Sn∫An(i)cnl(i,a)ηnπn2(i,da)⩽α(d∞l-C)+ε.Letνnε≔(1-λε)ηnπn1+λεηnπn2, whereλε≔(α+1)εαC<12. Then, for each1⩽l⩽pandn⩾Nε,∑i∈Sn∫An(i)cnl(i,a)νnε(i,da)=(1-λε)∑i∈Sn∫An(i)cnl(i,a)ηnπn1(i,da)+λε∑i∈Sn∫An(i)cnl(i,a)ηnπn2(i,da)⩽(1-λε)αd∞l+ε+λεαd∞l-C+ε⩽αdnl,which implies thatνnε∈Fnfor alln⩾Nε.Then, let{εk}⊆Rbe such thatεk↓0and0<2εk<αCα+1. For each fixedk⩾1(corresponding to a givenεk), as in the previous argument, there exists an integerNk(depending on k) which is assumed to be increasing ink⩾1, such that(6.4)νnk≔(1-λk)ηnπn1+λkηnπn2∈Fn∀n⩾Nk,k⩾1,whereλk≔(α+1)εkαC.Letηn≔νnk, andλn≔λkfor eachNk⩽n<Nk+1. Then, sinceεk↓0, by (6.1) and (6.4), we haveηn→ηandηn∈Fnfor eachn⩾N1, which completes the proof of (i).(ii) The first statement follows from Proposition 5.1. Then, under Assumptions 2.1, 3.1 and 3.2, Theorem 5.2(ii) gives the existence of a subsequence{ηm}of{ηn}andη∞∈F∞, such thatηm→η∞. Without loss of generality, we assume thatηn→η∞. On the other hand, for anyη̃∞∈F∞, under Assumptions 2.1, 3.1, 3.2 and 3.3, it follows from (i) that there exist an integerN′>Nandη̃n∈Fnfor alln⩾N′, such thatη̃n→η̃∞weakly, which together withηn∈On, gives(6.5)∑i∈Sn∫An(i)cn0(i,a)ηn(i,da)⩽∑i∈Sn∫An(i)cn0(i,a)η̃n(i,da)∀n⩾N′.Sinceη∞∈F∞andη̃n→η̃∞, under Assumptions 2.1, 2.2, 3.1, by Theorem 5.1(i) and (6.5), we have∑i∈S∞∫A∞(i)c∞0(i,a)η∞(i,da)⩽∑i∈S∞∫A∞(i)c∞0(i,a)η̃∞(i,da), and so (ii) follows.□(a) For then∈N‾, it follows from Theorem 5.2(i) thatFn≠∅. By the definition of the optimal value of LPn, under Assumptions 2.1 and 3.1, by Lemma 5.1, there exists a sequence{ηm}ofFn, such that(6.6)limm→∞1α∑i∈Sn∫An(i)cn0(i,a)ηm(i,da)=infLPn,and moreover, by Theorem 5.2(i), there exists a subsequence{ηmk}of{ηm}such thatηmk→η∈Fn. Then, under Assumptions 2.1 and 3.1, by Theorem 5.1(i) (for the special case that each one of the models in{M1,M2,…}is taken as theMn) and (6.6) we have1α∑i∈Sn∫An(i)cn0(i,a)η(i,da)=limk→∞1α∑i∈Sn∫An(i)cn0(i,a)ηmk(i,da)=infLPn. This isη∈On.Define a policyπ∗by the decomposition ofη(i,da)=:η(i)π∗(da|i). Then, for anyπ∈Un, by (5.2) we haveVn0(π∗)=1α∑i∈Sn∫An(i)cn0(i,a)η(i,da)⩽1α∑i∈Sn∫An(i)cn0(i,a)ηnπ(i,da)=Vn0(π),and soπ∗is optimal forMn.(b) We first prove (b1) and (b2) together. Under Assumptions 2.1, 3.1, 3.2 and 3.3, by Proposition 5.1, it follows that there exists an integer N such thatUn≠∅for eachn⩾N, then by (a) we see that (b1) is true. Moreover, for eachn⩾N(includingn=∞), it follows from Lemma 5.1 and (5.2) thatπis optimal forMnif and only ifηnπ∈On, which together with Proposition 6.1(ii) and Theorem 5.1(ii), implies (b2).We next prove (b3). First, under Assumptions 2.1, 3.1, 3.2 and 3.3, there existηn∗∈Onfor alln⩾N, with someN⩾1(by (b1)). Let{Vnk0∗}be any subsequence of{Vn0∗}, which converges to some constant. Then, under Assumptions 2.1, 3.1–3.3, by Theorem 5.2(ii) and Proposition 6.1(ii), there exists{ηnks∗}⊆{ηnk∗}, such thatηnks∗→η∞∗∈O∞weakly ass→∞, and so it follows fromVn0∗=minLPnand Theorem 5.1(i)(n∈N‾)thatlimk→∞Vnk0∗=lims→∞Vnks0∗=lims→∞1α∑i∈Snks∫Anks(i)cnks0(i,a)ηnks∗(i,da)=1α∑i∈S∞∫A∞(i)c∞0(i,a)η∞∗(i,da)=V∞0∗.which together with the arbitrariness of the subsequence{Vnk0∗}, implies (b3).□

@&#CONCLUSIONS@&#
