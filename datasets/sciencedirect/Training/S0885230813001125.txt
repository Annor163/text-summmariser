@&#MAIN-TITLE@&#
Incorporating local information of the acoustic environments to MAP-based feature compensation and acoustic model adaptation

@&#HIGHLIGHTS@&#
Designing suitable prior distributions is important for MAP-based methods.We propose a framework to characterize local information of acoustic environments.With the local information, suitable prior distributions can be designed.Four algorithms to specify hyper-parameters for prior distributions are derived.Results confirm the advantage of using local information to MAP-based methods.

@&#KEYPHRASES@&#
MAP,Feature compensation,Acoustic model adaptation,Local information,Hyper-parameter specification,Noise robustness,

@&#ABSTRACT@&#
The maximum a posteriori (MAP) criterion is popularly used for feature compensation (FC) and acoustic model adaptation (MA) to reduce the mismatch between training and testing data sets. MAP-based FC and MA require prior densities of mapping function parameters, and designing suitable prior densities plays an important role in obtaining satisfactory performance. In this paper, we propose to use an environment structuring framework to provide suitable prior densities for facilitating MAP-based FC and MA for robust speech recognition. The framework is constructed in a two-stage hierarchical tree structure using environment clustering and partitioning processes. The constructed framework is highly capable of characterizing local information about complex speaker and speaking acoustic conditions. The local information is utilized to specify hyper-parameters in prior densities, which are then used in MAP-based FC and MA to handle the mismatch issue. We evaluated the proposed framework on Aurora-2, a connected digit recognition task, and Aurora-4, a large vocabulary continuous speech recognition (LVCSR) task. On both tasks, experimental results showed that with the prepared environment structuring framework, we could obtain suitable prior densities for enhancing the performance of MAP-based FC and MA.

@&#INTRODUCTION@&#
Applications of automatic speech recognition (ASR) have received considerable attention in recent years. However, the applicability of ASR is seriously limited by the fact that its performance can deteriorate when training and testing conditions do not match (Acero, 1990; Gong, 1995; Junqua et al., 1996; Huo and Lee, 2000; Huang et al., 2001; Molau et al., 2003; Deng and Huang, 2004). Maintaining satisfactorily robust performance under mismatched conditions is an essential task for ASR applications. Handling the mismatch is difficult, because it generally comes from multiple sources, including inter- and intra-speaker effects, additive noise, convolutive transmission, and channel distortions. The overall effect of these distortions can be complex and hard to characterize. Many robustness approaches have been proposed to handle the mismatch issue. These approaches can be categorized into three groups, signal-space, feature-space, and model-space approaches (Sankar and Lee, 1996; Lee, 1998), based on the space in which the mismatch issue is handled.The signal-space approach (also known as speech enhancement methods) aims to reduce noise components from noisy speech signals while avoiding large speech distortions. Classical algorithms include spectral subtraction (SS) (Boll, 1979), Wiener filtering techniques (Scalart and Filho, 1996; Hansler and Schmidt, 2006; Chen et al., 2007), minimum mean square error spectral estimator (MMSE) (Ephraim and Malah, 1984; Martin, 2005; Hansen et al., 2006), minimum mean-square error log-spectral amplitude estimator (LSA) (Ephraim and Malah, 1985), maximum a posteriori spectral amplitude estimator (MAPA) (Lotter and Vary, 2005), and maximum likelihood spectral amplitude estimator (MLSA) (Kjems and Jensen, 2012). In the meanwhile, some models that characterize human speech production systems were often incorporated for speech enhancement, such as harmonic model (Quatieri and McAulay, 1992), the linear prediction (LP) model (Makhoul, 1976), and the hidden Markov model (HMM) (Ephraim, 1992).The feature-space approach tries to generate feature vectors that are robust to environment mismatches. These approaches can be divided into two categories, feature processing (FP) and feature compensation (FC). FP methods process both training and testing data sets to remove mismatches on features. Temporal filtering and feature normalization methods are two effective classes of FP approaches. Representative temporal filtering algorithms include relative spectral (RASTA) (Hermansky and Morgan, 1994), moving average and auto-regression moving average (Chen et al., 2002a, 2002b), which try to smooth acoustic features to suppress noise interferences. Feature normalization methods aim to reduce the mismatch by mapping training and testing acoustic features to make them close to each other in the first or higher order statistical measures. Successful algorithms include cepstral mean subtraction (CMS) (Viikki and Laurila, 1998; Kim and Rose, 2003), cepstral mean and variance normalization (CMVN) (Tibrewala and Hermansky, 1997), and histogram equalization (HEQ) (Ibm et al., 2000). On the other hand, FC methods compute a mapping function to characterize the environmental mismatch. The acoustic features are then transformed by the mapping function to match the acoustic model. A variety of mapping functions has been applied in previous studies, among which affine transform and compensation bias are two popular choices. Notable examples include maximum likelihood (ML) and maximum a posteriori (MAP) based stochastic feature matching (SFM) (Lee, 1998; Jiang et al., 2001), feature space maximum likelihood linear regression (feature space MLLR (Gales, 1997)) and maximum a posteriori linear regression (feature space MAPLR (Li et al., 2002)).The goal of the model-space approach is to estimate an acoustic model that is more robust to environmental changes or matches the testing condition better. Two classes of model-space approaches, discriminative training (DT) and model adaptation (MA), have been confirmed to be effective and are widely used. Generally, DT approaches use an objective function that measures the separation between parameters in a set of acoustic models. The objective function is optimized based on training data to increase the separation between model parameters. Well-known DT approaches include minimum classification error (MCE) (Juang et al., 1997), maximum mutual information estimation (MMIE) (Valtchev et al., 1997), minimum phone error (MPE) (Povey and Woodland, 2002), large margin estimation (LME) (Jiang et al., 2006), and soft margin estimation (SME) (Li et al., 2007) methods. On the other hand, MA approaches estimate a mapping function to adjust parameters in the original acoustic model to match the testing condition. Successful examples include stochastic matching algorithm (Sankar and Lee, 1996; Lee, 1998), maximum a posteriori (MAP) (Gauvain and Lee, 1994; Huo et al., 1995), MLLR (Leggetter and Woodland, 1995; Gales, 1997), and MAPLR (Chesta et al., 1999; Siohan et al., 2001).In the reviewed approaches above, MAP-based FC and MA estimate mapping functions based on the MAP criterion to compensate for acoustic mismatches. Owing to their efficiency and flexibility, they have received extensive attention in recent years (Gauvain and Lee, 1994; Chesta et al., 1999; Siohan et al., 2001; Jiang et al., 2001; Li et al., 2002). These approaches require prior densities of the mapping function parameters, and determining suitable densities is an important task in obtaining satisfactory performance. Traditionally, prior densities were designed without considering the underlying environment structures, so the prior density could not characterize the local statistical structure of the acoustic environments. In this paper, we propose an environment structuring framework for exploring local information of the ensemble speaker and speaking environment conditions. Based on local information, we derive suitable prior densities for MAP-based FC and MA. We conducted experiments using two standardized speech databases, Aurora-2 (Pearce and Hirsch, 2000; Macho et al., 2002) and Aurora-4 (Hirsch, 2001; Parihar and Picone, 2002; Parihar et al., 2004). Experimental results confirmed the effectiveness of our proposed idea for enhancing the MAP-based FC and MA capability to handle the mismatch issue.The reminder of this paper is organized as follows. Section 2 reviews MAP-based FC and MA and introduces the environment structuring framework. Section 3 describes four algorithms for specifying hyper-parameters of the prior densities based on the environment structuring framework. Section 4 shows our experimental setup and evaluation results. Section 5 concludes the study by summarizing our findings.This section first reviews the fundamental theories of MAP-based FC and MA. Then we introduce the proposed environment structuring framework used for prior density specification.Fig. 1illustrates FC and MA in a speech recognition system. FC transforms the original testing speech features, FY, to new speech features, FX, that match the acoustic model for the training condition by(1)FX=Γυ(FY)where Γυ(.) is an FC mapping function, and υ denotes the parameters in the FC mapping function. We use the MAP criterion to calculate υ in Γυ(.) by(2)υˆ=argmaxυP(FY|υ,ΛX)[(p(υ)]α,where α is a forgetting factor, p(υ) is the prior density for FC (Jiang et al., 2001), and ΛX denotes the acoustic model for the training condition. When setting α=0 in Eq. (2), the estimation ofυˆis exactly the same as that based on the ML criterion (Lee, 1998).In MA, a mapping function, Γθ(.), is used to adjust parameters of the acoustic model for the training condition, ΛX, and generate a new acoustic model, ΛY, for the testing condition according to(3)ΛY=Γθ(ΛX),where Γθ(.) characterizes the mismatch between the training and testing conditions. Similar to MAP-based FC, the estimation of the parameters, θ, in Γθ(.), is formulated as(4)θˆ=argmaxθP(FY|θ,ΛX)[p(θ)]τ,where τ is a forgetting factor, and p(θ) is the prior density for MA. We can also obtain the ML-based solution ofθˆby setting τ=0 in Eq. (4).In Eqs. (2) and (4), the hyper-parameters for the prior densities must be properly specified to characterize the statistics of the underlying acoustic environments. In what follows, we introduce the proposed environment structuring framework for doing this.Two steps are involved in constructing the environment structuring framework, environment clustering (EC) and environment partitioning (EP) (Tsao and Lee, 2009). After these two steps, the environment structuring framework is structured as a two-stage hierarchical tree, as shown in Fig. 2. The algorithms involved in these two steps are briefly introduced in the following discussion.The goal of EC is to cluster the entire set of training data into several subsets. Each subset includes speech data representing similar acoustic characteristics. As shown in Fig. 2, a hierarchical tree structure is adopted to perform EC. Assuming that the tree built using EC (named EC tree hereafter) has C nodes, including the root node, intermediate nodes, and leaf nodes, we accordingly cluster the entire set of training data into C subsets {Q1, Q2, …, QC}, where each subset contains local information about the entire set of training data. Next, we use the data in each subset to estimate an acoustic model and obtain C sets of acoustic models, {Λ1, Λ2, …, ΛC}. We use these C sets of acoustic models to characterize local information about the entire acoustic space.Some previous studies also proposed to structure the training data to facilitate the model adaptation process. In Zhang et al. (2003), training data is divided into several noisy clusters, which are used to prepare multiple HMM sets. Then a noisy cluster that best matches the testing utterance is located, and its corresponding HMM set is used for recognition. Additionally, an MLLR transformation is applied to further adapt the Gaussian mean parameters. In Padmanabhan et al. (1998), speaker clustering is first performed, and model adaptation is conducted based on linear transforamtions caclulated by the cluster of speakers that is acoustically close to the testing speaker. The EC algorithm shares the similar concept of the above appraoches, while we investigate to apply the constructed EC tree to not only model adapation but also feature compensation. Furthermore, since the EC tree can characterize local informtion of the entire training acoustic space, we propose to utilize the local infromation to specify suitable prior densities for MAP-based FC and MA mapping fucntion estaimtions. These two parts will be dicsussed in more details in the following discussion.In Gales (1996), an acoustic space clustering and selection algorithm based on a regression tree was proposed. The regression tree can be constructed based on the phonetic knowledge or in a data driven manner and was adopted to facilitate MLLR acoustic model adaptation. In Shinoda and Lee (2001), a hierarchical tree structure was used for MAP based model adaptation. Both approaches used the tree-structured clustering and selection methods for acoustic model adaptation (Gales, 1996; Shinoda and Lee, 2001). The EP algorithm adopts the same idea to partition the Gaussian components in an acoustic model into several groups. Based on the EP algorithm, we build an EP tree, as shown in Fig. 3, which is used for both FC and MA. Moreover, based on the EP tree structure, we further design four prior densities to be used for MAP-based FC and MA (refer Section 3). In this study, we propose a two-stage tree structure, as shown in Fig. 2. For each of the C sets of acoustic models, {Λ1, Λ2, …, ΛC}, we estimate a tree using the EP algorithm (named EP tree hereafter). Accordingly, we prepare C EP trees, {Ω1, Ω2, …, ΩC}, corresponding to the C acoustic models. The EP tree presented in Fig. 3 corresponds to one EP tree in Fig. 2. Assume that this EP tree includes N nodes, the entire set of Gaussian components in an acoustic model is accordingly partitioned into N groups (Z1, Z2, …, Zn, …, ZN), where Zndenotes the nth group of Gaussian components in the EP tree. Because each node in the EP tree is obtained from separating the Gaussian components from its parent node, the Gaussian components are mutually exclusive in the nodes of the same layer and represent different acoustic properties. For the EP tree in Fig. 3, Z1 denotes the entire set of mean parameters, Φ1 represents the hyper-parameter set for Z1, Zndenotes the nth subset of the entire set of mean vectors, and Φnrepresents the hyper-parameter set for Zn.In the constructed environment structuring framework in Fig. 2, we have multiple acoustic models for characterizing local acoustic conditions. These multiple acoustic models are used online to perform cluster selection (CS) for determining one acoustic condition that best matches the testing condition. The selected acoustic model is used to perform FC or/and MA, and the compensated features or/and adapted acoustic models are then used to test recognition. In the compensation or/and adaptation stage, the EP tree structure in Figs. 2 and 3 are used to specify prior densities, which are used in MAP-based FC and MA. In our study, MAP-based stochastic feature matching (SFM) using a compensation bias is adopted for FC, and linear regression (LR) is chosen for MA. In the following, we introduce these two approaches under the proposed environment structuring framework.In Eq. (1), by settingFX=[f1Xf2X,…,fTX]andFY=[f1Yf2Y,…,fTY], we perform a frame-wise feature compensation by(5)ftX=Γυ(ftY),t=1,2,…,T,whereftYandftXare noisy and compensated features at the tth time index, respectively. To perform Eq. (5), we first define the form of the FC mapping function, Γυ(.). Generally, when sufficient samples from the testing condition are available, a complex parametric function of Γυ(.) can be used to compensate noise components accurately. When only a small number of samples is available, a simple form of Γυ(.) should be used to avoid over-fitting. In this study, we focus on the condition that only few data samples are available to estimate the compensation function. Therefore, we use a simple compensation bias for Γυ(.). Thus, Eq. (5) becomes(6)ftX=ftY−δn,t=1,2,…,T,where δnis a compensation bias belonging to the nth node in the EP tree. To perform Eq. (6), we first decode FY to generate a transcription reference. Then based on the transcription reference, we can obtain the node sequence corresponding toFY=[f1Yf2Y,…,fTY]to perform SFM. Please note that the N biases, δn(n=1, …, N), are shared and used to compensate all of the testing feature vectors. Namely, the compensation is performed in a frame-wise manner. Each feature vector,ftY, selects a particular bias δnto perform SFM, and the selection of n out of N nodes is done by a searching process through the EP tree.When applying MAP-based SFM to calculate δn, we first specify a prior density:(7)p(δn)∝∏i=1Dexp−12Vn(ii)(δn(i)−ηn(i))2,where δn(i), ηn(i), and Vn(ii) are the ith components of δn, ηn, and iith diagonal component of Vn, respectively, ηnand Vnare the hyper-parameters, Vnis a diagonal matrix, and D is the feature vector dimension. From Eqs. (6) and (7), the MAP estimation of δncan be computed as:(8)δn(i)=kn(i)Gn(i),with(9)Gn(i)=αVn(ii)+∑t=1T∑s∈Znrs(t)1Σs(ii),(10)kn(i)=αVn(ii)ηn(i)+∑t=1T∑s∈Znrs(t)ft(i)Y−μs(i)Σs(ii),whereft(i)Yis the ith component of the tth testing feature vector, rs(t) is the posterior probability at the tth observation, Znrepresents the Gaussian components in the nth EP node, andμs(i)andΣs(ii)are the ith component of the mean, μs, and iith diagonal component of variance, Σs, of the sth Gaussian component that belongs to the nth EP node, respectively.The overall implementation steps of MAP-based SFM online can be divided into four steps:Step 1: With FY, perform the CS process to locate one EC node (e.g., the CSth node) that best matches the testing condition by(11)ΛCS=argmaxΛcP(FY|Λc),∀c=1,…,C,thereby locating the acoustic model, ΛCS, and the EP tree, ΩCS, for that CSth node.Step 2: Based on FY, ΛCS, and ΩCS, find the alignment information and calculate the FC mapping functions,Γν={gν1,gν2,…,gνN}, where the located EP tree (ΩCS) is assumed to have N nodes.Step 3: Finally, obtain the compensated feature,FX=[f1X,f2X,…,fTX]by compensating FY using(12)ftX=gνn(ftY)=ftY−δn,t=1,2,…,T,whereftXis the compensated speech feature,gνn(.)is the mapping function, and δnis the compensation bias for the nth node in the EP tree. To determine the node index for the tth feature,ftX, we first determine a Gaussian mixture component,s˜, bys˜=argmaxsrs(t),s∈S′, where S′ denotes the group of Gaussian components that belongs to the state corresponding toftXin the decoded transcription reference. With the determineds˜, we search through the EP tree to determine the optimal node forftX. The search process is conducted in a bottom-up manner, which is different from the top-down scheme that is used in (Gales, 1996). Before the search process, we first calculate the accumulated statistics for every node in the EP tree,ϒq=∑t=1T∑s∈Zqrs(t), q=1, 2, …, N. If the accumulated statistics for the nth EP node, ϒn, is larger than a predefined threshold, we use the compensation bias of the nth node, δn, to perform MAP-based SFM. If ϒnis smaller than a pre-defined threshold, we examine the accumulated statistics at the parent node of the nth node. This process repeats until an EP node with sufficient statistics is located.Step 4: Decode FX by ΛCSto obtain the final recognition result.MAPLR adapts the mean parameters in the original acoustic model to form a new one for the testing condition (Chesta et al., 1999). From Eq. (3), MAPLR is formulated as(13)μsY=Γθ(μsX),s=1,…,S,whereμsYandμsXare the sth mean vectors in ΛY and ΛX, respectively, and S denotes the entire set of Gaussian components in the acoustic model. MAPLR uses linear regression for the mapping function, Γθ(.), so we have(14)μsY=AnμsX+bn=Wnξs,s=1,…,S,where An, bn, and Wnare the rotation matrix, bias, and affine transform, respectively, that belong to the nth node in the EP tree, and ξsis the augmented vector,ξs=μsX′,1′. For MAPLR, we specify the prior density for p(Wn) as(15)p(Wn)∝∏i=1Dexp−12(Wn(i)−ρn(i))Hn(i)−1(Wn(i)−ρn(i))′,where Wn(i) and ρn(i) are the ith row of Wnand ρn, respectively; ρnandHn(i),i=1,…,D, are hyper-parameters. Here we assume that each ofHn(i),i=1,…,D, is a diagonal matrix (Erdoan et al., 2001). Then, MAPLR calculatesWn(i)using(16)Wn(i)=kn(i)Gn(i)−1,where(17)Gn(i)=τHn(i)−1+∑t=1T∑s∈Znrs(t)ξsξs′Σs(ii),(18)kn(i)=τρn(i)Hn(i)−1+∑t=1T∑s∈Znrs(t)ft(i)Yξs′Σs(ii),The overall implementation steps of MAPLR can also be divided into four steps:Step 1: With FY, perform the CS process to locate one EC node (e.g., the CSth node) that best matches the testing condition by Eq. (11), thereby locating the acoustic model, ΛCS, and the EP tree, ΩCS, for that node.Step 2: Based on FY, ΛCS, and ΩCS, find the alignment information and calculate the MA mapping functions,Γθ=gθ1,gθ2,…,gθN, where the located EP tree (ΩCS) is assumed to have N nodes.Step 3: Adapt mean parameters in ΛCSusing(19)μsY=gθn(μsCS)=Wnξs,s=1,…,S,whereμsCSis the mean vector,ξs=μsCS′,1′is for the sth Gaussian, which belongs to the nth EP node, andμsYis the adapted mean parameters. After the entire set of mean parameters has been adapted, we obtain the acoustic model for the testing condition, ΛY. Similar to MAP-based SFM, we search through the EP tree to determine the node that has sufficient number of adaptation statistics to compute an accurate affine transform. The search process is conducted in a bottom-up manner. Before the search process, we first calculate the accumulated statistics for every node in the EP tree,ϒq=∑t=1T∑s∈Zqrs(t), q=1, 2, …, N. If the accumulated statistics for the nth EP node, ϒn, is larger than a predefined threshold, we use the affine transform of the nth node, Wn, to perform MAPLR. If ϒnis smaller than a pre-defined threshold, we examine the accumulated statistics at the parent node of the nth node. This process repeats until an EP node with sufficient statistics is located.Step 4: Decode FY by ΛY to obtain the final recognition result.Although FC and MA can be used to compensate the same mismatch factors (or sources), they may be complementary to each other, since they deal with the mismatch problem using different strategies. Therefore, the two approaches can be integrated in an iterative manner to achieve further improvements. More details about the integration of FC and MA will be presented in Section 4.As introduced in Sections 2.3 and 2.4, both MAP-based SFM and MAPLR take account of the hierarchical tree structure to well fit the testing acoustic environments. In this section, we present to use the tree structure to specify suitable hyper-parameters of the prior densities for MAP-based SFM and MAPLR. Four types of prior densities are developed and introduced in the following discussion.With the environment structuring framework, we can prepare clustered prior (CP), sequential prior (SP), hierarchical prior (HP), and integrated prior (IP) densities for MAP-based SFM and MAPLR.The hyper-parameters of the clustered prior (CP) density are estimated directly from the clustered data in each EP node of the hierarchical tree. In the following, we assume that the cth EC node is selected, and the corresponding training data for this node is Qc. Next, we further assume that the cth EC node includes training data from K different speaker and speaking environments. Accordingly, we can divide Qcinto K subsets of training data {Qc,1, Qc,2, …, Qc,K}. With these K subsets of training data, the CP densities of the MAP-based SFM and MAPLR in the cth EC node are computed as follows.Step 1: Apply ML-based SFM to calculate K sets of compensation biases {δn1,δn2,…,δnK}, using the data from K different environments, namely {Qc,1, Qc,2, …, Qc,K}.Step 2: Estimate the hyper-parameters of the CP density (mean and covariance), {ηnCP,VnCP} using(20)ηn(i)CP=1K∑k=1Kδn(i)k,(21)Vn(ii)CP=1K∑k=1K(δn(i)k−ηn(i)CP)2.Step 1: Apply MLLR to calculate K sets of transformations, {Wn1,Wn2,…,WnK}, using the data from K different environments, namely {Qc,1, Qc,2, …, Qc,K}.Step-2: Obtain the hyper-parameters in the CP density {ρnCP,HnCP} using(22)ρn(i)CP=1K∑k=1KWn(i)k,(23)(Hn(i)CP)jj=1K∑k=1K(Wn(ij)k−ρn(ij)CP)2,whereWn(ij)kandρn(ij)CPare the (ij)th elements ofWnkandρnCP, respectively, and(Hn(i)CP)jjis the jjth diagonal element inHn(i)CP.With the same procedure, we can estimate the CP density for every node in all of the C EP trees. Because each CP density corresponds to a specific group of mean parameters for a particular cluster of environments, it provides local information of the ensemble environments. With the online CS process, we can directly locate the CP densities that best match the testing condition for MAP-based SFM and MAPLR.The hyper-parameters of the sequential prior (SP) density are estimated based on sequential Bayesian learning (Hamilton, 1991). The SP densities enable MAP-based SFM and MAPLR to incorporate information seen previously for compensating the current testing utterances and for adapting the current acoustic model. The use of the SP density has been confirmed effective for MAP-based SFM (Jiang et al., 2001; Tsao et al., 2011); here we refine it further by using the local information provided by the environment structuring framework. In our system, the CS procedure is performed first to locate the acoustic model and EP tree that best match the testing utterance. With the located acoustic model and EP tree, the SP densities for MAP-based SFM and MAPLR are estimated through the following steps.Step 1: At the beginning stage, initialize the hyper-parameters in the SP densities for every EP node. The hyper-parameter for the nth EP node is initialized as{ηnSP(0)=0}. For the first utterance,δn(1)is computed based on the ML criterion using Eqs. (8)–(10) while setting α=0 in Eqs. (9) and (10).Step 2: For the uth utterance, use the SP density withηnSP(u−1), estimated from the previous (u−1) utterances, to calculateδn(u)using Eqs. (8)–(10).Step 3: Use the calculatedδn(u)to update the hyper-parameters for the following utterances. Accordingly, the hyper-parameter for the nth EP node becomes{ηnSP(u)=δn(u)}.Step 1: At the beginning stage, initialize the hyper-parameters in the SP densities for every EP node. The hyper-parameter for the nth EP node is initialized as{ρnSP(0)=0}. For the first utterance,Wn(1)is computed based on the ML criterion using Eqs. (16)–(18) while setting τ=0 in Eqs. (17) and (18).Step 2: For the uth utterance, use the SP density withρnSP(u−1), estimated from the previous (u−1) utterances, to calculateWn(u)using Eqs. (16)–(18).Step-3: Use the calculatedWn(u)to update the hyper-parameters for the following utterances. Accordingly, the hyper-parameter for the nth EP node becomes{ρnSP(u)=Wn(u)}.To simplify the online computation, we only sequentially updateηnSP(u)andρnSP(u)for MAP-based SFM and MAPLR, respectively, and use fixedVnSPandHnSPin the online process. Here, we setVnSP=VnCPandHnSP=HnCP.Although the SP density can effectively utilize the information from previous testing data to perform FC and MA, when the environment condition changes abruptly (for example, from high SNR to low SNR conditions), the use of the SP density may lead to poor FC and MA mapping function estimations. Therefore in our study, the CS process is performed before using the SP density to prevent the performance degradations caused by sudden acoustic condition changes. By performing the CS process, only the most suitable EP tree is selected for each testing utterance, and the SP density of that EP tree is used for the MAP-based estimations. After decoding on that utterance, we only update the SP density of that selected EP tree for the following utterances. In this sense, only the suitable SP densities are used and updated for each particular test utterance.As in the case of the SP densities, we perform the CS process to locate the acoustic model and EP tree that best match the testing condition to calculate the HP densities. The HP densities for MAP-based SFM and MAPLR are estimated as follows.Step 1: For the root node of the EP tree, we calculate δ1 using the entire set of means in the root node based on the ML criterion using Eqs. (8)–(10) while setting α=0 in Eqs. (9) and (10), where no HP density is used in the calculation. The estimated δ1 is used to prepare the prior densities for the child nodes in the next layer.Step 2: For the nth node with its parent node r (as shown in Fig. 3), we have the hyper-parameterηnSP=δr, and MAP-based SFM calculates δnusing Eqs. (8)–(10). The calculated δnis used to prepare the prior densities for the child nodes of the nth node.Step 3: Repeat Step 2 until reaching the leaf nodes of the EP tree.Step 1: For the root node of the EP tree, we calculate W1 using the entire set of means in the root node based on the ML criterion using Eqs. (16)–(18) while setting τ=0 in Eqs. (17) and (18), where no HP density is used in the calculation. The calculated W1 is used as the prior densities for the child nodes in the next layer.Step 2: For the nth node with its parent node r (as shown in Fig. 3), we have the hyper-parameterρnHP=Wr, and MAPLR calculates Wnusing Eqs. (16)–(18). The calculated Wnis used to prepare the prior densities for the child nodes of the nth node.Step 3: Repeat Step 2 until reaching the leaf nodes of the EP tree.As in the case of the SP densities, we only online estimate mean hyper-parameters,ηnHPandρnHPfor MAP-based SFM and MAPLR, respectively, and use fixedVnHP(=VnCP)andHnHP(=HnCP). The main advantage of the HP densities is that the information of the current testing utterance can be used efficiently with the EP tree structure.The hyper-parameters in the IP densities combine those in the three prior densities presented above. We simply use a linear combination in this study. Therefore, for MAP-based SFM, we obtain the hyper-parameter,ηnIP, using:(24)ηnIP=wCPηnCP+wSPηnSP+wHPηnHP,wherewCP,wSP, andwHPare weighting coefficients.Similarly for MAPLR, we obtain the hyper-parameter,ρnIP, using:(25)ρnIP=εCPρnCP+εSPρnSP+εHPρnHP,where ɛCP, ɛSP, and ɛHPare weighting coefficients. In this study, we only updateηnIPandρnIP, respectively, for MAP-based SFM and MAPLR online, and use fixedVnIP(=VnCP)andHnIP(=HnCP). As in the case of the HP densities, we first locate one EP tree, and then iteratively estimate and propagate the IP densities. Finally, the estimation and propagation stop at the leaf nodes of the EP tree. Notably, the CP, SP, and HP densities are estimated using the information from the training data, statistics seen from the previous utterances, and the current testing data with the EP tree, respectively. Therefore, the IP densities incorporate multiple prior information sources.

@&#CONCLUSIONS@&#
