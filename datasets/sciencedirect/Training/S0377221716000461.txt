@&#MAIN-TITLE@&#
Biobjective robust optimization over the efficient set for Pareto set reduction

@&#HIGHLIGHTS@&#
We present a biobjective formulation for identifying robust solutions from a given Pareto set.Solutions are mapped onto a 2-dimensional space, termed the robustness space.Structural properties and a solution algorithm are developed for the case of multiobjective linear programs.The methodology enables dealing with both discrete and continuous Pareto sets.

@&#KEYPHRASES@&#
Multiple criteria analysis,Multiple objective programming,Robustness and sensitivity analysis,Pareto set reduction,

@&#ABSTRACT@&#
This paper presents a biobjective robust optimization formulation for identifying robust solutions from a given Pareto set. The objectives consider both solution and model robustness when the exact values of the selected solution are affected by uncertainty. The problem is formulated equivalently as a model with uncertainty on the constraint parameters and objective function coefficients. Structural properties and a solution algorithm are developed for the case of multiobjective linear programs. The algorithm is based on facial decomposition; each subproblem is a biobjective linear program and is related to an efficient face of the multiobjective program. The resulting Pareto set reduction methodology allows the handling of continuous and discrete Pareto sets, and can be generalized to consider criteria other than robustness. The use of secondary criteria to further break ties among the many efficient solutions provides opportunities for additional trade-off analysis in the space of the secondary criteria. Examples illustrate the algorithm and characteristics of solutions obtained.

@&#INTRODUCTION@&#
This paper presents a methodology for identifying a subset of robust solutions from the Pareto set of a multiobjective program (MOP). We term this problem the robust Pareto set reduction problem.The Pareto set of an MOP contains solutions that are incomparable (i.e., non-dominated) with respect to the objective functions for optimization. The size of the Pareto set can be very large and possibly infinite, posing a significant challenge to a decision maker needing to select a single solution for implementation. For instance, the size of a Pareto set composed of a finite number of outcomes can grow exponentially with the number of objective functions, even when the number of constraints and decision variables are fixed (Deb & Saxena, 2005). In a multiobjective linear program (MOLP) the efficient set is usually formed by an infinite number of solutions, expressed as the union of all maximal efficient faces (Yu & Zeleny, 1975). In addition, selecting a single solution in a high dimensional objective space can lead to challenging trade-off analysis (Engau & Wiecek, 2007). This problem is augmented when considering the incommensurability of the objectives in the MOP. To remedy this issue, interactive methods are often utilized in which the decision maker is iteratively asked to express his/her partial trade-offs in order to guide the search procedure to a final most preferred solution. For instance, Engau and Wiecek (2008) provide an interactive method based on objective space decomposition procedures that may be applied to an MOP faced with scenario-wise uncertainties. The problem dealt with here differs in the sense that it falls into the a posteriori category of multiobjective programming, i.e. the decision maker preferences are only considered after the Pareto set has been generated. The interested reader should refer to Alves and Clímaco (2007); Luque, Ruiz, and Steuer (2010); Steuer and Choo (1983) and Luque, Ruiz, and Miettinen (2011) for further applications of interactive methods.Pareto set reduction (PSR) methods are available in the literature to alleviate the problem of having to trade off among several alternatives. Most existing PSR methods are limited to the case of discrete Pareto sets and use ranking and clustering methodologies. Ranking methods attempt to prioritize solutions based on some function of the objective values (e.g. Das, 1999a; Branke, Deb, Dierolf, & Osswald, 2004; Vafaeyan & Thibault, 2009; Carrillo & Taboada, 2012), or rank solutions based on a degree to which each objective function affects efficiency (e.g. Das, 1999b; Venkat, Jacobson, & Stori, 2004; Kao & Jacobson, 2008). Clustering methods aim at finding a representative subset of efficient solutions (e.g. Steuer & Harris, 1980; Morse, 1980; Rosenman & Gero, 1985; Taboada & Coit, 2008; Aguirre, Taboada, Coit, & Wattanapongsakorn, 2011; Eusébio, Figueira, & Ehrgott, 2014; Vaz, Paquete, Fonseca, Klamroth, & Stiglmayr, 2015). In these methods, a cluster groups solutions with similar objective values; the reduced subset includes a representative solution from each cluster.Briefly, the PSR problem is modeled as the second stage in a two-stage optimization process. The first stage is the problem of generating the Pareto set (or an approximation) corresponding to an MOP; the second stage (i.e. the PSR problem) is an optimization problem over the efficient set of the MOP to identify solutions that are also efficient with respect to the aforementioned secondary objectives. It must be noted that the literature on optimization over the efficient set typically focuses on algorithms to find an optimal solution to a single objective (e.g Benson, 1984; Horst & Thoai, 1999; Sayin, 2000; Yamamoto, 2002; Jorge, 2009; Thang, 2015). In contrast, we focus on a new formulation and theoretical properties of the Pareto set reduction problem, and propose a solution approach for the case when the first stage problem is an MOLP. Here the Pareto set of the MOP is assumed to be known, i.e. we do not consider solving the first stage problem. For a review on generating the Pareto set of an MOP the interested reader is referred to Ehrgott and Gandibleux (2002); Miettinen (1999) or Marler and Arora (2004). It is implied that the secondary objectives, although meaningful (i.e. they capture desirable characteristics of a solution), are not as important as the ones in the first stage MOP; otherwise, they should be considered together with the objectives in the MOP typically resulting in a larger, rather than reduced, Pareto set.In a recent work, Vaz et al. (2015) formulate the PSR as a facility location problem to find a representative set based on clustering Pareto outcomes in the objective space of the MOP. The model proposed by the authors assumes that the Pareto set is discrete and is applied to the case of a biobjective MOP. Although similar, the problem dealt with in this paper does not attempt to find a representative subset from the Pareto set, but rather, to provide additional trade-off context by introducing secondary criteria related to both the objective and the decision spaces of the MOP in order to break ties among the Pareto outcomes. In addition, we do not require the Pareto set to be discrete and the methodology may be applied to an MOP with any number of objective functions.The consideration of robustness to develop secondary objective functions is central to this paper. Here a solution is deemed robust if it remains “close” to its optimal objective values and/or “almost” feasible when affected by uncertainty. The notions of what is “close” and “almost” are made precise later in the paper. Mulvey, Vanderbei, and Zenios (1995) termed the robustness with respect to objective value loss as solution robustness, and robustness with respect to feasibility as model robustness. While it is unlikely that a solution retains its objective value and at the same time remains feasible when affected by uncertainty, the robust optimization literature often focuses on finding solutions that will remain feasible for all possible realizations within the uncertainty set (e.g. Ben-Tal & Nemirovski, 2002; Bertsimas & Sim, 2004), hence not explicitly providing the decision maker with trade-off information between model and solution robustness; see (Bertsimas, Brown, & Caramanis, 2011) for a survey on the extensive work in single objective robust optimization, and Deb and Gupta (2006); Ehrgott, Ide, and Schöbel (2014); Gunawan and Azarm (2005); Mavrotas, Pechak, Siskos, Doukas, and Psarras (2015b) and Goberna, Jeyakumar, Li, and Vicente-Pérez (2015) for literature on the less studied multiobjective case. The choice of the uncertainty set plays an important role in tractability of robust counterpart problems. For examples of different structures of uncertainty sets see (Bertsimas & Brown, 2009) and (Bertsimas & Thiele, 2006). Here, we focus on the box and cardinality-constrained uncertainty sets. A major advantage from these cases is that they lead to tractable robust counterpart problems in the linear case (Bertsimas & Sim, 2004).A few recent papers deal with problems similar to the one presented here. A methodology for identifying efficient solutions within a set of robust solutions was proposed by Iancu and Trichakis (2013). The authors assessed efficiency of a solution in terms of performance for all scenarios in the uncertainty set. Here our methodology seeks the opposite, i.e. finding robust solutions within the set of efficient solutions of the MOP. Finally, Mavrotas, Figueira, and Siskos (2015a) used Monte Carlo simulation to assess the robustness of efficient solutions of an MOP using nominal values of the problem parameters. A simulation trial consists of solving the MOP with an instantiation of the uncertain problem parameters; in turn, the robustness of each nominal efficient solution is evaluated by a ratio that reflects the number of times it belongs to the efficient set across all Monte Carlo trials. Important differences are that our methodology is based on mathematical programming rather than simulation on a finite efficient set, and that we explicitly consider model and solution robustness as opposed to a unique robustness ratio.The remainder of the paper is organized as follows. Section 2 formalizes the model, introducing notation and mathematical definitions used in the paper. Section 3 describes the robust Pareto set reduction problem formulation and analysis. Section 4 develops properties when the first stage problem is an MOLP, while Section 5 shows a solution procedure for this case. Section 6 provides numerical examples and Section 7 presents concluding remarks.The notation is as follows. LetRn,RmandRkbe finite dimensional Euclidean vector spaces. Letf=(f1,…,fk)Tdenote a vector of objective functionsfi:Rn→R,fori=1,…,k,where each fiassigns to each decision vectorx∈Rna real number fi(x), such thatf(x)=(f1(x),…,fk(x))T. Let X be the feasible set defined on the decision spaceRn,such thatX={x:hi(x)≥bi,i=1,…,m},wherebi∈Ris the right-hand-side parameter of the ith constraint and the mappinghi:Rn→Rassigns to eachx∈Rna real number hi(x) defining the left-hand-side of the ith constraint, fori=1,…,m. LetY={y∈Rk:y=f(x),forx∈X}be the corresponding outcome set in the objective spaceRk. Then, the MOP can be written as:(MOP)Minf(x)s.t.x∈XFor any x andx′∈Rn,we will adopt the following notation: f(x) < f(x′) if fi(x) < fi(x′) for alli=1,…,k; f(x)≦f(x′) if fi(x) ≤ fi(x′) for alli=1,…,k; and f(x) ≤ f(x′) if f(x)≦f(x′) but f(x) ≠ f(x′). LetR≧k={y∈Rk:y≧0}be the nonnegative orthant ofRk. The setsR≥kandR>kare defined similarly. We denote by int Y and bd Y the interior and the boundary of the set Y, respectively.To solve the MOP is understood as to find the set of efficient solutions, defined next.Definition 1Yu & Zeleny, 1975A solution x ∈ X to the MOP is called efficient if and only if there does not exist another x′ ∈ X such that f(x′) ≤ f(x).Any solution x ∈ X that does not satisfy efficiency is called a dominated solution. A solution x′ ∈ X is said to dominate another solution x ∈ X if f(x′) ≤ f(x). If x is an efficient solution and there does not exist another x′ ∈ X such thatf(x)=f(x′),then x is said to be strictly efficient (Lowe, Thisse, Ward, & Wendell, 1984). Throughout this paper, the image of an efficient solution in the objective space is referred to as a Pareto outcome. The set of all efficient solutions in the decision spaceRnis termed efficient setX,whereas the set of all Pareto outcomes in the objective spaceRkis referred to as the Pareto setY. Here, we assume thatXandYare non-empty compact sets. For details on the existence of the Pareto and the efficient sets, see (Sawaragi, Nakayam, & Tanino, 1985).Letf̲i=min{fi(x):x∈X}and letf¯i=max{fi(x):x∈X}denote the minimum and the maximum of the i-th objective function over the efficient set, respectively. We assume thatf̲i≠f¯ior else objective function fiwould be non-conflicting in the MOP. The outcomef̲=(f̲1,…,f̲k)Tis referred as the ideal point andf¯=(f¯1,…,f¯k)Tis referred as the Nadir point. In general, computing the Nadir point can be computationally challenging. However, an estimate may be obtained from a payoff table. For further details on computing the Nadir point, the reader may refer to Ehrgott and Tenfelde-Podehl (2003) and Alves and Costa (2009).Here we assume thatX,Y,f¯andfare already known. We further assume that efficiency of a solution with respect to the MOP has priority over hedging against the uncertainty. Hence,Xrestricts the feasible set for the subsequent problem of finding those efficient solutions that satisfy model and/or solution robustness.In this paper, we are motivated by cases where the prescribed values of the decision variables cannot be implemented exactly as computed. These implementation errors, referred here to as implementation uncertainty, can occur due to lack of model fidelity resulting from practical issues such as insufficient modeling time or unavailable knowledge during model building. Ben-Tal, El Ghaoui, and Nemirovski (2009) state that implementation uncertainty may arise due to the inherent characteristics of some physical devices (e.g. in antenna design) and that these implementation uncertainties are equivalent to “appropriate artificial data uncertainties”. In this paper, we model uncertainties directly affecting the decision variables; the results, however, are applicable to both data and implementation uncertainty because we will deal with MOLPs. It must be noted that, in other cases establishing the equivalence may not be as straightforward; for instance, in the case of conic quadratic programs, Ben-Tal and Den Hertog (2011) had to develop extensions of the S-lemma to show that a convex quadratic constraint under implementation uncertainty given by an ellipsoidal uncertainty set is equivalent to a system of conic quadratic constraints.Next, we formalize the general representation of the perturbation on a solution used in this paper.Definition 2For some uncertainty level α > 0, the perturbation factorβ˜=(β˜1,…,β˜n)Tis a random vector such that1−α≤β˜j≤1+α,for allj=1,…,n. Given a realization β ofβ˜,βx=(β1x1,…,βjxj)Tdenotes a perturbation on the solution values of x.Although this paper restricts the analysis to the case of a multiplicative perturbation factor, the model may alternatively be defined by additive perturbations, which would be equivalent to perturbing the right-hand-side of the constraint set in the case of linear constraints. LetUdenote the uncertainty set of all possible realizations of the perturbation factorβ˜. At this point, no further assumption is imposed onUother than being bounded by a box according to Definition 2.To measure the degree of model robustness, let the function δ:Rn↦R≧be a mapping that assigns to eachx∈Rna non-negative real number, denoted byδ(x)∈R≧,that measures the maximum degree of constraint violation due to perturbations on the values of x, given as follows.Definition 3Letx∈Rn. Then,δ(x)=supβ∈Ui=1,…,m{max{(bi−hi(βx))/|bi|,0}}is called the infeasibility level associated with x.Definition 3 requires that bi≠ 0; if somebi=0,an alternative would be to replace the denominator |bi| for|bi|+1. The case whenδ(x)=0implies that the solution will remain feasible for any perturbation within the uncertainty set.Similarly, in order to measure solution robustness let the function γ:Rn↦R≧be a mapping that assigns to eachx∈Rna non-negative real number, denoted byγ(x)∈R≧,that measures the maximum degree of objective function values loss due to perturbations on the values of x, given as follows.Definition 4Letx∈Rn. Then,γ(x)=supβ∈Ui=1,…,k{max{fi(βx)−fi(x)f¯i−f̲i,0}}is called the outcome degradation level associated with x.In Definition 4, a normalization of objective function values is used due to the possibly different ranges of the objective functions in the MOP. The case whenγ(x)=0implies that the perturbations on x within the uncertainty set will not worsen any objective function value.Considering both model and solution robustness, Definition 5 introduces the robustness projection set and the robustness space.Definition 5The robustness projection setDdefined on the robustness spaceR≧2contains the set of pointsD={(δ(x),γ(x))T,∀x∈X}Given the efficient setXof an MOP and the uncertainty setU,the robust Pareto set reduction problem (RPSR) is a bicriterion program to minimize the infeasibility and the outcome degradation levels over the efficient set of the MOP. The RPSR is formulated as follows:(RPSR)Min(δ,γ)Ts.t.hi(βx)+|bi|δ≥bi∀i=1,…,m,β∈Ufi(x)−fi(βx)+(f¯i−f̲i)γ≥0∀i=1,…,k,β∈Ux∈Xδ,γ≥0where the constantsf¯iandfiare also assumed to be known. The formulation of the RPSR, in its general form, may contain infinitely many constraints becauseUis not explicitly specified. As in a classical robust optimization approach, this issue can be solved by using uncertainty sets with specific geometries; in particular, we will utilize the box and the cardinality-constrained uncertainty sets in the following sections.LetX′denote the subset of efficient solutions to the RPSR, termed the robust efficient set. LetY′denote its image in the objective space, the robust Pareto set. The setD′={(δ(x),γ(x)):x∈X′}is the image of the robust efficient set in the robustness space. In general,Y′can still possess an infinite number of outcomes when the MOP is a continuous problem. In this case, the term “reduction” is used in a broader sense to denote that the RPSR identifies only the subset ofYthat contains robust solutions.The model is illustrated in Fig. 1. In the first stage, we assume that the MOP is solved to generate the efficient setXand the Pareto setY. In the second stage, i.e. the PSR problem focus of this paper, the efficient setXand the uncertainty setUare taken as input to find the subset of efficient solutions that remain Pareto optimal in the robustness space. The model defines a mapRk→R2from the k-dimensional objective space of the MOP onto a 2-dimensional robustness space (i.e. the objective space of the RPSR).Solving the RPSR is not equivalent to solving a robust counterpart of the MOP, i.e. when uncertainty is considered directly when solving the MOP. This could result in solutions dominated by the ones inX,asYlies on the boundary of Y. The RPSR formulation is neither analogue to introducing the infeasibility and outcome degradation criteria directly into the MOP as follows:(P2)Min(f1(x),…,fk(x),δ,γ)Ts.t.hi(βx)+|bi|δ≥bi∀i=1,…,m,β∈Ufi(x)−fi(βx)+(f¯i−f̲i)γ≥0∀i=1,…,k,β∈Ux∈Xδ,γ≥0LetXP2be the efficient set of P2. If allx∈Xare strictly efficient in the sense of Lowe et al. (1984), it follows thatX⊆XP2. Hence, adding the measures of robustness directly when solving the MOP would not yield the desired set reduction.Next, limit conditions for δ(x) and γ(x) are presented.Theorem 3.1Ifhi:Rn↦R,fori=1,…,m,andfi:Rn↦R,fori=1,…,k,are continuous functions, then for every ξ > 0 there exists ν > 0 such that0<α<ν⇒0≤δ(x)<ξand0≤γ(x)<ξ,forallx∈X.The proof of Theorem 3.1 follows straightforward analysis of limits. As a result, as α approaches zero, the values of infeasibility and outcome degradation levels of all efficient solutions tend to zero.LetCi=(c1i,…,cni)T,i=1,…,k,be the cost vector for the ith objective function. LetX={x:Ax≧b,x≧0},whereA∈Rm×nis a matrix of elements aijfori=1,…,mandj=1,…,n. Then, the RPSR associated with an MOLP will havehi(x)=∑j=1naijxj,fori=1,…,m,andfi(x)=∑j=1ncjixj,fori=1,…,k.When the uncertainty set is given as the boxU={β∈Rn:1−α≤βj≤1+α,j=1,…,n},for some α > 0, then the worst case violation for the ith constraint will haveβj=1+α,if aij< 0, andβj=1−α,if aij> 0. Therefore, the first set of constraints in the RPSR formulation is reduced to∑j=1n(aij−|aij|α)xj+|bi|δ≥bi,∀i=1,…,m. Notice thatδ(x)=0can happen for somex∈X,if x ∈ int X. Similarly, the worst case degradation for the ith objective function value will haveβj=1+α,ifcji>0,andβj=1−α,ifcji<0. Therefore, the second set of constraints in the RPSR formulation is reduced to(f¯i−f̲i)γ−∑j=1n|cji|αxj≥0,∀i=1,…,k. Hence, if fi(x) ≠ 0 for somei=1,…,k,it follows that γ(x) > 0.The following subsections describe several structural properties of the problem resulting from the linearity condition.The bounds presented next are developed as a function of the uncertainty level α; hence if the value of α can be adjusted, the decision maker gains additional control over the robustness of the solution selected for implementation. For instance, in engineering design problems (e.g. in the antenna design in Ben-Tal et al. (2009)), improving the precision of the manufacturing system would allow for a lower value of α, hence decreasing the value of the upper bounds. Conversely, given a maximum infeasibility and outcome degradation levels that are acceptable to the decision maker, the bounds may be useful to select the appropriate value of α.Theorem 4.1For allx∈X,the infeasibility level is bounded byδu(x)=αmaxi=1,…,m{∑j=1n|aijxjbi|}LetJi+be the columns of row i in constraint matrix A where aij≥ 0 and letJi−be the columns where aij< 0. Then, foraij∈Ji+,the upper bound on the constraint violation will be whenβj=1−α. Similarly, foraij∈Ji−,the upper bound will be whenβj=1+α. Therefore:δ(x)≤maxi=1,…,m{max{bi−(∑j∈Ji+aij(1−α)xj+∑j∈Ji−aij(1+α)xj)|bi|,0}}=maxi=1,…,m{max{bi−∑j=1naijxj|bi|−α∑j∈Ji−aijxj−∑j∈Ji+aijxj|bi|,0}}≤maxi=1,…,m{max{−α∑j∈Ji−aijxj−∑j∈Ji+aijxj|bi|,0}}=αmaxi=1,…,m{∑j=1n|aijxjbi|}where the last inequality follows from the fact thatbi−∑j=1naijxj≤0,∀i=1,…,m.□If parameters aijand b are non-negative, then the following corollary follows:Corollary 4.2If bi> 0 and aij≥ 0 for alli=1,…,mandj=1,…,n,then for allx∈X,the infeasibility level is bounded byδu(x)=α.Because bi> 0, the modulus in the denominator of δ(x) can be dropped. The upper bound on the constraint will be whenβj=1−αfor allj=1,…,n. Then, it becomes:δ(x)≤maxi=1,…,m{max{bi−∑j=1naij(1−α)xjbi,0}}≤maxi=1,…,m{max{1−(1−α),0}}=αwhere the last inequality follows from the fact that∑j=1naijxj/bi≥1,∀i=1,…,m.□Upper bounds for the outcome degradation level are developed next.Theorem 4.3For allx∈X,the outcome degradation level is bounded byγu(x)=αmaxi=1,…,k{∑j=1n|cji|xjf¯i−f̲i}LetJi+be the columns j where, for objective functioni=1,…,k,cji≥0and letJi−be the columns wherecji<0. Then, forcji∈Ji+,the upper bound on γ(x) will be whenβj=1+α. Similarly, forcji∈Ji−,the upper bound will be whenβj=1−α. Then, it follows thatγ(x)≤maxi=1,…,k{∑j∈Ji+cji(1+α)xj+∑j∈Ji−cji(1−α)xj−∑j=1ncjixjf¯i−f̲i}=αmaxi=1,…,k{∑j=1n|cji|xjf¯i−f̲i)}□Ifcji≥0for alli=1,…,kandj=1,…,n,then for allx∈X,the outcome degradation level is bounded byγu(x)=αmaxi=1,…,k{f¯if¯i−f̲i}Becausef¯i≥∑j=1ncjixj∀x∈X:γ(x)≤αmaxi=1,…,k{∑j=1ncjixjf¯i−f̲i}≤αmaxi=1,…,k{f¯if¯i−f̲i}□While Theorem 4.3 provides a tighter bound on the outcome degradation level, the bound in Corollary 4.4 is independent from the value of the nominal solution x.The cardinality-constrained uncertainty set arises when the number of decision variables that are simultaneously affected by uncertainty is limited by some given non-negative integer Γ. As in Bertsimas and Sim (2003), the value of Γ can be adjusted to control the level of conservatism when finding robust efficient solutions. In this case,Uis given by:(1)U={β∈Rn:(1−αyj)≤βj≤(1+αyj),∑j=1nyj≤Γ,y∈{0,1}n}Let δcand γcdenote the infeasibility and outcome degradation levels under the cardinality-constrained uncertainty set. Then, the cardinality-constrained RPSR, denoted as C-RPSR, becomes:(C-RPSR)Min(δc,γc)Ts.t.∑j=1naijxj+|bi|δc−αmaxyj∈{0,1}{∑j=1n|aij|xjyj:∑j=1nyj≤Γ}≥bi∀i=1,…,m(f¯i−f̲i)γc−αmaxvj∈{0,1}{∑j=1n|cji|xjvj:∑j=1nvj≤Γ}≥0∀i=1,…,kx∈Xδc,γc≥0where the first and second sets of constraints come from the application of the uncertainty set (1) to Definitions 3 and 4, respectively.In order to see that the first set of constraints follows, letJi−andJi+denote the set of columns in row i where coefficients aijare negative and positive, respectively. With the cardinality restriction, the constraints∑j=1naijβjxj+|bi|δ≥biin the RPSR formulation become:maxyj∈{0,1}{∑j∈Ji+aij(1−αyj)xj+∑j∈Ji−aij(1+αyj)xj:∑j=1nyj≤Γ}+|bi|δc(x)≥biwhich yields the first set of constraints in the C-RPSR. Similarly, letJi−andJi+denote the set of columns in the ith objective function where coefficientscjiare negative and positive, respectively. The cardinality-constrained outcome degradation level from constraints∑j=1ncjixj−∑j=1ncjiβjxj+(f¯i−f̲i)γ≥0in the RPSR formulation becomes:∑j=1ncjixj−maxvj∈{0,1}{∑j∈Ji+cji(1+αvj)xj+∑j∈Ji−cji(1−αvj)xj:∑j=1nvj≤Γ}+(f¯i−f̲i)γc≥0which yields the second set of constraints in C-RPSR.In the C-RPSR formulation, the first and the second constraint sets are non-linear due to the inner max in each of them. Similar to Bertsimas and Sim (2004), it can be shown that using an LP relaxation of the binary variables and invoking strong duality principles in the inner maxima would yield an equivalent formulation of the C-RPSR where the constraints related to the infeasibility and outcome degradation levels are convex. Here the original formulation of the C-RPSR was kept to preserve the structure of the problem.WhenXis approximated by a finite number of solutions (e.g. by solving the MOLP using the ϵ-constraint method or some metaheuristic), xj’s can be regarded as constants in the C-RPSR. Then, the inner maxima in the first and second sets of constraints in the C-RPSR consist of knapsack problems with equal weights. Hence, the solution for a given x will be simply to setyj=1andvj=1for the columns with the Γ largest absolute values of aijxjandcjixj,respectively. In the worst case, computing δ(x) and γ(x) for eachx∈Xcan be done inO((m+k)n)time, since: (i) finding the Γ largest |aijxj| values for each constrainti=1,…,m,and the Γ largest|cjixj|values for each objective functioni=1,…,k,are selection problems and can be done in O(n) time in the worst case; (ii) taking the maximum of the m constraint violations and the maximum of the k objective function values degradations associated with the previous step require O(m) and O(k) time, respectively. Filtering dominated solutions in the robustness space requires pairwise comparisons of all solutions in the worst case. Hence, the computational complexity associated with solving the C-RPSR isO(|X|2+|X|(m+k)n)whenXis approximated by a finite number of solutions.If a low value of Γ is used, the actual realization of the infeasibility and the outcome degradation levels might be higher than the ones obtained from the C-RPSR. This is because, in reality, more than Γ decision variables might be simultaneously affected by uncertainty. Indeed, in the worst case, all columns would be simultaneously affected by uncertainty. Theorems 4.5 and 4.6 determine upper bounds on the probabilities of constraint violations and objective function degradations that exceed the calculated values using the cardinality-constrained uncertainty set. These theorems are extensions of Bertsimas and Sim (2004) in the sense that the probability bounds are developed for i.i.d. and bounded random variables with unknown distributions. However, in Bertsimas and Sim (2004) the bounds were derived for the probability of constraint violations of any size, whereas here the bounds are for the excess probability.Fori=1,…,m,letδ˜i(x)=max{(bi−∑j=1naijβ˜jxj)/|bi|,0}and denote the cardinality-constrained infeasibility level for the ith constraint,δic(x),as:(2)δic(x)=max{(bi−∑j=1naijxj+αmaxy∈{0,1}n{∑j=1n|aij|xjyj:∑j=1nyj≤Γ})/|bi|,0}=(bi−∑j=1naijxj+max{αmaxy∈{0,1}n{∑j=1n|aij|xjyj:∑j=1nyj≤Γ},∑j=1naijxj−bi})/|bi|Fori=1,…,kletγ˜i(x)=max{∑j=1ncjixj(β˜j−1)/(f¯i−f̲i),0}and denote the cardinality-constrained outcome degradation level for the ith objective function,γic(x),as:(3)γic(x)=(αmaxv∈{0,1}n{∑j=1n|cji|xjvj:∑j=1nvj≤Γ})/(f¯i−f̲i)The bounds using the cardinality-constrained uncertainty set are presented next.Theorem 4.5LetUbe as in(1)and letβ˜jfrom Definition2be symmetric i.i.d. random variables centered at 1. Fori=1,…,m,the probability that the ith constraint violation exceeds the value ofδicis given by:Pr(δ˜i(x)>δic(x))≤exp(−τi22∑j=1n(aijxj)2)whereτi=max{maxy∈{0,1}n{∑j=1n|aij|xjyj:∑j=1nyj≤Γ},∑j=1naijxj−biα}LetUbe as in(1)and letβ˜jfrom Definition2be symmetric i.i.d. random variables centered at 1. Fori=1,…,k,the probability of outcome degradation for the ith objective function that exceeds the value ofγicis given by:Pr(γ˜i(x)>γic(x))≤exp(−(maxv∈{0,1}n{∑j=1n|cji|xjvj:∑j=1nvj≤Γ})22∑j=1n(cjixj)2)The proofs of Theorems 4.5 and 4.6 are given in Appendices A and B, respectively. For any realization ofβ˜within the cardinality-constrained uncertainty set, the formulation of the C-RPSR provides a deterministic guarantee that the actual infeasibility and outcome degradation levels will be less than or equal toδc(x)=max{δ1c(x),…,δmc(x)}andγc(x)=max{γ1c(x),…,γkc(x)},respectively. Moreover, even if the realization ofβ˜falls outside the cardinality-constrained uncertainty set, Theorems 4.5 and 4.6 still provide probabilistic guarantees that the infeasibility level associated with the ith constraint, fori=1,…,m,and outcome degradation levels associated with the ith objective function, fori=1,…,k,will be less than or equal to the values calculated from (2) and (3) using the cardinality-constrained uncertainty set. Hence, Theorems 4.5 and 4.6 may be utilized to determine an appropriate value for Γ according to the decision maker’s level of conservatism.The bounds in Theorems 4.5 and 4.6 were developed for the general case of bounded random variables. Next, we derive a simple-to-compute bound that is independent of the solution value when perturbations on each xjare a composite random variableβ˜j∘ν˜jwhereν˜jare i.i.d. Bernoulli trials. Letδ˜(x)=max{δ˜1(x),…,δ˜m(x)}and letγ˜(x)=max{γ˜1(x),…,γ˜k(x)}. The bound is shown in Theorem 4.7.Theorem 4.7Let1−αν˜j≤β˜j≤1+αν˜j,whereν˜jare i.i.d. Bernoulli trials with probability of success 0 < p < 1. IfΓ≥pn−1,the following upper bound holds:Pr(δ˜(x)>δc(x))<exp(−2n(Γ+1n−p)2)andPr(γ˜(x)>γc(x))<exp(−2n(Γ+1n−p)2)We will proceed by showing the probability bound forδ˜(x)>δc(x). The proof procedure forγ˜(x)>γc(x)follows analogously. It holds thatPr(δ˜(x)>δc(x))=1−Pr(δ˜(x)≤δc(x))=1−Pr(δ˜1(x)≤δc(x),…,δ˜m(x)≤δc(x)). LetT˜=∑jnν˜j. Because1−αν˜j≤β˜j≤1+αν˜j,it follows from the C-RPSR formulation thatPr(δ˜1(x)≤δc(x),…,δ˜m(x)≤δc(x)|T˜≤Γ)=1. From Bayes’ Rule, it follows that:Pr(δ˜1(x)≤δc(x),…,δ˜m(x)≤δc(x))=Pr(T˜≤Γ)Pr(δ˜1(x)≤δc(x),…,δ˜m(x)≤δc(x)|T˜≤Γ)Pr(T˜≤Γ|δ˜1(x)≤δc(x),…,δ˜m(x)≤δc(x))≥Pr(T˜≤Γ)ThereforePr(δ˜(x)>δc(x))≤1−Pr(T˜≤Γ)=Pr(T˜≥Γ+1). Given thatT˜∼B(n,p),from Okamoto’s inequality (Okamoto, 1959), we have that for any c ≥ 0 and 0 < p < 1,Pr(T˜≥n(c+p))<exp(−2nc2). Selectingc=(Γ+1)/n−pfor anyΓ≥pn−1,yields the desired result.□Clearly p, Γ,δ˜(x),γ˜(x)and the values of δc(x) and γc(x) are related. While Γ controls the degree of conservatism of the formulation of the C-RPSR and hence affects the calculated values of δc(x) and γc(x), the realized values associated withδ˜(x)andγ˜(x)increase with p.The robust counterpart of the MOLP, represented via the minimax absolute robustness approach of Kouvelis and Yu (1997), introduces uncertainty directly when solving the MOLP. In this section we assume the box uncertainty set, and formulate the robust counterpart of the MOLP, denoted as RMOLP, as follows.(RMOLP)Min(∑j=1n(cj1+|cj1|α)xj,…,∑j=1n(cjk+|cjk|α)xj)Ts.t.∑j=1n(aij−|aij|α)xj≥bi∀i=1,…,mxj≥0∀j=1,…,nLetXRMOLPdenote the set of efficient solutions to the RMOLP. From Definition 3, it is straightforward to see that the RMOLP guarantees model robustness, i.e.δ(x*)=0for allx*∈XRMOLP. Using Definitions 3 and 4 to projectx*∈XRMOLPin the robustness space, the following relatesXRMOLPandX′.Theorem 4.8For the box uncertainty set, ifX⊆R>n⋂bd X, the following statements are true:(a)For allx*∈XRMOLP∄x∈X′:δ(x)≤δ(x*)and γ(x) ≤ γ(x*) with at least one inequality holding strictly.Ifcji≥0,j=1,…,n,i=1,…,k,it follows that for somex∈X′∄x*∈XRMOLP:δ(x*)≤δ(x)and γ(x*) ≤ γ(x) with at least one inequality holding strictly.If allx∈Xare strictly efficient in the sense of Lowe et al. (1984),cji≥0,j=1,...,n,i=1,2,and bi> 0 and aij≥ 0,i=1,…,m,j=1,…,n,then|X′|=1.(a)Follows trivially sinceδ(x*)=0for allx*∈XRMOLPand δ(x) > 0 for allx∈X′asX′⊆R>n⋂bd X.Assume that for allx∈X′,∃x*∈XRMOLP:δ(x*)≤δ(x)and γ(x*) ≤ γ(x) with at least one inequality holding strictly. Let x′ be an optimal solution tolexmin{γ(x),δ(x)|x∈X},i.e. the solution with smallest value δ(x) among all solutions with smallest value of γ(x). Notice thatx′∈X′. Because all perturbationsβ˜jcan take the worst case simultaneously, the bound from Theorem 4.3 will be tight and sincecji≥0we have that∀x∈X′,∃x*∈XRMOLP:γ(x*)≤γ(x)⇒maxi=1,…,kfi(x*)f¯i−f̲i≤maxi=1,…,kfi(x)f¯i−f̲iwhich implies that∃x*∈XRMOLP:maxi=1,…,kfi(x*)f¯i−f̲i≤maxi=1,…,kfi(x′)f¯i−f̲iBecauseX⊆R>n⋂bdXandcji≥0,∃x∈Xsuch that fi(x) < fi(x*),∀i=1,…,k. Hence,∃x∈X:maxi=1,…,kfi(x)/(f¯i−f̲i)<maxi=1,…,kfi(x*)/(f¯i−f̲i). Given that x′ is optimal tominx∈X{maxi=1,…,kfi(x)/(f¯i−f̲i)},it follows thatmaxi=1,…,kfi(x′)f¯i−f̲i<maxi=1,…,kfi(x*)f¯i−f̲iwhich yields a contradiction.Because all perturbationsβ˜jcan take the worst case simultaneously, and all parameters are non-negative, the bounds from Corollary 4.2 and Theorem 4.3 will be tight, hence forx∈X:δ(x)=αγ(x)=αmax{f1(x)f¯1−f̲1,f2(x)f¯2−f̲2}Therefore, the set of robust solutions will be given by:X′=argminx∈Xγ(x)Because of efficiency, there does not exist x andx′∈X:f1(x′)≤f1(x)and f2(x′) ≤ f2(x) with at least one inequality holding strictly. Hence, it holds that:X′=argminx∈Xγ(x)={x∈X:f1(x)f¯1−f̲1=f2(x)f¯2−f̲2}From strict efficiency, only one solution can satisfy the above condition, hence|X′|=1.□Part (a) of Theorem 4.8 shows a case where the solutions obtained from introducing robustness directly when solving the MOLP (i.e. the RMOLP) will not be dominated in the robustness space by any solution obtained from the RPSR. Part (b) provides a condition where at least one solution obtained from the RPSR will not be dominated in the robustness space by any solution from the RMOLP. While the former is due to the fact that solutions from the RMOLP have zero infeasibility level, the later shows that solutions from the proposed methodology may have lower outcome degradation levels. This will be illustrated in Example 2 in Section 6. Part (c) shows a condition in which the RPSR is guaranteed to effectively break ties among efficient solutions, leading the decision maker to a unique solution for implementation.These conditions show that the RPSR may find fewer robust solutions than a classical robust optimization approach, and at least one solution that is not dominated in the robustness space by any solution found by a classical robust optimization approach. For the purpose of protecting against worst case model robustness, one could argue that a classical robust optimization approach would be more appropriate since all solutions would remain feasible for all possible realizations within the uncertainty set. On the other hand, in a less conservative case of model robustness or when robustness is considered as secondary criteria, one could argue that the PSR methodology would be more appropriate to aid decision making since it allows the trade-off analysis between objective function values losses and constraint violations, while providing the decision maker with a reduced subset of solutions.In general, the RPSR is a nonconvex problem since the efficient set is typically nonconvex, even in the special case of MOLPs. Although it has been shown that the problem of linear optimization over the efficient set is NP-hard (Fülöp, 1994), here the setD′may be effectively obtained because here we assume that the efficient set is known and given as input. The proposed algorithm is applied to the case where the efficient set is associated with an MOLP and is based on a facial decomposition of the RPSR and the application of a filtering procedure, similar to Vincent, Seipp, Ruzika, Przybylski, and Gandibleux (2013), in the robustness space.Before presenting the approach to solve the RPSR, we briefly introduce additional concepts and notation from Yu and Zeleny (1975) and Sayin (1996). For the sake of brevity, we focus on the case of the box uncertainty set, although it would be straightforward to extend the algorithm to the case of the cardinality-constrained uncertainty set by using the convex relaxation formulation of the C-RPSR mentioned in Section 4.2.Yu and Zeleny (1975) showed that the efficient setXof an MOLP can be decomposed by the faces of X that are efficient. Here we make use of this property and assume that a face of X is represented via the corresponding constraints of the MOLP that hold at equality. Let I denote an n × n identity matrix and letA^=[AI]be an augmented left-hand side constraint matrix. Letb^denote the corresponding right-hand side vector augmented by n zero-elements. Define the index setQ={1,…,m+n}and let P ⊆ Q. LetA^Pandb^Pbe the matrix and the vector obtained by deleting the rows ofA^Pandb^P,respectively, that are not in P. Then, a face F(P) of X is given asF(P)={x∈X:A^Px=b^P}. A face F(P) of X is an efficient face if for all x ∈ F(P),x∈X. An efficient face F(P) of X is said to be a maximal efficient face if there does not exist another efficient face F(R) of X such that F(P) ⊂ F(R). LetQ={P1,…,P|Q|}be the collection of subsets of Q that represent all maximal efficient facesF(P1),…,F(P|Q|)of the MOLP. Then, the efficient set of the MOLP is assumed to be given asX=⋃s=1|Q|F(Ps). Hence, the decomposition subproblem DECOMP(Ps) considers the projection of a maximal efficient face F(Ps) in the robustness space:(DECOMP(Ps))Min(δ,γ)Ts.t.∑j=1n(aij−|aij|α)xj+|bi|δ≥bi∀i=1,…,m(f¯i−f̲i)γ−∑j=1n|cji|αxj≥0∀i=1,…,kx∈F(Ps)δ,γ≥0Because DECOMP(Ps) is an MOLP, the weighted sum method can be used to find the extreme points of DECOMP(Ps) in the robustness space. Let Nsdenote the total number of extreme points(δs1,γs1)T,...,(δsNs,γsNs)Tfrom DECOMP(Ps). Without loss of generality, we assume that the Nsextreme points are sorted in non-decreasing order of γ values within each subproblem. Similar to Sayin (2000), our procedure carries a search over the maximal efficient faces of X, which translates to a search in the robustness space over all subproblems DECOMP(Ps), fors=1,…,|Q|. However, because the RPSR is a bicriterion program, the subsequent application of a filter in the robustness space is made necessary to remove dominated solutions from each subproblem DECOMP(Ps). The algorithm is presented as follows.In order to see that the FDF is a valid algorithm for solving the RPSR, note that procedure examines all maximal efficient facesF(P1),…,F(P|Q|)of the MOLP and projects the solutions in the robustness space via subproblems DECOMP(Ps), fors=1,…,|Q|(cf. line 3). The algorithm then proceeds by connecting adjacent extreme points,vsi=(δsi,γsi)Tandvsi+1=(δsi+1,γsi+1)T,from the same subproblem DECOMP(Ps) to form line segmentsℓsi. Without loss of generality, we assume that ifNs=1,then subproblem DECOMP(Ps) will have a unique line segment that is a singleton. After all DECOMP(Ps),s=1,…,|Q|,have been examined, the application of a filter (cf. lines 6–10 of Algorithm 1) removes dominated portions of the efficient faces in the robustness space. While the extreme points of each subproblem can be obtained in line 3 via the weighted sum method, the subsequent filtering (i.e. line 10) can be done using the properties proposed by Vincent et al. (2013). After the application of the filtering steps, eachℓsimay consist of: (a) a connected line segment (closed, open or semi-open); (b) a collection of disconnected line segments (closed, open or semi-open), where the dominated solutions fromℓsiwere removed by the filtering steps; (c) a singleton; and (d) an empty set; hence,D′is formed by the union of the resultingℓsi,fori=1,…,Nsands=1,…,|Q|. Fig. 2illustrates the application of the filtering steps in these four cases. Case (a) shows the bold portion of line ℓ2 that contains non-dominated solutions with respect to solutions from line ℓ1; case (b) shows two disconnected semi-open portions of ℓ2 that contain non-dominated solutions; case (c) shows a non-dominated singleton from ℓ2; and case (d) shows that all solutions from line ℓ2 are dominated by the ones from ℓ1.Assuming that solving each subproblem in line 3 can be done in Δ steps in the worst case and that the number of extreme pointsNs=Nfor all subproblems DECOMP(Ps), fors=1,…,|Q|,then lines 2–5 of Algorithm 1 can be solved inO(|Q|(Δ+N)). In line 10, checking if two line segments intersect and finding whether one contains solutions that dominate the other requires constant time. Let (ℓwq,ℓsr) denote the verification of whetherℓwqcontains solutions dominated by the ones inℓsr,as per line 10 of Algorithm 1. Let us consider the example shown in Fig. 3 and restrict our attention toℓ11. When comparing (ℓ11,ℓ31), we find the two bold segments corresponding to the solutions inℓ11that are not dominated by solutions fromℓ31. Hence,ℓ11becomes the collection of the two bold segments denoted byℓ11.1andℓ11.2. Similarly, becauseℓ21also contains solutions dominated by the ones inℓ31,lineℓ21becomes the collection ofℓ21.1andℓ21.2. Therefore, (ℓ11,ℓ21) implies performing(ℓ11.1,ℓ21.1),(ℓ11.2,ℓ21.1),(ℓ11.2,ℓ21.2)and(ℓ11.1,ℓ21.2),resulting in a total of 5 comparisons associated with the filtering ofℓ11. Hence, if all the|Q|(N−1)initial line segments are parallel in such a way that each will split another line segment in half as illustrated in Fig. 3, the number of steps required for filtering will be bounded by|Q|(N−1)∑i=1|Q|(N−1)−122(i−1). Therefore, the total complexity of the FDF algorithm isO(|Q|(N2|Q|N+Δ)). Of notice is also the fact that in the worst case there might be exponentially many maximal efficient faces, and for each of these faces there might be exponentially many extreme points, so that the computational complexity of Δ may grow exponentially. This illustrates the challenges associated with solving such a non-convex problem. However, empirical analyses have shown that the number of efficient faces in an MOLP, in general, does not increase exponentially with problem size (Sayin, 1996) and solving each subproblem (line 3) is typically easier than solving the first stage MOLP since the feasible set is restricted to only one face of X.OnceD′is determined, values of decision variables can be found by solving again each subproblem DECOMP(Ps), fors=1,…,|Q|,with the additional restriction that δ and γ be equal to the values of each corresponding extreme point.To illustrate the algorithm, consider the following MOLP:(N3M6O2)Min(3x1+x2,−x1+3x2+10x3)Ts.t.x1+x2−2x3≥8−x1+x2≥−9−2x1−3x2+x3≥−362x1−x2≥123x1+2x2+x3≥30x1+11x2≥32x1,x2,x3≥0The three efficient faces of N3M6O2 are as follows:F(P1)=X∩{x∈R3:3x1+2x2+x3=30,x3=0},F(P2)=X∩{x∈R3:2x1−x2=12,3x1+2x2+x3=30}andF(P3)=X∩{x∈R3:x1+11x2=32,x3=0}. Assumingα=0.1,each subproblem DECOMP(Ps) fors=1,…,3,becomes:(DECOMP(Ps))Min(δ,γ)Ts.t.0.9x1+0.9x2−2.2x3+8δ≥8−1.1x1+0.9x2+9δ≥−9−2.2x1−3.3x2+0.9x3+36δ≥−361.8x1−1.1x2+12δ≥122.7x1+1.8x2+0.9x3+30δ≥300.9x1+9.9x2+32δ≥32−0.3x1−0.1x2+9.02γ≥0−0.1x1−0.3x2−x3+19.75γ≥0x∈F(Ps)δ,γ≥0Using the weighted sum approach to solve each subproblem yields the extreme points in the robustness space shown in Table 1(before filtering).The extreme points within each subproblem are connected to form the two line segments and the singleton shown in Fig. 4.Figs. 4 and 5show the projection of solutions from the 3 subproblems in the robustness and objective spaces, respectively. The bold segments represent the setD′. While all solutions from the first subproblem are robust efficient, the line segment from the second subproblem contains solutions that are dominated in the robustness space by solutions from the first subproblem. The singleton generated from the third subproblem is dominated by solutions generated from the second subproblem.The examples in this section are aimed to illustrate the proposed methodology in the linear case previously discussed. In addition, the first example compares the solution sets obtained via different PSR methods. The second example shows how the methodology compares to a classical robust optimization approach, i.e. the RMOLP. Moreover, it demonstrates that applying an approach often utilized to select a most preferred alternative based on knee solutions (e.g. Das, 1999a; Branke et al., 2004) may lead to the selection of a non-robust solution. While the first two examples assume a box uncertainty set, the third one focuses on the cardinality-constrained uncertainty set and illustrates how solutions vary with different values of Γ. For simplicity, we useα=0.10in all instances.Example 1The first instance is an MOLP withn=3decision variables,m=6constraints andk=3objective functions. The formulation is as follows:(N3M6O3)Min(3x1+x2,−x1+3x2+10x3,−x3)Ts.t.x1+x2−2x3≥8−x1+x2≥−9−2x1−3x2+x3≥−362x1−x2≥123x1+2x2+5x3≥35x1+11x2≥32x1,x2,x3≥0The efficient setXof N3M6O3 is formed by all solutions lying onX∩({x∈R3:x1+x2−2x3=8}∪{x∈R3:x1+11x2=32}). The red points in Fig. 6 show 1407 efficient solutions obtained via the ϵ-constraint method. Here the discrete representation ofXis used to allow for comparison with existing PSR methods. The RPSR formulation of N3M6O3 is shown next.Min(δ,γ)Ts.t.0.9x1+0.9x2−2.2x3+8δ≥8−1.1x1+0.9x2+9δ≥−9−2.2x1−3.3x2+0.9x3+36δ≥−361.8x1−1.1x2+12δ≥122.7x1+1.8x2+4.5x3+35δ≥350.9x1+9.9x2+32δ≥32−0.3x1−0.1x2+19.91γ≥0−0.1x1−0.3x2−1x3+56.67γ≥0−0.1x3+5.13γ≥0x∈Xδ,γ≥0The robust efficient set was obtained by computing δ(x) and γ(x) for each solution x found by the ϵ-constraint method and filtering out the ones that were dominated in the robustness space. The PSR methods considered in this instance were the forward filtering clustering (FC) (Steuer & Harris, 1980) and the greedy reduction for percentile maximization (GRP) (Venkat et al., 2004). In addition, the SEABOE (Das, 1999b) method was applied, but no solutions of order of efficiencyk=2were found for the problem (i.e. no solutions inXwould remain efficient if one of the objective functions was dropped from the MOLP).The FC algorithm was implemented using Minkowski’s distance metric and the objectives were normalized to a [0,1] scale with indifference distance value set tod=α. The GRP algorithm was implemented using equal weights in the percentile function. In order to have a more comprehensive analysis, different runs of the GRP algorithm were performed with subset sizes from N′ = 1 to 15 solutions. The run with N′ = 15 results in a superset of solutions from the other runs. Figs. 6–8 show the solutions obtained in the decision, robustness and objective spaces, respectively.The plot in Fig. 6 illustrates that the PSR methods can lead to distinct regions of the decision space, capturing different aspects of the goodness of the solutions. All solutions of the GRP algorithm were mapped to the same point in the robustness space, having both a high outcome degradation and infeasibility levels. The FC algorithm generated the entire representation of the Pareto set in a reduced number of outcomes. Of notice is that the clustering technique is particularly useful to understand the shape of the Pareto set while also achieving the desired size reduction. This suggests that clustering solutions may be used as input for the RPSR in larger instances.Alike other PSR methods, the RPSR was effective in reducing the size of the Pareto set. However, the proposed methodology focuses only on the regions of the efficient set that maintain efficiency of solutions in the robustness space (cf. Fig. 7). In this example, the size of the robust Pareto set was reduced to 12 outcomes, a 99.1 percent reduction compared to the discrete sample of the Pareto set of the MOLP.Instance N2M6O2 is a bicriterion program withn=2decision variables andm=6constraints. The formulation is presented next.(N2M6O2)Min(3x1+x2,−x1+3x2)Ts.t.x1+x2≥12−x1+x2≥−9−2x1−3x2≥−362x1−x2≥123x1+2x2≥33x1+11x2≥32x1,x2≥0The efficient set of N2M6O2 was obtained via the algorithm from Sayin (1996) and is formed by the union of three maximal efficient faces, given asX=X∩({x∈R2:3x1+2x2=33}∪{x∈R2:x1+x2=12}∪{x∈R2:x1+11x2=32})(cf. red dotted lines in Fig. 11). The RPSR becomes:Min(δ,γ)Ts.t.0.9x1+0.9x2+12δ≥12−1.1x1+0.9x2+9δ≥−9−2.2x1−3.3x2+36δ≥−361.8x1−1.1x2+12δ≥122.7x1+1.8x2+33δ≥33−1.1x2+32δ≥32−0.3x1−0.1x2+5.95γ≥0−0.1x1−0.3x2+9.88γ≥0x∈Xδ,γ≥0The solution of the RPSR formulation from instance N2M6O2 was obtained via Algorithm 1. To illustrate how the RPSR differs from a classical robust optimization approach, robustness was incorporated directly in the MOLP by solving the RMOLP:(N2M6O2-RMOLP)Min(3.3x1+1.1x2,−0.9x1+3.3x2)Ts.t.0.9x1+0.9x2≥12−1.1x1+0.9x2≥−9−2.2x1−3.3x2≥−361.8x1−1.1x2≥122.7x1+1.8x2≥330.9x1+9.9x2≥32x1,x2≥0Results are depicted in Figs. 9–11.The shaded areas in Figs. 10 and 11 denote the outcome set Y and the feasible set X, respectively. The red dotted lines in Figs. 9–11 denoteD,YandX,while the blue lines are the subsetsD′,Y′andX′,respectively.As shown in Fig. 10, the efficient solutions obtained from N2M6O2-RMOLP are dominated by the efficient solutions of N2M6O2 in the objective space. Although the conditions from Theorem 4.8 part (b) are not met (i.e.cji≥0), Fig. 9 shows that the robust efficient solutions obtained by the RPSR are non-dominated in the robustness space with respect to the solutions obtained from the RMOLP. While the solutions from the RMOLP remain always feasible, their outcome degradation levels are higher than the ones from solutions inX′. In fact, the robust efficient solutions obtained by the RPSR are non-dominated in the robustness space with respect to any feasible solution in problem N2M6O2 (cf. Fig. 9). Although this case is also observed in Example 1, it does not always hold true and is problem dependent. In addition, during our experimentation, we have found cases where the solutions from the RPSR dominate solutions from the RMOLP, and vice-versa.An approach often utilized to select an alternative from the Pareto set is based on knee solutions, which are the solutions with maximum convex bulge on the Pareto curve (Branke et al., 2004; Das, 1999a). In Fig. 10, the knees would be solutions with objective values in the region off=(30,0)Tand(32,−4)T. In this instance, selecting a knee would yield a non-robust solution. Although the knee solutions in Fig. 10 show a low infeasibility level (δ(x)=0.1for all knee solutions), they are all dominated in the robustness space by solutions inX′,which maintain lower outcome degradation levels. This illustrates that an approach often utilized to select an alternative from the Pareto set may lead to a solution that is highly affected by uncertainty.The RPSR was able to reduce the number of maximal efficient faces that remained robust efficient. In addition, only 11.6 percent of the length covered by the line segments forming the Pareto set of N2M6O2 remained Pareto optimal in view of the RPSR.Instance N10M5O2 is a problem withn=10decision variables,m=5constraints andk=2objective functions. The formulation is presented next:(N10M5O2)Min(10x1+5x2+3x3+2x4+2x5+x6+x7+x8+x9+x10,−x1−x2−x3−x4+4x5+5x6+6x7+7x8+8x9+9x10)Ts.t.x1−2x2+x3+x4+x5+x6+x7+x8+x9+x10≥5−2x1−2x2−3x3−5x4−10x5+20x6+3x7+2x8+5x9+x10≥3−x1−x6+2x10≥16x1+x2−2x8≥72x2+4x7+x8≥−1xi≥0i=1,…,10The RPSR was formulated using the cardinality-constrained uncertainty set with Γ varying from 1 to 10. Fig. 12 showsD′for the various values of Γ.From Fig. 12, the values of δ(x) and γ(x) increase with Γ. When the most optimistic case of robustness is assumed, i.e.Γ=1,the infeasibility and outcome degradation levels are lower because only one decision variable is assumed to be affected by uncertainty at one time. As the decision maker increases his/her level of conservatism, i.e. by increasing Γ, the infeasibility and outcome degradation levels also increase since more decision variables are assumed to be simultaneously affected by uncertainty. As shown in Fig. 12, the most conservative case, i.e.Γ=10,yields the same results as the case withΓ=5. This is because when the efficient solutions have decision variables at zero and the perturbations are multiplicative, such as in this example, using a value of Γ < n may yield the same result as the case withΓ=n.If the perturbations on each xjare a composite random variableβ˜j∘ν˜jwhereν˜jare i.i.d. Bernoulli trials with probability p, then Theorem 4.7 may be used to guide the selection of the appropriate Γ according to the decision maker’s level of conservatism. For instance, ifp=0.1,then the selection ofΓ=4would guarantee that the probability of constraint violations or outcome degradation levels exceeding the calculated values from the C-RPSR formulation would be less than 0.04; similarly, using a less conservative value ofΓ=3would guarantee a probability bound from Theorem 4.7 of 0.165.The large number of Pareto outcomes from an MOP makes it difficult for a decision maker to select a particular solution for implementation; this issue hinders the applicability of multiobjective optimization in practice. To the best of our knowledge, the majority of PSR methods rely on clustering solutions according to their similarity in the objective space of the MOP. This paper poses the PSR as an optimization problem over the efficient set based on the idea of incorporating multiple secondary criteria related to both the objective and the decision spaces of the MOP in order to break ties among the Pareto outcomes. The use of secondary criteria provides the decision maker with additional trade-off information in the space of the secondary criteria. This new formulation allows dealing with continuous Pareto sets circumventing the need for discretization procedures that characterize existing PSR methodologies.Although the methodology can be used with any secondary criteria of interest, in this paper we use model and solution robustness such that solutions in the reduced set are less sensitive to uncertainties, in addition to being efficient with respect to the original MOP. Hence, the proposed model integrates aspects from the areas of multiobjective optimization and robustness to aid decision making.As an area for future research, of interest are the development of specialized algorithms to solve the RPSR since the efficient set is nonconvex, and the study of extensions in the realm of integer, binary and mixed-integer programming.

@&#CONCLUSIONS@&#
