@&#MAIN-TITLE@&#
Scalable gastroscopic video summarization via similar-inhibition dictionary selection

@&#HIGHLIGHTS@&#
We design a dictionary selection model via the similar-inhibition constraint.We propose a scalable gastroscopic video summarization algorithm.We build the first gastroscopic video summarization dataset with 30 videos.

@&#KEYPHRASES@&#
Video summarization,Key frame,Similar-inhibition dictionary selection,Image attention prior,Gastroscopic video,

@&#ABSTRACT@&#
ObjectiveThis paper aims at developing an automated gastroscopic video summarization algorithm to assist clinicians to more effectively go through the abnormal contents of the video.Methods and materialsTo select the most representative frames from the original video sequence, we formulate the problem of gastroscopic video summarization as a dictionary selection issue. Different from the traditional dictionary selection methods, which take into account only the number and reconstruction ability of selected key frames, our model introduces the similar-inhibition constraint to reinforce the diversity of selected key frames. We calculate the attention cost by merging both gaze and content change into a prior cue to help select the frames with more high-level semantic information. Moreover, we adopt an image quality evaluation process to eliminate the interference of the poor quality images and a segmentation process to reduce the computational complexity.ResultsFor experiments, we build a new gastroscopic video dataset captured from 30 volunteers with more than 400k images and compare our method with the state-of-the-arts using the content consistency, index consistency and content-index consistency with the ground truth. Compared with all competitors, our method obtains the best results in 23 of 30 videos evaluated based on content consistency, 24 of 30 videos evaluated based on index consistency and all videos evaluated based on content-index consistency.ConclusionsFor gastroscopic video summarization, we propose an automated annotation method via similar-inhibition dictionary selection. Our model can achieve better performance compared with other state-of-the-art models and supplies more suitable key frames for diagnosis. The developed algorithm can be automatically adapted to various real applications, such as the training of young clinicians, computer-aided diagnosis or medical report generation.

@&#INTRODUCTION@&#
More and more people are suffering from stomach diseases, and the trend is rising [1]. As an effective technique to show the interior of a stomach directly, gastroscopy has been widely used for clinical examination, especially for the early detection of gastric cancer. Usually, the entire procedure lasts approximately 20 min, and a video containing approximately 15,000 frames is captured. However, the visual inspection of such a large number of frames is a challenging task, even for the most experienced clinicians. To more easily browse through such a video archive, a clinician records approximately 20–50 images manually during the examination for diagnosis and later generates a medical report. Nonetheless, the manual annotation may have the following shortcomings:•Because of the need to perform multiple tasks simultaneously, clinicians may miss some important information for the final diagnosis.Due to the lack of enough experience, some junior clinicians cannot guarantee accuracy when analyzing the massive data continuously. Especially when the operation is not timely, clinicians may select poor quality images.After the completion of the manual operation, the number of selected frames is fixed, which cannot meet the needs of different scenarios and may increase the time cost for re-analysis.In fact, the above process is a typical video summarization procedure, i.e., selecting some frames with the most important and meaningful semantic content from a full-length video sequence [2–5]. Therefore, in this paper, we intend to design a computer-aided gastroscopic video summarization algorithm to overcome these problems and assist clinicians to more effectively go through the abnormal contents of the video. The computer-aided system based on our algorithm can be adopted in real applications, such as the training of young clinicians, computer-aided diagnosis or medical report generation.For video summarization [6–10], most state-of-the-art methods mainly focus on the summarization of structured videos, such as sports, cartoons or surveillance videos. In comparison, the automatic summarization of unstructured data, e.g., gastroscopic videos, is much more challenging. First, gastroscopic videos contain deformable and low-texture context, which makes it more difficult to extract semantic information. Second, due to the complexity of the inner human cavity and arbitrary movement of the camera, some gastroscopic images are of poor quality, which makes an accurate video summarization difficult. Finally, the objective of gastroscopic video summarization is for diagnosis, so the result of video summarization should highlight the suspected regions. Some previous models, e.g., the group sparsity dictionary selection model [2] in our previous work, cannot handle the above challenges very well. For gastroscopic videos, the result cannot encompass all video content, and some similar frames are also frequently selected as key frames. Therefore, we design a new similar-inhibition dictionary selection model by adopting the similar-inhibition constraint to select elements with more diversity between each other. Based on the similar-inhibition constraint, the video structure information will be taken into account to cover as much video content as possible in comparison with traditional sparse dictionary selection models. Furthermore, we also integrate an attention prior into the group sparsity term to reduce the gap between low-level features and high-level concepts. The main contributions of this paper reside in three aspects:•We design a new dictionary selection model by adopting the similar-inhibition constraint, which reinforces the diversity of the selected subset.By taking into account the attention prior, we propose a scalable gastroscopic video summarization algorithm via similar-inhibition dictionary selection, which can select key frames with the most semantic information efficiently.We collect and build a new gastroscopic video summarization dataset from 30 volunteers with approximately 432,000 frames, and we annotate the ground truth for evaluation as well. To the best of our knowledge, this dataset is the first gastroscopic video summarization dataset.The rest of this paper is arranged as follows. Section 2 discusses the related works. In Section 3, we present the formulation of the problem. Section 4 describes the implementation of our video summarization. Section 5 presents various experiments and comparisons. Finally, Section 6 concludes the paper.

@&#CONCLUSIONS@&#
To better navigate gastroscopic video content for diagnosis and future research, a new scheme of gastroscopic video summarization has been proposed in this paper. By representing each video frame as a feature vector, we convert the gastroscopic video summarization problem into a sparse dictionary selection problem under three terms, namely, reconstruction error, group sparsity and similar-inhibition. Moreover, we compute an attention score by merging two cues, i.e., gaze and content change, and add it into the model as a prior cue. Our method not only provides a scalable solution to video summarization, which allows us to select any given number of key frames, but can also reinforce the diversity of the selected key frames. The preliminary results obtained on our new gastroscopic video dataset validate that our method outperforms the state-of-the-art video summarization models.