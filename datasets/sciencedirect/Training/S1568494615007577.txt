@&#MAIN-TITLE@&#
Image-based handwritten signature verification using hybrid methods of discrete Radon transform, principal component analysis and probabilistic neural network

@&#HIGHLIGHTS@&#
Dynamic variable is introduced to static signature images with DRT reconstruction.Feature data length is reduced through linear compression (PCA).PNN is feasible to filter the skilled forgery from the genuine signature.Time complexity is decreased notably with one-training-sample scheme.

@&#KEYPHRASES@&#
Offline signature verification,Discrete Radon transform,Principal component analysis,Probabilistic neural network,

@&#ABSTRACT@&#
Image-based handwritten signature verification is important in most of the financial transactions when a hard copy of signature is needed. Considering the lack of dynamic information from static signature images, we proposed a working framework through hybrid methods of discrete Radon transform (DRT), principal component analysis (PCA) and probabilistic neural network (PNN). The proposed framework aims to distinguish forgeries from genuine signatures based on the image level. Extensive experiments are conducted on our own independent signature database, and a public signature database – MYCT. Equal error rates (EER) of 1.51%, 3.23% and 13.07% are reported, respectively, for random, casual and skilled forgeries of our own database. When working on the MYCT signature database, our proposed approach manages to achieve an EER of 9.87% with 10 training samples.

@&#INTRODUCTION@&#
A signature is a handwritten depiction of someone's name, nickname or even a simple “X” that a person writes on documents as a proof of identity and intent. The traditional function of a signature is to provide authentication for a document, especially in the prevalence of financial transactions, such as credit card and bank checks. The principal application of a handwritten signature verification system is to verify computationally a person's identity based on the way in which he or she signs his or her name. There are 2 types of system: online verification and offline verification. Online verification uses dynamic features, such as the motion of the stylus, locations, possibly velocity, acceleration and pen pressure, as functions of time (i.e. time series), where in most cases, these can be done using a dynamic tablet; while offline handwritten signature verification uses static features, e.g. 2-D scanned images of handwritten signatures. Although online verification is of great interest for “point-of-sale” application, our work will concentrate primarily on offline verification, which is of interest for those applications where a hard copy of the signature is needed. Compared to online systems, offline systems offer greater potential for widespread application due to the simplified recording process. The implementation cost is also much lower since the entire operation can be performed in a centralized location, rather than at multiple places.Offline signature verification is an old pattern classification process to distinguish the genuine signature from the forgery. There are 3 popular groups of forgery: casual forgery, random forgery and skilled forgery. Skilled forgery (Fig. 1b) is a professional imitation of the genuine signature. Professional forgers are provided with a sample of the genuine signature, and they are allowed to practise forging it. A casual forgery (Fig. 1c) is a non-professional forgery where the forgers have not been provided with a sample of the actual signature to practise. Therefore, stylistic differences are prevalent in this case. A random forgery (Fig. 1d) is a signature sample that is randomly extracted from a different group of writers, or any random scribble. Among these 3 categories, skilled forgery detection emerged as the most challenging task even for expert document examiners, especially without the aid of dynamic tablets. Thus, our main concern in this work is to distinguish a genuine signature from a skilfully forged signature using a statistic image instead of relying on the information derived from dynamic tablets. More precisely, we have to distinguish the intra-variations among the genuine signatures and the true differences between a signature and a forgery. In most cases, there is a subtle difference between a genuine signature and a skilfully forged one.Much research has been devoted to the field of offline handwritten signature verification over the past 2 decades. Numerous methods and approaches have been summarized in a number of survey articles [1–7]. From the survey, we found that most earlier works on image-based/offline signature verification deal primarily with casual and random forgeries, where deceit is generally obvious. As signature databases became larger, researchers are moving towards the more difficult skilled forgery detection task, which is still an open research question. There are plenty of pattern recognition techniques being used in this field; some of those prominent techniques are related to our work, especially in the case study of skilled forgery, will be selectively reviewed in this section.Mighell et al. [8] proposed a back propagation learning algorithm to detect random forgeries. By training 10 genuine signatures and 10 forgeries, respectively, which latter group was tested on 70 genuine signatures and 56 forgeries, they reported a false rejection rate (FRR) of 1% with a false acceptance rate (FAR) of 4%.Qi and Hunt [9] proposed a multi-resolution approach to address the offline signature verification problem. A multi-resolution representation of signatures was obtained using the wavelet transformation. By using a database of 450 signatures from 25 signatories, the classification was, respectively, tested through a vector quantization (VQ) classifier and an artificial neural network classifier. The best VQ classification function is the accumulative, multi-resolution system, which reported an FRR of 6.7%, and a FAR of 13.3% for skilled forgery. One drawback of VQ could be its incapability of handling complicated and nonlinear data. On the other hand, the multi-resolution network yields the lowest verification error rate when independent features were used, FRR of 4.0%, and FAR of 9.3% (skilled forgery) were reported from their own independent database.Kaewkongka et al. [10] proposed using the Hough transform (i.e. a general Radon transform) as the feature extractor. It extracts the parameterized Hough space from a signature skeleton as a unique characteristic feature of a signature. Evaluation was performed through a backpropagation neural network. By using the dataset of 70 signatures, a recognition rate of 95.24% was reported.Deng et al. [11] developed a closed contour tracing algorithm to represent the edges of each signature with several closed contours, the data collected were decomposed into multiresolutional signals using wavelet transforms. When only skilled forgeries were considered, an average error rate (AER) of 13.4% was reported using their English signatures database; while an AER of 9.8% was reported when using their Chinese signatures. However, the wavelet technique is not well adapted to the detection of highly anisotropic elements, such as the alignments in a signature image.Quek et al. [12] proposed a system based on novel fuzzy neural network modelling, called the POPFNN-TVR. POPFNN-TVR, consisting of a 5-layer structure. It had high learning ability, high generalization ability, and high computational ability, which made it a very powerful model to detect the skilled forgeries. During the preprocessing step, 4 kinds of features were extracted from the static image of the signature, which included the reference pattern based features, global baseline, pressure features and slant features and to be used as the training vector. Two experiments were conducted; the first experiment used the genuine signatures and forgeries as training data, while the second used only the genuine signatures as training data. Based on the signatures of 15 different signatories from 3 ethnic groups, the average of the individual EER, 22.4% was obtained for the first experiment. For the second experiment, they claimed that comparable results were obtained.Fierrez-Aguilar et al. [13] proposed an amalgamated technique to fuse reliable local and global information from the signature images through a sum rule calculation. Empirical tests were conducted on local-based approach with hidden Markov models (HMM), global-based approach with Mahalanobis distance metrics, and the proposed amalgamated technique. Tested on a subgroup of the large MCYT signature database, their proposed amalgamated technique greatly outperformed the local analysis and global analysis, reporting an EER of 11.00% and 9.28% for 5 training samples and 10 training samples, respectively, in the case of skilled forgery.Disregarding the local features of signature image, Güler and Meghdadi [14] devised an automatic handwritten signature verification (AHCV) system by considering only the global features of signature images; the thickness and size of signatures were also ignored in their application. Working on a subset of the large MCYT signature database, an EER of 25.1% was achieved for skilled forgery using the classifier method of dynamic time warping (DTW).Alonso-Fernandez et al. [15] investigated 2 ranking schemes to automatically predict the performance of offline signature verification. The first approach ranked the slant of the different directions-intersected area based on the average measurement of the enrolment signatures, while the second approach ranked the intra-variability of a set of signatures based on the enrolled set. Computed on a Mahalanobis distance metric, the best EER of 22.4% (using 5 training samples) and 20% (using 10 training samples) were reported on a subset of the large MCYT signature database.Wen et al. [16] exploited 2 computing models to address the non-linear rotation invariant problem for skilled signatures, which usually occurred after the step of image preprocessing. The first model used the discrete fast Fourier transform (DFFT) to extract the ring-peripheral features from signature images, and tested on a Mahalanobis-distance model. An EER of 15.3% was reported on skilled forgeries of the MCYT signature database. The second model used ring-HMM to model the signature images, and EER of 15.02% was reported on skilled forgeries of the MCYT signature database.Gilperez et al. [17] presented a local analysis of offline signature verification by extracting various contour features from signature images. The writer-individuality was transformed based on probability density functions, and available in two forms: (i) features based on direction work; and (ii) features based on lengths. Tested on the MCYT signature database using 10 training samples, an EER of 6.44% was reported on skilled forgeries when the contour features were extracted based on direction work.Sigari et al. [18] proposed a Gabor wavelet transform technique for offline signature identification and verification system. They performed noise reduction and signature image normalization by size and rotation after pre-processing by placing a virtual grid on the signature image. Gabor wavelet coefficients with different directions and frequencies were computed on each grid point, and fed into a classifier. The experiment was tested on 4 signature datasets with different nationalities. The experiments produced an EER of 17.125%.Yilmaz et al. [19] proposed an offline signature verification system based on the signature's local histogram features, e.g. histogram of oriented gradients (HOG) and histogram of local binary patterns (LBP). The classification was performed based on support vector machines (SVMs). Two approaches were investigated: global and user-dependent SVMs. The experiment was tested on the GPDS 160 signature database and an EER of 15.41% was reported in the skilled forgery test.Vargas et al. [20] used statistical texture features to extract the grey level variations from the handwritten signature images. The approach was carried out at the global image level. Least squares support vector machines (LS-SVM) was employed as a classifier to test 2 publicly available databases: (i) MCYT-75 and (ii) GPDS-100 Corpuses. An EER of 12.82% was reported for MYCT-75 skilled forgeries.Aiming to solve the signature image template storage issue for e-commerce and m-commerce application, Radhika et al. [21] used the minimum variance quadtree components (MVQCs) to extract the useful yet small-sized subpatterns from the signature images. The subpatterns were transformed into a set of features by using the Hu moment. The proposed model was tested on 2 classification learners: the radial basis function (RBF) and feed-forward neural networks. Empirical tests showed that the RBF delivered a better result, with a FRR of 7% and FAR of 10% on MCYT database.Kumar et al. [22] believed that the shape of a signature can be interpreted as a spatial distribution of black pixels around a candidate pixel, and these sets of features (both shape and texture properties) can serve as unique identifiers. The proposed feature extraction model was tested using the classifiers of multilayer perceptron and SVMs on two public databases: GPDS300 corpus (reported with 13.76% for both FAR and FRR) and CEDAR (reported with 8.33% for both FAR and FRR). Promising empirical results substantiated that the proposed model is sufficiently robust to handle data collected from different groups.Recently, Guerbai et al. [23] proposed a scheme to consider only genuine signatures. The classifier used in this context is one-class support vector machines (OC-SVM), and was tested based on writer-independent schemes with 2 public available databases: (i) CEDAR and (ii) GPDS. AERs of 8.70%, 7.83% and 5.60% were reported, respectively, by using 4, 8 and 12 genuine signatures.One of the encouraging feature extraction techniques used in offline signature verification would be the one developed by Coetzer et al. [24]. The offline handwritten signatures authentication system was deployed with the discrete Radon transform (DRT) and a HMM. When the signatures are originally captured offline, their system achieves an EER of 18% (considering only the skilled forgery). The discrete Radon transform appears as a stable and robust method of feature extraction. However, the accuracy of HMM is limited, due to some presumptions. First, it is assumed that feature vectors are independent and as a result, the probability of vector sequence can be calculated as the multiplication of each vector. Second, it is assumed that stationary segments are connected through Markov model, which implicitly imposes a geometric distribution on each state's duration that is not empirically true.DRT is a discrete version of Radon transform. With its ability to compute various generalizations of the Radon transform, it has been manifested as a useful tool to process multidimensional digital signal [25,26]. Not just limited to signal processing, Coetzer et al. [24] demonstrated that the DRT is also able to reconstruct a signature image through multiple angles’ projection. With the reconstruction, a dynamic variable (which is the value of projection's angle) is introduced to each of the static signature images, yielding a more reliable set of features. Therefore, it is reasonable for us to utilize it as the main feature extractor in this work.Due to the vast DRT-reconstructed features size, compression is needed as a practical solution when considering data storage capacity and data processing speed. PCA has been widely used for dimensionality reduction in computer vision. The successful implementation of PCA in various dimensionality reduction tasks in different fields of interest [27–32] popularizing the idea of matching images in compressed subspaces. Hence, to preserve the reliable information reconstructed with DRT and avoid the curse of dimensionality, PCA has been adopted as the primary compression method in this work.Instead of using HMM [24], we employ the probabilistic neural network (PNN) as the primary modelling agent in this work. PNN was first introduced by Specht [33,34] and has been widely used in classification tasks in different disciplines [35–40]. As a kernel-based approach to probability density function approximation, PNN possess the advantages to handle complex, non-linear and imprecise problems that traditionally occur in signature verification. The greatest advantage of PNN over the backpropagation network is its training speed, which is greater than ordinary neural network-based classifiers, making it more practical in real-world verification tasks.Our main contributions from this paper are: (1) a modelling formulation to reconstruct static 2-D signature images into the dynamic subspaces with DRT; (2) a straightforward approach to compress the DRT-reconstructed features with PCA; (3) a hybrid framework to integrate the DRT, PCA and PNN; and (4) extensive empirical tests on own database and the MYCT – public database to corroborate the proposed method.Generally, an offline handwritten signature verification system can be divided into several steps, including preprocessing, feature extraction and encoding, as well as matching, as depicted in Fig. 2. Each of the processes will be further discussed in the following sections.Any scanning devices can be used as an image acquisition device. However, the scanning hardware and the speckled paper background on which the signature is signed may introduce certain “noises” to the signature image. These “noises” need to be removed so that they will not affect the feature extraction process. In this work, we deploy a median filter to smooth the image, even though we do not compute the real noise distribution. The use of median filtering is similar to an averaging filter like a mean filter. Each output pixel is set to an average of the pixel values in the neighbourhood of the corresponding input pixel. We opt for the median filtering instead of mean filtering due to its more robust average than the mean. More precisely, a single unrepresentative pixel in a neighbourhood will not unduly affect the median value. Due to the fact that median value must be the exact value of one of the pixels in the neighbourhood, it does not create new unrealistic pixel values when the filter straddles an edge. Thus, the median filter is much better at preserving sharp edges than the mean filter. Fig. 3depicts the image after median filtering.In this work, we do not consider the colour of the image. Thus, the image is binarised with a simple thresholding scheme. A binary image can be considered as a special kind of intensity image, containing only black and white, which uses far less memory. The rationale of doing this is to minimize database storage. It is normally not greater than 1bit/pixel, and this value can be reduced as such images are very amenable to compression. It also encourages simpler algorithms than those applied to grey-level images.DRT represents a projection (shadow) of the signature at different angles. It transforms the two-dimensional images with lines into a domain of possible line parameters. Each line in the image will give a peak positioned at the corresponding line parameters. A set of transform values is produced after the transformation. The DRT of an image is calculated as follows. Assume that each signature image consists of N pixels in total, and that the intensity of the ith pixel is denoted by Ii, i=1, …, N. The DRT is calculated using β non-overlapping beams per angle and Θ angles in total. The cumulative intensity of the pixels that lie within the jth beam is denoted by Rj, j=1, …, βΘ. This is called the jth beam sum. In its discrete form, the Radon transform is expressed asRj=∑i=1NwijIi,j=1,2,…,βΘ,where wijindicates the contribution of the ith pixel to the jth beam sum (see Fig. 4). The value of wijis determined by two-dimensional interpolation. Each projection therefore contains the beam sums that are calculated at a given angle.Along the equations, we can see that the number of angles (Θ), the number of beams per angle (β), and the interpolation method used to calculate wijwill determine the accuracy of the DRT. Our system works on DRT at Θ angles, which are equally distributed between 0° and 180° as depicted in Fig. 5.The dimension of each projection is subsequently altered from β to d, where β>d. This is done by first decimating all the zero-valued components from each projection. In this way, a feature vector with the required dimension is obtained. Furthermore, the decimation of zero-valued components ensures that moderate levels of noise (which are represented by a few additional small-valued components within certain projections) are “attached” to the other non-zero components. These decimated vectors are then shrunk or expanded to a length of d through interpolation. This process is to ensure that scale invariance is in the direction perpendicular to the direction in which the image is scanned, that is, perpendicular to the beams, and in the direction parallel to the beams. Some of the signatures and their respective DRTs are shown in Fig. 6. We can observe that the DRT exhibits a similar pattern for intra-class signatures (i.e. signatures among the same signatory) and a different pattern for inter-class signatures (i.e. signatures among different signatory).Since the number of transformed values after DRT is too huge, PCA is utilized here for feature data compression. PCA is a reliable dimensionality reduction method, where it finds a set of orthogonal basis vectors that describe the major variations among the training images and with the minimum reconstruction means square error.Using PCA, the average of K DRT features with M dimension is defined as Ravg. Each DRT feature, Rjdiffers from Ravgby the vector φj=Rj−Ravg. A covariance matrixC=∑j=1KφjφjTis constructed. Then, eigenvectors, vk and eigenvalues, λkwith the symmetric matrix C are calculated. vk determines the linear combination of K difference images with φ to form the EigenSignature,Ul=∑k=1Kvlkφk,l=1,...,K.Then, P(<K) EigenSignatures are chosen to correspond to the P highest eigenvalues, which implies that P features are selected. An input DRT feature, Rkis transformed and projected into the EigenSignature space by the operation, ρk=Uk(Rk−Ravg), where k=1, …, P.Instead of using the similarity matching concept as in traditional verification systems, we construct the decision boundaries directly by optimizing an error criterion with the aid of PNN. In general, a PNN consists of 3 layers: a pattern, summation and output layers (apart from the input layer), as illustrated in Fig. 7. The pattern layer contains one neuron for each input vector in the training set, while the summation layer contains one neuron for each user class to be recognized. The output layer merely holds the maximum value of the summation neurons to yield the final outcome (i.e. the probability score).The network is established by setting the weights of the network using the training set. The modifiable weights of the first layer are set by ωij=ρijwhere ωijdenotes the weight between ith neuron of the input layer and jth neuron in the pattern layer, and ρijis the j element feature of ρiin the training set. The second layer weights are set by ωjk=Tjk, where ωjkis the weight between neuron j in pattern layer and neuron k of the output layer, and 1 is assigned to Tjkif pattern j of the training set belongs to user k and 0 otherwise. It is then ready for classification task after the network is trained. The outcome of the pattern layer is defined asoutj=exp−∑i=1m(ρiωij)/σ. Note that outjis the output of neuron j in pattern layer and σ is the smoothing parameter of the Gaussian kernel, which is the only independent parameter that can be decided by the user. The input of the summation layer is calculated by the following equation:ink=∑j=1noutj×ωjkwhere inkis the input of neuron k in output layer. The outputs of the summation layer are binary neurons that produce the classification decision, i.e. 1 is assigned to outkif inkis larger than the input of other neurons, and 0 otherwise.The smoothing parameters (σ1, σ2, …, and σj) need to be carefully determined in order to obtain an optimal network with a reasonable amount of overlap; too small deviations will cause a very spiky approximation that cannot be generalized; while too large deviations will smooth out the detail. Fortunately, PNNs are not unduly sensitive to the precise choice of smoothing factor. Thus, an appropriate figure can be easily chosen through the experiment by selecting a number that produces the lowest selection error. In this work, we use a straightforward procedure to select the best value for σ. First, an arbitrary value of σ is chosen to train the network, and further testing on a test set. This procedure is repeated for other σ values and the σ giving the least errors will be selected.The motivation of using a PNN is driven by its generalization property and its simple training scheme (i.e. only one epoch of training is required). The speed of training is achieved at the cost of an increase in complexity and computational/memory requirements. The time complexity for training is O(nP), where n denotes the number of training samples and P is the length of PCA feature data. In our context, the time complexity of PNN that depends on P and n can be decreased due to the compressed feature data length. As such, the association of DRT and PNN is feasible in practical usage due to its high speed and accuracy performance.Our independent database comprised 1000 genuine signatures, 500 casual forgeries and 500 skilled forgeries, which were collected from 100 writers and 10 forgers. The signatures are collected from Chinese, Malay and Indian (the 3 main ethnic groups in Malaysia). Due to the non-repetitive nature of variation of the signatures, the signatures produced will have certain variations among the same writers. Thus, data preparation was divided into 2 stages. In the first stage, 5 sample signatures are registered per writer at a single contact session producing 500 samples. In the second stage, another set of 5 genuine signatures were supplied by the same writer during the contact sessions 2 weeks after the initial session, yielding another 500 samples. Thus, by recording the specific date, we can observe the variations among the same signature either within a single session or different session. For the forgery part, the casual forgeries are obtained first; the forgers are aware of the writer's name but not the original signatures. The skilled forgeries are obtained from the same group of forgers as well. This time, they are provided with several samples of the original signature to practise.The pen or pencil used by each writer is not prescribed, but signatures are written within a pre-drawn 5×2 grid on A4 paper as illustrated in Fig. 8.These signatures were scanned into the computer using a 24-bit millions of colours, at 600dpi resolution. The individual images are extracted and labelled with both the writer names and the signature class number.The experiment schemes are designed as follows: 4 samples of each person are sequentially selected for Eigenbasis construction, and the remaining 6 samples are used for testing; the PCA length is set to 100. We evaluated the system based on false acceptance rate (FAR), false rejection rate (FRR), and equal error rate (EER).

@&#CONCLUSIONS@&#
This paper extends the work of Ref. [24] by replacing the modelling agent of HMM with the classifier of PNN. The high accuracy and speed of the PNN are feasible to filter the skilled forgeries from the genuine signatures. The results are encouraging and thus should motivate more research on skilled forgery detection, especially for offline handwritten signatures. The framework is also applied to a public offline handwritten signature database – MYCT, where a comparable result (EER of 9.87%) is obtained. A larger database of signatures with forgeries and a powerful specification of PC support are essential to obtain a more reliable statistic of the EER of the system.