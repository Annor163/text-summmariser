@&#MAIN-TITLE@&#
The vector linear program solver Bensolve – notes on theoretical background

@&#HIGHLIGHTS@&#
We present the vector linear program solver Bensolve.We review the theoretical background of the algorithm.We provide numerical examples.

@&#KEYPHRASES@&#
Vector linear programming,Linear vector optimization,Multi objective optimization,,

@&#ABSTRACT@&#
Bensolve is an open source implementation of Benson’s algorithm and its dual variant. Both algorithms compute primal and dual solutions of vector linear programs (VLP), which include the subclass of multiple objective linear programs (MOLP). The recent version of Bensolve can treat arbitrary vector linear programs whose upper image does not contain lines. This article surveys the theoretical background of the implementation. In particular, the role of VLP duality for the implementation is pointed out. Some numerical examples are provided. In contrast to the existing literature we consider a less restrictive class of vector linear programs.

@&#INTRODUCTION@&#
Let us start with the formulation of a multiple objective linear program, which is a special case of a vector linear program. Given positive integers n, m, q and data of the formP∈Rq×n,B∈Rm×n,a∈(R∪{−∞})m×1,b∈(R∪{+∞})m×1,andl∈(R∪{−∞})n×1,s∈(R∪{+∞})n×1,we consider the problem(MOLP)minPxsubjecttoa≤Bx≤b,l≤x≤s.Minimization is understood with respect to the component-wise ordering inRq.In the more general setting of a vector linear program, one considers a partial ordering ≤Cgenerated by a polyhedral convex ordering coneC⊆Rqthat does not contain lines, or equivalently in this setting, is pointed. For vectorsy,z∈Rq,we definey≤Cz:⇔z−y∈C.The polyhedral cone C can be given either by a matrixY∈Rq×oas(1)C={y∈Rq|∃v∈Ro:y=Yv,v≥0},or by a matrixZ∈Rq×pas(2)C={y∈Rq|ZTy≥0}.Throughout, (1) is referred to as cone-representation and (2) is called dualcone-representation. This can be motivated as C is generated by the columns of the matrix Y (in the sense of (1)), whereas the dual coneC*:={w∈Rq|∀y∈C:yTw≥0}of C is generated by the columns of the matrix Z. The latter statement is a consequence of Farkas’ lemma. The resulting vector linear program is(VLP)minCPxsubjecttoa≤Bx≤b,l≤x≤s.The recent version of Bensolve assumes further that the cone C is solid, i.e., it has dimension q, or equivalently, nonempty interior. This assumption is equivalent torankY=q. Further, C is free of lines if and only ifrankZ=q. This implies that necessarily o ≥ q and p ≥ q.We close this section with some bibliographical remarks. It seems that Dauer (1987) and Dauer and Liu (1990) started to propagate the objective space approach in multiple objective linear programming, saying that on the one hand it is more efficient, and on the other hand it is sufficient in practice to generate only the minimal (or non-dominated) vertices in the objective space (or image space). The algorithms of Bensolve are based on the papers by Benson (1998a), (1998b). Since then, several extensions, simplifications and improvements have been published, among them the introduction of a dual algorithm in Ehrgott, Löhne, and Shao (2012), the extension to the unbounded case in Löhne (2011), approximate variants in Shao and Ehrgott (2008), the extension to pointed solid polyhedral ordering cones in Hamel, Löhne, and Rudloff (2014), a simplification which requires only one LP per iteration (independently) in Csirmaz (2015) and Hamel et al. (2014), and a complexity analysis in Bökler and Mutzel (2015). Recently, it was shown that Bensolve can be used to compute projections of polyhedra (Löhne & Weißing, 2015). In contrast to the literature, see e.g. Hamel et al. (2014), we make weaker assumptions: The geometric duality parameter vectorc∈Rqis required to satisfy cq≠ 0 rather thancq=1. The choice of ordering cones is therefore less restricted. Moreover, we derive geometric dual programs for maximization problems as well as for problems with box constraints.In contrast to most classical textbooks on vector optimization and multiple objective programming, Bensolve is based on a recent solution concept, which has been introduced in Heyde and Löhne (2011) and Löhne (2011). This concept entails the notions of minimality and infimum attainment, which are equivalent in the scalar linear programming case, but do diverge with increasing image space dimension. While in the classical literature essentially only minimality is taken into account, we will show in the following that both conceptions are essential for a proper solution concept. To this end, we start with the classical scalar theory and extend it to the case of multiple image space dimensions.Consider the scalar linear program(LP)minx↦cxs.t.x∈S,whereS⊆Rnis some feasible set defined by linear inequalities. Finding a solution to (LP) means to find a feasible variablex¯∈Swhose imagecx¯equals the minimum of the set of objective values {cx ∣ x ∈ S} ≔ c[X].The generalization of minimality to higher image space dimension with respect to the ordering induced by C is a standard notion:Definition 1A pointy∈A⊆Rqis called C-minimal in A, if for every pointy˜∈Athe following implication holds:y˜⩽Cy⇒y˜=y.The set of all C-minimal points of a set A is denoted byMinCA.The generalization of the term ‘solution’, however, is not so obvious. Likewise to the scalar case, a solution to a problem should be a single entity. But, a single minimizer is not an appropriate solution, even though it is referred to as efficient solution in the classical literature. The reason is that a single minimizer can be obtained by solving a scalarized problem, which in the present setting is usually a linear program. The problem to determine a single minimizer is therefore a matter of scalar optimization. Thus, the single entity mentioned above should be a set of minimizers.The problem to compute all extreme minimizers has been investigated, see Evans and Steuer (1973), Steuer (1989), but for many applications, this approach does not seem to be tractable. This can be seen already by considering the scalar case: The problem to compute all extreme minimizers (i.e. a representation of all solutions) of a linear program is NP hard: Consider the feasibility problem. This leads to vertex enumeration, which is NP hard, see e.g. (Dyer, 1983, Proposition 5).Dauer (1987) and many followers aimed at characterizing every minimal element in the objective space. A corresponding set of minimizers is what we understand to be a solution to a vector linear program. Surprisingly this idea can be defined via infimum attainment.Let us consider the scalar case first. An alternative characterization of a solution for (LP), which does not rely on minimality, is provided by means of infimum attainment: The imagecx¯of a solutionx¯to (LP) is the infimum of the image of the feasible set c[S], which may be expressed equivalently by(3){cx¯}+R+⊆c[S]+R+.The generalization of the right hand side of inequality (3) in the case of multiple image space dimensions features prominently in the solution concept for (VLP) and is therefore denoted by a dedicated term:Definition 2The upper image of (VLP) is the Minkowski sum of the image P[S] of the feasible set S and the ordering cone C:(4)P:=P[S]+C.The lower image, in contrast, is obtained by adding the negative of the ordering cone to the image:(5)P[S]−C.As a generic term for both notions we use extended image.The upper image can be understood as an infimum, too: It serves as infimum in a complete lattice which embeds the image spaceRq. As the theoretical details are beyond the scope of the present article, the interested reader is referred to Heyde and Löhne (2011); Löhne (2011) for a thorough discussion. Here, we focus on the practical implications the consideration of the upper image yields. Observe that the right hand side of inequality (3) describes all the information in the image space that matters for a solution to (LP): While the image c[S] may be a closed interval[cx¯,y],the actual value of y or even the existence of y is not of interest for a minimization problem. Adding the ordering cone (R+in the case of scalar minimization) to the image c[S] of the feasible set conveys this fact. Before showing that this feature of the upper image is retained in higher image space dimensions (Proposition 8), we provide the notion of minimal directions in order to be able to describe the upper image geometrically. Hitherto we recapitulate that polyhedra may be represented by different means:(i)In terms of finitely many points and directions, called V-representation.As intersection of finitely many affine halfspaces, called H-representation.yh∈Rq∖{0}is a C-minimal direction inA⊆Rqif for some y ∈ A the pointy+μyhis C-minimal in A for every nonnegative scalar μ ≥ 0.Minimizers now can be defined as feasible elements generating minimal points and minimal directions. We setkerP:={x∈Rn|Px=0}.Definition 4FeasibilityA pointx¯∈Rnis called feasible for (VLP) ifx¯∈S:={x∈Rn∣a≤Bx≤b,l≤x≤s}.A directionx¯h∈Rn∖kerPis called feasible for (VLP) ifx¯h∈Sh:={x∈Rn∣0·a≤Bx≤0·b,0·l≤x≤0·s},where we define0·±∞=±∞.A feasible point x ∈ S is called minimizer for (VLP) if its image Px is C-minimal in P[S]. Likewise, a directionxh∈Sh∖kerPis called minimizer for (VLP) if Pxhis a C-minimal direction in P[S].An infimizer of (VLP) is a pair of sets that generates the upper image. For a setB⊆Rq,conv B denotes its convex hull. The cone generated by a non-empty setB⊆Rqis denoted byconeB:={tx|x∈B,t⩾0}. We setcone∅:={0}.Definition 6InfimizerA pair(S¯,S¯h),whereS¯is a nonempty finite set of feasible points andS¯his a finite set of feasible directions is called a finite infimizer of (VLP) if(6)convP[S¯]+coneP[S¯h]+C⊇P[S]+C.We note here that minimality is a kind of “local” property, whereas infimum attainment characterizes the relevant parts of the image of (VLP) “as a whole.” A solution to (VLP) combines both conceptions:Definition 7SolutionA finite infimizer(S¯,S¯h)is said to be a solution of (VLP) if the setsS¯andS¯hconsist of minimizers only.It is imperative, of course, that no minimal point is lost during the transition from the image P[S] to the upper imageP. This is ensured by the following proposition:Proposition 8SupposePcontains a vertex. Then(i)MinCP=MinCP[S].Every vertex ofPis C-minimal.An extreme direction ofPis C-minimal if and only if it does not belong to C.The first two statements are well-known and can be proven straight-forward. To prove (iii), first note that no c ∈ C∖{0} may serve as a minimal direction, as for anyy∈Pwe havey⩽Cy+candy≠y+c.Now let an extremal directiony¯∈Pbe given, that is, there existsy∈Psuch thatF:={y+ty¯∣t≥0}is a 1-dimensional face ofP. Now consider an elementy˜∈Pwithy˜⩽Cy+ty¯for given t ≥ 0, which means that there exists c ∈ C withy˜+c=y+ty¯. For any given λ ∈ (0, 1) we havey˜+11−λc∈P. Fromy+ty¯=λy˜+(1−λ)(y˜+11−λc)∈Fwe concludey˜∈Fandy˜+11−λc∈F. This means eithery¯is a nonnegative (asPdoes not contain lines) multiple of c orc=0. Therefore, ify¯∉C,y+ty¯is C-minimal for every t ≥ 0, proving minimality ofy¯.□The preceding proposition shows that for obtaining a solution to (VLP) it is sufficient to find the vertices Px and minimal extreme directions Pxhof the upper image as well as preimages x ∈ S, xh∈ Shwhich generate them. In fact, this is how Bensolve works: A vertex representation of the upper image is found along with corresponding preimages for the vertices and minimal directions. Actually, Bensolve does even more: The V-representation found by Bensolve is irreducible, that is, if any element of the solution is left out, it will not generate the upper imagePin the sense of (6).Those extremal directions in the V-representation which are not minimal (namely those belonging to C) are not a part of the solution, but nevertheless they are necessary for a complete description of the upper image. To emphasize their significance, these directions are labeled specifically:Definition 9The set of extreme directions ofPbelonging to C is called cone compartment.Duality plays an important role for Bensolve. For the user of the software the following aspects are important:(i)The extended imageDof the dual problem contains information about the extended imagePof the primal problem: Bensolve outputs a V-representation ofD,which can be used to obtain an H-representation ofP. Likewise, an H-representation ofDcan be obtained from the V-representation ofPcomputed by Bensolve.A dual algorithm can be chosen, which can be advantageous for certain problem instances. The dual algorithm constructs an outer and inner approximation ofDwhich corresponds, by duality, to an inner and outer approximation ofP.A duality parameter vectorc∈Rqcan be chosen by the user. The dual problem and the dual solution (but not the primal problem and primal solution) depend on this vector. It has influence on numerical issues of both the primal and the dual algorithm.To introduce the reader into the main ideas of duality for vector linear programming (in the sense of “geometric duality” established in Heyde & Löhne (2008), we begin with the following special case of (MOLP):(7)minPxsubjecttoa≤Bx.The dual problem to (7) is the following vector linear program with ordering coneK:={y∈Rq|y1=0,…,yq−1=0,yq≥0}:(8)K-maximizeD(u,w)s.t.BTu=PTw,u≥0,w≥0,eTw=1,where the objective function is defined asD:Rm×Rq→Rq,D(u,w):=(w1,w2,…,wq−1,aTu)Tande=(1,…,1)Tdenotes the all-one vector inRq. In this special case, the duality parameter vectorc∈Rqhas been chosen asc=e. Later on, the constrainteTw=1will be replaced bycTw=1. The feasible set is denoted byT:={(u,w)∈Rm×Rq|BTu=PTw,u≥0,w≥0,eTw=1}.Duality provides a relationship between the upper imagePof the primal problem (7) and the lower imageDof the dual problem (8), defined asD:=D(T)−K.In addition to weak and strong duality, for details see e.g. Löhne (2011), there is a third type of duality relation, called geometric duality. It states that there is a one-to-one correspondence between the proper faces of the polyhedronPand the non-vertical (i.e. the last component of the corresponding normal vector does not vanish) proper faces of the polyhedronD. The dimension of a proper face ofPand the dimension of the corresponding face ofDadd up toq−1. In particular, facets ((q−1)-dimensional faces) correspond to vertices (0-dimensional faces).In order to be able to formulate duality results we consider the following bi-affine coupling function, which was introduced in Heyde and Löhne (2008):(9)φ(y,y*):=∑i=1q−1yiyi*+yq(1−∑i=1q−1yi*)−ξ(y)yq*,whereξ(y)={1ifyisapoint0ifyisadirection.The next theorem is a consequence of the geometric duality theorem (Heyde & Löhne, 2008, Theorem 3.1). It points out the facts relevant for users of Bensolve and does not aim to cover the complete idea of geometric duality. For simplicity, we assume thatPhas a vertex, which corresponds exactly to the setting of the recent version of Bensolve (Löhne & Weißing, 2015).Theorem 10IfPhas a vertex, then the following statements hold true:(i)A finite setY¯of points and directions inRqis an irredundant V-representation ofPif and only ifφ(y,y*)≥0,y∈Y¯is an irredundant H-representation ofD.A finite setW¯of points combined with the direction(0,…,0,−1)TinRqforms an irredundant V-representation ofDif and only ifφ(y,y*)≥0,y*∈W¯is an irredundant H-representation ofP.Statement (i) follows from Corollary 3.3 in Heyde and Löhne (2008) and Theorem 4.62 in Löhne (2011). One has to take into account the following facts: (a) If a polyhedron P has a vertex, then an irredundant V-representation of P consists exactly of all vertices and all extreme directions of P, see e.g. Schrijver (1986); (b) Every vertex ofPis weakly minimal (and even minimal), see e.g. (Löhne, 2011, Corollary 4.67); (c) The vertical facets are exactly the ones which are not K-maximal, see e.g. (Löhne, 2011, Lemma 4.60).Statement (ii) follows from Corollary 3.2 in Heyde and Löhne (2008) and the following facts: (d)Dhas a vertex, see (Heyde & Löhne, 2008, Lemma 5.2), hence an irredundant V-representation ofDconsists of its vertices and extreme directions; (e) every proper face and hence any facet ofPis weakly minimal, see e.g. (Heyde & Löhne, 2008, Lemma 5.6).□Let us now consider the general case of (VLP). Given a (fixed) duality parameterc∈Rqwith cq≠ 0, the dual problem of (VLP) is the following vector linear program with ordering coneK:={y∈Rq∣y1=0,…,yq−1=0,yq≥0}:(10)K-maximizeD(u,w,v)s.t.BTu=PTw+v,Yw≥0,cTw=1with objective function(11)D(u,w,v)=(cq|cq|w1,cq|cq|w2,…,cq|cq|wq−1,d(u,v))T.The functiond:Rm×Rn→Ris defined as(12)d(u,v)=aTu+−bTu−+lTv−−sTv+,where we define±∞·0=0andα+:=max(0,α),α−:=max(−α,0),forα∈R,and(α1,…,αm)+:=(α1+,…,αm+),(α1,…,αm)−:=(α1−,…,αm−)for(α1,…,αm)∈Rm.Theorem 11Let c ∈ int C such that cq≠ 0. Then Theorem10also holds for the general case of problem(VLP)and the dual problem(10)if the following generalized coupling function is used:(13)φ(y,y*):=cq∑i=1q−1yiyi*+yq(|cq|cq−∑i=1q−1ciyi*)−ξ(y)|cq|yq*.The generalization of geometric duality to the case of a polyhedral convex ordering cone C that does not contain lines and has nonempty interior and a duality parameter vector c ∈ int C withcq=1can be found in Hamel et al. (2014). In this setting the dual problem isK-maximizeD(u,w)s.t.BTu=PTw,u≥0,YTw≥0,cTw=1with objective functionD(u,w):=(w1,w2,…,wq−1,aTu)T. The coupling function in this setting is(14)φ(y,y*):=∑i=1q−1yiyi*+yq(1−∑i=1q−1ciyi*)−ξ(y)yq*.Now let us relax the assumptioncq=1by cq> 0. Introducing new coordinates in the image space of the primal problem by replacing the last componentyq→cq−1yq(which effects the data Y and P of the primal problem as well as the duality parameter vector c), we obtain the dual problem(15)K-maximizeD(u,w¯)s.t.BTu=PTw¯,u≥0,YTw¯≥0,cTw¯=1,with objective functionD(u,w¯):=(w¯1,…,w¯q−1,aTu)T,where the dual variablew∈Rqhas been replaced byw¯withw¯i:=wifori=1…,q−1andw¯q:=cq−1wq. The coupling function is(16)φ(y,y*):=∑i=1q−1yiyi*+cq−1yq(1−∑i=1q−1ciyi*)−ξ(y)yq*.Of course, the statement of Theorem 10 remains valid if the coupling function is replaced by (13) and the objective function is defined by (11) for the special cased(u,v)=aTu.Let us now consider the case cq< 0. We perform a coordinate transformationy→−y, which results in a primal problem with dataP¯:=−P,Y¯:=−Yand a duality parameterc¯:=−c. Sincec¯q>0,the result is known for this case from the first part of the proof. The dual problem isK-maximizeD(u,w¯)s.t.BTu=P¯Tw¯,u≥0,Y¯Tw¯≥0,c¯Tw¯=1with objective functionD(u,w¯):=(w¯1,…,w¯q−1,aTu)T. Substitution of the dual variablew¯by−wleads toK-maximizeD(u,w)s.t.BTu=PTw,u≥0,YTw≥0,cTw=1,with objective functionD(u,w):=(−w1,−w2,…,−wq−1,aTu)T. The coordinate transformation (y→−y,c→−c) transforms the coupling function (13) for the case cq> 0 to (13) for the case cq< 0.The constraints of the general case (VLP) can be expressed as(17)(B−BI−I)x≥(a−bl−s),where I denotes the n × n unit matrix. This leads to the dual constraintsBTu′−BTu′′=PTw+v′−v′′,u′,u′′,v′,v′′≥0,YTw≥0,cTw=1,and the last component of the objective function D isd(u,v)=aTu′−bTu′′+lTv′′−sTv′.If some components of the right-hand side in (17) are−∞,the corresponding dual variables must vanish (i.e. they do not occur in the dual program). This is taken into account by setting±∞·0=0.Finally, in the constraints we setu:=u′−u′′andv:=v′−v′′,and in the objective function we chooseu′:=u+,u′′:=u−,v′′:=v−,v′:=v+. Since a ≤ b and l ≤ s imply thataTu′−bTu′′+lTv′′−sTv′≤aTu+−bTu−+lTv−−sTv+,this specification does not influence the optimum in case of maximization.□We close this section by a short consideration of maximization problems:(VLPmax)maxCPxs.t.a≤Bx≤b,l≤x≤s.In this case we deal with a lower imageP:=P[S]−Cof the primal problem and an upper imageD:=D[T]+Kof the dual problem, which can be stated as(18)K-maximizeD(u,w,v)s.t.BTu=PTw+v,Yw≥0,cTw=1with objective function(19)D(u,v,w)=(cq|cq|w1,…,cq|cq|wq−1,d¯(u,v))T,where(20)d¯(u,v)=bTu+−aTu−+sTv−−lTv+.The ordering cone is againK:={y∈Rq|y1=0,…,yq−1=0,yq≥0}.Theorem 12Let c ∈ int C such that cq≠ 0. Then Theorem10holds for (VLPmax) and for the dual problem(18)if the following coupling function is used:(21)φ(y,y*):=−cq∑i=1q−1yiyi*−yq(|cq|cq−∑i=1q−1ciyi*)+ξ(y)|cq|yq*.This follows from Theorem 11. We first replace maximization with respect to C by minimization with respect to−C. This requires the transformationsY→−Yandc→−c. In the dual problem we substitute(u,w,v)→−(u,w,v). The resulting maximization problem with respect to K is finally expressed as a minimization problem with respect to K, which refers to a coordinate transformationyq*→−yq*.□Bensolve is an implementation of primal and dual Benson-type algorithms. The origin of these algorithms is discussed in Section 1. The implementation is closely related to the presentation in Hamel et al. (2014), therefore, we do not present too much details here. Bensolve can handle problems which are generalized in comparison to Hamel et al. (2014) with respect to the following two aspects:(i)The assumptioncq=1can be replaced by cq≠ 0, which allows to use arbitrary solid and line-free polyhedral ordering cones.Maximization is covered in addition to minimization.These generalizations can be easily realized by the transformations and the dual programs discussed in the previous section. A modification of the algorithms is not necessary.The VLP-solver Bensolve is a C-implementation of the algorithms discussed above. In this section, we investigate and compare numerical properties of two applications of multiobjective optimization problems.The first example (Example 13) is used to show the improvements that could be made in comparison to prior implementations. The second problem class (Example 14) with image space dimension equal to ten shows that Bensolve is well suited for problems with high image space dimensions.The numerical examples were run on a computer with 8 gigabyte memory and an Intel® Core™ i5-4200 CPU with 1.60 gigahertz clock. The source code of Bensolve11The source code is available at http://bensolve.org along with documentation and example problems.was compiled with the GNU Compiler Collection gcc 5.2.1 and linked against the GNU Linear Programming Kit library libglp 4.55.Example 13In their paper, Shao and Ehrgott (2008), Shao and Ehrgott use a variant of Benson’s algorithm to solve MOLPs originating from a model for optimizing radiotherapy treatment planning. The clinical example (PL) from this paper has three objectives, 1211 constraints and 595 variables (which are additionally nonnegative). The constraint matrix is sparse with 153936 nonzeros, see Fig. 1. Solving this problem exactly is not tractable. Thus, an approximation variant of Benson’s algorithm has been introduced in Shao and Ehrgott (2008): The algorithm stops as soon as the translation of an approximationPɛof the upper imagePby the duality parameter c is contained in the upper image:Pɛ+ɛ·c⊆P.This problem instance is also used for numerical tests in Hamel et al. (2014) with a Matlab®-implementation preceding the current version of Bensolve. The implementation used in Hamel et al. (2014) is similar to Bensolve v1.222Bensolve v1.2 is available in the download section at http://bensolve.org.. The major difference is the use of a certain warm start heuristic in Hamel et al. (2014). Approximations for various error-levels ε were computed with both the primal and dual variant of Bensolve33The authors thank Lizhen Shao for supplying the problem data., were we used the primal simplex as LP-solver in both cases. The run times are listed and compared with those of the implementation from Hamel et al. (2014) in Table 1. It can be seen that Bensolve performs superior to the preceding implementation with regard to the run times. This might be explained partially by the speed-up gained through the transition from a Matlab® to a C-based implementation or by refinements in the algorithm itself. It should be noted that even better results are expected as soon as a warm start heuristic similar to the one used in Hamel et al. (2014) is implemented. Currently, a kind of “indirect” warm start technique is used, which is imminent in the LP-solver44GNU Linear Programming Kit, http://www.gnu.org/software/glpk/glpk.html.we use for our implementation: between subsequent calls to the solver, the basis factorization of the solution found last remains in memory, hence speeding up the computation time due to the similar structure of the LP’s.A further explanation for the improved run times is the utilization of a variant of the double description method (see e.g. Fukuda & Prodon, 1996), adapted specifically for the vertex enumeration part of Bensolve: In each iteration we are given an H-representation and a V-representation of a polyhedron P. We intend to compute the intersection P ∩ H of P with an affine halfspace H. We assume that only a few vertices of P do not belong to H. The classical variant requires a classification of vertices K1 of P belonging to H and vertices K2 of P not belonging to H. The adjacency relation for every pair (v1, v2), where v1 ∈ K1 and v2 ∈ K2, needs to be checked in order to compute the new V-representation. The new variant avoids this classification. One starts with some v1 ∈ K1 and checks every neighboring vertex v2 whether it belongs to K2 or not. If not, the procedure is repeated with v2.While approximations with an error threshold below5·10−3where hardly possible with the version used in (Hamel et al., 2014), our new implementation is capable of finding approximations with error level1·10−5in a reasonable amount of time. Additionally, an improvement with respect to the approximation quality can be observed: both the primal and dual variants of Bensolve are able to achieve approximations of the upper image with the same approximation error ε with fewer vertices (compare Table 2) and by solving less linear programs (Table 3). This behavior can be explained by a new implementation of the vertex enumeration: If two vertices are very close to each other, they are replaced by a single one, while maintaining the outer approximation property.In Csirmaz (2015) Csirmaz presents a rather fascinating application of Benson’s algorithm: Exploring the entropy region formed by the entropies of the nonempty subsets of four random variables, which consists basically in finding a V-representation of a 10-dimensional projection of a high dimensional polytope. Csirmaz used a revised version of Benson’s algorithm to solve several instances of vector linear programs, which are generated by a procedure involving so called “copy steps”. The problem instances have been solved with Bensolve55The authors are indebted to László Csirmaz for providing the perl-script that generates the problem instances.and we compared the run times with those of Csirmaz (2015) (compare Table 4). Here we used the default options of Bensolve, the primal algorithm was used with an approximation error ofɛ=10−8. Although we used a machine with slightly higher specifications than the one used in Csirmaz (2015), our implementation seems to be much faster, especially for large problem instances. One explanation might be the adapted vertex enumeration method used in Bensolve: In Csirmaz (2015) it is stated that due to the huge number of vertices of intermediate polytopes the vertex enumeration (the double description method) becomes the bottleneck of the algorithm. It should be noted that Csirmaz (2015) put a lot of effort in reducing numerical errors to a minimum. Therefore, we also list the number of vertices and facets computed by the different implementations in Table 5. While the number of primal vertices concur for all problem instances, the number of dual vertices (which corresponds to the number of facets of the upper image) differs slightly for different instances. This may be the result of numerical errors or imprecision due to the approximating character of Benson’s algorithm.

@&#CONCLUSIONS@&#
