@&#MAIN-TITLE@&#
Simplifying the powder metallurgy manufacturing process using soft computing tools

@&#HIGHLIGHTS@&#
This soft computing based model act as an expert in manufacturing of composites.Capable to select the range of parameters for predicting their properties.It will avoid expensive experimentation.

@&#KEYPHRASES@&#
Soft computing,Computational intelligence,Knowledge mining,Powder metallurgy,Composite preforms,

@&#ABSTRACT@&#
The tools of soft computing will aid the knowledge mining in predicting and classifying the properties of various parameters while designing the composite preforms in the manufacturing of Powder Metallurgy (P/M) Lab. In this paper, an integrated PRNET (PCA-Radial basis functional neural NET) model is proposed in different versions to select the relevant parameters for preparing composite preforms and to predict the deformation and strain hardening properties of Al–Fe composites. It reveals that the predictability of this model has been increased by 67.89% relatively from the conventional models. A new PR-filter is proposed by slightly modifying the conventional filters of RBFNN, which improves the power of PRNET even though raw data are highly non-linear, interrelated and noisy. Moreover, fixing the range of input parameters for classifying the properties of composite preforms can be automated by the Fuzzy logic. These types of models will avoid expensive experimentation and risky environment while preparing sintered composite preforms. Thus the manufacturing process of composites in P/M Lab will be simplified with minimum energy by the support of these soft-computing tools.

@&#INTRODUCTION@&#
Soft computing models have been studied in recent years, with an objective of achieving human like performance in many fields of knowledge engineering. These tools are being successfully applied in material design, improvement and selection as well as in the control of the processes in materials fabrication. Many researchers have attempted to use soft computing tool like neural network for various applications in manufacturing such as, tool wear, TTT diagram prediction, optimization of powder packing density, Powder Metallurgy (P/M) process modelling, turning force prediction and on-line monitoring, etc. [1–3]. The life cycle of P/M process needs a different sequence of operations with various machines to manufacture the composite preforms as a steel manufacturing process [4]. Fig. 1exhibits the various stages like blending, mechanical alloying, compacting, sintering, preforms and inspecting the products, involved in powder metallurgy process. In P/M laboratory, the needed metal powders are mixed in different ratios, compressed and sintered to prepare powders to prepare composite preforms (pre-designed forms), which will be used as models to manufacture various products such as aircraft parts, aluminium coins and snowing machinery parts etc. Using Soft computing models, the various deformation and strain hardening characteristics of preforms are mined before preparing the material parts. The deformation characteristics like axial strain (ɛz), hoop strain (ɛθ), conventional hoop strain (ɛθ’), strain factor (S), Poisson's ratio (ψ), new Poisson's ratio (ν), axial stress (σz), hoop stress (σθ), hydrostatic stress (σm) and strain hardening characteristics like instantaneous strain hardening exponent (ni) and instantaneous strength coefficient (ki) of these manufactured composite preforms will be varied with respect to the proportions of input parameters like compaction load (P), aspect ratio (A), fractional density (D), iron content (C) and lubricant (L).While applying hard computing methods, the P/M process needs three critical stages: selection of relevant input parameters, fixing the range of input parameters and predicting the various characteristics of composite preforms. In this work, the soft computing tools are applied for simplifying the manufacturing process of Al–Fe composite preforms.The Section 2 covers the literature survey of related work. The role of hard computing in conventional process and soft computing techniques in knowledge mining are described in the Sections 3.1 and 3.2, respectively. The purpose of the soft computing tools for each stage of this work is mentioned in the Section 4. The design and implementation details were described in the Section 5 along with the need of the pre-processing. The results are analyzed and reported in the Section 6.The knowledge oriented models described in this paper were not developed by any researcher in the field of powder metallurgy. But anyway, the survey was done over the related problems of this work in three aspects: Data level, architecture level and an efficiency of an intelligent algorithm. Data cleaning is a major step in the knowledge discovery process [5]. Our intelligent/soft computing algorithms will take more time complexity if we apply dirty data to the knowledge mining. In the related work, the properties of raw data were not analyzed in detail. Data transformation (normalization) and data reduction (fixing the range of parameters and selecting the relevant subset selection) are two major issues in data cleaning. The raw data was handled without using these mining techniques in the previous work while predicting various parameters [3,6–19]. Also the data discretization was not applied to fix the range of input parameters for supporting data reduction in the previous work. Moreover, the survey done on the previous research, which reveals that the pre-processing steps like data cleaning, normalization and data reduction were not carried out for handling non-linear, interrelated, noisy and null data. In this paper, the systematic strategy is prescribed to handle this kind of data.The initial research for the computation of data was started in the year 2003 [20] to predict the properties of the properties of composite preforms without applying soft computing models. It took more resources and time. The researchers had to conduct the experiments, physically for each sample in the Laboratory. Later, the statistical methods were applied. The following observations were made over statistical method like multiple regression analysis:•Polynomial regression can be applied only for single input and single output parameters.Too complex for statistical methods because numerous variables are involved and non-linearity of the relationship between the varieties of parameters [21].Statistical methods will be suitable only, when the number of variables is small and when their effects can be described by simple relationships [8].Regression analyses are not particularly suited to modelling due to substantial gap present in the data [20].In some cases, multiple regression yields better results, but it can be limited to predicting the single output. So it is not applicable to multi-dimensional data.Then the soft computing based tools were used. In the architecture level, most of the related work for this work had predicted only few linear parameters (even a single parameter) from more inputs using the Neural Network tool [2,6,7,9,15–19,22–27]. Only a few researchers had applied the soft computing tools in simulating the preform other than Al–Fe composites, where the number of outputs is less than or equal to the number of inputs [11,14,24,25,28–31]. By trial and error, the architecture was fixed. The objective of this work is to predict more outputs from optimal inputs.While developing the intelligent models, the generality should be measured to recognize the independent test samples. The capacity of architecture, number of training samples and network convergence determines the generality of the model. Fox example, if the hidden layer size is more than the number of training samples, then the network will converge quickly. But the network generalization will be very poor. This kind of problem called overfitting was reported in the related work [32], where various generalization tools were utilized to avoid overfitting. But the network was unable to predict the outputs for null parameters. Also the system accuracy was evaluated using the biased measure like correlated coefficient instead of the unbiased measure like Average Absolute Relative Error (AARE) percentage. Hence the objective of the proposed model is to improve the generality in terms of AARE% and also to handle the null entries in data for an analysis.The intelligence of an algorithm was not analyzed in terms of system accuracy and convergence (training completion) in the related work [12,13]. The previously developed models took more epochs like 175 [11], 251 [12], 1322 [13], 160 [14], 4541 (55h) [15], 130 [17], and 1,537,695 [18] even for predicting few linear outputs with limited training samples. The previous research used the conventional filters to find the activation functions. Hence the proposed work aims to find the suitable filter to improve the training time.The life cycle of P/M covers various stages as shown in Fig. 1. The role of hard computing method under the different stages of the manufacturing process of P/M Lab is described as given below.Generally a product is identified for manufacturing using P/M process; the selection of material and process parameters requires inputs from a number of experts in the field. Unlike wrought products, design specifications determine the process parameters and type of powder to be used in producing a P/M part [1]. In the initial stage of the manufacturing process, numerous variables are used in hard computing model to predict the output. It is difficult to apply different permutations of input parameters in mixing powders and to select the most relevant input combination, since each input combination will give different results. While using hard computing model, it is very critical to select the needed input combination of the required product. This work will be automated with the help of soft computing tool in P/M Lab to select the proper input combination of metal powders.In the next stage of P/M process, the needed metal powders are mixed in different ratios using ball-milling equipment as shown in Fig. 2(a) to prepare powders in homogeneous form is frequently used to improve various material properties and to prepare advanced materials that are different or impossible to be obtained by traditional techniques. With respect to the product type in production, the proper range of input parameters should be applied. The blending and mechanical alloying process may need repeated experiments due to the wrong range of powder mixture, for the inexperienced users. The intelligent oriented models like soft computing will aid the blending and mechanical alloying process, in fixing the ratios of various input parameters in preparing the powder mixture.The die set assembly as shown in Fig. 2(b) is used to compress the above powder mixture and sintered (heated) to get the required shapes of preforms. In this work, atomized aluminium powder of 150μm size was obtained from M/s. The Metal Powder Company Limited, Madurai, Tamilnadu, India. The aluminium powder was analyzed and was found to be of purity greater than 99.68% have been used throughout the experiment. The aluminium powder was used for preparing compacts of different height to diameter ratios (aspect ratio). The initial aspect ratios were 0.50, 0.75 and 1.00. Compacts of above initial aspect ratios were prepared from the aforesaid powder on a compacting pressure of 100±5, 155±5, 205±5, 215±5 and 280±5MPa in a universal testing machine having capacity of 1.0 MN with various initial compaction densities of 80, 85, 88, 90 and 92% of the theoretical density. Molybdenum disulphide (MoS2) was used to lubricate the punch, die and the butt, when preparing the compacts. The sintering was carried in an electric muffle furnace at 520±10οC for a holding period of 1h. The measurements such as height, diameters and densities were carried out before and after each of deformations. During the axial compression tests, the die set was well lubricated by MoS2, which created a situation for almost ideal deformation. In general, each compact was subjected to compressive loading in steps of 0.01 MN until the appearance of visible cracks on the free surface. Immediately after the completion of each step of loading, the height, the contact diameters (at the top and bottom), the bulged diameter and the density were measured for each of the deformed compacts, the density measurements were carried using the Archimedes principle [20].The aluminium (Al) and iron (Fe) powders are mixed in different ratios with molybdenum disulphide (MoS2) as die surface lubricant in order to prepare green compacts. This powder mixture is loaded into the die set assembly and then to universal testing machine as shown in Fig. 2(b). As the compaction load (L) increases, the density of the powder mixture increases and hence the height of the preform (h0) will decrease. After the completion of sintering of green compacts, it is ready for inspection, which is named as preforms. The load, P is applied over the preform with an increment of 5kN. If the load increases, the deformation and strain hardening properties of the preform also increases proportionally. The minimum and maximum aspect ratio of preform (A) is 0.4645 and 1.0539 respectively, and this also depends on compaction load and weight of powder used for compaction. Similarly, the minimum and maximum values for fractional density (D) are 0.82 and 0.99 respectively. The output parameters representing the characteristics of preforms increases if the fractional density increases, but after certain limit it will decrease. Using, hard computing methods, it is difficult to find the association between input and output parameters. Hence the need occurs to apply Soft computing models to simplify this work.At the end of the manufacturing process, the properties of developing preforms are studied before shifting the preforms to the production process of material parts. While applying hard computing (deterministic) model, it has to implement the Ludwik equations [20] completely to predict the deformation and strain hardening properties.Deformation characteristics:•Using the initial height of preform (h0) and height after the deformation (hf), the axial strain can be calculated as given below:(1)εz=lnh0hfHoop strain is calculated with a contact and bulged diameter of the samples.(2)εθ=ln2DB2+Dc23D02where D0 is an initial diameter of the preform, DBis a bulged diameter of the preform andDcis a contact diameter of the preform after deformation.Conventional hoop strain is calculated without bulged diameter of the sample.(3)εθ'=lnDcD0Strain factor using axial strain ɛzand hoop strain ɛθis defined as(4)S=eεz−εθPoisson's ratio based on contact diameter (ν) is calculated as below:(5)ν=εθ'εzPoisson's ratio (ψ) based on contact and bulged diameter is calculated as below:(6)ψ=εθ2εzAxial stress is mechanical stress defined for rotationally symmetric objects being the result of deformation acting longitudinally (axially), with load P as given below:(7)σz=4PπDc2Hoop stress based on bulged and contact diameter can be derived as(8)α=dεθdεzwhereα=dεθdεzδ is the slope between hoop strain (ɛθ) and axial strain (ɛz).Meanwhile, the hydrostatic stress (σM) can be calculated using the relationship:(9)σM=13σθ±σzStrain hardening characteristics:The properties niand kiare derived using the difference between the mth and (m−1)th rows of axial strain and axial stress parameters as given below:•Instantaneous strain hardening exponent(10)ni=ln(σm/σm−1)ln(εm/εm−1)Instantaneous strength coefficient(11)ki=σm−σm−1εmn−εm−1nSince the hard computing model adopts sequential computation, it takes more time and effort. As raw-data collected from the P/M Lab are interrelated, noisy and highly non-linear as given below, these are not suitable to parallel processing. Hence, it is advisable to use soft computing based model which can tolerate imprecision, uncertainty, partial truth and approximation to simplify the manufacturing process of preforms [21].•Interrelated dataThe certain output parameters should be fed as input to derive the other set of output parameters. As mentioned in the mathematical representation, the output parameters are given as derived from other output parameters as given below:Output parametersNeeded output parameters to act as inputs1, 2, 3, 7 (Linear parameters)Not having this type of input4, 61, 251, 381, 2, 797, 810, 119Noisy dataWhile measuring the parameters of raw-data using physical instruments in P/M Lab, it is possible to have the variation between the measured (actual) data and expected data. The unwanted data may affect the system accuracy.Empty dataIt is possible to have certain rows of the parameter may be empty (Table 1). In the raw database Table 1, the empty cell of niand kiparameters will be derived from the difference between two subsequent previous two rows of known column value as per the Eqs. (10) and (11). In each experimental data set, for the every first row, there is no previous row value. It is not applicable to find the difference between the mth and (m−1)th rows of strain and stress parameters. Hence, nearly 42 rows are made as empty for the parameters niand ki.Highly non-linear dataMore parameters have a non-linear relationship with each other. Fig. 3(a) shows the linear relationship between axial strain and hoop strain. But Fig. 3(b) shows the non-linear relationship between variation of stress (axial, hoop and hydrostatic stress) and axial strain.The experiments conducted physically in P/M Lab as given in Section 3.1, need costly equipments. In order to provide security to the people working in P/M Lab and by considering the drawbacks behind the hard computing models as given in Section 3.1, the proposed work will be implemented by the soft-computing tools. Fig. 4shows that the proposed model based on soft computing will reduce the complexity rather than the conventional hard computing model in terms of time, manpower and other resources using the components mentioned in Fig. 5. The tool of soft-computing, Neural Network (NN) has major contribution in prediction oriented problems [21]. As per the existing models adopted in the previous research [6–9] with NN, there is no more efficient neural network design in the powder metallurgy field to select the relevant input features (meaningful parameters) in predicting the properties of composite preforms.Many input features are involved in designing the soft-computing model and these parameters (features) can be selected only by the experience of technicians in the powder metallurgy Lab. And also, for each set of combination, these earlier models gave different results. To overcome this problem, a mathematical procedure, Principal Component Analysis (PCA) is integrated with NN to build PRNET model to select the most relevant input features, since it is a powerful tool to convert a set of observations of possibly correlated variables into a set of values of linear uncorrelated variables called principal components. It reduces the dimension of input and improves the efficiency of the system [33]. In implementing NN, Radial basic Functional Neural Network based model is preferred, since it offers a powerful framework for representing non-linear mappings from several inputs to one or more outputs [34]. In this work, different categories of PRNET models are proposed and also a new filter of type PR filter is proposed by slightly modifying the components of conventional filters of RBFNN to improve the power of PRNET even though raw data are highly nonlinear, interrelated, null and noisy. Also the Fuzzy logic of soft computing tool will be used to fix the range of parameters used in designing preforms, since it will be helpful to make a clear quality distinction among the product lots [35]. The following Section 4 describes in detail about the components involved in the proposed model.In recent years a considerable research effort is being gone into the development of soft computing for data analysis, function approximation, sensor processing and control of material properties. Significantly, their ability to perform complex nonlinear mappings can be used for approximating multiple input and multiple output relationships. The modelling problem in P/M process can be thought of as a continuous non-linear mapping from ‘n’ dimensional space to ‘m’ dimensional space. The soft computing based models have significant contribution in simplifying the various processes involved in the manufacturing of composite preforms as given below.A fundamental aspect of Neural networks (NN) is to use simple processing elements that are essentially models of neurons in the brain. These elements are then connected together in a well-structured fashion, although the strength and nature of each of the connecting links dictate the overall operational characteristics of the total network. Neural networks operate by simulating the ability of biological neural systems to perform complex decision making tasks without any prior programming. They are feed-forward networks consisting of three layers namely input, hidden and output layer as given in Fig. 6. The hidden layer has kernel neurons and an output layer has linear neurons [36]. The connection between input and hidden layer does not use the weighted sum of inputs. The output of the hidden layer represents basis functions, which are determined by the distance between the network input and the centre of the basis function. As the input moves away from a given centre, the neuron output drops off rapidly to zero. The output layer of RBFNN is linear and produces a weighted sum of the outputs of the hidden layer. The neurons in the RBFNN have localized receptive fields because they only respond to inputs that are close to their centres.Construction of radial basis function neural networks involves selection of radial basis function centroid, radius (width or scale), and number of radial basis function (RBF) units in the hidden layer [37]. RBFNN's are commonly following a hybrid procedure in two stages. In the first stage, from the available training samples the centres are selected and radial functions are computed without a target in unsupervised mode. The second stage operates in supervised mode, where the weights are computed using the target values of training samples.In the proposed RBFNN model, the exact interpolation, called NADP (Neuron At every Data Point) is preferred for training the Network, because this technique maps every point in the input pattern to the output layer. The given Q amount of training samples is considered as centres in this method. Formally, the exact interpolation of Q data points in a multi-dimension space require all the D dimensional input patternsxk={xik,i=1,2,…,D}to be mapped onto the corresponding target output ykwhere D is the size of the input layer. The goal is to find the f function such that(12)f(xk)=yk∀k=1,…,QThis approach requires Q amount of radial basis functions. The algorithm given below is used to interpolate the source data exactly:I.Initialize the free parameters like the spread factor, number and values of centres, the type of radial basis function and weight values between hidden and output layer.The kth training pattern with D amount of features is applied to input layer X, whose size is equal to D. Then each input (xi; i=1,2,…,D) node of kth pattern sends the input data to the hidden layer.At hidden layer, the distance between the input layer X and the jth centre point μjis calculated by the formula:(13)X−μj=∑i=1i=D∑j=1j=Q(xi,j−μj,i)2The activation of hidden unit (ϕ) is determined by the distance between the input vector and centres using any one of the RBFNN filters ƒ as given in Section 4.1.3.(14)ϕj(X)=f(||X−μj||)ϕ is a Q×Q matrix computed entirely from the data points X(15)ϕ=⋮ϕ(||XQ−μ1||)......ϕ(||XQ−μQ||)ϕ(||X1−μ1||)......ϕ(|||X1−μQ|)The activation of the output unit is determined by a dot product between the hidden activation vector and weight vector. For convenience an additional basis function ϕ0 with a constant activation value of ‘1′ can be used with weight W0 to improve the accuracy of the network. Finally the value of kth output neuron is calculated by:(16)yk=∑j=1QWjkϕj(X)+W0ϕ0The above steps (I––V) belong to the training procedure. At the end of training, the weight vector is used to test the generality of network with independent test samples. The weight may be computed in terms of known ϕ functions and target vector T of supervised learning as below:The unknown term ‘W’ required for the network recognition can be calculated by:(17)Wb=ϕ−1TEq. (17) can be derived easily since ϕ been symmetric, that is Y=ϕTW=ϕWWhile testing the independent input samples, Wbis separated as W and W0 to derive the output value Y using the Eq. (16).As per the algorithm of RBFNN in Section 4.1.2, the deviation between the input nodes and RBF centres are calculated and it applies to filters of RBFNN to derive the output of hidden layer as per Eq. (14). The RBFNN supports the possible conventional filters as given below:Gaussian function:(18)ϕ(r)=exp−r22σ2Cubic function:(19)ϕ(r)=r3Linear function:(20)ϕ(r)=rMulti quadric function:(21)ϕ(r)=r2+σ2Gaussian kernel has almost exclusively been used as basic function of the cluster centres of RNFNN in most of its applications. This work proposes PR filter as given in Eq. (22) by slightly modifying the parts from the above conventions filters.PR filter(22)ϕ(r)=r22σ2Principal Component Analysis (PCA) involves a mathematical procedure that transforms a number of (possibly) correlated variables into a (smaller) number of uncorrelated variables called principal components. The first principal component accounts for as much of the variability in the data as possible, and each succeeding component accounts for as much of the remaining variability as possible. It helps to discover or to reduce the dimensionality of the data set and to identify new meaningful underlying variables. Janakiraman et al. [9] used PCA as a pre-processing step to reduce the input dimension, thereby reducing the memory requirements of the models and to reduce the cross-validation time required to identify optimal model hyper-parameters. Jing Zhou et al., [34] applied the PCA to acquire main features of measured data for quick and accurate fault detection and identification in health monitoring.The raw data set has more number of input parameters in the form of P, h0, hf, D0, Dc, DB, α, δ, iron content and lubricant. While using with more input parameters, the network complexity increases in architecture and it will turn in increasing the training time. Also, each input pattern will give different results. Hence the selection of relevant input features is the main issue in designing the architecture of neural networks. Using the working experience in P/M Lab, the input layer size may be decided. There is no assurance to select the unique optimal selection among the available input features. The PCA tool helps in identifying meaningful parameters and reducing the dimension of the input space, which in turn reduces the architecture and training time. Also, this provides the unique path for deciding the possible input features in P/M Lab.Fuzzy logic (F/L) is a form of many-valued logic or probabilistic logic and it deals with reasoning that is approximate rather than fixed and exact. Compared to traditional binary sets (where variables may take on true or false values) fuzzy logic variables may have a truth value that ranges in degree between 0 and 1. Fuzzy logic has been extended to handle the concept of partial truth, where the truth value may range between completely true and completely false. Furthermore, when linguistic variables are used, these degrees may be managed by specific functions. Fuzzy set, therefore, provides a powerful computational paradigm for extending the capability of binary logic in ways that enables a much better representation of knowledge in materials engineering [21]. This is because fuzzy logic facilitates the expression of continuous by way of assigning a numerical grade of membership.The multi-value attribute of F/L allows intermediate values to be defined between conventional binary evaluation points, such as the degree of presence or absence of a material constituent of a composite. This facilitates the intuitive assignment of numerical values in obtaining exact solutions even when vague or imprecise concepts are used to describe material properties. Qian Zhang et al. [38] successfully applied F/L to the industrial problems of predicting machining induced residual stresses for aerospace alloy components as well as modelling the mechanical properties of heat-treated alloy steels. Yuanfei Han et al. [39] applied strain rate, deformation temperature and the strain as input parameters and flow stress as output parameter using ANFIS model. Hence, the application of fuzzy logic will be helpful in P/M Lab. for classifying the properties of composites into various levels like low, medium, high and very high level. The knowledge of this classification will be useful for the technicians working in the P/M Lab to fix the range of input parameters while mixing various powders for preparing composites.The dirty data will slow down the mining algorithm. Hence the following strategies were adopted to convert the dirty data into clean data.The highly non-linear parameters (niand ki) representing the strain hardening properties have more incomplete entries (empty cells). The following issues were tried to substitute the values for these null parameters.1.The empty cells may be omitted completely from the raw database.The empty cells may be substituted strictly by zero.The empty cells may be substituted by the mean of the parameter.The first method is logically incorrect, since it affects the originality of the raw data. The second method is not adequate since the conflict may occur between the original raw value (zero) and substituted value (zero). Among the above methods, third strategy is felt as a suitable method than the other two methods. In this case the empty cell of ni is substituted by the mean 0.23 and parameter ki is substituted by its mean value 222.5365.The raw data reported in Table 1, has an irregular range of values in the input and output parameters. Some are having the values below 1.0 and some are having values greater than or equal to 1.0. This kind of distribution will slow down the learning period and generalization of the system. Hence, the source data collected from P/M Lab is normalized to enhance the learning period of system. Before applying the soft computing tools, the raw data x is mapped as normalized data xnbetween 0 and 1, as given below:(23)Xn=Nmin+(X−minx)(Nmax−Nmin)(maxx−minx)where the minxand maxxare the minimum and maximum value of x respectively. Further, the Nmin and Nmax are the minimum and maximum value of normalized data respectively. Since the Nmin is zero and Nmax is one, the above equation is reduced to:(24)Xn=(X−minx)(maxx−minx)At the end of successful learning, to recognize the independent test samples, the post processing (De-normalization) is applied as given below to convert the normalized data into raw data.(25)X=(Xn+minx)(maxx−minx)In order to verify the de-normalized output while predicting the properties of composite preforms, the error is derived between the expected and actual value of the system. This error is measured in the form of correlation coefficient (R) and Average Absolute Relative Error (AARE) percentage as given in Eq. (26). The AARE% is used mostly in this paper since it is an unbiased term to measure the error accurately.(26)AARE%=Absolute(raw data−network output)raw data×100Also the reduction process mentioned in the Section 4.2, applies normalization with respect to the mean and standard deviation for a certain case.The raw data with 463 samples are collected as per the procedure stated in the Section 1. The raw data is pre-processed using the procedures of Sections 5.1.1 and 5.1.2. The raw data with 21 parameters is divided into two data sets, namely: training (350 samples) and testing (113 samples). Among 21 parameters, 10 parameters are considered as input and remaining 11 parameters are named as output parameters to represent the deformation and strain hardening properties of composite preforms. The network structure is fixed as x – 350 – 11, where the size of input layer x will be determined by the reduction process. The mining algorithm Section 4.1.2 is used to train the samples. The weight vector for this algorithm is initialized as random values between zero and one. The pure linear filter is selected for mapping input and output data and PR filter is used for mapping the input data of the hidden layer.The programming language C++ and the software package MATLAB 2010 were used to implement this work. MATLAB is a high-level technical computing language and interactive environment for algorithm development, data visualization, data analysis, and numeric computation. Using the MATLAB product, we can solve technical computing problems faster than with traditional programming languages such as C, C++, and Pascal.For implementing a Neural network, the object-oriented classes, namely input neuron, hidden neuron, output neuron and friend class namely ‘back’ were developed in C++. Each class has the necessary private data members to represent activation value, out value, error and weight information of each kind of neuron and also sufficient public member functions. The output neuron object includes additionally the desired or target value specified by the user. The friend class is a backbone of an entire architecture to map input to output. The data files were used to retrieve the information for the network and to transfer the network simulated results. In the client programme, three objects such as train object, validate object and test object were created to test the network training, validation and testing. Fuzzy code was developed using MATLAB.

@&#CONCLUSIONS@&#
The conclusions that can be derived from this soft computing modelling for this analysis are as given below:•PRNET developed in this work is capable of identifying the most meaningful parameters for RBFNN training and predicting deformation and strain hardening properties of Al–Fe composite preforms used in manufacturing divisions of the P/M Lab with proposed PR filter.Its predictability has increased by 67.89% relative from the conventional model even though the existence of highly non- linear interrelated and noisy raw data.Fuzzy logic helps to decide the range of input parameters for classifying the various properties of composite preforms.These Knowledge Based Systems developed using Soft computing tools will provide accurate and timely advice relating to the design and manufacture of powder metallurgy parts, even though the raw data are interrelated, non-linear, noisy and empty entries.They not only avoid expensive experiments, but also evade handling unsafe materials that cause severe damage to the environment.In future, this kind of soft computing models will be helpful for researchers to predict the characteristics of any kind of powder materials even for the nanocomposite preforms.