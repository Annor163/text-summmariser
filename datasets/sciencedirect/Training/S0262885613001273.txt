@&#MAIN-TITLE@&#
Spatiotemporal bag-of-features for early wildfire smoke detection

@&#HIGHLIGHTS@&#
We select key frames from a video and detect candidate blocks only in key frames.We prepare 3D spatiotemporal volumes by combining the candidate blocks.We introduce a new weighting scheme for generating a more reasonable BoF.The random forest classifier is built during the training phase by using the BoF.

@&#KEYPHRASES@&#
Wildfire smoke detection,Spatiotemporal feature,Bag-of-features,Histogram of oriented gradient,Histogram of oriented optical flow,Random forest,

@&#ABSTRACT@&#
Wildfire smoke detection is particularly important for early warning systems, because smoke usually rises before flames arise. Therefore, this paper presents an automatic wildfire smoke detection method using computer vision and pattern recognition techniques. First, candidate blocks are identified using key-frame differences and nonparametric smoke color models to detect smoke-colored moving objects. Subsequently, three-dimensional spatiotemporal volumes are built by combining the candidate blocks in the current key-frame with the corresponding blocks in previous frames. A histogram of oriented gradient (HOG) is extracted, and a histogram of oriented optical flow (HOOF) is extracted as a temporal feature based on the fact that the direction of smoke diffusion is upward owing to thermal convection. From spatiotemporal features of training data, a visual codebook and a bag-of-features (BoF) histogram are generated using our proposed weighting scheme. For smoke verification, a random forest classifier is built during the training phase using the BoF histogram. The random forest with the BoF histogram can increase the detection accuracy performance when compared with related methods and allow smoke detection to be carried out in near real time.

@&#INTRODUCTION@&#
As public interest in natural disasters increases, research on wildfire detection is gaining attention because wildfire is one of the major reasons for global warming and is resulting in not only extensive loss of life and property but also ecological problems. According to a survey report [1], an average of 586 wildfires occurs each year in South Korea, with damaged areas averaging 6620ha. Therefore, an early warning of wildfires is crucial to protecting the ecological environment and reducing the potential for casualties and property damage.Wildfire management requires large budgets and extensive human resources for prevention and suppression within private forests. In particular, it is not easy to monitor and control wildfires in remote areas. Therefore, the construction of a systematic, scientific, and integrated system for wildfire control with risk forecasting is necessary [1].With the rapid development of information technology, automatic wildfire detection has evolved to become a new research field. Wildfire detection can be divided into two research categories: smoke detection and flame detection. Smoke detection is particularly important for early warning systems, because smoke usually rises before flames arise. The conventional approaches to wildfire smoke use either infrared (IR) sensors that identify the heat flux of firelight or light detection and ranging (LIDAR) systems that measure the laser light backscattered by smoke particles. These types of smoke detectors are more common than others because they are better at detecting the smaller amounts of smoke produced by flaming fires. However, the optical sensors have limitations: they are expensive to manage and they generate many false alarms due to atmospheric conditions, light reflections, and the vast distance between the sensor and the burning point [2,3]. Moreover, because these sensors are point sensors and each covers a limited area, many sensors are necessary to cover a wide area. These sensors cannot provide additional information such as the locations of burning points, degree of smoke, and direction of burning.In contrast to optically based systems, visual sensors such as charge-coupled device (CCD) cameras that produce visible spectrum images have been used for several years to watch for wildfire. This is because a visual sensor has several advantages: it functions as a volume sensor and thus can monitor a wider area than an optical sensor, its equipment and management costs are lower, and it can provide the status regarding smoke without visiting the location.The conventional approach is to watch for signs of fire or smoke on a monitor using a camera that is installed atop a mountain. However, because this method needs many human participants, several recent studies [3–12] based on computer vision techniques have attempted to detect wildfire automatically so that dependable smoke detection results can be achieved.Detection using visual sensors is more difficult for wildfire smoke than for indoor or short-range smoke, because the main characteristics of wildfire smoke are low spreading speed, indistinct shape, vague color patterns, and constant uncertainty [3]. Therefore, we focus on developing a robust smoke detection algorithm by analyzing the indefinite characteristics of wildfire smoke. The main recent investigations are summarized below.Vicente and Guillemant [4] proposed an automatic system for early wildfire smoke detection consisting of two parts: In the first part, a temporal algorithm is performed at the pixel level and a spatial analysis is performed to insert connected pixels into the same envelope. The second part deals with a classification method for discriminating between distant smoke and various other phenomena.Krstinić et al. [5] presented a comparative evaluation of the histogram-based smoke classification methods. To find an efficient combination of color space and pixel-level smoke segmentation, several color space transformations were evaluated by measuring the separability of smoke and non-smoke classes. Then, they proved that good color spaces for smoke detection include HSI and its derivatives.Töreyin and Cetin [6] proposed a partitioned smoke detection algorithm using four sub-algorithms: 1) slow-moving video object detection, 2) gray region detection, 3) rising object detection, and 4) shadow elimination. These four sub-algorithms individually detect the presence or absence of smoke, and the decisions of the sub-algorithms are combined by an adaptive weighted majority algorithm.Ham et al. [7] proposed a fire-smoke detection method that analyzes temporal patterns in smoke and uses fuzzy finite automata (FFA). To consider the smoke characteristics over time, the temporal patterns of intensity entropy, wavelet energy, and direction of motion are used for generating multivariate probability density functions and FFA are applied for smoke verification. The proposed FFA comprise a set of fuzzy states (Very High, High, Low, and Very Low) and a transition mapping that describes what event can occur in which state and what the resulting state will be.Habiboglu et al. [8] used background subtraction and color thresholds to find the smoke-colored slow-moving regions in video. Candidate regions are divided into spatiotemporal blocks and correlation features are extracted from the blocks. Then, a binary support vector machine (SVM) classifier with spatiotemporal correlation descriptors is used to classify smoke-colored and non-smoke-colored objects.Genovese et al. [9] proposed an image processing system for the detection of wildfire smoke on the basis of computational intelligence techniques. The detection process focuses on the extraction of specific features such as the movement, color, and edge of wildfire smoke. Then, two-layer feedforward neural networks are used to estimate the areas that describe smoke regions in the different frames.Benazza-Benyahia et al. [10] proposed wildfire smoke detection by measuring the local fractal feature of smoke areas based on the discrete cosine transform. First, moving blocks are extracted as candidate smoke-containing areas. At the next stage, a candidate block is declared a smoke block if it has a roughness characterized by a specific range of the Hurst exponent.Stula et al. [11] presented the iForestFire system for protection against forest fires. To detect smoke with reasonably low error rates, several algorithms based on different visual characteristics of smoke are implemented one by one. Post-processing algorithms based on the merging of meteorological and video data are applied, and a decision about raising the alarm is made through voting based on the output of each detection algorithm.Ko et al. [3] proposed a wildfire smoke detection algorithm that uses spatiotemporal visual features and an ensemble of decision trees (i.e., a random forest). To detect wildfire smoke using a video camera, spatiotemporal characteristics such as the color, wavelet coefficients, direction of motion, and histogram of oriented gradient (HOG) are extracted from candidate blocks. Two different random forests are trained and tested using independent spatial and temporal feature vectors. This method yields good performance for a variety of smoke. However, it needs additional computation time because two classifiers are used.Even though early wildfire smoke detection is clearly important, detecting wildfire smoke is more difficult than detecting indoor or short-range smoke for the following reasons:•The main characteristics of wildfire smoke are low spreading speed, indistinct shape, vague color patterns, and constant uncertainty [3].The whirls and spirals typical of fluid behavior are not detectable, and many other details are lost [9].Smog, cloud, and fog have color and textural characteristics similar to those of wildfire smoke.In an initial study [12], we briefly introduced a wildfire smoke detection method based on a spatiotemporal bag-of-features (BoF) and a random forest classifier. However, in this study, we take steps toward more accurate wildfire smoke detection. First, we have analyzed more of the related work to reflect the current research trends in our system. Second, we change the color probability model to cover a wider range of smoke. Third, we change the structure of the ensemble trees of the random forest to improve the detection performance. Fourth, we propose a new weighting scheme for generating a more reasonable BoF. Fifth, we perform several experiments on the influence of codebook size for a BoF, the histogram binning for a BoF, the number of trees in a random forest for smoke classification, and the performance compared with that of other recent methods.In brief, the main contributions and overall procedures of our work are as follows:1.We select key frames from a video sequence and detect candidate blocks only in key frames rather than in every frame.We prepare 3D spatiotemporal volumes by combining the candidate blocks in the current key frame with the corresponding blocks in previous frames. A histogram of oriented gradient (HOG) is extracted from the current block as a spatial feature, and a histogram of oriented optical flow (HOOF) is extracted as a temporal feature based on the fact that the direction of smoke diffusion is upward owing to thermal convection.A visual codebook is built using a combination of the spatiotemporal features, and we introduce a new weighting scheme for generating a more reasonable BoF based on the visual codebook.The random forest classifier, which is an ensemble of decision trees, is built during the training phase by using the BoF histogram. The random forest with the BoF histogram can increase the detection accuracy and allow smoke detection to be carried out in near real time.The remainder of this paper is organized as follows: Section 2 describes the candidate smoke block detection algorithm as the first step. Section 3 introduces our feature extraction method using a spatiotemporal BoF. Section 4 introduces the smoke verification using a random forest classifier. Section 5 presents an experimental evaluation of the accuracy and applicability of our proposed wildfire smoke detection method. Section 6 presents our conclusions and discusses the scope for future work.One of the main characteristics of wildfire smoke is the relatively low apparent spreading speed, as the surveillance cameras are installed at vast distances. Therefore, a general frame difference, background subtraction, and optical flow calculation may fail to extract all smoke pixels or may generate false smoke regions due to a dynamic background. In this study, whenever the frame difference is over a certain threshold, we adopt the method of [3] to select key frames from a video sequence instead of using all frames.First, the input video sequences are divided into 32×24 blocks according to the aspect ratio in the MPEG standard, and all subsequent procedures are applied to these units. Because wildfire smoke has a relatively slow spreading speed unlike indoor smoke or moving object, a general frame difference cannot detect moving smoke regions effectively. Thus, to overcome this problem and distinguish wildfire smoke from moving object, key frames are selected from a video sequence using gray image whenever the frame difference is over a certain threshold (θ1) [3].(1)ifKframek−framei>θthenKframek+1=framei;k++;i++;elsei++;where the threshold θ has a lower value for slow wildfire smoke as it has a slower movement speed than indoor smoke. In this study, we set θ as 0.9% of the overall pixels as the same method of [3]. Using the new key frame Kframe [k+1] and previous key frame Kframe [k], a block (Bb) at position b in the current key frame is declared as a moving block using the following formula [3]:(2)Bb=1δKframekxyb,Kframek+1xyb0otherwisek≥1where δ(·)is the Kronecker delta function. This function returns “1” if the two corresponding blocks of key frames have difference, which implies a candidate smoke block and “0” otherwise.If the current frame has a significant frame difference from the previous key frame using Eqs. (1) and (2), we detect slow-moving blocks between key frames and then confirm the candidate blocks by using a smoke color model for real-time processing.In general, the smoke color is widely distributed in the RGB color space, depending on the burning material. However, it has been proved that the HSI color space can improve the accuracy of smoke detection over that of the RGB color space, because the HSI color space increases the differentiation between smoke and non-smoke [13]. Moreover, Ham [7] proved that smoke color in the HSI color space is distributed with a wide range of hue (H), a low level of saturation (S), and a high level of intensity (I). Thus, to remove non-smoke-colored blocks, we design the probability density functions (PDFs) of a smoke color using only S and I without H.The parameters of the PDFs are learned from training data. In typical supervised learning the underlying distribution functions are known [14], but smoke color does not follow a known distribution or parametric densities. Therefore, we construct the PDFs to have multimodal densities, rather than unimodal densities, by using a nonparametric method. In this study, we use a smoother kernel function in the form of a Gaussian in order to obtain the following smoother kernel density model:(3)px=1N∑n=1N12πh2d2exp−x−xn22h2,where N is the number of data and h is the parameter that determines the width of the effective Gaussian window in each dimension d. Once PDFs are generated, the likelihood of a pixel bj, denoted byp(bj|Smoke), can be estimated from the PDFs defined.Fig. 1shows the resultant PDFs for wildfire smoke. These PDFs are then used to configure real candidate blocks.From the PDF, a candidate block is determined on the basis of a pixel likelihood p(bj|Smoke) in a block (bi) using the following formula:(4)bi=10if∑j=1nIpbj|Smoke≥0.01>T1otherwisewhere I(·) is an indicator function. That is, I(·) returns unity if the argument equals or exceeds the minimum probability of 0.01, and zero otherwise. The adjustable parameter T1 determines the extent of candidate blocks. In this study, on the basis of several experiments, the most appropriate minimum threshold T1 was found to be 30% of the total number of pixels (n) included in a box. If the result exceeds the threshold T1, the block biis declared a candidate smoke block.Fig. 2(a) shows candidate smoke blocks after key-frame differencing. The blue blocks in Fig. 2(b) are the result of filtered non-smoke-colored blocks. Once the candidate smoke blocks are detected, the image is scanned to group the blocks into clusters based on block connectivity.Once candidate smoke blocks are detected, we extract an HOG for a spatial feature and an HOOF for a temporal feature. Then, we combine these two features into one feature vector, and we construct a BoF model in order to transform the feature vector into a BoF histogram owing to the simplicity, robustness, and good practical performance [15].Sparse spatiotemporal features have recently exhibited good performance in video-based action recognition [15–18]. To obtain a descriptor for interest points, the spatial feature and temporal feature are calculated for each spatiotemporal cube surrounding an interest point and concatenated to form a vector. This descriptor is then projected to a lower-dimensional space using a BoF model. In this study, we use candidate blocks that are selected from previous steps instead of from interest points.In a manner similar to that for action recognition in video, we first prepare 3D spatiotemporal volumes by combining the candidate blocks with t corresponding blocks in previous frames, as shown in Fig. 3. Each volume (Δx, Δy, Δt) has the same width and height, with candidate blocks (10, 10), and the time duration Δtis 100. From each volume, we compute the spatial appearance and temporal motion as the local spatiotemporal features, as shown in Fig. 3.For a spatial feature, an HOG is generated from the current block. Since the direction of smoke diffusion is upward owing to thermal convection, the gradient distribution of a smoke boundary has a distinguishable pattern. By using this characteristic, we extract an HOG as a spatial feature. In order to extract an HOG from a candidate block, gradient orientations are estimated at each pixel and a histogram of each orientation in a candidate block is calculated.For a temporal feature, an HOOF is generated from 100frames within the same volume. To generate the proposed HOOF, the optical flow is computed at every frame of the video. Each flow vector is binned according to its primary angle from the horizontal axis and weighted according to its magnitude [16]. The observed HOOF is the same histogram whether the smoke is moving from the left to the right or vice versa. Since smoke usually drifts continually upwards due to hot airflows, we estimate the direction of motion from the 100frames in each volume. The range of motion is discretized into nine directions including zero motion, and each discrete direction is binned according to magnitude. Then, all HOOF histograms are accumulated into one histogram and normalized to 0–1 using an L1-sqrt normalization step. The final dimension of the spatiotemporal feature is 18 (=9+9).After extracting a set of spatiotemporal features from training data, we construct a spatiotemporal BoF. Such BoF models have received much attention owing to their simplicity, robustness, and good practical performance [15]. A BoF is designed to represent each image by an orderless collection of local features calculated from a set of small sub-images called patches [19]. The feature descriptors of all patches are clustered using k-means clustering and each cluster is treated as a visual codeword. Then, a visual codebook that is composed of k visual words is built to describe a BoF using training descriptors. By mapping the local features of an image to the visual codebook, we can describe the image as a BoF histogram of the visual codewords according to the presence (or count) of each visual codeword [20].Given a random subset of volumes including smoke and non-smoke regions from the training set, the visual words are learned by performing k-means clustering. In our experiments, the size of the visual codebook was determined as k=100. The experimental results for deciding the appropriate number of codewords are described in Section 5.Once the visual codebook of the BoF is built, two kinds of BoF histograms should be estimated for the smoke and non-smoke classes. The BoF histogram assigns each feature to the closest visual word and computes the histogram of visual word occurrences over a spatiotemporal volume [21]. In general, the K-dimensional BoF histogram is estimated from patches by means of binary weighting, which indicates the presence or absence of a visual word by the values 1 and 0, respectively. All of the weighting schemes perform the nearest-neighbor search in the visual codebook, in the sense that each patch is mapped to the most similar visual word. However, binary weighting causes an aliasing effect on the BoF histogram, which may lead to sudden changes in the computed feature vector.Jiang et al. [20] proposed a soft-weighting approach to weight the significance of visual words. Instead of searching only for the nearest visual word of each patch in an image, they selected the N nearest visual words and assigned different weights according to the sum of distances. By using the soft-weighting scheme, they avoided the fundamental disadvantages of the conventional weighting schemes. This method uses a visual vocabulary of K visual words and a K-dimensional vectorT=[t1,…,tk,…,…tK], with each component tkrepresenting the weight of a visual word k such that(5)tk=∑i=1N∑j=1Mi12i−1simjk,where Mirepresents the number of patches whose ith nearest neighbor is visual word k. The measure sim(j,k) represents the similarity between patch j and visual word k.In spite of its good performance, soft weighting has three limitations. First, even if the nearest N patches have long distances from visual word k, they influence how much weight is placed on visual word k because of the factor 1/2i−1. Second, even if the nearest N patches have similar short distances from visual word k, the lower-order patches give relatively low weight to visual word k regardless of the similarity. Third, this method needs additional memory because every visual word has to memorize the order of all nearest patches.To solve the first problem of soft weighting, three steps are taken. First, we set the number of nearest visual words to N like in soft weighting but define the minimum threshold to control the number N. Therefore, the number N can be changed, depending on the visual distance. Second, our method estimates the weight using only the visual distance itself, regardless of the order of nearness. Third, each patch memorizes only the N nearest visual words, regardless of the order. Each patch will therefore contribute not only to its visual word k of a BoF histogram but also to a maximum of N neighboring visual words.Suppose that we have a visual vocabulary of K visual words and we use a K-dimensional BoF histogram. The proposed weighted BoF histogram is generated as follows:(1)Set all components of the K-dimensional BoF histogram T=[t1,⋯,tk] to zero.Each component tkrepresents the weight of a visual word k in image I.Extract a patch P from an image I.Compute the L1-distance D between P and the visual words V by using the following formula:(6)Di=1…k=P−vi.Sort distances Di=1…kin ascending order and find visual word vi∈V that has a distance below the minimum threshold T2by searching from higher order to lower order:(7)NearV=vi|Di=1…k<T2.i=0while (i≤N or visual words exist in a set Near (V)), do(5-1)Add the contribution of P to the component of tkcorresponding to Di:(8)ti=ti+WDi.The weighting function W(·) for the distance Diis chosen to obey the following exponential weighting scheme:(9)WDi=1expF⋅Di,F>0.i=i+1End.In the above, the minimum distance threshold (T2) is selected as the median value betweenT2∈miniDiandT2∈maxiDi. In addition, a weighting factor F can be chosen to maximize (minimize) the influence of Dion W(·). When F equals 1, a change in Diwill be exponentially reflected in W(·). The exponential weighting is more sensitive to changes in local feature relevance and gives rise to a greater performance improvement [22]. In this study, we set F at 0.5 in accordance with experiments.Fig. 4shows the overall procedure for generating a BoF histogram. Then, BoF histograms generated from training data are used for learning a random forest classifier as shown in Fig. 4(d).As opposed to previous heuristic methods and simple pattern classifiers for smoke verification, this study uses a random forest classifier [23] to determine whether the candidate smoke clusters represent real smoke. Recently, the random forest has been employed in many computer vision applications such as action recognition [24], human detection [25], image retrieval [26], and smoke detection [3]. A random forest is a decision tree ensemble classifier, with each tree grown using some type of randomization. Random forests have a capacity for processing large amounts of data with high training speeds. The structure of each tree in the random forest is binary and is created in a top-down manner, as shown in Fig. 4(d).In general, a random forest with Tntrees is trained offline from the database. Once a training set is collected from the training data, the random forest is started by choosing a random subset I′ from the training data including the local BoF histograms I and placing that at the root node. At node n, the training data Inis iteratively split into left and right subsets Iland Irby using Eq. (10) with the decision threshold t and the splitting function f(vi) for the feature vector v. The threshold t is randomly chosen in the rangeT3∈minifvi,maxifviby the splitting function f(vi) [23].(10)Il=i∈In|fvi<T3,Ir=In\Il.The growth for training one decision tree of a random forest continues within the maximum tree depth. After decision tree T is completed, each training datum must correspond to one of the leaf nodes k. To assign a class label ciat each leaf node k, we count the number of samples in a leaf node and assign a class that has a higher frequency:(11)k=argmaxiPci|T.There are two conditions that can end the iterative training. The first condition occurs when no more information gain is possible. From among the candidate thresholds for each spit function, the candidate threshold T3 that maximizes the gain in information about the corresponding node is selected. The information gain, ∆E, is defined at each spit node as follows:(12)ΔE=−IlInEIl−IrInEIrwhere E(Il) and E(Ir) are the entropies of subclasses Iland Irin the set of training data and Indenotes the total input data at the splitting node. The second condition occurs when the training process reaches a leaf node that is at the maximum depth of the tree. We set the maximum tree depth at 20 according to the experiment of [27].Once the individual decision trees are trained, the ensemble of trees is assembled into a random forest classifier as shown in Fig. 4(d). The number of trees T is set to 60, which has been shown empirically to yield good results and computation times comparable with those for related methods. The experimental results used to decide the appropriate number of trees and compare the processing times are described in Section 5.Once the random forest classifier has been learned, the BoF histogram of the test blocks is created and is distributed into the trained random forests. Then, each feature corresponds to one leaf of a decision tree in the random forest. In order to compute the final class distribution, we sum the probabilities of all trees, L=(l1, l2,…, lr), as follows:(13)Pci|L=1Tn∑t=1TnPci|ltwhere Tnis the number of trees. We choose cias the final class of an input feature if p(ci|L) has the maximum value.In Fig. 5, the test block is placed into the smoke class because that has the maximum posterior probability.

@&#CONCLUSIONS@&#
