@&#MAIN-TITLE@&#
Sample size estimation in diagnostic test studies of biomedical informatics

@&#HIGHLIGHTS@&#
Sample size calculation in diagnostic studies.Tables of required sample size in different scenarios.How sample size varies with accuracy index and effect size.Help to the clinician when designing ROC diagnostic studies.

@&#KEYPHRASES@&#
Diagnostic studies,Sample size,Sensitivity,Specificity,ROC analysis,Area under the curve,

@&#ABSTRACT@&#
ObjectivesThis review provided a conceptual framework of sample size calculations in the studies of diagnostic test accuracy in various conditions and test outcomes.MethodsThe formulae of sample size calculations for estimation of adequate sensitivity/specificity, likelihood ratio and AUC as an overall index of accuracy and also for testing in single modality and comparing two diagnostic tasks have been presented for desired confidence interval.ResultsThe required sample sizes were calculated and tabulated with different levels of accuracies and marginal errors with 95% confidence level for estimating and for various effect sizes with 80% power for purpose of testing as well. The results show how sample size is varied with accuracy index and effect size of interest.ConclusionThis would help the clinicians when designing diagnostic test studies that an adequate sample size is chosen based on statistical principles in order to guarantee the reliability of study.

@&#INTRODUCTION@&#
Biomedical informatics deals with health information, its structure, acquisition and use in health care and medical practices [1]. It includes health research, education, and health services, clinical disciplines and health care and information systems that ranging from theoretical model to the building and evaluation of applied diagnostic systems [1]. A specific of its domain is the evaluation of biomarkers and diagnostic systems for classification of diseased from healthy subjects to make a decision in clinical practices [1–4]. The bioinformatics markers/systems in medicine have been developed progressively during the past decades. Primarily, in order to apply the new developed biomarkers/systems for decision in clinical practices and to extract extra useful information from them, they should be evaluated in experimental setting versus a gold standard [4–6]. The collecting experimental data of gold standard is often expensive and time consuming. Thus, the evaluation of classification performance of bioinformatics systems needs annotated training sample since the predictive power in detection difference between two alternative classifiers strongly depends on sample size [7,8]. In estimating the diagnostic accuracy and to obtain a desired level of statistical power to detect an effect size for testing a single modality or a comparative study of two diagnostic tasks in order to know which has a greater diagnostic ability of certain target classification performance, the investigators need to know the minimal sample size required for their experiments. On the other hand, if the experiments are done on with available samples only, the investigators need to know the power of statistical test for detection a desirable effect size in their experiments.However, the receiver operating characteristic (ROC) analysis used in diagnostic medicine for continuous biomarkers in classification is rather complex with no single approach for analysis [3–6]. Also, there is no single measure of accuracy index in evaluating diagnostic tools for decision support and how to estimate the sample size needed for proposed experiment. All depend on specific application and design used in biomarker experiments. This paper provides the sample size calculation for estimating and testing of accuracy indexes. We included different accuracy indexes with various types of experimental design for single diagnostic test and comparative study of two diagnostic tasks both independent design and matched paired design. First we briefly described some examples of relevant biomedical informatics research and then we addressed the relevant diagnostic accuracy and the main concept of ROC analysis in diagnostic studies and it was followed with review of sample size calculation.There are several examples of the use of ROC curve analysis in bioinformatics medicine. A large number of computer diagnostic systems have been developed to advise physician on patient diagnosis and management. For example, recently a text classifier model for high quality article retrieval in internal medicine [9] and an automated text classifier to detect radiology report have been evaluated in ROC analysis [10]. In another study, several least square vector machines for prediction of preoperative malignancy of ovarian tumors have been developed and assessed [11]. In particular, a study was designed to evaluate a compute based algorithm for diagnosis of heart disease (HD) in order to provides useful information that can improve the cardiac diagnosis in a typical clinical setting [12]. In this study, 127 patients were entered in two cohorts of 60 and 67 subjects. The follow up information was available on 114 subjects with mean age of 60years for their future cardiac problem for final diagnosis as gold standard. The heart disease program (HDP) algorithm was designed to assist physician in diagnosis of HD, in particular, condition leading to homodynamic dysfunction and heart failure. This diagnostic algorithm is based on casual probability in term of severity of necessary causes and the possible mechanism and the risk profile. The program uses the input data to specialize the patient profile including a set of prior probability of disease based on demographic characteristics and risk profile and to put a set of assumption and to compute the risk score. The authors wished to compare the diagnostic performance of physician alone and heard disease program (HDP) alone with combination of physician and HDP in prediction of cardiac problem. They used sensitivity and specificity and also ROC curve analysis but in their ROC analysis, comparison of different diagnostic tasks was done with descriptive method regardless of performing statistical test. However, it is most helpful to justify the required sample size. The question would be raised whether the achieved sample size has power to detect a desirable effect size of accuracy index and how to calculate the optimal sample size for their study. In addition, the power calculation would be helpful in interpretation of lack of difference between diagnostic tasks with achieved sample size. These questions are also relevant for any other ROC diagnostic studies in bioinformatics research.In diagnostic studies of biomedical informatics which the test yields dichotomized outcome (positive or negative results), the accuracy is evaluated by sensitivity and specificity. These two measures determine the inherent ability of diagnostic test versus a dichotomized gold standard and they are not influenced by prior probability of disease (or prevalence) in population [2,4]. The gold standard may be another test without errors but a more expensive diagnostic method or invasive method. It can be the combination of tests that may be available in clinical follow up, surgical verification, autopsy, and biopsy or by panel of experts [5,6]. The sensitivity indicates the proportion of diseased subject with positive test result and specificity determines the proportion of nondiseased subject with negative test results. The sensitivity and specificity can be combined as one-dimensional index that is called likelihood ratio (LR). The positive LR is the ratio of probability of positive test in diseased to nondiseased and negative LR is the ratio of probability of negative test in diseased to nondiseased. In fact, the positive LR is the ratio of sensitivity to 1-specificity and the negative LR is the ratio of 1-sensitivity to specificity [13]. The higher value of positive LR corresponds with greater information of positive test result while the lower value of negative LR associates with more information of negative test results. In particular, the positive and negative LR is of greater interest in comparative studies of two diagnostic tests.For a quantitative diagnostic test or the test results are recorded on ordinal scale, the sensitivity and specificity varies across the different thresholds and the sensitivity is inversely related with specificity [2,4,14]. Then, the plot of sensitivity versus 1-specificity is called receiver operating characteristic (ROC) curve and the area under the curve (AUC), as an effective measure of accuracy has been considered and it has a meaningful interpretations [15]. This curve plays a central role in evaluating diagnostic ability of tests to discriminate the true state of subjects and comparing two alternative diagnostic tasks when each task is performed on the same subject [5,14–16].In evaluating the accuracy of diagnostic test in medicine, the sample size plays an important role either for estimation or testing of accuracy. A small sample size produces an imprecise estimate of accuracy with wide confidence interval [17] which is non-informative for decision makers in medical context. On the other hand, unduly large sample size is wastage of resources especially when the new diagnostic test is expensive [18]. Unfortunately, sample sizes calculations are rarely reported by clinical investigators for diagnostic studies [19,20] and few clinicians are aware of them. Researchers often decide about the sample size arbitrary either for their conveniences or from the previous literature. For example, among 40 (out of 1698 articles) published studies on non-screening diagnostic accuracy in five higher impact factors of ophthalmology journal in 2005, only one study (2.5%) reported a prior sample size calculation for a planned sensitivity and specificity of 80% and 95% confidence level [19]. Another report of eight journals published in 2002, 43 articles (out of 8999 articles) were non-screening on diagnostic accuracy and two of 43 studies (5%) reported a prior calculation of sample size but no study reported that the sample size had been calculated on the base of pre-planned subgroup analysis while twenty articles (47%) reported results for subgroup of patients [20].In sample size calculation for estimating both sensitivity and specificity, Buderer [21] incorporated prevalence of disease in sample size formula for sensitivity/specificity and provided the table of sample size for sensitivity and specificity but only for precision of 10%. Malhotra and Indrayan [18] argued that the sample size without considering prevalence would be adequate for sensitivity or specificity alone but not for both while Obuchowski [22] addressed that this is because of unknown true disease status at time of sampling from target population. Charley et al. [23] have provided monogram for estimation of sensitivity and specificity with too many lines and curves make complexity in reading. Malhotra and Indrayan [18] presented a table of sample size calculation based on Borderer formula only for estimating sensitivity and specificity but not for testing. Simel et al. [24] deal with sample size based on desired likelihood ratios (LR) confidence interval but not calculate sample size for a wide range of marginal errors around LR. Obuchowski [22] also provided a review of sample size formula for a various diagnostic accuracy but did not provide practical tables for calculating sample sizes. Several other authors also developed methods for sample size calculation in diagnostic medicine [25–28] because of complexity of their methods for clinician and the lack of availability of software their methods were not used frequently in clinical practices. In this article, a review of the critical elements of sample size calculations for diagnostic accuracy were addressed conceptually and the formula was driven based on statistical principles with respect to study purpose (estimation or testing) and accuracy of interest (sensitivity/specificity, LR and AUC). We also calculated the required sample size for various situations and the calculated sample size were tabulated for practical convenience of clinician in diagnostic test evaluation.Based on statistical principle, as a general rule of sample size calculation for proportions, since sensitivity (or specificity) is a proportion, it is intuitively appealing that the four essential elements are required for calculation of sample size in estimating sensitivity (or specificity): (1) a pre-determined value of sensitivity (or specificity) that is available from previous published studies or clinical judgment; this is because the standard error of sensitivity (or specificity) depends on its value; (2) the confidence level (1−α) for statistical judgment where α is the probability of type I error; (3) the precision of estimates of sensitivity (or specificity) i.e. the maximum difference between estimated sensitivity (or specificity) and the true value. Additionally, the prevalence of disease in population is needed to be ascertained and also to be taken into account in sample size calculation [21]. In effect, we are planning for the number of affected subjects and the number of unaffected subjects separately, so we need a total number of subjects that will make both these groups large enough. In practice usually it is the sensitivity, not the specificity that determines the total number of subjects to be used. When the true status or condition is known before undergoing subjects into new diagnostic test, no longer the prevalence is incorporated into sample size calculation for sensitivity/specificity [22]. For the purpose of testing, instead of third element, the difference of sensitivity (or specificity) under the null and alternative hypothesis is required (i.e. the maximum difference to be detected in statistical test with power of 1−β where β is the probability of type II error). Thus, the power of statistical test (the compliment of type II error) should be considered the prior sample size calculation. As a general rule, with higher precision (i.e. the lower marginal error: the half wide of confidence interval) in estimating accuracy and detecting a small difference of effect in testing of accuracy with higher power, a greater sample size is required.First, assume we wish to determine the number of cases to estimate sensitivity (Se) of new diagnostic test. Similarly, one may estimate specificity (Sp). Since sensitivity (or specificity) is a proportion, for estimation of sensitivity (or specificity) alone when the diseased status is known, the formula for sampler size with (1−α)% confidence level and with maximum marginal error of estimate of d for constructing confidence interval of true value of sensitivity (or specificity) using normal approximation is driven as follows:(6.1)n=Zα22P^(1-P^)d2whereP^is pre-determined value of sensitivity (or specificity) that is ascertained by previous published data or clinician experience/judgment and for α=0.05,Zα2is inserted by 1.96. This is an estimate of sample size for sensitivity or specificity alone when the true condition of disease status is known. Buderer [21] incorporated the prevalence of disease in formula for sample sizes calculation when the true disease status is not known at the time of sampling. This might occur in prospective study when consecutive subjects undergoing the test are used as samples [22]. In practice, the clinicians would like to estimate the number required both in sensitivity and specificity within a study population containing cases and controls. In this situation, to ensure the study sample which the test will be applied is a representative of study population, the proportion of cases and controls should be taken into account by the prevalence of the disease in population.Lets ncases, ntotal (cases and control) and Prev denote the number of cases, the total sample sizes (cases and control) and the prevalence of disease respectively, then based on sensitivity, the overall sample size (both cases and controls) is(6.2)ntotal=ncasesPrevIn fact, if one divides the right hand side of Eq. (6.1) by the prevalence of disease in target population, it gives the total number of subjects (cases and controls) need for sensitivity. The required sample size of specificity is estimated by dividing the right hand side of Eq. (6.1) by (1-prevalence) that gives the total subject for specificity. Then, if one is interested for both sensitivity and specificity, the largest value of two calculated total sample sizes will be considered as total study samples.If one knows the ntotal and ncases, one can simply calculate the number of control that is needed to estimate specificity of new diagnostic test as follows:(6.3)ncontrols=ntotal-ncases=ntotal(1-Prev)Thus, based on specificity(6.4)ntotal=ncontrols1-PrevSimply one can drive the proportion of cases to controls as follows(6.5)ncasesncontrols=Prev1-PrevThus, the total sample sizes based on sensitivity and specificity respectively are(6.6)nSe=Zα22Se^(1-Se^)d2×Prev(6.7)nSp=Zα22Sp^(1-Sp^)d2×(1-Prev)For α=0.05,Zα2is inserted by 1.96;Se^,Sp^, and Prev are the pre-determined values of sensitivity, specificity and prevalence of disease respectively and d as the precision of estimate (i.e. the maximum marginal error) is pre-determined by clinical judgment of investigators.For example, if the Se is primary interested in diagnostic screening purpose and lets the pre-determined values of Se and prevalence of disease as 80% and 10% respectively. In order the maximum marginal error of estimate does not exceed from 7% with 95% confidence level, the total required sample size can be driven by plugging the above values in Eq. (6.6) as follows:nSe=1.962×0.8×0.200.072×0.10=1254In Section 8 (Tables 1 and 2), we calculated and tabulated the required total sample sizes with various values of Se, Sp, Prev and marginal errors.Obviously, the formula based on sensitivity and specificity yield a similar sample size at prevalence of 0.5. With low prevalence, the required sample size based on sensitivity is much higher than that of specificity while the prevalence of diseased becomes more than 0.50 which is less intuitive appealing, the sample size based on sensitivity lower than that of specificity. In practice, clinicians may be guided first to calculate the number of cases based on sensitivity and then uses Eq. (6.5) to estimate the number of controls but our thought intuitively hints that first the maximum total number of subjects based on sensitivity and specificity should be taken into account and then the number of cases (or controls) be calculated based on Eq. (6.5).Alternatively, Li and Fine developed sample size for sensitivity and specificity in prospective studies when disease status may not be known at the time of enrolment since the gold standard applied at pre-determined time after initial screening. They developed a formal method of sample size calculation based on unconditional power property of statistical test [26].Suppose P0 denote the pre-determined value of sensitivity or specificity of new diagnostic test. In comparing the test’s accuracy to fixed value of P0, the null and alternative hypothesis isH0:Se=P0versusH1:Se≠P0(orSe=P1)where P1 is the value of sensitivity (or specificity) under alternative hypothesis. A general sample size formula for comparison of proportion with fixed value can be applied for evaluation of single diagnostic test. With (1−α)% confidence level and (1−β)% power for detection an effect of P1−P0 using normal approximation as a general rule, Z-score under the null and alternative hypothesis can defined and thus the required sample size for cases is driven as follows:(6.8)n=Zα2P0(1-P0)+ZβP1(1-P1)2(P1-P0)2whereZα2and Zβdenote the upperα2and β percentiles of standard normal distribution and α, β are the probability of type I and type II errors respectively. For α=0.05 and β=0.20, they are inserted byZα2=1.96and Zβ=0.84 respectively. In this paper, we used consistently two side tests instead of one side test in our sample size calculation; for one side test Zαand Zβshould be used.For example, an investigator compares H0: Se=0.70 versus H1: Se≠0.70. The sample size one would need to have 95% confidence and 80% power to detect a difference of 10% from presumption value of Se=70%, can be calculated by plugging in the above information in Eq. (6.8) as follows:n=(1.96×0.70×0.30+0.84×0.80×0.20)2(0.10)2=153In Eq. (6.8), one may argue that why the prevalence was not appeared in the formula. As we already mentioned since the true status of disease is know in comparative situations. Therefore, the prevalence is not relevant for sample size calculation in this condition.A general formula of sample size calculation for comparing two independent proportions can be used to estimate sample size for studies comparing sensitivity and/or specificity of two tests of unpaired design. In comparing the diagnostic accuracy of two alternative tasks for two independent samples, suppose P1 and P2 denote the expected proportion (Se or Sp) of two alternative diagnostic tests respectively. For testing hypothesis: H0: P1=P2 versus H1: P1≠P2, the required sample size with equal size based on normal approximation of binomial data with 1−α confidence level and 1−β power is(6.9)n=Zα22×P‾(1-P‾)+ZβP1(1-P1)+P2(1-P2)2(P1-P2)2whereP‾the average of P1 and P2 and Zα, Zβis are the standard normal Z values corresponding to α and β (the probability of type I and type II errors respectively).Suppose, one wishes to compare the Se of two alternative diagnostic tasks H0: P1=P2 versus H1: P1≠P2. The sample size would one need to have 95% confidence and 80% power to detect a difference of 10% from a Se of 70% (i.e. P1=0.70, P2=80% andP‾=0.75) can be calculated by inserting this information in Eq. (6.9) as follows:n=(1.96×2×0.75×0.25+0.84×0.70×0.30+0.80×0.20)2(0.10)2=293Epi info software can be used to perform these calculations and to estimate the required sample size for proportion. Also the approach can be extended for paired designs when multiple tests are performed on the same subjects, then the proportion (Se or Sp) should be considered as dependent. Beam [29] presented formulae for calculation of sample size for paired designs; he has also written a program in FORTRAN for calculation of sample sizes. To avoid the increased complexity of this text for clinician, we referred the interesting readers to previously published papers [29–32].As we described when test yields positive or negative results, sensitivity and specificity are the two inherent indexes of accuracy. One may estimate sample size based on one of these two indexes regarding preference of researcher either uses sensitivity or specificity as primary of interest but LR that combines the sensitivity and specificity of test as uni-dimensional index, is a greater of interest. A test with higher LR+ has a greater value of rule in the disease while a test with lower value of LR− has a higher value of rule out disease. These two indexes are particularly interesting in comparative studies of two or multiple tests. The test with greater value of LR+ and lower values of LR− has more diagnostic abilities in the classification of true status of diseased and nondiseased. Thus, positive LR and negative LR play an important rule for clinical decision and they can be used in estimating sample size in diagnostic test. Simel et al. [24] proposed the confidence interval of positive LR (or negative LR) to be used for sample size estimation. For example, a clinical investigator wishes to calculate sample size where the LR+ is greater from a pre-determined value of LR with (1−α)% confidence interval (i.e. a pre-determined value lies within the confidence bound with (1−α)% confidence level.SupposeP^1andP^2denote the sensitivity and 1-specificity of a test respectively and n1 and n2 denote the sample size for diseased and nondiseased. The ratio estimator ofLR+=P^1P^2is skewed and the logarithm transformation can be used to convert its distribution to normal approximately. Thus, logP^1P^2can be assumed that asymptotically normally distributed with standard error of1-P^1n1P^1+1-P^2n2P^2and therefore (1−α)% confidence interval for log(LR+) is as follows:(6.10)log(LR+)=logP^1P^2±Zα21-P^1n1P^1+1-P^2n2P^2With the presumption of equal sample size for diseased and nondiseased (i.e. n1=n2=n), then the required sample size for each group of cases and controls can be calculated by solving the Eq. (6.10) as follows:(6.11)n=Zα21-P^1P^1+1-P^2P^22log(LR+)-logP^1P^22For example, an investigator wishes to estimate the sample size of a study where LR+ has more valuable when LR+⩾2. Given the result of pilot study, sensitivity=0.8 and specificity=0.7 and thusLR+=Se1-Sp=2.96. For sample size calculation, we substituted LR=2 for lower bond of confidence interval. With the presumption of equal sample size for diseased and nondiseased (i.e. n1=n2=n), then the required sample size can be calculated by solving the following equation:(6.12)2=explog0.80.7-1.961n0.20.8+0.70.3n=74 for each group and thus, the total sample size would be 148. With these sample sizes the investigator 95% of time to be confident that positive LR is greater than 2 (i.e. the LR of 2 lies below the lower bound of 95% confidence interval). One also can assume the ratio of r for controls (n1) to cases (n2), then n2=r×n1. By replacing r×n1 instead of n2, the solution of Eq. (6.10) yields sample size for cases (n1).In another condition, a diagnostic test may be useful, if negative LR is lower than a pre-determined value. Then, the sample size would be calculated based on the confidence bond of negative LR. Similarly, one could drive a confidence interval for LR− as follows:(6.13)log(LR-)=logP^1P^2±Zα21-P^1n1P^1+1-P^2n2P^2whereP^1=SpandP^2=1-Se.For example, from a clinical point of view, a test is useful when the maximum value of negative LR about 0.4 and from literature review Se=0.9 and Sp=0.5. With presumption of n1=n2=n, the required sample size is calculated by solving the following equation with respect to n,(6.14)log0.4=log0.90.5+1.961n0.90.1+050.5Thus, n=80 for each group and total sample size is 160.So far, we discussed sample size calculations when the test yields a binary outcome. As we addressed already, for a quantitative test or the test results are recorded on ordinal scale, ROC curves show the trade off between sensitivity and specificity and the area under the curve (AUC) is considered as an index of accuracy. The AUC can be estimated parametric (binormal model) and nonparametric (Wilcoxon statistic) approaches. Both approaches allow estimating the sampling variability of AUC. In diagnostic studies, involving ROC analysis, for the purpose of estimating or testing AUC, the clinicians should decide the number of patients and controls needed in study protocol. Suppose a clinical researcher wishes to estimate the diagnostic accuracy as defined by AUC in which the marginal error of estimate (i.e. the difference between true AUC and its estimate) does not exceed from a pre-determined value of d with (1−α)% confidence level (e.g. 95%). Using normal approximation in constructing confidence interval for AUC, we have(7.1)Zα2SE(AUC^)⩽dBy squaring two sides of equation, then(7.2)Zα22Var(AUC^)=d2LetsV(AUC^)=nVar((AUC^). Thus, the required sample size for each group of nondiseased and diseased is(7.3)n=Zα22V(AUC^)d2The variance ofAUC^denoted as Var(AUC^) can be estimated can be estimated parametrically based on binormal assumption [22,33,34] (see Appendix B) or exponential approximation using Hanley and McNeil formula [15] (see Appendix A).In numerical results that we produced the required sample size in Section 9, we used binormal based variance of AUC as described in Appendix B and we assumed n1=n2=n. Thus, the V(AUC) can easily be driven from Eq. (A3) (see Appendix B) as follows:(7.4)nVar(AUC^)=V(AUC)=(0.0099×e-a2/2)×(6a2+16)where a=φ−1(AUC)×1.414 and φ−1 is the inverse of standard cumulative normal distribution.For example, Suppose, the pre-determined value of AUC=0.70, in order to estimate AUC with 95% confidence the degree of precision of estimate about 0.07, the required sample size can be calculated as follows:For estimating V(AUC), first one should calculate a=φ−1(0.70)×1.414=0.741502 and then, V(AUC) can be calculated using Eq. (7.4) as:V(AUC)=(0.0099×e-0.7415022/2)×(6×0.7415022+16)=0.145136Therefore, the required sample size is obtained by inserting the V(AUC) and d=0.07 in Eq. (7.3) as follows:n=1.962×0.1451360.072=114Alternatively, the pure nonparametric method was proposed by Delong et al. [35–37] (see Appendix C). This method is based on structure components of individual based data which we called as pseudo accuracies for both diseased and nondiseased subjects. Hanley and McNeil formula [15] is a convenient method for estimation of SE of AUC that only depends on estimate of accuracy index (AUC) but it does not consider the ratio of standard deviation of nondiseased to diseased populations. While the normal based standard error is more flexible to consider the ratio of two standard deviations [33]. Both formulae take into account the ratio of controls to cases. Obuchowski [33] reported that Hanley and McNeil method underestimate the SE of AUC for rating data but not for continuously distributed data while the normal based standard error is more flexible to consider the ratio of two standard errors produces a conservative estimate of SE In a Monte Carlo simulation studies with continuously distributed data, Hajian-Tilaki and Hanley [38] showed that overall the three methods of SE of AUC (binormal model, exponential approximation and Delong’s method) worked well in reflecting actual variation for various configurations of nonbinormal data while for bimodal data, the binormal estimator of SE produces as more conservative estimate of SE than others.Assume a clinical researcher may wish to test the accuracy (AUC as unknown parameter of interest) of a new diagnostic method with a pre-specified value of AUC0. The null and alternative hypothesis isH0:AUC=AUC0versusH1:AUC≠AUC0(i.e.AUC=AUC1)Using the normal approximation, the required sample size for each group of cases and controls (assuming the ratio of cases to controls is one) in detecting an effect of δ=AUC1−AUC0 with (1−α)% confidence level and (1−β)% power is as follows(7.5)n=Zα2VH0(AUC)^+ZβVH1(AUC)^2[AUC1-AUC0]2whereV(AUC^=nVar(AUC^).VarH0(AUC^)andVarH1((AUC^)denote the variance ofAUC^under the null and alternative hypothesis respectively.In comparative study of two diagnostic tasks in the context of ROC analysis, for example, a clinical investigator has a plan to compare the accuracy of MRI and CT in detecting abnormal condition. The accuracy of these two diagnostic tasks is determined by AUC and the same subjects are undergoing two alternative tasks for the purpose of efficiency of design for the assessment of conditions. Let AUC1 and AUC2 are the true two diagnostic accuracies for the two diagnostic modalities respectively. The null and alternative hypothesis areH0:AUC1=AUC2versusH1:AUC1≠AUC2The investigator wants to decide how many cases and controls are needed to detect an effect between two diagnostic tasks as defined by δ=AUC1−AUC2 under alternative hypothesis with (1−α)% confidence level and (1−β)% power. By constructing confidence interval for parameter of interest AUC1−AUC2 using normal approximation under the null and alternative hypothesis, then the required sample sizes for each group are driven as(7.6)n=Zα2VH0(AUC^1-AUC^2)+ZβVH1(AUC^1-AUC^2)2[AUC1-AUC2]2where(7.7)V(AUC^1-AUC^2)=nVar(AUC^1)+nVar(AUC^2)-2nCov(AUC^1,AUC^2)In Eq. (7.6), theVar(AUC^1-AUC^2)needs to be estimated under the null (H0) and alternative hypothesis (H1). In a case, two diagnostic tasks do not apply on the same subjects, then the two AUC’s are independent and the Eq. (7.6) can be written as:(7.8)n=Zα22VH0(AUC^)+ZβV(AUC^1)+V(AUC^2)2[AUC1-AUC2]2where the AUC under the H0 is the average of AUC1 and AUC2.For example for detection of 10% difference in estimating two independent diagnostic systems with 95% confidence and 80% power, assuming AUC1=0.70 and AUC2-AUC1=0.10 using binormal based variance of AUC as described in Section 7.1, on could easily calculate V(AUC)H0=0.13480; V(AUC1)=0.14513; V(AUC2)=0.11946. Then the required sample size for each task with 80% power and 95% confidence for detection 10% difference in accuracy index (AUC) using Eq. (7.8) asn=[1.96×2×0.1348+0.84×0.14513+0.11946]2(0.10)2=211In the following Section 9, we also calculated the required sample sizes in different situation of AUC and effect size and it is tabulated in Table 7 for two independent AUC.TheVar(AUC^1)andVar(AUC^2)can also be estimated using Hanley and McNeil formula [15] but it does not gives the covariance between two correlated AUC’s. While the advantage of Delong’s method [35,36] is that the covariance between two correlated AUC’s can be estimated from its components of variance and covariance matrix as well. In addition, CORROC software (Metz Software) also estimates the covariance between the two correlated AUC’s in parametric approach of comparative study of two diagnostic tasks [39].(7.9)Cov(AUC^1,AUC^2)=rSE(AUC^1)·SE(AUC^2)where and SE denote the correlation between the two estimated AUC’s and the standard error (i.e. the square root of variance) of estimate of AUC’s respectively. If the two diagnostic tasks are not examined on the same subjects, the two estimated AUC to be independent and thus the covariance term will be zero. The investigator may assume the ratio of sample size for the controls to the cases to be as R. Then, the sample size can be estimated for each group with this ratio.Although AUC as an overall accuracy index is admired as robust index with meaningful interpretation and primarily interesting in diagnostic accuracy, in comparing of AUC from two diagnostic tasks when two ROC curves crossing each other, this overall index may be not useful. The partial area at clinical relevant of false positive and true positive fraction at specific false positive rate (TPFFPF) are the two other indexes of accuracy that had been considered in ROC analysis. The methods have been developed for sample size calculations of partial area and TPFFPF[22]. In addition, ROC studies in particular for rating data may be involved with multiple readers. Obuchowski provided tables of calculated sample size for multiple reader studies. The interesting readers are referred to some published articles in this area [22,40].We calculated sample size using Excel software (Windows office 2007) for purpose of estimating of different diagnostic accuracies (sensitivity, specificity, LR and AUC) and of testing as well, assuming the ratio of sample sizes for cases and controls to be one. We provided tables of required samples for combinations of various conditions. In particular, for estimating and testing of AUC in single modality and comparative study of two correlated and independent accuracy index (AUC), we used binomial based variance with standard ratio of one. For the two correlated AUC when the two alternative tasks are applied on the same subject, we assumed the correlation of 0.5. A correlation between two accuracies close to this value was reported by Rockette et al. [41]. Obviously, if the different samples of patients underwent the two different diagnostic tasks, then the correlation would be zero. We examined the required sample sizes with a wide range of accuracy indexes from 0.60 to 0.98 and a rational range of marginal errors and different effects (varied from 0.03 to 0.15) with 95% confidence level and 80% power.Table 1 shows that the required total sample size for sensitivity is substantially varied in relation to marginal errors (i.e. the difference between the estimates and true value that is expected to be detected or one half the desired width of the confidence interval), the degree of sensitivity and the prevalence of disease in population. The greatest sample size of 89,637 was calculated for low marginal errors (0.03) and low sensitivity (0.70) and low prevalence (0.01). For a given sensitivity and a marginal error, the sample size substantially decreased as prevalence reached to 0.50. The smallest sample size for sensitivity was calculated when the prevalence was about 0.50. For example, for the sensitivity of 0.70 and the marginal error of 0.03, the required sample size basically varied from 89,637 to 179 as prevalence elevated from 0.01 to 0.50. In addition, for a given prevalence and marginal error, sample size decreased as sensitivity increased. Table 2 shows that the required total sample size for specificity increases by higher prevalence of disease. The largest sample size was calculated for low specificity and low marginal errors and high prevalence (the first row of Table 2). The smallest one was computed for high accuracy, high marginal error and low prevalence. In Table 3, the third column shows the point estimate of LR+, as confidence bound of LR+ becomes wider which included with higher marginal error, the sample size decreased since LR as ratio estimator is more sensitive with respect to variation of sensitivity and specificity. A wider confidence bound of LR+ (the difference between the third column and the boundary value) (i.e. lower precision) which is unacceptable statistically and clinically as well, produces a small sample size. Similarly, Table 4shows the narrower of confidence bound for LR− (i.e. the lower difference between the third column and above) is corresponded with higher sample sizes.Table 5shows for estimation of AUC with a given marginal error of 0.03 and 95% confidence level, sample sizes varied from 665 to 42 for low (AUC=0.60) to high (AUC=0.98) accuracy index. For moderate marginal error (0.05), the required sample size was 240 and 50 from low to high accuracy. Table 6shows for testing AUC with pre-determined fixed value and for detecting an effect of 0.03 with 95% confidence level and 80% power, the sample sizes varied from 1317 to 716 for low to high accuracy while for detecting a moderate effect (0.07), the required sample size was 240 for low and 143 for high AUC.Tables 7 and 8show that for the comparison of two independent diagnostic tasks, as one expected the required sample size was greater than that of the two correlated indexes in similar conditions. For example the required sample size for each group for detecting an effect of 0.07 with 95% confidence and 80% power in comparison of two independent AUC is equal to 490 for low accuracy and 70 for high accuracy while for two correlated AUC for detecting of the same effect and the same confidence and power, the required sample size decreased to 408 for low and to 69 for high accuracy (Table 8).As an example of biomedical informatics study illustrated in Section 2, the performance of three diagnostic tasks (physician alone, HDP alone and their combination) was assessed for prediction of heart failure [12]. First the author used sensitivity and specificity in their analysis. Then, they acknowledged the limitation of sensitivity and specificity that depending on threshold used. Thus, they performed ROC curve analysis. The ROC curves were depicted for physician alone and HDP alone and also some points for their combination. They only tested for comparison of sensitivity and specificity but not for AUC. They just descriptively reported AUC were 68.8%, 70% for physician alone and HDP alone respectively. They descriptively presented and concluded that the combination of HDP and physician gave better discrimination than HDP program and physician alone without reporting the p-values. It is more helpful to report the AUC for the combination of two tasks and the SE of each task and their confidence interval of difference of accuracy of two alternative tasks. Since this study used a matched paired design, we recommend the SE of difference of AUCs to be calculated using Delong’s method. However, it is not clear with the small difference observed in ROC curves this difference would be significant with the achieved sample size. In addition, they also reported the sensitivity of HDP alone was significantly higher than physician alone (0.53% versus 34.8%, p<0.001) while physician alone had higher specificity than HDP alone (93.9% versus 75.6%) but their depicted ROC curves did not shows such a differences in ROC space. Although, they reported p-values for comparison of sensitivity and specificity of different tasks, reporting the CI would have been more informative. Also reporting SE of AUC or its CI and the p-value also would be informative instead of a visualized comparison. Sample size consideration was necessary and the power calculation would help in particular the difference between two diagnostic classifiers was not detected to be significant with achieved sample size. The calculated sample size in our Table 8 shows with paired design for AUC about 70% and for detection of an effect of 10%, the required sample size is 108 subjects for each group of cases and controls with 80% power and 95% CI but for a desirable effect of 12%, this sample size is reduced to 71 for each group of cases and control.Listed below is recommendation for sample size calculation in diagnostic studies with respect type of study and classifier.1.In a single diagnostic test with dichotomized outcomes, if an investigator interested in sensitivity and specificity of performance of diagnostic test, depending on conditions for estimating accuracy and desirable marginal error of estimates as outlined in formula in Sections 6.1 and 6.2, the required sample size can be chosen with respect to sensitivity (or specificity) and prevalence of disease in Tables 1 and 2.For comparison of sensitivity (or specificity) of two diagnostic tests with dichotomized outcome for detection of a desirable effect between two tasks with 95% CI, choose the formula in Sections 6.2 and 6.3 for sample size calculation.For a dichotomized classifier when the choice of accuracy index is the LR+ or LR−, depending on condition which is more interested from clinical prospective, one can choose the sample size in Tables 3 and 4 or using formula in Section 6.4.When the diagnostic test results are recorded in ordinal or continuous scale, ROC curve analysis is the choice of interest and AUC is primarily of interested accuracy index. In estimating purpose, for a given AUC and desired marginal errors of the estimates as outlined in Table 5, select the optimal sample size.For testing AUC with a pre-specified value in a single diagnostic task, depending on the AUC and the effect to be detected with 80% power and 95% CI, choose Table 6 for the required sample size.For comparison of two independent AUCs, given a base value for AUC and desirable effect size with 80% power and 95% CI, select Table 7 for minimum sample size of each group.For comparison of two diagnostic tasks in paired design, choose Delong method for estimation of SE of difference of AUCs of two correlated tasks. Select the possible value of AUC and the desirable effect size with 80% power and 95% CI in Table 8 for the optimal sample size of each group.Additionally, in any of the above conditions, if the required sample size is not achieved in practice, the calculation of power of achieved sample size is needed if it differs from required sample size.

@&#CONCLUSIONS@&#
