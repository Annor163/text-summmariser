@&#MAIN-TITLE@&#
Evaluating ecommerce websites cognitive efficiency: An integrative framework based on data envelopment analysis

@&#HIGHLIGHTS@&#
The website cognitive efficiency is used as a measure of website performance.A framework based on cognition theories is proposed to model website performance.DEA is used to compare ecommerce websites.Navigation ambiguity and website usefulness affect website cognitive efficiency.

@&#KEYPHRASES@&#
Cognition,Human–computer interaction,Electronic commerce,Website,Efficiency,Data envelopment analysis,Uncertainty,Ambiguity,

@&#ABSTRACT@&#
This paper presents an integrative framework to evaluate ecommerce website efficiency from the user viewpoint using Data Envelopment Analysis (DEA). This framework is inspired by concepts driven from theories of information processing and cognition and considers the website efficiency as a measure of its quality and performance. When the users interact with the website interfaces to perform a task, they are involved in a cognitive effort, sustaining a cognitive cost to search, interpret and process information, and experiencing either a sense of satisfaction or dissatisfaction for that. The amount of ambiguity and uncertainty, and the search (over-)time during navigation that they perceive determine the effort size – and, as a consequence, the cognitive cost amount – they have to bear to perform their task. On the contrary, task performing and result achievement provide the users with cognitive benefits, making interaction with the website potentially attractive, satisfying, and useful. In total, 9 variables are measured, classified in a set of 3 website macro-dimensions (user experience, site navigability and structure). The framework is implemented to compare 52 ecommerce websites that sell products in the information technology and media market. A stepwise regression is performed to assess the influence of cognitive costs and benefits that mostly affect website efficiency.

@&#INTRODUCTION@&#
The World Wide Web (WWW) has dramatically changed the way consumers buy goods and services, collect information to compare products, and companies conduct their business. Consumers can choose among several websites when surf the net, and henceforth websites compete to grasp their attention and receive visits in the future. Recent statistics indicate that although there is a growing number of people that use the WWW to search for product information, to do price comparisons, and to collect useful information in order to make their purchasing decision, the number of actual online purchases remains still relatively small (Moe and Fader, 2004). Findings from a research carried on by IPSOS Belgium in 2006 (IPSOS, 2008a,b) showed that a not negligible percentage (38%) of consumers did not buy online as they found it difficult to make a choice among a great range of available products, features and parameters. Poor website design can be a major factor that negatively affects the consumer purchasing decisions and, as a consequence, the profitability of ecommerce businesses and retailers may be losing a large percentage of potential sales simply because their websites are confusing and difficult to use (Lais, 2002; Nielsen, 2001). Several scholars found that website characteristics may affect the perception of the website quality developed by the users, and, as a consequence, their purchasing behavior and decision outcome (Dholakia and Rego, 1998; Ho and Wu, 1999; Jarvenpaa and Todd, 1997; Ranganathan and Ganapathy, 2002; Wolfinbarger and Gilly, 2002). Good or improved website design may even enhance credibility of information content, supporting – for instance – navigation of anxious users who are more susceptible to deception (Singh and Iding, 2011). Thus, for those businesses that use the WWW as a marketing channel it is crucial to assess the appreciation rate for their website either against the competitors' websites or more conventional marketing tools and channels, and to determine what makes a consumer satisfied with the website, as well as what might be potential causes of dissatisfaction (Djamasbi et al., 2010).In the literature, several methods and approaches to website evaluation have been proposed. They differ as to the goal of the evaluation (usability measurement, website effectiveness evaluation, interface features definition, website quality assessment), how information and data useful for the evaluation are collected (observations and log activity, heuristics, focus groups, questionnaires, brainstorming, website features enumeration, cognitive walk-through and the user testing), and type and nature of information collected (navigation, website content, customer behavior, searching mechanisms, website security, technical features) (see, for instance: Bauer and Scharl, 2000; Chen and Macredie, 2005; Cox and Dale, 2002; Cunliffe, 2000; Day, 1997; Grandon and Ranganathan, 2001; Jordan, 1998; Koufaris et al., 2002; Magoutas et al., 2010; Mich et al., 2003; Nielsen, 1995; Nielsen and Loranger, 2006; Palmer, 2002). In particular, scholars and practitioners who focused their efforts on the evaluation of website design quality and usability provided a number of guidelines and criteria for this aim, stressing the importance of usability assessment in the study of online purchasing behavior as a measure of website quality and use (Agarwal and Venkatesh, 2002; Nielsen, 2000; Palmer, 2002). But, as some researchers emphasize, even when a website has a low usability, other features, i.e. its visual appeal, may be an important factor that affects the positive judgment of the user relative to that website (Djamasbi et al., 2010; Lindgaard et al., 2006; Schenkman and Jönsson, 2000). In addition, traditional website usability evaluation privileges the use of qualitative data, and in general usability approaches are unable to resort to users' emotions and experiences (Chamorro-Koc et al., 2009). As Hahn and Kauffman (2004) claim, there are a number of issues that make common approaches which are successfully adopted to assess electronic interfaces not very suited for ecommerce website evaluation, and particularly: 1) as websites are continuously redesigned and updated, costly experts have to be frequently involved in a continuous evaluation process, and 2) users of ecommerce websites may be very heterogeneous customers whose habits, preferences, and attitudes differ. As a consequence, website design has to match the needs of a differentiated population of users and website performance assessment should be conducted involving a variegated sample of them.Although in the last years many scholars have provided frameworks and a number of methods to evaluate ecommerce websites specifically (Boyd, 2002; Merwe and Bekker, 2003), generally there is a lack of theoretical justifications of the frameworks and evaluation criteria they adopt. Moreover, these approaches also neglect or do not effectively model the cognitive process of online consumers that determines how they perceive the quality of the websites that are experiencing. Indeed, information processing and cognition are central activities when consumers interact with websites (Zhang and von Dran, 2000).This paper presents an integrative framework inspired by concepts driven from various theories of cognition and information processing – i.e., cognitive load, distributed cognition, cognitive fit, and media richness (Clark and Chalmers, 1998; Daft and Lengel, 1986; Hutchins, 1995a,b; Lave, 1988; Rogers and Ellis, 1994; Ramarapu et al., 1997; Vessey, 1991) that helps to assess and compare ecommerce websites. This framework adopts the concept of cognitive efficiency as a measurement of the website quality and performance, measured by the ratio of user perceived cognitive benefits to cognitive costs. Further, it uses Data Envelopment Analysis to calculate the website cognitive efficiency score. The framework is implemented to compare 52 ecommerce websites of businesses selling goods in the information technology and media market (PC equipment, music CDs, DVDs, books). A stepwise regression analysis is performed to identify cognitive costs and benefits that mostly affect website cognitive efficiency. The paper has the following structure. Firstly, information processing and cognition issues related to the website usage are discussed. Secondly, the user–website interaction cognitive efficiency is presented. Thirdly, the sources of cognitive costs and benefits are analyzed. Next, the methodology for the measurement of the website cognitive efficiency and implementation of the framework are illustrated. Finally, results are reported and discussed.Ecommerce websites, acting as decision support systems, allow the consumers to perform problem-solving and decision-making more efficiently along the stages of online purchasing, providing them with an aid capable to reduce their cognitive effort and increase their information processing and cognitive ability (Helander and Khalid, 2000). The interaction occurring between the user and the website forms a unique coupled cognitive system in which the website, providing the user with patterns of action and an additive short-memory, supports this latter by keeping the internal mental information processing activity less complex (Clark and Chalmers, 1998; Halverson, 1994). In such a way, the external resources (i.e., personal notes, paper catalogs, webpages, etc.) become a part of the user cognitive system (Edmondson and Beale, 2008).11That is consistent with the view of cognition as a distributed phenomenon between individuals and artifacts used to perform a task (e.g., paper notes, documents, more or less complex technological devices, electronic interfaces, etc.) (Flor and Hutchins, 1992; Hutchins, 1995b; Hutchins and Klausen, 1996; Rogers, 2004; Suchman, 1987).The representations of information and knowledge by means of a website interface have a number of properties that may greatly affect the users cognitive effort when they perform their task on the WWW (Carroll, 1987; Wright et al., 2000; Zhang, 1991):•firstly, as underlined, they can provide memory aids, and because information resides in front of the user, that has not to be remembered. The website supports cognition not just passively by merely representing itself, but actively by registering and storing user activities for future use, and thus functioning like an external memory (Clark, 1997; Kirsh, 1996; Kirsch and Maglio, 1994). When the user surfs the WWW, the browser – as an external representation – can advise if a page has already been visited, remembering which page the user has already visited and which has not yet. For instance, links to pages that have not been seen by the user are blue, while links to previously seen pages appear purple or red. Henceforth, when the user interacts with the website interface, information and knowledge are continuously transformed through mental, external and technological representational states, and in terms of distributed cognition achievements are characterized as the assembling of various representational states (Staggers and Norcio, 1993; Zhang and Norman, 1994);secondly, they can anchor and structure the user cognitive behavior, because physical structures in the external representations constrain the range of possible cognitive behaviors, allowing some of them and prohibiting others. The website indeed provides filtering devices and structures to represent and store information and knowledge through the use of symbols, constraints and working rules which are complementary to the user's ones (see Table 1);thirdly, they change the nature of task, making its performance easier by simplifying the problem and reducing the user information load. To a certain extent, the website addresses how user cognition evolves during interaction as the website dynamically assumes new configurations that better fit the user information processing capability;fourthly, technology makes website interfaces very flexible decision support systems. Hence, by removing or adding different features and functions such as text, audio, colors, interactivity, customization, etc., websites may assume several configurations, and, consequently, have different degrees of richness, becoming more or less responsive to the information needs of the user and task characteristics (Palmer, 2002; Carlson and Zmud, 1999);finally, they provide information that can be directly perceived and used without being interpreted and formulated explicitly, as it emerges from the physical constraints. For instance, easily identifiable and meaningful icons on a website page may reduce perceived complexity and support the user navigation unequivocally (Cheng and Patterson, 2007).As human short-term working memory capacity is limited, a website should be capable to eliminate or reduce the working memory overload associated to the need to mentally retain and integrate several pieces of information and knowledge, but, at the same time, to provide the user with a pleasant and satisfying experience (Sweller, 1994). Cognitive efficiency, then, may be an effective measure of how much cognitive work the users have to perform outside of their working memory in a given task, given the constraining nature of the website interfaces. The theories of cognitive efficiency suggest that, when the user cognitive tasks can be performed easily and quickly, the cognitive effort can be minimized and the search performance and the user gratification can be maximized. If information is almost processed automatically with the support of the website, the user cognitive efficiency may substantially increase. Thus, better websites allow the user to have a greater cognitive efficiency during interaction. Following this discussion, an efficiency index can be constructed, by considering the ratio of the user perceived cognitive benefits to cognitive costs incurred during the interaction with the website:(1)efficiency=∑cognitive benefits∑cognitive costsDuring the interaction with the website, the user has to bear a cognitive cost because of the efforts made to search, interpret and process information (Suchman, 1987). If the website user is either unable to locate critical information or to manage the information overload, and feels disoriented because information already collected is either redundant or ambiguous, proceeding with this search and retrieving supplementary information necessary to accomplish the task will be difficult (Germanprez and Zigurs, 2003). That will increase the user perception of task complexity and bewilderment, causing the search activity to become psychologically and cognitively costly (Chevalier and Kicka, 2006; Sweller, 1988, 1994; Wilkie, 1994). The amount of ambiguity and uncertainty perceived by the user is a measure of the cognitive costs to bear when using the website.22Literature differentiates these two cognitive states of individuals. In particular, uncertainty is a consequence of the perceived lack of information (Daft and Lengel, 1986; Galbraith, 1973). This lack of information increases with task complexity, i.e. the variety of its constituting actions and their interrelationships. When a great number of actions have to be executed, it is not easy to define accurately all the details before starting task execution, and new information has to be acquired during interaction as unexpected events produce a gap in the knowledge. On the other side, ambiguity emerges when there might be several different interpretations, even contrasting, of a certain situation (Daft and Weick, 1984). When either tasks or actions cannot be correctly framed, their execution cannot be easily planned and has ambiguous aspects.Literature suggests that individuals perceive and process uncertain and ambiguous information differently, depending on their cognitive capabilities, past experience, and attitudes (Grisé and Gallupe, 2000; Kuhlthau and Tama, 2001; Tversky, 1972), as their cognitive and learning style works as a sort of internal mechanism filtering or activating their cognitive capabilities (Anderson, 2006). In the distributed cognition view, the perceived uncertainty and ambiguity are not only related to the type of task to be accomplished using the website or to the user information processing capabilities, but also to the website features themselves. Poor website design requests to the user a greater attention to grasp the logic and the way the website works. Vice versa, a well designed website interface may simplify the access to information and reduce both ambiguity and uncertainty. Time needed to search for information also affects the amount of cognitive cost the user has to bear in the interaction with the website. The more the user has to think about how to use the website interface, the less a sufficient amount of cognitive and perceptual resources will be available to perform the main task. Time perception is thus associated to mental workload (Baldauf et al., 2009). A lower amount of time consumed to achieve a task is usually associated to more efficient information processing and effective website design (Hong et al., 2004). When the website includes both highlighted and non-highlighted options or differently colored options, the search time for collecting useful information depends both on the time necessary to find the target when there is a highlighted option and the time necessary to find the target when there is no highlighted option or this option is differently colored (Crosby et al., 2003). Search time for information is strongly related to website features, i.e. the density and visual complexity of the background (Drury et al., 1978; Tuch et al., 2009). Moreover, a low speed at which website pages load and commands are carried out contributes to make the user frustrated when the website is used. However, it may happen that when the interaction with the website is really enjoyable, the user becomes so engaged in this interaction, so full immersed in what is doing and focused on the task to be totally unaware of the time which is passing. In this case, the perception that the user has of time becomes distorted, and an objective measure of it might not be associated to the real cognitive cost sustained. Even, much more time to complete the task can be spent, if the interaction with the website is pleasing and the satisfied website user has fallen in a state of flow (Hoffman et al., 2000; Hoffman et al., 2002). Thus, an objective measurement of time may be even misleading in the assessment of website quality.Interacting with the website interface is for the user also a source of gratification and satisfaction, which are associated both to the quality of interaction itself and the way it develops, and the successful goal attainment. Online shopping is intrinsically more uncertain and risky than conventional shopping for the consumer, because of the inability to check the product or service quality before buying and receiving it at home, or to find enough information about the seller, or monitor the safety of sending personal and financial information. Further, it provides the consumer with a different experience from shopping in a physical retail store, and as the web store is unable to reproduce the environment and the atmosphere of a physical retailer due to the technical limitations of the electronic interface, the website design has to compensate for the loss of them (East, 1997; Engel et al., 1995). Thus, the users will generally be more attracted by websites that make them at ease, nourishing their trust. Scholars found that the positive experience during online shopping is an important determinant of retaining online consumers (Rice, 1997), and the quality of a retailing website is a dominant antecedent of the user satisfaction within the online shopping environment (Wolfinbarger and Gilly, 2002). Csíkszentmihályi (1990) uses the concept of “states of optimal experience” or “flow” to refer to a cognitive state of the user which is characterized as being intrinsically enjoyable, accompanied by a loss of self-consciousness, and self-reinforcing.33In the WWW context the flow describes an online experience where the users are completely engaged with their online interaction with the website, judging it intrinsically interesting to the extent that they often perceive a sense of control over the website interaction, losing track of time passing and of the immediate physical surroundings (Hoffman et al., 2002; Trevino and Webster, 1992; Webster et al., 1993).Vellido et al. (2000) found that the easiness of use of the online store website and the perceived control over it by the user are major determinants of user satisfaction that explain purchasing on the web. As empirical studies reveal (Csíkszentmihályi, 1990; Hoffman et al., 2000), a state of flow is generally associated to a good balance between how much the users perceive that the interaction with the website is challenging and to what extent their skills match the websites complexity. This means that an interaction with a website which is apparently extremely easy-to-use might be as frustrating as the interaction with an ambiguous or technically deficient website. That is a major concern that should be taken into account when using conventional approaches to the assessment of website usability.The measurement of the cognitive efficiency of a website implies the development of a complex model that relates a set of input and output variables associated to measurements of the user perceived cognitive costs and benefits. For this aim, scholars have suggested the implementation of Data Envelopment Analysis (DEA), a mathematical non parametric multi-criteria technique based on a seminal idea proposed by Farrell (1957) that provides a measure of the relative efficiency of a number of units based on a not necessarily known or pre-defined conversion process of inputs into outputs (Charnes et al., 1978). Particularly, DEA adopts linear programming to identify a production frontier as locus of efficient units. In the original formulation by Charnes et al. (1978) (CCR model), units which are placed on the production frontier are 100% efficient, while units that are displaced away from the frontier are considered not efficient. If a unit is less than 100% efficient, a linear combination of other units yields the same level of outputs consuming a lower amount of inputs which is actually used by that unit. This technique allows to avoid some of the critical assumptions made to measure efficiency, assessing the relative efficiency of units without the need to introduce any a priori minimal assumption relatively to the functional relationships between input and output factors in these units to build the efficiency frontier. As the standard development of the DEA model produces an efficiency measure which is between 0 and 1, and does not generate a ranking of units, Andersen and Petersen (1993) – modifying the original CCR model – introduced the concept of super-efficiency that makes the efficiency analysis more discerning and provides a full not censored ranking of unit efficiency (Lovell and Rouse, 2003; Zhu, 1996). Details relative to how DEA works and the re-formulated model measuring super-efficiency are illustrated in the Appendix.Alpar et al. (2001) propose a productivity model for websites comparison treating page views as output, and webpages, scripts, and some web constructs as inputs. Alpar and Donthu (2007) conceptualize shopping websites as a computer information system and sales channel. Data measuring input and output variables in their model are collected from three different sources: site analysis by means of a webcrawler, website visiting statistics retrieved by a market research company, and the measurement of visitor's perceptions. Hahn and Kauffman (2004) also provide a conceptualization of a website as a production function that transforms inputs (functions) into outputs (purchase transactions). Adopting this model, they evaluate one single ecommerce website. Rather than benchmarking different websites, the scholars compare completed purchase transactions performed by a great number of customers that use the same ecommerce website. In their DEA model, inputs consist of customers use of a set of website functions, while the only output is the product type basket at checkout. Finally, Benslimane and Yang (2006) implemented DEA to identify the minimum function set that generates the maximum value for buyers that use commercial websites for electronic procurement. Particularly, they consider four website functions (identification, selection, execution, and post sale support) as inputs, and three dimensions of website commercial value (usefulness, reduced research and processing cost) as outputs. Literature on website usability has suggested three macro-dimensions (or areas) useful for measuring performance of a website (Jordan, 1998; Nielsen, 1995, 2000; Nielsen and Loranger, 2006): user experience, website navigability and structure. These dimensions are used in the proposed framework to measure the user cognitive benefits and costs (see Fig. 1). Particularly, the “experience” dimension includes those cognitive benefits that a user receives in terms of perceived satisfaction (S), usefulness (US) and attractiveness (AT) for the use of the website. The remaining two dimensions, “navigability” and “structure” are related to website characteristics that can originate cognitive costs for the user along the interaction with it. These characteristics can generate ambiguity (A) and uncertainty (U), and determine an over-consumption of time (T) in the search for useful information.Thus, the website efficiency index assumes the following shape:(2)∑BenefitExperience(US,S,AT)∑CostStructure(A,U,T)+∑CostNavigability(A,U,T)The framework is implemented to compare 52 websites of businesses that sell their products online (PC equipment, music CDroms, DVDs, books).Literature emphasizes how – generally – usability cannot be conceptualized independently of the context where it should be assessed, but its definition and implementability are dependent both on the specific goals and tasks that can be performed by means of the website and on the website user target (Lecerof and Paterno, 1998). Scholars also found that the user perception of website easiness of use and control of user–website interface interaction vary with the kind of task that has to be accomplished (Guriting and Ndubisi, 2006; Laforet and Li, 2005). Henceforth, in the preparatory stage of the study, a particular attention was paid to define and circumscribe a specific task and sample of users. Consistently with the tradition and methods of usability research suggesting that website assessment is performed through an intense user involvement, the evaluation framework was implemented in an experimental setting according to the following steps:a)customization of the questionnaire to collect judgments relative to the 52 websites of the sample.44The number of websites in the sample is consistent with the sum of input and output variables. Andersen and Petersen (1993) underline that, unless the sum of the input and output variables is small relatively to the number of units, DEA implementation provides generally a large number of units as 100% efficient. Further, input and output variables are usually highly correlated with one another. Thus, the greater the number of input and output variables, the less discerning the analysis (Jenkins and Murray, 2003).The original questionnaire was designed and tested in a previous study by the author (lo Storto, 2004a,b). The questionnaire was designed to measure all the nine variables of the framework that provide proxy measurements of the user cognitive benefits and costs (i.e., the cognitive cost induced by a sense of ambiguity during website navigation, the cognitive cost induced by the website structure, the cognitive cost associated to the perception of time passing to navigate in search of useful information, the experience linked to website attractiveness, etc.). Constructs measuring the framework variables were built using a list of statements, adopting scales reported in the literature and already tested (see lo Storto, 2004a,b). The users were requested to express their agreement/disagreement for the statement content using a 9 level measurement grid. After filling in questionnaires, the reliability of scales was measured both by calculating the Cronbach α index and performing a factorial analysis.55At this stage sample used to check scale reliability included 84 questionnaires.Values were acceptable and consistent with previous studies (lo Storto, 2004a,b) (see Table 2). The first section of the questionnaire included a scale to classify the cognitive and learning style of the user.66Taking into account the influence of the cognitive and learning style of website users is of paramount importance to design successful websites. Indeed, scholars claim that information processing capabilities are influenced by personal characteristics of the consumers (McGuire, 1976), by their past experience (Tversky, 1972), and cognitive ability (Grisé and Gallupe, 2000). Newell and Simon (1972) suggest that every individual processes information in a unique way, showing a different capability to do that. Jones et al. (1998) found that males and females react differently to images, while Meyers-Levy and Maheswaran (1991) point out that males focus their attention on a more limited number of issues when process information. Similar findings emerged in eye-tracking experiments (Lorigo et al., 2006).This scale adopted the PLSI (Paragon Educational Consulting Student Learning Style Inventory) model developed by Shindler (1992) and is based on the Kolb (1984), Jung (1971), and Myers-Briggs and McCaulley (1992) frameworks.77The scale of the Shindler model includes 48 statements. It classifies individuals into 16 categories, according to their cognitive and learning characters, combining together 4 dimensions: Introverts (I)/Extroverts(E), Sensing(S)/Intuitive(I); Feeler(F)/Thinker(T), Judger(J)/Perceiver(P) (see http://www.oswego.edu/plsi/plsinfo.htm).Information relative to the cognitive and learning style of students who were involved in the study as website users was therefore used to select a reduced number of website evaluators to preserve a high degree of homogeneity;in the front page, the questionnaire also requested the user to provide information relative to the technology adopted (i.e., speed of connection, PC motherboard chip frequency, etc.), the evaluation process (i.e., amount of time dedicated to the website assessment, number of steps in which the process was fragmented, etc). This information was utilized to pick up questionnaires that made the sample used to implement DEA more homogeneous assuring a high internal validity;the questionnaire was administered to a sample of 135 computer science engineering, biomedical engineering and automation engineering undergraduate students at the beginning of the term, providing them with all information relative to the aim of the study and questionnaire filling, inviting them to return it no later than 4 weeks. Each student was requested to assess all 52 websites of the sample and filling in the first section of the questionnaire that contained the PLSI scale. Participants were also informed that they had to assess websites features rather than their content. At the due date, slightly more than 30% of questionnaires had been filled in. After soliciting the return of the questionnaires, new questionnaires were filled in the next 4 weeks. The final amount of questionnaires available for the study after 8 weeks was 92 units. However, at this step 8 questionnaires were rejected because they had several unfilled scales and, as a consequence, were not acceptable for the study;in the next step, the 84 questionnaires were classified and clustered according to the student cognitive and learning style. Eleven questionnaires were excluded from the analysis as they had been filled in by means of technologies and an assessment process that were not compatible with the rest of the sample (i.e., the user had a slow connection speed modem or the questionnaire was filled in fragmenting the evaluation of websites into an exaggerated number of steps). Furthermore, because it was not possible to have a univocal identification of the cognitive and learning style of the user for 22 questionnaires, they were discarded and not considered for the next step of the study. The final sample that was used in the next steps includes 51 questionnaires. Fig. 2reports the outcome of questionnaire grouping according to cognitive and learning style. As it shows, the cognitive and learning style labeled as “ESFJ” includes the largest number of questionnaires. From this group, 5 questionnaires associated to 5 students were randomly chosen and used in the calculation of website cognitive efficiency and comparison. The ESFJs are particularly interesting as a reference group for the test of the framework, both for its large diffusion in the population – it is the second most common type, close to 12% – and the cognitive characteristics of these users. The ESFJs are generally uncomfortable with uncertain and ambiguous contexts, but enjoy routine and working methodically with an attention to procedures and specifications, focusing on details rather than the overall picture. They are often unable to deal with unstructured problems without the support of others;for every scale, judgments given by the 5 selected students were averaged obtaining a unique evaluation. These values were used to run DEA. The DEA technique implemented in the study has adopted a radial measure for efficiency and an input orientation (cognitive costs), in order to get a quantification of the input reduction necessary to make a not efficient website 100% efficient keeping the same output value (the cognitive benefits) (Charnes et al., 1978). It was assumed that scale effects are not influential in the study, and henceforth the CCR DEA model was implemented. In order to have a ranking for the 100% efficiency websites too, the re-formulated CCR model was implemented to calculate super-efficiency measures.88For not efficient websites, efficiency and super-efficiency have the same value (Andersen and Petersen, 1993).Finally, a stepwise backward regression analysis was performed to find cognitive costs and benefits that mostly affect website efficiency.

@&#CONCLUSIONS@&#
