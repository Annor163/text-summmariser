@&#MAIN-TITLE@&#
Text summarization using Wikipedia

@&#HIGHLIGHTS@&#
Summarization using Wikipedia and graph-based ranking.Theoretical analysis for various sentence–concept models.Real-time incremental summarization.Performance analysis using the ROUGE metric and user evaluations.Personalized and query-focused summarization, multi-document summarization.

@&#KEYPHRASES@&#
Summarization,Wikipedia,Sentence ranking,Personalization,

@&#ABSTRACT@&#
Automatic text summarization has been an active field of research for many years. Several approaches have been proposed, ranging from simple position and word-frequency methods, to learning and graph based algorithms. The advent of human-generated knowledge bases like Wikipedia offer a further possibility in text summarization – they can be used to understand the input text in terms of salient concepts from the knowledge base. In this paper, we study a novel approach that leverages Wikipedia in conjunction with graph-based ranking. Our approach is to first construct a bipartite sentence–concept graph, and then rank the input sentences using iterative updates on this graph. We consider several models for the bipartite graph, and derive convergence properties under each model. Then, we take up personalized and query-focused summarization, where the sentence ranks additionally depend on user interests and queries, respectively. Finally, we present a Wikipedia-based multi-document summarization algorithm. An important feature of the proposed algorithms is that they enable real-time incremental summarization – users can first view an initial summary, and then request additional content if interested. We evaluate the performance of our proposed summarizer using the ROUGE metric, and the results show that leveraging Wikipedia can significantly improve summary quality. We also present results from a user study, which suggests that using incremental summarization can help in better understanding news articles.

@&#INTRODUCTION@&#
Text summarization has seen renewed interest recently. The reason for this is twofold: first, summarization can help cope with the information overload, and second, small form-factor devices are becoming increasingly popular. Internet access on the move often happens in an attention-deficit situation where the user is capable of assimilating lesser content. Hence, it becomes important to present only the most relevant information. For example, while reading a news article, the user might first want to look at a short summary (about 50–100 words), and then request the full article if interested.Radev, Hovy, and McKeown (2002) define a document summary as “a text that is produced from one or more texts, that conveys important information in the original text(s), and that is no longer than half of the original text(s) and usually significantly less than that”. In other words, a good summary: (1) is short and (2) preserves important information. There is a rich history of literature, dating back to the 1950s, that aims to achieve these two objectives. While the earliest efforts were restricted to simple position and word-frequency methods (perhaps due to the limited computation available at the time), more recent work has leveraged learning and graph-based algorithms for generating better summaries. This paper aims to study a further possibility: utilizing a human-generated knowledge base, like Wikipedia, in conjunction with graph-based summarization.Wikipedia is perhaps the best example of collaborative knowledge creation and sharing, whereby the entire information is readily available to anyone–anywhere–anytime. The fact that it contains topics and entities of interest to humans makes it especially useful for summarization tasks. Moreover, Wikipedia is constantly updated, and provides the topic quality required for generating good summaries. Thus, Wikipdia can serve as the basis for understanding salient concepts from the input text, which can then be used to extract summary sentences.The main contributions of this work are: (1) We cast the Wikipedia-based summarization problem into a general sentence–concept bipartite framework, and propose an iterative ranking algorithm for selecting summary sentences. (2) We provide precise mathematical definitions and analysis of the iterative ranking algorithm, and derive several convergence results. (3) We study generalizations of the basic bipartite setup, including directed/weighted edges, personalization and query focusing of summaries, and extensions to multi-document summarization. Furthermore, our algorithms provide incremental summarization in real-time, so that users can first view an initial summary, and if interested, can then request additional content. We also provide novel connections of our proposed algorithms with latent topic models and other known optimization problems.The rest of this paper is organized as follows. We first review related summarization literature in Section 2, and state our research objective in Section 3. Then, in Section 4, we present the Wikipedia-based single document summarizer which is based on a novel iterative sentence–concept ranking. We provide precise mathematical definitions and convergence analysis under different scenarios, starting with undirected binary sentence–concept mappings in Section 4.2, followed by a generalization to weighted and directed mappings in Section 4.4, and then personalized and query-focused summarization in Section 4.5. Next, the Wikipedia-based multi-document summarizer is presented in Section 5. Experiments and performance evaluation are presented in Section 6, and the paper is concluded in Section 7.

@&#CONCLUSIONS@&#
