@&#MAIN-TITLE@&#
A tabu search based hybrid evolutionary algorithm for the max-cut problem

@&#HIGHLIGHTS@&#
We design a hybrid evolutionary algorithm (TSHEA) for the max-cut problem.Results disclose TSHEA discovers new best solutions for 15 out of 91 instances.Analysis indicates the effectiveness of the designed key components.

@&#KEYPHRASES@&#
Max-cut,Metaheuristics,Hybrid evolutionary algorithm,Tabu search,

@&#ABSTRACT@&#
This paper presents a tabu search based hybrid evolutionary algorithm (TSHEA) for solving the max-cut problem. The proposed algorithm integrates a distance-and-quality based solution combination operator and a tabu search procedure based on neighborhood combination of one-flip and constrained exchange moves. Comparisons with leading reference algorithms from the literature disclose that the proposed algorithm discovers new best solutions for 15 out of 91 instances, while matching the best known solutions on all but 4 instances. Analysis indicates that the neighborhood combination and the solution combination operator play key roles to the effectiveness of the proposed algorithm.

@&#INTRODUCTION@&#
Given an undirected graph G=(V, E), each edge e(i, j)∈E being associated with a weightwij, the max-cut problem is to partition the vertex set V into two disjoint subsets V0 and V1, without requiring that |V0|=|V1|, such that the total weights of all the cutting edges are maximized. A cutting edge is such an edge that connects two vertices with one in V0 and the other in V1. The objective function of the max-cut problem can be represented as follows:(1)f(V0,V1)=max∑i∈V0,j∈V1wijAlternatively, let the variable xirepresent the vertex i. Let xireceive the value 0 if the vertex i belongs to V0 and receive the value 1 otherwise. Then the max-cut problem can be formulated with the following binary quadratic function:(2)f(x)=max∑i=1n∑j=1,j≠inwij(1−xi)xjwhere n denotes the number of vertices in the graph G.The solution of the max-cut problem consists in determining a binary value (0/1) for each variable in a n-dimensional vector.The max-cut problem is one of Karp's 21 NP-complete problems and has important applications in circuit layout design and statistical physics [3]. The past decades have witnessed many solution procedures for tackling the max-cut problem reported in the literature. Several examples of exact algorithms can be found in [7,13,22]. Due to the computational complexity of solving large scale problem instances, various heuristic algorithms are accordingly proposed. Geomans and Williamson proposed a semidefinite relaxation based randomized heuristic and established 0.878 performance guarantee [9]. Burger et al. proposed a rank-two relaxation heuristic that does not increase the number of variables when approximating large-scale problems in despite of a non-convex relaxation [6]. Festa et al. investigated several heuristics derived from greedy randomized adaptive search procedure, variable neighborhood search and path relinking [8]. Palubeckis and Krivickiene designed two multistart tabu search implementations, one of which produces initial solutions by fixing variables and the other operates in a random way [19]. Krishnan and Mitchell proposed a semidefinite programming based polyhedral cut and price approach, in which the pricing phase is solved using the interior point cutting plane algorithm and the cutting phase is based on the polyhedral theory [15]. Martí et al. proposed a scatter search algorithm which is characterized of constructing a reference set by the way of solving the maximum diversity problem, conducting an ejection chain move in the local search, and applying multiple types of combination methods [16]. Arráiz and Olivo implemented tabu search and simulated annealing heuristics, both of which use the linearly selected move, random move and their combination [2]. Kochenberger et al. reformulated the max-cut problem into the binary quadratic programming model (BQP) and solved the reformulated problem with a diversification driven tabu search algorithm [14]. Wang et al. also reformulated the max-cut problem as the BQP problem and proposed two path relinking algorithms, where one employs a greedy strategy to generate a path of intermediate solutions connecting two solutions and the other operates in a random way [27]. Shylo et al. developed global equilibrium search algorithms consisting of initial solution construction dependent on accumulated information from a set of good solutions and tabu search for solution improvement [23,24]. Benlic and Hao proposed a breakout local search algorithm which alternates between a steepest descent phase to discover local optima and an adaptive perturbation phase to locate search into new promising area [5]. Wu and Hao developed a memetic algorithm integrating a multi-parent crossover operator which tries to preserve the largest common vertex groupings with respect to parent solutions and an iterated tabu search improvement procedure [28]. Among the reported heuristic algorithms, breakout local search, global equilibrium search and path relinking are the best heuristics for solving challenging max-cut problems.In this paper, we present a hybrid evolutionary algorithm featuring a combined neighborhood based tabu search and a solution combination operator being an innovative variant of the traditional crossover. The tabu search component repeatedly alternates between a one-flip move guided tabu search phase and a constrained exchange move guided tabu search phase. The proposed solution combination operator is simple in design, which inherits maximally common solution components from parent solutions and completes the solution construction using a distance-and-quality evaluation mechanism.The proposed tabu search based hybrid evolutionary algorithm (TSHEA) is distinct from the previously proposed memetic algorithm (MA) [28] in the following aspects: (1) TSHEA uses neighborhood combination in its tabu search procedure, which enhances the neighborhood exploitation in MA that employs a single neighborhood; (2) TSHEA uses a solution combination operator similar to the traditional uniform crossover by reference to two parent solutions while MA uses a group-based crossover operator by reference to multiple parent solutions; (3) TSHEA is evaluated on larger benchmark instances and is capable of achieving better performance than MA, in particular leading to the improvement of solution quality on several hard instances.Experimental comparisons with leading reference algorithms in the literature reveal that the proposed algorithm is capable of discovering improved solutions for 15 out of 91 instances and matching all but 4 instances. Furthermore, additional analysis discloses the merit of using neighborhood combination and the solution combination operator for the proposed TSHEA algorithm.The rest of the paper is organized as follows. Section 2 describes the proposed algorithm. Section 3 presents experimental results and comparisons with state-of-the-art algorithms in the literature. Section 4 analyzes several essential components in the algorithm. Concluding remarks are given in Section 5.Hybrid evolutionary algorithms are known to be particularly effective for solving many hard combinatorial optimization problems [12,18]. Similar to traditional evolutionary algorithms, hybrid evolutionary algorithms use a crossover operator over parent solutions to produce offspring solutions. However, the inclusion of a local search procedure, such as tabu search [10], for extensively exploiting the search area around the offspring solutions, is of great importance to hybrid evolutionary algorithms’ superiority over traditional evolutionary algorithms [4,20].Algorithm 1Outline of the tabu search based hybrid evolutionary algorithm1. P={x1, …, x|P|} ⟵ Init_Pop()2. Record the best solution x* with its cut f(x*)3. repeat4.   xp1, xp2 ⟵ Select_Parents(P)5.   xo⟵ Combination_Operator(xp1, xp2)6.   xo⟵ Tabu_Search(xo)7.   P={x1, …, x|P|} ⟵ Population_Update(x1, …, x|P|, xc)8.   iff(xo)>f(x*) then9.     x*=xo, f(x*)=f(xo)10.   end if11. until the stopping criterion is satisfiedThe general scheme of our tabu search based hybrid evolutionary algorithm for tackling the max-cut problem is described in Algorithm 1. Starting from an initial population P, TSHEA selects two solutions from P as parents to produce an offspring solution, whereupon a tabu search procedure with a randomized perturbation mechanism for diversification is launched to optimize the newly generated offspring solution. Subsequently, a population updating rule decides whether such an improved offspring solution should be inserted into the population and which existing individual in the population should be replaced if yes. The above procedure repeats until the prescribed stopping criterion is satisfied. In the following sections, we describe the main components of the proposed algorithm.The initial population contains |P| solutions, each of which is generated as follows. First, a solution x is randomly created, where each variable xiof x receives the value 0 or 1 with an equal probability of 0.5. Notice that any x is a valid solution. Then this solution x is passed to the tabu search procedure for an improved solution x′. The resulting improved solution is added to the population if it is not identical to any solution currently in the population. The two solutions, say x1 and x2, are determined to be identical if the Hamming distance d(x1, x2)=0 or d(x1, 1−x2)=0 (due to the symmetry caused by the binary vector representation for the solution of the max-cut problem). This procedure is repeated until the population is filled up with 3×|P| solutions from which we finally retain the |P| best ones with the largest objective values to form the initial population. This procedure allows us to obtain an initial population of relatively high quality. Notice that for some small (or easy) instances, our algorithm can even reach the optimal solutions (or solutions of previously best known objective values) during the population initialization phase due to the high efficiency of the tabu search procedure.Once a population is complete, the combination operator that produces an offspring solution from selected parent solutions begins to work. Each time a new offspring solution is produced and improved by the tabu search procedure, a population updating procedure follows. As in the simple version of the scatter search template [10], the improved offspring solution that is permitted to be put into the population should satisfy a population updating rule. This rule only permits a solution to join in the population if it does not duplicate any solution and gets better fitness (objective function value) than that of at least one solution in the population. A qualified solution goes into the population in place of the solution with the worst solution quality.To maintain an appropriate diversity of the population and to prevent the search process from premature convergence, we use a parent selection rule to favor the selection of distanced parents for mating. Our parent selection rule is based on the Hamming distance d(xi, xj) between two parent solutions xiand xj, instead of their fitness. The Hamming distance d(xi, xj) is defined as the number of variables that receive different values in solutions xiand xj. In the case that the number of such variables is larger than n/2 where n is the number of variables, we change all solution components of xito their corresponding complementary values. This is due to the fact that we always use the shortest Hamming distance between the two solutions which are represented with either the binary vector itself or its complementary vector. The solutions xiand xjchosen as parents need to satisfy the criterion that their Hamming distanced(xi,xj)>d¯, withd¯=(2/|P|(|P|−1))∑i=1|P|∑j=i+1|P|d(xi,xj)being the average distance between pairs of solutions in the population.Both solution quality and population diversity are essential to the performance of a hybrid evolutionary algorithm. Our distance based parent selection rule is used to ensure the diversity of the population while our quality based replacement strategy is able to introduce more high quality solutions into the population. In this way, we could maintain a healthy population with good diversity and high quality during the search process.Given two selected parents xp1 and xp2, our tabu search based hybrid evolutionary algorithm uses a dedicated solution combination operator to generate a promising offspring solution xo. The proposed combination operator consists of the following two steps. The first step is to create a partial solution by conserving variables that receive the same values in the two selected parent solutions. In order to obtain a feasible solution, the second step is to stepwise assign the unassigned variables to complete this partial solution, making use of a diversification-guided strategy that takes into account both the solution quality of the offspring and its distance to its parent solutions.Relative to a given incomplete solutionxˆ=(x1,x2,…,xp)and a variable xiwherexi∉xˆ, we define the contribution value of assigning xi=1 asVCi1(xˆ)=∑xj∈xˆ,xj=0wij. By the same token, we define the contribution value of assigning xi=0 asVCi0(xˆ)=∑xj∈xˆ,xj=1wij.To quickly evaluate the contribution value for each variable xinot inxˆ, we maintain a vector g0 with each entrygi0being initialized asVCi0(xˆ)and a vector g1 with each entrygi1being initialized asVCi1(xˆ).Let Cand denote the set of variables not inxˆ. If variable xk∈Cand is picked with the assigned value 1 (chosen according to its contribution value) to join inxˆ, which is then readily removed from Cand, thengi0for each variable xiin Cand should be updated as follows:(3)gi0=gi0+wik,xi∈CandIf variable xk∈Cand is picked to join inxˆwith the assigned value 0, thengi1should be updated as follows:(4)gi1=gi1+wik,xi∈CandThe pseudo-code of the solution combination operator is presented in Algorithm 2, which mainly consists of two steps. The first step is to construct a partial solution xoby inheriting maximally common solution components from the two selected parent solutions xp1 and xp2. Lines 5–6 in Algorithm 2 are used because of the symmetry of the binary vector representation. The second step gradually enlarges the partial solution xoby a sequence of construction steps until a complete solution is acquired.Each constructive step enlarges the partial solution xoby joining a variable together with its assigned value from the parent solution xc, for c=p1 or p2. More precisely, let NC denote the set of variables not in xo. Considering first the parent solution xp1, we identify the variable xi∈NC with the highest contribution value when assigned to the same value as inxip1and includexip1into xo. Afterward, we identify the variable xi∈NC using the same rule and includexip2into xo. Each variable joined into xois immediately removed from NC. The parent solutions xp1 and xp2 are alternatively chosen until NC becomes empty. One observes that the offspring xogenerated by this combination operator has essentially the same Hamming distance |NC|/2 to its two parents, thus keeping good diversification. Meanwhile, the objective contribution based construction procedure enables the offspring xohold good solution quality.Algorithm 2Outline of the combination operator1. Input: Two parent solutions xp1 and xp22. Output: An offspring solution xo3. Let V denote the set of all the variables and n denote the size of V4. Identify the set of maximally common variables C between xp1 and xp2, i.e. C=xp1∩xp25. if |C|<n/2 then6.   C=xp1∩(1−xp2)7. end if8. Create a partial solution by settingxio=xip1if xi∈C9. Identify the set of noncommon variables NC=V\C10. fork=1, …, |NC|do11.   Select parent xcto be considered: if k is odd, then c=p2, otherwise c=p112.   Identify the variable xi∈NC with the highest contribution value when assigned with the same value asxic13.xio=xio∪{xic}, NC=NC\{xi}14.   Update allgt0andgt1values for ∀t∈NC according to Eqs. (3) and (4)15. end forTabu search is a powerful metaheuristic for solving many combinatorial optimization problems [10] and has proved to be effective for tackling the max-cut problem [23,24,27,28]. In contrast to previous algorithms that explore a single neighborhood, our tabu search employs a combined neighborhood based on the one-flip and exchange moves to enhance neighborhood exploitation. The combined neighborhood was first proposed in variable neighborhood search, which switches among different neighborhoods to escape from local optima [17]. Our tabu search procedure repeatedly alternates between two complementary neighborhood searches, one defined by the well known one-flip move and the other defined by an innovative constrained exchange move. The following describes in detail the one-flip move, the exchange move and how to combine them to build the tabu search.Given a solution x=(x1, x2, …, xn), the one-flip move consists of changing the value of a solution component xiinto its complementary value 1−xi(i.e., moving a vertex from its current subset into the other subset). After performing the one-flip move w.r.t. the solution component xi, we get the following solution:(5)x′=x⊕Flip(i)=(x1,…,xi−1,1−xi,xi+1,…,xn)The neighborhood N1 of the solution x consists of all such solutions that are obtained by performing the one-flip move for each solution component xi, which contains a total of n neighboring solutions.The move gain represents the difference in the objective function value between the resulting neighboring solution after a move is performed and the current solution. To quickly calculate move gains, we use the similar stream-lined technique as in the unconstrained binary quadratic optimization problem [11]. Specifically, given a solution x=(x1, x2, …, xn), we maintain a vector Δ with elements Δirecording the move gain of flipping the solution component xi. Then the vector Δ can be initialized as follows:(6)Δi=Σj∈V0wij−Σj∈V1wij(xi=0)Σj∈V1wij−Σj∈V0wij(xi=1)After performing the one-flip move w.r.t. the solution component xi, the Δ is updated as follows:(7)Δk=−Δk(k=i)Δk−2wik(k≠i,xk=xi)Δk+2wik(k≠i,xk=1−xi)With this additional memory, the complexity to identify the best one-flip move reduces to O(n) from O(n2). Notice that we only need to maintain one such Δ vector to record the move gains for all solutions during the search process. After initialization, we can measure the objective difference between the neighboring solution and the current solution by only updating this vector.When the tabu search based on the one-flip move neighborhood is detected being trapped in a local optimum, our algorithm switches to the exchange move based tabu search for further improvement. The idea of using multiple neighborhoods comes from the fact that a local minimum within a neighborhood is not necessarily a local optimum within another neighborhood and an algorithm that explores multiple neighborhoods is expected to have more chances to find better solutions [17]. Although the exchange move has been widely exploited for solving the maximum clique problem [30], traveling salesman problem [26], quadratic assignment problem [25], etc., this is the first study of using the exchange move to the max-cut problem.The exchange move consists of exchanging two solution components xiand xj, subject to requiring that xiand xjreceive different assigned values (i.e., moving the vertex i from its current subset, say V0, to the other subset V1 and then moving the vertex j from V1 to V0). After performing the exchange move w.r.t. xiand xj, we get the following solution:(8)x′=x⊕Exg(i,j)=(x1,…,xi−1,xj,xi+1,…,xj−1,xi,xj+1,…,xn)The neighborhood N2 of the solution x consists of all such solutions that are obtained by performing the exchange move for each pair of solution components with different assigned values, which contains a total of |V1|·|V0| neighboring solutions.The move gain δijof performing the exchange move (xi, xj) is calculated as follows:(9)δij=Δi+Δj+2wijAfter performing this exchange move, the Δ value is updated in the following way:(10)Δk=−Δk−2wij(k=iork=j)Δk−2wik+2wjk(k≠i,k≠j,xk=xi)Δk+2wik−2wjk(k≠i,k≠j,xk=xj)Essentially, our tabu search algorithm repeatedly alternates between a one-flip move based tabu search phase and an exchange move based tabu search phase until a maximum allowed number of iterations (γ) is reached. One iteration is counted when a solution component xiis flipped into its complementary value 1−xi. Notice that an exchange move can be trivially decomposed into two sequential one-flip moves (i.e., flipping xito 1−xiand flipping xjto 1−xj), which is thus counted as two iterations. The pseudo-code of the tabu search is shown in Algorithm 3.Algorithm 3Outline of the tabu search algorithm1. Input: a given solution x with its solution value f(x)2. Output: the local optimal solution x* found by tabu search with its solution value f(x*)3. TL is an n-dimensional vector that maintains the tabu list, Δ is an n-dimensional vector that maintains the move gain of performing each one-flip move, Iter=04. whileIter<γ (γ is a parameter) do5.   Initialize Δ according to Eq. (6), TLi=0 for all i=1 to n, NonImpN1=0, NonImpN2=06.   /* Make improvement with the one-flip move based tabu search phase*/7.   repeat8.     Identify the best non tabu one-flip move or the best one-flip move that is tabu but satisfies the aspiration rule, say this move corresponds to flipping xi9.     xi=1−xi, f(x)=f(x)+Δi10.     Update Δ according to Eq. (7)11.     Update Tabu List by setting TLi=Iter+tl (tl is a parameter)12.     iff(x)>f(x*) then13.       x*=x, f(x*)=f(x), NonImpN1=014.     else15.       NonImpN1=NonImpN1+116.     else if17.     Iter=Iter+118.   untilNonImpN1<α (α is a parameter)19.   /* Make improvement with the exchange move based tabu search phase */20.   repeat21.     Identify the best non-tabu exchange move or the best tabu move that satisfies the aspiration rule, say this move corresponds to exchange xiand xj22.     xi=1−xi, xj=1−xj23.f(x)=f(x)+Δi+Δj+2wij24.     Update Δ according to Eq. (10)25.     Update Tabu List by setting TLi=Iter+tl, TLj=Iter+tl26.     iff(x)>f(x*)then27.       x*=x, f(x*)=f(x), NonImpN2=028.     else29.       NonImpN2=NonImpN2+130.     else if31.     Iter=Iter+232.   untilNonImpN2<α33. end whileStarting from a given initial solution, the proposed tabu search algorithm first conducts the one-flip move based tabu search phase, in which each iteration performs either the best one-flip move that is not tabu or a tabu move that satisfies the aspiration rule. A move is set to be tabu if it was performed during the past tl iterations. Although this tabu rule is able to prevent the search from going back to previously visited solutions, it may neglect some unvisited high quality solutions. Hence, an aspiration rule is accompanied that permits a move to be performed if performing it leads to a solution with a better objective function value than the best found so far.As long as the best solution cannot be improved within α consecutive iterations by using the one-flip move, the exchange move based tabu search phase is followed to further enhance the solution quality. Since the identification of the best exchange move is of high computational complexity, we carry out the following heuristic mechanism to reduce the computational efforts. Among all the variables with assigned value 1, we pick the ones that are not tabu and get the best one-flip move gain Δi(see Section 2.5.1). Likewise, among all the variables with assigned value 0, we pick the ones that are not tabu and get the best Δj. The exchange move is only operated on the variables xiand xj. Similar to the tabu rule used in the one-flip based tabu search phase, a variable is set to be tabu if it is involved in a performed exchange move during the past tl iterations. An exchange move is said to be tabu if either variable involved in this move is tabu.In our tabu search, each time a variable xiis flipped, it is forbidden to be flipped again for the next tl iterations, where tl is a parameter called tabu tenure. For the current study, we selected to set tl=rand[3, …, 0.15|V|], where |V| is number of variables and rand[3, …, 0.15|V|] takes a random integer from 3 to 0.15|V|. This randomized function is called each time one move is performed.While the exchange move based tabu search phase is not able to reach a better solution within α consecutive iterations, the search switches back to the one-flip move based tabu search phase for further improvement. This process is repeated until the specified maximum number of iterations is reached.The proposed tabu search based evolutionary algorithm (TSHEA) is evaluated on two sets of benchmark instances. The first benchmark consists of 71 G-set instances with nodes ranging from 800 to 20,000, which can be downloaded at http://www.stanford.edu/∼yyye/yyye/Gset/. These instances are generated by a machine-independent graph generator, comprising of toroidal, planar and random weighted graphs. Many authors including [6,8,16,19,23,14,27] employ these instances to test their algorithms for the max-cut problem. The second benchmark consists of 20 cubic lattices instances with 1000 or 2744 nodes, available at http://www.optsicom.es/maxcut/.The parameter settings of TSHEA used in our experiments are given in Table 1. These parameter values were determined by performing a preliminary experiment on a selection of 11 problem instances (G32, G33, G35, G40, G41, G42, G55, G57, G62, G65, G66) from the G-set benchmark instances. The selected instances are typically hard for existing max-cut algorithms and are thus appropriate for the purpose of comparisons. The chosen 11 instances are used both for the parameter tuning and for the analysis of key components in Section 4.The parameters are tuned as follows. For the parameter |P| required by our memetic algorithm, we simply set it to 10 as many memetic algorithms do in the literature [12,28,29]. For the three parameters used in the TS procedure (γ, tl and α), we tested different values for each of them, while fixing the rest with the values shown in Table 1. The parameter settings are further justified by the parameter sensitivity analysis in Section 4.3.Our TSHEA algorithm is programmed in C++ and compiled using GNU g++ on a Xeon E5440 with 2.83GHz CPU and 8GB RAM. Given the stochastic nature of our algorithm, each instance is solved for 20 independent runs with different random seeds. Each run is stopped when the processing time reaches the prescribed time limit, which is set to be 30min for graphs with |V|<5000 and 120min for graphs with |V|≥5000. Notice that this time limit is quite comparable with what the reference algorithms use [5,16,27].Tables 2and 3present the computational statistics of the proposed TSHEA algorithm on the G-set and the cubic lattices benchmark instances, respectively. In each table, columns 1 to 3 give the instance names (Instance), number of vertices (|V|) and the best known results (fprev) previously reported in the literature [5,23,24,27,28]. The columns under the heading TSHEA report the best solution values (fbest), the average solution values (favg) along with the standard variance shown in parenthesis (σ), the number of hits to reach the fbestover 20 runs (hits), the total number of iterations Iters and the average time (time) to reach fbest(in seconds). Results marked in bold indicate that TSHEA gets better results than the best known results fprev.From Tables 2 and 3, we first observe that TSHEA is capable of improving the best known results for a total of 15 instances, among which are 13 G-set instances and 2 cubic lattices instances. Moreover, TSHEA matches the best known results for all instances except 4 instances G62, G72, G77, G81. Given the random nature of our algorithm, it's possible to obtain better results in terms of the best solution values if each instance has more runs, in particular to large instances where TSHEA fails to reach the best solution values over all the runs. However, since all the reference algorithms used for comparisons (such as BLS [5], GES [23,24] and PR2 [27]) have 20 runs for each instance, we also report the best found solution over 20 runs in order to make a fair comparison. In addition, TSHEA gets 20/20 hits for 62 out of 91 instances and for those failed instances the average solution values are quite close to the best ones. Finally, TSHEA achieves good performance with reasonable computational effort. For instances with no more than 3000 variables, the computational consumption ranges from 0.08 to 1889.23s. For instances with 3000–5000 variables, the computational consumption ranges from 1903.68 to 7125.31s. In sum, these results disclose that the proposed TSHEA algorithm performs quite well in terms of both the solution quality and the computational time.In order to further show the effectiveness of our TSHEA algorithm, we compare TSHEA with the best performing heuristics in the literature, including Breakout Local Search (BLS) [5], Global Equilibrium Search (GES) [23,24] and a Binary Quadratic Programming based Path Relinking (PR2) [27]. Although the Scatter Search [16] and CirCut [6] are popular algorithms, they are recently outperformed by the reference algorithms we use for comparisons [5,23,24,27].Tables 4 and 5show the best and average solution values obtained by TSHEA, BLS, GLS and PR2 algorithms, respectively. We do not include comparisons with BLS on the cubic lattices instances because BLS do not report results on this set of benchmark instances. Considering that a completely fair comparison of the computing time is quite difficult due to implementation differences and different software and hardware platforms used, it is thus preferable to compare algorithms based on the solution quality. For indicative purpose, TSHEA is highly competitive with the other algorithms in terms of computational efficiency. The results unavailable in Table 4 are marked as “–” and the best results in each row are marked as bold.From Table 4, we find that for the first 54 instances, TSHEA is able to find better results for 6, 3 and 17 instances than BLS, GES and PR2 respectively. For the 17 large G-set instances, TSHEA is able to find better results for 12 instances while it fails to match the results of BLS for only 4 instances. Furthermore, TSHEA is quite robust to reach the best solutions for the former 54 small or medium instances, which is much better than BLS and PR2. For the large instances, it is still hard for TSHEA as well as other reference algorithms to have a robust performance. In addition, in order to see whether there is any statistical difference between the population of the 20 results achieved by our TSHEA and the mean reported by the reference algorithms, we conduct the one-sample t-test with a significance factor of 0.05 for each problem instance. Since this statistical test requires the standard deviation on a set of results is not 0, we add a random value taken from [−0.0001, 0.0001] to such results that are the same during all the 20 runs for one instance. The statistical results reveal that TSHEA is statistically better than BLS and PR2 for most instances and significantly outperforms GES for 8 instances with p−value<0.05.From Table 5, we observe that TSHEA is able to reach better results than GES and PR2 for 2 and 10 out of 20 cubic lattices instances, respectively. In addition, the average values of TSHEA are competitive with GES and much better than PR2. Similar to the Table 4, we conducted the one-sample t-test for each instance and the results reveal that TSHEA performs significantly better than PR2 and GES for 17 and 2 instances, respectively. In conclusion, comparisons with state-of-the-art algorithms on a total of 91 instances demonstrate the effectiveness of our proposed TSHEA algorithm.

@&#CONCLUSIONS@&#
