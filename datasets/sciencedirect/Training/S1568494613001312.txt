@&#MAIN-TITLE@&#
Rough membership function based illumination classifier for illumination invariant face recognition

@&#HIGHLIGHTS@&#
We make use of rough set as a decision maker for illumination classification.Efficient for any type of illumination.Normalization of illumination can be done with efficient illumination normalization technique.Evaluated the efficiency for real time images also.

@&#KEYPHRASES@&#
Face recognition,Illumination variation,Rough set theory,

@&#ABSTRACT@&#
This paper proposes a face recognition system to overcome the problem due to illumination variation. The propose system first classifies the image's illumination into dark, normal or shadow and then based on the illumination type; an appropriate technique is applied for illumination normalization. Propose system ensures that there is no loss of features from the image due to a proper selection of illumination normalization technique for illumination compensation. Moreover, it also saves the processing time for illumination normalization process when an image is classified as normal. This makes the approach computationally efficient. Rough Set Theory is used to build rmf illumination classifier for illumination classification. The results obtained as high as 96% in terms of accuracy of correct classification of images as dark, normal or shadow.

@&#INTRODUCTION@&#
For any face recognition system, variations in illumination in the facial images, changes the appearance of faces that results in distinct texture patterns of the faces. Eventually, it has been proved theoretically [1] and experimentally [2] that differences induced by illumination in the face images are more significant than the inherent face differences between different individuals. In addition to this illumination problem, many a times during acquisition of an image, due to linear motion of camera, image may get blurred along with some added noise. Thus, the presence of noise and variations in illumination becomes one of the causes for the degradation of 2D face recognition system. This problem of illumination variation is generally removed at pre-processing stage through illumination normalization techniques such as histogram equalization, gamma correction, and homomorphic [3]. Related approaches addressing this problem can be divided into three main categories: (1) normalization and pre-processing [7–9], (2) invariant features extraction [10–16], (3) generative model based approaches [17] and (4) 3D morphable model [18].Here, our focus is on first category as it does not require any modeling procedure. Histogram equalization and gamma correction are well known normalization techniques [3] that belong to this category. These techniques are simple global transforming methods that process the entire image information. However, these techniques do not show desired result for larger degree of variations in illumination. Homomorphic, a well known illumination normalization technique, is basically a Fourier transform taken over the log value of gray level of the observed image at each pixel [3,4], however, it is computationally complex. The self quotient image (SQI) [9] is a popular technique gives an illumination invariant by division over a smoothed version of image itself. It neither uses the information about the lighting source, nor needs a training set. Moreover, it produces good results on dark or shadow images. The disadvantage of this technique is that it might lead to some feature loss when used on properly illuminated images [5]. Later, inspired by SQI, authors proposed logarithmic total variation (LTV) and total variation quotient image (TVQI) [20]. In [22], author extended the concept of quotient image and proposed morphological quotient image (MQI). MQI employed morphology operations to smooth up the image and obtained luminance estimation. Similar to LTV, another approach proposed in [29], where image is decomposed into two parts: small-scale and large-scale similar to the LTV. Based on the same methodology of decomposition, authors in [25] apply the TVQI model to generate a small-scale part that contains more detailed information. Recently, in order to incorporate the inherent effectiveness of individual illumination normalization technique, a three-stage chain of preprocessing techniques proposed in [26].However, the use of the normalization techniques on illuminated images is subjective in nature. That is, illumination normalization technique is applied on all images irrespective of the degree of illumination variations. On the other hand, it is trivial, and may be impossible, to predict how the appearance of the image would be during acquisition. Therefore, if any of the techniques applied to all images irrespective the way, they are illuminated, might lead to feature loss in well illuminated part. So the focus area of our research is to exploit the effectiveness of any technique based on the illumination type. The estimation of illumination type based on the ambiguity in the gray level can be very well modeled with the help of soft computing tool such as rough sets [6]. Considering ambiguity in the gray level as rough terms, the concepts of dark, normal and shadow can be expressed by membership functions. If the images can be classified as dark, shadow and normal, based on their illumination type, an appropriate normalization technique like histogram, SQI, homomorphic, can be chosen for illumination normalization and thus it ensures that there is no loss of features. In addition, there is no need to normalize the normal image which will save the processing time.In this paper, we propose a system that applies the illumination normalization technique to only those facial images which are not properly illuminated and then extract the facial features for recognition. This is achieved through a decision based rmf classifier that is basically based on rough membership function (rmf). For illumination classification, we first extract texture based statistical parameters from the illuminated images. Geometrical facial features [30] are directly extracted from properly illuminated images classified as normal, without any illumination normalization; whereas shadow and dark images must be normalized with an appropriate technique before feature extraction. Any test image is first checked and preprocessed for noise and blur and then statistical parameters are extracted for illumination classification. According to these three different illumination type's relevant illumination normalization technique is selected and images are pre-processed for variation in illumination. Later, geometrical features are extracted for recognition of images from trained face database. For recognition nearest neighbor classifier has been used. The contribution of our work is twofold: First, proposed system statistically models variations in illumination using more than one parameter (i.e. average intensity value) and second, proposed system shows an optimized approach as in our case illumination normalization technique can be selected based on illumination type. The remainder of the paper is organized as follows: Section 2 presents the related theory on illumination ambiguity and rough set theory. Section 3 discusses the proposed system that emphasizes on the design of rmf illumination classifier. Section 4 presents the experimentation and simulation results, followed by conclusions.As said earlier variation in illumination is still a great challenge for face recognition. In order to understand the problem of illumination variation, this section firstly discusses the issues present with variation in illumination in brief. Next, the overview of rough set theory is presented in short.Due to large variations in illumination, it is very difficult to identify the image of a particular person from a given set of images. For example, in Fig. 1, the set of images shown are the faces of a same person. From these set of images it is impossible to conclude that these images are of the same person.In addition, experimentally it is observed that application of any particular illumination normalization technique is not efficient enough to map all the variations present in illumination. Fig. 2(b) and (c) shows that, for larger degree of variations in illumination or lighting histogram equalization [3] and gamma correction [3] have not shown smooth result, respectively. In contrast, illuminated images normalized with homomorphic [3] as shown in Fig. 2(d) and with SQI [9] in Fig. 2(e) have shown smother results for dark and shadow images comparatively.This shows that if the illumination of an image can be classified in proper illumination type, a particular technique could be used from the bank of illumination normalization techniques. This can be achieved through gray level property, i.e. average intensity value [25] and set theory. For instance, from Fig. 3, we will define a set of gray levels that share the illumination type dark using the classical set theory. For example, let the threshold (gray level value) be 50, as observed from the gray bar shown in Fig. 3. Then all the gray levels between 0 and 50 will be element of the dark set and the other gray values will not belong to this set as shown in Fig. 3. At this stage, if an image with gray value 51 is considered for example, it does not belong to the defined dark set even though it is a dark image. This gives an idea, that, the boundary between two gray levels is indistinct or vague in nature.Moreover, a single parameter for example an average intensity value alone is not sufficient to classify the image as dark, normal or shadow image. The problem arises in such images when it comes to decide whether an image should be considered for illumination normalization based on the average intensity value of an image. For instance, the image in Fig. 4needs illumination compensation, but due to some well illuminated parts present in the image, the luminance value climbs up to an exceptionally large value classifying it as a normal image, thereby missing the required preprocessing. Thereby we conclude that darkness and brightness of an image is a matter of degree. Further, this degree of vagueness and uncertainty can be very well modeled with the help of systematic and mathematically founded method based on statistical parameters such as average mean level, and standard deviation. Modeling such a system can be achieved using a rough set theory (RST) as it very well deals with vagueness and uncertainty present in the data. The overview of rough set theory is presented in the forthcoming section.In RST [6], information about the real world is given in the form of an information table. An information table can be represented as a pairA=(U,A), where, U is a non-empty finite set of objects called the universe and A is a non-empty finite set of attributes such that information function fa:U→Va, for every a∈A. The set Vais called the value set of a. Furthermore, a decision system is any information table of the formA=(U,A∪{d}), where d∉A is a decision attribute. For every set of attributes B⊆A, an indiscernibility relation IND(B) is defined in the following way: two objects, xiand xj, are indiscernible by the set of attributes B⊆A, if b(xi)=b(xj) for every b⊆B. The equivalence class of IND(B) is called elementary set in B because it represents the smallest discernible groups of objects. For any element xiof U, the equivalence class of xiin relation IND(B) is represented as [xi]IND(B). The notation [x]Bdenotes equivalence classes. Thus the family of all equivalence classes, partition the universe for all B will be denoted by U/B. This partitions induced by an equivalence relation can be used to build new subsets of the universe. The construction of equivalence classes is the first step in classification with rough sets.Rough sets can also be defined by rough membership function instead of approximation. A rough membership function (rmf) makes it possible to measure the degree that any specified object with given attribute values belongs to a given decision set X. Let, B⊆A and let X be a set of observations of interest. The degree of overlap between X and [x]Bcontaining x can be quantified with an rmf value computed through Eq. (2):(1)μXB:→[0,1](2)μXB(x)=|[x]B∩X||[x]B|where |·| denotes the cardinality of a set. The rough membership valueμXBmay be interpreted as the conditional probability that an arbitrary element x belongs to X given B. The decision set X is called a generating set of the rough membershipμXB. Thus rough membership function quantifies the degree of relative overlap between the decision set X and the equivalence class to which x belongs.In order to overcome the problem of selection of appropriate illumination normalization technique according to all type of illumination, this section presents a decision based rmf classifier based on rough membership function (rmf). The basic idea is to apply normalization technique to only those facial images which are not properly illuminated and then extract the geometrical features for face recognition. For properly illuminated images which we refer as normal images, features are directly extracted for face recognition without any illumination normalization. The complete architecture of proposed system for illumination invariant face recognition shown in Fig. 5is presented in detail. The proposed system consists of four separate modules. These modules are; (1) illumination classification using rmf classifier (2) preprocessing (3) feature extraction to represent the face and (4) at last recognizing the test face from the train face database.The proposed illumination classification technique is a two step process; first is the computation of features to represent the illumination variation and the second is illumination classification through rough sets.In general, feature extraction is an important step before classification. Instead of single feature i.e., average intensity value, four statistical parameters are used as attributes to characterize each illumination type namely: (1) average mean level (b1), (2) standard deviation (b2), (3) uniformity (b3) and (4) entropy (b4) [3]. Average mean level is a measure representing the average intensity of all the pixel values in the image (face). Standard deviation of the pixel intensities is a measure of root mean square (RMS) of contrast. Third parameter measures the uniformity of an image texture. Entropy is a measure of randomness. Our choice of these statistical attributes for classification is influenced by work presented in [15,17]. In order to find the illumination type (dark, normal and shadow) following functions are defined for each attribute based on the experimental values. Table 1shows information table for sample 10 images (I1, I2,…,I10) based on four parameters as features/attributes (b1, b2, b3 and b4).In this section, the objective is to present rough set based illumination classifier to cater the existence of vagueness/ambiguity in the data set due to variation in illumination. There in, the training observations from data set are assumed to belong to a finite set of illumination type (dark, normal and shadow) and the built classifier is capable of assigning the test data to one of the three illumination types.For any real world problem, such as face recognition, feature/attribute values are continuous data as seen in Table 1. These set of continuous data are proven to be rather unsuitable for depiction of crisp decision class and also, rough sets find its application for discrete values for various domains [31,32]. Hence, first of all, the original data have to be disjointedly discretized to generate function values f. As given in [32], let S be a continuous data and let the domain of S be the interval [p,q]. A partition φSon [p,q] is defined as the following set of m subintervals (definition given in [32]):(3)φS={[p0,p1),[p1,p2),…,[pm−1,pm]}where p0=p,pi−1>pifor i=1,2,…,m, and pm=q. Thus, discretization is the process that produces a partition φSon [p,q]. Here, interval based discretization method is adapted depicted through Algorithm 1. For instance the interval range for each attribute for the images taken from YaleB database is shown in Table 2. The continuous values of features have been discretized into function values as shown in Table 3.Once the data values of information table have been discretized the next step is classification of images based on its illumination type. At this point, the facial images from YaleB Database with different illumination variations formed the universe of images U. For instance, U={x|x′ is an image with illumination variations}={I1|yaleB01_P00A+000E+00.pgm, I2|yaleB01_P00A+000E+20.pgm, I3|yaleB01_P00A+000E+45.pgm, I4|yaleB01_P00A+000E+90.pgm,…}, where {x=I1,I2,I3,…,IN} are the number assigned to each sample image in information table and x′=yaleB01_P00A+000E+00.pgm is the actual name of image from YaleB face database. With these values of U and aforesaid F={f1, f2, f3, f4} next step is to construct the decision system with function values as shown in Table 3, which is necessary for classification. To build this decision table, the shape of histogram of each illuminated image can be used to decide the values for decision attributes. It is evident that the shape of gray level histogram gives an idea about the overall appearance of an image as shown in Fig. 6. Experimentally it has been observed that, for dark images gray level histogram is negatively skewed, for normal images the shape of histogram is bell shaped and for shadow images it is not well defined. Taking these shapes into consideration, label (decision value) has been assigned to each illumination type. For instance, here we have considered only 10 images (i.e. objects) which are divided into three illumination type (i.e. decision classes). Each object face is assigned into one of three illumination type according to the nearest view value; dark=0, normal=1 and shadow=2. Thus the sample decision table is shown in Table 3.Algorithm 1(Interval based discretization of continuous data)Given:N×Pcontinuous feature data value set matrix (where N=number of attributes in P=number of samples)Step 1: For each attribute b∈N•Find the range of values which falls in one intervalStep 2: For each discrete range of every attribute•label each discrete range with i=1,2,3,…,nStep 3: Get the discretized information table.Once the decision table with feature values is prepared, it can be partitioned into the following sets of equivalence classes shown in Table 4(as discussed in Section 2.2). Images I4 and I6 are indiscernible with respect to the function values generated and therefore constitute equivalence class. These images belong to different decision classes. The set of all decision classes related to an equivalence class is called the generalized decision of this equivalence class.The decision of classes of normal and shadow images are rough sets because they cannot be defined uniquely in term of the equivalence classes. They can, however, be defined either by an approximation or rough member ship function. Standard decision/target sets, we summarize in terms of the decision attribute value. For instance, normal target set={x: d(x)=1}. For the given decision classes, three different target sets can be formed as:•dark target set 0={I5,I2,I9,I10}normal target set 1={I1,I6}shadow target set 2={I3,I4,I7,I8}The approximation that an image belongs to a particular illumination type is computed with membership function called rough membership function. For instance, consider the degree of overlap of equivalence class [1]Bwith the decision sets normal target set 1. The degree of overlap is calculated using rmf given in Eq. (2).=|[1]B∩normaltargetset1||[1]B|=1/2=0.5This demonstrates that the degree to which the images in class [1]Bbelong to normal target set 1 is 50%. This shows that images in class [1]Band the images in the set normal target on set 1 are partially related. The highest rmf for any of the decision set indicates the illumination type of the test facial image. The proximity of the rmf value that we spoke about in Eq. (2) shall be in acceptable tolerance limit of 0.5.Note that, here we are really interested in whether these illumination types can be predicted for the unknown data. Let us assume that we have three new images with the following attribute values shown in Table 5. The resultant output is shown in Table 6, where the bold number symbolizes the rmf value for particular illumination type for each of the test images. Here, we can check that the classification of illumination to its correct type is same as that of the actual illumination type. Once the exact illumination type of the face image is determined, next module is to normalize the variation in illumination through appropriate illumination normalization technique.In order to simulate a real time environment, test image is first checked for blur (may be due to camera motion or lack of focus). If the test image is blurred and noisy, it is first pre-processed as shown in Fig. 7. For any test image, the type of noise can be estimated from its histogram shape. For instance, a set of blur and noisy facial images have been prepared by adding Gaussian noise of varying variance and blurred the image with motion function. Manually by looking at test image it has been decided for preprocessing before the computation of statistical parameter for illumination classification. To remove the effect of noise and restore the blurred image Wiener filter [3,4] was applied. To get effective results for some test images, deblurring have been applied iteratively, until the best approximation of the original image is achieved. After restoration again if some noise is present it is being removed by reapplication of Weiner technique. The deblurred and sharpened image is sharpened with replicated function. The resultant images after each operation are shown in Fig. 7.Once the illuminations of facial images are classified in one of the desired type next step is to preprocess them using illumination normalization. Based on the experiments conducted shown in Fig. 2, it is observed that, Homomorphic technique is efficient for even ambient images as shown in Fig. 2(d). On contrary, SQI has shown smooth results for partial effects of illumination i.e., for shadow images. Afterward, the geometry-based approach [30] has been used to extract the facial features for face representation. This approach basically focuses on locating the certain characteristic points, e.g.; the corners of the eyes, the nose tip, etc. and remaining features listed in Table 7are automatically calculated. These extracted features are further used for recognizing the person using nearest neighbor classifier.The proposed system is evaluated by two separate set of experiments. In the first experiment, for the illumination classification, it was considered immaterial whether or not the person is recognized. Generally, the performance of any classification technique in an unnoticed circumstance can be improved if more number of training images is available. Therefore, experiment is carried out with 3, 4, 5 and 6 train samples/subject. It is observed that 5 train samples per subject give better result and no significant improvement in performance is noticed for 6 samples. This has encouraged us to use 5 training sample images per subject to train the system. Also, statistical parameters computed from these five samples that are randomly chosen in five different illumination variations helps in building a strong train system. Further, illumination variations even vary for each individual in terms of (azimuth, elevation). During testing, exclusively, images of those subjects with completely different variations are also taken into consideration on which training is not performed. Testing has also been performed on images that have been degraded with blur and noise.In the second set of experiments we have normalized only those images with appropriate illumination normalization technique that has been classified as either dark or shadow. No illumination normalization has been performed on normal images. Images classified as dark is normalized with homomorphic technique and images classified as shadow normalized with SQI. The features for face recognition are extracted from the normalized images by applying the canny edge detection algorithm to locate the fiducial points as shown in Fig. 11. Using five facial points (the outside corners of each eye, the outside corners of the mouth, and the tip of the nose), the facial symmetry axis is found by connecting a line between the midpoint of the eyes and midpoint of the mouth [28]. Locating the same desired facial points, the geometrical spatial relations between the facial feature points are computed to represent a face [30].In order to test the performance of the proposed system, both the experiments have been performed on the Extended YaleB face database [21], CMU-PIE face database [33] and our own face database. Since we are concerned with the illumination variation problem, only frontal faces under different illumination conditions are chosen from all the three databases.Extended YaleB [21] database consists of whole range of illumination space and has obviously become a standard for variable-illumination recognition algorithms. The Extended YaleB contains approximately 2496 facial images (640×486 pixels) of 39 different individual subjects. Each individual is seen under 64 different illumination conditions with varying expressions. Classification performance of the proposed rmf classifier is assessed on the total test input of 1500 images of 30 subjects (50 different illumination conditions of each individual) selected randomly.We first investigated the performance of the proposed rmf classifier. The highest rmf indicates the illumination type of test image. To test the accuracy of the proposed classification, images of every type of illumination are used to create the testing table shown in Table 8(only few examples are shown in Table 8). Performance of rmf classifier for illumination classification for few test samples is shown in resultant Table 9. A summary of the overall performance is tabulated in Table 10. We obtained the performance as 99% for the normal and 100% for the dark and 98% for shadow images. Performance tends to be slightly poorer for shadow images because of uneven distribution of lighting from all directions. Proposed rmf illumination classifier has achieved on an average 98.8% illumination classification on a wider range of variations for extended YaleB face database. Sample images from correctly classified images and misclassified images are shown in Figs. 8 and 9, respectively. Results of normalized images with appropriate technique after it has been classified as dark, normal or shadow is shown in Fig. 10.From experiment, it is observed that homomorphic and SQI have shown excellent and smooth results for dark and shadow images, respectively. The resultant images in Fig. 10 shows that instead of applying any particular normalization technique on all range of variations in illumination, if we first classify the illumination type and then we select the normalization technique yields more better result. The classification results of proposed rmf classifier are compared against state-of-art classifiers such as k-nearest neighbor classifier [19], SVM [23], and neural network [24]. SVM-Torch software with Gaussian kernels has been used to train and perform multiclass classification. The comparative results are depicted in Table 11. It is observed from Fig. 11, that more clear and relevant fiducial points are obtained from images that are pre-processed with an appropriate illumination normalization technique.In order to prove the validity of our proposed system, same experiment is conducted on CMU-PIE face database [33]. The CMU-PIE database consists of 41,368 images of 68 subjects. The images are acquired from 13 different poses, with 43 different illumination conditions and with 4 different facial expressions. Moreover, this database also consists of images captured both with the room lights on as shown in top row of Fig. 12and with the room lights off shown in bottom row of Fig. 12. On contrary, YaleB illumination database consists of the images that were captured only with the room lights switched off. Therefore, only those facial images are selected from CMU-PIE face database which are similar to the YaleB database in-order to determine the robustness of proposed system to illumination change for both the databases. Twenty-four frontal face images per person under different illumination conditions have been considered that has been captured from camera c27 (totally, 1632 face images). For every subject 5 random images with varying illumination are selected for training and remaining 19 images are used for testing.Resultant images classified as shadow and dark are shown in Fig. 13(a) and (b), respectively. It shows that how efficiently an existing illumination normalization technique can be utilized for illuminating the appearance of a face hidden due to illumination problem after classifying it in one of the illumination type, based on the decision of rmf classifier. Specifically, the classified ambient images from CMU-PIE face database when normalized with homomorphic illumination normalization technique, it is observed that they are blank images with no facial images. Moreover, we have only considered the frontal images, the illumination variation for faces in the CMU-PIE face database that can be classified as dark are almost not present.The proposed system is also evaluated on ORL face database [34]. There are 400 images of 40 subjects (10 samples per subject). All the face images are of size 92×112 with 256 gray levels. The face data has male or female subjects, with or without glasses, with or without beard, with or without some facial expression, with varied poses and scales. Each image was manually cropped and resized to 60×60 pixels with aligned eye positions. Training is performed with randomly chosen 5 samples per subject and remaining 5 images were used for testing. The results of illumination classification is depicted is Table 11. If the performance depicted in Table 11 of three standard face databases such as YaleB, CMU-PIE and ORL is compared YaleB has outperformed. The results of CMU-PIE and ORL degrade to 95.03% and 98.70%. The overall recognition performance of all face databases is depicted in Table 12. The results shows that CMU-PIE and ORL have shown inferior results compared to YaleB. The reason could be that a few good number of sample images in both the face databases are also have variation in poses in addition to illumination variation.Lastly, we also tested the variations in illumination from the real-world environments. The experiment is conducted on our own database. This database contains 200 images of 10 individuals, each with 20 different illuminations. Few samples are shown in Fig. 14. Although the database is relatively very small, it contains images with difficult illumination variations where one cannot predict the degree of variations in illumination same as that of standard face databases. Each image is manually cropped and resized to 60×60 pixels with aligned eye positions. Out of 20 samples we use 5 sample images for training and 15 remaining images for testing. Table 11 shows the performance of different classifiers for our own face database. Table 11 illustrates that the performance deteriorates by an approximate rate of 10% compared to standard face databases. This is due to the fact the images have been captured under real illumination variations. However, the rmf classifier has shown better performance in terms of overall accuracy. Thus the proposed rmf classifier is successful in classifying illuminated images under difficult conditions of illumination variations based on rough membership functions using four statistical parameters.With large number of face recognition algorithms available in the literature, direct comparison between them is very difficult since tests are normally performed on different data sets and in different experimental environment. Even though, we cannot show the direct comparison, we compare the results of proposed system with the results of approach performed on the CMU-PIE and ORL face databases. In Table 13, all the results for comparison are directly cited from the related paper. Table 13 depicts the improvement in the performance through the proposed face recognition system. The performance of proposed system is comparable with the approach proposed in [28,36]. One advantage of proposed system over the approach proposed in [36], instead of applying two normalization technique one after another, we apply any one illumination normalization technique based on the decision given by rmf classifier. This makes our proposed system computationally more efficient. For the CMU-PIE face database the results are compared with the approach proposed in [37] and shows an improvement. The most important thing is, the performance of any approach mainly depends on the face database used for evaluation and number of training images used in the experimentation.The overall advantages offered by the proposed system is that instead of taking decision based on a single parameter (average intensity value) as in [25]; more than one parameter like average mean level, standard deviation, uniformity and entropy have been used to make the decision about the illumination type of the image. This leads to a more robust and reliable decision system. Even authors in [26] have also used the normal images (ideal) as training samples but nowhere it has been mentioned that on what basis those images have been considered as ideal images. In this regard, when illumination of images has to be classified as normal, shadow or dark for further processing our proposed approach adds a new dimension to it. Yet, another approach proposed in [27] seeks conventional image illumination normalization techniques by incorporating series of steps. Three-stage processing chain has been employed that normalize for various effects of the changing illumination environment. Practically, it is trivial to predict how the appearance of the image would be during acquisition. At this point, application of chain of illumination normalization techniques to all images will be computationally high. On the contrast, proposed system makes use of any one appropriate illumination normalization technique based on the illumination type. Here, the main advantages of proposed system are simplicity and computational efficiency.The proposed rmf classifier for illumination classification uses a rough membership function of rough set theory. Proposed rmf classifier uses four statistical parameters for illumination variations classification. Experimentation on the YaleB, CMU-PIE and our own face databases has shown that the proposed rmf classifier accurately classify the images under difficult illumination variations as normal, shadow and dark. After illumination classification, the shadow images are normalized with SQI and dark images with homomorphic illumination normalization techniques. That permits us to select one appropriate illumination normalization technique based on the rmf decision model. In this regard, the proposed system contributes in the selection of illumination normalization technique through a simple and computational efficient decision model. The average illumination classification results for all the four different face databases are 96.36% that shows the robustness of proposed system.The work can be extended for video base face recognition system. When a video is captured in real time environment, effect of lighting is not in human control. For a subject moving around in a video, there will be no constant lighting from all direction. In such videos where for each frame we get different types of illumination, use of any particular illumination normalization technique will not suffice the illumination compensation. So the proposed machine learning model for classification of illumination, based on statistical parameters will be effective. This will help in illumination compensation with proper selection of illumination compensation techniques.

@&#CONCLUSIONS@&#
