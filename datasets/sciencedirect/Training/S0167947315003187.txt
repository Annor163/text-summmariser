@&#MAIN-TITLE@&#
Using hierarchical centering to facilitate a reversible jump MCMC algorithm for random effects models

@&#HIGHLIGHTS@&#
We consider a hierarchical centering approach for reversible jump MCMC algorithms.We describe the case for a log-linear Poisson model with mixed effects.The zero-mean of the random effect is replaced with part of the linear predictor.We apply the methods to point transect data of indigo buntings and simulated data.Our methods improve model mixing and inference on parameters.

@&#KEYPHRASES@&#
Combined likelihood,“Metropolis–Hastings”,Point transect sampling,Random effects,Reparameterization,

@&#ABSTRACT@&#
Hierarchical centering has been described as a reparameterization method applicable to random effects models. It has been shown to improve mixing of models in the context of Markov chain Monte Carlo (MCMC) methods. A hierarchical centering approach is proposed for reversible jump MCMC (RJMCMC) chains which builds upon the hierarchical centering methods for MCMC chains and uses them to reparameterize models in an RJMCMC algorithm. Although these methods may be applicable to models with other error distributions, the case is described for a log-linear Poisson model where the expected valueλincludes fixed effect covariates and a random effect for which normality is assumed with a zero-mean and unknown standard deviation. For the proposed RJMCMC algorithm including hierarchical centering, the models are reparameterized by modeling the mean of the random effect coefficients as a function of the intercept of theλmodel and one or more of the available fixed effect covariates depending on the model. The method is appropriate when fixed-effect covariates are constant within random effect groups. This has an effect on the dynamics of the RJMCMC algorithm and improves model mixing. The methods are applied to a case study of point transects of indigo buntings where, without hierarchical centering, the RJMCMC algorithm had poor mixing and the estimated posterior distribution depended on the starting model. With hierarchical centering on the other hand, the chain moved freely over model and parameter space. These results are confirmed with a simulation study. Hence, the proposed methods should be considered as a regular strategy for implementing models with random effects in RJMCMC algorithms; they facilitate convergence of these algorithms and help avoid false inference on model parameters.

@&#INTRODUCTION@&#
For Bayesian analyses, for a given model, the posterior distribution of the parameters is formed by combining the likelihood of the data with the prior distributions of the parameters. A Markov chain Monte Carlo (MCMC) algorithm is often used to sample from this posterior distribution to obtain inference on the parameters of interest. In the presence of model uncertainty, the posterior distribution can be extended to be defined jointly over both parameter and model space. This posterior distribution is often explored using the reversible jump Markov chain Monte Carlo (RJMCMC) algorithm (Green, 1995). However, the art of setting up an RJMCMC algorithm can be challenging on multiple levels. The objective is generally to construct a chain that moves freely between models, efficiently exploring model and parameter space simultaneously.The RJMCMC algorithm entails iteratively updating the parameters conditional on the model (i.e. within-model move) and then updating the model (and corresponding model parameters) conditional on the current parameters (i.e. between-model move). Mixing problems for the within-model moves are often due to high autocorrelation within the constructed Markov chain. Improvements for mixing within a given model have been investigated in the framework of MCMC with the aim of reducing posterior correlations and increasing the effective sample size by reparameterization. In this context, Browne (2004) and Browne et al. (2009) have shown that hierarchical centering (first described by Gelfand et al., 1995) can significantly reduce the autocorrelation within the MCMC algorithm. The use of hierarchical centering in the presence of random effects refers to exchanging the zero-mean of the random effect component, typically assumed to be of normal form, with a model consisting of an intercept and one or more fixed effect covariates. This will be described in detail in Section  2. Papaspiliopoulos et al. (2007) investigated the circumstances when hierarchical centering performs well in comparison to noncentering for MCMC algorithms.Other methods for improving mixing of an MCMC algorithm include parameter expansion, which refers to augmenting the model with additional parameters to form an expanded model (Browne, 2004). The original model is embedded in the expanded one and parameters from the original model can be constructed with parameters from the expanded model. Vines et al. (1995) describe a method of reparameterization for random effects models called sweeping which is suitable also for models with multiple sets of random effects in a generalized linear mixed model (glmm) framework. The idea consists of adding the mean of the random effect coefficients to the intercept of the fixed effects while subtracting the same quantity from each random effect coefficient.For the between-model move in an RJMCMC algorithm (the RJ step), the current model is updated by proposing to move to an alternative model (with given parameters) and accepting this move with some probability. Mixing problems for these between-model moves may arise for multiple reasons, e.g. due to difficulties in finding proposal distributions and updating procedures that produce suitable acceptance probabilities. Besides careful pilot-tuning of proposal distributions, several methods for improving the acceptance rate for the reversible jump step have been proposed. For example, Green and Mira (2001) proposed delayed rejection, where after initial rejection a second attempt to jump is made with samples generated from a new distribution that may depend on the rejected proposal. Brooks et al. (2003) assumed a family for the proposal distribution, where the proposal parameters are chosen to maximize (in some form) the acceptance probability. Al-Awadhi et al. (2004) demonstrated that increasing acceptance probabilities may be achieved by using a secondary Markov chain with a fixed number of steps that serves to move the value of an RJMCMC proposal closer to a mode before calculating the acceptance probability for the proposed move. Papathomas et al. (2011) proposed that model mixing for generalized linear models may be improved by using proposal densities that draw samples from parameter subspaces of competing models. Forster et al. (2012) used the Laplace approximation to integrate out the random effects and orthogonal projections of the current linear predictor onto the proposed linear predictor to produce effective proposals for glmms.While these previous approaches describe strategies to improve the acceptance rate for RJ steps in general, they can be quite complex to implement. We propose an approach using hierarchical centering that is relatively straightforward to implement for random/mixed effect models. A particular problem that one may encounter with random effect models is that the random effect coefficients may begin absorbing the effect of one or more fixed effect covariates if these are not present in the model at times during the Markov chain. The inclusion of such effects into the model may then be unlikely as they are already accounted for within the random effects. We will demonstrate below that using hierarchical centering provides a simple way of reparameterizing the model that will prevent this problem and improve the between-model mixing.Hierarchical centering was initially described by Gelfand et al. (1995) as a method to improve convergence for mixed models using MCMC methods. Here we extend the ideas to improve mixing in an RJMCMC algorithm. Although our methods may be applicable to models with other error distributions, we consider the case for a log-linear Poisson model with fixed effects and a normally distributed random effect, where the overall likelihood combines the Poisson likelihood for each observation and the normal density for each random effect coefficient. We demonstrate how the Poisson likelihoods and the normal densities are affected differently during a proposal to add a covariate for a regular RJMCMC algorithm and one including hierarchical centering.We demonstrate the improved model mixing using a case study of point transects of indigo buntings (Passerina cyanea L.). Point transects are a form of distance sampling (Buckland et al., 2001) where, in addition to the number of detections during the counts, distance from the point to each detection is collected. This allows estimation of the average detection probabilities at the point and adjustment of counts for imperfect detection. To study the effect of establishing conservation buffers along margins of agricultural fields on density of several species of conservation interest, pairs of points were set up at the edge of fields in a number of states in the USA. These pairs of points consisted of one point on a treatment field and one on a nearby control field without a buffer and these pairs will be referred to as sites in the following. Counts were repeated 1–4 times in each year 2006–2007. We use a combined likelihood including the likelihoods for the detection function and the log-linear Poisson model where counts are adjusted for imperfect detection within the search area around the point (Oedekoven et al., 2014). A random effect for site is included in the Poisson model to accommodate correlated counts between different sites.In the following we describe how to implement hierarchical centering for RJMCMC, describe the effects on the dynamics of the algorithm, and present updating methods for the RJ step using hierarchical centering (Section  2). We then apply the methods to our case study (Section  3) and confirm our results with a simulation study (Section  4) and discuss our findings (Section  5).The hierarchical centering described in this paper refers to mixed effect models where a normal distribution is assumed for the random effect. Other distributions may be assumed for the random effect (e.g.  Komárek and Lesaffre, 2008) to which these methods can be applied but we focus on the normal distribution for simplicity. We describe the case for a glmm with a Poisson error structure, suitable e.g. for fitting a model to correlated count data from repeated measurements. In the following we denote the different groups for the random effect with subscriptjand the repeated measurements within the individual groups with subscriptr. Here, the expected valueλjris modeled via a log-link function with a common intercept,β0and random effect coefficientsbjfor groupsjare included for which normality is assumed. For a mixed effect model without hierarchical centering, the random effect is incorporated into the model under the assumption of a global zero-mean and unknown standard deviation,σb, i.e.bj∼N(0,σb2)(e.g.  Bates, 2009). Let us assume we have a set ofKcovariates fork=1,…,K,xk(and associated coefficients,βk) that can be incorporated as fixed effects. The expected value for the full model including all covariates may then be expressed as:(1)λjr=exp(β0+∑k=1Kxkjrβk+bj),bj∼N(μj=0,σb2),where thexkjrare the measured covariate values corresponding to therth observation of the response of groupj. While all potential models include the intercept and the random effect, different models included in the RJMCMC algorithm correspond to the combinations of covariates present in the model (i.e. non-zeroβkvalues). During a between-model move (the RJ step) of an RJMCMC algorithm using this scenario, the proposal to delete or add one (or more) of the covariates alters the formula forλjrwhile the distribution for the random effects termsbjremains the same (see Appendix A for details on the RJ step).Let us now assume that one covariate, sayx1, was measured at the group level, i.e. values for all repeated measurements for this covariate within a given group were the same, which allows us to usex1for hierarchical centering. In hierarchical centering, the mean of the random effect is modeled using a combination of the interceptβ0and one or more covariates that are “pulled from” theλjrmodel from (1) (Gelfand et al., 1995). In the case that the intercept and covariatex1are used for centering, the full model from (1) becomes:(2)λjr=exp(∑k=2Kxkjrβk+bj),bj∼N(μj=β0+x1jβ1,σb2).Note that we omitted the subscriptrfor covariatex1in (2) since we assume that the measured values for this covariate were the same for all observations in groupj. The proposal to delete or addx1from the model during the RJ step of the RJMCMC algorithm involves altering the distribution forbj, while the proposal to delete or add any other covariates remains the same as before in (1) (altering the formula forλjr).In the case that allkcovariates were measured at the group level, all covariates may be included in the centering and the full model from (1) becomes:(3)λjr=exp(bj),bj∼N(μj=β0+∑k=1Kxkjβk,σb2).Again, we omitted the subscriptrfor the covariates in the model forμjin (3). In (3), it could be omitted fromλjras well, as there are no covariates in theλjrmodel (or theμjmodel) that may vary between different observations within the same group. However, we keep it for simplicity in the following equations. In this scenario, the formula forλjrremains unchanged during the proposals to delete or add any of the covariates, while the distribution forbjchanges for each proposed model move.We note that it is essential that only those covariates are included in the centering (i.e.x1in (2) orxkwithk=1,…,Kin (3)) that have the same measured value for all observations within a group (Browne et al., 2009). We refer to a group in terms of the grouping unit for the random effect where grouping should occur to account for intra-group dependence (Davison, 2003). All observations belonging to the same groupjare modeled with the same random effect coefficientbjin the equations above.The proposed hierarchical centering is only applicable if for at least one covariate, measured values for the respective covariate are the same within a group. If, for example, the grouping unit for a study is site, then the covariate state (the geographical governed entity) can be included in the centering as each site only belongs to one state and all repeated observations for a site belong to the same state. Conversely, Julian day could not be included as values will likely vary between repeated measurements. As long as this condition holds, any combination of covariates may be included.Hierarchical centering relies on the fact that the random effect coefficients pick up the effect of the covariates included in the centering (given that they have an effect) as they are updated during the within-model move of each iteration of the RJMCMC. Running separate MCMC algorithms (without between-model moves) on the full models from (1), (2) or (3) should result in nearly identical summary statistics for the covariates if the chain was run long enough (since all Markov chains have the same stationary distribution), although mixing might be different for these different parameterizations. However, when including the between-model moves in an RJMCMC algorithm, mixing problems can become more severe, potentially leading to different summary statistics–due to lack of convergence–and hence potentially to the wrong conclusions. Here, convergence and, hence, obtaining correct results may depend on which scenario and initial starting values were used. If, e.g. under the scenario of (1), the random effect coefficients absorb the effect of covariatex1, the chain may get “stuck” in models that do not includex1. For the scenarios of (2) and (3), moves to models including covariatex1would be favored if the random effect coefficients absorbed the effect ofx1as then the coefficients will be closer to their modeled means. We will show below that this is due to the fact that here different parts of the likelihood are affected by a proposed model move compared to (1).Using either one of the models forλjrfrom above ((1), (2), or (3)), the likelihood of the log-linear Poisson model,Ln(β,σb), with a normally distributed random effect may be formulated as (modified from McCulloch and Searle, 2001):(4)Ln(β,σb)=∏j=1J(∏r=1Rj(λjr)njrexp(−λjr)njr!×12πσj2exp(−(bj−μj)22σj2)),where vectorβcontains the coefficients for covariates included in the models andnjrare the observed measurements of the response. The indicesj=1,2,3,…,Jrepresent the groups for the random effect andr=1,2,3,…,Rjindices for the different measurements taken for thejth group. Hence for each group of observations,j, the probability of observingnjrunder the log-linear Poisson model with expected value ofλjris multiplied for all observations within that group, which is then multiplied by the normal density of the random effect coefficientbj. The only coefficients that influence both parts of this likelihood, i.e. the Poisson likelihood for the observations and the normal densities, are the random effect coefficients, regardless of which scenario is used from the previous section.Consider now, that we use this likelihood as part of calculating the acceptance probabilities for updating the model as well as the fixed and random effect coefficients in an RJMCMC algorithm (e.g.  Oedekoven et al., 2014). Both the Poisson likelihood and the normal densities are higher if the observed value of the response or the random effect coefficients are closer to their respective means (λjrorμj, respectively). Hence, combining what we know from (1)–(4), it is evident that the Poisson likelihoods will improve if the variation that is not accounted for by the fixed effect coefficients is picked up by the random effect coefficients (which — as well as the fixed effect coefficients of the current model — are updated during the within-model move). On the other hand, the normal densities will return higher values for random effect coefficients close to their mean values.Intuitively, one may think that a problem arises for a between-model move (using models from (1)) when a covariate, sayx1, may have an effect but is not included in the current model. Then, the random effect coefficients may begin to absorb this effect and in this manner, adjust the value forλjrto improve the likelihood. This may result in a “tug-of-war” between the Poisson likelihood trying to adjust the coefficients in such a manner that the effect ofx1is accounted for and, on the other hand, the normal densities trying to keep the coefficients close to their mean, i.e. zero for (1). This will typically also result in an inflated random effect standard deviation since the random effect coefficients are replacing some unexplained variability attributable tox1. If this has indeed occurred, an acceptance ofx1into the model during a between-model move proposal may become very unlikely as its effect is already accounted for by the random effect coefficients. Hence, during a proposal to addx1, the new model withx1will create inferiorλjr. These will then return decreased likelihood values even if the randomly drawn value(s) forx1would produce a larger likelihood under circumstances before the effect has been absorbed by the random effect coefficients. In other words, the values of the random effect coefficients are dependent on the model. A strategy to account for this could be to jointly update the coefficient value(s) for covariatex1and the values for the random effect coefficients. However, this complicates the RJ step involving more complex proposal distributions.Alternatively, this issue may be addressed using hierarchical centering since proposing to addx1using either (2) or (3) into the model will not changeλjr(and the Poisson likelihood). Here, the random effect coefficients absorb the effects of the covariates included in the model (given they have an effect) within the mean of the random effect distribution (in addition to the interceptβ0). Using (2) this would be only covariatex1; using (3) this would be covariatesxkwithk=1,2,3,…,K. The only part of the likelihood that is affected when updating this/these covariate(s) for within-model and between-model moves are the normal densities from (4). It is likely that, on average, the normal densities improve for the individual random effect coefficients as these will on average be closer to their assumed mean. Asλjrremains the same, likelihood values returned by the Poisson part of (4) remain the same (which also increases the speed of calculating the acceptance probability for the RJ step since only the normal densities need to be evaluated).To demonstrate how to implement hierarchical centering, we use a simple example where during the between-model move of iterationt+1we propose to include covariatex1into an intercept-only model, say modelm. Suppose that at iterationtthe current state of the chain is modelm, whereλjr=exp(bj)withbj∼N(μj=β0,σb2)from (3) (although ifx1is the only covariate available,K=1and (2) and (3) are equivalent). During iterationt+1we propose to move to modelm′by adding covariatex1. Hence, modelm′is defined asλjr′=exp(bj′)withbj′∼N(μj′=β0′+x1jβ1′,σb′2). For simplicity, let us assume that covariatex1represents a categorical covariate with only two levels where the first level is absorbed in the interceptβ0′and the second level has an associated coefficientβ1′; hence,x1is either 0 for the first level or 1 for the second level. We note that these methods also apply in the case that the covariate used for centering has more than two factor levels. Let us further assume that all measurements within a groupjbelong to the same level ofx1and that, for simplicity, we have 200 groups where groupsj=1,…,100belong to the first level ofx1and groupsj=101,…,200belong to the second level ofx1. We use the identity function as the bijective function (King et al., 2010):(5)u0′=β0,β0′=u0,β1′=u1and draw samplesufrom the respective proposal distributions for the parametersβ0′andβ1′. See Appendix A for further details.In the following, we describe two different ways for implementing the RJ step. The difference between them lies in the definition of the proposal distributions for the new parameters for the between-model move, and, hence, should only have an influence on the acceptance probability of this move. The second approach (Section  2.2.2) uses more information compared to the first (Section  2.2.1) and should, on average, return higher acceptance rates for this move. Either method should not have an influence on estimated posterior summary statistics of the parameters in the final model given that the chain had an adequate burn-in.For this method, we define proposal distributions for the coefficientsβ0,β0′andβ1′. If, for example, normal proposal distributions are used, we define the proposal distributions for coefficientsβ1′asβ1′∼N(μ1′,σ1′2), for some predefinedμ1′andσ1′. Equivalently, the normal proposal distributions for the interceptsβ0andβ0′are defined asβ0∼N(μ0,σ02)andβ0′∼N(μ0′,σ0′2)(for some predefinedμ0,σ0,μ0′andσ0′).Here, the meanμ0of the proposal distribution for the global interceptβ0of modelmand the meansμ0′andμ1′of the proposal distributions for the coefficientsβ0′andβ1′of modelm′are updated before the RJ step during each iteration of the RJMCMC algorithm. To updateμ0at iterationt+1, we take the overall meanb̄jtof the current values of all random effect coefficientsbjt(i.e.β0t+1∼N(μ0t+1=b̄jt,σ02)including groupsj=1,…,200). To update theμ1′at iterationt+1, we take the meanb̄j′tof the random effect coefficients from iterationtbelonging to the second level of covariatex1. Hence, we haveβ1′t+1∼N(μ1′t+1=b̄j′t,σ1′2)only including groupsj=101,…,200. To updateμ0′at iterationt+1, we take the meanb̄j′tof all random effect coefficients belonging to the first level of covariatex1(i.e. groupsj=1,…,100).To establish the success of planting herbaceous buffers around agricultural fields in several South-eastern and Midwestern US states, point transect surveys were conducted from a large number of randomly selected fields during the breeding season (May–July) of 2006–2007 in each participating state (Fig. B.1,Oedekoven et al., 2013). Survey points on control fields of the same agricultural use and located within 1–3 km were surveyed concurrently. Each pair of adjacent points from a treated and control field was considered a site. Points were located at the edge of the fields. Observers recorded all male indigo buntings (all singles) detected either visually or aurally during a 10-minute count at each point in one of five predetermined distance intervals (0–25, 25–50, 50–100, 100–250, 250–500 and >500 m). It is assumed that indigo buntings distribute themselves evenly within and in the various possible habitats adjacent to the field. Only those sites that were surveyed at least once in each survey year were included in the analysis. These 446 sites were located in nine states: Georgia, Iowa, Illinois, Kentucky, Missouri, Mississippi, Ohio, South Carolina and Tennessee.

@&#CONCLUSIONS@&#
