@&#MAIN-TITLE@&#
Comparative assessment of feature extraction methods for visual odometry in wireless capsule endoscopy

@&#HIGHLIGHTS@&#
Wireless capsule endoscopes can be localized based solely on visual features.State-of-the-art visual localization strategies are compared.Several visual feature extraction methods are applied.A significantly lower localization error than the state of the art is reported.

@&#KEYPHRASES@&#
Wireless capsule endoscopy,Localization,Visual odometry,Feature extraction,Algorithm,Small bowel,Gastrointestinal tract,

@&#ABSTRACT@&#
Wireless capsule endoscopy (WCE) enables the non-invasive examination of the gastrointestinal (GI) tract by a swallowable device equipped with a miniature camera. Accurate localization of the capsule in the GI tract enables accurate localization of abnormalities for medical interventions such as biopsy and polyp resection; therefore, the optimization of the localization outcome is important. Current approaches to endoscopic capsule localization are mainly based on external sensors and transit time estimations. Recently, we demonstrated the feasibility of capsule localization based—entirely—on visual features, without the use of external sensors. This technique relies on a motion estimation algorithm that enables measurements of the distance and the rotation of the capsule from the acquired video frames. Towards the determination of an optimal visual feature extraction technique for capsule motion estimation, an extensive comparative assessment of several state-of-the-art techniques, using a publicly available dataset, is presented. The results show that the minimization of the localization error is possible at the cost of computational efficiency. A localization error of approximately one order of magnitude higher than the minimal one can be considered as compromise for the use of current computationally efficient feature extraction techniques.

@&#INTRODUCTION@&#
Wireless capsule endoscopy (WCE) is a non-invasive procedure for the visual inspection of the gastrointestinal (GI) tract [1]. It is performed with a miniaturized, swallowable endoscope packed into a capsule of the size of a large vitamin pill. It is equipped with one or more color cameras and during its journey to the anus it wirelessly transmits color images to an external receiver using radiofrequency (RF) signals [2].The knowledge of the exact location of the capsule endoscope within the GI tract is important for the localization of abnormalities. Since WCE is currently used only for screening purposes, any medical intervention for biopsy or treatment is performed at a secondary phase. For example, if a lesion, such as a polyp, is detected in the small bowel by WCE, a biopsy and/or lesion resection can be performed at a second phase with a more invasive technique, such as surgery or device-assisted enteroscopy [3]. Therefore, the accurate estimation of the location of the lesion by WCE increases the yield and outcome of subsequent interventions. In the case of an open surgical procedure this can result in minimal loss of intestine tissue during the operation, whereas in the case of double-balloon enteroscopy it can determine the insertion route (antegrade or retrograde) of the enteroscope as well as the insertion depth so as to minimize the patients׳ discomfort [4,5].In clinical practice, the location of an abnormality can be approximated by the estimation of the expected transit time of the capsule with respect to anatomic landmarks, and decision-making is based on a devised time index [6]. However, this localization approach can be very inaccurate, especially if the capsule cannot visualize the cecum [7,8].In addition to the transit time estimation, commercial WCE platforms provide the localization of the capsule in a 2-dimensional (2D) projection of the body with respect to the umbilicus, e.g., the abdominal quadrant where the capsule is located. This is accomplished by a wearable RF sensor array, which receives the RF signals transmitted by the capsule while it wirelessly transmits the images. The estimation of the position of the capsule is based on the triangulation principle, with average position errors ranging between 3.7 and 11.4cm [9,10]. A more recent approach enables localization of the capsule in the 3-dimensional (3D) human body space with an average localization error of 13.3cm3[11].RF signals are influenced by tissue densities, juxtaposition of different organs, and other anatomic considerations which can affect capsule localization accuracy [6]. Considering that magnetic waves are less sensitive in the presence of human tissue, various magnetic localization techniques have been proposed [10]. The most promising ones involve magnetic sensor arrays capable of localizing capsules equipped with a permanent magnet in the 2D or 3D body space. The average position errors reported from ex-vivo experiments range between 1.8 and 10mm and the average orientation errors between 2° and 3° [9]. Other localization techniques of capsule endoscopes are also possible, e.g., using x-ray and magnetic resonance imaging; however, they require expensive equipment and could result in adverse health effects [10].A drawback of both the RF and magnetic localization techniques is that they do not directly provide information related to the distance the capsule travels within the GI tract. Having the 2D or 3D body coordinates of the capsule endoscope it is difficult to determine its location with respect to an anatomic landmark, such as the pylorus, needed in the case of a surgical intervention after WCE. To cope with this issue a concept capsule endoscope design with three wheels has been proposed [12,13]. The wheels are mounted on expandable and retractable legs designed to keep contact with the mucosal surface. As the capsule moves within the GI tract the wheels spin and measure the distance traveled by conventional (wheel) odometry.Recently we proposed a visual odometry approach to capsule endoscope localization that requires neither external sensors nor wheels to measure the distance traveled by the capsule from an anatomic landmark [14]. It is based on the estimation of the motion of the capsule by tracking visual features extracted from consecutive video frames. In this paper, we perform an extensive comparative study to determine the optimal feature extraction scheme that minimizes the displacement and orientation error for capsule endoscope localization. Implementation and time performance issues of the feature extraction methods are addressed and novel results indicating up to one order of magnitude lower error rates are obtained in the majority of the test cases.The rest of this paper consists of four sections: Section 2 reviews the state-of-the-art capsule endoscope localization approaches that have been based solely on visual features. Section 3 describes the methods compared in this study, and Section 4 presents the results obtained. A summary of conclusions is provided in the last section.

@&#CONCLUSIONS@&#
In this paper we presented an extensive comparative assessment of several state-of-the-art techniques which aim to localize a capsule endoscope using solely visual features and a motion estimation model. In contrast to most approaches that rely on external, high-cost, intrusive equipment, the proposed approach does not require any external sensors, does not require any additional cost and does not discomfort patients by any means. Moreover, it is able to provide a more accurate estimation of the location of e.g. abnormalities, allowing specialists to treat patients more effectively. We feel that the use of commercial visualization products along with a tracking approach, as the one proposed herein, an endoscopist shall be able to combine quantitative with qualitative information and precisely locate abnormalities of the GI tract.The method proposed in [14] has been proven to produce reliable estimations with significantly small errors in the measurement of both the orientation and displacement of the WCE capsule. In the case of the SIFT features, the retrieved values of these measures have been almost perfect. SIFT algorithm was constantly able to produce invariant key-points and a set of at least three correspondences (i.e. the minimum required number of correspondences) per pair of frames that are needed for the estimation of an affine geometric transformation. SURF and LIOP features also proved reliable. We should notice that to the best of our knowledge, the use of LIOP features had not been investigated prior to this study in the research area of WCE. The performance of MSER, although at a first glance appears promising, remains a few magnitudes of error above the one of SIFT. FAST and GFtT features in conjunction with a binary visual descriptor, i.e. FREAK, had also not been investigated prior to this study. However, they have proven to produce non-practical errors. In comparison to state-of-the-art techniques [31,23] and with our previous work [14], we achieved an improvement of about an order of magnitude of error. Although the use of SIFT features introduces delays in the estimation process, due to their higher extraction time and the larger number of features they produce, we feel that results compensate.In this study we have made a significant step towards the determination of the most robust state of the art feature extraction algorithm for visual odometry in WCE. Future work includes the investigation of different strategies for wireless capsule endoscope localization, e.g., by relaxing the affinity assumption of the presented methods and by improving the deformable model concept introduced in [45] for capsule velocity estimation, further experimentation with phantom models of animal intestines where ground truth information can be established ex-vivo.There is no conflict of interest in relation to this paper.