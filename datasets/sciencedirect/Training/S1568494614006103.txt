@&#MAIN-TITLE@&#
Automatic identification of butterfly species based on local binary patterns and artificial neural network

@&#HIGHLIGHTS@&#
A computer vision method was proposed for automatically identifying butterfly species.To our knowledge, it was the first study in identifying the butterfly species with computer vision.The method is based on local binary patterns and artificial neural network.Results demonstrated that the proposed method has achieved well recognition accuracy rates.

@&#KEYPHRASES@&#
Butterfly identification,Local binary patterns,Texture features,Artificial neural network,

@&#ABSTRACT@&#
Butterflies are classified firstly according to their outer morphological qualities. It is required to analyze genital characters of them when classification according to outer morphological qualities is not possible. Genital characteristics of a butterfly can be determined by using various chemical substances and methods. Currently, these processes are carried out manually by preparing genital slides of the collected butterfly through some certain processes. For some groups of butterflies molecular techniques should be applied for identification which is expensive to use. In this study, a computer vision method is proposed for automatically identifying butterfly species as an alternative to conventional identification methods. The method is based on local binary pattern (LBP) and artificial neural network (ANN). A total of 50 butterfly images of five species were used for evaluating the effectiveness of the proposed method. Experimental results demonstrated that the proposed method has achieved well recognition in terms of accuracy rates for butterfly species identification.

@&#INTRODUCTION@&#
Insects, the most crowded family in the animal kingdom are represented with one and a half million species. The Lepidoptera order that involves butterflies and moths, who are distinguished from their closest relatives Trichoptera with flakes rather than trichome on their wings and with absorbent mouth parts in adolescents, is one of the richest teams among insects with its more than 170,000 species. The wing shape, textures and colors vary in butterflies with a great range. The figures on the wings of butterflies mostly have important roles in distinction of species at first glance. While these types of features are used as taxonomic characters as long as they are used within the species, examination of genitals organs’ outer structural features of especially the male individual is required when distinguishing species very similar to each other at first glance [1]. On the other hand, these techniques are difficult to apply and time-consuming. In recent years, molecular studies are added to these identification characteristics [2]. All of the studies carried out previously, although not completely decisive, have been on supporting characters for morphological characters can be used in butterfly identifications. The aim of this study is to design an automatic machine viewing (computer vision) system that correctly identifies butterfly species based on texture features of butterfly images. To our knowledge, there are no enough studies with machine vision and machine learning in the literature to identify the butterfly species.In previous studies, we used the energy spatial Gabor filtered (GF) (different orientations and frequencies) method with various classification methods for identification of five butterfly species. The highest obtained accuracy is 97% by ELM for five butterfly species and the accuracy obtained by ANN is 92% [3]. In another study, we obtained 96.3% classification accuracy, while employing gray-level co-occurrence matrix (GLCM) with multinomial logistic regression (MLR) for classification of 10 butterfly species and the accuracy obtained by ANN is 93.2% [4]. Additionally, 92.85% accuracy was obtained by GLCM with ANN methods for 14 butterfly species methods [5]. Furthermore, we employed GLCM and local binary pattern (LBP), the highest accuracy of identification of 19 butterfly species was obtained for these feature extraction methods is observed while employing ELM with 98.25%, 96.45% accuracy, respectively, and the accuracy obtained for ANN are 93.16% and 89.47%, respectively [6].For classification of butterflies, the texture features on surface of butterfly wings were used. Texture analysis plays an important role in many image analysis applications. Texture can be defined as the visual or tactile surface characteristics of objects [7]. It can also be formed by a single surface via variations in shape, illumination, shadows, absorption and reflectance [8,9]. Although in general there is no information on the cause of the variations, differences in image pixels provide a practical means of analyzing the textural properties of objects [10–14]. In this paper, we used the local binary pattern (LBP) operator to analyze patterns of the butterfly species and extract their texture properties. The LBP texture analysis operator was introduced as a robust descriptor of microstructures in images [15] and it has already been used in a large number of computer vision applications such as visual inspection, image retrieval, remote sensing, biomedical image analysis, face image analysis, motion analysis, environment modeling and outdoor scene analysis [16–21]. The main advantages of this operator are its tolerance to illumination changes, its computational simplicity, which makes it possible to analyze images in challenging real-time settings [17].In present study, it is tried to prove that texture features of organisms are also decisive in outer morphological features used in identification. This study was formed with two stages; first, texture features, which were obtained from butterfly images and then classification was realized through ANN (artificial neural network). In the past years, ANNs have seen an increasingly interests in image processing. The advantage of using ANN is able to build the non-linear and requires only input and output of data without knowing the processes in ANNs clearly. As a result of this study, identification and classification of butterfly species by using LBP texture features through ANN is showed a significant success.The rest of this paper is organized as follows. Section 2 gives an overview of butterflies species used in study; Section 3 describes the LBP operator; Section 4 describes the feature extraction based on LBP. In Section 5, we describe the application of artificial neural network (ANN) for pattern recognition. In Section 6 the proposed method is given. The experimental results are presented in Section 7, and section 8 provides concluding remarks.In this study, species belonging to family Papilinidae was collected from Mount Erek, Van between May 2002 and August 2003. Field studies were carried out between the attitudes of 1800–3200m. In the field, butterflies were caught by using net trap. After being killed in jars containing ethyl acetate the butterflies were put into special envelopers prepared in advance together with labels including collection information. At the end of the field studies, samples in temporary storage boxes were put in softening containers. Samples of the butterflies softened in it for 2–3 days were pinned with standard insect pins of the appropriate numbers (0 and 1 pins). Then samples were stretched in stretching boards and dried for being prepared as standard museum materials. The drying process lasted one week in an incubator fixed to 50–55°C. Locality labels were added to the samples rejected from stretching boards and these samples were then classified in collection drawers. External and internal morphological genital features were considered in the identification of samples. Together with morphological features of extremities and organs on head and chest, textures and colors on upper and lower sides of wings were considered in the identification made regarding external morphological features. Slides of male genital organs of some samples, which could not be identified with the external morphological features, were prepared. The identification was made by comparison of genital structures of related literature. Various handbooks, revision studies and comparison materials are used in identification, as follows in alphabetical order: Carbonell [22], Hesselbarth et al. [23], Skala [24] and Tolman [25]. Identification labels, on which the scientific names were written, were pinned on the samples at the end of the identification process. For an identification of texture features of the species used in the study 10 images for each of 5 species were used shot with a Nikon Professional camera. Butterfly species belonging to Papilinidae family that is spread in Van Lake basin were used in the study, as shown in Fig. 1.The local binary pattern (LBP) operator was proposed to measure the local contrast in texture analysis [15]. This operator is defined as a gray scale invariant texture measure, derived from a general definition of texture in a local neighborhood [17]. The LBP can be seen as a unifying texture model that describes the structure of a texture with micro-textons and their statistical distribution rules. The original LBP operator, introduced by Ojala et al. [26], is a powerful means of texture description and it is defined as a gray-scale invariant texture measure, derived from a general definition of texture in a local neighborhood. For each pixel in an image, a binary code is produced by thresholding its value with the value of the center pixel. The basic version of the LBP operator considers only the eight neighbors of a pixel, but the definition has been extended to include all circular neighborhoods with any number of pixels [15,26]. Different LBP operators can be defined according to the neighbors (see Fig. 2).In general, LBPP,R, where R is defined by a set of different multi-scale models, P is the number of neighbors; R indicates the radius of the model. At a given pixel position (xk, yk), LBP operator labels the pixels of an image by using the value of the center pixel as a threshold value of the neighborhood of each pixel. If the neighboring pixel value is greater than or equal to the center pixel value this pixel takes the value 1 otherwise it takes 0. Then an LBP code for a neighborhood is formed (Fig. 3). Fig. 3 shows a basic LBP where P and R are 8 and 1, respectively. The decimal value of this binary code gives the local structural information around the given pixel.The mathematical formulation of LBP for a pixel is as follows:(1)LBP(x)=∑i=0PS(G(xi)−G(x))2i−1(2)S(t)=1,t≥00,t<0where x is the location of the center pixel. xiis the location of the ith neighboring pixel and G(·) is the pixel intensity value. Note that each bit of the LBP code has the same significance level and that two successive bit values may have a totally different meaning. Actually, the LBP code may be interpreted as a kernel structure index. By definition, the LBP operator is unaffected by any monotonic gray-scale transformation which preserves the pixel intensity order in a local neighborhood (Fig. 4).By applying this procedure an LBP image is formed, which has pixel values ranging between 0 and 255. Each LBP value corresponds to a different pattern. When the histogram of the LBP image was produced, it shows how often each of these 256 different patterns appears in a given texture [27]. However, it is possible to decrease the number of patterns in an LBP histogram by only using uniform patterns without losing much information. An LBP pattern is a uniform pattern if it contains at most two bitwise transitions from 0 to 1 or 1 to 0 at its binary representation when the binary string is considered circular. For example, 11100001 (with 2 transitions) is a uniform pattern, whereas 11110101 (with 4 transitions) is a non-uniform pattern.Experiences in saccadic eye movements indicate that local appearances play an important role for classification [28]. People can recognize objects because they seek particular regions where discriminating information is located. LBP features computed over the whole butterflies’ wings represent only the micro patterns without any information about their locations. All the LBP values can composite a texture spectrum, called texture pattern matrix or LBP matrix, which is a map of a butterflies’ image. The map can show the distribution of gray levels and the main texture information of the butterflies’ image. The approach presented in this paper utilizes this finding by dividing butterfly images into sub-blocks and comparing the similarities between these sub-blocks. The butterflies’ images are divided into 64 sub-blocks for feature extraction. This representation captures local textures of images. Five texture features are extracted from the LBP matrix. These are average (F1), deviation (F2), energy (F3), entropy (F4) and correlation (F5). Let f(x, y) be the texture pattern matrix of size M×N. The five features are listed as follows:(3)F1=1MN∑x=0M−1∑y=0N−1f(x,y)(4)F2=1MN∑x=0M−1∑y=0N−1(f(x,y)−AVE)2(5)F3=1MN∑x=0M−1∑y=0N−1f2(x,y)(6)F4=−∑x=0M−1∑y=0N−1f(x,y)ENElnf(x,y)ENE(7)F5=−∑x=0M−1∑y=0N−1xyf(x,y)−μxμyσxσywhere μ is the mean and σ is the standard deviation.The artificial neural network (ANN) method is based on the findings of the biological nervous system [29]. In this artificial neural system, there are nerve cells which are joined together in a variety of ways to form networks. The ANN consists of layers, namely the input layer, the inter layers (hidden layers) and the output layer. The input layer receives data from the external world. The output layer presents the data to the user. The hidden layers between these two layers are where the data is processed. The number of the nerve cells in the hidden layer is significant for the performance as well as the length of the network. Usually the output of each neuron is determined by using a nonlinear activation function such as a sigmoid and hyperbolic tangent. ANNs are trained by experience, when applied to an unknown input in the network; it can generalize from past experiences and produce a new result [30]. The output of the neuron net is determined by Eq. (8). Fig. 5shows a fundamental representation of an artificial neuron [31–33].(8)y(t+1)=F∑j=1nwijxj(t)−θiand neti=∑j=1nwijxj−θiIn Fig. 5, various inputs of the network are represented by a symbol xn. Each of these inputs is multiplied by a connection weight that represented by Wn. In ANN, xn×Wnproducts are summed fed through an activation function to generate a result for output. θiis a bias value, G(x) is activation function. ANN models have been used for pattern matching, nonlinear system modeling, communications, electrical and electronics industry, energy production, chemical industry, medical applications, data mining and control because of their parallel processing capabilities [30]. There are many different parameters that should be decided when designing an ANN such as the number of layers, the number of neurons per layer, and the number of training iterations, learning rate, and activation function.The idea of using LBPs for butterfly species description is motivated by the fact that butterflies can be seen as a composition of micro-patterns which are properly described by this operator. The method for classifying the images proposed in this paper is based on texture descriptors extracted from the butterfly images. As illustrated in Fig. 6, our approach can be divided into four main steps:•Step 1: The objective of image preprocessing is to remove irrelevant noise and to enhance image features which are important for further analysis point of view. Otherwise it may complicate the classification and reduce the recognition rate. In this paper, a preprocessing and tessellation step was implemented, which included normalizing the image and dividing the images into N×N overlapping cells. Then images were resized to 256×256pixels.Step 2: The objective of the feature extraction step is to produce a representative feature vector that can accurately capture the unique and salient texture features of each butterfly images. Firstly, the texture descriptors were calculated from a set of selected cells. Then, LBP features were extracted from butterfly images based on the feature extraction methods in Eqs. (3)–(7). Five-dimensional feature sets for training and testing data were obtained. The dimensions here describe different features resulting from the LBP matrix, that is to say, the total size of data set is 5×50, where 5 is the dimension of feature size of each butterfly and 50 comes from 10 samples per class multiplied by 5 classes. A representation of data set obtained from the LBP matrix is given in Fig. 7. This is a part of the input vector to be classified, and their coefficients were presented in a two-dimensional scatter plot form. This approach allows the assessment of the nature of the features clearly. As seen in Fig. 7, the scatter plot may provide distinctive regions to separate and distinguish each butterfly species accurately.Step 3: The objective of the classification step is to automatically identify, as a unique gray level, the features occurring in an image in terms of the object. In this stage, the LBP matrix features were applied as input to ANN. The architecture of ANN is the multi layer perceptron. The output of the classification step is the butterfly species. The ANN training parameters used in this study were given in Table 1.Step 4: In this stage, classification results were described in terms of a 5×5 confusion matrix. The diagonal elements represent the correctly classified butterfly species. The off-diagonal elements represent the misclassified butterfly species.

@&#CONCLUSIONS@&#
