@&#MAIN-TITLE@&#
Finding cultural heritage images through a Dual-Perspective Navigation Framework

@&#HIGHLIGHTS@&#
The framework, DPNF, seamlessly combines faceted browsing and tag-based navigation.DPNF integrates experts’ subject headings and social tags.DPNF offers a more efficient, effective, and user-oriented interface than single ones.

@&#KEYPHRASES@&#
Social tags,Subject headings,Indexing,Navigation,Interface,User study,

@&#ABSTRACT@&#
With the increasing volume of digital images, improving techniques for image findability is receiving heightened attention. The cultural heritage sector, with its vast resource of images, has realized the value of social tags and started using tags in parallel with controlled vocabularies to increase the odds of users finding images of interest. The research presented in this paper develops the Dual-Perspective Navigation Framework (DPNF), which integrates controlled vocabularies and social tags to represent the aboutness of an item more comprehensively, in order that the information scent can be maximized to facilitate resource findability.DPNF utilizes the mechanisms of faceted browsing and tag-based navigation to offer a seamless interaction between experts’ subject headings and public tags during image search. In a controlled user study, participants effectively completed more exploratory tasks with the DPNF interface than with the tag-only interface. DPNF is more efficient than both single descriptor interfaces (subject heading-only and tag-only interfaces). Participants spent significantly less time, fewer interface interactions, and less back tracking to complete an exploratory task without an extra workload. In addition, participants were more satisfied with the DPNF interface than with the others. The findings of this study can assist interface designers struggling with what information is most helpful to users and facilitate searching tasks. It also maximizes end users’ chances of finding target images by engaging image information from two sources: the professionals’ description of items in a collection and the crowd's assignment of social tags.

@&#INTRODUCTION@&#
Image search has been an important problem in the area of information access. Over the years, museums, news archives, and other key stakeholders established and perfected two ways of helping users to find relevant images – keyword-based search and metadata-based search. Yet, the rapid rise of online sharing of digital images challenges both approaches. While keyword-based search is still popular as demonstrated by Google image search,11https://www.google.com/imghp?hl=en&tab=wi.extracting relevant keywords to describe an image has become increasingly more problematic since many images are now published online without any textual descriptions.Classical image metadata (known as subject headings in the museum context) supports both search and browsing (e.g., faceted browsing) but requires significant manual generation effort that is a challenge for large-scale image collections. It is still difficult for automatically generated metadata to match the quality of that created by professional indexers. At the same time, professionally generated metadata suffers from the classic indexer-user mismatch problem: non-professional end-users usually perceive items in a different manner than professional indexers. As a result, it has become increasingly difficult for the majority of end-users to find even properly processed and indexed images. The growing volume of content combined with the pressures of time, money, and competition means that the need to improve techniques for findability (Morville, 2005) of images is now becoming a critical issue.In this context, social tagging has emerged as an alternative crowd-powered mechanism to generate textual descriptors that bring out the aboutness of the images so that effective and efficient browsing and keyword-based access to images can be achieved. Aboutness indicates the subject or topic that an item refers to from a user's perspective (Fairthorne, 1969). Different users with different perspectives may generate different descriptors for aboutness. In this study, we use aboutness to capture the main concept(s) expressed in an image. It can be the most significant characteristics of the image, such as the theme, the main character(s), the obvious attributes, and so on.The diversity of input sources and the engagement of end users in the process of image description give modern social tagging systems tremendous power to assist users in finding images. Yet, tag-based access has its own problems, such as the lack of structure, semantic ambiguity, and wrong assignment, which may decrease the accuracy of the aboutness represented by social tags.It is easy to see that components of both the metadata-based and tag-based approaches to image access have their own merits, which is why our paper develops a hybrid approach, Dual-Perspective Navigation Framework (DPNF), that includes both experts’ and general users’ descriptors to represent more comprehensive aboutness of an item. We argue that this hybrid approach can increase the completeness of the aboutness from diverse points of view and enhance the item's findability.The cultural heritage sector, with its vast resource of images, has realized the value of social tags and proposed the integration of folksonomies and controlled vocabularies for increasing the odds of users finding items of interest (Hayman & Lothian, 2007; Rolla, 2009; Steele, 2009). However, the majority of the research on integrating experts’ annotations and social tags has focused on how to utilize controlled vocabularies to structure folksonomies, which are taxonomies created by multiple users (Peters, 2009). A smaller thread, known as the multiple interface approach (McGrenere, Baecker, & Booth, 2002), explored the idea of using both professional index terms and social tags independently, but in parallel with one another, by offering multiple types of navigational support for users’ various information needs.By contrast, the approach presented in this paper focuses on a true integration of these two aboutness descriptors to facilitate resource finding. That is, tags and metadata are integrated in our approach in such way that they reinforce their strengths without changing their nature or forcing users to choose one means over the other. Our DPNF approach is an interface-level integration of tag-based and metadata-based information access mechanisms.DPNF utilizes the mechanisms of faceted browsing and tag-based navigation in its design of seamless interaction between experts’ subject headings and public tags to maximize information scent (Pirolli, 2007) and facilitate the image search. Users are able to start their search via a traditional keyword query, a specific subject heading, or a tag, then progressively narrow down the search results using both subject headings and tags. The presence of hierarchical facets of subject headings and a flat cloud of tags allows users to search with more flexibility and to specify their interests more precisely using the structure of different types of information descriptors. To assess whether DPNF does, in fact, support efficient and effective user-oriented image finding, we performed a controlled user study, which is reported in this paper.The remainder of the paper is organized as follows: Section 2 reviews the related work, including the applied background theories and relevant research in the area of image finding; Section 3 introduces our approach – the Dual-Perspective Navigation Framework (DPNF); Section 4 demonstrates our research process including our data collection, system design, and experimental design, the research tasks involved, and the procedure of the user study; Section 5 discusses research results; and Section 6 offers a discussion with a further analysis. Section 7 concludes the important findings of this research.

@&#CONCLUSIONS@&#
The work presented in this paper aimed to enhance image findability (Morville, 2005) by suggesting and examining the Dual-Perspective Navigation Framework (DPNF) for image search. We expected that DPNF could model the aboutness of an item more comprehensively, which can increase the information scent and therefore provide better support to users to their desired items in an efficient and effective manner. Effectiveness, efficiency, and satisfaction of the ISO 9241 standard for usability (1998) were adopted to evaluate the usability of DPNF. We summarize the important results for the three research questions as the following:RQ1: Participants successfully completed more exploratory tasks with the DPNF interface than with the tag-only interface. While performing the exploratory search, participants with the DPNF interface made fewer unsuccessful (futile) searches than participants with the tag-only interface.RQ2: Participants spent significantly less time, fewer interface interactions, and less back tracking to complete an exploratory task with the DPNF interface than with the subject-heading only and tag-only interfaces. In addition, the DPNF interface did not cause any extra workload for participants as compared to using the other single perspective interfaces.RQ3: Participants were more satisfied with the DPNF interface than with the others. DPNF interface was selected as the interface that the participants were most confident using in the future, and as the top choice to be recommended to cultural heritage institutions.This study compared user performance and feedback for three types of image finding interfaces in the context of two types of search tasks – lookup and exploratory search. The results demonstrated that the DPNF interface outperformed the subject heading-only and tag-only interfaces. Both objective performance analysis and subjective perception analysis produced significant findings.By truly integrating both experts’ and general users’ descriptors to represent the aboutness of an item more comprehensively, DPNF reinforces the strengths of both the metadata-based and tag-based approaches without changing their nature or forcing users to choose one over the other. The findings of this study can assist interface designers working on more efficient exploratory search interfaces. Although this study explicitly focuses on image search, the results may be applicable to a wide variety of other domains. The lack of textual content in image systems makes images particularly hard to locate using traditional search methods. Our study shows that the integration of folksonomies (i.e. social tags) and controlled vocabularies (i.e. subject headings) supports more effective and efficient exploratory search in the image search context.Although DPNF offered two types of descriptors to guide users to find images, we cannot claim that this study uncovered how different information descriptors guide individual users in finding target images. The data hint that each participant is likely to have a different background as well as a different preferred search strategy to perform a particular search task in the manner to which they are accustomed. In our future studies, we are interesting in exploring on a deeper level how participants consumed different information descriptors during their search process, and how that might relate to their background and individual differences. Further study with eye tracking augmentation may be helpful in learning more about the interaction between users’ search behaviors and various types of information descriptors.Participant#:_________Collection#:_________Order#:_________LookupNot at allSlightlyModeratelySomewhatStrongly(1) How well did the interface provide support to this task?□□□□□(2) How well did you find the subject headings and tags useful in finding the target items?□□□□□(3) The first image #_______________How clearly did the first image have salient/unique features that make it easy to locate?□□□□□The second image #_______________How clearly did the first image have salient/unique features that make it easy to locate?□□□□□The third image#__________________How clearly did the first image have salient/unique features that make it easy to locate?□□□□□Task topic# :_________ExploratoryNot at allSlightlyModeratelySomewhatStrongly(1) How well did the interface provide support to this task?□□□□□(2) How well did the subject headings and tags in the result page provide you with a good overview of the returned images?□□□□□(3) How well did the subject headings and tags in the result page give you good hints about how to proceed to the next step?□□□□□(4) How well did the subject headings and tags in the detail page guide you to related images?□□□□□(5) When you clicked to see a full image, was it mostly because you thought the image might be relevant?□□□□□(6) How familiar are you with this task topic?□□□□□(7) How confident are you in the system's ability to help you find useful information on other topics?□□□□□Please write down any other comments.Participant#:_________Subject heaing-onlyTag-onlyDual-perspective navigation(1) Which one of the interface do you like most?□□□Why do you like the interface most?(2) Which one of the interface would you feel more confident to use for other search tasks ?□□□Why do you think that you feel more confident to use the interface for other search tasks?(3) Which one of the interfaces would you prefer for lookup search (finding a specific picture)?□□□(4) Which one of the interfaces would you prefer for exploratory search?□□□(5) Which one of the interfaces would you suggest that the cultural heritage institutions, such as museums, provide their visitors for searching their image collections?□□□Why is the selected interface in the previous question the best for the museum?Not at allSlightlyModeratelySomewhatStrongly(6) Overall, how would you rate your experience with the subject heading-only interface?□□□□□(7) Overall, how would you rate your experience with the tag-only interface?□□□□□(8) Overall, how would you rate your experience with the dual-perspective navigation interface?□□□□□Do you have any suggestions to improve any of those interfaces?