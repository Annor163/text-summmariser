@&#MAIN-TITLE@&#
Human behaviour recognition in data-scarce domains

@&#HIGHLIGHTS@&#
We challenge the notion that the exact temporal structure of activities needs to be modelled.We compare performance against a Hidden Markov Model baseline.The weak temporal structure of our approach makes it less sensitive to observation order.Hidden Markov Models cannot be used to classify some activity sequences.Our approach outperforms the baseline by 17%.

@&#KEYPHRASES@&#
Behavior recognition,Bayesian inference,Visual surveillance,Behavior decomposition,

@&#ABSTRACT@&#
This paper presents the novel theory for performing multi-agent activity recognition without requiring large training corpora. The reduced need for data means that robust probabilistic recognition can be performed within domains where annotated datasets are traditionally unavailable. Complex human activities are composed from sequences of underlying primitive activities. We do not assume that the exact temporal ordering of primitives is necessary, so can represent complex activity using an unordered bag. Our three-tier architecture comprises low-level video tracking, event analysis and high-level inference. High-level inference is performed using a new, cascading extension of the Rao–Blackwellised Particle Filter. Simulated annealing is used to identify pairs of agents involved in multi-agent activity. We validate our framework using the benchmarked PETS 2006 video surveillance dataset and our own sequences, and achieve a mean recognition F-Score of 0.82. Our approach achieves a mean improvement of 17% over a Hidden Markov Model baseline.

@&#INTRODUCTION@&#
Computer systems that can recognise human activity have captured the imagination of the research community for decades. This multi-faceted problem has drawn researchers from many different disciplines and has wide application potential including; systems that can monitor the wellbeing of people with a disability and the infirm (assisted living) [1], improving recognition in areas where human observers are suboptimal (e.g. security) [2], and improving situation awareness for autonomous vehicles [3].Since video surveillance applications are the focus of our work, we begin with a motivating example. Fig. 1shows two examples of the types of activity that occur in security footage (PETS2006). The ‘Watched Item’ activity represents two people travelling together where one traveller leaves their luggage in the custody of the other when he leaves the scene. The ‘Abandon Item’ activity is subtly different; it represents two travellers arriving independently but waiting in close proximity. In this circumstance, a person departing without their luggage is cause for concern while the former scenario is not.The multi-disciplinary nature of activity recognition research has led to a set of terms that are inconsistent, and sometimes conflicting. In this paper behaviours and activities are synonymous, and will be discussed in two contexts; high-level (complex) and low-level (primitive). Primitive activities are isolated and do not involve long-term dependencies. Examples include ‘enter-area’ for somebody entering the field of view, and ‘object-placed’ for the placement of luggage on the floor by a person. Complex activities are composite and are comprised of sequences of primitive activities that achieve a higher-level goal. For example, watching a companion׳s luggage can be considered complex because it involves several components: some kind of association between people, placing luggage, the departure of one person and the monitoring of their luggage by another.The relative infrequency of abandoned objects in security footage prevents statistically robust conclusions from being drawn via machine learning algorithms, which are becoming increasingly important for solving related computer vision problems. In automated surveillance it is not uncommon to manually specify semantic constraints [4,5], but these approaches are largely deterministic and lack convenient methods for handling observational uncertainty [1]. In the absence of training corpora one can rely on the mobilisation of human prior knowledge, but this too can be time consuming, expensive and unreliable [6]. In distributed, wide area surveillance, it is unclear if it would be possible to manually construct robust temporal models. Other state-of-the-art techniques for detecting object abandonment include monitoring the proximity of objects to their owners, although such techniques are unable to distinguish between the two motivating scenarios and do not generalise to other behaviours. Statistical and distance based anomaly detection algorithms are another two approaches for identifying irregular activity, but cannot be used to detect specific patterns of interest. Clustering techniques such as Hierarchical Dirichlet Processes [7] can be used to automatically discover activities from unlabelled training data, but cannot always distinguish between behaviours that are very similar [8].The current state-of-the-art in video-surveillance research has failed to match the advances being made in plan recognition research, which has made significant advances in human activity recognition. The most robust plan recognition techniques adopt trained probabilistic models, although a limitation is that they are not well suited to data-scarce domains. By the phrase “data-scarce” we mean those scenarios where there is a natural lack of exemplars. In video surveillance applications in particular (since this is the application focus of this work) accurately annotated libraries of video do not exist for many of the interesting activities one would wish a machine to detect: anomalies and infrequently occurring activities.This paper proposes that there is a better way to use probabilistic models in data-scarce domains and is fundamentally grounded upon the idea of an alternative activity representation that removes the need to learn temporal structure. We take our motivation from a phenomenon in psycholinguistics where randomising letters in the middle of words (or, ‘radnsimnoig lteters in the mdidle of wrods) has little effect on the ability of skilled readers to understand the text [9]. We propose that like the letters in words, it is the primitive activities (e.g. items in ovals in Fig. 1) that are most important for allowing recognition, and de-emphasis the strict (temporal) ordering of those primitives. Specifically, we propose that the primitive activity subcomponents of a complex activity can be used as salient features, and that by imposing weak temporal constraints on the expected primitives we can recognise complex activities without learning their temporal structure. In doing so we are able to extend state-of-the-art techniques from plan recognition research to provide new algorithms for robust probabilistic recognition in data-scarce domains that are able to reason about uncertainty. The contributions of this work are:1.A novel framework that builds upon existing research with Rao–Blackwellised Particle Filters by integrating a feature based representation and its Dynamic Bayesian Network implementation (thus retaining a unified and principled mathematical foundation). We demonstrate high recognition F-Score (0.82) in real-time within a noisy, sensor-based environment without model training.We compare our approach against a set of Hidden Markov Model (HMM) classifiers, and show that our approach yields a mean improvement of 17% in F-Score.Our method can recognise agents concatenating and switching between activities and remains robust to activities with significant similarities.Inspired by cascaded Hidden Markov Models we develop a cascading particle filter to recognise activity at multiple levels of abstraction.We achieve multi-agent (paired) activity detection by merging filtering densities from multiple particle filters and identifying the most probable joint activity explanation of all agents using combinatorial search, demonstrably improving the scientific state-of-the-art.We validate our framework within the video surveillance domain using the PETS 2006 video surveillance dataset (e.g. Fig. 1), our own video sequences (e.g. Fig. 2) and a large corpus of simulated data.The next section of this paper discusses related research. Sections 2 and 3 will provide an overview of our approach and encapsulates our ideas within a dynamic Bayesian network (DBN). Section 4 will show how efficient inference can be performed using a Rao–Blackwellised particle filter. Section 5 extends the representation into a hierarchical approach allowing multi-agent activities to be detected in Section 6. Section 7 will introduce the application domain and will describe the implementation details of our validation. We then discuss performance on both simulated and real video data and compare to the current state-of-the art before presenting conclusions and future work in Section 9.

@&#CONCLUSIONS@&#
