@&#MAIN-TITLE@&#
A cosine maximization method for the priority vector derivation in AHP

@&#HIGHLIGHTS@&#
A cosine maximization method (CM) based on the similarity measure.An optimization model for the CM to derive a reliable priority vector from a pair-wise comparison matrix.Compare CM with other prioritization methods based on two performance evaluation: Euclidean distance and minimum violation.Induce a consistency index for a pair-wise comparison matrix based on the CM.

@&#KEYPHRASES@&#
Analytic Hierarchy Process,Pair-wise comparison matrix,Cosine similarity measure,Priority vector,Consistency index,

@&#ABSTRACT@&#
The derivation of a priority vector from a pair-wise comparison matrix (PCM) is an important issue in the Analytic Hierarchy Process (AHP). The existing methods for the priority vector derivation from PCM include eigenvector method (EV), weighted least squares method (WLS), additive normalization method (AN), logarithmic least squares method (LLS), etc. The derived priority vector should be as similar to each column vector of the PCM as possible if a pair-wise comparison matrix (PCM) is not perfectly consistent. Therefore, a cosine maximization method (CM) based on similarity measure is proposed, which maximizes the sum of the cosine of the angle between the priority vector and each column vector of a PCM. An optimization model for the CM is proposed to derive the reliable priority vector. Using three numerical examples, the CM is compared with the other prioritization methods based on two performance evaluation criteria: Euclidean distance and minimum violation. The results show that the CM is flexible and efficient.

@&#INTRODUCTION@&#
Analytic Hierarchy Process (AHP) introduced by Saaty (1977, 1980, 2000) is one of the widely used multi-criteria decision making (MCDM) methods (Peng, Kou, Wang, Wu, & Shi, 2011). MCDM deals with three main types of decision problems: ranking, sorting and choice (Roy, 1996; Peng, Kou, Wang, & Shi, 2011; Kou, Lu, Peng, & Shi, 2012; Corrente, Greco, & Slowiński, 2013). In this paper we only focus on ranking as it is one topic of prioritization methods based on AHP model. Ranking problem consists in rank ordering of all alternatives with respect to the considered criteria (Kadziński, Greco, & Slowiński, 2012; Siraj, Mikhailov, & Keane, 2012). It is an important issue in AHP to derive a reliable priority vector from a pair-wise comparison matrix (PCM) that is collected from experts’ judgments. The validity of the derived priority vectors mainly relies on the design of prioritization methods. The prioritization method refers to the process of deriving a priority vector from a PCM. Over the past few decades, lots of prioritization methods have been developed, including weighted least squares method (WLS) (Chu, Kalaba, & Spingarn, 1979), eigenvector method (EV) (Saaty, 1977), additive normalization method (AN) (Saaty, 1980; Srdjevic, 2005), least squares method (LS) (Saaty & Vargas, 1984), logarithmic least squares method (LLS) (Crawford & Williams, 1985), gradient eigenweight method (GE) and least distance method (LD) (Cogger & Yu, 1985), geometric least squares method (GLS) (Islei & Lockett, 1988), goal programming method (GP) (Bryson, 1995), geometric mean method (GM) (Barzilai, 1997), logarithmic goal programming method (LGP) (Bryson & Joseph, 1999), fuzzy preference programming method (FPP) (Mikhailov, 2000), singular value decomposition method (SVD) (Gass & Rapcsa’k, 2004), interval priority method (IP) (Sugihara, Ishii, & Tanaka, 2004), linear programming method (LP) (Chandran, Golden, & Wasil, 2005), data envelopment analysis method (DEA) (Ramanathan, 2006), correlation coefficient maximization approach (CCM) (Wang, Parkan, & Luo, 2007), Bayesian prioritization procedure (BP) (Altuzarra, Moreno-Jime’nez, & Salvador, 2007). Besides, Srdjevic (2005) suggested combining some different prioritization methods to derive the better priority vector. Lipovetsky and Conklin (2002) suggested deriving a robust estimation of the priority vector using the transformed matrices. Srdjevic and Srdjevic (2011) put forward a bi-criteria evolution strategy for deriving the weights estimation. Lin, Kou, and Ergu (2013a) proposed a heuristic approach for the priority vector derivation based on the nearest consistent matrix and experts’ judgments.However, there is some dispute on which prioritization method is better as existing prioritization methods perform differently with regard to different measures, that is, some prioritization methods perform better in some cases, and some others are better in other cases. Some comparative analysis between the commonly used prioritization methods can be found in the literature (Chu et al., 1979; Crawford & Williams, 1985; Saaty & Vargas, 1984; Saaty, 1990; Golany & Kress, 1993; Mikhailov & Singh, 1999). Main conclusion is that there is no one method that is superior to the others in all cases. Therefore, the choice of the prioritization method should be dictated by the objective of the analysis. Until now, the issue of the relative superiority of prioritization methods is still unresolved. In this paper, based on cosine similarity measure, a new prioritization method for the priority vector derivation from a PCM is proposed, which is called cosine maximization method (CM) and maximizes the sum of the cosine of the angle between the priority vector and each column vector of a PCM, and then the proposed CM is compared with the other four prioritization methods regarding two performance evaluation criteria.The rest of the paper is organized as follows. In Section 2, the CM and its consistency index is formulated based on cosine similarity measure. In Section 3, four typical prioritization methods and two performance evaluation criteria are reviewed. In Section 4, the proposed CM is compared with four typical prioritization methods by examining three numerical examples. Section 5 concludes the paper.We will propose a CM method for the priority vector derivation from a PCM based on similarity measure, and then develop a new consistency index related with the CM to measure the inconsistency level of a PCM.In order to develop the CM for the priority vector derivation, several definitions and theorems are introduced as follows:Definition 1Matrix A=(aij)n×nis said to be positive reciprocal if aij>0, aii=1 and aij=1/ajifor all i, j∈ {1, 2,…,n}.A positive reciprocal matrix A=(aij)n×nis said to be perfectly consistent if aij=aikakjfor all i, j, k∈ {1,2,…,n}.Similarity measure between two vectors tiand tj, SM(ti,tj) in a n dimensional vector space V is a mapping from V×V to the range [0,1]. Thus, SM(ti,tj)∈[0,1].The similarity measure inDefinition 3has the following well known characteristics:(1)∀ti∈V, SM(ti,ti)=1;∀ti, tj∈V, SM(ti,tj)=0 if tiand tjare not similar at all;∀ti, tj, tk∈V, SM(ti,tj)<SM(ti,tk) if tiis more like tkthan it is like tj.The objective is to define a similarity mapping such that more similar vectors have a higher similarity value.Theorem 1Let two vectors be ti=(ti1,ti2,…,tin)Tand tj=(tj1,tj2,…,tjn)T, then the cosine similarity measure between two vectors tiand tjis denoted asCSM(ti,tj)=∑k=1ntiktjk∑k=1ntik2∑k=1ntjk2.Proof ofProperty 1andTheorem 1. See the reference (Salton & Mcgill, 1983).There are several common similarity measures used in practice such as Dice similarity measure, Jaccard similarity measure, overlap similarity measure, and cosine similarity measure (Dunham, 2003). The concept of similarity measure can be extended all the way to the priority vectors derived from a PCM. Therefore, in any complex decision problem represented by a hierarchy in AHP, the similarity measure between the priority vector and each column vector of the PCM is denoted by the cosine similarity measure between them due to its simplicity. Such a cosine similarity measure has been successfully used and completely discussed in models of Information Retrieval (Salton, 1971; Salton & Mcgill, 1983) and AHP model (Zahir, 1999).We now consider deriving a reliable priority vector from a PCM based on the cosine similarity measure of Theorem 1. Let A=(aij)n×nbe a positive reciprocal PCM and w=(ω1,ω2,…,ωn)Twith∑i=1nωi=1and ωi⩾0 (i=1,2,…,n) be a priority vector derived from A using some prioritization method.If A is perfectly consistent, it follows that (Saaty, 1980)(1)aij=ωi/ωj,i,j∈{1,2,…,n}.From (1), A can be precisely characterized by(2)A=ω1/ω1ω1/ω2⋯ω1/ωnω2/ω1ω2/ω2⋯ω2/ωn⋮⋮⋯⋮ωn/ω1ωn/ω2⋯ωn/ωn.According to (2), A can be viewed as consisting of the following n column vectors:(3)(ω1,ω2,…,ωn)T/ωi,i=1,2,…,n.Let Cjbe the cosine similarity measure between the priority vector w and the jth column vector ajof A, where w=(ω1,ω2,…,ωn)Tand aj=(a1j,a2j,…,anj)T.By Theorem 1, we have(4)Cj=CSM(ω,aj)=∑k=1nωkakj∑k=1nωk2∑k=1nakj2,j=1,2,…,n.Since aij=ωi/ωj, i, j∈{1,2,…,n}, we have(5)Cj==∑k=1nωk2/ωj∑k=1nωk2∑k=1n(ωk/ωj)2=1,j=1,2,…,n.It is obvious that the cosine similarity measure between the derived priority vector and each column vector of A is equal to 1 if and only if A is perfectly consistent.If A is not perfectly consistent, from Definition 3 it follows that(6)0⩽Cj<1In order to derive a reliable priority vector, the cosine similarity measure between the derived priority vector and each column vector of a PCM should be equal to 1 as highly as possible. Inspired by this idea, we construct an optimization model as follows:(7)MaximizeC=∑j=1nCj=∑j=1n∑i=1n(ωiaij)∑k=1nωk2∑k=1nakj2subject to∑i=1nωi=1,ωi⩾0,i=1,2,…,n.We set(8)ωˆi=ωi∑k=1nωk2⩾0,i=1,2,…,n.and(9)bij=aij∑k=1nakj2>0,i,j=1,2,…,n.Then we have(10)∑i=1nωˆi2=1.and(11)∑i=1nbij2=1.Accordingly, optimization model (7) can be equivalently transformed into the following optimization model:(12)MaximizeC=∑j=1nCj=∑j=1n∑i=1nbijωˆi=∑i=1n∑j=1nbijωˆisubject to∑i=1nωˆi2=1,ωˆi⩾0,i=1,2,…,n.With regard to optimization model (12), we have the following theorems.Theorem 2Letwˆ∗=ωˆ1∗,ωˆ2∗,…,ωˆn∗Tbe the optimal solution to optimization model(12)and C∗be the optimal objective function value of it. Thenωˆi∗=∑j=1nbij/∑k=1n∑j=1nbkj2,i=1,2,…,nandC∗=∑i=1n∑j=1nbij2.Due to the fact thatwˆ=(ωˆ1,ωˆ2,…,ωˆn)Tis a bounded vector and C is a continuous function ofwˆ, there exists a maximum point such that optimization model (12) holds. To find the maximum point, we construct the following Lagrangian function.L(C,λ)=C+λ∑i=1nωˆi2-1=∑i=1n∑j=1nbijωˆi+λ∑i=1nωˆi2-1.Taking the partial derivatives of the Lagrangian function with respect towˆiand letting them be zero.∂L(C,λ)∂ωˆi=∑j=1nbij+2λωˆi=0,i=1,2,…,n.Then, we haveωˆi=-∑j=1nbij/2λ.Since∑i=1nωˆi2=1,wˆi⩾0andbij>0.Then, we obtain∑i=1n∑j=1nbij/2λ2=∑i=1nωˆi2=1andλ<0.It follows thatλ=-∑k=1n∑j=1nbkj22.The results are obtained as follows:ωˆi∗=-∑j=1nbij2λ=∑j=1nbij∑k=1n∑j=1nbkj2,i=1,2,…,n.andC∗=∑i=1n∑j=1nbijωˆi∗=∑i=1n∑j=1nbij∑j=1nbij/∑k=1n∑j=1nbkj2=∑k=1n∑j=1nbkj2.□Furthermore, we write(13)Ω={w=(ω1,ω2,…,ωn)T∑i=1nωi=1,ωi>0,i=1,2,…,n}.Then the objective function C of optimization model (7) has a unique maximum point(14)w∗=ω1∗,ω2∗,…,ωn∗T∈Ω.That is to say, optimization model (7) can produce a unique solution, avoiding the inconvenience of how to choose one solution from a set of solutions. The unique solution can be indirectly determined by optimization model (12). From (8), we have(15)ωi∗=ωˆi∗∑k=1nωk2,i=1,2,…,n.Let(16)β=∑k=1nωk2⩾0Then (15) can be equivalently written as(17)ωi∗=ωˆi∗β,i=1,2,…,n.where β is called weight assignment coefficient. Solving the following system of equation(18)∑i=1nωi∗=∑i=1nωˆi∗β∑i=1nωi∗=1.We have(19)β∗=1∑j=1nωˆj∗.From (17), we have(20)ωi∗=ωˆi∗β∗=ωˆi∗∑j=1nωˆj∗,i=1,2,…,n.Theorem 3Let PCM A=(aij)n×nbe perfectly consistent, the CM method can precisely derive the optimal objective function value C∗=n and the prioritiesωj∗=1∑i=1naij(j=1, 2,…, n).Let w=(ω1,ω2,…,ωn)Tbe a priority vector derived from A. Since A is perfectly consistent, it follows thataij=ωi/ωjandaij=aikakjfor alli,j,k∈{1,2,…,n}.From (9), we havebij=aij∑k=1nakj2=aij∑k=1n(aij/aik)2=1∑k=1n(1/aik)2=1∑k=1naki2.Thus,∑j=1nbij=∑j=1n1∑k=1naki2=n∑k=1naki2=n∑k=1n(ωk/ωi)2=nωi∑k=1nωk2.By Theorem 2, the optimal objective function value is obtained as follows:C∗=∑i=1n∑j=1nbij2=∑i=1nnωi∑k=1nωk22=∑i=1n(nωi)2∑k=1nωk2=n.Since∑j=1nbij=nωi∑k=1nωk2and∑k=1n∑j=1nbkj2=n.We havewˆi∗=∑j=1nbij∑k=1n∑j=1nbkj2=ωi∑k=1nωk2.Thus,wˆj∗=ωj∑k=1nωk2and∑i=1nwˆi∗=∑i=1nωi∑k=1nωk2.From (20), the priorities are derived as follows:ωj∗=ωˆj∗∑i=1nωˆi∗=ωj∑i=1nωi=1∑i=1n(ωi/ωj)=1∑i=1naij,j=1,2,…,n.□In order to facilitate the solution process of the CM, the involved steps are briefly described as follows:Step 1. Normalize the PCM A=(aij)n×nto the transformation matrix B=(bij)n×nby (9).. Calculate the transformed weightsωˆi∗(i=1,2,…,n)by Theorem 2.. Calculate the optimal objective function value C∗ by Theorem 2.. Calculate the weight assignment coefficient β∗ by (19).. Calculate the final priority vectorw∗=ω1∗,ω2∗,…,ωn∗Tby (20).It is well-known that the consistency of a PCM is a vital basis of AHP theory in the course of deriving the priority vector. Saaty (1977) proposed a consistency index (CI) related to the EV method:(21)CI=(λ-n)/(n-1)where n is the dimension of the PCM, and λ is the principal eigenvalue of the PCM. It follows that CI⩾0 with CI=0 if and only if the PCM is perfectly consistent. Several consistency indices and methods have been proposed to measure the inconsistency level of a PCM. For example; Crawford (1987) developed a new consistency index using the geometric mean procedure. Peláez and Lamata (2003) described a consistency measure method based on the determinant of a PCM; Aguarón and Moreno-Jiménez (2003) proposed the geometric consistency index (GCI) and provided the approximated thresholds associated with it; Alonso and Lamata (2006) proposed a transformation formulation of consistency thresholds by a regression of the random indices; Stein and Mizzi (2007) developed harmonic consistency index (HCI); Vargas (2008) compared consistency indices based on deterministic and statistical approaches and provided a statistical approach for the consistency test; Ergu, Kou, Peng, and Shi (2011) proposed an induced matrix method to measure and improve the consistency of a PCM; Lin, Kou, and Ergu (2013b, 2013c) improved the statistical approach for the consistency test. However, these existing consistency indices and methods is still criticized and disputed in some aspects. Therefore, we will deduce a new consistency index related to the CM method to measure the inconsistency level of a PCM.Given that C∗ is the optimal objective function value of optimization model (12). According to Theorem 3, if a PCM is perfectly consistent, we have(22)C∗=n.Otherwise,(23)0<C∗<n.In order to make eliminate the influence of the size of a PCM, we should divide the objective function value C∗ by n, resulting in C∗/n. Where C∗/n is called cosine consistency index (CCI) of the PCM and takes on values in the interval (0,1]. We write(24)CCI=C∗/n.If the PCM is perfectly consistent, it follows that(25)CCI=1.Otherwise(26)0<CCI<1.which indicates that the PCM has the relative consistency.It is not discussed in this paper that how to determine the thresholds associated with CCI and the relationship between the CCI and the consistency of a PCM. Although there is no standard cut-off rule for the CCI, given its meaning for a PCM, as a general rule, one would expect CCI to be at least 90%.From the above discussion, it is found that the CM has some advantages over the other prioritization methods, including uniqueness of solution, easy computation and consistency indication. However, it is noted that we only consider the CM under condition of the complete and precise PCM with both the acceptable consistency and validity and that the CCI threshold is associated with each decision-maker in practice.We briefly review four typical prioritization methods and two performance evaluation criteria on them. Like the previous section, let A=(aij)n×nbe a positive reciprocal PCM and w=(ω1,ω2,…,ωn)Twith∑i=1nωi=1and ωi⩾0 (i=1,2,…,n) be the priority vector derived from A using some prioritization method.There exist lots of prioritization methods for the priority vector derivation from a PCM in AHP. Among them, EV and LLS are the most popular and commonly used, AN is competitive with the others due to its extreme simplicity (Srdjevic, 2005), WLS can easily be solved and can provide a unique solution unlike LS and EV. Moreover, following discussion in Golany and Kress (1993), some other existing prioritization methods are considered inferior to EV, WLS, AN, LLS expect for LGP and FPP. Therefore, we will choose EV, WLS, AN and LLS with which the CM is compared, regarding the preference evaluation criteria.Eigenvector method (EV).The desired priority vector w=(ω1,ω2,…,ωn)Tas the principal eigenvector of A is obtained by solving the linear system (Saaty, 1977):(27)Aw=λwsubject to∑i=1nωi=1,ωi⩾0,i=1,2,…,n.where λ is the principal eigenvalue of A. If A is perfectly consistent, then λ=n; Otherwise λ>n. EV method gives reasonably good approximation of the desired priority vector under condition of small deviations around the consistent ratios ωi/ωj. However, the solution is not so satisfactory if the inconsistency level of A is high.Weighted least squares method (WLS).The desired priority vector w=(ω1,ω2,…,ωn)Tis formulated as the non-linear constrained optimization problem (Chu et al., 1979):(28)Minimize∑i=1n∑j=1n(ωi-aijωj)2subject to∑i=1nωi=1,ωi⩾0,i=1,2,…,n.The optimization problem is transformed into a system of linear equations by differentiating the Lagrangian of (28) and equalizing it to zero. Blankmeyer (1987) showed that in this way WLS can provide a unique and strictly positive solution.Additive normalization method (AN).The desired priority vector w=(ω1,ω2,…,ωn)Tis obtained by the procedure that is described as follows (Saaty, 1980):(29)Firstaij′=aij∑i=1naij,i,j=1,2,…,n.(30)Thenωi=(1/n)∑j=1naij′,i=1,2,…,n.Srdjevic (2005) showed that the resulting priority vector will be fairly close to the eigenvector solution if A is close to perfectly consistent. Thus, AN can be viewed as an approximation to EV in practice.Logarithmic least squares method (LLS).The desired priority vector w=(ω1,ω2,…,ωn)Tis formulated as the multiplicative normalizing constrained optimization problem (Crawford & Williams, 1985):(31)Minimize∑i=1n∑j=1n(lnaij-lnωi+lnωj)2subject to∑i=1nωi=1,ωi>0,i=1,2,…,n.Crawford and Williams (1985) showed that the solution of the optimization problem (31) is unique and can be found as the geometric mean of the columns of A.More general and applicable to all prioritization methods are error measures such as generalized Euclidean distance (ED) and minimum violations (MV) introduced by Golany and Kress (1993). They measure both the accuracy of the solution and the ranking order properties and are accepted and widely used by researchers (Srdjevic, 2005; Mikhailov & Singh, 1999). In order to assess the performance of the proposed CM, we choose ED and MV as the performance evaluation criteria of prioritization methods.Euclidean distance criterion(ED).(32)ED(w)=∑i=1n∑j=1n(aij-ωi/ωj)21/2.This error measure is represented by the total distance between all elements in A and related ratios of the weights contained in the priority vector derived from A using some prioritization method.Minimum violation criterion (MV).MV(w)=∑i=1n∑j=1nIij,where(33)Iij=1ifωi>ωjandaji>1,0.5ifωi=ωjandaji≠1,0.5ifωi≠ωjandaji=1,0otherwise.This error measure sums up all violations associated with the priority vector derived from A using some prioritization method. The conditions of violation defined by (33) penalize possible order reversal.We will evaluate the performance of the CM by comparing it with EV, WLS, AN and LLS regarding the performance evaluation criteria: ED and MV. These error measure values can also be easily solved by software packages such as SPSS, MATLAB and Microsoft EXCEL. The inputs: the PCM A=(aij)n×nand the priority vector w=(ω1,ω2,…,ωn)Tderived from A using some prioritization method. The outputs: the error measure values (ED and MV) between the derived priority vector w=(ω1,ω2,…,ωn)Tand A. Obviously, the smaller the error measure value is, the better the prioritization method is.In this section, we compare the CM with EV, WLS, AN and LLS regarding two preference evaluation criteria: ED and MV. Three numerical examples are used to demonstrate applications and advantages of the CM. The results are discussed as follows:Example 1Consider the following PCM, which was used by Saaty (2000).A=1431341/41731/511/31/711/51/51/611/35111/31/3551131/41631/31.For this PCM, we have the following results using the CM.Step 1. Normalize the PCM to the transformation matrix by (9), we getB=0.65270.60910.24910.21800.89680.76780.16320.15230.58130.65400.05980.19200.21760.02180.08300.04360.05980.03200.65270.05080.41520.21800.29890.06400.21760.76310.41520.21800.29890.57590.16320.15230.49830.65400.09960.1920.Step 2. Calculate the transformed weights by Theorem 2, we getwˆ∗=ωˆ1∗,ωˆ2∗,…,ωˆ6∗T=(0.6514,0.3460,0.0879,0.3262,0.4773,0.3377)T.Step 3. Calculate the optimal objective function value by Theorem 2, we getC∗=5.210.Thus,CCI=C∗/n=5.210/6=86.8%.Step 4. Calculate the weight assignment coefficient by (19), we getβ∗=0.4491.Step 5. Calculate the final priority vector by (20), we getw∗=ω1∗,ω2∗,…,ω6∗T=(0.293,0.155,0.039,0.147,0.214,0152)T.It is shown in the first column of Table 1, where the numbers in parentheses are ranking orders. Table 1 also shows the priority vectors and ranking orders obtained by EV, WLS, AN and LLS. Table 2shows the error measure values for CM, EV, WLS, AN and LLS, where the numbers in parentheses are ranking orders regarding ED.From Table 1, it is clear that the CM achieves the same ranking order as EV and AN while WLS and LLS lead to different ranking orders. From Table 2, the CM is better than the other prioritization methods according to ED and MV as the smaller error measure value means the better performance.Example 2Consider another PCM below, which is investigated by Lipovetsky and Conklin (2002).A=1537661/31/41/511/35331/51/71/33163461/51/71/51/611/31/41/71/81/61/31/3311/21/51/61/61/31/44211/51/6351/675511/247586621.Using the CM for the PCM, the results are obtained as follows:The transformation matrix isB=0.19530.47830.50460.44360.54750.54030.05190.20800.03910.09570.05610.31690.27370.27020.03110.11890.06510.28700.16820.38020.27370.36020.93420.16640.02790.01910.02800.06340.03040.02250.02220.10400.03250.03190.05610.19010.09120.04500.03110.13870.03250.03190.04210.25350.18250.09010.03110.13870.58580.47830.02800.44360.4562045030.15570.41610.78110.66970.84110.50700.54750.54030.31140.8322.The transformed weight vector iswˆ∗=(ωˆ1∗,ωˆ2∗,…,ωˆ8∗)T=(0.4090,0.1655,03629,0.0437,0.0849,0.1105,0.4151,0.6928)TThe optimal objective function value isC∗=7.2607.Thus,CCI=C∗/n=7.2607/8=90.8%.The weight assignment coefficient isβ∗=0.4377.The final priority vector isw∗=ω1∗,ω2∗,…,ω8∗T=(0.179,0.072,0.159,0.019,0.37,0.048,0.182,0.303)T.Table 3shows the priority vectors and ranking orders obtained by the CM along with EV, WLS, AN and LLS, where the numbers in parentheses are ranking orders. Table 4shows error measure values for CM, EV, WLS, AN and LLS, where the numbers in parentheses are ranking orders regarding ED.From Table 3, it is clear that the CM achieves the same ranking order as AN while EV, WLS and LLS lead to different orders. This is mainly reason that the original PCM was badly inconsistent and needs to be adjusted. Lipovetsky and Conklin (2002) showed that the adjusted ranking order is exactly the same as the ranking order obtained by the CM, that is ω8>ω7>ω1>ω3>ω2>ω6>ω5>ω4. Obviously, from Table 4, the CM is the best among these prioritization methods based on ED and MV.Example 3Consider the following PCM, which comes from Saaty (1980).A=14966551/41755341/91/711/51/51/71/51/61/55111/31/31/61/55111/31/31/51/3733121/51/45331/21.For this PCM, we have the following results using the CM.The transformation matrix isB=0.90890.96240.56360.66650.66650.83930.73510.22720.24060.43840.55540.55540.50360.58810.10100.03440.06260.02220.02220.02400.02940.15150.04810.31310.01110.01110.05600.04900.15150.04810.31310.01110.01110.05600.04900.18180.08020.43840.33330.33330.16790.29400.18180.06020.31310.33330.33330.08390.1470.The transformed weight vector iswˆ∗=ωˆ1∗,ωˆ2∗,…,ωˆ7∗T=(0.7950,0.4626,0.0440,0.1250,0.1250,0.2721,0.2161)T.The optimal objective function value isC∗=6.720.Thus,CCI=C∗/n=6.720/7=96%.The weight assignment coefficient isβ∗=0.4902.The final priority vector isw∗=ω1∗,ω2∗,…,ω7∗T=(0.390,0.227,0.022,0.061,0.061,0.133,0.106)T.It is shown in the first column of Table 5, where the numbers in parentheses are ranking orders. Table 5 also shows the priority vectors obtained by EV, WLS, LS and LLS. Table 6shows the error measure values for CM, EV, WLS, AN and LLS, where the numbers in parentheses are ranking orders regarding ED.From Table 5, it is clear that the CM achieves the same ranking order as all the other prioritization methods, which shows the ranking is robust and credible. From Table 6, the CM is smaller than the other prioritization methods according to ED. All priority methods result in the same result according to MV. This partly shows that the CM still performs better than the other prioritization methods.From the above examples, the CM has the better performance than the other four prioritization methods according to the two performance evaluation criteria: ED and MV. The investigation of three numerical examples has shown applications and advantages of the CM. However, the CM does not extend to the incomplete and imprecise PCM and the thresholds associated with CCI are not directly determined, which is the research objective and direction in the future work.

@&#CONCLUSIONS@&#
We have proposed a flexible and efficient CM for a priority vector derivation from a PCM. The main idea of the CM is to maximize the sum of the cosine of the angle between the derived priority vector and each column vector of a PCM. An optimization model has been suggested for determining transformed the weight vector and weight assignment coefficient, which makes the CM easy to compute. The CM possesses some attractive properties that make it an appealing alternative to the other prioritization methods. For example, the CM does not require any statistical assumptions and provides consistency indication for a PCM, CCI is easy to compute and interpret in AHP. These features of the CM can be considered as sufficient compensation for deriving a reliable priority vector from a PCM. However, the CM has own disadvantages: the CM does not extend to the incomplete and imprecise PCM and the thresholds associated with CCI are not determined in terms of the relationship between the CCI and the consistency of a PCM, which is our research objective in the future. Moreover, discussion about advantages and disadvantages of prioritization methods is still controversial mainly because existing prioritization methods perform differently with regard to different performance evaluation criteria. Therefore, combining different prioritization methods should be considered as a new direction in improving the current prioritization techniques.