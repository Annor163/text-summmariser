@&#MAIN-TITLE@&#
Constrained differential evolution optimization for underwater glider path planning in sub-mesoscale eddy sampling

@&#HIGHLIGHTS@&#
An approach for tackling constrained underwater glider sub-mesoscale path planning.The feasible path area is defined as a corridor around the border of an ocean eddy.A new configuration of constrained differential evolution algorithm and mechanisms.A new benchmark set with 28 different specialized scenarios defines the challenge.Per-scenario and aggregated performance analyses of different mechanism's new configurations.

@&#KEYPHRASES@&#
Differential evolution,Constraint handling,Underwater robotics,Underwater glider path planning,Sub-mesoscale ocean eddy sampling,

@&#ABSTRACT@&#
This paper presents an approach for tackling constrained underwater glider path planning (UGPP), where the feasible path area is defined as a corridor around the border of an ocean eddy. The objective of the glider here is to sample the oceanographic variables more efficiently while keeping a bounded trajectory. Therefore, we propose a solution based on differential evolution (DE) algorithm mechanisms, including in its configuration self-adaptation of control parameters, population size reduction, ϵ-constraint handling with adjustment, and mutation based on elitistic best vector. Different aspects of this DE configuration are studied for the constrained UGPP challenge, on a prepared benchmark set comprised of 28 different specialized scenarios. The DE configurations were tested over a benchmark set over 51 independent runs for each DE configuration aspect. Comparison and suitability for the combination of these mechanisms is reported, through the per-scenario and aggregated statistical performance differences, including different constraint handling definition strategies, different DE mutation strategies’ configurations, and population sizing parameterizations. Our proposed solution outranked all other compared algorithms, keeping a trajectory within the limits with 100% success rate in all physically feasible scenarios; on average, it improved the randomly initialized trajectories fitness by roughly 50%, even reaching perfect fitness (all-around, 360-degree eddy corridor sampling) in some scenarios.

@&#INTRODUCTION@&#
This paper presents a challenge and a suitable approach regarding corridor-constrained underwater glider path planning (UGPP) [1–4]. The underlying oceanographic purpose is the characterization of sub-mesoscale ocean eddy structures, by means of the analysis of its border; the most interesting area but also the harder to sample due to its highly dynamic changes and unstability. Altogether, the presented challenge constitutes an excellent scenario for applying automated path planning generation and optimization. In the proposed approach, the feasible vehicle trajectories are therefore implicitly confined to a corridor area around the border of an ocean sub-mesoscale eddy. Violation of the constraint is quantified by integration of the out-bounded trajectory path's parts. Additionally, we present an approach for tackling this challenge, i.e. we select a configuration of differential evolution (DE) algorithm mechanisms for this corridor-constrained path optimization challenge.An underwater glider is an autonomous underwater vehicle (AUV), a nautical robotic vessel, operating on and below the sea's surface. The glider propels itself by producing small changes in its buoyancy and transforming the resultant vertical motion to horizontal displacement by means of the interaction between the vehicle control surfaces and the water column. The vehicle trajectory consists of a series of saw-tooth profiles (yo-yos) between two target maximum and minimum depths (typically 1000 and 10m), then returning to the surface after completing so-called transects or stints. Once at sea surface, satellite or wireless communication with the control center takes place, during which the glider can fix its position, send data, and receive new commands.The objective of a glider for the challenge our approach tackles in this paper is to sample the scientific research data along an ocean eddy border efficiently. The border region of an eddy shows intense mixing of physical–chemical processes which make it a primary objective for sampling [5,6]. At the same time, this area is subjected to higher variabilities and stronger ocean currents, making manual piloting a very demanding task. In order to keep the glider inside the path limits, waypoints need to be changed almost at every surfacing due to the drifting induced by the currents [7]. Human pilots of underwater vehicles normally operate in reactive control mode, analyzing the result of the previous command before deciding the next bearing to send, not relying on ocean models predictions. Such an approach is valid for some applications, justified by the uncertainties of both forecasts and simulations. However, in the case of short-term dynamic scenarios as the one presented in this paper, operating with no precomputed plan supposes a high risk of missing the sampling target. Additionally, other aspects like multiple vehicle coordination or mission robustness to communication failures give support to automatic path planning convenience, as it would thereby benefit glider operational capabilities [1,8,9]. According to this analysis, we here propose an automated and configured set of algorithmic mechanisms for corridor-constrained path optimization.There are many different approaches for AUV path planning (see the recent survey [1]), including the case of sampling eddies [10] and evolving structures [11], although we have not specifically found a case for maximizing traveling around an eddy border. Also, to date, researchers have mostly addressed the UGPP automatization problem using classical mathematical programming methods, simulated annealing, and genetic algorithms [12,13]. However, the approach [3] addresses the UGPP problem by DE and shows, that (1) DE is suitable for UGPP optimization and (2) suggests especially well performing DE for UGPP. In that approach, some interesting trajectories nearby islands were presented, and the land area had already created some sort of constraints for adhering, i.e. the approach allowed for certain land constraints. However, the simulator used in that approach simply sets glider velocity to zero when colliding, so it remains in that position until the simulation stops. This also always makes the evolved path feasible within this approach. By excluding any enhanced constraints handling in the algorithm, the collision trajectories would then gradually become discarded because they would stop far from the target point; an early marginal collision (a hard limit) could prevent some really good trajectories being evaluated. Also, that approach would not allow the defining of special corridor areas on the sea to adhere to.The contributions of this paper are as follows. As a new suitable configuration of an optimization algorithm for the proposed new challenge, we thereby propose a new approach to UGPP for sub-mesoscale eddy sampling. The configured new variant of jDE combines the mechanisms of self-adaptation [14,15], population size reduction [16,17], and ϵ-constraint handling using ϵ level adjustment [18]. This configuration of a new DE for UGPP is the main contribution of this paper, enabling automatic corridor-constrained UGPP. Also, as the jDE algorithm [14] is mostly reported to perform best when using a randomly chosen population vector during mutation (known as ‘rand’ DE mutation [19]), we show that on a small number of function evaluations like UGPP, we can confirm that when the best population vector within mutation is used (known as ‘best’ DE mutation [19]), the jDE algorithm performs better than when using its most widely used ‘rand’ mutation operation; this observation is another contribution of this paper to UGPP and DE advances. Also, as proposed and demonstrated by the recent paper by Zamuda and Brest [15], a contribution is that we test and confirm that a different than the default value of τ=0.1 for control parameters randomization frequency is suitable on the benchmark used, such as a value of τ=0.5 in this case (and an unsuitable setting would make the algorithm rank worse). Further contributions are that, different aspects of this new DE configuration for constraint optimization are studied in this paper for the constrained UGPP challenge, on a contributed prepared benchmark set, comprised of 28 different specialized scenarios. The DE configurations are tested over a benchmark set on 51 independent runs for each DE configuration aspect, then per-scenario and aggregated statistical performance differences are reported, including different constraint handling definition strategies, DE mutation strategies configuration, and population sizing parameterizations. Utterly, the proposed approach contributes to improve the robotic vehicle capabilities, giving support to better autonomous operation levels.In the next section, related work with more definitions and background on DE and UGPP is presented. Section 3 presents the proposed areal constraint definition for the eddy corridor and the proposed novel approach to tackle the new UGPP challenge on such eddy border. Section 4 presents the 28 proposed novel scenarios inhibiting different eddy borders, then it presents statistical assessment of the proposed algorithm and relates some comparisons. Section 5 concludes the paper, including some guidelines for future work.In this section, the differential evolution and underwater glider path planning related work and background are presented in their respective subsections.Differential evolution (DE) was introduced by Storn and Price [19] using a floating-point encoding evolutionary algorithm [20] for global optimization over continuous spaces. Its main performance advantages over other evolutionary algorithms [14,21–23] lie in floating-point encoding and a good combination of evolutionary operators, the mutation step size adaptation, and the elitist selection. DE has been modified and extended several times with new versions proposed [24–32,22,33] and the performances of different DE variant instance algorithms have been widely studied and compared with other evolutionary algorithms, also at various competitions of major scientific conferences, where DE has won several evolutionary algorithm competitions [34–36,23]. Recent DE algorithms have also been introduced by Wang et al. [37–39], Gong et al. [40], Islam et al. [41], Ghosh et al. [42], Jia et al. [43], Piotrowski [44], Cheng et al. [45], Guo et al. [46], and Ge et al. [47]. DE is also used for constraint optimization and there are several variants which entered competitions held at the IEEE Congress on Evolutionary Computation (CEC) [48,35,49]. DE has also been introduced for multi-objective optimization [50,51]. Successful DE applications have also been published in several major journals. Joshi and Sanderson [52] presented DE for minimal representation multisensor fusion. Chang and Chang [53] used DE to reduce harmonic voltage distortion in electrical distribution systems. Glotić and Zamuda applied a surrogate DE in scheduling hydro and thermal power systems [54]. Maulik et al. [55] applied DE for pixel classification. DE was also applied to remote sensing image sub-pixel mapping [56], image thresholding [57], satellite image registration [58], automatic rule extraction from medical databases [59], and parallel problem solving [60,61]. DE was also used for the reconstruction of procedural tree models [62,63] within the EcoMod ecosystem rendering framework [64]. Alatas et al. presented mining numeric association rules in the optimization of multi-objective problems [65]. Tirronen et al. applied DE to paper production defects’ detection [66]. Tušar et al. used their DEMO optimizer to parameterize an electric motor design [67]. Salvatore et al. [68] utilized DE to optimize an algorithm for sensorless induction motor control. Civicioglu [69] used DE for transforming geocentric cartesian coordinates to geodetic coordinates. DE has also been used for learning and intelligence accumulation approaches optimization, like [70,71]. DE has also been applied in the robotics and autonomous systems class of applied soft computing [3]. Joshi et al. [52] used DE to fuse multi-sensor data in building intelligent robotic systems. Robotic motion planning and navigation was also addressed by DE by Aydin and Temeltas [72] and Chakraborty et al. [73]. Neri and Mininno [74] applied DE to cartesian robot control by introducing memetic operators and compact representation. Chen et al. [75] used DE to design satellite orbit for prioritized multiple targets.The basic DE [19] has a main evolution loop within which a population of vectors is computed for each generation of the evolution loop. During one generation g, for each vector xi, ∀i∈{1, 2, …, NP} in the current population, DE employs evolutionary operators, namely mutation, crossover, and selection, to produce a trial vector (offspring) and to select one of the vectors with the best fitness value. NP denotes population size and g∈{1, 2, …, G}, the current generation number.Mutation creates a mutant vector vi,g+1 for each corresponding population vector. Among the many proposed, two of the most popular DE mutation strategies [24,19] are the ‘rand/1’:(1)vi,g+1=xr1,g+F(xr2,g−xr3,g)and the ‘best/1’:(2)vi,g+1=xbest,g+F(xr1,g−xr2,g),where the indexes r1, r2, and r3 represent the random and mutually different integers generated within the range {1, 2, …, NP} and also different from index i. The xbest,gdenotes the currently best vector. F is an amplification factor of the difference vector within the range [0,2], but usually less than 1. The first term in the mutation operators defined above is a base vector. Following, the difference between two chosen vectors denotes a difference vector which after multiplication with F, is known as an amplified difference vector. The simple DE mutation ‘rand/1’ is by far the more widely used [33], however, a form of ‘best/1’ mutation has also been signified as beneficial, especially in more restrictive evaluation scenarios [52,76,77,3].After mutation the mutant vector vi,g+1 is taken into the recombination process with the target vector xi,gto create a trial vector ui,g+1={ui,1,g+1, ui,2,g+1, …, ui,D,g+1}. The binary crossover operates as follows:(3)ui,j,g+1=vi,j,g+1ifrand(0,1)≤CRorj=jrandxi,j,gotherwise,where j∈{1, 2, …, D} denotes the jth search parameter of D-dimensional search space, rand(0, 1)∈[0, 1] denotes a uniformly distributed random number, and jranddenotes a uniform randomly chosen index of the search parameter, which is always exchanged to prevent cloning of target vectors. CR denotes the crossover rate [78].Finally, in a case of basic single-objective optimization, the selection operator propagates the fittest individual [79] in the new generation (for a minimization problem):(4)xi,g+1=ui,g+1iff(ui,g+1)<f(xi,g)xi,gotherwise.The self-adaptation of the control parameters F and CR is a good mechanism, first introduced in DE with the jDE algorithm [14]. Population size reduction was introduced in [16], where population size is reduced by half, when the number of generations exceeds the ratio between the number of function evaluations allowed and the population size:(5)Gp>MAX_FESpmaxNPp,where MAX_FES is the total number of function evaluations and NPpis the population size reduced as of a current generation. The vectors are discarded index neighbor pairwise, as drawn in [16]. A variant of the jDE algorithm, based on the population size reduction [16] and extended with constraint handling was introduced in [54] as the NPdynϵjDE, a rand/1/bin DE algorithm for combined hydro and thermal power plants scheduling with constraints. Although the jDE algorithm also has other known mechanism combined with its extensions that are not utilized, we therefore refer the reader to further literature [80–82,36,83,23,77].The differential evolution is a family of algorithms which exhibits many existing variants with different configurative combinations of mechanisms and specific recommendations on its mechanisms and parameters’ fine-tuning. In order to decide on which mechanisms from DE literature to apply when tackling a specific new challenge, there therefore exist several to choose from for a new DE configuration. In the survey by Neri and Tirronen [22], it was concluded that compared to the other algorithms, an extended branch of DE, jDE [14], is superior in terms of robustness and versatility over diverse benchmark sets. The jDE however has also been further extended and also won the 2009 WCCI Dynamic and Uncertain Environments competition [36] and performed well at other competitions on Large Scale Global Optimizations in 2008 and 2010 [84,83], Real-World Industry Challenges in 2011 [17], and a recent Real Parameter Single Objective Optimization in 2013 [77], where more than half of the entered algorithms were based on DE. Some popular jDE extension mechanisms are the population size reduction [16,17] and ϵ-constraint handling using ϵ level adjustment [85,18]. Therefore, since the jDE branch of algorithms shows promising performances and its derivatives have been extended to similar challenges, we have chosen to apply in this paper as an optimizer, a new variant of jDE.Several methods have been proposed for defining constraints and addressing them in genetic algorithms for parameter optimization problems [86]. A summary of constraint handling techniques can be found in [87–89], which also contains information on many stochastic techniques. An application of the constraint definition is to use it to guide the search towards feasible areas of the search space. Given constraints, there are different methods for consideration when defining feasibility and possible violation estimation of a solution, varying with the ease of defining such methods on the one hand and guiding feedback amount suitability for constraint violation handling on the other:1The easiest methods for defining are by limiting the values of the parameters and defining how to repair the generated parameters each time before objective function evaluation into pre-defined viable values (box-constraint) ranges, perhaps by some heuristic function (i.e. this is the class of methods based on preserving the feasibilities of solutions [86]). If it is possible to define the challenge in this way, this is preferable from the view of ease of use in an evolutionary algorithm but not necessarily from the view of optimization performance potential.Basic methods which make a clear distinction between feasible and infeasible solutions, providing some feedback to a possible constraint handling mechanism [86], would be when defining boolean functions. Such a function could assess whether a certain set of chosen search parameters yields a viable solution. The CEC 2011 Real World Industrial Challenges (RWIC) competition benchmark set [90] included such a limiting function, rendering the constraint handling to merely using a boolean feasible/infeasible threshold decision, e.g. as defined in the algorithm [17].Such methods are regarded as an equality constraint in optimization, and should be avoided if possible. Namely, it is very hard to use pure equality constraints, since first a set of parameters that are viable with regard to this equality constraint boolean function need to be found and then secondly, by preserving an evolved solution on this boolean function front, to still try to improve the solution. Equality constraints are therefore usually transformed to inequality constraints utilizing a very small violation interval that is allowed, since the real-world solution error might be practically invariant to the very small changes in search parameters; e.g. the surrogate DE algorithm in [54] uses this feature as its main accelerator for outperforming other current approaches.A better solution to the thresholded binary constraint-based feasibility definition is to use some continuous value estimation. This type could still be seen as a method which makes a clear distinction between feasible and infeasible solutions but also has more feedback that penalizes distinctly. This enables better constraint handling, by having one or more floating-point types of constraint functions, which are similar to the ordinary evaluation function from unconstrained single-objective optimization. As a constraint denotes some functionality which is more important than the functionality being optimized as the main task, the constraint function is therefore usually defined as an easier function than the evaluation function, since it needs to be solved first in order to attain the optimization front of the desired evaluation function. As noted by Elsayed et al. [91], due to the variabilities of problem characteristics, no single algorithm performs consistently over a range of problems and in their paper they, instead of introducing another such algorithm, proposed an evolutionary framework that utilizes existing knowledge to make logical changes for better performance.By further detailing a constraint definition into more sub-functions returning separate continuous violation values, there are even more options on how to design a final framework for addressing constraints, as the problem of aggregation becomes a multi-objective problem in itself. Therefore, we will explore further improvements that could be gained through different aggregations when using the constraint feedbacks of several sub-functions in an optimization algorithm by adjusting feasibility, e.g. by gradually relaxing the feasibility measures and analyzing the performance comparisons. One such adjustment scheme is within the ϵ-constraint [92] constraints definition, which was also used in some high ranking DE algorithms at the IEEE CEC competitions [48,35,49], including [92,93,18,94]. We will use one of such methods to define a corridor constrained area in this paper and its constraint handling is detailed in the following subsubsection.A solution x is regarded as feasible with regards to inequality constraints gi(x)≤0 and equality constraints hj(x)=0 if(6)gi(x)≤0,i=1,…,q,(7)|hj(x)|−ϵ≤0,j=q+1,…,m,where equality constraints are transformed into inequalities. A mean value of all constraints’ violationsν¯is defined as:(8)ν¯=(∑i=1qGi(x)+∑j=q+1mHj(x))m,where the sum of all constraint violations is zero for feasible solutions and positive when at least one constraint is violated:(9)Gi(x)=gi(x),gi(x)>0,0,gi(x)≤0,(10)Hj(x)=|hj(x)|,|hj(x)|−ϵ>0,0,|hj(x)|−ϵ≤0.The ϵ-jDE algorithm [85] follows the jDE-2 algorithm [95] and emphasizes constraints as follows. It compares two solutions, say i and j, during the selection operation:(11)xi,g+1=xj,gif(ν¯i,g>ν¯j,g),xj,gelse if(ν¯j,g=0)∧(f(xi,g)>f(xj,g)),xi,gotherwise.The algorithm distinguishes between feasible (ν¯=0) and infeasible individuals: any feasible solution being better than any infeasible one. Namely, the jDE-2 algorithm had difficulties when solving constrained optimization problems with equality constraints. Since Takahama and Sakai in [92] pointed out that for problems with equality constraints, the ϵ level should be controlled properly in order to obtain high quality solutions, the ϵ-jDE algorithm therefore uses ϵ level controlling, where the ϵ level constraint violation precedes the objective function when the aggregated constraints value is small. The ϵ-jDE also uses an adaptive and self-adaptive control of ϵ level but thereby introduces some additional control parameters. The ϵ level is updated until the number of generations g reaches the control generation gc. After the number of generations exceeds gc, the ϵ level is set at 0 to obtain solutions with minimum constraint violations [85].An ocean glider is an autonomous vehicle that propels itself by changing its buoyancy. The resultant vertical velocity is transformed into an effective horizontal displacement by means of the active modification of the pitch angle and the effect of the control surfaces. The glider motion pattern consists of a series of “v” or yo-yos descending/ascending profiles between two target maximum and minimum depths, after which the vehicle returns to the surface, having completed a stint, to transmit data and update its target way-points [3].Ocean gliders constitute an important advance in the highly demanding ocean monitoring scenario. Their efficiency, endurance, and increasing robustness make these vehicles ideal observation platforms for many long-term oceanographic applications [96]. Nevertheless, they have also proved to be useful for the opportunistic short-term characterization of dynamic structures. Among these, mesoscale and sub-mesoscale eddies are of particular interest due to the relevances they have in many oceanographic processes [97]. The characterization of pollution and harmful algal bloom episodes have also been included as part of recent glider missions. Having the potential of fully autonomous operation, the usual control scheme of ocean gliders does not exploit these capacities too much and relies mainly on a human-in-the-loop approach [3].Path planning plays a major role during glider navigation [98] as a consequence of the special motion characteristics these vehicles present. Indeed, ocean current velocities frequently show values that are comparable to or even exceed the low surge speed of a glider, typically around 1km/h (0.28m/s). In such situations a feasible path must be prescribed to make the glider reach the desired destination. This can be accomplished by analyzing the evolution of the ocean currents predicted by a numerical model. This problem is nontrivial, as the planner must take into account a 4D, spatio-temporally varying field over which to optimize. Also, since increasing the number of function evaluations (FES) degrades the optimization execution time and jeopardizes mission planning time (limiting the optimization time to minutes), it is inevitable to have a restriction on FES, e.g. limited to roughly few thousand FES which may compute within a few minutes [3].This work is specifically concerned with the sampling of highly dynamic ocean structures, more specifically eddy border areas. When a glider is performing a long-term extended range mission in the open sea, the piloting can apply reactive control strategies with minor penalties; this corresponds to a traditional human in the loop control based in a trial and error command scheme. Nevertheless, there is a growing interest in extending the operational capacities of the gliders for also dealing with short-term opportunistic applications. During a long mission, for example, dynamic structures can appear within the vicinity of the glider offering windows of opportunity for collecting valuable scientific data. Some representative examples of these structures include eddies, fronts, plumes or algae blooms. However, in these scenarios, a reactive control scheme is no longer valid due to the typically short duration and relatively rapid spatial evolution of the structures of interest. In order to maximize the possibilities of success, the glider's behavior needs to be anticipated according to as precise as possible forecasts of the environmental conditions. Within this perspective, it is interesting to have at hand automatic path planning tools able to generate a feasible trajectory for the vehicle over a reasonably short period of time. The glider mission planning needs to be completed within a few hours, minutes in some critical applications, in order to prepare the mission files to be downloaded for the next underwater segment.Different solutions to the glider path planning problem can be found in the literature. Inanc et al. [99] propose a method that applies Nonlinear Trajectory Generation (NTG) on a Lagrangian Coherent Structures (LCS) model to generate near-optimal routes for gliders within dynamic environments. Yoon [100] designed UGPP trajectory for considering depth constraints. Alvarez et al. [12] used Genetic Algorithms (GA) to produce suitable paths in the presence of strong currents while trying to minimize energy consumption. Other authors have focused on the coordination of glider fleets to define optimal sampling strategies [101]. A multi-objective GA was also applied to autonomous underwater vehicles for sewage outfall plume dispersion observations [8], which considered two objectives, i.e. the maximum number of water samples besides the total travel distance minimization.In the particular case of eddies, the complexity of the path planning scenario is aggravated by the high spatio-temporal variabilities of these structures and their specific sampling requirements [102]. Garau et al. [10] used an A* search algorithm to find optimal paths over a set of eddies with variable scale and dynamics. Smith et al. [11] proposed an iterative optimization method based on the Regional Ocean Modeling System (ROMS) predictions for generating optimal tracking and sampling trajectories for evolving ocean processes. Their scheme includes near real-time data assimilation and has been tested both in simulation and real field experiments. In a recent publication [103] Kularatne et al. have extended this work to make the vehicle adaptively follow a zig-zag sampling trajectory. Eichhorn [9] also proposed a method for tackling optimal path planning within time varying scenarios. Some early glider path planning approaches use optimization based on a Nelder-Mead algorithm [104] (the fmisearch Matlab implementation [105]) or genetic algorithms (GA) [97]. Lolla et al. [106] have recently applied a level set theory to some path planning problems in the presence of dynamic flows, including obstacle avoidance. Their work focuses on multi-vehicle coordination applications.To date, researchers have mostly addressed the UGPP problem using classical mathematical programming methods, simulated annealing, and genetic algorithms [12,13]. Now we address the constrained UGPP problem by DE and constraints handling and show, that (1) DE is suitable for constrained UGPP optimization and (2) suggest an especially well performing constrained DE configuration for UGPP. Differential evolution is a family of algorithms which exhibit many existing variants and specific recommendations regarding their mechanisms and parameters fine-tuning. Therefore we have sought to utilize some of its good ranking mechanisms [48,35,49], so as to have insight into which DE mechanisms would be suitable for constrained UGPP, especially when compared to typical scenarios of dynamic sub-mesoscale ocean structures where short-term opportunistic sampling mostly benefits broader UGPP mission planning.In [3], UGPP was addressed using DE and other evolutionary algorithms, where it was suggested that the use of DE is beneficial on the 12 test scenarios, and a real mission was carried out to confirm the viability of the approach. For a certain DE algorithm, the jDE algorithm [14], which is mostly reported to perform best when using a randomly chosen population vector during mutation (known as ‘rand/1’ DE mutation [19]), it was also shown that on a small number of function evaluations like for the UGPP, when the best population vector within mutation is used (known as ‘best/1’ DE mutation [19]), the jDE algorithm performed better than when using its most widely used ‘rand’ mutation. Further, in [4,107], selected early results of the population sizing parameterizations and population size reduction configurations were presented for the UGPP. In this subsection, the UGPP DE approach is explained in more detail, as the current paper extends this approach to a significant degree by hardening the test scenarios and including more constraint functionalities.Modeling a glider trajectory, the approach [3] evolves a global underwater glider path based on the local kinematic simulation of an underwater glider, by considering the daily and hourly sea currents predictions. The global path is represented by control points where the glider is expected to resurface for communication with a satellite and to receive further navigational instructions. Such an evolutionary algorithm (EA) application (UGPP DE), the UGPP trajectory optimization, is even more interesting when the current field is not homogeneous and bearings are non-trivial.For the sake of clarity, and since the constraint-based approach presented in this paper is based on the same principles, a detailed description of the approach [3] is included in the following three subsubsections, clearly defining the approach for the purpose of being extended in the next section; first the evolved parameters and their genotype encoding, then the genotype–phenotype mapping, and finally the phenotype fitness evaluation.In [3], the glider path is iteratively evolved by minimizing its fitness evaluation. The parameters within a DE population vector x={x1, x2, …, xD} to be evolved during optimization are used to compute the bearings to be sequentially commanded to the glider at each surfacing.11During a stint, the glider's autonomous control system tries to make the actual heading angle the glider is experiencing, equal to the orientation of the next way-point (bearing angle) commanded to the glider.Every vector component encodes a bearing increment [3].Starting normally from the last known glider position p0, the initial reference bearing angle b0∈[0°, 360°] is computed as the orientation of the desired target point ptarget:(12)b0=bearing(p0,ptarget),where bearing() is the bearing angle computation between a glider starting point and a target point, that is, the azimuth evaluated as the angle at which the arc between both points crosses the meridian containing the glider position. The new (to be commanded) absolute bearings b={b1, b2, …, bD} are computed incrementally from the xj, j∈{1, 2, …, D}, values: b1=b0+x1, b2=b1+x2,…, bj=bj−1+xj. b0 is not a bearing to be commanded to the glider, but an initial reference bearing, with the first absolute bearing to be commanded being b1. The dimensionality of the problem D is therefore the same as the number of bearings commanded, which equals the total number of glider surfacings. The DE parameters are encoded as floating-point scalar values packed into an individual vector of bearing increments, where ∀x1, x2, …, xD∈[−100, 100]. Extreme +180° and −180° increment values are not desirable, as they introduce ambiguities during the fitness function evaluation [3].After obtaining bearings representation from a DE vector to be evaluated, the bearings are inputted to the glider kinematic simulator, together with the dynamic currents scenario, to form a trajectory. A glider point model for the kinematic simulation can be defined from the following differential equations for a sample point in position (x, y, z) at time t:(13)x′=u+Ugcos(θ)cos(ϕ),(14)y′=v+Ugcos(θ)sin(ϕ),and(15)z′=w+Ugsin(θ),where x′, y′, and z′ denote differences prediction for the three-dimensional position of the glider after time t, Ug is the glider's nominal surge speed, u,v, andware the ocean current velocity components at point (x, y, z) at time t, and θ and ϕ are the pitch and heading angle, respectively. The vertical velocity component of the sea current is normally not considered as its modulus is relatively small, in fact many ocean models do not provide this variable as output. The glider's kinematic simulator integrates these velocities to compute the three-dimensional glider path taking into account the pre-defined surfacing times and maximum and minimum depths of the yo profiles [3].The main glider control parameter is the heading angles, directly related with the bearings, while the pitch angle is normally pre-fixed. In simulation and for short distances (our case), headings can be considered equivalent to bearings, while in real missions and for long distances factors such as rhumb lines and magnetic declination should be taken into account. Fig. 1shows the XYZ global coordinate system and the XgYgZg glider coordinate system. The heading angle is the projection of the X−Xg angle on the XY plane, while the pitch angle is the projection of the Z−Zg angle on the XZ plane. The u/v/wcurrent components are aligned with the X/Y/Z axes, respectively.The sea current maps were provided from MyOcean IBI service,22http://myodata.puertos.es/.that included a high resolution Regional Ocean Modeling System. It provided outputs for different oceanic variables in various formats in 19°W 5°E 26°N 56°N area coverage at 1/36° resolution. In the context of the work [3], maps for a 3 day forecasting horizon were used, containing hourly two-dimensional (longitude, latitude) surface currents and daily means three-dimensional (longitude, latitude, depth) currents. For detailed short-term fine-grain simulation, both maps were combined into a three-dimensional hourly pre-processed map that was later interpolated at a given position/time coordinates. For long-term simulation, and in order to reduce the computational cost, daily three-dimensional maps with the nearest neighbor interpolation could have been applied [3].After mapping the genotype x into its phenotype b, as described in previous subsection, the process for computing the fitness function was as follows from [3]:Step 1Obtain last glider known position (p0).Predict next surfacing position p1:(16)p1=simulate_stint(pj−1,b1,map),where p1 denotes the predicted surfacing position, b1 the bearing selected, and map represents the ocean currents predictions’ provided by the forecast model, and simulate_stint is the procedure that simulates the glider underwater path according to the formulas described in the previous subsection. Then a short surface drift simulation is applied to take into account the drift affecting the glider's position p1 while the data_send and command_receive satellite communications are performed:(17)p1′=simulate_drift(p1,map).The resulting pointp1′is then taken as the initial point for the next local simulation and the new bearing b2 is applied. The cycle repeats until the last element of the bearings set bj, ∀j∈{1, 2, …, D}, is reached.The genotype x={xj}, ∀j∈{1, 2, …, D} is transformed into a full glider path {pj}, ∀j∈{1, 2, …, D}, by incrementally concatenating a series of D individual glider kinematic simulations described in the previous step.Obtain fitness value as the remaining geometrical distance from the last trajectory point pDand the target point:(18)f(x)=∥pD−ptarget∥.Before the distance computation, for speedup purposes the longitude and latitude differences were approximated by conversion into metric distances to avoid the use of sine and cosine functions. When considering the mission ranges evaluated in [3], the conversion error was negligible.With respect to the previous work, in the present paper we have faced a more challenging path planning problem, where the glider is required to maximize the sampling inside a corridor defined on the border of an ocean eddy in a given period of time. The base new mathematical model is similar to the one described in Sections 2.3.1, 2.3.2, 2.3.3, with a new formulation of the fitness evaluation and the introduction of the constraint function. The problem to be solved can be stated as:(19)argminx(f(x))s.t.Eq.(6),where the f(x) is the trajectory fitness function to minimize, subject to the corridor constraints and where x={x1, x2, …, xD}, ∀x1, x2, …, xD∈[−150, 150]. By combining the differential evolution with the underwater glider path planning simulator, we evolve a three-dimensional path on and under sea for finding the best-fit trajectory (i.e. its genotype x), depending on the sea currents and underwater glider vessel operation. This fitness computation of an evolved trajectory inside the DE is based on glider kinematic simulation. A better fitness (i.e. takes smaller values) is obtained for trajectories circling more around the eddy, so towards the best possible result would be a full circle (360°) turn with the vehicle kept inside the corridor all the time. From the glider modeling point of view, there are some complex kinematic [108] or even dynamic [109,110] models that take the different lift, buoyancy, and drag forces into account. However, they are not suitable for long-range glider navigation simulations given the high computational cost that would overrun on time restrictions. Instead, a simple kinematic point model is applied integrating the glider velocity vector with the currents’ vectors.In the following subsection, fitness computation iterations and corridor constrained definitions and their handling are presented first, then in the next one parts of the optimization algorithm for the proposed combined approach are described, where the necessary extensions with constraint handling are also presented.The architectural steps for computing fitness during the current approach are similar to the ones described in Section 2.3[3]. However, the formulas in Steps 1…4 have to be changed because now the fitness value is obtained by analyzing the angular coverage of the glider trajectory along the eddy border (close to 180° in the trajectory shown in Fig. 2, for example). As will be further explained below, this calculation requires to include the intermediate trajectory points and similarly for the constraint violations computation. In the previous approach [3] the intermediate trajectory points were not relevant, as there was no constraints and also as the fitness function depended only on the target point and the one final (last) trajectory point. With this mindful increase in included number of glider trajectory control points for fitness estimation (and constraints checking), the trajectory evaluation process complexity increased considerably, further impacting the UGPP performance.In the previous approach [3], there was no advanced constraints handling, because the feasibility of the trajectory was always preserved during evaluation. Now, explicit constraints have been introduced that allow the optimization algorithm to address path restrictions, using a continuous evaluation measure and a hybrid constraint handling. A pair of inner and outer corridor borders are defined as the minimum and maximum allowed distances for the glider trajectory from the eddy center, respectively. The trajectory violation is then defined using path segments outside this eddy border corridor, yielding tangent lines outliers that are aggregated as a constraint violation value (see Fig. 2, where the lengths of the tangentially perpendicular lines aggregate into a constraint violation value). We present here the use of a circular area eddy corridor shape definition; however, the extension to more generic ellipsoidal areas is straightforward.The constraint violation estimation function is defined as a range of floating-point function evaluations on trajectory time-equidistant control points. A function within this range computes a perpendicular offshoot of the glider from a corridor border. In order to aggregate this trajectorial violations (constraint area function violations), it would perhaps be interesting to test some different methods. Namely, based mainly on the different current properties of a scenario, addressing the trajectory constraint might be current-distribution (stability) dependent, currents average strength dependent; nonetheless, aggregation suitability may well be dependent on the combination of the mechanisms of a DE configuration. So perhaps a faster converging problem definition would not be to merely minimize the largest outlier offsets. Therefore, we considered different methods for constraint area function violation definition and aggregation.Regarding the intermediate trajectory points, a glider path consisting of trajectory point set {tk}, k=1, 2, …, K is formed by a succession of D pairs of a stint segment, containing L control points, and a surface drift segment, containing L′ control points; so the total number of points in the trajectory point set is K=(L+L′)D. As an example, if the stint duration is around 6h (a typical value), and the time difference among control points tkfor the simulation is 10min, that makes the number of points L=36 for every jth stint trajectory{tlj;∀j=1,2,…,D,∀l=1,2,…,L}. The last point in a stint trajectory segment ispj=tLjand corresponds to the surfacing position after the stint finishes (normally 1 or 2 yo-yos). Surface time is around 20min, this adds 2 more points for the trajectory points set{tlj}, ∀l=L+1, L+2, ∀j=1, 2, …, D. This makes a total of K=(L+2)D=38D control points to test for constraint violation, e.g. in a case of D=10, this results in K=380 control points to be checked for corridor containment.The fitness/constraints computation is organized in four main steps derived from the ones described in Section 2.3, these steps are: simulation of the glider trajectory, transformation to polar coordinates, fitness computation, and constraints evaluation.Step 1Simulation of the glider trajectory.Step 1.1Obtain last glider known position p0 and the initial reference bearing b0 as the direction pointing from p0 to the center of the eddy:(20)b0=bearing(p0,peddy center),Compute next bearing expressed using DE trial vector's component ui,j,g+1 (from population i=1, 2, …, NP), beginning with j=1:(21)bj=bj−1+ui,j,g+1.Predict next surfacing position pjand collect the stint trajectory point set:(22){tlj;∀l=1,2,…,L}=simulate_stint(pj−1,bj,map),where pjdenotes the initial glider position p0 when j=0 or otherwise, when j>1, preceding drift's last point locationtL+L′j−1.The short surface drift simulation is then applied:(23){tlj;∀l=L+1,L+2,…,L+L′}=simulate_drift(pj,map).Repeat the steps 1.2–1.4 for D times (once for every bearing, increasing index j in each loop). These simulations for stint and drift therefore yield D path segments consisting of a series of individual jth glider kinematic control points{tlj,∀l=1,2,…,L+L′}. A trial phenotype for a genotype ui,g+1, i=1, 2, …, NP, is then transformed into a full glider path by concatenating all these segments,|{tlj}|=K, ∀l=1, 2, …, L+L′, ∀j=1, 2…, D and a full path is defined from points∀tk∈{tlj}.Transformation to polar coordinatesStep 2.1Transform the absolute coordinate glider trajectory relative to the eddy center (peddy center) coordinates: transform all previously latitude/longitude coordinates [°] to UTM x/y coordinates [m], using the WGS 84 standard transformation.33Using a publicly available Matlab function (deg2utm.m), adapted as a local version for faster execution in Canary Islands sea locations (deg2utmCan.m).The transformation to relative eddy center coordinates is straightforward once in UTM metric coordinates: a simple translation to eddy center, subtracting eddy center x and y coordinates from trajectory x and y coordinates, respectively:(24)Rtk=deg2utmCantk−deg2utmCanpeddycenter,∀k=1,…,K.Transform to polar coordinates from the relative metric coordinate system for the kth point Rtk={Rtk,x, Rtk,y}, ∀k=1, …, K:(25)γk=atan2(Rtk,y,Rtk,x),(26)rk=Rtk,x2+Rtk,y2.Fitness computation: compute the fitness as the unsampled angular sector around the eddy center, that is, the remaining angle to cover a full 2π turn:Step 3.1Compute the angle increments of the path around the eddy center, Δγ:(27)Δγk=γk+1−γk,∀k=1,2,…,K−1.Compute the cumulative angle (around the eddy center, zero angle at p0).(28)αkcum=0,k=1,αk−1cum+Δγk−1,∀k=2,3,…,K.Compute the fitness value as the difference between the angular extent and a full turn:(29)αext=maxK=1Kαkcum−minK=1Kαkcum,(30)f(ui,g+1)=2π−αext.Constraints evaluationFor a circular corridor defined by rmin and rmax, the constraint violations of all D trajectory segments points tk, ∀k=1, …, K, transformed by Eqs. (24) and (26) are defined using the relative polar transformed coordinates as a tangent perpendicular distance doutside(tk) of these points from a corridor border as:(31)νk=doutside(tk)=0rk>rmin∧rk<rmaxmax(rmin−rk,rk−rmax)otherwise.The discretized time glider trajectory doutside(tk) equals 0 if the trajectory point tkis inside the corridor, or minimum distance to corridor if outside.The composite constraints violation valueν¯u,g+1, corresponding to ui,g+1, is then computed using νkvalues.In order to compute a composite value of the whole set of constraints violationsν¯however, the ν values are aggregated as is explained in this paragraph. A human pilot would try to be conservative and keep the glider as centered as possible in the corridor. Being close to the limits would increase violation probability and, in the worst case, make it impossible to drive the glider back into the corridor. The fitness and constraints violation values have to be minimized, so the best trajectories are the longer ones along the eddy border corridor (i.e. the difference to full circle is minimal w.r.t. angular subtraction) and less violating the feasible area, respectively. For the constraints violation definition using Eq. (32), we shall use name sum – this one aggregates the violating parts of the trajectory by adding up values proportionate to the surface area of the violation area part (see Fig. 2). For aggregation of the violated segments of a path, we utilize and compare following aggregation methods for configurating our approach:sum method)this method sums the tangents (perpendicular lines of segments in Fig. 2, i.e. the distances from a border, of all the trajectory samples outside the corridor) for out-lying bearings, is something like a power or a surface of the area that is being traveled outside:(32)ν¯u,g+1=∑k=1Kνk.the squares of each value before summing the values up, i.e. amplifying the outliers by their own powers, (similar to the standard deviation measure of a signal is defined),(33)ν¯u,g+1=∑k=1Kνk2.considers an average value of the aggregated values and also a maximal violation among these values; this method is used in the NPdynϵjDE of [54], where it is also suggested balancing equally among the average and maximal outliers, i.e. the same priority with weight coefficients at 0.5 is used; this way, additional attention is given to the largest outlier and the algorithm has to try so that the highest violation would be as small as possible, even if including some smaller ones:(34)ν¯u,g+1=0.5∑k=1KνkK+0.5maxk=1K∑k=1Kνk.In this paper the constraint handling mechanism ϵ level adjustment is adaptive and with less control parameters, which simplifies the adjustment scheme of ϵ-jDE into the following mechanism when comparing two solutions i and j while g<gc:(35)xi,g+1=xj,gif(f(xj,g)<f(xi,g))∧(ν¯i,g<ν¯η,g∧ν¯j,g<ν¯η,g),xi,gelse if(ν¯i,g<ν¯η,g∧ν¯j,g<ν¯η,g)∨(f(xi,g)⩽f(xj,g)),xj,gotherwise.After g≥gc, the selection operation relaxing mechanism reverts back to Eq. (11), as in the ϵ-jDE. This simplification eliminates the need for some control parameters since the evolutionary selection pressure replaces the adjustment scheme. In order to determine the pivotal index η that is used to select the reference individual for constraint comparison in Eq. (35), like in [54], η%=0.2NP is used to compute the population index of the xη, i.e. the top ηth constraint valued individual within the population is indexed as:(36)η=⌊ν%NP+1⌋.Algorithm 1Constrained differential evolution for underwater glider path planning (with sum aggregation method).procedure NPdynϵsumjDE/best/1/bin@cUGPP(x)Require: p0 (current glider location), map (MyOcean IBI), peddy center (eddy center as a virtual mission target point), L (number of trajectory points per stint), L′ (number of trajectory points per drift), MAX_FES (maximum number of FES allocated), NPinit (initial DE population size), NPmin (minimum DE population size), pmax (number of population size reductions), Fl, Fu, τ1, and τ2 (jDE constants, τ1=τ2=τ ad hoc), η%, gc(constraint handling parameters), rmin, rmax (corridor borders radii).Ensure: x – list of instructions (D incremental bearings) on how to navigate glider; also, for possible further mission plan assessment, some auxiliary outputs are generated based on the evolutionary run, such as 1) computation date and time, 2) fitness and constraint violation of the best obtained x, 3) per-generation convergence of the: a) best fitness or fitness for minimum constraint w.r.t. Eq. (11), b) minimum constraint value, c) mean fitness value for the population, and d) standard violation of fitness values for the population.uniform randomly generate DE initial population xi,0, ∀i∈{1, 2, …, NPinit};initialize ϵ-constraint handling method using Eq. (36);for DE generation loop g (while FES <MAX_FES) dofor DE iteration loop i (for all individuals xi,gof a population) doif population is to be reduced as of Eq. (5)thenreduce population to half using Eq. (11) for index-wise propagation (see  [16]);end ifDE individual xi,gcomputation (adaptation, mutation, crossover):Fi,g+1=Fl+rand1×Fuifrand2<τ1,Fi,gotherwise;CRi,g+1=rand3ifrand4<τ2,CRi,gotherwise;vi,g+1=xrbest,g+Fi,g+1(xr1,g−xr2,g);ui,j,g+1=vi,j,g+1ifrand(0,1)≤CRi,g+1orj=jrandxi,j,gotherwise,∀j∈{1,…,D};DE fitness evaluation and constraint violation estimation (UGPP simulation):b0=bearing(p0, peddy center);forj={1, 2, …, D}:bj=bj−1+ui,j,g+1;{tlj;∀l=1,2,…,L}=simulate_stint(tL+L′j−1,bj,map), where p0 is used astL+L′0;{tlj;∀l=L+1,L+2,…,L+L′}=simulate_drift(tLj,map);end forfork={1, 2, …, K} where K=D(L+L′) and∀tk∈{tlj},∀j=1,2,…,D,∀l=1,2,…,L+L′:Rtk=deg2utmCan(tk)−deg2utmCan(peddy center);γk=atan2(Rtk,y,Rtk,x),rk=Rtk,x2+Rtk,y2;αkcum=0,k=1,αk−1cum+(γk−γk−1)∀k=2,3,…,K;νk=0,rk>rmin∧rk<rmaxmax(rmin−rk,rk−rmax),otherwise;end forf(ui,g+1)=2π−maxk=1K(αkcum)−mink=1K(αkcum);ν¯u,g+1=∑k=1Kνk;DE selection: use Eq. (35) if g<gc, otherwise Eq. (11);end foradjust ϵ-constraint handling method parameters by recomputing η using Eq. (36);end forreturn: the best individual obtained among xi,G;Algorithm 1 outlines the proposed DE instance combined with corridor-constrained UGPP, featuring the extended jDE algorithm [14] and the ‘best/1’ mutation. The mutation strategy the original jDE algorithm uses is ‘rand/1’, as jDE algorithm was largely reported to perform better rather with ‘rand/1’ strategy [80,16,82], while the ‘best/1’ strategy was only used in some population-structured combination [76], possibly with other strategies [77].In this paper, a new best/1/bin strategy based DE variant of the jDE algorithm is used, itself based on the population size reduction [16] and extended with constraint handling as introduced in [54] for combined hydro and thermal power plants scheduling with constraints (the NPdynϵjDE, a ‘rand/1/bin’ DE algorithm variant). However, specifically we propose a new algorithm, because the ‘best/1’ (see Eq. (2)) instead of the ‘rand/1’ (see Eq. (1)) mutation strategy is used, there are three constraint violation definition methods utilized (sum, sum2, and avg+max, see Eqs. (32)–(34) above) instead of the initial avg+max, and the population sizing parameterization is adjusted for the UGPP challenge in this new algorithm variant.

@&#CONCLUSIONS@&#
