@&#MAIN-TITLE@&#
Constraint qualifications in convex vector semi-infinite optimization

@&#HIGHLIGHTS@&#
We introduce different types of tangent cones for convex vector SIO problems.We introduce and compare four constraint qualifications (CQs).We characterize (weakly, properly) efficient solutions in terms of cones.KKT results are provided.

@&#KEYPHRASES@&#
Multiobjective optimization,Convex optimization,Semi-infinite optimization,Constraint qualifications,

@&#ABSTRACT@&#
Convex vector (or multi-objective) semi-infinite optimization deals with the simultaneous minimization of finitely many convex scalar functions subject to infinitely many convex constraints. This paper provides characterizations of the weakly efficient, efficient and properly efficient points in terms of cones involving the data and Karush–Kuhn–Tucker conditions. The latter characterizations rely on different local and global constraint qualifications. The results in this paper generalize those obtained by the same authors on linear vector semi-infinite optimization problems.

@&#INTRODUCTION@&#
We consider convex optimization problems of the form(1)P:``min""f(x)=(f1(x),…,fp(x))s.t.gt(x)≤0,t∈T,where x ∈Rn(the space of decisions), f(x) ∈Rp(the objective space), the index set T is a compact Hausdorff topological space,fi:Rn→Ris a convex function,i=1,…,p,gtis convex for each t ∈ T, and the function (t, x)↦gt(x) is continuous onT×Rn.The continuity of f is consequence of the assumptions on its componentsf1,…,fp.The model (1) includes ordinary convex (scalar and vector) optimization problems just taking the discrete topology on the (finite) index set. Since the optimality theory for this class of problems has been thoroughly studied, we assume in the sequel that T is infinite. When p ≥ 2, P is a convex vector semi-infinite optimization (SIO in brief) problem; otherwise, P is a convex scalar SIO problem. Replacing in (1) the space of decisionsRnby an infinite dimensional space (typically a locally convex Hausdorff topological vector space) one gets a convex (scalar or vector) infinite optimization (IO in short) problem.We assume throughout the paper that p ≥ 2 and the feasible set of P, denoted by X, is non-empty. Obviously, X is a closed convex set whereas its image by the vector-valued objective functionf(X)⊂Rpis possibly non-convex and non-closed. The vector SIO problem P can be reformulated as a vector optimization problem with the single convex constraint function φ(x) ≔ maxt ∈ Tgt(x), called marginal function:P:``min""f(x)=(f1(x),…,fp(x))s.t.φ(x)≤0.Throughout the paper we use the following notation. Givenx,y∈Rm,we write x≦y (x < y) when xi≤ yi(xi< yi, respectively) for alli=1,…,m.Moreover, we write x ≤ y when x≦y and x ≠ y.An elementx¯∈Xis said to be efficient (weakly efficient) if there is nox^∈Xsuch thatf(x^)≤f(x¯)(f(x^)<f(x¯),respectively). There are many notions of proper efficiency in the literature, as those introduced by Geoffrion, Benson, Borwein and Henig. Since P is convex, all these concepts are equivalent to the proper efficiency in terms of linear scalarization (see, e.g., Ehrgott, 2005), so that we recall only Geoffrion’s definition: a feasible pointx¯∈Xis said to be properly efficientif there exists ρ > 0 such that, for alli=1,…,pandx^∈Xsatisfyingfi(x^)<fi(x¯),there existsj∈{1,…,p}such thatfj(x^)>fj(x¯)andfi(x¯)−fi(x^)fj(x^)−fj(x¯)≤ρ.We denote by XpE, XE, and XwEthe sets of properly efficient points, efficient points, and weakly efficient points of P, respectively. Obviously, XpE⊂XE⊂XwE, withX=XwEwhenever one component of f is identically zero, andX=XpEin the trivial case that f is the null function. Moreover, it is known that f(XpE) is dense in f(XE) (Hartley, 1978; see also Ehrgott, 2005, Theorem 3.17).Given a (possibly non-convex) vector SIO problemP:``min""f(x)s.t.x∈X,x¯∈Xis said to be locally (properly, weakly) efficient solution of P if there exists a neighborhoodNofx¯such thatx¯is (properly, weakly) efficient solution ofPN:``min""f(x)s.t.x∈X∩N.Global and local concepts coincide in convex vector SIO thanks to the convexity of X and the componentwise convexity of f. For instance, ifx¯∈Xis not weakly efficient there existsx^∈Xsuch thatf(x^)<f(x¯);sincef(λx^+(1−λ)x¯)<f(x¯)for all λ ∈ ]0, 1[, withλx^+(1−λ)x¯∈X∩Nfor λ sufficiently small,x¯cannot be a locally weakly efficient solution of P. The argument is similar for efficient solutions while the equivalence can easily be proved for proper efficient solutions via scalarization. For this reason, in convex vector SIO, we can characterize the (proper, weak) efficiency on the basis of local information. The known tests for non-linear vector optimization classify a given x ∈ X as locally (properly, weakly) efficient solution or not through conditions involving subsets of the objective spaceRpor suitable scalarizations of P (see, e.g., Boţ, Grad, & Wanka, 2009; Ehrgott, 2005).In this paper, on convex vector SIO, we give conditions forx¯∈XpE,x¯∈XE,andx¯∈XwEwhich are expressed in terms of convex cones contained in the decision spaceRnor in terms of the existence of Karush–Kuhn–Tucker (KKT in short) multipliers which can be computed fromx¯and the data describing P.As a general rule, to obtain a checkable necessary optimality condition for a given constrained optimization problem, one needs to assume some property of the constraint system called constraint qualification (CQ in short). We consider in this paper four CQs which extend those used in our previous paper (Goberna, Guerra-Vazquez, & Todorov, 2013) on constraint qualifications in linear vector SIO. The strongest one is the natural extension of the CQ introduced by M. Slater in a seminal work on scalar optimization published in 1950, which was adapted to linear scalar SIO by Charnes, Cooper and Kortanek in the 1960s. A weaker CQ for convex scalar SIO has been proposed in Li, Zhao, and Hu (2013). The locally Farkas–Minkowski CQ was first defined in Puente and de Serio (1999) for linear scalar SIO, and then extended to convex scalar SIO in Goberna and López (1998) and to convex scalar IO in Dinh, Goberna, López, and Son (2007). CQs weaker than the locally Farkas–Minkowski one have been introduced in Li et al. (2013), for convex SIO problems, and in Li, Ng, and Pong (2008), for convex IO problems. The local Slater CQ, introduced in Section 3 of this paper, seems to be new while the extended Kuhn–Tucker CQ was introduced in Tapia and Trosset (1994) for convex IO as an extension of that used by H.W. Kuhn and A.W. Tucker in Kuhn, Tucker, and Newman (1951) for ordinary non-linear optimization problems. Section 1 of Li et al. (2008) reviews the state of the art on CQs in convex scalar optimization. Some of the previous works also deal with the so-called regularity (or closedness qualification) conditions involving the objective function and the constraints (see, e.g., the recent papers Sun, Li, and Zhao (2013) and Sun (2014), dealing with IO problems with DC objective function and convex constraints, and references therein).The stability of linear and non-linear scalar SIO has been investigated since the last 1980s from different perspectives, e.g., the pseudo-Lipschitz property and the lower and upper semicontinuity of the efficient set mapping under different types of perturbations, well-posedness, and generic stability (see, e.g., Chuong, Huy, & Yao, 2009, 2010a, 2010b; Fan, Cheng, & Wang, 2012; Todorov, 1996; Todorov & Tzeng, 1994), while the existing literature on optimality conditions for vector SIO and vector IO problems is surprisingly limited.The main antecedent of this paper is Goberna et al. (2013), on linear vector SIO, which provides characterizations of the weakly efficient, efficient and properly efficient solutions in terms of cones involving the data and KKT conditions. In Caristi, Ferrara, and Stefanescu (2010), on a class of vector SIO problems involving differentiable functions whose constraints satisfy certain invex-type conditions and are required to depend continuously on an index t ranging on some compact topological space T, KKT conditions forx¯∈XpE,x¯∈XEandx¯∈XwEare given. In Guerra-Vazquez, Rückmann, Xu, Teo, and Zhang (2014), on non-convex differentiable vector SIO, the authors discuss constraint qualifications as well as necessary and sufficient conditions for locally weakly efficient points and present optimality conditions for properly efficient points in the senses of Geoffrion and of Kuhn et al. (1951). Finally, in Chuong and Kim (2014), on non-smooth vector IO problems posed on Asplund spaces whose index set T has no topological structure, necessary conditions as well as sufficient conditions for weakly efficient solutions are obtained appealing to the machinery of non-smooth analysis and a certain CQ, for non-convex systems introduced in Chuong et al. (2009), which can be seen as an extension of the so-called basic CQs introduced in Li and Ng (2005), for scalar IO problems posed in Banach spaces.The convex vector SIO problems considered in this paper arise in a natural way in robust linear vector optimization. Indeed, consider an uncertain linear vector optimization problem(LP)``min""(c1⊤x,…,cp⊤x)s.t.at⊤x≥bt,t∈T,where T is a finite set,ci∈Ui⊂Rn,i=1,…,p,and(at,bt)∈Vt⊂Rn+1,t ∈ T. The uncertainty setsUi,i=1,…,pare arbitrary non-empty sets whileVt,t∈Tare non-empty compact sets. The robust minmax counterpart of (LP) (term coined in Ehrgott & Idec (2014)) enforces feasibility for any possible scenario and assumes that the cost of any (robust) feasible decision will be the worst possible, i.e., the problem to be solved is(2)``min""(maxc1∈U1c1⊤x,…,maxcp∈Upcp⊤x)s.t.at⊤x≥bt,∀(at,bt)∈Vt,t∈T.Observe that (2) is as (1), just takingfi(x)=maxci∈Uici⊤x(i.e., the support function ofUi),i=1,…,p,and expressing the constraints either asb−a⊤x≤0for all(a,b)∈⋃t∈TVt(a compact index set) or as gt(x) ≤ 0, withgt(x)=max{b−a⊤x:(a,b)∈⋃t∈TVt}for all t ∈ T (a finite index set equipped with the discrete topology).This paper is organized as follows. Section 2 recalls basic concepts of convex analysis to be used later, applying some of them to characterize the so-called subdifferential cone and its interior, and to describe the relationships between several types of “tangent” cones which are closely related with the negative polar of the active cone. Section 3 extends to convex vector SIO four out of six constraint qualifications introduced in Goberna et al. (2013) for linear vector SIO. The two exceptions, the Farkas–Minkowski and the local polyhedral constraint qualifications, have not been considered in this paper as they are too strong in the convex framework. For methodological reasons, we give simple direct proofs of the lemmas in Section 3 even though most of them could be also obtained via linearization. The auxiliary Section 4 establishes different characterizations of the sets XpE, XE, and XwEin terms of the subdifferential cone; these characterizations do not involve constraint qualifications, i.e., they are independent of the given representation of the closed convex feasible set X. Finally, Section 5 combines the results in Sections 3 and 4 to get characterizations of XpE, XE, and XwEin terms of KKT multipliers. Here the proofs are necessarily direct as the objective functions are not linear. These results are applied to the robust linear vector optimization problem (LP).We start this section by introducing the necessary notations and concepts. GivenZ⊂Rn,intZ, clZ, and bdZ denote the interior, the closure, and the boundary of Z, respectively. The scalar product ofx,y∈Rnis denoted by x⊤y, the Euclidean norm of x by ‖x‖, the corresponding open ball centered at x and radius ε > 0 by B(x, ε), and the zero vector by 0n. We also denote by conv Z the convex hull of Z, whileconeZ:=R+convZdenotes the convex conical hull of Z ∪ {0n}. If Z is a convex cone, its positive (negative) polar cone isZ+:={d∈Rn:z⊤d≥0∀z∈Z}(Z−:={d∈Rn:z⊤d≤0∀z∈Z},respectively). A convex cone is said to be pointed whenever it does not contain lines. We use frequently in this paper the topological interior of polar cones.We make three claims concerning cone Z, where Z is an arbitrary non-empty set ofRn:First,(3)0n∉convZ⇔{coneZispointedand0n∉Z}.We shall prove that 0n∈ conv Z if and only if cone Z contains lines or 0n∈ Z.If cone Z contains lines, there existsu∈Rn∖{0n}such that ± u ∈ cone Z. Then, we can writeu=∑i=1mαiziand−u=∑i=1mβizi,withα1,…,αm,β1,…,βm∈R+,zi∈ Z,i=1,…,m,m∈N,so that0n=(∑i=1m(αi+βi))−1∑i=1m(αi+βi)zi∈convZ.Alternatively, if 0n∈ Z, it is obvious that 0n∈ conv Z.Conversely, if 0n∈ conv Z, there existαi∈R+and zi∈ Z,i=1,…,n,such that∑i=1nαi=1and∑i=1nαizi=0n.Letj∈{1,…,n}be such that αj> 0. If zj≠ 0n, putting α ≔ ∑i ≠ jαi> 0, it follows thatu:=−αjαzj=∑i≠jαiαzi∈coneZ,so that cone Z contains the line spanned by u. Now, suppose thatzj=0n.Then(4)∑i≠jαizi=0n.Ifαi=0for all i ≠ j, then0n=zj∈Z.Otherwise, there exists k ≠ j such that αk> 0, in (4), and we repeat the argument above.Second,(5)0n∉Z⇒int(coneZ)+⊂{d∈Rn:z⊤d>0∀z∈Z}.In fact, assume that 0n∉ Z andd∈int(coneZ)+.Let ε > 0 be such thatclB(d,ɛ)⊂(coneZ)+.Given z ∈ Z,d−ɛz∥z∥∈(coneZ)+while z ∈ cone Z, so thatz⊤(d−ɛz∥z∥)=z⊤d−ɛ∥z∥≥0and so z⊤d ≥ ε‖z‖ > 0. Obviously, ifZ∩(−Z)≠∅,then both members of the inclusion in (5 ) are empty.Third,(6)Zcompact⇒{d∈Rn:z⊤d>0∀z∈Z}⊂int(coneZ)+.In fact, by assumption, there exists δ > 0 such that ‖z‖ ≤ δ for all z ∈ Z. Letd∈Rnbe such that z⊤d > 0 for all z ∈ Z. By the compactness of Z, ε ≔ minz ∈ Zz⊤d > 0. Given x ∈ coneZ, we can writex=∑i=1nμizi,with μi≥ 0 and zi∈ Z,i=1,…,n.Then, given u such that ‖u‖ ≤ 1, one hasx⊤(d+ɛδu)=∑i=1nμizi⊤(d+ɛδu)≥∑i=1nμi(ɛ−ɛδ|z⊤u|)≥0.Thus,B(d,ɛδ)⊂(coneZ)+andd∈int(coneZ)+.The inclusion in (6) becomes an equation between non-empty sets whenever Z is compact and 0n∉ conv Z (as coneZ turns out to be a pointed cone).The one-sided directional derivativeof a real-valued functionh:Rn→Ratx¯∈Rnwith respect to a vectord∈Rnis defined to be the limith′(x¯;d)=limɛ↓0h(x¯+ɛd)−h(x¯)ɛ,if it exists. If h is convex, then it is continuous, the directional derivative function atx¯∈Rn,h′(x¯;.),is a finite convex function too, and thesubdifferential∂h(x¯):={ξ∈Rn:h(x)≥h(x¯)+ξ⊤(x−x¯)∀x∈Rn},is a non-empty compact convex such that(7)h′(x¯;d)=maxξ∈∂h(x¯)ξ⊤d(see, e.g., Rockafellar 1970, Theorems 23.1 and 23.4). From (7) one gets easily(8)[cone∂h(x¯)]−={d∈Rn:h(x¯;d)≤0}.On the other hand, if d is a descent direction of h atx¯there exists β > 0 such that(9)h(x¯+ɛd)−h(x¯)<0forallɛ∈]0,β[and, so,(10)maxξ∈∂h(x¯)ξ⊤d=h′(x¯;d)=limɛ↓0h(x¯+ɛd)−h(x¯)ɛ≤0,with 0n∉∂h(x¯)and∂h(x¯)compact. Then,h′(x¯;d)<0(otherwise, by (10), there existsξ˜∈∂h(x¯),ξ˜≠0nsuch thatξ˜⊤d=0andh(x¯+ɛd)−h(x¯)≥ɛξ˜⊤d=0for all ε > 0, in contradiction with (9)).It is easy to prove that, under the assumptions on P,(11)X={x∈Rn:ξ⊤x≤ξ⊤y−gt(y),∀(t,y)∈T×Rn,∀ξ∈∂gt(y)}.From (11) and Goberna and López (1998, Theorem 9.3) one gets that X is compact if and only ifcone(⋃(t,y)∈T×Rn∂gt(y))=Rn.This condition (expressed in terms of the data) guarantees the compactness of f(X). More information on X can be obtained from the linearization (11) of X under the constraint qualifications introduced in Section 3.Two convex cones involving the data of the vector SIO problem P in (1) are basic in our approach: the convex conical hull of the subdifferentials atx¯∈Xof the components of f,G(x¯):=cone(⋃i=1p∂fi(x¯)),that we shall call subdifferential cone atx¯,and the active cone atx¯∈X,A(x¯):=cone(⋃t∈T(x¯)∂gt(x¯)),whereT(x¯):={t∈T:gt(x¯)=0}is the set of active indices atx¯.We are interested in the negative polar of both cones,G(x¯)−andA(x¯)−,and their corresponding interiors,intG(x¯)−andintA(x¯)−.Lemma 1Givenx¯∈X,the following statements hold:(i)0n∉conv(⋃i=1p∂fi(x¯))if and only ifG(x¯)is pointed and0n∉⋃i=1p∂fi(x¯).G(x¯)−={d∈Rn:fi′(x¯;d)≤0,i=1,…,p}.If0n∉⋃i=1p∂fi(x¯),then(12)intG(x¯)−={d∈Rn:ξ⊤d<0∀ξ∈⋃i=1p∂fi(x¯)}={d∈Rn:fi′(x¯;d)<0,i=1,…,p},withintG(x¯)−≠∅whenever0n∉conv(⋃i=1p∂fi(x¯)).(i)It is straightforward consequence of (3), just takingZ=⋃i=1p∂fi(x¯).From (8),[cone∂fi(x¯)]−={d∈Rn:fi′(x¯;d)≤0},i=1,…,p.Hence,(13)G(x¯)−=(∑i=1pcone∂fi(x¯))−=⋂i=ip(cone∂fi(x¯))−={d∈Rn:fi′(x¯;d)≤0,i=1,…,p}.Again by the identityfi′(x¯;d)=maxξ∈∂fi(x¯)ξ⊤d,one has that ξ⊤d < 0 for allξ∈∂fi(x¯)if and only iffi′(x¯;d)<0,i=1,…,p.Assuming that0n∉⋃i=1p∂fi(x¯),from (5) and (6), one gets (12). The additional condition that0n∉conv(⋃i=1p∂fi(x¯))guarantees, by (i), thatG(x¯)is pointed, which in turn implies thatintG(x¯)−≠∅.□The KKT conditions will be obtained by analyzing the relationships between negative polar of the active coneA(x¯)and four “tangent” cones atx¯defined as follows.The cone of feasible directions atx¯isD(X;x¯)={d∈Rn:∃μ>0suchthatx¯+μd∈X}.It is known thatD(X;x¯)⊂A(x¯)−(Goberna & López, 1998, Lemma 7.7).The attainable cone atx¯,denoted byA(X;x¯),is formed by thosed∈Rnsuch that there exist τ > 0 and a vector functionh∈C1([0,τ[,Rn)withh(0)=x¯,h′(0)=d,and h(s) ∈ X for all s ∈ [0, τ[.The Bouligand tangent cone atx¯,denoted byT(X;x¯),is formed by thosed∈Rnsuch that there exist sequences{sk}k∈Nand{dk}k∈Nsuch that sk↓0, dk→ d as k → ∞ andx¯+skdk∈Xfor allk∈N.In that case, sincedk∈D(X;x¯)for allk∈N,d∈clD(X;x¯).The interior tangent coneatx¯,denoted byTi(X;x¯),is formed by thosed∈Rnsuch that there exist τ > 0 and a neighborhoodNof d such thatx¯+sN⊂Xfor all s ∈ ]0, τ[.Lemma 2Boţ et al., 2009; Hantoute & López, 2008; Laurent, 1972; Peterson, 1973; Rockafellar, 1970; Zălinescu, 2002Givenx¯∈X,the cones Ti(Z; x), D(Z; x), A(Z; x), and T(Z; x) are all convex and satisfy(14)Ti(X;x¯)=intD(X;x¯)⊂D(X;x¯)⊂A(X;x¯)=T(X;x¯)=clD(X;x¯).Consider the closed convex setX={(x1,x2)∈R2:t(x1−2)2−t−x2≤0∀t∈[0,1]}and the pointx¯=(1,0)∈X.Sinceφ(x)={−x2,1≤x1≤3,x12−4x1+3−x2,otherwise,one hasX={x∈R2:φ(x)≤0}={x∈R2:x2≥max{x12−4x1+3,0}},so thatD(X;x¯)={d∈R2:2d1+d2>0,d2≥0}∪{02},A(X;x¯)=T(X;x¯)={d∈R2:2d1+d2≥0,d2≥0}=clD(X;x¯),andTi(X;x¯)={d∈R2:2d1+d2>0,d2>0}=intD(X;x¯).Hence, the inclusions in (14) are strict. Observe thatA(x¯)=cone{(−2t,−1):t∈[0,1]}=cone{(0,−1),(−2,−1)}is the negative polar of any of the cones considered in Lemma 2.Givenx¯∈X,A(x¯)−={d∈Rn:φ′(x¯;d)≤0}andintA(x¯)−={d∈Rn:φ′(x¯;d)<0}One has(15)φ′(x¯;d)=maxt∈T(x¯)maxξ∈∂gt(x¯)ξ⊤d=max{ξ⊤d:ξ∈⋃t∈T(x¯)∂gt(x¯)}.From (15), we haveφ′(x¯;d)≤0if and only if ξ⊤d ≤ 0 for allξ∈⋃t∈T(x¯)∂gt(x¯)if and only ifd∈A(x¯)−.Similarly, by the compactness of⋃t∈T(x¯)∂gt(x¯),φ′(x¯;d)<0if and only if ξ⊤d < 0 for allξ∈⋃t∈T(x¯)∂gt(x¯)if and only ifd∈intA(x¯)−.□Next we introduce four constraint qualifications which are frequently encountered in the SIO literature or are inspired in classical constraint qualifications of non-linear optimization. When the constraint functions are affine, these constraint qualifications collapse to those introduced, under similar names, in Goberna et al. (2013) (for linear vector SIO). Even more, the below CQ hold for the convex system {gt(x) ≤ 0, t ∈ T} if and only if the corresponding linear versions hold for the linear system in (11).Definition 5We say that P satisfies the Slater constraint qualification (SCQ) if there is a Slater pointx0, i.e. gt(x0) < 0, for all t ∈ T.In other words, SCQ holds if and only if the marginal function φ takes a negative value at some point (observe that the marginal function of the linear system in (11) is also φ). By continuity of φ, SCQ implies that intX ≠ ∅, but the converse is not true. It is worth noting that, in contrast with the other three CQs to be introduced next, SCQ is not associated with a given feasible solution.Definition 6We say that the locally Farkas–Minkowski constraint qualification (LFMCQ) holds atx¯∈XifA(x¯)=D(X;x¯)−.Obviously, if LFMCQ holds atx¯∈X,thenA(x¯)is closed. Ifx¯∈intX, thenA(x¯)=D(X;x¯)−={0n}.Therefore the LFMCQ should be investigated only at the boundary feasible points. Moreover, if this property holds andx¯∈bdX, we haveA(x¯)≠{0n},i.e. there are binding constraints atx¯.Lemma 7Goberna & López 1998, Theorem 7.9SCQ implies LFMCQ at any feasible solution.Consequently, if P satisfies SCQ, then bdX={x∈X:A(x)≠{0n}}.Moreover, geometric information on X in terms of the data can be obtained by combining (11) and Goberna & López (1998, Theorem 5.9).Definition 8We say that P satisfies the local Slater constraint qualification (LSCQ) atx¯∈Xwhen eitherT(x¯)=∅or there exists a vectord∈Rnsatisfying(16)d⊤ξ<0forallξ∈⋃t∈T(x¯)∂gt(x¯).LSCQ holds atx¯∈Xif and only ifT(x¯)≠∅⇒0n∉conv(⋃t∈T(x¯)∂gt(x¯)).We can assume thatT(x¯)≠∅.The direct statement is obvious while the converse statement is consequence of the assumptions on P. In fact, the continuity oft↦gt(x¯)on the compact set T entails thatT(x¯)is a compact set, as well as⋃t∈T(x¯)∂gt(x¯)(see e.g. Hiriart-Urruty & Lemarechal, 1993, Theorem 4.4.2). Due to the compactness ofconv(⋃t∈T(x¯)∂gt(x¯))and the separation theorem, the condition0n∉conv(⋃t∈T(x¯)∂gt(x¯))guarantees the fulfilment of LSCQ atx¯.□If P satisfies LSCQ atx¯∈X,thenA(x¯)is a pointed closed cone.We can assumeT(x¯)≠∅(otherwiseA(x¯)={0n}is closed). By Proposition 9, sinceconv(⋃t∈T(x¯)∂gt(x¯))is a compact convex set which does not contain the origin,A(x¯)=cone(⋃t∈T(x¯)∂gt(x¯))is a pointed closed cone.□The following example shows that the converse statement of Corollary 10 does not hold.Example 11Letn=2andgt(x)=(1−t)|x1−1|+|x2|−1+tfor allT=[0,1].Then it is easy to see thatX={x∈R2:gt(x)≤0,t=0,1}=[0,2]×{0}.We haveT(02)=[0,1],with∂gt(02)=conv{(t−1,−1),(t−1,1)}={t−1}×[−1,1],t∈[0,1].Thus,⋃t∈T(02)∂gt(02)=[−1,0]×[−1,1]andA(02)=cone(⋃t∈T(02)∂gt(02))=R−×Ris closed. Finally, as ± (0, 1) ∈ ∂g0(02), LSCQ fails at 02.We say that P satisfies the extended Kuhn–Tucker CQ (EKTCQ) atx¯∈Xwhen(17){d∈Rn:φ′(x¯;d)≤0}⊂A(X;x¯).As a consequence of the Ioffe and Tihkomirov’s theorem on the subdifferential of the supremum function (see e.g. Zălinescu, 2002, Theorem 2.4.18; Hantoute & López, 2008, Proposition 6.3), whenx¯∈bdX,it holds that(18)φ′(x¯;d)=maxt∈T(x¯)gt′(x¯;d).The next lemma provides a useful approximations of the tangent cones to X atx¯∈bdXin terms of the directional derivative functionφ′(x¯;·).Lemma 13Letx¯∈bdX. Then,{d∈Rn:φ′(x¯,d)<0}⊂Ti(X;x¯)⊂T(X;x¯)⊂{d∈Rn:φ′(x¯,d)≤0}.We first show that{d∈Rn:φ′(x¯,d)<0}⊂Ti(X;x¯).Letd¯∈Rnbe such thatφ′(x¯,d¯)<0.Then, there exists τ > 0 such thatφ(x¯+sd¯)<0for all s ∈ ]0, τ[. By continuity of φ, there exist t0 > 0 and an open neighborhoodNofd¯such thatφ(x¯+td)<0for all t ∈ ]0, t0[ and alld∈N.That is,d¯∈Ti({x∈Rn:φ(x)<0},x¯)⊂Ti({x∈Rn:φ(x)≤0},x¯)=Ti(X;x¯).The inclusionTi(X;x¯)⊂T(X;x¯)is well-known (see, e.g. Stein, 2001).Finally, considerd¯∈T(X;x¯).Then, there exist sequences{sk}k∈Nand{dk}k∈Nsuch that sk↓0,dk→d¯as k → ∞ andφ(x¯+skdk)≤0for allk∈N.Sinceφ(x¯)=0,one hasφ(x¯+skdk)sk=φ(x¯+skdk)−φ(x¯)sk≤0∀k∈N.Now, taking limits as k → ∞, we conclude thatφ(x¯+skdk)sk→φ′(x¯;d¯)≤0.□The following statements are true:(i)SCQ implies LSCQ at anyx¯∈X.If LSCQ holds atx¯∈XandT(x¯)is a set of isolated points of T, then SCQ holds.If LSCQ holds atx¯∈X,then LFMCQ holds atx¯.If LSCQ holds atx¯∈X,then EKTCQ holds atx¯.(i)Let x0 be a Slater point andx¯∈X.Letd:=x0−x¯andξ∈∂gt(x¯)for somet∈T(x¯).Since0>gt(x0)≥gt(x¯)+ξ⊤(x0−x¯)=d⊤ξ,d satisfies (16).We shall prove that, under the assumption (equivalent to assert thatT(x¯)is finite andT∖T(x¯)is compact), there exists a Slater point in the half-line emanating fromx¯in some direction d satisfying (16). In fact, givent∈T(x¯),asgt′(x¯;d)=maxξ∈∂gt(x¯)ξ⊤d<0,there exists εt> 0 withgt(x¯+λd)<0for any λ ∈ ]0, εt[. On the other hand, by continuity of the functionmaxt∈T∖T(x¯)gt,there exists a neighborhoodNofx¯wheremaxt∈T∖T(x¯)gtis negative. Taking a sufficiently small λ0 > 0, we getgt(x¯+λ0d)<0for allt∈T(x¯)andx¯+λ0d∈N.So,x¯+λ0dis a Slater point.By a well-known result (see, e.g., Martínez-Legaz, Todorov, & Zetina, 2014, Proposition 5), ifφ′(x¯;d)<0,thend∈D(X;x¯).This, combined with Lemma 4, yields(19)intA(x¯)−⊂D(X;x¯),whereintA(x¯)−≠∅by Corollary 10, as the negative polar of a pointed closed convex cone contains interior points. Taking negative polars in both members of (19) one gets, by the Farkas lemma for cones,D(X;x¯)−⊂(intA(x¯)−)−=(A(x¯)−)−=clA(x¯)=A(x¯).We now prove the reverse inclusion by contradiction. Suppose that there exists ξ ∈A(x¯)∖D(X;x¯)−.Then there existsd∈D(X;x¯)such that ξ⊤d > 0, withξ=∑i=1mξi,ξi∈∂gti(x¯),ti∈T(x¯),i=1,…,m.Leti0∈{1,…,m}such thatξi0⊤d>0.This means that for any ε > 0, we havegti0(x¯+ɛd)=gti0(x¯+ɛd)−gti0(x¯)≥ɛξi0⊤d>0,so thatd∉D(X;x¯)(contradiction). Thus,A(x¯)=D(X;x¯)−.Letx¯∈intX.Ifx¯∈intX,thenA(X;x¯)=Rnand (17) holds trivially. Thus we can assume without loss of generality (w.l.o.g. in short) thatx¯∈bdX.Letd∈Rnsatisfy (16). By (18), we have, from (15),φ′(x¯;d)=max{ξ⊤d:ξ∈⋃t∈T(x¯)∂gt(x¯)}<0.Since{d∈Rn:φ′(x¯;d)<0}≠∅andφ′(x¯;·)is a finite-valued convex function (Rockafellar, 1970, Theorem 23.4), we getcl{d∈Rn:φ′(x¯;d)<0}={d∈Rn:φ′(x¯;d)≤0}.Then, by Lemmas 13 and 2,{d∈Rn:φ′(x¯;d)≤0}=T(X;x¯)=A(X;x¯),and so EKTCQ holds atx¯.□Observe that the assumptions onT(x¯)andT∖T(x¯)in Theorem 14(ii) are not superfluous (see Goberna et al., 2013, Example 4) and imply the non-connectedness of T. In the particular case that T is finite, SCQ and LSCQ are equivalent. Notice also that Lemma 7 follows straighforwardly from statements (i) and (iii) of Theorem 14.The next example shows that LFMCQ does not imply LSCQ (consequently does not imply SCQ).Example 15Letn=2andgt(x)=∥x∥−tfor allt∈T=[0,1].It follows thatX={02}andT(02)={0}.We haveD(X,02)+=R2,∂g0(02)=clB(02,1),A(x¯)=cone∂g0(02)=R2=D(X,02)−but (16) fails. So, LFMCQ holds at 02 while LSCQ fails.Consider the linear vector SIO problemP:``min""f(x)=(x1−x2,−x2)s.t.tx1+(1−(t−1)2)x2≤0,t∈[0,2],whose feasible set isX=R−2.It follows that EKTCQ holds at 02 (see Goberna et al., 2013, Example 25) andA(02)=(R++×R+)∪{02}is non-closed. Thus, EKTCQ does not imply LFMCQ.The following example shows that the converse statement of Theorem 14(iv) does not hold.Example 17Consider Example 11, for which LSCQ is not fulfilled at 02. We haveφ′(02;d)≤0⇔gt′(02,d)≤0∀t∈[0,1]⇔(t−1)d1+d2≤0and(t−1)d1−d2≤0∀t∈[0,1]⇔d1≥0,d2=0.Letd∈R2be such that φ′(02; d) ≤ 0. Then the vector functionh(s):=(sd1,sd2)=(sd1,0)∈Xfor alls∈[0,2/d1],satisfiesh(0)=02andh′(0)=d.That is, d ∈ A(X; 02). So, EKTCQ holds at 02.Letx¯∈bdX. Then, P satisfies EKTCQ atx¯if and only if(20)T(X;x¯)={d∈Rn:φ′(x¯,d)≤0}.Assume that P satisfies EKTCQ atx¯,i.e.,(21){d∈Rn:φ′(x¯,d)≤0}⊂A(X;x¯)=T(X;x¯).By (21) and Lemma 13, (20) holds. The converse statement is trivial.□The four constraint qualifications introduced above fail in the next example.Example 19Consider the following set:X={x∈R2:gt(x1,x2)=tx12−t(1−t)+(1−t)(x22+x2)≤0,t∈[0,1]}.Sinceg0(x1,x2)=x22+x2≤0⇒x2∈[−1,0]andg1(x1,x2)=x12≤0⇒x1=0,one getsX={0}×[−1,0].AsT(02)={0,1},02∈⋃t∈T(02)∂gt(02)={(0,0),(0,1)}and so LSCQ fails at 02. We also haveA(02)=cone{(0,1)}andD(X,02)=cone{(0,−1)},so thatA(02)⊊−D(X,02)+,which implies the failure of LFMCQ. Sinceg0′(02;d)=d2andg1′(02;d)=0,{d∈R2:φ′(02;d)≤0}=R×R−.On the other handA(X;02)={0}×R−.So, EKTCQ fails to hold at 02.It is well-known (see, e.g. Ehrgott, 2005, Theorem 3.21 and Corollary 3.23) that, if T is finite, fi,i=1,…,pand gt, t ∈ T, are convex differentiable functions,x¯∈X,and0n∉conv{∇f1(x¯),…,∇fp(x¯)},thenx¯is a weakly efficient solution of the (ordinary) convex vector optimization problem P if and only if there existtj∈T(x¯),j=1,…,q,as well as non-negative scalarsλ1,…,λp,μ1,…,μqsatisfying(22)∑i=1pλi∇fi(x¯)=∑j=1qμj∇gtj(x¯)≠0n.In geometric terms, the KKT condition (22) asserts thatG(x¯)∩A(x¯)≠{0n}(it is sufficient to take q ≤ n by Carathéodory’s theorem applied to the convex coneA(x¯)). In this section we give similar conditions for convex vector SIO problems and different types of efficiency.The characterizations of efficient and weakly efficient solutions in this section extend similar results on linear vector SIO in Goberna et al. (2013) to convex vector SIO. We start with two sufficient conditions forx¯∈Xto be efficient and weakly efficient solution independently of the constraints under assumptions which already appeared in Lemma 1.Proposition 20Ifx¯∈X,then the following statements are true:(i)If0n∈conv(⋃i=1p∂fi(x¯)),thenx¯∈XwE.if0n∈⋃i=1p∂fi(x¯)and the components of f are strictly convex, thenx¯∈XE.(i)Let0n=∑i=1pαiξi,with αi≥ 0 andξi∈∂fi(x¯),i=1,…,p,and∑i=1pαi=1.Let αj> 0,j∈{1,…,p}.Then,ξj=−∑i≠jαiαjξi.We can assume w.l.o.g. the existence of i ≠ j such that αi> 0 (otherwise,ξj=0nandx¯∈XwEbecause it is a minimizer of fjonRn,and so on X). If we suppose that there existsx^∈Xsuch thatf(x^)<f(x¯),for everyi=1,…,pandξi∈∂fi(x¯),then0>fi(x^)−fi(x¯)≥ξi⊤(x^−x¯).Thus,0>ξj⊤(x^−x¯)=−∑i≠jαiαjξi⊤(x^−x¯)>0,which is a contradiction wherebyx¯∈XwE.If0n∈⋃i=1p∂fi(x¯)and all the objective functions are strictly convex, thenx¯is the unique minimizer of at least one of the objective functions onRn(and so on X). Then, there is nox^∈Xsuch thatf(x^)≤f(x¯),i.e.,x¯∈XE.□We have stated and proved here Proposition 20(i) in order to motivate the assumption of Proposition 26. A stronger result can be shown easily via scalarization (see the forthcoming Theorem 25(ii)).Theorem 21Givenx¯∈X,the following statements hold:(i)IfD(X;x¯)∩G(x¯)−⊂{d∈Rn:fi′(x¯;d)=0,i=1,…,p},thenx¯∈XE.If0n∉⋃i=1p∂fi(x¯),thenx¯∈XwEif and only ifD(X;x¯)∩intG(x¯)−=∅.(i)DenoteF(x¯):={d∈Rn:fi′(x¯;d)=0,i=1,…,p}.Suppose thatx¯∉XE.Then, there existd∈D(X;x¯),i0∈{1,…,p},and β > 0 such that(23)fi(x¯+ɛd)≤fi(x¯),i=1,…,p,with(24)fi0(x¯+ɛd)<fi0(x¯)for all ε ∈ ]0, β[. From (23) it follows thatfi′(x¯;d)≤0,i=1,…,p.Thus, again by Lemma 1(ii),d∈D(X;x¯)∩G(x¯)−.But, from (24) we getɛξi0⊤d≤fi0(x¯+ɛd)−fi0(x¯)<0for allξi0∈∂fi0(x¯).That is,fi0′(x¯;d)=maxξi0∈∂fi0(x¯)ξi0⊤d<0,so thatd∉F(x¯).If0n∈conv(⋃i=1p∂fi(x¯)),thenx¯∈XwEby Proposition 20. So, we can assume that0n∉conv(⋃i=1p∂fi(x¯)),in which case0n∉⋃i=1p∂fi(x¯).Letd∈D(X;x¯)∩intG(x¯)−.Then, again by Lemma 1(iii),fi′(x¯;d)<0,i=1,…,p.That is, d is a feasible descent direction for fiatx¯,i=1,…,p.So,x¯∉XwE.Now, suppose thatx¯∉XwE,i.e. there exists x ∈ X such thatfi(x)<fi(x¯),i=1,…,p.Letd=x−x¯∈D(X;x¯).Since d is a feasible descent direction for each fiatx¯,we havefi′(x¯;d)=maxξi∈∂fi(x¯)ξi⊤d<0.Thus, d ∈intG(x¯)−by Lemma 1(iii). Thus,D(X;x¯)∩intG(x¯)−≠∅,which completes the proof.□The following example shows thatx¯can be an efficient solution and there existsd∈D(X;x¯)∩G(x¯)−such thatd∉F(x¯).Example 22Letn=2,p=2,f1(x)=(x1−1)2+(x2+1)2,f2(x)=x12−2x1+x22,andgt(x)=t2|x1|−x2for all t ∈ [0, 1]. We have thatX={x∈R2:gt(x)≤0,t∈[0,1]}={x∈R2:|x1|−x2≤0},02 ∈ XE,d=(1,1)∈D(X;02),f1′(02;d)=∇f1(02)⊤d=0andf2′(02;d)=∇f2(02)⊤d=−2.So, d ∈ D(X; 02) ∩G(02)−,but d ∉ F(02).The following example shows that the assumption0n∉⋃i=1p∂fi(x¯)in Theorem 21(ii) is not superfluous.Example 23Letn=2,p=2,f1(x)=x12+x22,f2(x)=x12−2x1+x22,andgt(x)=tx12−x2+t−1for all t ∈ [0, 1]. As gtgrows with t,X={x∈R2:gt(x)≤0,t∈[0,1]}={x∈R2:x2≥x12}.Since f1 and f2 are strictly convex and02=∇f1(02)∈⋃i=1,2∂fi(02),we have 02 ∈ XwE. Since∇f1(02)=02,it follows that∇f1(02)⊤d=0for alld∈R2.ThusG(02)−=R2∩{d∈R2:∇f2(02)⊤d≤0}.Now, taked=(1,1)∈D(X;02).We havef2′(02;d)=∇f2(02)⊤d=−2.Then D(X; 02) ∩ intG(02)−≠∅.Givenx¯∈X,x¯∈XwEif and only if(25){d∈Rn:fi′(x¯;d)<0,i=1,…,p}∩D(X;x¯)=∅.If0n∈⋃i=1p∂fi(x¯;d),thenx¯∈XwEby Proposition 20 and there existsi∈{1,…,p}such thatfi′(x¯;d)≥0,so that (25) holds too. Otherwise, both statements are equivalent by Theorem 21(ii) and Lemma 1(iii).□The next lemma reformulates well-known characterizations of XpEand XwEin terms of scalarizations of P and the cone of feasible directions. For the sake of brevity, givenλ=(λ1,…,λp)∈Rp,we denote∑i=1pλifiin matrix form as λ⊤f.Lemma 25Givenx¯∈X,the following statements hold:(i)x¯∈XpEif and only if∂(λ⊤f)(x¯)∩D(X;x¯)+≠∅for some λ > 0p.x¯∈XwEif and only if∂(λ⊤f)(x¯)∩D(X;x¯)+≠∅for some λ ≥ 0p.We associate with P the parameterized (weighted) problem(26)P(λ):min(λ⊤f)(x)=∑i=1pλifi(x)s.t.x∈X,where λ ≥ 0pis the weight vector and P(λ) is a convex SIO problem for each λ (we could aggregate∑i=1pλi=1). By Theorem 27.4 of Rockafellar (1970) it follows thatx¯is an optimal solution of P(λ) for some λ ≥ 0pif and only if there existsξ∈∂(λ⊤f)(x¯)∩D(X;x¯)+.(i)According to the Geoffrion Theorem (Geoffrion, 1968; see also Ehrgott, 2005, Theorem 3.15),x¯is an optimal solution of P(λ) for some λ > 0pif and only ifx¯∈XpE.Similarly, by Ehrgott (2005, Proposition 3.10),x¯is an optimal solution of P(λ) for some λ ≥ 0pif and only ifx¯∈XwE.□Observe that, givenx¯∈X,0n∈conv(⋃i=1p∂fi(x¯))entails that XwE. We consider now the case where0n∉conv(⋃i=1p∂fi(x¯)).Proposition 26Letx¯∈Xbe such that0n∉conv(⋃i=1p∂fi(x¯)).Thenx¯∈XwEif and only ifG(x¯)∩D(X,x¯)+≠{0n},in which casex¯∈bdX.Let0n∉conv(⋃i=1p∂fi(x¯)).Then,G(x¯)∩D(X,x¯)+≠{0n}if and only if there exist λ ≥ 0p,ξi∈∂fi(x¯),i=1,…,psuch that∑i=1pλiξi∈D(X;x¯)+if and only if∑i=1pλi∂fi(x¯)∩D(X;x¯)+=∂(λ⊤f(x¯))∩D(X;x¯)+≠{0n}for some λ ≥ 0p. The first statement follows from Lemma 25(ii).Finally, ifx¯∈intX,thenD(X;x¯)+={0n},so thatG(x¯)∩D(X,x¯)+={0n}.Hencex¯∉XwEby the first statement.□We are in a position to obtain KKT optimality conditions.Theorem 27Givenx¯∈X,the following statements hold:(i)If there exists λ ≥ 0p(λ > 0p) satisfying(KKT)∂(λ⊤f)(x¯)∩(−A(x¯))≠∅,thenx¯∈XwE(x¯∈XpE,respectively).Ifx¯∈XwE(x¯∈XpE) satisfies LFMCQ, then there exist λ ≥ 0p(λ > 0p, respectively) such that KKT holds. If, additionally,0n∉conv(⋃i=1p∂fi(x¯)),then the following stronger condition holds:∂(λ⊤f)(x¯)∩(−A(x¯))≠{0n}.(i)Recall thatD(X;x¯)⊂A(x¯)−.Taking positive polars we getD(X;x¯)+⊃−A(x¯)++=−clA(x¯)⊃−A(x¯),so that KKT implies that∂(λ⊤f)(x¯)∩D(X;x¯)+≠∅.The conclusion follows from Lemma 25.We are assuming thatA(x¯)=D(X;x¯)−=−D(X;x¯)+.The first part is straightforward consequence of Lemma 25 while the second one follows from the argument of Proposition 26.□Ifx¯∈XwE,then(27){d∈Rn:fi′(x¯;d)<0,i=1,…,p}∩T(X;x¯)=∅.Assume the contrary, that is, there existsd¯∈T(X;x¯)satisfying(28)fi′(x¯;d¯)<0,i=1,…,p.Byd¯∈T(X;x¯),there exist sequences{sk}k∈Nand{dk}k∈Nsuch that sk↓0,dk→d¯andx¯+skdk∈Xfor allk∈N.Sincex¯∈XwEthere exists (perhaps after passing to a subsequence) an indexi0∈{1,…,p}such thatfi0(x¯+skdk)≥fi0(x¯),k∈N.Sincefi0is directional differentiable atx¯in the Hadamard sense (see e.g. Bonnans & Shapiro, 2000, Proposition 2.126(v)(c)), the latter inequalities providefi0′(x¯;d¯)=limk→∞fi0(x¯+skdk)−fi0(x¯)sk≥0which contradicts (28).□Observe that, sinceD(X;x¯)⊂T(X;x¯),the direct part of Corollary 24 is immediate consequence of Lemma 28.We have shown in Theorem 27 that KKT is a necessary condition for weak efficiency under LFMCQ (and, by Lemma 7, also under SCQ). Finally, we prove that this necessary condition still holds under the remaining two CQ introduced in Section 3, namely, LSCQ and EKTCQ, together with the closedness of the active cone recall that LSCQ entails the latter property according to Corollary 10).Theorem 29Let0n∉conv(⋃i=1p∂fi(x¯))andx¯∈XwEsatisfying one of the following conditions:(i)LSCQ;EKTCQ andA(x¯)is closed.Then, there exists λ ≥ 0psatisfying KKT.Sincex¯∈XwEand0n∉conv(⋃i=1p∂fi(x¯)),x¯∈bdXand(29){d∈Rn:∑i=1pλifi′(x¯;d)<0,forallλ≥0p}∩T(X;x¯)=∅by Proposition 26 and Lemma 28, respectively. Combining the formulas (18) and (29) with Theorem 14(iv) and Lemma 18, we conclude that there is nod∈Rnsuch that(30)∑i=1pλifi′(x¯;d)<0forallλ≥0pand(31)gt′(x¯;d)≤0forallt∈T(x¯).(i) Assume that LSCQ is satisfied atx¯.Now, (30) and (31) are equivalent to: there is nod∈Rnsuch that(32)ξ⊤d<0forallξ∈∂(λ⊤f)(x¯)forallλ≥0p.and(33)ξ⊤d≤0forallξ∈∂gt(x¯)forallt∈T(x¯)Since the homogeneous linear system formed by (33) and (32) is inconsistent,∂(λ⊤f)(x¯)is a compact convex set andA(x¯):=cone(⋃t∈T(x¯)∂gt(x¯))is closed (by Corollary 10), so that the Minkowski sum of both sets is closed, we can apply Motzkin’s theorem (Goberna & López, 1998, Theorem 3.5) to conclude that0n∈∂(λ⊤f)(x¯)+A(x¯).(ii) The proof is the same, taking into account that nowA(x¯)is closed by assumption.□Example 16 shows that the closedness assumption in Theorem 29(ii) is not superfluous. Indeed, the unique solution of the system formed by the non-linear equationsλ1(1−1)+λ2(0−1)=∑i=12μi(−ti−1−(ti−1)2),t1,t2∈[0,2],and the inequalities(34)λi≥0,μi≥0,i=1,2,isλ1=λ2=μ1=μ2=0.Thus, KKTfails.Example 30Consider the robust counterpart problem in (2) withUi=B(c¯i,ɛ)⊂Rn,i=1,…,p.Then,fi(x)=maxci∈Uici⊤x=c¯i⊤x+ɛ∥x∥,with∂fi(x)={{c¯i+ɛx∥x∥},ifx≠0n,B(c¯i,ɛ),ifx=0n.LetX={x∈Rn:pk⊤x≥qk,k∈K}be the feasible set of (2) and letx¯∈X.According to Theorem 14, Proposition 20, and Theorems 27 and 29, the following statements hold:(i)If0n∈conv(⋃i=1p∂fi(x¯)),thenx¯is a minmax robust weakly efficient solution.Assume that0n∉conv(⋃i=1p∂fi(x¯))and either LSCQ or EKTCQ holds atx¯≠0n.Then,x¯is a weakly efficient solution of (2) if and only if there exists λ ≥ 0msuch that−∑i=1pλi(c¯i+ɛx¯∥x¯∥)∈A(x¯).

@&#CONCLUSIONS@&#
