@&#MAIN-TITLE@&#
Preference stability over time with multiple elicitation methods to support wastewater infrastructure decision-making

@&#HIGHLIGHTS@&#
Weights elicited in stakeholder interviews and public online survey were similar.Elicitation method was best explanatory variable for weight stability over time.Weights were more stable after one month with SWING method than with SMART/SWING.SWING method was perceived as more difficult than SMART/SWING method.Despite weight differences, stable ranking of alternatives across methods and time.

@&#KEYPHRASES@&#
Behavioral OR,Weight elicitation,Multiple criteria analysis,Online survey,OR in environment and climate change,

@&#ABSTRACT@&#
We used a multi-method and repeated elicitation approach across different stakeholder groups to explore possible differences in the outcome of an environmental decision. We compared different preference elicitation procedures based on Multi Criteria Decision Analysis (MCDA) over time for a water infrastructure decision in Switzerland. We implemented the SWING and SMART/SWING weight elicitation methods and also compared results with earlier stakeholder interviews. In all procedures, the weights for environmental protection and well-functioning (waste-)water systems were higher than for cost reduction. The SMART/SWING variant produced statistically significantly different weights than SWING. Weights changed over time with both elicitation methods. Weights were more stable with the SWING method, which was also perceived as slightly more difficult than the SMART/SWING variant. We checked whether the difference in weights produced by the two elicitation methods and the difference in their stability affects the ranking of six alternatives. Overall an unconventional decentralized alternative ranked first or second in 92 percent of all elicitation procedures, which were the online surveys or interviews. For practical decision-making, using multiple methods across different stakeholder groups and repeating elicitation can increase our confidence that the results reflect the true opinions of the decision makers and stakeholders.

@&#INTRODUCTION@&#
It is often crucial to choose decision-making processes that reflect values well. Environmental policy decisions are especially challenging and are increasingly addressed with Multi Criteria Decision Analysis (MCDA); for recent reviews see e.g. Gregory et al. (2012), Hajkowicz and Collins (2007), Huang, Keisler, and Linkov (2011) and Mendoza and Martins (2006). Here, we focus on water infrastructures for which we devoted considerable efforts to include stakeholder preferences (Lienert, Schnetzer, & Ingold, 2013, 2015; Scholten, Schuwirth, Reichert, & Lienert, 2015; Zheng, Egger, & Lienert, 2016). Water and sewer networks or wastewater treatment plants provide many services, including public health and protection from urban flooding or environmental pollution. These infrastructures are long-lived and aging; engineering planners face “daunting” future uncertainties (Milly et al., 2008). In many OECD countries, annual investment needs for water infrastructures are estimated at 0.75 percent of GDP (Cashman & Ashley, 2008), i.e. US dollar 300,000 million annually (OECD, 2012). A quarter of Swiss sewers need renovation, and the depreciation of public water infrastructures in the next 40 years amounts to CHF 81 billion (Maurer & Lienert, 2014). So it is almost inevitable that Swiss society will have to make major investments.MCDA relies on eliciting preferences from stakeholders11For the sake of conciseness, we use “stakeholder” synonymously to “decision maker”.(e.g. Belton & Stewart, 2003; Eisenführ, Weber, & Langer, 2010; Keeney & Raiffa, 1976). Environmental decisions affect many people, are usually financed by public money, are often long-term and may thus include the interests of future generations, and cannot easily be reversed. There are often very different views about the decision, resulting in conflicts of interest (Gregory et al., 2012). It thus seems especially important for environmental decisions that the elicited parameters reflect the preferences of different stakeholders and the public and that these are stable over time and persist beyond a single situation (Gregory et al., 2012, p. 210), especially if they affect long time ranges. However, empirical evidence suggests that human beings easily become biased during preference elicitation (for reviews see, for example, Hämäläinen, Luoma, & Saarinen, 2013; Montibeller & von Winterfeldt, 2015; Morton & Fasolo, 2009; Payne, Bettman, & Johnson, 1992; Slovic, 1995). The behavioral aspects of environmental decision-making have hitherto received comparatively less attention (Hajkowicz, 2012; Hämäläinen, 2015). For example, strategic bias (for references see Hämäläinen, 2015) is a major concern in public policy and environmental choices where real or perceived conflicts of interest often exist, but this has only recently been tested in an environmental context (Hajkowicz, 2012). To overcome strategic bias, it would seem important to include the views of different kinds of stakeholders, including the broader public (Gregory et al., 2012). Another specific example is groupthink (Janis, 1972), which can be an important bias in environmental modeling and decision-making, but the literature on this is very limited (Hämäläinen, 2015). A recent textbook about environmental management choices mentions important biases such as representativeness, availability, sunk costs, anchoring, overconfidence and motivation (Gregory et al., 2012, pp. 29–31). The main message about how to deal with biases is to be aware of them, to use multiple framings to guard against affective responses and to use multiple elicitation methods (Gregory et al., 2012, p. 212). Additionally, we suggest that further research is required. The MCDA behavioral literature also lacks work on preference stability over time. For instance, we found no reference to preference stability in recent reviews of behavioral operations research (BOR; Hämäläinen et al., 2013; Montibeller & von Winterfeldt, 2015).Against this background, the main aim of this paper is to explore the extent to which a multi-method and repeated elicitation approach that includes different stakeholders can contribute to increasing the confidence in the results of a decision-making process. Using the example of Swiss water infrastructures, we investigate whether the results of an earlier MCDA are supported by a larger public prepared to finance these investments, independently of the elicitation method and a time gap of one month. In an earlier project, namely SWIP (“Sustainable Water Infrastructure Planning”22http://www.eawag.ch/en/department/sww/projects/sustainable-water-infrastructure-planning-swip/.), we interviewed twenty stakeholders using the popular SWING method (e.g. Eisenführ et al., 2010; Scholten et al., 2015), or a variant of SMART/SWING (Mustajoki, Hämäläinen, & Salo, 2005; Zheng et al., 2016; the latter was perceived as less difficult, supporting the claim of Mustajoki et al. (2005). In the two interview series, we found patterns for the weights of objectives and we could identify viable wastewater and water supply alternatives, despite a very large uncertainty of predictions, stakeholder preferences and four future socioeconomic scenarios (Scholten et al., 2015; Zheng et al., 2016). In this paper, we build on this earlier experience and address the following research questions:•Are preferences stable over time?Do SWING and the SMART/SWING variant differ in the elicited weights and in preference stability?What are possible explanations for the observed weight profiles or preference instability when elicitation is repeated? As examples, are demographic variables or environmentally friendly behavior possible explanatory factors? Do experts who have more knowledge or experience in the domain of wastewater have different and/or more stable preferences than lay people? Do preferences change if new knowledge is obtained between the first and second survey? Is preference stability related to the perceived difficulty of the questionnaire?If preferences do differ, does this affect the ranking of alternatives in an MCDA?Finally, if substantial public decisions are made, agreement between stakeholders and the public is important. In our water infrastructure case, do preferences about the importance of objectives from earlier stakeholder interviews agree with the preferences of the general public and of experts in the water field?To tackle these questions, we conducted a public online survey in an experimental set-up with a simplified objectives hierarchy. Online tools overcome the problems of personal interviews by allowing access to the larger sample needed for the experimental research proposed here. They also speed up elicitation and allow involving the public. On the other hand, their validity and biases have been criticized (e.g. Marttunen & Hämäläinen, 2008). The use of online tools thus requires careful design and cross-validation with results from other elicitation methods.The remaining paper is organized as follows: In Section 2 we review the literature on preference stability. Our research approach and statistical tests are presented in Section 3. The results are presented in Section 4 and discussed in Section 5. We summarize our main conclusions in Section 6.

@&#CONCLUSIONS@&#
To justify environmental and policy decisions, it is important to design elicitation procedures that produce stable results which reflect the stakeholders' preferences. Various factors influence preference statements, including the selected elicitation method. In our case, SWING produced statistically significantly different weights than the SMART/SWING variant. Moreover, in our study, the weights elicited with the SMART/SWING variant changed statistically significantly more often in the follow-up survey after one month compared to SWING. Despite its rigorous design, not all the limitations of such a study can be avoided (see Section SI-3.2). There is also ample scope for future research. To better understand preference formation and stability, we suggest using procedural and experimental analyses that address the following research questions:1.Do popular elicitation methods such as SWING, SMART/SWING or trade-off (see e.g. Eisenführ et al., 2010) differ systematically in their elicited weight profiles, spread of weights and preference stability over time when applied to a variety of decision situations? The validity of online preference elicitation has been questioned (Marttunen & Hämäläinen, 2008). So virtual preference elicitation should also be compared with face-to-face procedures.What are the reasons and underlying psychological mechanisms for the systematic differences between methods? For example, which explanatory variables influence preference formation and why? We found that preferences were more stable if respondents had more knowledge. To generalize this finding, it should be replicated in other settings. As another example, does the proposition of Hoeffler and Ariely (1999) hold that preferences are more stable if the decision task is more difficult? This question can be approached experimentally by constructing different types of questionnaires which allow easy choices or force people to think harder about a decision. Learning seems important, and observational studies could shed light on how learning processes evolve over time. Experiments allow us to study whether a systematic increase in information promotes more stable preferences. Is there a saturation point after which more information reduces preference stability, possibly because respondents resort to decision heuristics? Moreover, the influence of different information modes such as visual and verbal cues and interactive elicitation should be explored. As an example, does preference stability over time differ if the same information content is presented in different ways?Environmental and policy decisions are especially sensitive to preference stability over a longer time range. Given that we can identify methods and processes that stabilize preferences, does this stabilizing effect wear off over time? Can this effect be avoided, for instance with targeted interventions at certain points in time?Many of these research questions can be approached experimentally in decision labs and with the aid of students. However, to assure their generalization, laboratory results must be transferred to different types of real-world decision situations and stakeholders. Finally, for every concrete decision, it is highly relevant to identify whether possible differences in weight profiles and preference stability would result in a different ranking of alternatives in an MCDA. This need not necessarily be the case, as our study demonstrates: the first-ranked alternative was very stable, irrespective of preference differences relating to individual traits such as having more knowledge, the elicitation method (interviews, online elicitation with SWING or SMART/SWING variant), or a one-month time gap.