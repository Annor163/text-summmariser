@&#MAIN-TITLE@&#
Hybrid BFOA–PSO algorithm for automatic generation control of linear and nonlinear interconnected power systems

@&#HIGHLIGHTS@&#
Suitable objective function selection is very important for controller design.An objective function using ITAE, damping ratio and settling times is proposed.The concept is applied to design an hBFOA–PSO based PI controller for AGC system.Linear and nonlinear interconnected power system models are considered.Simulation results show better performance than PSO, BFOA, GA, CRAZYPSO and ANFIS approaches.

@&#KEYPHRASES@&#
Automatic generation control (AGC),Multi-area power system,Proportional-integral (PI) controller,Bacteria foraging optimization algorithm (BFOA),Particle swarm optimization (PSO),

@&#ABSTRACT@&#
In the bacteria foraging optimization algorithm (BFAO), the chemotactic process is randomly set, imposing that the bacteria swarm together and keep a safe distance from each other. In hybrid bacteria foraging optimization algorithm and particle swarm optimization (hBFOA–PSO) algorithm the principle of swarming is introduced in the framework of BFAO. The hBFOA–PSO algorithm is based on the adjustment of each bacterium position according to the neighborhood environment. In this paper, the effectiveness of the hBFOA–PSO algorithm has been tested for automatic generation control (AGC) of an interconnected power system. A widely used linear model of two area non-reheat thermal system equipped with proportional-integral (PI) controller is considered initially for the design and analysis purpose. At first, a conventional integral time multiply absolute error (ITAE) based objective function is considered and the performance of hBFOA–PSO algorithm is compared with PSO, BFOA and GA. Further a modified objective function using ITAE, damping ratio of dominant eigenvalues and settling time with appropriate weight coefficients is proposed to increase the performance of the controller. Further, robustness analysis is carried out by varying the operating load condition and time constants of speed governor, turbine, tie-line power in the range of +50% to −50% as well as size and position of step load perturbation to demonstrate the robustness of the proposed hBFOA–PSO optimized PI controller. The proposed approach is also extended to a non-linear power system model by considering the effect of governor dead band non-linearity and the superiority of the proposed approach is shown by comparing the results of craziness based particle swarm optimization (CRAZYPSO) approach for the identical interconnected power system. Finally, the study is extended to a three area system considering both thermal and hydro units with different PI coefficients and comparison between ANFIS and proposed approach has been provided.

@&#INTRODUCTION@&#
An interconnected power system is made up of several areas. For the satisfactory operation of power systems, both constant frequency and constant tie-line power exchange are desired. In each area, an automatic generation controller (AGC) monitors the system frequency and tie-line flows, computes the net change in the generation required (generally referred to as area control error-ACE) and changes the set position of the generators within the area so as to keep the time average of the ACE at a low value [1]. Therefore ACE, which is defined as a linear combination of power net-interchange and frequency deviations, is generally taken as the controlled output of AGC. As the ACE is driven to zero by the AGC, both frequency and tie-line power errors will be forced to zeros [2]. AGC function can be viewed as a supervisory control function which attempts to match the generation trend within an area to the trend of the randomly changing load of the area, so as to keep the system frequency and the tie-line power flow close to scheduled value. The growth in size and complexity of electric power systems along with increase in power demand has necessitated the use of intelligent systems that combine knowledge, techniques and methodologies from various sources for the real-time control of power systems.The researchers in the world over are trying to propose several strategies for AGC of power systems in order to maintain the system frequency and tie line flow at their scheduled values during normal operation and also during small perturbations. A critical literature review on the AGC of power systems has been presented in [3] where various control aspects concerning AGC problem have been studied. Moreover the authors have reported various AGC schemes, AGC strategies and AGC system incorporating other additional devices. There has been considerable research work attempting to propose better AGC systems based on modern control theory [4,5], neural network [6–9], fuzzy system theory [10–12], reinforcement learning [13] and ANFIS approach [14,15]. Also, various artificial intelligence-based optimization techniques have been proposed to improve the performance of a power system. These approaches include particle swarm optimization [16,17], differential evolution [18,19], multi-objective evolutionary algorithm [20] and NSGA-II [21] etc. Bacteria foraging optimization algorithm (BFOA), proposed by Passino [22], is a new comer to the family of nature-inspired optimization algorithms. BFOA is based on social and cooperative behaviors found in nature. Application of group foraging strategy of a swarm of E. coli bacteria in multi-optimal function optimization is the idea behind BFOA. Nanda et al. [23] have demonstrated that BFOA is a powerful evolutionary computational technique, and provides better performance as compared classical and GA techniques. Ali and Abd-Elazim [24] have recently reported that bacterial foraging optimization algorithm (BFOA), based proportional integral (PI) controller provides better performance as compared to that with GA based PI controller in two area non-reheat thermal system.In BFOA, the chemotactic movement of a virtual bacterium models a trial solution of the optimization problem. However, during chemotaxis process, the performance of BFOA algorithm depends on random search directions which may lead to delay in reaching the global solution. Recently, a new algorithm BFOA oriented by PSO has shown superior performance compared to BFOA and PSO in proportional integral derivative controller tuning application [25]. In view of the above, an attempt has been made in this paper for the optimal design of hBFOA–PSO based PI controller for AGC in two area interconnected power system. The aim of the present work is twofold: to demonstrate the advantages of hBFOA–PSO over other techniques such as PSO, BFOA and GA which are recently presented in the literature for the similar problem and to show advantages of using a modified objective function based on integral time multiply absolute error (ITAE) criteria, damping ratio of dominant eigenvalues and settling times of frequency and tie line power deviations with appropriate weight coefficients to further increase the performance of the power system. The design problem is formulated as an optimization problem and hBFOA–PSO is employed to search for optimal controller parameters. Simulations results are presented to show the effectiveness of the proposed controller in providing good damping characteristic to system oscillations over a wide range of loading conditions, disturbance and system parameters. Further, the superiority of the proposed design approach is illustrated by comparing the proposed approach with some recently published approaches such as PSO, BFOA and GA.The dynamic model of Load Frequency Control (LFC) for a two-area interconnected power system is presented in this section. Each area of the power system consists of speed governing system, turbine and generator as shown in Fig. 1. Each area has three inputs and two outputs. The inputs are the controller inputΔPref(also denoted asu), load disturbanceΔPDand tie-line power errorΔPTie. The outputs are the generator frequencyΔfand area control error (ACE) given by Eq. (1).(1)AEC=BΔf+ΔPTiewhereBis the frequency bias parameter.To simplicity the frequency–domain analyses, transfer functions are used to model each component of the area. Turbine is represented by the transfer function [2]:(2)GT(s)=ΔPT(s)ΔPV(s)=11+sTTFrom [2], the transfer function of a governor is:(3)GG(s)=ΔPV(s)ΔPG(s)=11+sTGThe speed governing system has two inputsΔPrefandΔfwith one out putΔPG(s)given by [2]:(4)ΔPG(s)=ΔPref(s)−1RΔf(s)The generator and load is represented by the transfer function [2]:(5)GP(s)=KP1+sTPwhereKP=1/DandTP=2H/fD.The generator load system has two inputsΔPT(s)andΔPD(s)with one out putΔf(s)given by [2]:(6)Δf(s)=GP(s)[ΔPT(s)−ΔPD(s)]The system under investigation consists of two area interconnected power system of non-reheat thermal plant as shown in Fig. 2. The system is widely used in literature is for the design and analysis of automatic load frequency control of interconnected areas [24]. In Fig. 2,B1andB2are the frequency bias parameters;ACE1andACE2are area control errors;u1andu2are the control outputs form the controller;R1andR2are the governor speed regulation parameters in puHz;TG1andTG2are the speed governor time constants in seconds;ΔPV1andΔPV2are the change in governor valve positions (pu);ΔPG1andΔPG2are the governor output command (pu);TT1andTT2are the turbine time constant in seconds;ΔPT1andΔPT2are the change in turbine output powers;ΔPD1andΔPD2are the load demand changes;ΔPTieis the incremental change in tie line power (pu);KPS1andKPS2are the power system gains;TPS1andTPS2are the power system time constant in seconds;T12is the synchronizing coefficient andΔf1andΔf2are the system frequency deviations in Hz.Despite significant strides in the development of advanced control schemes over the past two decades, the conventional proportional integral-derivative (PID) controller and its variants remain an engineer's preferred choice because of its structural simplicity, reliability, and the favorable ratio between performance and cost. Beyond these benefits, it controllers also offer simplified dynamic modeling, lower user-skill requirements, and minimal development effort, which are issues of substantial importance to engineering practice. As the name suggests, the PID algorithm consists of three basic modes, the proportional mode, the integral and the derivative modes. A proportional controller has the effect of reducing the rise time, but never eliminates the steady-state error. An integral control has the effect of eliminating the steady-state error, but it may make the transient response worse. A derivative control has the effect of increasing the stability of the system, reducing the overshoot, and improving the transient response.On the other hand, design of a fuzzy based controller requires more design decision than usual, for example, regarding the number of membership functions, their shape, and their overlap for all inputs and outputs, rule base, inference engine, defuzzification, and data pre and post processing. Therefore, fuzzy logic based controllers suffers from the requirement of expert user in their design and implementation, and mathematical rigors and so are vulnerable to the experts’ depth of knowledge in problem definition.The derivative term in the PID controller increases the noise sensitivity of the controller. If noise is present in the input signal, the controller performance can be degraded, and instabilities may result. Also, any sudden change in set point (and hence the error, e) will cause the derivative term momentarily to become very large and thus provide a derivative kick to the final control output. Due to the above reasons, in practical scenario, the derivative term in PID controller is rarely used to avoid wear and tear. In view of the above, a PI structured controller is considered in the present paper.As AGC requires data gathering, signal processing and communication, a time delay will be introduced. In most of the published research works, these time delays are neglected which is a valid assumption with dedicated communication links. In view of the above time delays are neglected in the present work.The design of PI controller requires determination of the two parameters, proportional gain (KP) and integral gain (KI). As the two areas are assumed identical, the controllers in both the areas are also considered to be identical so thatKP1=KP2=KPandKI1=KI2=KI.The error inputs to the controllers are the respective area control errors (ACE) given by:(7)e1(t)=ACE1=B1Δf1+ΔPTie(8)e2(t)=ACE2=B2Δf2−ΔPTieThe control inputs of the power systemu1andu2are the outputs of the controllers. The control inputs are obtained as:(9)u1=KP1ACE1+KI1∫ACE1(10)u2=KP2ACE2+K21∫ACE2In the design of a PI controller, the objective function is first defined based on the desired specifications and constraints. The design of objective function to tune PI controller is generally based on a performance index that considers the entire closed loop response. Typical output specifications in the time domain are peak overshooting, rise time, settling time, and steady-state error. Four kinds of performance criteria usually considered in the control design are the integral of time multiplied absolute error (ITAE), integral of squared error (ISE), integral of time multiplied squared error (ITSE) and integral of absolute error (IAE). Also, the eigenvalues and modal analysis provides an extension of analytical methods to examine the low frequency oscillations that are present in a power system. Eigenvalue analysis uses the standard linear, state space form of system equations and provides an appropriate tool for evaluating system conditions for the study of small signal stability of power system. Eigenvalue analysis investigates the dynamic behavior of the power system under different characteristic frequencies (modes). In a power system, it is required that all modes be stable. Moreover, it is desired that all electromechanical oscillations be damped out as quickly as possible. In other words, the damping ratios of dominant eigenvalues should be maximized as much as possible [1].Some of the realistic control specifications for automatic generation control (AGC) are [2]:(i)The frequency error should return to zero following a load change.The integral of frequency error should be minimum.The control loop must be characterized by a sufficient degree of stability.Under normal operating conditions, each area should carry its own load.To meet the above design specifications, two different objective functions are employed in the present paper as given by Eqs. (11) and (12). The first objective function (ITAE) given by Eq. (11) is a standard one and employed often in other papers. It tries to achieve the design specifications given by (i) and (ii). To add some degree of stability and damping of oscillating modes, the second objective function given by Eq. (12) is proposed. It aims to minimize the ITAE, maximize minimum damping ratio (MDR) of dominant eigenvalues and minimize the settling times ofΔf1,Δf2andΔPTie.(11)J1=∫0tsimΔf1+Δf2+ΔPTie⋅t⋅dt(12)J2=∫0tsimω1⋅∫0tsimΔf1+Δf2+ΔPTie⋅t⋅dt+ω2⋅TS+ω3⋅1min∑i=1n(1−ζi)whereΔf1andΔf2are the system frequency deviations;ΔPTieis the incremental change in tie line power;tsimis the time range of simulation;ζiis the damping ratio andnis the total number of the dominant eigenvalues;TSis the sum of the settling times of frequency and tie line power deviations;ω1toω3are weighting factors. Inclusion of appropriate weighting factors to the individual terms helps to make each term competitive during the optimization process. Wrong choice of the weighting factors leads to incompatible numerical values of each term involved in the definition of fitness function which gives misleading result. The weights are so chosen that numerical value of all the terms in the right hand side of Eq. (6) lie in the same range. Repetitive trial run of the optimizing algorithms reveals that numerical value of ITAE lies in the range 1.18–3, minimum damping ratio lies in the range 0.02–0.4 and total settling times ofΔf1,Δf2andΔPTielies in the range 15–30. To make each term competitive during the optimization process the weights are chosen as:ω1=1.0,ω2=0.1, andω3=0.5.The problem constraints are the PI controller parameter bounds. Therefore, the design problem can be formulated as the following optimization problem.(13)MinimizeJSubject to(14)KPmin≤KP≤KPmax,KImin≤KI≤KImaxwhereJis the objective function (J1andJ2) andKPmin,KIminandKPmax,KImaxare the minimum and maximum value of the control parameters. One more important factor that affects the optimal solution more or less is the range for unknowns. The range of unknowns depend on the type of applications i.e. the problem. For the very first execution of the program, a wider solution space can be given and after getting the solution one can shorten the solution space nearer to the values obtained in the previous iteration. As reported in the literature, the minimum and maximum values of controller parameters for the present problem are chosen as −1.0 and 1.0 respectively.Bacteria foraging optimization algorithm (BFOA), proposed by Passino [22], is a new comer to the family of nature-inspired optimization algorithms. BFOA is based on social and cooperative behaviors found in nature. Application of group foraging strategy of a swarm of E. coli bacteria in multi-optimal function optimization is the idea behind BFOA. The foraging behavior of E. coli bacteria present in our intestines, which includes the methods of locating, handling and ingesting food, has been successfully mimicked in BFOA. Each bacteria tries to maximize its obtained energy per each unit of time expended on the foraging process and avoiding noxious substances. Further, individual bacterium communicates with other individuals by sending signals.The optimization technique consists of determining the minimum of a function J(α) where the variables under consideration constitute the high-dimensional vectorα∈ℜpand it is very difficult or almost impossible to determine δJ(α). Here α determines the position of a bacterium in high dimensional space. A negative value of J(α) indicates that the bacterium is in nutrient-rich environment, a zero value indicates a neutral environment and a positive value indicates a noxious environment. The objective will be to try and implement a biased random walk for each bacterium where it will try to climb up the nutrient concentration and try and avoid noxious substances and will attempt to leave a neutral environment as soon as possible.This optimization procedure comprises of four basic steps: swarming and tumbling chemotaxis, reproduction and elimination and dispersal [22,23,26].During foraging of the bacteria, locomotion is realized by a set of tensile flagella. An E. coli bacterium can move in two different ways; it can swim for a period of time or it can tumble. When they rotate the flagella in the clockwise direction, each flagellum pulls on the cell, which results in the moving of flagella independently and finally the bacterium tumbles with lesser number of tumbling. In a harmful place it tumbles frequently to find a nutrient gradient. Moving the flagella in the counterclockwise direction helps the bacterium to swim at a very fast rate. The bacterium alternates between these two modes of operation its entire lifetime. The cell-to-cell signaling in E. coli swarm may be represented by:(15)JC(α,P(j,k,l))=∑i=1NJC(α,αi(j,k,l))=∑i=1N−datexp−wat∑m=1P(αm−αmi)2+∑i=1Nhreexp−wre∑m=1P(αm−αmi)2In the above equation,JC(α,P(j,k,l))is the objective function value which is to be added to the actual objective function to get a time varying objective function, N is the total number of bacteria, P is the number of variables to be optimized,α=[α1,α2,…,αp]Tis a point in the P-dimensional search domain and dat, wat, hre, wreare different attractant and repellant coefficients.Chemotaxis process simulates the movement of an E. coli cell through swimming and tumbling via flagella. Suppose αi(j, k, l) represents ith bacterium at jth chemotactic, kth reproductive and lth elimination–dispersal step. S(i) is the size of the step taken in the random direction specified by the tumble (run length unit). Then in computational chemotaxis the movement of the bacterium may be represented by:(16)αi(j+1,l,l)=αi(j,k,l)+S(i)δ(i)δT(i)δ(i)where δ indicates a vector in the random direction in the range (−1, 1).In this process, the least healthy bacteria eventually die while each of the healthier bacteria giving better objective function values asexually split into two bacteria. These new bacteria are placed in the same location to keep the swarm size constant.Gradual or sudden changes in the local environment where a bacterium population lives may occur due to various reasons. When local significant increase in heat kills a population of bacteria that are currently in a region with a high concentration of nutrient gradients is called the elimination process. A sudden flow of water can disperse bacteria from one place to another. Elimination and dispersal events may destroy chemotactic progress, but they also have the effect of assisting in Chemotaxis, since dispersal may place bacteria near good food sources. To simulate this phenomenon in BFOA some bacteria are liquidated at random with a very small probability while the new replacements are randomly initialized over the search space.The PSO method is a member of wide category of Swarm Intelligence methods for solving the optimization problems. It is a population based search algorithm where each individual is referred to as particle and represents a candidate solution. Each particle in PSO flies through the search space with an adaptable velocity that is dynamically modified according to its own flying experience and also to the flying experience of the other particles. In PSO each particles strive to improve themselves by imitating traits from their successful peers. Further, each particle has a memory and hence it is capable of remembering the best position in the search space ever visited by it. The position corresponding to the best fitness is known as pbest and the overall best out of all the particles in the population is called gbest.The features of the searching procedure can be summarized as follows [27]:•Initial positions of pbest and gbest are different. However, using the different direction of pbest and gbest, all agents gradually get close to the global optimum.The modified value of the agent position is continuous and the method can be applied to the continuous problem. However, the method can be applied to the discrete problem using grids for XY position and its velocity.There are no inconsistency in searching procedures even if continuous and discrete state variables are utilized with continuous axes and grids for XY positions and velocities. Namely, the method can be applied to mixed integer nonlinear optimization problems with continuous and discrete state variables naturally and easily.The modified velocity and position of each particle can be calculated using the current velocity and the distance from the pbestj,gto gbestgas shown in the following equations [16,28]:(17)vj,g(t+1)=wvj,g(t)+c1r1()(pbestj,g−xj,g(t)+c2r2()(gbestg−xj,g(t))(18)xj,g(t+1)=xj,gt+vj,g(t+1)with j=1, 2, …, n and g=1, 2, …, m; where n is the number of particles in a swarm, m is the number of components in a particle, t is the number of iterations (generations),vj,g(t)is the gth component of velocity of particle j at iteration t,Vgmin≤vj,g(t)≤Vgmax, w is the inertia weight factor, c1, c2 are the cognitive and social acceleration factors respectively, r1, r2 are the random numbers uniformly distributed in the range (0, 1),xj,g(t)is the gth component of position of particle j at iteration t, pbestjis the pbest of particle j, and gbesgjis the gbest of the group.The jth particle in the swarm is represented by a d-dimensional vector xj=(xj,1, xj,2, …, xj,d) and its rate of position change (velocity) is denoted by another d-dimensional vector vj=(vj,1, vj,2, …, vj,d). The best previous position of the jth particle is represented as pbestj=(pbestj,1, pbestj,2, …, pbestj,d). The index of best particle among all of the particles in the swarm is represented by the gbestg. In PSO, each particle moves in the search space with a velocity according to its own previous best solution and its group's previous best solution. The velocity update in a PSO consists of three parts; namely momentum, cognitive and social parts. The balance among these parts determines the performance of a PSO algorithm. The parameters c1 and c2 determine the relative pull of pbest and gbest and the parameters r1 and r2 help in stochastically varying these pulls. In the above equations, superscripts denote the iteration number.The hybrid bacteria foraging optimization algorithm and particle swarm optimization algorithm to search optimal values of parameters is described as follows [25]:Step 1:Initialize the following parameters:p,S,Nc,Ns,Nre,Ned,Ped,C(i)andqiwhere p is the number of parameters to be optimized, S is the number of bacteria used for searching, NSis the swimming length after which tumbling of bacteria is performed in a chemotaxis loop, Ncis the maximum number of iterations in a chemotaxis loop, Nreis the maximum number of reproduction to be performed, Nedis the maximum number of elimination and dispersal events to be performed over the bacteria, Pedis the probability of elimination and dispersal, C(i) is the size of the step taken in the random direction specified by the tumble, dat, wat, hre, wreare the attractant and repellant coefficients, Δ(p, i) is the direction of bacterium, P(i, j) is the position of bacterium, c1, c2 are the cognitive and social acceleration factors respectively for PSO algorithm, r1, r2 are the random numbers uniformly distributed in the range (0, 1) for PSO algorithm.In the above notations, j is the index for the chemotactic step, k is the index for the reproduction step and l is the index of the elimination–dispersal event.Step 2:Elimination and dispersal loop: l=l+1Step 3:Reproduction loop: k=k+1Step 4:Chemotaxis loop: j=j+1Substep a: For i=1, 2, …, S take a chemotactic step for bacterium i as follows:•Compute fitness function, J(i, j, k, l)Let J(i, j, k, l)=J(i, j, k, l)+Jcc(θi(j, k, l), P(j, k, l))Let J_last=J (i, j, k, l)Substep b: For i=1, 2, …, S take a take the tumbling/swimming decision.•For the first iteration, generate a random vector Δ(i)∈RPwhere each element Δm(i), m=1, 2, …, p a random number on [–1,1]. For subsequent iterations, update the direction and position of bacteria using PSO.Move bacteria by lettingθi(j+1,k,l)=θi(j,k,l)+C(i)((Δ(i))/(ΔT(i)Δ(i))).This results in a step of size C(i) in the direction of the tumble for bacterium i.•Compute J(i, j+1, k, l)=J(i, j, k, l)+Jcc(θi(j+1, k, l), P(j+1, k, l))SwimLet m=0 (counter for swim length)While m<NSLet m=m+1.If J(i, j+1, k, l)<J_last, let J_last=J (i, j+1, k, l) andθi(j+1,k,l)=θi(j,k,l)+C(i)((Δ(i))/(ΔT(i)Δ(i))).Use this new θi(j+1, k, l) to compute new J(i, j+1, k, l), Else, let m=NS. This is the end of the while statement for swim.Substep c: Go to next bacterium (i+1) if i≠S (i.e., go to substep b to process the next bacterium).Step 5:Evaluate the local best position for each bacterium and global best position.Step 6:Update the velocity and position of bacterium using PSO. Update the vector Δ(p, i).Step 7:If j<Nc, go to step 4 and continue chemotaxis until life of the bacteria is over.Step 8:Reproduction:Substep a: For the given k and l, and for each i=1, 2, …, S, find health of bacterium i,JHLias:JHLi=∑j=1NC+1J(i,j,k,l).JHLigives a measure of how many nutrients it got over its lifetime and how successful it was at avoiding noxious substances. Sort bacteria and chemotactic parameters C(i) in order of ascending JHLvalue (higher JHLvalue means lower health).Substep b: The Sr=S/2, bacteria with the highest JHLvalues are removed and other Srbacteria with the best JHLvalue split. New bacteria that are made are placed at the same location as their parent.Step 9:If k<Nre, go to step 3.Step 10:Elimination and dispersal: For i=1, 2, …, S with probability Ped, eliminate and disperse each bacterium.

@&#CONCLUSIONS@&#
