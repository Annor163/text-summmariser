@&#MAIN-TITLE@&#
An experimental study of adaptive control for evolutionary algorithms

@&#HIGHLIGHTS@&#
Adaptive operator selection selects the most appropriate operators in an evolutionary algorithm.The proposed framework aims at controlling a basic EA for non-expert users.Our generic controller may achieve good results using “average” operators dynamic strategies better manage the search process.The framework can be used by expert users to improve EA design.

@&#KEYPHRASES@&#
Algorithms,Design experimentation,Measurement,Performance,Evolutionary algorithms,Adaptive operator selection,

@&#ABSTRACT@&#
In this paper, we investigate how adaptive operator selection techniques are able to efficiently manage the balance between exploration and exploitation in an evolutionary algorithm, when solving combinatorial optimization problems. We introduce new high level reactive search strategies based on a generic algorithm's controller that is able to schedule the basic variation operators of the evolutionary algorithm, according to the observed state of the search. Our experiments on SAT instances show that reactive search strategies improve the performance of the solving algorithm.

@&#INTRODUCTION@&#
During the past decades, Evolutionary Algorithms (EAs) [14,22,27] have been successfully applied to many optimization problems. From a high level point of view, EAs manage a set of potential solutions of a problem – a population of individuals according to the evolutionary metaphor. The population is progressively modified by variation operators in order to converge to an optimal solution with regards to a fitness function, which evaluates the quality of the individuals. Two well-known concepts are commonly used to describe the behavior of a EA: exploitation – which reflects the ability of the algorithm to converge to an optimum – and exploration – which ensures that the algorithm is able to visit sufficiently sparse areas of the search space. The balance between exploration and exploitation (referred to as EvE) is widely recognized as a key issue of the overall search performance. This balance often relies on the adjustment of several parameters, such as the size of the population and the application rates of the different operators.Significant progress has been achieved in parameter setting [33]. Following the taxonomy proposed by [15], tuning techniques adjust the parameters of the algorithm before the run, and control techniques modify the behavior of the algorithm during the search process. Efficient tuning methods use statistical tools such as racing techniques [4] or meta-algorithms that explore the parameters’ space (e.g., ParamILS [29] or Revac [42]). Control techniques have also been proposed in order to provide adaptive or self-adaptive EAs [13].In this paper, in the context of control, we focus on the operator selection problem, i.e., given a set of available operators, how to select the operator to apply for the next iteration of the evolutionary process. To this aim, we use an Adaptive Operator Selection (AOS) approach [36] using a control point of view in order to dynamically adjust the EvE balance and improve search efficiency. The control of the EvE balance has been only partially investigated so far: most works focus on exploitation and use the quality of the population as a unique criterion to guide the search [17,24,52], and the few works that use several criteria [39] keep the EvE balance fixed. Since it has been shown that an efficient algorithm requires different parameter values during the search for achieving better results [32], the EvE balance should be dynamically controlled.The purpose of our work is twofold. Firstly, we investigate the management of dynamic control strategies by using the framework proposed by [38] to implement a generic controller.11In this paper, we call controller, the complete architecture that allows us to perform adaptive operator selection.This controller must thus identify the suitable operators at each step of the search in order to achieve the required EvE balance, which may change dynamically according to a given control strategy. Then we want to assess the impact of dynamic control on the performance of the algorithm. Our experimental methodology is organized as follows:1.Evaluating the operators management of the controller:•by assessing whether the controller is able to identify the required operators in presence of non-efficient operators, i.e., in presence of noisy operators;by checking whether the controller is able to manage a high level search policy that modifies the desired EvE balance during the search.Evaluating the solving performances:•by checking whether the controlled EA is able to solve problems efficiently with regards to existing algorithms on a sufficiently large set of problems.We want to point out that Maturana et al. [38] have proposed a controller that maintains a fixed desired compromise amongst criteria, to check whether the operators application fits the desired compromise. In our work we extend this approach by implementing a controller in which the desired compromise may change over time, and by designing high level search strategies that adjust this compromise: these new strategies allow us to improve the EA's performances. Furthermore we have devised a new reactive strategy referred to as REACTIVEMOVING in Section 5.2 that achieves very good performances in terms of solution quality, which are comparable –when not better– than those obtained by a specific state-of-art solver on large instances of the satisfiability problem.Organization of the paper: we recall the main literature on the topic in Section 2 before describing the controller in Section 3. Then, we introduce the experimental setting in Section 4 before discussing results obtained through the experimental phase: Section 5 focuses on the management of the operators, and solving performance is investigated in Section 6.

@&#CONCLUSIONS@&#
In this paper, we have investigated the control ability of adaptive control techniques for EAs. Control consists in achieving a dynamic management of the algorithm with respect to a given search policy that is defined according to high level criteria, i.e., the quality and the diversity of the population. We have considered various search policies, in order to handle more dynamic scenarios. This work has addressed some important aspects related to the automatic control of EAs, namely:1.The ability to identify and select suitable operators according a given search strategy;The ability to manage high level dynamic search policy during the search process by automatically adjusting the EAs’ behaviour;The ability to solve problems and to perform better than non-controlled EAs.Results show that dynamic strategies are better than fixed search policies, in terms of solution quality and operators management. Furthermore, the dynamic version allows the EA to better allocate computational time and is more robust w.r.t. the setting of the controller. The contribution of this paper is thus focused on providing deep insights for users willing to use EAs for solving specific problems. In this context, adaptive control can be used for two complementary purposes:•Controlling a basic EA in which classic or less known operators have been included without having any knowledge about parameters setting. In particular, in presence of many parameters (as in our study, where we consider 20 operators), it is virtually impossible to forecast the impact of the application of these operators during the search, while it would be more intuitive to think in terms of search policy, managing a higher level criterion.Improving the design of EAs for expert users, for which adaptive control can be used to study the behavior of customised operators according to various search scenarios. We have shown that a good controller may achieve good results using “average” operators compared to the best performing stand-alone ones, whose design normally requires the execution of costly and time-consuming experiments.