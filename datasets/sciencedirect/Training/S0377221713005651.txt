@&#MAIN-TITLE@&#
A solution algorithm for non-convex mixed integer optimization problems with only few continuous variables

@&#HIGHLIGHTS@&#
We suggest a new method for solving nonlinear mixed-integer programs.We prove convergence of our method.We identify a special case in which the new method finds an exact global optimum in a finite number of iterations.We identify cases in which our method works efficiently.We evaluate the method numerically show that it outperforms standard solvers.

@&#KEYPHRASES@&#
Global optimization,Combinatorial optimization,Non-convex optimization,Mixed-integer optimization,Branch-and-bound methods,Facility location problems,

@&#ABSTRACT@&#
Geometric branch-and-bound techniques are well-known solution algorithms for non-convex continuous global optimization problems with box constraints. Several approaches can be found in the literature differing mainly in the bounds used.The aim of this paper is to extend geometric branch-and-bound methods to mixed integer optimization problems, i.e. to objective functions with some continuous and some integer variables. Mixed-integer non-linear and non-convex optimization problems are extremely hard, containing several classes of NP-hard problems as special cases. We identify for which type of mixed integer non-linear problems our method can be applied efficiently, derive several bounding operations and analyze their rates of convergence theoretically. Moreover, we show that the accuracy of any algorithm for solving the problem with fixed integer variables can be transferred to the mixed integer case.Our results are demonstrated theoretically and experimentally using the truncated Weber problem and the p-median problem. For both problems we succeed in finding exact optimal solutions.

@&#INTRODUCTION@&#
Geometric branch-and-bound methods are popular solution algorithms for continuous and non-convex optimization problems with a small number of variables, see e.g. Horst, Pardalos, and Thoai (2000) or Tuy (1998). These techniques find applications for example in facility location problems, see Plastria (1992), Drezner and Suzuki (2004), Blanquero and Carrizosa (2009), and Schöbel and Scholz (2010a) for general geometric branch-and-bound solution approaches in location theory and, e.g. Drezner and Drezner (2007), Fernández, Pelegrín, Plastria, and Tóth (2007), Blanquero, Carrizosa, and Hansen (2009), and Blanquero, Carrizosa, Schöbel, and Scholz (2011) among plenty of other references for some specific location problems solved by these techniques.The most important task throughout any branch-and-bound algorithm is the calculation of lower bounds on the objective function for some smaller rectangles or boxes. Different techniques to do so are collected in Schöbel and Scholz (2010b), Scholz (2012b), and Scholz (2012a). Therein, therate of convergenceis introduced that allows to evaluate the quality of some well-known bounding operations.All the above mentioned techniques deal with pure continuous objective functions. The contribution of this paper is to extend the method to mixed-integer non-linear (MINLP) optimization problems, see Hemmecke, Köppe, Lee, and Weismantel (2010, chap. 15) for a recent survey about methods in this field. Problems of this type are extremely hard to solve, containing several classes of NP-hard problems as special cases, among them, e.g.:•the class of integer linear problems which is well known to be NP-hard, see Garey and Johnson (1979),the class of continuous quadratic programs with box constraints which is NP-hard if the problem is non-convex, see Pardalos and Vavasis (1991), orthe problem of minimizing a polynomial function of degree 4 overZn, which is NP-hard due to Lasserre (2001).In contrast to the classical discrete branch-and-bound approach for mixed-integer (linear) optimization we propose a geometric branch-and-bound approach for solving mixed-integer non-linear problems. The idea is the following: In every step we branch along the continuous variables (as done in geometric methods such as, e.g., the big square small square method, see Plastria (1992)) and solve the discrete problem in any node to get a lower bound. Note that this is contrary to the usual discrete branch and bound approaches in which branching is done along the discrete variables and the continuous relaxation is solved in each node in order to obtain a bound.Although the algorithm we propose can theoretically be applied to any (MINLP), it only works efficiently if the (MINLP) admits some special properties. These are a small number of continuous variables admitting some box-constraints, and that fixing the continuous variables results in a discrete problem which can be efficiently solved, or at least bounded. Such problems appear in many fields (e.g. location theory or robust statistics), many of them being NP-hard, see Section 5 for more examples and references.In order to apply geometric branch-and-bound techniques to mixed integer non-linear problems we derive some general bounding operations and we present theoretical results about the rate of convergence similar to Schöbel and Scholz (2010b). Moreover, we discuss an extension of the method which leads to exact optimal solutions under certain conditions given below. We implemented the approach and applied it to some facility location problems. The numerical results show that we succeeded in finding exact optimal solutions and that our method outperforms standard solution approaches.The remainder of the paper is organized as follows. In the next section we will summarize notations and basic concepts which we use throughout the paper. Section 3 presents the geometric branch-and-bound prototype algorithm for mixed integer optimization problems before we prove the convergence of our algorithm in Section 4. In Section 5 we discuss some general bounding operations and results concerning their rates of convergence. Next, in Section 6 we suggest an extension of the algorithm which leads to exact optimal solutions under certain conditions. In the following two sections (Sections 7 and 8) we apply the proposed techniques to some facility location problems and report on some numerical results. Finally, a brief conclusion and aspects of further research can be found in Section 9.Throughout the paper, we will use the following notations.Notation 1Aboxorhyperrectanglewith sides parallel to the axes is denoted byX=[x̲1,x¯1]×…×[x̲n,x¯n]⊂Rn.Thediameterof a boxX⊂Rnisδ(X)=max{‖x-x′‖2:x,x′∈X}=(x¯1-x̲1)2+…+(x¯n-x̲n)2and thecenterof a boxX⊂Rnis defined byc(X)=12(x̲1+x¯1),…,12(x̲n+x¯n).Our goal is to minimize a mixed integer functionf:Rn×Zm→Rassuming a feasible region X×Π whereX⊂Rnis a box with sides parallel to the axes andΠ⊂Zmwith ∣Π∣<∞. In order to apply the algorithm presented in the next section, we further need the following definition which is an extension of the bounding operation defined in Schöbel and Scholz (2010b) to mixed integer functions.Definition 2LetX⊂Rnbe a box,Π⊂Zmwith ∣Π∣<∞, and considerf:X×Π→R.Abounding operationis a procedure to calculate for any subbox Y⊂X alower boundLB(Y)∈RwithLB(Y)⩽f(x,π)forallx∈Yandπ∈Πand to specify a point r(Y)∈Y and a point κ(Y)∈Π.The algorithm suggested in this section is a generalization of thebig cube small cubemethod presented in Schöbel and Scholz (2010a). Here, we extend the problem to mixed integer minimization problems, i.e. to problems which contain continuous and integer variables.GivenX⊆RnandΠ⊆Zmthe goal of our approach is to minimizef:X×Π→R.This is done using the following algorithmic scheme with an absolute accuracy of ε>0.(1) LetXbe a list of boxes and initializeX≔{X}.(2) Apply the bounding operation to X and set UB≔f(r(X), κ(X)).(3) IfX=∅, the algorithm stops. Else setδmax≔max{δ(Y):Y∈X}.(4) Select a boxY∈Xwith δ(Y)=δmaxand split it into s subboxes Y1 to Yssuch that Y=Y1∪…∪Ys.(5) SetX=(X⧹Y)∪{Y1,…,Ys}.(6) Apply the bounding operation to Y1 to Ysand setUB=min{UB,f(r(Y1),κ(Y1)),…,f(r(Ys),κ(Ys))}.(7) For allZ∈X, if LB(Z)+ε⩾UB setX=X⧹Z. If UB has not changed it is sufficient to check only the subboxes Y1 to Ys.(8) Whenever possible, apply some further discarding test, see Section 6.(9) Return to Step(3).We remark that it is a non-trivial task to calculate the lower bound LB(Y) as required throughout the algorithm. We will address this question in Section 5.In order to evaluate the quality of bounding operations, we first extend the definition for the rate of convergence given in Schöbel and Scholz (2010b).Definition 3LetX⊂Rnbe a box, letΠ⊂Zmwith ∣Π∣<∞, andf:X×Π→R. Furthermore, consider the minimization problemminx∈Xπ∈Πf(x,π).We say a bounding operation has therate of convergencep∈Nif there exists a fixed constant C>0 such that(1)f(r(Y),κ(Y))-LB(Y)⩽C·δ(Y)pfor all boxes Y⊂X.As shown in Schöbel and Scholz (2010b) for pure continuous objective functions, the larger the rate of convergence the smaller the number of iterations needed throughout the algorithm.The next theorem shows that the proposed algorithm terminates after a finite number of iterations if the bounding operation has a rate of convergence of at least one.Theorem 1LetX⊂Rnbe a box, letΠ⊂Zmwith ∣Π∣<∞, andf:X×Π→R. Furthermore, consider the minimization problemminx∈Xπ∈Πf(x,π)and assume a bounding operation with a rate of convergence of p⩾1.Then the proposed algorithm terminates after a finite number of iterations and we obtain a solution within an absolute accuracy of ε from the global minimum.Define the objective functiong(x)≔minπ∈Πf(x,π)and consider the global optimization problemminx∈Xg(x)with a function g containing only continuous variables. Note that this problem is equivalent to the minimization of f(x,π) on X×Π. Since f(r(Y),κ(Y))−LB(Y)⩽C·δ(Y)pfor any subbox Y⊂X, we also findg(r(Y))-LB(Y)=minπ∈Πf(r(Y),π)-LB(Y)⩽f(r(Y),κ(Y))-LB(Y)⩽C·δ(Y)p.This yields a bounding operation for the continuous functiong:X→Rwith a rate of convergence of p⩾1. From Schöbel and Scholz (2010b) we hence know that the algorithm terminates after a finite number of iterations with an absolute accuracy of ε from the global minimum.□Note that it is also possible to compute how many iterations are necessary in the worst case, see Theorem 2 of Schöbel and Scholz (2010b).Our general scheme is applicable to all mixed-integer programming problems. However, the geometric branch-and-bound algorithm we propose runs efficiently only if we are able to compute good lower bounds in every step, i.e., if a good bounding operation is at hand. To this end, we need a class of (MINLP) problems for which such bounding operations can be developed. Problems we have in mind contain a combinatorial part which can be easily solved once the continuous variables are fixed. This restriction seems to be strong, but it turns out that many well-known problems admit these property, most of them being NP-hard. Since continuous branch-and-bound approaches only run efficiently if the number of variables is not too high we are furthermore interested in problems having only a few number of continuous variables. Some example applications satisfying the required properties are given below.•The p-median problem (see Section 7.1) is a classical example for a mixed-integer location problem in which not only the location of the facilities but also the assignment between the facilities and its customers has to be determined. If the location of the facilities is fixed, the assignment of the customers can be done by just choosing the closest facility for every customer. The problem in NP-hard. Its discrete counterpart is the uncapacitated facility location problem, see Nemhauser and Wolsey (1999).A similar situation occurs for (planar) hub-location problems, see Hamacher and Meyer (2009), in many different variations and with different objective functions.Another problem which fits very well into our framework are ordered median problems, see Nickel and Puerto (2005). Here one looks for a set of facilities (described by continuous variables) where the weights in the objective function depend on the ordered distances of these facilities to some existing points. Again, if the facilities are fixed, the remaining discrete problem can be solved just by computing the distances. A special case is the truncated Weber problem, see Section 7.2.A recent application concerns problems in image registration, see Pfeuffer, Stiglmayr, and Klamroth (2012), where two images should be compared. The discrete problem in this case is a bipartite matching problem which can be solved efficiently if the continuous variables (describing the transformation between the images) are fixed.Also in robust statistics similar problems appear. An example are trimmed regression problems where outliers should be neglected and the quality of the estimation is only measured to a fixed percentage of the (best fitted) data points. If the regression line (described by only two continuous variables) is fixed, the outliers can be determined easily.Integrated location problems, e.g. the simultaneous scheduling and location problem (ScheLoc), see Elvikis, Hamacher, and Kalsch (2009) and Kalsch and Drezner (2010), are again mixed-integer problems which reduce to a known discrete problem once the continuous variables are given.Finally, also in number theory, one may end up with a problem with only few (three or four) continuous and thousands of binary variables where a solution can very easily determined if the continuous variables are fixed, see Blomer and Schöbel (2012).Our main goal in this section is to extend some known bounding operations known from continuous optimization to mixed integer optimization problems and to analyze their rates of convergence in this case.For the concave bounding operation, we assume that we are in a position to solve the combinatorial problemminπ∈Πf(x,π)for any fixed x∈X.Moreover, for any π∈Π we assume that the functionfπ(x)≔f(x,π)is concave on X. Next, defineg(x)≔minπ∈Πfπ(x)=minπ∈Πf(x,π)and note that g is concave since the minimum of a finite number of concave functions is concave. Denoting by V(Y) the 2nvertices of Y, we then find theconcave bounding operationLB(Y)=minx∈Yg(x)=minv∈V(Y)g(v),r(Y)∈argminv∈V(Y)g(v),κ(Y)∈argminπ∈Πf(r(Y),π).Formally, we obtain the following result.Theorem 2Considerf:X×Π→Rand assume that for any fixed π∈Π the function fπ(x)=f(x,π) is concave.Then the concave bounding operation has a rate of convergence of p=∞.Sincef(r(Y),κ(Y))=minx∈Yπ∈Πf(x,π)=minx∈Yg(x)=LB(Y)we havef(r(Y),κ(Y))-LB(Y)=0for all subboxes Y⊂X.□The idea of the location bounding operation for pure continuous location problems is given in Plastria (1992).Assume that the objective function can be written asf(x,π)=h(π,d(a1,x),…,d(am,x))wherea1,…,am∈Rnare some given demand points and d(a,x) is a given distance function.Furthermore, we assume that we can solve problems of the formmin{h(π,z):π∈Πandlk⩽zk⩽ukfork=1,…,m},wherelk,uk∈Rare some given constants for k=1,…,m. In order to calculate a lower bound LB(Y) for an arbitrary box Y⊂X, suppose that the valuesdkmin(Y)=min{d(ak,x):x∈Y},dkmax(Y)=max{d(ak,x):x∈Y}for k=1,…,m are easily derived. This is the case if d is a monotone norm or a polyhedral gauge, see Plastria (1992). We then have thelocation bounding operationLB(Y)=min{h(π,z):π∈Πanddkmin(Y)⩽zk⩽dkmax(Y)fork=1,…,m},r(Y)=c(Y),κ(Y)∈argminπ∈Πf(c(Y),π).Note that this lower bound results in exactly the same bound if we are using tools from interval analysis for the continuous variables x, namely the natural interval extension.Theorem 3Assume thatf(x,π)=h(π,d(a1,x),…,d(am,x))whereh:Π×Rm→Ris for all π∈Π a Lipschitzian function in the last m variables with constant Lπ⩽Lmaxand assume that d is a norm.Then the bounding operation for location problems has a rate of convergence of p=1.Using the functiong(x)=minπ∈Πf(x,π)the proof is analogous to the result in Plastria (1992) and therefore omitted here.□The idea of the d.c. bounding operation is to reduce the problem to the concave bounding operation as follows, see e.g. Tuy (1998) or Tuy and Horst (1988) for d.c. decompositions of continuous functions.We assume that for all π∈Π a d.c. decomposition of fπ(x)=f(x,π) can be constructed, i.e.fπ(x)=gπ(x)-hπ(x)where gπand hπare convex functions. Consider an arbitrary subbox Y⊂X and c=c(Y). Then, for any subgradientξπ∈Rnof gπat c we obtainaπ(x)≔gπ(c)+ξπT·(x-c)-hπ(x)⩽fπ(x)forallx∈Yand aπis concave. Hence,q(x)≔minπ∈Πaπ(x)⩽minπ∈Πfπ(x)=f(x,π)forallx∈Y,π∈Πand also q is concave. We now apply the concave bounding operation on q and we obtain thed.c. bounding operationLB(Y)≔minv∈V(Y)q(v),r(Y)∈argminv∈V(Y)q(v),κ(Y)∈argminπ∈Πaπ(r(Y))where V(Y) is again the set of the 2nvertices of Y. Note thatLB(Y)=minπ∈Πaπ(r(Y))=aκ(Y)(r(Y)).In contrast to the concave bounding operation, we assume for the d.c. bounding operation that for any subbox Y⊂X and for all x∈V(Y) we are able to solve the combinatorial problemminπ∈Πaπ(x).Note that this combinatorial problem is identical to the minimization of f(x,π) for any fixed x since the d.c. decomposition was done with respect to the continuous variables x. Hence, the example applications mentioned at the beginning of Section 5 satisfy the required property.Theorem 4Considerf:X×Π→Rsuch that for all π∈Π a d.c. decomposition offπ(x)=gπ(x)-hπ(x)is known and assume that gπis twice continuously differentiable on X for all π∈Π.Then the d.c. bounding operation has a rate of convergence of p=2.For any fixed π∈Π we know from Schöbel and Scholz (2010b) thatLB(Y)≔minv∈V(Y)aπ(v),r(Y)∈argminv∈V(Y)q(v)is a bounding operation for fπ, i.e.fπ(x)-aπ(x)⩽Cπ·δ(Y)2for some Cπ>0 which do not depend on Y. DefiningCmax≔max{Cπ:π∈Π},we obtainf(r(Y),κ(Y))-LB(Y)=fκ(Y)(r(Y))-aκ(Y)(r(Y))⩽Cκ(Y)·δ(Y)2⩽Cmax·δ(Y)2which proves the theorem.□So far the prototype algorithm solves a series of continuous problems until the boxes get small enough and relies on the solvability of the combinatorial problem for fixed continuous variables x. However, if the continuous problem can be solved efficiently with a high accuracy for fixed values of the integer variables π we may improve the prototype algorithm by adding a further discarding test, see Step(8) in the prototype algorithm in Section 3. This discarding test even ensures that the mixed integer problem can be solved exactly under special conditions.We assume that for any fixed π∈Π we are in a position to solve the pure continuous problemminx∈Xf(x,π)exactly or with an absolute accuracy of at least ε′⩾0.Definition 4Let Y⊂X be a subbox of X. Then a set Ω(Y)⊂Π is called acombinatorial dominating setfor Y ifminx∈Yπ∈Ω(Y)f(x,π)=minx∈Yπ∈Πf(x,π).In other words, if we know that x∈Y, we only have to consider π∈Ω(Y) and can neglect all π∈Π⧹Ω(Y). Examples for sets Ω(Y) are given in the next section.If a combinatorial dominating set is known for every subbox Y⊂X, we suggest to use the following further discarding test for a given parameterM∈N.(8) For i=1,…,s, if ∣Ω(Yi)∣⩽M, solve the minimization problemti=min{minx∈Xf(x,π):π∈Ω(Yi)}and set UB=min{UB,ti} as well asX=X⧹Yi.Note that the choice of the parameterM∈Nstrongly depends on the given objective function. If M is too small, the condition ∣Ω(Yi)∣⩽M might be satisfied only rarely. On the other hand, if M is too large, it could be too expensive to solve all ∣Ω(Yi)∣ minimization problems. Therefore, we suggest to start the algorithm with a small value for M and increase M throughout the algorithm if the method does not terminate.Lemma 5LetX⊂Rnbe a box, letΠ⊂Zmwith ∣Π∣<∞, andf:X×Π→R. Assume that for any fixed π∈Π the pure continuous problemminx∈Xf(x,π)can be solved with an absolute accuracy of ε′⩾0. Moreover, assume that there exist fixed constantsτ>0,M∈Nsuch that(2)|Ω(Y)|⩽Mfor all boxes Y⊂X with δ(Y)⩽τ.Then the geometric branch-and-bound algorithm for mixed integer problems using ε=0 and the previously presented discarding test finds a solution forminx∈Xπ∈Πf(x,π)with an absolute accuracy of ε′ in a finite number of iterations.Since in every iteration of the algorithm a box with largest diameter is selected for a split into some smaller subboxes, we obtainδ(Y)⩽τfor allY∈Xafter a finite number of iterations.We next analyze the discarding test. To this end, letx¯πbe the solution forminx∈Xf(x,π)found by the continuous algorithm. Since this algorithm has an absolute accuracy of ε′, we know thatf(x¯π,π)⩽minx∈Xf(x,π)+ε′.In the discarding test(8) we taketi=minπ∈Ω(Yi)f(x¯π,π)and receive thatti=minπ∈Ω(Yi)f(x¯π,π)⩽minπ∈Ω(Yi)minx∈Xf(x,π)+ε′=minx∈Xπ∈Ω(Yi)f(x,π)+ε′⩽minx∈Yiπ∈Ω(Yi)f(x,π)+ε′=minx∈Yiπ∈Πf(x,π)+ε′,hence the solution on Yifound in(8) also has an absolute accuracy of ε′.Thus, the discarding test(8) ensures the termination of the algorithm with an absolute accuracy of at least ε′ after a finite number of iterations.□Note that Lemma 6 holds independent from the bounding operation chosen.Finally, an interesting implication of Lemma 6 should be mentioned. Many practical mixed integer optimization problems admit the property that both, the combinatorial and the continuous part can be solved exactly if the respective other variables are known. This is the case for the truncated Weber problem of the next section, for many ordered median problems, and also for many applications in robust statistics. In such a case we can use our results to find an exact global minimum by setting ε=0 and ε′=0, i.e. we only delete subboxesZ∈Xwith LB(Z)⩾UB in Step(7) of the prototype algorithm. Formally, we obtain the following result.Corollary 6LetX⊂Rnbe a box, letΠ⊂Zmwith ∣Π∣<∞, andf:X×Π→R. Assume that for any fixed π∈Π the pure continuous problemminx∈Xf(x,π)can be solved exactly, i.e. ε′=0. Moreover, assume that there exist fixed constantsτ>0,M∈Nsuch that(3)|Ω(Y)|⩽Mfor all boxes Y⊂X with δ(Y)⩽τ.Then the geometric branch-and-bound algorithm for mixed integer problems using ε=0 and the discarding test (8) finds an exact optimal solution forminx∈Xπ∈Πf(x,π).In this section, two example problems are discussed, namely the p-median problem and the truncated Weber problem. For both problems, consider m demand pointsa1,…,am∈R2.Thep-median problem (or multi-source Weber problem) is to locate p new facilitiesx1,…,xp∈R2assuming that each demand point is served by its nearest new facility. To be more precise, withX⊂R2p, with P={1,…,p}, and withΠ=Pm⊂Zmthe problem is to minimize the objective functionf(x,π)=f(x1,…,xp,π1,…,πm)=∑k=1mwk·d(ak,xπk)where w1,…,wm⩾0 are some given non-negative weights.The p-median problem is one of the most studied facility location problems and still a challenging problem since it is NP-hard due to Megiddo and Supowit (1984). Drezner (1984) presented an exact algorithm for p=2 using the Euclidean norm, some more general global optimization approaches can be found in Chen, Hansen, Jaumard, and Tuy (1998) and Schöbel and Scholz (2010a). Also the variable neighborhood search heuristic was applied in Brimberg, Mladenović, and Salhi (2004) and Brimberg, Hansen, and Mladenović (2006). Recently, a branch-and-price algorithm for large instances of the problem has been developed in Righini and Zaniboni (2007), and a big triangle small triangle approach is under investigation in Suzuki (2012). A survey is provided in Brimberg, Hansen, Mladenović, and Salhi (2008).We use the problem to demonstrate the application of the geometric branch-and-bound method for mixed integer programs. We can again make use of the d.c. bounding operation since the objective function is convex for all fixed π∈Π.Next, letY=Y1×…×Yp⊂R2psuch that xi∈Yifor the new facilities i=1,…,p and define the sets Ωk(Y)⊂P for k=1,…,m as follows:Ωk(Y)≔P⧹i∈P:thereisaj∈Pwithdkmin(Yi)>dkmax(Yj)wheredkmin(Yi)anddkmax(Yi)are defined as before, see also Example 1.Example 1As an example with p=7, consider the values ofd1min(Yi)andd1max(Yi)for i=1,…,7 as depicted in Fig. 1.In this case, we obtain Ω1(Y)={2,3,6}, i.e. for all x=(x1,…,x7)∈Y the demand point a1 will never be served by x1, x4, x5, or x7.This leads toΩ(Y)≔Ω1(Y)×…×Ωm(Y)and we obtain the following result.Lemma 7Consider the p-median problem with objective function f(x,π), let Y⊂X be an arbitrary subbox, and assume that (x∗,π∗)∈Y×Π is an optimal solution forminx∈Yπ∈Πf(x,π).Then we have π∗∈Ω(Y), i.e. Ω(Y) is a combinatorial dominating set for Y.Assume that π∗∉Ω(Y). Hence, our goal is again to construct for all x∈Y a μ=(μ1,…,μm)∈Ω(Y) such that f(x,π∗)>f(x,μ).To this end, assignμk=πk∗for all k∈{1,…,m} withπk∗∈Ωk(Y), i.e.d(ak,xπk∗)=d(ak,xμk)for all x= (x1,…,xp)∈Y. Moreover, note that for all x=(x1,…,xp)∈Y and all k∈{1,…,m} withπk∗∉Ωk(Y)there exists by construction of Ωk(Y) a μk∈Ωk(Y) such thatd(ak,xπk∗)>d(ak,xμk),see also Example 1. To sum up, for all x∈Y it exists a μ∈Ω(Y) such thatf(x,π∗)>f(x,μ),a contradiction to the optimality of (x∗,π∗).□Thetruncated Weber problemis to find a new facility locationx∈R2such that the sum of the weighted distances between the new facility location x and the nearest 1<K<m demand points is minimized. Therefore, assume some weights w1,…,wm⩾0, letX⊂R2be a box, and considerΠ={π=(π1,…,πm)∈{0,1}m:π1+…+πm=K}.The truncated Weber problem is to minimize the objective functionf(x,π)=∑k=1mπk·wk·d(ak,x)forx∈X,π∈Πwhere d is a given distance function. Note that this problem is a special case of the general ordered median problem, see Nickel and Puerto (2005), and moreover a special case of the general location-allocation problem introduced by Plastria and Elosmani (2008). Solution algorithms can be found in Drezner and Nickelm (2009b) and Drezner and Nickel (2009a). Note that these methods do not provide an exact optimal solution.Obviously, for any fixed x∈X we can easily solve the problemminπ∈Πf(x,π)by sorting wk·d(ak,x) for k=1,…,m. Moreover, for any fixed π∈Π the functions fπ(x)=f(x,π) are classical Weber problem objective functions and therefore convex. Hence, we can apply the d.c. bounding operation.Next, denote bydkmin(Y)=min{wk·d(ak,x):x∈Y},dkmax(Y)=max{wk·d(ak,x):x∈Y}the minimal and the maximal weighted distances between a subbox Y and the demand point ak, respectively. DefiningΩk(Y)≔{0}ifdkmin(Y)>djmax(Y)foratleastKindicesj∈{1,…,m}{1}ifdkmax(Y)>djmin(Y)foratmostKindicesj∈{1,…,m}{0,1}elsefor k=1,…,m, we findΩ(Y)≔Π∩(Ω1(Y)×…×Ωm(Y)).Example 2As an example with m=7 demand points, all of them with equal weights wk=1, see Fig. 2which also shows a box Y. The values ofdkmin(Y)anddkmax(Y)for k=1,…,7 for the Manhattan norm d(a,x)=∥a−x∥1 are depicted in Fig. 3.For the case K=3, we obtain the following sets:Ω1(Y)={1},Ω2(Y)={0},Ω3(Y)={0},Ω4(Y)={0},Ω5(Y)={1},Ω6(Y)={0,1},Ω7(Y)={0,1}.Hence, for the given box Y only the variables π6 and π7 are not assigned to a fixed value. Furthermore, note thatΩ(Y)=Π∩(Ω1×Ω2×…×Ω7)={(1,0,0,0,1,1,0),(1,0,0,0,1,0,1)},hence ∣Ω(Y)∣=2.The following result shows that Ω(Y) is indeed a combinatorial dominating set for any box Y.Lemma 8Consider the truncated Weber problem with objective function f(x,π), let Y⊂X be an arbitrary subbox, and assume that (x∗,π∗)∈Y×Π is an optimal solution forminx∈Yπ∈Πf(x,π).Then we have π∗∈Ω(Y), i.e. Ω(Y) is a combinatorial dominating set for Y.Assume that π∗∉Ω(Y). We now construct for all x∈Y a μ=(μ1,…,μm)∈Ω(Y) such that f(x,π∗)>f(x,μ).To this end, let I⊂{1,…,m} such that i∈I if and only ifπi∗∉Ωi(Y). Next, defineνi=0ifπi∗=1,1ifπi∗=0for all i∈I and find a μ∈Ω(Y) such that μi=νifor all i∈I. Note that such a μ exists and note that∑k=1μk≠πk∗mπk∗=∑k=1μk≠πk∗mμk.Moreover, by construction of Ω(Y) we obtain for all x∈Y∑k=1μk≠πk∗mπk∗·wk·d(ak,x)>∑k=1μk≠πk∗mμk·wk·d(ak,x),see also Example 2. Hence, for all x∈Y we havef(x,π∗)>f(x,μ),a contradiction to the optimality of (x∗,π∗).□Unfortunately, in general we cannot expect|Ω(Y)|⩽Mfor all boxes Y⊂X with δ(Y)⩽τ for a τ⩾0 and an M<∣Π∣ as the following counterexample shows.Example 3Consider the m demand pointsak=km,1-km∈R2for k=1,…,m and consider the objective functionf(x,π)=∑k=1mπk·‖x-ak‖1.Then, for all 1<K<m and Y=[0,0]×[0,0] we havedkmin(Y)=dkmax(Y)=1fork=1,…,m.Hence, Ω(Y)=Π although δ(Y)=0.In this section we present some numerical results for the example problems introduced in the previous section.The proposed algorithm was implemented in JAVA, compiled by JAVA 2 SDK 1.4, using double precision arithmetic. All tests were run on a 3.0gigahertz computer with 4gigabytes of memory. For both example problems, we generated up to m=10,000 demand points a1,…,amuniformly distributed in X={−500,−499,…,499,500}2 and weights wk∈{1,2,…,10} for k=1,…,m. Ten problems were run for different values of m. As distance measure, we applied the Manhattan norm, i.e.d(ak,x)=‖x-ak‖1for k=1,…,m. Hence, the pure facility location problems could be solved easily up to an exact optimal solution using the algorithm given in Drezner, Klamroth, Schöbel, and Wesolowsky (2001) with a complexity ofO(mlogm). Moreover, we used ε=0 and M=4 throughout the algorithm and note that we found an exact optimal solution in all problem instances.The p-median problem was solved for p=2 and p=3 new facilities. Here, every selected box Y throughout the algorithm was split into s=2 subboxes, i.e. Y was bisected in two subboxes perpendicular to the direction of the maximum width component. Our results are collected in Table 1.As can be seen, for the p-median problem the number of solved pure location problems increases with the number m of demand points. However, even with m=5000 the 2-median problem could be solved by considering only a few hundred single facility problems.In our second example problem, we set K=round(m/5) and all boxes were split into s=4 congruent subboxes. Our results are illustrated in Table 2. Therein, the run times, the number of iterations throughout our geometric branch-and-bound algorithm, and the number of solved single facility location problems in Step(8) are reported.Observe that the average number of solved facility location problems is for all values of m almost constant.Our further goal is to compare the presented geometric branch-and-bound algorithm to two standard approaches. These are(NL)using a straightforward formulation as non-linear program and a non-linear integer solver andusing a formulation as mixed integer linear program and a linear integer programming solver.We exemplarily do this for the truncated Weber problem. The formulation as nonlinear mixed-integer program uses the continuous variables x1 and x2 as well as the variables αk=∣x1−ak1∣ and βk=∣x2−ak2∣, such thatαk+βk=‖ak-x‖1=d(a,x)for the Manhattan distance d. The binary variables πkare needed to decide if demand point akis counted in the objective function. In our non-linear formulation (NL) we minimize a non-linear (and non-convex) objective function over a polyhedral integer set:(NL)min∑k=1mπk·wk·(αk+βk)s.t.∑k=1mπi=Kαk⩾x1-ak1forallk=1,…,mαk⩾ak1-x1forallk=1,…,mβk⩾x2-ak2forallk=1,…,mβk⩾ak2-x2forallk=1,…,mαk,βk⩾0forallk=1,…,mπk∈{0,1}forallk=1,…,mx1,x2∈RIn order to linearize this formulation we replace the non-linear expression in the objective function by additional continuous variables yk=πk(αk+βk) which lead to additional constraints using a value M large enough:(MIP)min∑k=1mwk·yds.t.∑k=1mzi=Kαk⩾x1-ak1forallk=1,…,mαk⩾ak1-x1forallk=1,…,mβk⩾x2-ak2forallk=1,…,mβk⩾ak2-x2forallk=1,…,mαk+βk-yk⩽M·(1-zk)forallk=1,…,mαk,βk,yk⩾0forallk=1,…,mzk∈{0,1}forallk=1,…,mx1,x2∈RTen problem instances for various values of 10⩽m⩽100 were solved three times each: employing our geometric branch-and-bound algorithm (B&B), solving the non-linear program (NL), and solving the mixed integer program (MIP). Both the non-linear and the mixed-integer linear program were solved using the FICO Xpress optimization suite. In particular, Xpress-optimizer was used for solving the MIP and Xpress-SLP (a solver for non-linear problems via sequential linear programming) for solving (NL).Our results are described next. First, we look at the solution values. The MIP solver found (the same) optimal solution as our geometric branch-and-bound approach whenever it was able to solve the problem within our time limit of one hour (which was possible up to 70 demand points). The non-linear solver found an optimal solution in 16% of all runs and got stuck in local optima otherwise. Table 3presents the average absolute gap between the global minimum x∗ found by (B&B) (as well as by (MIP) for m⩽60) and the solution x(NL) found by (NL). As can be seen, the solution x(NL) found by (NL) might be far away from an optimal solution, see Fig. 4.The average run times in milliseconds can be found in Table 4. Obviously, the run times using the mixed integer program (MIP) increase exponentially and they are very high compared to the geometric branch-and-bound algorithm (B&B) and the non-linear program (NL). Furthermore, also the run times of (NL) are considerably larger than the run times of the geometric branch-and-bound algorithm (B&B), see Fig. 5, although in general no global minimum was found by (NL).Hence, we summarize that the suggested geometric branch-and-bound algorithm outperforms commonly used optimization tools such as Xpress.In this paper, we suggested an extension of well-known geometric branch-and-bound methods for mixed integer optimization problems. The main contribution of our work were some general bounding operations and we proved their theoretical rate of convergence. Hence, we provided a general algorithm to solve mixed integer optimization problems. The method was demonstrated on some location problems and we succeeded in finding exact optimal solutions. Note that the example problems can also be solved in the same manner using the Euclidean norm and the Weiszfeld algorithm for the solution of the pure location problems, see Weiszfeld (1937).However, as in the classical pure continuous algorithms, the method is only suitable if the number n of continuous variables is relatively small. Moreover, for all bounding operations we assumed that for any fixed x the pure combinatorial problem can be solved easily. As a part of further work, the presented techniques and theoretical results should be tested at other applications, e.g., for image registration problems.On the theoretical side, new ways of combining the geometric branch-and-bound approach with discrete branch-and-bound methods seem to be interesting. To this end, discrete branch-and-bound approaches for (MINLP), see Buchheim and Rinaldi (2007) and Bonami et al. (2008), may be used, and the development and usage of other bounds as developed in Hübner and Schöbel (2011) is under research.If the discrete problem is hard to solve one may apply some discrete branch-and-bound algorithm for the pure combinatorial part. In particular, if Ω(Y)⩽M for some boxes Y, we can find the optimal solution for all x∈Y and all π∈Ω(Y) branching the integer variables π.Finally, it is interesting to apply the method also for more complicated constraints on the continuous variables, e.g. by using barrier or penalty functions, or by explicitly incorporating the structure of the constraints in the procedure.

@&#CONCLUSIONS@&#
