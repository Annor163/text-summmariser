@&#MAIN-TITLE@&#
Fast computation of optimal polygonal approximations of digital planar closed curves

@&#HIGHLIGHTS@&#
A novel method to solve the min-# polygonal approximation problem is proposed.The approach uses a modified Mixed Integer Programming model to solve the min-# problem.The proposed model is smaller than previous proposals.The novel procedure obtains the optimal solution faster than state-of-the-art methods.Only one execution of our procedure is needed to assure the optimality of the solution.

@&#KEYPHRASES@&#
Digital planar curves,Polygonal approximation,Integral Square Error,Mixed Integer Programming,Discrete optimization,min-# polygonal approximation problem,

@&#ABSTRACT@&#
We face the problem of obtaining the optimal polygonal approximation of a digital planar curve. Given an ordered set of points on the Euclidean plane, an efficient method to obtain a polygonal approximation with the minimum number of segments, such that, the distortion error does not excess a threshold, is proposed. We present a novel algorithm to determine the optimal solution for the min-# polygonal approximation problem using the sum of square deviations criterion on closed curves.Our proposal, which is based on Mixed Integer Programming, has been tested using a set of contours of real images, obtaining significant differences in the computation time needed in comparison to the state-of-the-art methods.

@&#INTRODUCTION@&#
Since Attneave [1] pointed out that the information is concentrated at dominant points, their detection has become an important research area in computer vision. Dominant points are those that can describe the curve for visual perception and recognition. In the literature two major categories can be found: corner detection methods [2–4] and polygonal approximation methods [5–7].In computer vision polygonal approximation of digital planar curves is an important task for a variety of applications like simplification on vectorization algorithms [8], image analysis [9], shape analysis [10], object recognition [11], Geographical Information Systems [12], and digital cartography [13].The main idea behind polygonal approximations of digital planar curves is to provide a compact representation of the original shape with reduced memory requirements, preserving the important shape information.The optimization problem of polygonal approximations has been formulated into two separated ways, depending on the objective function that we want to minimize:•min-#: Minimize the number of line segments M that forms a polygonal approximation, such that, the distortion error does not excess a threshold ε. Moreover the optimal solution should have the lowest distortion associated among all the solutions with the same number of line segments.min-ε: Given a number of line segments M, minimize the distortion error associated to the polygonal approximation.In the literature, several alternatives to solve the min-# and min-ε problem can be found, using heuristic, metaheuristic and optimal approaches. The selection of the distortion measure used in the algorithm is task dependent: the use of the L∞-norm is used to assure that the maximum deviation does not exceed the threshold provided by the user, whereas, the use of the L2-norm provides a polygonal approximation whose distortion (Integral Square Error) is lower than the provided threshold.For instance, to solve the min-ε problem using the L2-norm several metaheuristics have been applied: genetic algorithms [14], ant colony search algorithms [15], integer particle swarm optimization algorithms [7], etc.The main problem of using the metaheuristic approaches is the computational cost. There are several proposals in the literature that use some heuristic with a low computational cost: split based methods [16], merge based methods [17,18], merge-split based methods [5], etc.This problem is solved optimally by using dynamic programming approach [19] and graph approach [6]. These algorithms obtain optimal solutions, however a high computational burden is required to obtain them. A more recent and faster method based on Mixed Integer Programming was proposed in [20].In practice, the reduction of the description of a shape with a maximum tolerance error, that is, the min-# problem, is a more common task. Therefore, a great variety of algorithms have been proposed to solve this problem. For example, the min-# problem using the L2-norm has been solved by using metaheuristic solutions: genetic algorithms [21], ant colony optimization [15], particle swarm optimization [22,23], tabu search [24], etc. More rapid algorithms are based on other heuristics like a split approach [13], merge approach [25], graph approach [26] etc.The min-# can also be solved optimally by using a modified version of the dynamic programming approach proposed by Perez and Vidal [19] and a graph approach by Salotti [27]. The original algorithm, by Perez and Vidal, was used to obtain the polygonal approximation with a fixed number of segments M which has the minimum distortion error associated (min-ε problem). This modified version of the algorithm was proposed in [27] and is shown in Algorithm 1. The idea is to increase the number of segments needed to reach the last point of the curve until the error associated to the polygonal approximation is lower than a threshold ε.The main drawback of using optimal algorithms is the computational cost required to achieve the solution. Some improvements have been made to reduce this computational burden. For instance, Horng and Li [28] proposed an heuristic method to determine the initial point for the method based on Dynamic Programming used to solve the min-ε. This method uses two iterations of the Dynamic Programming method to obtain a polygonal approximation. Kolesnikov and Fränti [29] introduced a method to obtain polygonal approximations based on a cyclically extended closed curve of double size. The method selects the best starting point by searching on the extended search space for the extended curve. Both methods obtain good solutions using different heuristic approaches, however, neither of these methods can assure the optimality of the solution.However, optimal polygonal approximations are very important because they are commonly used to assess the quality of the suboptimal polygonal approximations obtained by suboptimal methods.The main contributions of this paper are: (i) a novel Mixed Integer Programming (MIP) model to solve the min-# polygonal approximation problem using a different approach to the state-of-the-art optimal algorithms, (ii) our proposal reduces significantly the computation time to obtain the optimal solution; (iii) the proposed MIP model is smaller than previous proposals.Section 2 summarizes the most important measures to evaluate the quality of polygonal approximations that appear in the literature. In Section 3, we formulate the problem and present the MIP model that solves this problem. Section 4 defines the experiments carried out and the results obtained. In Section 5, we discuss the results obtained and the most important aspects of the proposed method. Finally, Section 6 presents the main conclusions of this paper.The quality of a polygonal approximation is quantified by the amount of data reduction obtained and the closeness of the approximation to the original curve. Several authors have faced this problem using different approaches.Sarkar [30] proposed a method to evaluate the quality of the polygonal approximation, based on the distortion associated to the solution (Integral Square Error) and the compression ratio obtained by the solution. This measure, called Figure of Merit (FOM), is defined as(1)FOM=CRISEwhere the compression ratio (CR) is defined as the number of points N of the original contour divided by the number of points M of the polygonal approximation (CR=NM). The ISE is the sum of the squared orthogonal distances from the points of the original contour to the line of the polygonal approximation which approximates them.Rosin [31] showed that the FOM measure is biased to favor approximations with larger number of line segments, because its two terms are unbalanced. Another problem of the FOM is that is not suitable to assess polygonal approximations with different number of points M. To solve these drawbacks, Rosin [31] proposed to use a novel measure. The new measure, named as Rosin’s merit, is defined based on two components: fidelity and efficiency. Fidelity measures how well the suboptimal polygonal approximation fits the curve relative to the optimal polygon in terms of the approximation error. This component is defined as(2)Fidelity=EoptEapproxwhere Eopt is the error associated to the optimal solution and Eapprox is the error of the suboptimal polygonal approximation. Both, the optimal solution and the suboptimal polygonal approximation, use the same number of points M.Efficiency measures how compact is the polygonal approximation relative to the optimal polygonal approximation that incurs in the same error. This measure is defined as(3)Efficiency=MoptMapproxwhere Mapprox is the number of points M of the polygonal approximation which is been tested, and Mopt is the number of points that an optimal solution needs to obtain the same error associated to the polygonal approximation which is been tested.These two components are combined using a geometric mean that is named Rosin’s merit. This measure is defined as(4)Merit=Fidelity×EfficiencyThe main advantage of the Rosin’s merit over the FOM is that it can be used to compare two polygonal approximation with different number of points. However, Carmona–Poyato et al. [32] showed that the Rosin’s merit presents one significant disadvantage: this measure does not take into account if the number of points M of the polygonal approximation faithfully represents the original shape. That is, an optimal polygonal approximation with very low number of segments (M=3,for instance) will obtain better merit than a suboptimal solution with a reasonable number of points. A modified version of the Rosin’s merit was proposed in [32] to solve this drawback. The novel measure uses an optimal solution which is taken as reference, and for each optimal polygonal approximation i is obtained a value M(i). Using these values, the proposed fidelity and efficiency are computed. Finally, Carmona’s merit is computed using the geometric mean of these two components.State-of-the-art techniques to assess polygonal approximations use optimal solutions to be computed. However, optimal algorithms require a high computational cost to obtain the optimal polygonal approximation. We face the problem of obtaining the optimal polygonal approximation with the minimum number of segments using the sum of square error measure on closed curves. Our proposal is based on the Mixed Integer Programming optimization framework.Mixed Integer Programming (MIP) is an optimization technique broadly used to solve discrete optimization problems. Some examples of real problems are: allocation of distributed generators in radial distribution systems [33], data envelop analysis [34], modern semiconductor manufacturing systems [35] and augmented reality [36].A MIP problem is the minimization or maximization of a linear objective function which is subject to a set of linear constraints. The objective function is defined as(5)z=mincTx,c,x∈Rnwhere x is a vector of decision variables and c is the vector of cost values associated to the decision variables. This objective function is subject to a set of linear constraints which can be defined as(6)Ax≤bwhere A is called constraint matrix. Decision variables may take values between an upper and a lower bound which is defined as:(7)l≤x≤uSome decision variables are required to take integer values. Integer variables that must take values 0 or 1 are called binary variables and play a special role in MIP modeling and solving.The MIP problems are solved using two phases. In the first stage, the model is solved using the Simplex algorithm (introduced by Dantzig [37]) as if there were no integer restrictions. The Simplex algorithm obtains a value for the objective function that is used as a lower or upper bound, depending on whether we are maximizing or minimizing the objective function.The next stage is solved using the algorithm known as Branch & Bound (introduced by Land and Doig [38]) or some variant of the algorithm (Branch & cut, Branch & price, etc). This algorithm relies on a process of searching in a tree. The method works by enumerating all the possible combinations of the integer variables in the tree. Each node of this tree is a continuous optimization problem, based on the original problem, but with some of the decision variables set to a fixed value of the integer range provided. The root of the tree is the relaxed version of the optimization problem without integrality constraints. The value of the objective function of the root node is always a bound of any integer solution found in the tree. The Branch & Bound method generates the tree by selecting an integer variable xiand adds a node for each possible integer value of the range. The algorithm selects one of these new nodes of the tree, and solves the model using Simplex with this variable xifixed to the selected value. We can obtain four different results:•The subproblem is infeasible if the Simplex algorithm returns that the subproblem is unbounded. Therefore, any further restriction of this subproblem would be also infeasible, then, this node should be pruned.The subproblem is feasible, however the objective function obtained is worse than a previous integer solution, therefore, no children of this subproblem could improve the objective function. This node should be pruned.The subproblem is feasible, all the integer restrictions are satisfied and the objective function is better than any previous known integer solution. Then, the method stores this integer solution as the best feasible solution found. This node is a leaf of the tree because no children nodes can be generated.If none of the above occurs, then some integer decision variable xjis fractional at optimality. The method branches the problem on this variable by generating a children node of xjfor each integer value that the variable can take from its possible range. If there are several decision variables with fractional values, then the method selects one of these variables using some of the heuristic method proposed (e.g. [39,40]).This algorithm repeats until no new nodes can be generated, because no fractional decision variable can be used to branch.We can formulate the problem as follows. Let suppose a closed curve C defined by a number of ordered points N, where N > 2. A segment S can be determined using two points Piand Pjbelonging to the curve C.A polygonal approximation A can be defined as an ordered number of segments M (A={S1,S2,…,SM}), such that, the first point of segmentSi+1is the last point of segment Si.Any polygonal approximation A has an associated error. Several measures can be used to define the error associated, however we use the L2-norm which is used to define the Integral Square Error. We can define this error measure associated to a segment Sijformed by points Piand Pjas(8)Δ(i,j)=∑k=ijdist(Pk,Sij)2where dist(Pk, Sij) is the orthogonal distance from the point Pkto the segment Sijthat approximates it. Then, Integral Square Error (ISE) is the sum of the distortion associated to each segment belonging to the polygonal approximation. We can define this measure as(9)ISE=∑k=1MΔ(ik,ik+1)where ikandik+1are the indexes of the initial and end points of the segment Sk.Therefore, given an error threshold ε the polygonal approximation ISE associated is less than or equal to this threshold. The solution provided must be optimal in the number of segments M and in the error ISE associated. That is, the polygonal approximation should have the minimum number of segments M whose distortion associated does not exceed the error threshold ε and the polygonal approximation should have associated the minimum error among the polygonal approximations with the same number M of segments.As explained above, the keypoint is to create a suitable MIP model which defines the problem. In this paper we propose a MIP model to solve the min-# polygonal approximation problem on closed curves. Our model defines a set of binary decision variables. We use these binary variables to define whether a segment Si,jis used in the polygonal approximation provided as the solution. For this reason, we define the following set of variables:(10)∀xi,j∈{0,1}∀i∈[1,2,⋯,N]∀j∈[1,2,…,N],i≠jThese decision variables are used to define all the possible solutions. Due to the fact that we are considering all possible solutions, the method does not need to fix any point as the initial point of the solution. The decision variables xi,j, wherei=j,are not defined in the model, because a valid segment is formed by two different points. This reduction of decision variables regarding the MIP model in [20] causes this model to be more compact. We have defined(N−1)×(N−1)decision variables instead of N × N defined in the model for solving the min-ε polygonal approximation problem.Taking into account these decision variables, the objective function is defined as:(11)z=min∑i=1N∑j=1Nxi,j·(ɛ+1)+∑i=1N∑j=1Nxi,j·Δ(i,j),i≠jwhere, all the segments belonging to the final solution are summed in the first summation of the objective function while the second summation is the distortion (ISE) of the solution. The first summation of the objective function uses the threshold error ε (plus one) to penalize adding a new segment to the solution. The first summation of the objective function is always greater than the second summation, because the distortion of the solution should be lower than the error threshold ε. Therefore, the second summation of the objective function is defined to obtain the solution with the minimum distortion associated, among all the solutions with the minimum number of segments. A further explanation of the objective function is given in Section 3.4.The error associated to the polygonal approximation should be lower than the threshold ε provided by the user. Therefore, to take into account this information we define a new constraint as(12)∑i=1N∑j=1Nxi,j·Δ(i,j)≤ɛ,i≠jThis model has also to take into account that we want to obtain closed polygonal approximations (not isolated segments). For this reason, the new set of constraints are defined as(13)∑r=1Nxi,r=∑c=1Nxc,i∀i∈[1,2,3,⋯,N],i≠r,i≠cA new problem arises taking into account how a solution is represented using the defined decision variables. A polygonal approximation is defined usingM−1segments Si,jwhere i < j and one segment Sa,bwhere a > b. For instance, the polygonal approximation which is shown in Fig. 1(a) is defined setting the decision variablesx0,2,x2,3,x3,5,x5,7,x7,8,x8,0=1in the model. However, this polygonal approximation may be defined in the opposite direction (x0,8,x8,7,x7,5,x5,3,x3,2,x2,0=1) as is shown in Fig 1(b). These two representations define the same solution. This problem is known in Mixed Integer Programming as symmetries [41], and makes the solver to take more computational time to obtain the optimal solution. Therefore, these symmetries must be avoided by mainly adding new constraints, which define that these symmetric solutions are not considered valid. To avoid this problem we have defined a new constraint as(14)∑i=1N∑j=1ixi,j=1,i≠jwhere we state that only the solutions defined in counterclockwise direction are valid. Therefore, this constraint expresses that a valid polygonal approximation must contain one segment Sa,bwhere a > b.Our MIP model is defined using a set of linear constraints (see inequalities (12)–(14)). These sets of constraints are used to define the problem and to obtain a feasible optimal solution for the min-# polygonal approximation problem. In this section we evaluate the convenience of using the defined constraints.We analyze the objective function of the model first. The min-# problem definition states that we are seeking the polygonal approximation with the minimum number of segments which have an error associated that is lower than a threshold ε provided by the user. The objective function that is shown in Eq. (11) minimizes the summation of binary decision variables xi,j, that represent the number of segments. However, we define that this number of segments are multiplied by a constant value (ɛ+1). By multiplying the number of segments M by the valueɛ+1,we are not modifying the optimal solution, but ordering the solutions according to the number of segments and the distortion associated. This is achieved because the distortion associated to the polygonal approximation should be lower or equal than the error threshold ε and the number of segments multiplied byɛ+1will be greater than this distortion. For instance, two solutions a and b with the same number of segmentsMa=Mbhave associated distortion errors such that ISEa < ISEb. Therefore, the objective functions obtained areza=Ma·(ɛ+1)+ISEaandzb=Mb·(ɛ+1)+ISEb. Since the number of segments are equal, thenMa·(ɛ+1)=Mb·(ɛ+1). Therefore, the minimum value for the objective function is obtained for that polygonal approximation which has the minimum distortion associated, that is, ISEa.Let us suppose that the constraint defined in inequality (12) is removed. This linear constraint defines that distortion associated to the solution is lower or equal than a threshold ε defined by the user. Without this constraint, the MIP solver always obtains a trivial solution with 3 points, which is the minimum polygonal approximation that we can define. This trivial solution does not meet the requirements of the min-# problem. Therefore, this constraint is mandatory to define a suitable model for this problem.The constraint defined in inequality (13) forces the MIP solver to select consecutive line segments, that is, if the line segment consisting of points i and j is selected (xi,j=1) then some segment which ends with point i must be selected; and some segment which starts with point j must be selected as well. For instance, if the constraint (13) is not present in the model, we can define a solution using four line segments (x2,11=x21,23=x38,43=x58,60=1) for the contour known as chromosome, however this solution is not a valid polygonal approximation as is shown in Fig. 2(b). Therefore, the constraint defined in inequality (13) is mandatory to obtain feasible optimal solutions.To avoid the symmetric solutions, the constraint defined in inequality (14) is used. If this constraint is removed, the solver will consider the symmetric solutions valid, therefore the number of feasible solutions to explore grows exponentially. This constraint is not mandatory to obtain optimal feasible solutions, however, considerably reduces the computation time required for solving the min-# problem.The defined MIP model is finally solved by using the Branch & Bound algorithm, introduced by Land and Doig [38]. This algorithm enumerates all possible solutions to the problem creating a search tree: the nodes are new problems with some decision variables equal to some value. The method searches for the optimal solution in the search tree, pruning those solutions which do not produce better results than the best solution found so far. To illustrate how the algorithm works, a little example is presented below.Let us suppose we want to solve the min-# problem for contour chromosome (Fig. 2(a)) with distortion thresholdɛ=12. The algorithm first runs the Simplex method (introduced by Dantzig [37]) on the proposed model with no integer restrictions. This relaxed version of the model is the root node of our search tree. We obtain a value of the objective function of 122.94 with all the decision variables with an integer value except the decision variables x29,31, x29,47, x31,37, x37,47. Notice that the objective function for the relaxed version of the problem will be lower than the objective function of the solution where all the integrality constraints are satisfied. We should select a node (decision variable) to branch and then fix possible values for this variable. In the literature, several branching techniques can be found [42]. To simplify the explanation we select the first fractional (not integer) decision variable, i.e., the depth first strategy. We select the decision variable of x29,31 and fix the value to 1. We obtain a value for objective function ofz=129.95where all decision variables have taken integer values except the decision variables x47,49, x47,54, x49,53, x53,0, x54,0. Therefore, we setx47,49=1in the model and run the Simplex algorithm. We obtain an objective functionz=133.55and the fractional variables x0,14, x0,15, x14,16, x15,22, x16,22. We set the valuex0,14=1in the model and run the Simplex algorithm again. The objective function obtained isz=136.78and the fractional variables are x14,16, x14,23, x16,22, x22,29, x23,29. We fix the decision variablex14,16=1and executed the Simplex algorithm using this new restriction. We obtain a solution where all the decision variables take integer values, the objective function obtained isz=138.07. The solution of the problem isM=10andISE=8.07. This solution is stored as the best feasible optimal found and is highlighted in Fig. 3. This figure presents a small piece of the tree generated by the Branch & Bound algorithm.The algorithm should select a node to backtrack in order to continue. We select the last node which has been branched, that is, x14,16. The algorithm selects now a different valuex14,16=0and solves the model using this new restriction. The objective function obtained isz=137.80and the decision variables with no integer values are x14,17, x14,23, x17,22, x22,29, x23,29. The new valuex14,17=1is added to the model and solved. We obtain a solution where all decision variables are integer and an objective functionz=139.20,which is worse than the previous feasible solution found (z=138.07). Therefore, this solution is not stored.The algorithm selects the last node that has been branched to backtrack, and fixes a different possible valuex14,17=0. The model is solved taking into account this new restriction. The solution contains fractional decision variables, however, the objective functionz=139.59is worse than the best feasible solution foundz=138.07; therefore, no children of this node could improve the best solution found and the node should be pruned.The algorithm keeps working as explained above, discarding those integer solutions which have a worse objective function and pruning those nodes that have fractional variables, but whose objective function is worse than the best feasible solution found so far. The algorithm stops when no new nodes can be explored and the best feasible solution found is returned as the optimal solution.

@&#CONCLUSIONS@&#
The current paper presents a novel and efficient method to obtain the minimum number of line segments for the polygonal approximation of a digital planar curve, using the ISE error criterion. It is based on the Mixed Integer Programming optimization framework. The main idea is to represent all possible line segments and solutions using binary decision variables. Then, using a set of linear constraints, the MIP solver searches for the feasible optimal solution.The present proposal has demonstrated to be faster than all optimal methods tested. Due to this issue, we recommend to use the present approach on complex and big contours, where the optimal polygonal approximation is required, for instance to compute measures to assess the quality of suboptimal polygonal approximations.The present approach is capable to obtain the optimal solution on closed curves using the sum of square deviation criterion error. Our approach only needs one execution to assure the optimality of the solution in closed curves, because our proposal does not need to fix any point of the final solution as the initial point.We have used the square deviation error to solve the min-# problem on closed curves. However our proposal could be easily adapted to use another error criterion.