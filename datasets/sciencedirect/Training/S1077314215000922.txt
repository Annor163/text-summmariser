@&#MAIN-TITLE@&#
Factorized appearances for object detection

@&#HIGHLIGHTS@&#
We present an object detection framework based on an advanced part learning.A generic learning method of the relationships between part appearances is proposed.We treat part locations as well as their appearance as latent variablesWe modify the weakly-supervised learning to handle a more complex structure.Our model yields to state-of-the-art results for several object categories.

@&#KEYPHRASES@&#
Object recognition,Deformable part models,Learning and sharing parts,Discovering discriminative parts,

@&#ABSTRACT@&#
Deformable object models capture variations in an object’s appearance that can be represented as image deformations. Other effects such as out-of-plane rotations, three-dimensional articulations, and self-occlusions are often captured by considering mixture of deformable models, one per object aspect. A more scalable approach is representing instead the variations at the level of the object parts, applying the concept of a mixture locally. Combining a few part variations can in fact cheaply generate a large number of global appearances.A limited version of this idea was proposed by Yang and Ramanan [1], for human pose dectection. In this paper we apply it to the task of generic object category detection and extend it in several ways. First, we propose a model for the relationship between part appearances more general than the tree of Yang and Ramanan [1], which is more suitable for generic categories. Second, we treat part locations as well as their appearance as latent variables so that training does not need part annotations but only the object bounding boxes. Third, we modify the weakly-supervised learning of Felzenszwalb et al. and Girshick et al. [2], [3] to handle a significantly more complex latent structure.Our model is evaluated on standard object detection benchmarks and is found to improve over existing approaches, yielding state-of-the-art results for several object categories.

@&#INTRODUCTION@&#
Pictorial structures (PSs) [4,5] and their modern variants such as the deformable part models (DPMs) [2] are probably the most popular models for object category detection. A PS is a collection of independent object parts whose spatial configuration is constrained by a system of elastic connections (springs). A DPM is a particular example of a PS that is learned by a discriminative method (latent SVM) and that uses linear classifiers on top of HOG features to describe the part appearance.By design, DPMs model variations of the object that can be expressed as an independent motion of the object parts, which excludes, in particular, all the effects that cannot be expressed as an image deformation. Examples are appearance variations due to the self occlusion of a three dimensional object rotating out-of-plane. Other examples are three dimensional articulations or deformations: the appearance of a horse tail or of a scarf can change quite dramatically with motion. Since the linear HOG filters used in DPMs represent, by their very nature, a unimodal distribution of appearances, none of these variations can be modelled effectively by a DPM.A simple way of incorporating multi-modal statistics in a DPM is to give up the linearity of the filters. For a discriminatively trained model, this means using a kernel other than a linear one, for example a radial basis function (RBF) kernel [6,7]. Unfortunately, non-linear kernels have a major impact on the learning and testing complexity of the model [6]. In fact, if the bottleneck of a standard DPM is searching object parts at all image locations and scales [8], with a non-linear kernel this is further exacerbated by the need of comparing each candidate part appearance to a large number of support vectors (typically in the order of thousands [6]). Recent techniques for the efficient “linearization” of non-linear kernels [7,9] do not help much here because they are limited to additive kernels, which, unlike the RBF ones, cannot be used to express multi-modal functions. Approximating RBF kernels very efficiently are still an open issue [10].The alternative and more common approach for modeling multi-modal statistics with a DPM is to use a mixture of multiple DPMs [2,11,12], one for each object aspect (e.g., the front, three-quarter, and side views of a car, as in Fig. 1). The multiple DPMs are “glued” together by a latent variable that selects which component to use for each given candidate object instance. Compared to using non-linear kernels, the increase in complexity is bounded (linear in the number of components), and the latent variable explicitly captures which appearance variant is active, which may have a well defined semantic (e.g., the object viewpoint).Mixtures of DPMs are usually learned jointly to calibrate their scores and to determine which component to use for each training object instance [2,11]. Other than that, the components are independent computationally and statistically. The latter issue is particularly severe as it limits the number of components that can be added to the model before overfitting starts to kick in. In practice, mixtures of DPMs can only model a handful of different object aspects. A more effective modeling scheme must exploit the fact that the various object aspects are by and large statistically dependent.In this paper we extend the mixture-of-parts proposed in Yang and Ramanan [1] for pose estimation to general object class detection. In essence, we investigate the simplest extension to DPMs that allows exploiting the statistical dependencies between different object aspects. In particular, we apply the notion of a mixture of object appearances at the level of the object parts, rather than to the object as a whole. In object detection, the class structure for any object and the part locations are generally unknown, and only bounding boxes are available. Therefore, the fully supervised method of Yang and Ramanan [1] cannot be used. In contrast, our model considers the object parts and their appearances as latent variables that should be jointly estimated during training. In order to properly constraint the latent variables, we adapt the weakly-supervised latent SVM algorithm [2,3], with a hierarchical regularization as explained in Section 3. In this way, local part appearances can be learned in an unsupervised way.To illustrate our model, consider a standard mixture of DPMs [2]. Graphically, this can be represented by the AND-OR tree of Fig. 1(i). The root node represents an OR node, and entails selecting one of a number of possible DPM models (corresponding to the three-quarter, side, and front views of the car). Each of these nodes is in turn connected to a small number of parts by an AND node, meaning that all those parts should be detected for the corresponding DPM. Our extension associates to each part a pool of different appearances to choose from, connected by an OR node. These multiple part appearances can represent local variations such as different styles of the wheel of a car, different shapes of the tail of a horse, or different rotations of the head of a person.The key insight is that the model can now represent a much broader range of object variations combinatorial rather than linear in the number of model components, with a very modest increase in the number of model parameters (e.g., just twice as many if two appearance models per part are considered). As we will see in Section 5, the impact on the inference and learning costs is also very modest.Nevertheless, selecting parts independently from each other can yield unreasonable configurations (e.g., two different wheel styles for the same car). To improve the model specificity and ultimately its precision, we consider on top of the AND-OR graph a mechanism to constrain the part activations to be pairwise compatible. (see Fig. 1(iii)). While in Yang and Ramanan [1] the structure of the compatibility constraints have the same structure used for deformations, i.e. a tree, since our goal is to generic object categories whose structure may be unknown a-priori, local appearance compatibility is enforced on a planar graph instead, where each part is connected to its neighborhoods. This structure is a loopy conditional random field (CRF) and it can be optimized efficiently with combinatorial techniques [29]. In this way, the actual structure of the object is learned during training by associating a weight to each pairwise term.

@&#CONCLUSIONS@&#
We have presented a new extension of the deformable parts model that can be used to learn multiple local appearances at a reasonable computational cost.Compared to a traditional mixture of DPMs, our model (i) can express a very large set of different object appearances with a very small increase in the number of parameters, (ii) can learn the same amount of variation from far less training data by better exploiting the statistical dependencies between different object appearances, and (iii) is still very discriminative because the CRF constraints can reject unlikely part configurations.Compared with multiple independent models, our approach can approximate an exponentially rich combination of appearances maintaining the same model representation. In addition, to limit our representation to only the feasible configuration of local parts, we introduce pairwise potential between appearances. We are also investigating the possibility to introduce the concept of occluded parts to the model as another local appearance, which can help on learning clearer parts.