@&#MAIN-TITLE@&#
An evolving surrogate model-based differential evolution algorithm

@&#HIGHLIGHTS@&#
To improve the performance of differential evolution (DE) algorithm.We present an evolving surrogate model-based differential evolution (ESMDE) method.In ESMDE, the surrogate model is constructed using population members of the current generation.Surrogate model assists in producing competitive offspring during the evolution.Surrogate model evolves with population to better represent the search basin.

@&#KEYPHRASES@&#
Differential evolution,Global optimization,Surrogate model,Parameter adaptation,Ensemble,

@&#ABSTRACT@&#
Differential evolution (DE) is a simple and effective approach for solving numerical optimization problems. However, the performance of DE is sensitive to the choice of mutation and crossover strategies and their associated control parameters. Therefore, to achieve optimal performance, a time-consuming parameter tuning process is required. In DE, the use of different mutation and crossover strategies with different parameter settings can be appropriate during different stages of the evolution. Therefore, to achieve optimal performance using DE, various adaptation, self-adaptation, and ensemble techniques have been proposed. Recently, a classification-assisted DE algorithm was proposed to overcome trial and error parameter tuning and efficiently solve computationally expensive problems. In this paper, we present an evolving surrogate model-based differential evolution (ESMDE) method, wherein a surrogate model constructed based on the population members of the current generation is used to assist the DE algorithm in order to generate competitive offspring using the appropriate parameter setting during different stages of the evolution. As the population evolves over generations, the surrogate model also evolves over the iterations and better represents the basin of search by the DE algorithm. The proposed method employs a simple Kriging model to construct the surrogate. The performance of ESMDE is evaluated on a set of 17 bound-constrained problems. The performance of the proposed algorithm is compared to state-of-the-art self-adaptive DE algorithms: the classification-assisted DE algorithm, regression-assisted DE algorithm, and ranking-assisted DE algorithm.

@&#INTRODUCTION@&#
Differential evolution (DE) [1] is a fast and simple population-based stochastic search technique that is inherently parallel and performs well on a wide variety of real-world problems [2]. The performance of the DE algorithm is sensitive to the population size (NP), mutation and crossover strategies, and their associated control parameters, such as the crossover rate (CR) and scale factor (F) [3,4]. The best combination of strategies and control parameters can be different for different optimization problems and also for the same functions with different computation times and accuracy requirements. Therefore, to successfully solve a specific optimization problem, it is generally necessary to perform a time-consuming trial-and-error search for the most appropriate combination of strategies and their associated parameter values, which results in high computational costs. In addition, when the population of DE evolves through different regions in the search space, different strategies [5] combined with different parameter settings may be more effective than a single combination of strategies and parameters for the entire search. Therefore, to overcome the trial-and-error search for the appropriate combination of strategies and parameter values and to adapt the combination to different regions in the search space, various adaptation schemes have been proposed [5–10]. Recently, a DE algorithm with ensemble of mutation strategies and parameter values (EPSDE) [10,11] was proposed to overcome the time-consuming trial-and-error procedure of the conventional DE algorithm and has shown significant improvement compared to other state-of-the-art algorithms.In time-consuming and expensive optimization problems, surrogate models built based on the evolutionary history of the population members have been incorporated into different evolutionary algorithms (EAs) to reduce the number of original fitness evaluations [12–14]. A surrogate model is an estimation model, built by using other functions, which is used to estimate the original objective function. Surrogate models can be built using a variety of techniques, such as radial basis functions [13], artificial neural networks, Kriging models [14], support vector machines, splines, and polynomial approximation models. A classification-assisted DE that incorporates classification for pairwise comparison was proposed in [15] to solve computationally expensive problems. The performance of the support vector classification-assisted DE (SVC-DE) algorithm has been compared with both the support vector regression-assisted DE (SVR-DE) algorithm and ranking-based support vector machine assisted DE (RankSVM-DE) algorithm.In this paper, we present an evolving surrogate model-based differential evolution algorithm (ESMDE). In the EMSDE, the DE algorithm is equipped with an evolving surrogate model constructed using the evolving population members. The evolving surrogate model enables the EMSDE algorithm to generate competitive offspring during different stages of the evolution with the assistance of the appropriate strategy and parameter combinations. In the present work, we adopt a surrogate model built using the Kriging technique based on the suggested model discussed in [14]. Kriging is a spatial prediction method based on minimizing the mean squared error. We also apply design and analysis of computer experiments (DACE), which is a parametric regression model that can handle three or more dimensions [14]. The performance of the proposed algorithm has been compared with state-of-the-art self-adaptive algorithms, such as JADE [16], CoDE [17], SaDE [5], and EPSDE [11]. The performance of the proposed algorithm has also been compared to the SVC-DE, SVR-DE, and RankSVM-DE algorithms presented in [15].The reminder of this paper is organized as follows: Section 2 presents a literature survey regarding DE, surrogate models, and the usage of surrogate models in DE. Section 3 presents the proposed ESMDE algorithm. Section 4 presents the experimental results and discussions, and Section 5 concludes the paper.

@&#CONCLUSIONS@&#
In this paper, we present an evolving surrogate model-assisted DE algorithm (ESMDE). This algorithm makes use of an evolving surrogate model, which helps generate competitive offspring corresponding to each population member in every generation of the evolution based on an appropriate combination of strategies and their associated parameter values. From the results, the performance of the ESMDE method is statistically similar or better than the state-of-the-art self-adaptive DE algorithms in terms of mean and standard deviation values. The improved performance of the proposed ESMDE algorithm is due to the faster convergence speed and better consistency in finding the global optima with the assistance of the surrogate model. In the proposed ESMDE, corresponding to each parent, a few number of trial vectors are generated using different combinations of strategies and parameter values. From the generated offspring members, a competitive offspring is selected based on the surrogate model evaluation. Hence, the proposed method does not require any trial and error approach to find the approximate combination of strategies and their associated parameter values.The performance of the proposed algorithm depends on the accuracy of the employed surrogate model, and different surrogate models are effective for the different dimensionality and complexity requirements of the problem. The present work employs a surrogate model built using the Kriging technique. In the future, we would like to evaluate the performance of the proposed algorithm employing different surrogate modeling techniques. Our final goal is to develop a parameter-free DE algorithm using surrogate models to solve high dimensional problems with better convergence and consistency.