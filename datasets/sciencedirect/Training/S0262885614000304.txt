@&#MAIN-TITLE@&#
A unified approach to the recognition of complex actions from sequences of zone-crossings

@&#HIGHLIGHTS@&#
We present a method for the recognition of complex actions in a unified way.We encode simple action HMMs within the stochastic grammar that models complex actions.As input our method receives a sequence of crossings of tracks through a set of zones.We evaluate our method in a threat recognition setting.

@&#KEYPHRASES@&#
Threat recognition,Complex actions,Temporal relations,Multi-threaded parsing,Stochastic parsing,

@&#ABSTRACT@&#
We present a method for the recognition of complex actions. Our method combines automatic learning of simple actions and manual definition of complex actions in a single grammar. Contrary to the general trend in complex action recognition that consists in dividing recognition into two stages, our method performs recognition of simple and complex actions in a unified way. This is performed by encoding simple action HMMs within the stochastic grammar that models complex actions. This unified approach enables a more effective influence of the higher activity layers into the recognition of simple actions which leads to a substantial improvement in the classification of complex actions. We consider the recognition of complex actions based on person transits between areas in the scene. As input, our method receives crossings of tracks along a set of zones which are derived using unsupervised learning of the movement patterns of the objects in the scene. We evaluate our method on a large dataset showing normal, suspicious and threat behaviour on a parking lot. Experiments show an improvement of ~30% in the recognition of both high-level scenarios and their composing simple actions with respect to a two-stage approach. Experiments with synthetic noise simulating the most common tracking failures show that our method only experiences a limited decrease in performance when moderate amounts of noise are added.

@&#INTRODUCTION@&#
Recognition of complex actions such as having a meal or checking the vulnerabilities of a truck is a challenging task with applications in fields such as surveillance and monitoring of activities of daily living (ADL). Complex actions are composed of one or more threads of simple actions with specific temporal arrangements. Simple actions such as run, walk, crouch or bend are aimed at providing an instantaneous behavioural description. There exist a number of methods in the literature for the recognition of simple actions [1]. Their relatively short temporal span and stability make them suitable to be modelled from appearance using few abstraction layers in the form of discriminant representations [2–5], state-based models [6–8] or a combination of both.Complex actions may involve a single actor for a long period of time such as having a meal or involve several actors simultaneously such as checking the vulnerabilities of a parked truck where the threatening action must be carried out after the truck driver has left the vehicle. Modelling of complex actions is usually done by breaking the complex action into sequences or sets of simple actions. Hierarchical approaches are very popular for this kind of problems because of their high descriptive power achieved by adding new abstraction layers on top of previously defined ones. Some examples of these approaches are Hierarchical Hidden Markov Models (HHMM) [9–12] and Syntactic methods [13–18].Many authors recognised the need to learn the simple actions, by attribute learning [19–21] or using topic models based upon Latent Dirichlet Allocation (LDA) or Hierarchical Dirichlet Process (HDP) [22–24], where Hospedales [25] also included explicit knowledge of rare event using a weakly supervised joint topic model. In this paper we address this need to learn the simple actions by matching the sensor data domain to a semantically higher level using zones, which are defined by data driven clustering. In contrast to the approaches mentioned before we favour using tracks over lower level image features as we expect that tracks provide longer term information needed to recognise longer term threat models.In the present paper, we address the problem of recognition of complex actions using syntactic approaches and present an application to the recognition of threats in a parking lot. We tackle the problem of sparsity of training data by allowing manual definition of the complex actions. Manual definition of the structure of the activity in the surveillance setting has been previously highlighted by other authors [15,26,16,27–30].We present an approach for the recognition of complex actions. Our method is inspired by the recent method by Zhang et al. [31]. They propose multi-threaded parsing to recognise multi-threaded complex actions. In their approach simple actions are deduced from trajectories between common start and end points. In our case we use more advanced simple action detectors based on HMMs that allow one to recognise more sophisticated behaviours such as loitering and walking around. Our approach gets as input sequences of zone-crossings learned in an unsupervised way from the trajectories of detected objects in the scene. The novelty of our method is that we integrate statistical learning of simple actions with manual specification of complex actions in a single grammar by encoding simple action HMMs as stochastic grammar rules. Recognition is carried out in a unique parsing procedure. Similar approaches divide this problem into two stages: In the first stage simple actions are detected which are then passed to a second stage that recognises complex actions. Our motivation for using a unified approach is that optimal detections at the simple action level are not necessarily optimal at the complex level. Therefore, our unified approach leads to a more effective top-down influence which allows to select simple action detections more relevant at the complex action layer. We provide experimental evaluation in a threat recognition dataset and show that the proposed method outperforms in terms of recognition accuracy to a similar method that divides recognition into two stages. Fig. 1shows an overview of our method.The outline of the paper is as follows: in Section 2 we describe some related work. In Section 3 we describe the problem that we aim at solving. Section 4 describes the feature extraction process. Section 5 covers the process of learning statistical models for simple actions. In Section 6 we show how simple actions models and complex activity rules are both put together in the form of a grammar. Section 7 contains details of the parsing procedure used for recognition. Section 8 presents the experimental validation of our approach for the recognition of threats in a parking lot. Finally, Section 9 gives some concluding remarks.

@&#CONCLUSIONS@&#
We have presented an approach for the recognition of threats in a parking lot, or more generally, for the recognition of complex actions. Our method integrates statistical learning of simple actions and manual specification of complex actions into a single grammar. It implements a multi-threaded parsing procedure that allows the modelling and recognition of actions involving multiple objects which are related by complex temporal relations such as precede, during, overlap, … Our main contribution is a unified parsing mechanism allowing for effective influence of the higher layers into the recognition of primitive actions. As input to our method we use the crossings along a set of zones learned in an unsupervised way from the trajectories of detected objects in the scene. Learned zones create a partitioning of the scene in correspondence to the activities carried out on the scene (entering/exiting areas, loitering/standing areas) and are thus well suited for our action definition.Our unified approach achieves improvements in the recognition of both simple and complex actions of ~30% with respect to a two-stage approach. Optimal detections regarding the simple action layer are not necessarily optimal for the complex action layer. We argue that such division limits the influence of the higher layer towards the lower one thus leading to a loss in accuracy. This is demonstrated in the experiments in a realistic dataset where we show higher recognition rates, both of simple and complex actions, of our unified approach with respect to a similar two-stage approach. Perhaps the clearest example is the ability to distinguish the subtle differences between the scenarios stop for a meal and stop for a meal with check which only differ on the occurrence of the loiter action in the latter case. This is particularly challenging since the loiter action is quite ambiguous in terms of trajectory and therefore triggers many phantom detections when someone is nearby the truck. Experiments with synthetic noise show the robustness of our method to the dominant failures in the tracking module causing track breaks and ghost tracks. Specifically, for moderate amounts of noise the proposed method only experiences a limited decrease in performance. The improvements in our method come at the expenses of higher computational costs. This is specially the case in the presence of track breaks where the track continuity constraint cannot be applied to reduce the number of candidate hypothesis. Directions of further research will explore ways of reducing computational complexity while preserving the discriminative and beneficial properties of our method.