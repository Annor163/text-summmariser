@&#MAIN-TITLE@&#
Evolving fuzzy grammar for crime texts categorization

@&#HIGHLIGHTS@&#
This paper introduces the evolving fuzzy grammar (EFG) method for crime texts categorization. The learning model is built based on a set of selected text fragments which are then transformed into their underlying structure called fuzzy grammars.The fuzzy notion is used because the matching, parsing and grammar derivation involves uncertainty. Fuzzy union operator is also used to combine and transform individual text fragment grammars into more general representations of the learned text fragments. The set of learned fuzzy grammars is influenced by the evolution in the seen pattern; the learned model is slightly changed (incrementally) as adaptation, which does not require the conventional redevelopment.This paper compares EFG, a novel method for learning text structure at the text fragment level Refs. [1,2] with ML in categorizing crime incidents data. In contrast, the ML methods are generally statistically founded and require the conventional train-test–test–retrain when new pattern is found.It is hypothesized in this research that this makes the whole time involved in this ML higher. An experiment is carried out to compare the performance between EFG and ML methods in precision, recall, FF-measure and extension learning. A significant test is performed to measure the difference in mean value within precision, recall and FF-measure competency.The main strength of this paper in comparison with previous related works is that it describes completely the steps involved in developing EFG. In Ref. [2] the authors presented the general step for grammar–grammar combination. In Ref. [3] the highlight was given on the step to combine grammar while the Ref. [4] emphasizes the permutation free generated fuzzy grammars.This paper however, integrates and refines the previous mentioned papers by providing more details such as the algorithm for grammar combination and demonstrates this using data that express armed attack and bombing events.This paper also ventures on a new problem on text classification compared to previous smaller scale data used in case study of EFG in Ref. [2] and text extraction task in Refs. [1,6].Results show that the EFG algorithm produces results that are close in performance with the other ML methods in terms of precision, recall, and FF-measure. The performance across approaches investigated in this paper is compared against EFG using significant test. Result has also shown that EFG has lower model retraining adaptability time.

@&#KEYPHRASES@&#
Evolving fuzzy grammar,Machine learning,Text categorization,Crime,Soft computing,Incremental learning,

@&#ABSTRACT@&#
Text mining refers to the activity of identifying useful information from natural language text. This is one of the criteria practiced in automated text categorization. Machine learning (ML) based methods are the popular solution for this problem. However, the developed models typically provide low expressivity and lacking in human-understandable representation. In spite of being highly efficient, the ML based methods are established in train–test setting, and when the existing model is found insufficient, the whole processes need to be reinvented which implies train–test–retrain and is typically time consuming. Furthermore, retraining the model is not usually practical and feasible option whenever there is continuous change. This paper introduces the evolving fuzzy grammar (EFG) method for crime texts categorization. In this method, the learning model is built based on a set of selected text fragments which are then transformed into their underlying structure called fuzzy grammars. The fuzzy notion is used because the grammar matching, parsing and derivation involve uncertainty. Fuzzy union operator is also used to combine and transform individual text fragment grammars into more general representations of the learned text fragments. The set of learned fuzzy grammars is influenced by the evolution in the seen pattern; the learned model is slightly changed (incrementally) as adaptation, which does not require the conventional redevelopment. The performance of EFG in crime texts categorization is evaluated against expert-tagged real incidents summaries and compared against C4.5, support vector machines, naïve Bayes, boosting, and k-nearest neighbour methods. Results show that the EFG algorithm produces results that are close in performance with the other ML methods while being highly interpretable, easily integrated into a more comprehensive grammar system and with lower model retraining adaptability time.

@&#INTRODUCTION@&#
Text mining concerns itself with identifying and transforming information embedded within unstructured text into more structured forms such as metadata [1]. A method that can assist towards this goal is text fragment categorization which assigns categories to text fragments such as sentences and paragraphs. This can benefit text mining tools and algorithms because the analysis of such texts is simpler and can enable the discovery of links and patterns not easily noticeable previously.However, a few challenges exist. The first is posed by the nature of the embedded meanings in text which makes their identification difficult. This typically requires identification of possible feature representations in order to capture the underlying structure of the text and the analysis of possible categories by interrelating the extracted features. However, the number and types of the features that will be used are dependent on the text content; therefore, they cannot be anticipated in advance. Since the enumeration of all described phenomena that can be encountered is infinite, it is not possible to use it as the set of features. All these render difficult the mapping of textual information into manageable datasets that are in standardized form. This scenario is made more critical by the knowledge that linguistic and domain knowledge bases are very expensive to build and almost impossible to generate “on the fly” for any corpus of potentially interesting texts selected or retrieved by some process. Therefore, we must find an easy and systematic approach to impose a simple structure yet one rich and descriptive enough to allow us to use discovery techniques and reveal interesting patterns in texts.Machine learning (ML) [2] is a common approach to solving this problem since it can be applied in cases where a programmer cannot explicitly tell the computer what steps to take. ML algorithms often work well even in scenarios where the programmer provides little input beyond training sets. However, due to the big pool of algorithms, users are often faced with the challenge of selecting the appropriate algorithms that are suitable for the data. Thus, some background knowledge of the data in hand is necessary. For instance, in building a classifier for text fragment categorization, a training set containing lists of texts that contain the features relevant to the categories that we want to assign is required. Fig. 1shows an example list of text expressions that can be used to train a classifier to recognize text fragments about “bombing”.This paper compares EFG, a novel method for learning text structure at the text fragment level [3,4] with ML in categorizing crime incident data. In the EFG method, during training a set of text fragments are prepared and converted into fuzzy grammars. Then, a fuzzy technique is employed to measure the degree of parsing between each derived grammar with the set of texts that it can parse. An advantage of this method is that the learning is done incrementally; the text fragment bearing a new pattern (extension) is adopted into the learnt model with a slight change without the necessity to repeat the whole train–test process. The output of the model is a compact version of fuzzy grammars which represent the set of text fragments selected for training. In contrast, the ML methods are generally statistically founded and require the conventional train–test–retrain when a new pattern is found. It is hypothesized in this research that this makes the whole time involved in this ML higher. An experiment is carried out to compare the performance between EFG and ML methods in precision, recall, F-measure and extension learning. A significance test is performed to measure the difference in mean value within precision, recall and F-measure competency.The main strength of this paper in comparison with previous related works is that it describes completely the steps involved in developing fuzzy grammars using EFG model. This paper also fills the gaps in the limited application of fuzzy approach in text understanding research and demonstrate that fuzzy set in fact has an advantage in text learning problem [5]. In Ref. [4] the authors presented the general step for grammar-grammar combination. In Ref. [6] the highlight was given on the step to combine grammar while Ref. [7] emphasizes the permutation free generated fuzzy grammars. This paper however, integrates and refines the previous mentioned papers by providing more details such as the algorithm for grammar combination and demonstrates this using data that express armed attack and bombing events. This paper also ventures on a new problem on text classification compared to previous smaller scale data used in case study of EFG in Ref. [8] and text extraction task in Refs. [3,9].The paper is organized as follows. Section 1 gives the introduction of the research. Section 2 details the related works which include text categorization and incident management and surveillance. Section 3 focuses on text categorization methods which are used to compare against the introduced method. Section 4 details the main contribution of the paper while the Section 5 provides the evaluation of the method's performance.

@&#CONCLUSIONS@&#
