@&#MAIN-TITLE@&#
Analysis of production characteristics of laughter

@&#HIGHLIGHTS@&#
Production characteristics of laughter are analysed using EGG and speech signals.Three cases are considered: normal speech, laughed-speech and nonspeech-laugh.A modified zero-frequency filtering method is proposed to extract source features.Parameters representing production features are derived to distinguish the 3 cases.These help studying discriminating characteristics of laughter from normal speech.

@&#KEYPHRASES@&#
Laughter analysis,Nonspeech-laugh,Laughed-speech,Modified zero-frequency filtering,Dominant frequency,Closed phase quotient,EGG,Differenced EGG,

@&#ABSTRACT@&#
In this paper, the production characteristics of laughter are analysed at call and bout levels. Data of natural laughter is examined using electroglottograph (EGG) and acoustic signals. Nonspeech-laugh and laughed-speech are analysed in comparison with normal speech using features derived from the EGG and acoustic signals. Analysis of EGG signal is used to derive the average closed phase quotient in glottal cycles and the average instantaneous fundamental frequency (F0). Excitation source characteristics are analysed from the acoustic signal using a modified zero-frequency filtering (mZFF) method. Excitation impulse density and the strength of impulse-like excitation are extracted from the mZFF signal. Changes in the vocal tract system characteristics are examined in terms of the first two dominant frequencies derived using linear prediction (LP) analysis. Additional excitation information present in the acoustic signal is examined using a measure of sharpness of peaks in the Hilbert envelope of the LP residual at the glottal closure instants. Parameters representing degree of change and temporal changes in the production features are also derived to study the discriminating characteristics of laughter from normal speech. Changes are larger for nonspeech-laugh than laughed-speech, with reference to normal speech.

@&#INTRODUCTION@&#
Laughter is a vocal-expressive communicative signal produced by human speech production mechanism, that occurs as either nonlinguistic event or interspersed with normal speech. Laughter signals can have widely varying acoustic features. Laughter characteristics are analysed usually at episode, bout, call or segment levels. An episode consists of two or more laughter bouts, separated by inspirations. A laugh bout is an acoustic event, produced during one exhalation, or inhalation sometimes. The period of laughter vocalization contains one or more laugh-cycles or laugh-pulses, called calls, interspersed with pauses. Calls are also referred to as notes or laugh-syllables. Segments reflect changes in the production mode within a call, that can be seen better in the components of spectrogram (Moore and Von Leden, 1958; Bachorowski et al., 2001). A laughter bout consists of three parts: onset, that has short steep laughter, apex, the vocalization part, and offset, the post-vocalization part in which the smile fades out smoothly (Ruch and Ekman, 2001). Number of calls in a laugh bout (3–8) is limited by the dynamic change (reduction) in the volume of lungs. Typically up to four calls occur in a laugh bout (Provine and Yong, 1991; Rothganger et al., 1998). In this study, laughter is analysed at bout and call levels.Categorization of laughter sounds was carried out in several studies in different ways. Laughter was categorized into three classes: spontaneous laughter, that occurs without restrain on its expression, voluntary laughter, a kind of faked laughter, and singing laughter, that has breathiness, aspiration and phonation with lesser resonance in trachea (Ruch and Ekman, 2001). Three types of laugh bouts were discussed in (Bachorowski et al., 2001): song-like laugh involving pitch modulation of voiced sounds (like in giggle or chuckle), snort-like unvoiced call with salient turbulence in nasal-cavity, and unvoiced grunt-like laugh including breathy pants and harsher cackles. Three classes of vowel quality ha, he and ho of laugh sounds were studied in (Provine and Yong, 1991; Provine, 2000). Laughter was also categorized as voiced laughter, that involves regular vocal fold vibration like in melodic song-like bouts and giggles, and unvoiced laughter, that includes open-mouth breathy sounds, closed-mouth grunts and nasal-snorts (Owren and Bachorowski, 2003). The continuum from speech to laugh was divided into speech, speech-laugh and laugh (Nwokah et al., 1999; Menezes and Igarashi, 2006). Laughter in dialogic interaction was categorized as: speech-smile, speech-laugh and laughter (Kohler, 2008). Four phonetic types of laughter were studied in (Campbell et al., 2005; Tanaka and Campbell, 2011): voiced, chuckle, breathy ingression and nasal-grunt.Since laughter signal is produced by human speech production mechanism, its production characteristics can be analysed in terms of the excitation source and vocal tract system characteristics, like for normal speech. Significant changes apparently take place in the characteristics of the excitation source, during production of laughter. But, acoustic analyses of laughter have been carried out mostly using spectral and perceptual features (Bickley and Hunnicutt, 1992; Bachorowski et al., 2001; Truong and Leeuwen, 2007; Makagon et al., 2008). Features such as fundamental frequency, root mean square amplitude, time duration and formant structure were examined in the acoustic analysis (Bickley and Hunnicutt, 1992), to discriminate laughter and speech. Acoustic features such as F0, number of calls per bout, spectrograms and formant clusters (F2 vs F1) were used for analysing temporal and source-filter effects of laughter (Bachorowski et al., 2001). In a study, rhythm (duration) and changes in F0 were used as features for evaluating laughter bouts (Kipper and Todt, 2003). Pairwise feature combinations such as pitch-energy, global pitch-voicing, perceptual linear prediction-modulation spectrum were used for modeling laughter and speech (Truong and Leeuwen, 2005). Another study used the degree of variation in F0, intensity and durational patterning (onset, main part, pause and offset) features for assessing naturalness of synthesized laughter (Lasarcyk and Trouvain, 2007). Source feature like glottal open quotient were considered along with spectral tilt (Menezes and Igarashi, 2006), but these features were derived (approximately) from differences in amplitudes of harmonics in the spectrum. Features such as instantaneous pitch period, strength of excitation, and their slopes and ratio were proposed for laughter analysis (Sudheer Kumar et al., 2009).In the current study, we examine changes in the glottal excitation source characteristics and associated changes in the vocal tract system characteristics, during production of laughter. Laughter at bout and call levels is analysed. Production characteristics of the speech-laugh continuum are analysed in three categories: normal speech (NS), laughed-speech (LS) and nonspeech-laugh (NSL). Laughed-speech consists of (linguistic) speech interspersed with (nonlinguistic) laugh content to some degree. Only voiced nonspeech-laugh, produced spontaneously, is considered. Data consists of natural laugh responses. In each case, both electroglottograph (EGG) (Fant et al., 1985) and acoustic signals are examined. Changes in the glottal vibration characteristics are examined using features such as closed phase quotient in each glottal cycle (Mittal and Yegnanarayana, 2013a) and F0 (i.e.,F0EGG), both derived using the differenced EGG signal (Gobl, 1988). Excitation source features are also extracted from the acoustic signal using a modification of the zero-frequency filtering (ZFF) method (Murty and Yegnanarayana, 2008). Features such as excitation impulse density and strength of excitation are derived. Changes in the vocal tract system characteristics are examined using the first two dominant frequencies (FD1andFD2) (Mittal and Yegnanarayana, 2013b), derived from the acoustic signal using linear prediction (LP) analysis (Makhoul, 1975). Production features are also examined using a sharpness measure (Seshadri and Yegnanarayana, 2009) of peaks in the Hilbert envelope of LP residual (Markel and Gray, 1982) of the acoustic signal around glottal closure instants. Voiced/nonvoiced decision (Dhananjaya and Yegnanarayana, 2010) is based on the framewise energy of the modified ZFF output signal. Parameters derived to measure the degree of changes and temporal changes in the production features are also explored to discriminate NS, LS and NSL.The paper is organized as follows. Section 2 discusses details of the data collected for this study. The signal processing methods used for deriving the source and system characteristics are discussed in Section 3. Changes in the glottal source characteristics in production of laughter are examined from the EGG signal in Section 4. Section 5 examines changes in the production characteristics of source and system derived from the acoustic signal. Results of the study are discussed in Section 6. Finally, a summary is given in Section 7, along with scope for further work.The data of laughter (LS and NSL) was collected by eliciting spontaneous natural laughter responses by subjects. Series of hilarious/comedy audio-visual clips and/or jokes audio clips from online media sources were played to each subject. The subjects were asked to use 3 texts in their natural responses and express themselves, in case they really liked the comedy or joke. The texts are: (i) “It is a good joke.” (ii) “It is really funny.” (iii) “I have enjoyed.” The idea of using predefined texts was to help subjects express their natural responses with minimal text-related variability in the acoustic features. The laughter (LS and NSL) responses and normal speech (NS) were recorded in each case. Normal speech for speakers was also recorded for the utterance of a fourth (neutral) text (iv) “This is my normal voice.” Both acoustic and EGG signals were recorded in parallel, in each case. Data was recorded from 11 speakers (7 males and 4 females), all research scholars at IIIT, Hyderabad. The nonspeech-laugh calls occur mostly prior to (or sometimes after) the laughed-speech calls in the utterance of a text. The data has total 191 (NSL/LS) calls in 32 utterances of natural laughter bouts/responses, and 130 (NS) voiced segments of normal speech in 35 utterances, from 11 speakers.EGG signal was recorded using a EGG recording device [EGGs for Singers (Miller, 2012)]. Changes in the glottal impedance during vocal folds vibration are captured in the EGG signal, but not the changes in air pressure in the glottal region. The corresponding acoustic signal was recorded using a close-speaking stand-mounted microphone (Sennheiser ME-03), kept at a distance of about 15 cm from the speaker. The data was collected in normal room conditions (ambient noise of about 50dB), at a sampling rate of 48kHz with 16bits/sample. The data was downsampled to 10kHz before analysis. The ground truth for the data of nonspeech-laugh and laughed-speech was established by listening to each audio file. The data can be downloaded (upon request) from the link: “http://speech.iiit.ac.in/svldownloads/svllaughdata/”.The production characteristics of laughter are analysed in terms of features of the excitation source and the vocal tract system, to examine the differences in the laughed-speech and nonspeech-laugh with reference to normal speech. The features are derived from both EGG and acoustic signals. Since it is difficult to derive the excitation component of the signal precisely, certain features that reflect the excitation characteristics are used in this analysis. The proportion of closed phase region in each glottal cycle (Mittal and Yegnanarayana, 2013a) and the instantaneous fundamental frequency are derived from the EGG signal. Parameters reflecting the impulse-like excitations within each glottal cycle and the sharpness of the major excitation at the glottal closure instants (GCIs) are derived using suitable signal processing methods. In particular, the ZFF method of extracting GCIs (Murty and Yegnanarayana, 2008; Yegnanarayana and Murty, 2009) is modified to derive a modified ZFF signal, which can capture the impulse-like excitation characteristics, besides some other information. The Hilbert envelope of the LP residual is considered to characterize the sharpness of the peaks around GCIs. The vocal tract system characteristics are represented in terms of the first two dominant frequencies of the short-time spectrum. These frequencies are derived using a low-order (5th) linear prediction analysis. Note that these frequencies correspond to the region where the average short-time spectral energy is large. One or both of the dominant frequencies may correspond to resonances of the vocal tract in a few cases, when one or both the spectral peaks are strong and distinct. In this section, the signal processing methods used to extract the different features characterizing the excitation source and the vocal tract system are described. They include modification in the ZFF method (Murty and Yegnanarayana, 2008), and deriving group delay from LP spectrum (Makhoul, 1975; Murthy and Yegnanarayana, 1991).(a)Let xin[n] be the speech signal. The differenced speech signal is given by(1)s[n]=xin[n]−xin[n−1]Pass the differenced speech signal s[n] through a cascade of two ideal digital filters, called zero-frequency resonators (ZFRs) (Murty and Yegnanarayana, 2008). Each ZFR has a pair of poles located on the unit circle in the z-plane. The output of the ZFRs is given by(2)y1[n]=−∑k=12aky1[n−k]+s[n]y2[n]=−∑k=12aky2[n−k]+y1[n],where a1=−2, a2=1. Successive integration-like operations result in a polynomial growth/decay trend in its output y2[n], as illustrated in Fig. 1(b), for the nonspeech-laugh bout signal in Fig. 1(a).A trend removal for modal voicing (Murty and Yegnanarayana, 2008) is normally carried out by subtracting local mean computed over a window of size 2N+1 samples, whose duration is between 1 and 2 times the average pitch period (T0). But, for nonmodal voices such as laughter, the trend removal operation is applied in stages using gradually reducing window sizes. The gross trend is removed by successive mean subtraction over window sizes of 20ms, 10ms and 5ms. Then, the window sizes of 3ms, 2ms and 1ms are used successively for computing the local mean. The trend removed output after each stage is given by(3)y2˜[n]=y2[n]−12N+1∑l=−NNy2[n+l]where the window size is 2N+1 samples. The final trend removed output is called the modified zero-frequency filtered (mZFF) signal (zmx[n]). An illustration of the mZFF signal is shown in Fig. 1(c), for the acoustic signal in Fig. 1(a). The detection of voiced/non-voiced (V/NV) regions (Dhananjaya and Yegnanarayana, 2010) is based on the framewise energy of the mZFF signalzmx[n]. An illustration of V/NV regions for the laughter signal is shown in Fig. 1(d). The unmodified ZFF signal (zx[n]) and the modified ZFF signal (zmx[n]) are shown separately for the segment (0.2–0.3s in Fig. 1) of laughter in Fig. 2, to illustrate the result of the modification of the ZFF method. The mZFF signal (zmx[n]) in Fig. 2(c) highlights the significant excitation within each glottal cycle better. Features are derived using this in Section 5, to discriminate laughter and normal speech.For modal voicing, the locations of (negative to positive going) zero-crossings of ZFF signal (computed using about 1.5Tavefor window for trend removal) correspond to the GCIs (epochs) (Murty and Yegnanarayana, 2008). The instantaneous fundamental frequency (F0) is computed from the inverse of the period (T0) between successive epochs (Yegnanarayana and Murty, 2009). But in the case of nonmodal voices like laughter, it is expected that there may be many instants of impulse-like excitation (including secondary ones), which makes it difficult to extract the GCI locations uniquely. However, these multiple excitations may result in several zero-crossings in the modified ZFF signal. It is possible that some of the zero-crossings in the mZFF signal may not correspond to impulse-like excitation. But, the behaviour of mZFF signal, in terms of number of zero-crossings and also the strength of excitation SoE at GCIs, are used to characterize the excitation component. The SoE is derived from the slope of the mZFF signal at GCIs (obtained from EGG).An illustration of F0 and SoE (ψ) contours for calls in a nonspeech-laugh bout is given in Fig. 3(b) and (c), respectively, for the acoustic signal (xin[n]) shown in Fig. 3(a).Changes in the vocal tract system characteristics are captured using the first two dominant resonant frequencies (FD1andFD2) derived from the acoustic signal (Mittal and Yegnanarayana, 2013b). These frequencies may correspond to resonance frequencies in a few cases. The steps involved in computing the dominant frequencies (FD1andFD2) are as follows:(a)The all-pole filter H(z) obtained using linear prediction (LP) analysis is given by (Makhoul, 1975):(4)H(z)=11−∑k=1pakz−k,where {ak} are LP coefficients (k=1, 2, …, p), that capture the vocal tract system information for each analysis frame. For a 5th order LP analysis, the LP spectrum will have maximum two peaks, corresponding to two complex conjugate pole pairs. The frequencies corresponding to these two peaks are termed as dominant frequencies, denoted asFD1andFD2, respectively. These dominant frequencies give the frequency response with high spectral energies, thus giving an idea of the concentration of energy in the spectrum.The dominant frequencies can be computed better from the coefficients {ak} using the group delay function (Murthy and Yegnanarayana, 1991, 2011). Group delay function is the negative derivative of the phase response of the all-pole filter (Murthy and Yegnanarayana, 1991). If the complex frequency response of the filter is H(ejw)=|H(ω)|ejθ(ω), then the group delay function is given by(5)τg(ω)=−dθ(ω)dωThe frequency locations of the peaks in the group delay function give the dominant frequencies (FD1andFD2).An illustration ofFD1andFD2contours for laughter is shown in Fig. 3(d) for the acoustic signal in Fig. 3(a).Glottal vibration characteristics of laughter are examined from the EGG signal. Changes are examined in the closed phase quotient (α) in each glottal cycle. The open/closed phase durations are computed using the differenced EGG (dEGG) signal (Gobl, 1988), as illustrated in Fig. 4. Peaks and valleys in the dEGG signal (dex[n]) correspond nearly to the positive going and negative going zero-crossings in the EGG signal (ex[n]), respectively. Peaks in the dEGG indicate glottal closure instants (GCIs). The region in a glottal cycle from peak to valley in dEGG is considered as closed phase of duration Tc, and the region from valley to peak in dEGG as open phase of duration To. The closed phase quotient is α=Tc/(To+Tc). An illustration of the acoustic signal (xin[n]), EGG signal (ex[n]), dEGG (dex[n]) and the α contour is given in Fig. 5(a)–(d), respectively, for calls in NSL bout and in LS bout. The NSL calls are marked in Fig. 5(d) as regions 1, 2, 3, 4 and the LS calls as 5, 6, 7, 8.The average of α values (i.e., αave) and the standard deviations in α (i.e., σα) are computed for each speaker, for normal speech, laughed-speech and nonspeech-laugh. The changes in α are represented using a parameter β(6)β=σααave×100In Table 1, the β values for the three cases of NS, LS and NSL are given in columns (a), (b) and (c), respectively. Changes in β for LS and NSL from NS, i.e., ΔβLS(%)=((βLS−βNS)/βNS)×100 and ΔβNSL(%)=((βNSL−βNS)/βNS)×100, are given in columns (d) and (e), respectively. The β and Δβ values are rounded to integers. The average β values for NS, LS and NSL cases are 19, 23 and 38, respectively. Across speakers, the increase in β is higher for nonspeech-laugh than laughed-speech, with reference to normal speech. It means, across speakers the closed phase quotient α reduces more for nonspeech-laugh than laughed-speech. In some cases of individual speakers (e.g., S10), the β value for NS is higher, though β value for NSL is higher than LS in this case as well.The observation that the instantaneous fundamental frequency (F0) rises in a laughter call (Bickley and Hunnicutt, 1992; Bachorowski et al., 2001; Kipper and Todt, 2003; Menezes and Igarashi, 2006), is confirmed in this study by the analysis from EGG signal. The F0 values (i.e.,F0EGG) are computed from the inverse of the glottal cycle periods (T0EGG) obtained using the dEGG signal, as illustrated in Fig. 5. In Table 1, average F0 (in Hz) for the three cases NS, LS and NSL, are given in columns (f), (g) and (h), respectively. Changes in average F0 for LS/NSL from NS, i.e.,ΔF0LS(%)=F0LS−F0NS/F0NS×100andΔF0NSL(%)=F0NSL−F0NS/F0NS×100are given in columns (i) and (j), respectively. The values are rounded to integers. Across speakers, the changes in average F0are larger for nonspeech-laugh than for laughed-speech. The average rise in F0 for nonspeech-laugh and laughed-speech, with reference to normal speech, is 44% and 23%, respectively.It is interesting to observe that the average α values (αave) for calls within a NSL/LS laugh bout also show some inter-calls increasing/decreasing trend. An illustration of inter-calls changes in αavefor the calls in NSL and LS bouts is given in the voice of a male speaker and a female speaker, in Fig. 6(a) and (b), respectively. For nonspeech-laugh there is decrease in αavefor successive calls in bout. The inter-calls trend in the average F0 values (F0ave) also is observed for the calls in NSL and LS bouts of a male speaker and a female speaker, as illustrated in Fig. 6(c) and (d), respectively. The trends of inter-calls changes in αaveandF0aveare indicative of the (inter-calls) growth/decay characteristics of natural laughter bouts. Higher F0and Lower α for NSL calls, compared to LS calls, can also be observed for both the speakers.The analysis from EGG/dEGG signal highlights some interesting changes in the glottal vibration characteristics during production of laughter. But, two practical limitations in using the EGG signal are: (i) EGG captures changes in the glottal impedance (related with air flow), not the air pressure in glottal region, and (ii) collecting EGG signal may not be practically feasible at all times. Hence, the excitation source characteristics are examined from acoustic signal in next section.The excitation source characteristics of laughter are derived from the acoustic signal using a modified ZFF (mZFF) method discussed in Section 3.1. Two features, namely, density of excitation impulses (dI) and strength of impulse-like excitation (SoE) are extracted from the mZFF signal (zmx[n]). Changes in the source characteristics are analysed by measuring the degree of changes and the temporal changes in these features. Parameters capturing the degree of changes in features are computed using the average values and standard deviation. Temporal parameters are derived by capturing the temporal changes in features. Changes in the parameters for laughed-speech and nonspeech-laugh are compared, with reference to normal speech.All the negative to positive going zero-crossings of the mZFF signal (zmx[n]) may indicate impulse-like excitation at those time-instants. Some of these zero-crossings correspond to epochs (i.e., GCIs). An illustration of few glottal cycles of acoustic signal (xin[n]), EGG signal (ex[n]) and mZFF signal (zmx[n]) is given in Fig. 7(a)–(c), respectively. The presence of impulse-like excitation in-between some successive epochs can be observed in the acoustic signal (Fig. 7(a)) and in the mZFF signal (Fig. 7(c)), but the same is not visible in the EGG signal (Fig. 7(b)). This presence of more than one pulses in a glottal cycle is possibly related to the secondary excitation, also observed in the context of LPC vocoders (Holmes, 1976; Atal and Remde, 1982). The role of these secondary excitation pulses in the production of laughter is examined in this section.In laughter production, the extra zero-crossings seem to occur within almost each glottal cycle, in addition to those corresponding to the epochs, as can be observed in the modified ZFF signal (zmx[n]) in Fig. 7(c). Whether these additional zero-crossings are related to the characteristics of the excitation source or the vocal tract system, can be ascertained by observing the spectrograms in Fig. 8, for a few nonspeech-laugh calls. The spectrogram of a epoch sequence that has impulses located at only epochs with amplitude as SoE shows the source characteristics (Fig. 8(c)). It can be compared with the spectrogram shown in Fig. 8(d), for a sequence of impulses located at all negative to positive going zero-crossings ofzmx[n]with amplitude representing the strength of excitation around these instants. Both spectrograms in Fig. 8(c) and (d) are quite similar. It may also be noticed that the spectrogram in Fig. 8(d) does not show any formants-like characteristics that can be observed in the spectrogram in Fig. 8(b) for the acoustic signal. Similar observations are made from the spectrograms of laughter calls of other speakers. Hence, it may be inferred that the additional zero-crossings inzmx[n]are related to the characteristics of the excitation source only, and not of the vocal tract system.These additional zero-crossings can also help in discriminating the three cases NS, LS and NSL. A feature termed as ‘density of excitation impulses’ (dI) is obtained from all the successive negative to positive going zero-crossings of the mZFF signal (zmx[n]). Feature dIrepresents instantaneous density of the impulse-like excitation at such zero-crossings in the unit ‘number of impulses per sec’. Changes in dIare analysed in two ways, by measuring the degree of changes and temporal (intra-call) changes in the dIcontour.The average dIvalues (i.e.,dIave) and standard deviations in dI(i.e.,σdI) are computed for each speaker, for the three cases NS, LS and NSL. Changes in dIare reflected in a parameter γ1(7)γ1=dIave×σdI1000wheredIaveandσdIare computed over each LS/NSL call and NS voiced region. In Table 2, the average γ1 values for each speaker are given in columns (a), (b) and (c) for the three cases NS, LS and NSL, respectively. Changes in γ1 for LS and NSL from NS, i.e.,Δγ1LS(%)=γ1LS−γ1NS/γ1NS×100andΔγ1NSL(%)=γ1NSL−γ1NS/γ1NS×100, are given in columns (d) and (e), respectively. The values are rounded to integers. The average γ1 values for NS, LS and NSL, are 54, 48 and 69, respectively. For most of the speakers, |Δγ1|NSL>|Δγ1|LS, i.e., the degree of changes in γ1is more for nonspeech-laugh than for laughed-speech, with reference to normal speech.Changes in the dIcontours are observed to be more rapid than those in F0 contours. Hence, temporal changes in the dIcontour are captured by a parameter ϕ, that is computed using ΔdIbetween all successive (negative to positive going) zero-crossings of the mZFF signal (zmx[n]). The temporal measure for dI, i.e., parameter ϕ, captures the rate of temporal change in dIfor a call.(8)ϕ=1N∑i=1NΔd′IΔt,i=1,2,…,Nwhered′I=ΔdI/Δtis the temporal change (per sec) in impulse density, and N is number of all (negative to positive going) zero-crossings ofzmx[n]in that call. An illustration of the temporal measure ϕ is given in Fig. 9, in which larger changes in ΔdIcan be observed for NSL calls than for LS calls.In Table 2, average ϕ values for each speaker are given in columns (f), (g) and (h), for NS, LS and NSL, respectively. Changes in ϕ for LS and NSL in comparison with NS, i.e., ΔϕLS(%)=((ϕLS−ϕNS)/ϕNS)×100 and ΔϕNSL(%)=((ϕNSL−ϕNS)/ϕNS)×100, are given in columns (i) and (j), respectively. Average ϕ values for NS, LS and NSL, are 96, 78 and 138, respectively. In general, higher changes in average ϕ for nonspeech-laugh can be observed in column (j). Interestingly, the changes in the temporal measure ϕ (i.e., Δϕ) in columns (i), (j), are mostly in line with changes in the parameter γ1 (i.e., Δγ1) that captures degree of changes in dI, in columns (d), (e). Both parameters γ1 and ϕ, derived from the feature dI(impulse density), are useful in discriminating between laughter and normal speech.In the production of laughter, changes in the characteristics of the glottal excitation source are reflected in two ways: (i) in the locations of epochs (GCIs) or ‘all’ (positive going) zero-crossings of the mZFF signal (zmx[n]), both manifested as changes in F0 and dI, respectively, and (ii) in the amplitude represented as the strength of impulse-like excitation (SoE, i.e., ψ) at the epochs. Similar to dI, changes in the SoE for laughter (LS/NSL) calls, with reference to normal speech (NS), are also analysed in two ways, by measuring the degree of changes and temporal (intra-call) changes in the SoE contour.The average SoE values (i.e., ψave) and standard deviation in ψ (i.e., σψ) are computed for each speaker, for NS, LS and NSL. Changes in SoE are represented using a parameter γ2(9)γ2=σψψave×100where σψand ψaveare computed for each LS/NSL call and NS voiced region. In Table 3, the average γ2 values computed for each speaker are given in columns (a), (b) and (c), for the three cases NS, LS and NSL, respectively. Changes in γ2 for LS and NSL from NS, i.e.,Δγ2LS(%)=γ2LS−γ2NS/γ2NS×100andΔγ2NSL(%)=γ2NSL−γ2NS/γ2NS×100, are given in columns (d) and (e), respectively. The values are rounded to integers. The average γ2 values for NS, LS and NSL are 57, 60 and 65, respectively. For most speakers, the changes in parameter γ2, with reference to normal speech, are larger for nonspeech-laugh than for laughed-speech.Temporal changes in SoE (ψ) contour are captured through a parameter ρ, like parameter ϕ for dI. The parameter ρ comprises of two factors, a monotonicity factor (mψ) and a duration factor (δtψ). The monotonicity factor (mψ) captures the monotonically increasing trend of SoE within a call. Hence, the (+)ve signed Δψ values are considered in each window. The duration factor (δtψ) captures the percentage duration of a call that has similar (+ve) signs of SoE in each window. The temporal measure for ψ, i.e., parameter ρ=mψ×δtψ, is computed as:(10)mψ=∑i=1n∑j=15Δψ|+,i=1,2,…,n,j=1,2,…,5(11)δtψ=NGC+NGCseg×1tdseg(12)ρ=∑i=1n∑j=15Δψ|+×NGC+NGCseg×1tdsegwhere i is index of window (each of size of 5 successive pitch periods) in a call, n is number of such windows in a laugh call, and j is index of Δψ values of same (+ve) sign within each window. Here,NGC+is number of glottal cycles (epochs) having Δψ of same (+)ve sign, andNGCsegis total number of epochs within a laugh call or NS voiced segment of durationtdseg(in ms).In Table 3, the average values of parameter ρ for each speaker are given in columns (f), (g) and (h) for NS, LS and NSL, respectively. Changes in average ρ for LS and NSL from NS, i.e., ΔρLS(%)=((ρLS−ρNS)/ρNS)×100 and ΔρNSL(%)=((ρNSL−ρNS)/ρNS)×100, are given in columns (i) and (j), respectively. The values are rounded to integers. The average values for NS, LS and NSL are 39, 35 and 54, respectively. In general, the degree of changes in parameter ρ (i.e., Δρ) are larger for nonspeech-laugh than for laughed-speech, with reference to normal speech. Also, the temporal changes in SoE (ψ) measured using the parameter ρ, are mostly in line with degree of changes in SoE captured using the parameter γ2.In the production of laughter, since there occur rapid changes in the excitation source characteristics, it is possible that there occur associated changes in the vocal tract system characteristics as well. The average values ofFD1andFD2(i.e.,FD1aveandFD2ave, respectively) are computed for each speaker, for the three cases NS, LS and NSL. An illustration of the distribution ofFD2vsFD1for LS and NSL bouts produced by a male speaker is given in Fig. 10. The points (FD1ave,FD2ave) are marked as centroids for LS and NSL bouts. It may be observed that distinct clusters are formed by the relative distribution ofFD1andFD2for nonspeech-laugh and laughed-speech.While there are some differences in the distribution ofFD1andFD2for NSL and LS call regions, it is difficult to practically use these vocal tract system features for discriminating between nonspeech-laugh and laughed-speech.Apart from the glottal excitation source and the vocal tract system characteristics examined earlier in this section, the acoustic signal consisting of laughter seems to carry some additional information that humans can perceive easily. This information may possibly be extracted from LP residual (Markel and Gray, 1982) of the acoustic signal. This additional information of the production characteristics of laughter is derived from the Hilbert envelope (Oppenheim and Schafer, 1975) of LP residual of the acoustic signal. Two features are extracted, the amplitude (hp) and sharpness measure (η) of peaks in the Hilbert envelope (HE) of the LP residual at GCIs (Seshadri and Yegnanarayana, 2009). The sharpness measure (η) is observed to be useful in discriminating the NS, LS and NSL cases.An illustration of peaks in the Hilbert envelope of LP residual at GCIs is given in Fig. 11(a)–(c), for the three cases NS, LS and NSL, respectively. Normalized values of HE peaks (hp) are used. The peaks are narrower and sharper for nonspeech-laugh in comparison with laughed-speech calls. Also, the width of peaks (near half-height level) is relatively more for NS than for LS/NSL calls. The degree of sharpness of these peaks can be compared in terms of the sharpness measure η (Seshadri and Yegnanarayana, 2009)(13)η=1N∑i=1Nσhn(xw)μhn(xw)|xw=xi−l1toxi+l2,i=1,2,…,Nwhere i is index of epoch within a laugh (NSL/LS) call or NS voiced region, and N is total number of epochs in the segment. Here,σhnandμhnare standard deviation and mean of the normalized values of Hilbert envelope (hn), computed over a window (xw) of size xi−l1 to xi+l2 located at xifor ith epoch. Normalized (hn) values are obtained by dividing the hpvalues in the window at xi, by the amplitude at xi. A lower value of η indicates a comparatively sharper (i.e., less spread) peak.The average η values (i.e., ηave) and standard deviations in η (i.e., ση) are computed for each speaker, for NS, LS and NSL cases. Changes in η are represented using a parameter ξ(14)ξ=σηηave×1000where ηaveand σηare computed for each LS/NSL call and NS voiced regions. In Table 4, the average values of parameter ξ for each speaker are given in columns (a), (b) and (c), for NS, LS and NSL, respectively. Changes in ξ for LS and NSL cases from NS, i.e., ΔξLS(%)=((ξLS−ξNS)/ξNS)×100 and ΔξNSL(%)=((ξNSL−ξNS)/ξNS)×100, are given in columns (d) and (e), respectively. The values are rounded to integers. The average ξ for NS, LS and NSL are 268, 263 and 250, respectively. For most speakers, larger changes (mostly reduction) in ξ occur for nonspeech-laugh than for laughed-speech, with reference to normal speech. It indicates that peaks of Hilbert envelope of LP residual (at GCIs) are generally more sharp (less spread) for laughter (NSL/LS) calls than for normal speech. It is possible that this increased sharpness of HE peaks is related to faster rate of closing (abrupt closure) of the vocal folds, during production of laughter.Production characteristics of laughter are examined in this study using the EGG and acoustic signals, in terms of: (i) source features α, F0, dIand SoE, (ii) system featuresFD1andFD2, and (iii) other production features hpand η. Parameters derived from these features, that distinguish laughter (LS/NSL) calls and NS voiced regions, can be summarized as:(i)parameter β, derived from the closed phase quotient (α) using EGG signalparameters γ1 and ϕ, derived from the source feature dI(impulse-density) using acoustic signalparameters γ2 and ρ, derived from the source feature SoE (i.e., ψ) using acoustic signalparameters ξ, derived from the other production feature η using acoustic signalAnalysis from EGG signal indicates that closed phase quotient (α) within each glottal cycle is reduced for laughter, in comparison to normal speech. The reduction in α is more for nonspeech-laugh than laughed-speech. It is reflected in the increase in β from normal speech, i.e., Δβ, which is more for nonspeech-laugh, across all speakers (Table 1). Also, the glottal cycle period (T0) is reduced more for nonspeech-laugh than laughed-speech, which is reflected in larger F0 for nonspeech-laugh (Table 1). Thus, significant changes in the characteristics of the glottal source of excitation indeed take place, during production of laughter.Interestingly, there also occurs gradual inter-calls decreasing trend in the average α over successive calls in a NSL bout (Fig. 6). The inter-calls rising/falling trend is also observed in the average F0 for (LS/NSL) laugh calls in a bout, which is in-line with an earlier study (Bachorowski et al., 2001).The excitation source characteristics are also analysed from the acoustic signal, in terms of features dIand SoE derived using a modified ZFF method proposed in Section 3.1. In the production of laughter, the possible presence of amplitude modulation of some higher frequency content (around 500-1000Hz) (Rothganger et al., 1998) can be observed in the acoustic signal (Fig. 7(a)), but not in the EGG signal (Fig. 7(b)). It is possibly related to the presence of secondary excitation pulses in each glottal cycle (Holmes, 1976; Atal and Remde, 1982), which gives rise to number of (negative to positive going) zero-crossings that are additional to regular GCIs (epochs). Their time-instants can be captured using the mZFF signal (Fig. 7(c)). These additional zero-crossings can be exploited for discriminating laughter from normal speech. A feature dIrepresents the density of excitation impulses located at all (positive going) zero-crossings of the mZFF signal (zmx[n]). Changes in dI, reflected in a parameter γ1, are higher for nonspeech-laugh than laughed-speech, with reference to normal speech (Table 2). Changes in the strength of excitation (SoE) (i.e., ψ), reflected in a parameter γ2, are also larger for nonspeech-laugh than laughed-speech, for most speakers (Table 3).Temporal parameters ϕ and ρ capture temporal changes in the features dIand SoE (ψ), respectively. Changes in ϕ and ρ are larger for nonspeech-laugh than laughed-speech (Tables 2 and 3). Similarity of results in discriminating between laughter and normal speech by two approaches, using the parameters γ1, γ2 and the temporal parameters ϕ, ρ, validates the approaches as well as the results.Changes in the vocal tract system characteristics during production of laughter are examined in terms of dominant frequenciesFD1andFD2, derived from the acoustic signal. The distribution ofFD2vsFD1(Fig. 10) may help in discriminating between NSL and LS bouts in some cases, which is similar to formants-clusters used in Bachorowski et al. (2001). But, it is difficult to use it practically.The additional information present in the acoustic signal of laughter, is examined in terms of the sharpness of peaks in the Hilbert envelope of LP residual at GCIs (Fig. 11). Changes (mostly reduction) in the sharpness measure (η), examined in terms of parameter ξ, are larger for nonspeech-laugh than for laughed-speech, with reference to normal speech (Table 4).Changes in all the parameters indicate that in general, larger changes take place in the production characteristics (mostly in the source) for nonspeech-laugh than for laughed-speech, with reference to normal speech.In this study, the production characteristics of laughter are examined from both EGG and acoustic signals. The speech-laugh continuum is analysed in three categories, namely, normal speech, laughed-speech and nonspeech-laugh. Data was collected by eliciting natural laughter responses. Three texts were used for comparing the laughed-speech and normal speech. Laughter data is examined at call and bout levels. Only, voiced cases of spontaneous laughter are considered. The excitation source features are extracted from both the EGG and acoustic signals. The vocal tract system features are extracted from the acoustic signal, along with some production characteristics related to both source and system. Parameters representing changes in these features are derived, to distinguish the three cases.The closed phase quotient (α) of glottal cycles and the instantaneous fundamental frequency (F0) are obtained from the analysis of EGG signal. Average α reduces and F0 increases more for nonspeech-laugh than laughed-speech, with reference to normal speech. The average values of α and F0 also exhibit some inter-calls decreasing/increasing trend for (LS/NSL) laughter bouts.The excitation source characteristics are derived from the acoustic signal using a modified zero-frequency filtering method proposed in this paper. In the acoustic signal of laughter, the likely presence of secondary impulse-like excitation is examined in terms of density of impulses (dI) and the strength of excitation (SoE), derived from the mZFF signal (zmx[n]). Parameters β, γ1 and γ2 represent the degree of changes in the source features α, dIand SoE, respectively. Results are validated using two temporal parameters ϕ and ρ derived from the source features dIand SoE, respectively. Changes in all these parameters are larger for nonspeech-laugh than laughed-speech, with reference to normal speech. These parameters also discriminate well the three cases (NS, LS and NSL).Changes in the vocal tract system characteristics are examined in terms of the first two dominant frequenciesFD1andFD2derived from the acoustic signal using LP analysis. The features discriminate between laughter and normal speech, in some cases. Additional excitation information present in the acoustic signal of laughter is examined using the Hilbert envelope of the LP residual around epochs, in terms of sharpness (η) of HE peaks. Parameter ξ derived from the feature η helps in further discriminating the three cases.In this study, the unvoiced grunt-like or snort-like laughs are not focused. Also, changes in the vowel-like nature of different laughter-types may be studied further. However, the production source characteristics of laughter examined in this study and the parameters derived, should be useful in further developing systems for automatic detection of laughter in continuous speech.

@&#CONCLUSIONS@&#
