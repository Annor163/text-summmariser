@&#MAIN-TITLE@&#
Face gender classification: A statistical study when neutral and distorted faces are combined for training and testing purposes

@&#HIGHLIGHTS@&#
Study of gender recognition from neutral, expressive and occluded facesComparison of global/local approaches, grey level/PCA/LBP features and three classifiersThree statistical tests over two performance measures are employed to support the conclusions.Local models surpass global ones with different types of training and test faces.Global and local models perform equally with the same type of training and test faces.

@&#KEYPHRASES@&#
Face analysis,Gender classification,Global/local representation,Cross-database experiment,

@&#ABSTRACT@&#
This paper presents a thorough study of gender classification methodologies performing on neutral, expressive and partially occluded faces, when they are used in all possible arrangements of training and testing roles. A comprehensive comparison of two representation approaches (global and local), three types of features (grey levels, PCA and LBP), three classifiers (1-NN, PCA+LDA and SVM) and two performance measures (CCR and d′) is provided over single- and cross-database experiments. Experiments revealed some interesting findings, which were supported by three non-parametric statistical tests: when training and test sets contain different types of faces, local models using the 1-NN rule outperform global approaches, even those using SVM classifiers; however, with the same type of faces, even if the acquisition conditions are diverse, the statistical tests could not reject the null hypothesis of equal performance of global SVMs and local 1-NNs.

@&#INTRODUCTION@&#
Classifying demographic traits such as gender, age and race is useful in countless tasks. In particular, gender classification can be applied to dynamic market studies, human–computer interaction, personalised services in a large number of businesses, among others.In the area of face analysis, face recognition [1–6] and facial expression analysis [7–10] are extensively studied compared to the gender classification problem which is addressed less often [11,12]. This could partly be due to a general belief that gender classification is similar to a face recognition problem with only two classes. To the best of our knowledge, there are not published studies that support this statement by exploring the performance differences of automatic systems when dealing with face recognition and gender classification. However, these studies are easily found in the psychology literature [13–15]. In [13], it is clearly stated that, in order to identify a face, the information that makes it unique has to be encoded. In contrast, to recognize the gender of a face the information encoded must be shared by a group of different faces (male or female). From the point of view of data complexity, gender classification is a 2-class problem with a generally large number of face images per class from different people resulting in sparse classes, while face recognition is a multi-class problem with usually very few faces per class that belong to the same individual. Therefore, gender classification problems have commonly a much higher intra-class variance than face recognition problems.Many believe that systems designed to address a face recognition problem generally succeed in gender classification. After the explanation above, it seems clear that this is not always true. One example could be the well-known face recognition system proposed by Martinez [1]. It uses only one training sample per class. When addressing a gender classification problem, it is desirable to have a broad and diverse training data set so each gender could be as well characterised as possible. For this reason, this would not be the best approach to deal with gender classification.Although the concept of gender is universally known, what type of information allows automatic systems to discriminate between male and female faces is not clear yet. According to psychological studies [16], humans use configural and featural information for recognizing faces, although it is possible for us to perform quite well in the absence of one of them. Since humans use both types of information when analysing faces, some authors have decided to use global (configural information) as well as local (featural information) descriptors assuming that it will ease the problem of classifying gender on automatic systems. Based on this idea, studies combining local and global features [17,18] conclude that using both types of features provides better face characterisations and hence better classification rates than using just one of them. It should be noted that these studies used occlusion-free face images.Most of the areas where automatic gender classification has interesting applications are usually set in real environments where the accessories and clothes worn by subjects are beyond our control, and people express their feelings through facial expressions. These are the main reasons why automatic gender classification systems should be able to properly classify expressive and partially occluded face images. Many studies have been published proposing several methodologies for recognizing faces in the presence of occlusions [1,5,6], as opposed to the very few published studies on gender classification of occluded faces [19]. Toews and Arbel [19] propose a methodology for classifying visual traits using the Object Class Invariant (OCI) model. Faces are described by an OCI consisting of a segment line from the bottom of the nose to the forehead and a set of model features denoted by scale-invariant geometric and appearance image information. Using images from the FERET database, the best classification rate is 83.7% obtained using a Bayesian classifier. In addition, the authors test their OCI model for classifying gender from simulated occluded faces. That is, images from the FERET database with a resolution of 256×384pixels were artificially obscured by a black circle of different radii. With an occlusion of radius 40pixels, the classification rate is 75%, however when the occluding radius goes up to 80pixels, the classification rate drops to 60% which is the rate of male faces in the data set.In the current literature, most of the automatic gender classification systems use the same face database for obtaining the training and test sets [20–22]. In this case, the acquisition conditions of training and test images are exactly the same which is far from a realistic scenario. Bekios-Calfa et al. [23] proved that single-database experiments are optimistically biased and present a cross-database study on gender classification. Regarding cross-database experiments with a reasonable amount of training samples, SVM+RBF roughly achieves 80% of success. However, if there is less training data and a broad demography, all the compared classifiers achieve similar classification rates of around 70–75%. All three face databases used in that work contained non-occluded faces.This paper presents an experimental study of gender classification from face images comparing two different representation approaches, three types of features and several classifiers using two performance measures. Experiments are carried out on single databases and crossing databases to explore more realistic scenarios. Furthermore, experiments focus on classifying the gender from face images showing different facial expressions and from partially occluded faces.The main contributions of this paper are the following:∙A thorough experimental study of gender classification methodologies from neutral and distorted faces used in all possible combinations of training and testing roles. Distorted faces refer to faces affected by facial expressions or by real occlusions caused by wearing a scarf or sunglasses. Conclusions are supported by three statistical tests applied to two different performance measures.Solid conclusions are drawn on the strengths and weaknesses of two representations approaches (global and local), three types of features (grey levels, PCA and LBP) and three classifiers (1-NN, SVM and PCA+LDA) when addressing the problem of gender recognition.A reliable assessment of the robustness of the presented methods to changes in acquisition conditions and demographic variables, such as age and ethnicity, by performing cross-database experiments.The rest of the paper is structured as follows: Section 2 outlines the methodology adopted for performing the experiments and details the processes of characterising face images and the classifiers to be used; Section 3 presents the databases involved in the experiments; Section 4 describes the experimental set-up and the statistical tests which are applied for comparing the results; in Section 5 the results of the experiments are discussed and the statistical differences found among the performances of the different classification models are provided; finally, the conclusions are presented in Section 6.

@&#CONCLUSIONS@&#
