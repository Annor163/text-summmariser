@&#MAIN-TITLE@&#
Agile factorial production for a single manufacturing line with multiple products

@&#HIGHLIGHTS@&#
To provide a lot-sizing technique that can deal with non-stationary demand.To introduce a method for planning agile manufacturing schedules.To generate production schedules via novel methods.To apply and compare these new methods on the basis of a real world case study.To propose an efficient parallel genetic algorithm configuration.

@&#KEYPHRASES@&#
Lot-sizing,Production schedule,ELSP,Genetic algorithm,

@&#ABSTRACT@&#
Industrial practices and experiences highlight that demand is dynamic and non-stationary. Research however has historically taken the perspective that stochastic demand is stationary therefore limiting its impact for practitioners. Manufacturers require schedules for multiple products that decide the quantity to be produced over a required time span. This work investigated the challenges for production in the framework of a single manufacturing line with multiple products and varying demand. The nature of varying demand of numerous products lends itself naturally to an agile manufacturing approach. We propose a new algorithm that iteratively refines production windows and adds products. This algorithm controls parallel genetic algorithms (pGA) that find production schedules while minimizing costs. The configuration of such a pGA was essential in influencing the quality of results. In particular providing initial solutions was an important factor. Two novel methods are proposed that generate initial solutions by transforming a production schedule into one with refined production windows. The first method is called factorial generation and the second one fractional generation method. A case study compares the two methods and shows that the factorial method outperforms the fractional one in terms of costs.

@&#INTRODUCTION@&#
Food manufacturers are experiencing increases in the variability of demand received and the variety of products required (Squire, Cousins, Lawson, & Brown, 2009). It is imperative for operations to manage the increasing dynamics of the situation to avoid excessive inventory. Through the application of an agile approach food manufacturers are increasing the flexibility of their operations and finished goods stocks to meet customer demand (Taylor & Fearne, 2006). This increased flexibility supports the production of goods as they are needed. The resulting manufacturing schedules are directed by the objective to minimize the holding, setup and shortage cost. This study focuses on a single, agile, production line accommodating multiple products. This single production line perspective is a reality for many industries. However, for several it is a simplification. Nevertheless the resulting production schedule is a useful strategy that can be used to derive a refined schedule.In this article we discuss the literature on lot-sizing models and its relationship to agile manufacturing. The classic Economic Order Quantity (EOQ) model is the starting point of the review, which leads to the Economic Lot Scheduling Problem (ELSP) and finishes with a review of research on the Stochastic ELSP (SELSP). The analyzed classifications are shown in Fig. 1. This section also defines some of the later used terminology.Our overall approach is to use lot sizing techniques to derive production schedules. A lot-size is the quantity of units that is (was, will be) produced for one or more products. A product is raw material that is manufactured into a finished good. Products are sometimes referred to as items.Lot sizing techniques are often divided into two categories. The first category is concerned with individual-product manufacturing and inventories. The second one looks at multiple products (Silver, Pyke, & Peterson, 1998). Lot-sizing techniques for the single product category have been extensively studied. Harris (1913) and Harris and Sollis (2005) introduced the EOQ model, which finds the optimal order quantity Q in terms of minimizing order costDQcoand holding costsQ2chsubject to several constraints such as constant demand D. Note that order cost in a manufacturing context is the setup cost. A number of EOQ derivatives were introduced using additional factors such as shortage costs, production rates and many more. Erlenkotter (1990) gives an interesting documentation of the EOQ history. The original EOQ models were extended to incorporate focus on probabilistic demand (predominantly assuming normal distributed demand). Policies such as Order-Point & Order-Quantity(s,Q), Periodic-Review & Order-Up-To-Level (R,S) and (R,s,S) became common practice. The (s,Q) system is a continuous review system with a fixed quantity Q which is ordered whenever inventory drops below s. The (R,S) system is a replenishment cycle system where the inventory is increased to level S every R time units. The (R,s,S) system is a combination of the previous two systems. Every R time units the inventory level is checked, and when it is below s the level is raised to S. Details of these methods are explained in Silver et al. (1998).In food manufacturing environments the multiple product category is typical challenging the capability and flexibility of the organizations to forecast demand (Christopher, 2011). The ELSP is an extension of the EOQ model that supports several products with differing demand Diand also introduces change over costs cijfrom product i to j. The first popular work was done by Rogers (1958) and is now known as an Economic Lot Scheduling Problem (ELSP). The usual objective of the ELSP is to find cyclical scheduling policies such that the setup and holding costs are minimized. The assumptions are that there is little demand fluctuation (no seasonality and trend) for each Diand that there is a single machine that allows only one product at a time to be produced. Cyclical means a repetition of the production. In a two product scenario there will be production times p1 and p2 and setup (change over) times s12 and s21. The timings for a possible production cycle are p1s12p2s21, which is then repeated. To be more precise the production time for one product is the amount of time required for all machines in use to manufacture a specified quantity of the product, including the run time and down time. The run time is the time machines are active. The down time is used to describe any possible machine inactivity. That means the cycle time is longer than the production time.Silver et al. (1998) introduce an approach which finds a feasible solution for the ELSP. Osman and Demirli (2012) have recently contributed to the classic ELSP work. They gave a quadratic assignment formulation and introduced an algorithm that found optimal solutions—even for large problem instances. The ELSP is non-deterministic polynomial-time (NP) hard as Hsu (1983) proved. The recent review of the ELSP done by Chan, Chung, and Lim (2013) suggests classifications of the ELSP according to the schedule cycles. Their investigation showed that the common cycle approach is most often found in literature (41 percent). That means there is a single cycle for all products. The next significant class is based on the basic period approach with a frequency of 28 percent. Here each product has its own cycle time, but each cycle must be a multiple of the basic period. The third major approach has varying lot sizes per production cycles, but only got 11 percent attention in the literature (Chan et al., 2013). From an agility perspective the varying lot size (VLS) is particularly relevant to manufacturers in an agile environment due to its practical applicability. The limited research in this area indicates a gap in the body of knowledge and the authors found no publications that address the use of VLS combined with varying production intervals in the food manufacturing sector.Important work in the time varying lot sizes class was done by Dobson (1987), which led to time varying cycles. However it is questionable whether the cycle term should continue to be used, because of the possible absence of repetitiveness. Moon, Giri, and Choi (2002) have looked at the ELSP with an “imperfect” production process, which also uses a time varying lot size approach. The last two mentioned papers reveal similar characteristics to this study, but these papers give priority to theoretical solutions based on numerous assumptions, while the approaches in this paper focus on a practical approach. Time-varying lot-sizes belong into the ELSP class rather than the SELSP category, because although demand varies—these variations are supposed to be known. However, one could put them into the category of stochastic ELSP claiming zero noise in the predicted demand. If noise cannot be explained—or if other random influences are present—stochastic models need to be regarded.Winands, Adan, and van Houtum (2011) survey the stochastic economic lot scheduling problem (SELSP). The term stochastic is primarily associated with random demands, (possible) random setup times and (possible) random production times. They classify the approaches according to production sequence, which could be fixed or dynamic.The fixed production sequences are further divided into those with fixed or dynamic cycle length. The fixed production sequence with fixed cycle length can fulfill the demand on a global scale by dividing the “stochastic” demand accordingly. This class can be associated with the common-cycle class mentioned in the ELSP classification. Bradley and Conway (2003) explain characteristics of cyclic inventory. The cycle time is defined here by the production times, the changeover times and slack time. This cycle is repeated. They found that the average cyclic inventory is directly proportional to changeover times. Cycle length is directly proportional to changeover times. Two common operations errors were identified: (1) interrupting a production run (lot-splitting) to fulfill sudden urgent demand requests; (2) increasing machine utilization. The fixed production sequence with dynamic cycle length adapts the cycle length to meet the stochastic demand without changing the production sequence. For this class Wagner (2004) proposes a local search algorithm. The demand is assumed to be a stationary renewal process, and the schedule minimizes the long-run average costs. Product scheduling cycles may vary in multiples of the base period. The algorithm finds feasible solutions, and its performance was tested on several instances. Other important work in this class include Gallego (1990, 1994) and Federgruen and Katalan (1996, 1999).On occasions it may occur that a product is not produced. In this case the production sequence may reinstate later. However, allowing changes to the production sequence (called dynamic production sequence) is another main category Winands et al. (2011) identified. These changes reflect the dynamic situation that agile manufactures face in altering schedules to meet changing demand (Harrison & Hoek, 2011). Gascon, Leachman, and Lefranois (1994) research falls into this class, as they provide heuristics that find schedules given stochastic demand, multi-items and a single-machine. Zipkin (1986, 1991) considered dynamic production sequences as well. Their demand and production processes have stochastic characteristics and are based on queueing models, which lead to interesting theoretical results. Sox, Jackson, Bowman, and Muckstadt (1999) is another important work in this field.The above literature review and the Bradley and Conway (2003) paper confirm that almost all literature assumes that stochastic demand is stationary. The work presented here was particularly developed to deal with the non-stationarity of demand to cover the gap currently in the lot-sizing literature. Bradley and Conway (2003) give a simple example that demonstrates some of the adverse effects of non-stationary demand in respect to stock-outs and service levels. In practical situations we need to assume that demand is non-stationary. The case study in this paper uses such demand patterns. As mentioned above most literature deals with cyclic approaches with fixed production sequences. There is a need for methods and algorithms that create dynamic production schedules. The research in this paper can be associated to the SELSP class dynamic production sequence which reflects the agile environment that food manufacturers operate within, if the demand is specified as non-deterministic. From the ELSP point of view our study and algorithms is situated in the varying lot size and varying lead time category, assuming deterministic “dynamic” demand.The main contributions and objectives of this paper are:•to provide a lot-sizing technique that can deal with non-stationary and varying demand;to introduce a method for planning agile manufacturing schedules;to generate production schedules via novel methods;to apply and compare these new methods on the basis of a real world case study;to propose an efficient parallel genetic algorithm configuration;to provide practitioners with tools to create production schedules.The remainder of the paper is structured as follows. An illustrative example motivates the general mathematical formulation of the problem (Section 2). This problem is solved with the genetic algorithm introduced in Section 3. The genetic algorithm terminology is linked with those from production. The new factorial and fractional methods are proposed in Section 4. These methods are trialed on an industrial scenario dominated by its demand data (Section 5). In Section 6 the results of the case study are presented and linked to operations issues. The paper concludes with a discussion of the results and future directions of research (Section 7). The main contribution of this paper is the development of an efficient way for practitioners to create agile production schedules. This is achieved through the generation of production schedules via novel methods which were subsequently tested in a real world situation.In the previous section various inventory models were introduced with a focus on the ELSP. It was found that the formulation of the ELSP, with varying lot size, was closest to the problem we sought to address. This section introduces and defines the problem under investigation. A solution procedure will be proposed in the next section.The objective is to find a production schedule for multiple products such that the total cost is minimized. The cost is constructed by the holding, shortage and changeover cost.Finding the schedule is subject to:•varying demand (non-stationary);a single manufacturing line;constant production rate;smallest production time window fixed;cost are product dependent.The variability in demand of the products motivates the agility of the manufacturing process. Here, agility means that production changes according to demand. For production only a single manufacturing line is available. We assume that production rates for each product remain the same over the entire manufacturing period. The smallest production time window is set, but the production run period itself adapts in an agile way. The holding and shortage costs are product dependent. The changeover (setup) cost occurs when changing to a different product. We will assume that the changeover time is neglect-able in comparison to the production run time.Example 2.1Principal approachOur goal is to create a production schedule that satisfies the demand and minimizes the costs. Demand for products one (d1) and two (d2) are known between day 1 and 20, d1 = (0 1 0 0 3 0 0 0 2 0 1 1 0 0 0 0 0 2 0 0) and d2 = (0 0 0 0 1 0 1 0 0 3 0 0 0 0 0 0 2 0 0 1). For instance the demand during day 5 for product one is three batches.There are three cost factors, which will be considered to minimize the overall cost. The holding, changeover and shortage cost factors for the two products are shown in Table 1. That means the daily holding costc1hfor one batch of product one is $2. The changeover costc1oto product one is $1. The shortage costc1sper batch is $8 and represents lost sales.The decision variable xiis the product batch to be produced on a given day, i.e. xican take on the values 1 or 2. There are 20 decision variables, i.e. x = (x1, x2,…, x20).The aggregated number of produced product batches arepk1(x)=∑i=1k[xi=1]xi,pk2(x)=∑i=1k[xi=2]xi.11Iverson (1962) introduced these brackets for true-or-false statements[S]:={1ifSistrue;0otherwise.. For instance the Kronecker delta is defined byδij:=[i=?j].The aggregated number of consumed product batches arerk1=∑i=1kdi1,rk2=∑i=1kdi2. That means the inventory (in batches) for product one for day i is qi1(x) = pi1(x) − ri1. This leads to daily holding costsci1h(x)=[qi1(x)>0]qi1(x)c1hand the total holding costc^1h(x)=∑i=1nci1h(x)for product one; similar for product twoc^2h(x)resulting inc^h(x)=c^1h(x)+c^2h(x). The total shortage costs for product one and two are determined in a similar wayc^js(x)=∑i=1n−[qi1(x)<0]qi1(x)cjs,resulting inc^s(x)=c^1s(x)+c^2s(x). Changing to product one on day i causes a cost of[xi≠xi−1]c1o,i > 0. The total of all setup costs are determined by:c^o(x)=cx1o+∑i=2n[xi≠xi−1]cxio.Thus the objective function isf(x)=c^h(x)+c^s(x)+c^o(x). A solution can be found using an evolutionary algorithm such as the genetic algorithm. A standard genetic algorithm finds the solution x = [1 1 1 1 2 2 1 1 2 2 1 1 2 1 1 2 2 1 2] with value f(x) = 80, where x is the production schedule and f(x) is the cost of this schedule.The above example demonstrated the approach in principle. This will be used to derive a more general approach.In Example 2.1 we looked at daily demand d1 and d2 for two products for 20 days in “batch” units. We will abbreviate the basic time period with tb. So this could represent a week, a day or an hour. Let n denote the number of production windows, and m the number of products. A production window is a time slot (with duration t) during which units of one product are manufactured. If the production window’s duration is tbthen we say it has window size 1. A window size of two means that we halve the basic time period. In general the window size wlis defined as the fraction1lthat divides the basic time period. For instance if tbis six days then w3tbleads to a two days production window. wlis used to refine the basic production window. A production run can spread over several adjacent production windows. The quantity produced within the production window is the batch size. The batch size bjis the number of units of one product j worked on in one process step. In this paper the batch size is dependent on the size of the production window. The supreme batch size is a multiple of batches that are produced within neighboring production windows of the same product. Note the differences to production time (window includes downtime and changeover time) and cycle time (window is non repetitive and only covers one product). The production rate is product dependent and is obtained bybjt.The demand matrix D = (dij) is given. Heredij∈Ris the demand in production window (e.g. week) i for product j. If only one index is used then this addresses a column vector of D, e.g. d2 = D: 2 is the demand profile for product two. In case demand is negative (dij< 0) there is no net demand during i. Negative demand will be called returned goods and may reduce the amount to produce, assuming the goods are reusable. In practical situations given demand may be in aggregated form although it actually occurs in shorter time intervals. For instance weekly demand might be given, but actually stock is depleted on a daily basis. There are two typical scenarios for the planning. The first scenario is that the demand can only be fulfilled in periodic (e.g. weekly) batches, due to warehouse and transportation arrangements. The second scenario is that demand could be satisfied “continuously” (e.g. on a daily basis). We will call the way the demand is satisfied as depletion scheme.We assume linear production and possible consumption during the production run. The decision variable xiis the product, which is produced during production window i. For instance x5 = 2 means that product two is produced in production window (e.g. week) five, in general xi∈ {1, 2,…, m}. The case of no production can be implemented by allowing xi= 0 (alternatively a product with zero demand can be used). The decision vector is defined as x = (x1, x2,…, xn). The decision variable combined with the product’s batch size bjspecifies the produced units in production window i, i.e. [xi= j]bj. Initial stock for product j is abbreviated by sj. However, if there is no initial stock available then it can be created by “shifting” the demand matrix, i.e. adding zero demand on top of the matrix. This might be suitable if the company would like to create initial stock.We will now develop a mathematical program based on the general aspects mentioned above. The following dimensions, parameters and variables will be needed:Dimensions and indices:mNumber of productsNumber of production windowsProductProduction windowAggregated indexDuration of production windowHolding cost (per unit per t)Shortage cost (per unit per t)Changeover cost from any product to product jBatch size for product j per tInitial stock of product jDemand for product j during production window iInventory at production window i for product jProduct to be produced in production window iThe aggregated number of produced units in the first k weeks for product j is:(1)pkj(x)=∑i=0k[xi=j]xibj+sj.We start with the production window i = 0, to represent additional initial stock p0: on top of existing inventory sj; and hereby allow the production of one additional batch for a single product j before units are consumed.The aggregated number of consumed units is the same as the aggregated positive demand:(2)rkj=∑i=1k[dij>0]dij.Note if returned goods are reusable thenrkj=∑i=1kdij,which reduces the quantity to produce.That means the units of inventory for product j at production window i is:(3)qij(x)=pij(x)−rij.This motivates the holding cost for product j:(4)c^jh(x)=∑i=1n[qij(x)>0]qij(x)cjh,wherecjhis the holding cost per unit per production window. One may want to choose to add the “initial stock” holding costs.The total shortage cost for product j is determined in a similar way:(5)cj^s(x)=∑i=1n−[qij(x)<0]qij(x)cjs,wherecjsis the shortage cost per unit per production window. Note that these product quantities cannot be back-ordered.The changeover (setup) cost is obtained by:(6)c^jo(x)=∑i∈Kcjo,with K = {i ∈ {1,…, n}|xi= j ∧ xi≠ xi − 1} andcjois the changeover cost from any product to product j. xi≠ xi − 1 is true if a different product was produced in the previous production window. We assume that the changeover (setup) time is negligible in comparison to the production window duration.Thus the objective function is:(7)f(x)=c^h(x)+c^s(x)+c^o(x).The agile manufacturing problem can be formulated as the mathematical program:(8)z*=minxf(x)=minxc^h(x)+c^s(x)+c^o(x)subject to the set of constraints:(9)1≤xi≤n,xi∈NA feasible solution for this mathematical program can be found with the genetic algorithm.The first section will give a brief explanation about the underlying biological concepts. The second section introduces the genetic algorithm (GA), and the third section explains how the GA is used in the context of production schedule creation.Genetic algorithms are based on the natural selection of the survival of the fittest. The idea of these algorithms was first introduced by Holland (1975) and their practical usage was demonstrated by Goldberg and Holland (1988).The biological background is shortly discussed. It is assumed that a human being is made out of 1014 cells (e.g. the diameter of a red blood cell is 9 μm). A cell contains a linear DNA string. A chromosome is a continuous piece of DNA string. The diameter of a chromosome is between 0.2 and 20 μm typically. A chromosome is built up by sequence of linearly ordered genes. A gene contains the information about the characteristics and shape of a macro molecule.Each living being has got a genotype and a phenotype. The genotype is made up by the chromosomes which identify the “whole” of a being. The phenotype describes the appearance of the individual. A set of individuals make up a population. Individuals survive because they are fit or lucky. But fit individuals are more likely to keep on living and to be selected as parents for the next generation. The selected parents reproduce with their strongest gens. But complete unexpected and unforeseen events happen occasionally and change parts of the genetic information. We call this mutation of the gens. A better generation (species) replaces the old one, which is part of the evolution process.The principals of a genetic algorithm are shown in Algorithm 1.We begin with deriving an initial population (i.e. set of initial production schedules). This is a set of diverse feasible solutions. Usually individuals (schedules) are chosen/created with an opening procedure. The fittest of these create the next generation, i.e. fitter individuals are more likely to be selected. These individuals represent parents and generate children, which “combine” the characteristics of their parents. This process is called crossover operation, which are often implemented by merging binary representations of the individuals. Mutation randomly changes some individuals. This completes a generation change over. This procedure repeats itself (i.e. the population evolves) until a certain number of iterations or other stop criteria have been reached.Genetic algorithms (GA) have previously been used for solving lot-sizing problems. Chang, Yao, Huang, and Chen (2006) used a GA for solving a fuzzy economic lot-size scheduling problem. They paid attention to perturbations of demand leading to “fuzziness” in the cost function. In contrast to our approach their search is governed by cycles, which they have to accommodate in the decision variables for the production schedule (individual). Yokoyama and Lewis (2003) developed a GA to optimize the stochastic dynamic production cycling problem. This problem differs from the ELSP by using more than one machine (production line). The representation of the decision variables is similar to the one chosen in this study, with the difference that a machine index was necessary. Furthermore, Yokoyama and Lewis (2003) did not investigate the refinement of production windows. Khouja, Michalewicz, and Wilmot (1998) created a GA for solving the basic period ELSP. Trials on some of the algorithm settings were done. In general finding appropriate settings for the GA is essential for the solution quality. Most authors state only one configuration, but it is advisable to set up an experimental design and test several factors as described in the following subsection. Torabi, Fatemi Ghomi, and Karimi (2006) looked at an extension of the economic lot and delivery scheduling problem (ELDSP) using a hybrid GA to find production sequences and other aspects. The hybridism addresses the issue that GAs are “slow” in the local search by introducing a local improvement method for each child. Similar reasons motivated the “guidance” algorithm proposed in Section 4. A GA is one of many possible meta-heuristics to be used for scheduling. Almeder and Mönch (2010) have analyzed various algorithms such as the Ant Colonization Optimization (ACO), Variable Neighborhood Search (VNS) and GA in manufacturing/scheduling context. Their study suggests that the VNS is superior to the ACO and GA. Another study by Raza and Akgunduz (2008) compared heuristics in regards to the ELSP. Moreover the study proposed a Simulated Annealing (SA) algorithm to solve the ELSP. SA outperformed other heuristics such as the hybrid GA and neighborhood heuristics. Their SA converged faster than Tabu Search (TS) having similar solution quality as TS. Gaafar (2006) implemented a GA for the dynamic lot sizing problem with batch ordering, which was compared against the modified Silver-Meal (MSM) heuristic. Their results indicate that the GA outperforms the MSM heuristic in regards to solution quality. From the mentioned literature no general statement about the superiority of a particular heuristic can be derived. Alternative approaches to GA will be discussed in Section 7 on further research. The overall framework of dealing with increased complexity introduced in Section 4 allows the GA to be substituted with any heuristic that accepts initial solutions.This section showed the basic GA and reviewed related literature associated to heuristics in regards to lot-sizing problems.We will now relate the GA to the production schedule creation. In particular we will describe the GA’s settings in more detail. These settings are applied to run a traditional and parallel GA algorithm. In Section 2 we have defined the decision variables xias the product manufactured during production window i. These decisions variables are the genes that make up an individual (also called genome) x. That means a feasible production schedule x is an individual in GA terminology. The fitness of an individual is determined by the value of the objective function (f(x), see equation (7)), which are the accrued holding, setup and shortage costs. A set of feasible production schedules represents the current population (generation).In general an initial set of production schedules (initial population) are determined with an opening procedure. These schedules should be diverse in x and usually vary in f(x) as well. This is important for creating better production schedules. In our algorithm x is obtained by applying a uniform random distribution on the produced products (genes) fulfilling the constraints of equation (9). It would be interesting to initialize production schedules (genomes) with longer production runs (strings of genes), e.g. that each production schedule produces just one product or mixtures with longer production runs. This should improve the run-time, but might affect the quality of the solution. As mentioned above more complex production schedules are based on previously simpler ones. For instance assume two products are produced over five weeks, e.g. x = (2, 2, 1, 1, 2). This will be transformed into a production schedule (parent) that deals with 3 products and 10 half-weeks by doubling each entry in x, i.e. x′ = (2, 2|2, 2|1, 1|1, 1|2, 2).To control the variation of f(x) we scaled it to a predefined range. In our approach we have used rank fitness scaling, i.e. we ordered f(x) and assigned value 1, 2,…s. The number of candidate schedules (size of the population) is determined by(10)s=min{max{n,40},200)},where n is the number of decision variables (number of production windows), i.e. s ∈ [40, 200]. For the case study this means that the population is initially 104 (number of weeks in two years), and will increase to 200 for refined production windows. The choice of the population size (number of production schedules to investigate) is a tradeoff between solution quality and performance. A large population will avoid more local optima and increase the chance of the GA finding a global optimum. However, the performance duration will increase. Several authors have document this population size issue, e.g. Alander (1992), Roeva, Fidanova, and Paprzycki (2013) and Pasandideh, Niaki, and Nia (2011). Based on linear algebra, n base vectors (i.e. initial production schedules, parents) are required to span the entire search space (i.e. all possible production schedules). However, if there are less production schedules, mutation would eventually create missing base vectors. Literature acknowledges a relation between the size of the search space and the population size. Our literature review indicates that there is no conclusive method that determines the population size depending on run time or number of decision variables, and that most authors using the GA have experimentally chosen the population size.Fit individuals (possible production schedules) are selected for generating the next generation (new production schedules). There are several popular selection methods such as the tournament, roulette and stochastic-uniform method. Single factor experimentation indicated that the tournament method leads to the best production schedules out of the three tested methods. In the deterministic tournament method k “players” (individuals) are chosen randomly and the best one becomes a parent. This is repeated until sufficient parents have been chosen. Additionally we allow migration. That means a fraction mfof the “best” schedules (fittest parents) replaces the worst schedules (i.e. individuals from a sub-population). Single factor experimentation suggested mf= 30 percent, other alternatives tested were 10 percent, 20 percent and 40 percent. These two fractions are the schedules for the next generation. Note that we use a percentage ecthat ensures the “best” schedules (fittest parents) reach the next generation, i.e. they by-passed crossover and mutation. We have set ecto 5 percent, other less successful options were 10 percent and 30 percent.Our crossover operation takes scheduled production windows (genes) randomly (uniform) from schedule 1 and merges them with schedule 2. For instance p1 = (2, 2, 1, 3, 3), p2 = (1, 2, 2, 3, 2) and the random production windows are (2, 4, 5). This means we merge(_,2,_,3,3)into p2, which gives us c = (1, 2, 2, 3, 3) as the new production schedule. The previously mentioned GA mechanism ensures that better schedules are used. Another crossover operation is to randomly choose the cut index. In the previous example, let the cut index be three, then the created schedule is c = (2, 2, 1|3, 2). We could also cut the schedule at two positions, e.g. two and four resulting in c = (2, 2|2, 3|3). Usually not all schedules of the population are created using the crossover operation, but rather a percentage cf. Our configuration had cf= 80 percent.After the crossover operation the mutation operation is applied. Initial generations are mutated more than later generations. Individual’s genes (i.e. parts of the production schedule) are changed by choosing a random number from the normal distribution with mean 0 and decreasing variance. The variance is given byσk2=σk−12(1−3k4g),where g is the total number of generations and k the current generation.Our primary interest is in the quality of the solution rather than the speed. However, we have limited the run time to 10 minutes. Furthermore, the GA stops if the improvement (fitness weighted average) over sg= 50 generations is less than tf= 10−7. The genetic algorithm (in context of the fractional schedule generation) terminated in 64.8 percent of all cases because there was no improvement in the best fitness value for a period of sg= 50 generations. 35.0 percent of terminations were due to exceeding the generation limit of 100. The rest was due to exceeding the time limit. Increasing the generation limit to 200 resulted in a 96.4 percent no improvement termination. The previously discussed parameters have been summarized in Table A2.The GA implementation takes advantage of parallelism. In our case study we used 32 cores and shared memory. Furthermore, we used a multi-start approach, which has been integrated in Algorithm 2 proposed in the next section. The number of multiple starts of the parallel GA (pGA) was set to 30. The run-time increased as the production schedule was refined. The decision variable could take on values between 0 and 10, i.e. 10 products (plus no production possible). We observed that on average the run-time to find a pGA solution for a decision vector of size 208 was 65.5 seconds (i.e. on average 2.18 seconds for a single pGA run utilizing 32 cores). This increased to 499.7 seconds for a production schedule with 2080 decision variables (i.e. on average 16.7 seconds for a single pGA run). The pGA for refined production schedules uses initial solutions (i.e. rougher schedules) found in prior runs. This approach will be explained in detail in the next section. In this section we have discussed the configuration of the pGA. We found that the pGA algorithm can be used to find the feasible production schedules even without initial solutions. However, the solution quality is not as good as using an iterative schedule creation. That means complexity is added iteratively.The iterative algorithm will be explained first. Followed by an introduction to the factorial and fractional approach.This study investigates how complex schedules are derived via an iterative algorithm that uses parallel genetic algorithms (pGAs). Initially the authors attempted to use the parallel genetic algorithm directly, i.e. without the guidance of the iterative algorithm. This led to high schedule costs. Our algorithm increases the complexity (i.e. number of production windows and products) step by step. The proposed iterative generation of feasible production schedules is shown in Algorithm 2. The input for this algorithm is the demand of all products. This demand should be ordered according to the product’s importance (see Section 5). The importance can be identified by the total volume, holding cost, shortage cost or profit. In the case of volume importance this means:(11)∑i=1ndi1≥∑i=1ndi2≥⋯≥∑i=1ndim,m>1.In the case of a single product the reader is advised to use techniques mentioned in Section 1. As mentioned previously the demand may vary, be non-stationary or be discontinued. A detailed discussion of demand for a case study is given in Section 5, demonstrating numerous real world issues. Other relevant input values and options such as costs or depletion scheme are specified in the input of the algorithm, which are detailed in Table A1.We will now explain the steps in the algorithm in more detail. [Line: 1] The algorithm begins with finding several production schedules P by using the GA explained in Section 3 multiple times. This step focuses on the first two products only. [Line: 2] The for-loop iterates (hence the name iterative algorithm) through a set of production windows W. The set is dependent on the factorial or fractional approach, which are explained in detail in subsequent subsections. [Line: 3] Setting the initial production schedules (population) is the “heart” for iterative improvements. This paper proposes and investigates the factorial and fractional approach. In the algorithm these two initial schedule generation methods are abbreviated with f(P, w), where P are existing production schedules and w is the new window size. f derives a schedule basis B such as{x132,x232,…,xs32}. Here, s is the number of runs defined in line 6.[Line: 4] In Section 2.2 two depletion schemes: periodic and continuous were introduced. The given demand has to be accordingly transformed. In the periodic depletion scheme the demand is requested at the end of a given period. As an example assume a 12 days schedule with demand aggregated over three days is 12, 3, 9 and 6. The end of period depletion on a daily basis is (0, 0, 12, 0, 0, 3, 0, 0, 9, 0, 0, 6). If we apply the continuous depletion scheme the average depletion is (4, 4, 4, 1, 1, 1, 3, 3, 3, 2, 2, 2). In the case study periodic depletion was used.[Line: 5] In order to fulfill all demand on average the production rate must bepavg=1n∑i,jdij. As mentioned in result Section 6 it is recommended that the actually used planning production rate is at least twice pavg. The permission of production windows with zero output can be interpreted as adjusting the production rate according to demand. Here, we set the batch size to:(12)b=2n∑j=1m∑i=1n[dij>0]dij.Note, that the batch size depends on the number n of production windows, i.e. n increases when the window size increases. It is also possible to set batch sizes for “individual” products:bj=2n∑i=1n[dij>0]dij.[Lines: 6–8] The iterative algorithm starts the GA multiple times. The GA was discussed in Section 3 and returns a single schedule (individual) pkvia g(w, B), since the GA includes some random operations the returned solutions are expected to vary. Thus, we are obtaining several production schedules {p1, p2,…, ps}, where s represents the number of runs. These schedules are used as part of the initial population (Line 3) for finding a refined production schedule (e.g. windows of size 6 for two products). Laterykw2will be used to describe pk∈ P with production window size w (w > 1) for two products. In the special case that P consists only out of one element we will drop the index k. So f(y32, 6) would have created x62 using the factorial design, which g(x62) turned into y62.[Lines: 10–12] These lines add additional products one at a time, i.e. the values a decision variable can take on are increase incrementally. Again the GA is used to achieve this. This leads to a growing product variety as shown in Fig. 2.Sections 4.2 and 4.3 will explain in detail how fractional and factorial schedules are created.The basic principle is that a “rough” schedule is refined, i.e. a top down approach where the number of products is fixed (see Fig. 2). For instance an initial schedule may consist of fixed weekly (six days) production windows. This duration is linked to window size w1. The first refinement is half-a-week (three days and window size w2). Followed by a third-week (two days and w3), and so on. The half-a-week (“division-by-two”) schedule uses the one-week slots as initial solutions. The same applies for a division-by 3, 5 and 7 schedule. In general any division-by a prime number schedule can be derived from the schedule with window size 1. The other schedules are derived from the highest factor, e.g. a divided-by 4 schedule is derived from 2, 6 (= 3 · 2) from 3, 8 from 4, 9 from 3 and so on. We will call this the factorial approach. The factorial approach is shown in Fig. 2. Here we see (1, 2) representing the schedule with window size 1 and two products, which can be derived via the parallel genetic algorithm proposed in Section 3. This is the basis to derive (2,2), (3,2) or (ω, 2), where ω is a prime number. In general the schedule yω2 is created via g(x12), where g the genetic algorithm. x12 is obtained via f(y02, 1). Here, f is the factorial generation function and y02 is an initial schedule (see Algorithm 2, Line 1). g and f are also shown in Algorithm 2 in Lines 7 and 3 respectively.Let y12 = (2, 1, 1, 2, 2) be a (1,2)-schedule. This is transformed into x22 = f(y12, 2) = (2, 2; 1, 1; 2, 2; 2, 2; 2, 2) the (2,2) schedule basis. Similarly into the (3,2) schedule x32 = f(y12, 3) = (2, 2, 2; 1, 1, 1; 2, 2, 2; 2, 2, 2; 2, 2, 2). x22 and x32 are initial schedules, which are improved by the GA to obtain y22 and y32, e.g. assume y22 evolved into (2, 2; 2, 1; 1, 1; 1, 2; 2, 2). From Fig. 2 it can be seen that y22 is the (2,2) schedule basis that obtains the initial production schedule for the (4,2) schedule via f. For the example that means x42 = f(y22, 4) = (2, 2, 2, 2; 2, 2, 1, 1; 1, 1, 1, 1; 1, 1, 2, 2; 2, 2, 2, 2). Now the y42 is obtained via g(x42). Schedule basis (4,2) will be used to derive schedule y43. That means the number of production windows remains four, but a third product is introduced via g. Furthermore f will not be used because of the “horizontal” direction (see Fig. 2). This gives us y43 = g(y42, 3) = (2, 2, 2, 3; 3, 3, 3, 1; 1, 1, 1, 1; 1, 1, 1, 3; 3, 3, 2, 2). The second parameter of g specifies the number of used products (see also Algorithm 2 Line 11). We see that g has replaced some of the previously set products with product 3. This iterative approach is based on the highest combined factor α obtained so far. This guarantees that the obtained schedule is better than the α schedule. In general ykα, 2 = g(f(yα, 2, k)); and yα, j= g(yα, j − 1, j) for j > 2. A higher product dimension schedule yω3 or ykα, 3 is derived via g from xω3 = yω2 or xkα, 3 = ykα, 2 respectively. This is used to derive the production window set W specified in Algorithm 2. For instance if the required production window is t = 16 then W = {1, 2, 4, 8, 16}. In the next section a second approach is discussed. Section 6 compares the production schedule costs of these methods.An alternative approach is a fractional generation, this means a production schedule is partially fitted into the refined schedule. For instance a slot 2 schedule with three products y23 = (2, 3|2, 2|1, 1|1, 3|2, 2) is transformed into a “refined” slot 3 schedule by leaving a production gap x33 = (2, 3, 0|2, 2, 0|1, 1, 0|1, 3, 0|2, 2, 0). The gap is defined by setting every third element to zero. Such refined schedules are used in the parallel genetic algorithm as initial solutions. In general the fractional generation process for two products is:y02→g∘fy12→g∘fy22⋯→g∘fyn2or yn2 = (g ○ f)n(x12), where g is the genetic algorithm or any production schedule generation function, f is the fractional generation function and y02 an initial solution (see Algorithm 2). This process shows that the set of production windows for Algorithm 2 is W = {1, 2,…, t}.The fractional generation function currently uses production gaps. However, instead of non-production fractions a heuristic interpolation procedure can be used. If product A is produced in the preceding and succeeding production window it can be assumed that product A will be produced during that time slot as well. If two different products surround the gap then the one with the greatest missing demand should be produced. These heuristics shall be investigated in future work.This section proposed an algorithm and methods to iteratively create a production schedule with higher complexity.The case study company observed that their inventory levels are too high and detached from the actual demand. So, a change from a push strategy to a pull strategy became of interest. That means that manufacturing has to be done in an agile way. The previous sections introduced a methodology that derives a schedule for agile production. This section will introduce the company process, the demand data and suggest a cost upper bound.The case study company produces a range of 250 food products that service a heterogeneous customer base. The SME had actively pursued growth through expanding its customer base driving a change in manufacturing variables including lead-times and order size. The new demand profile had adversely impacted on the performance of the operations area. The production process that is deployed utilizes a five stage manufacturing route. Raw material inputs are cleaned and sorted leading to the production of eight intermediary semi-finished products which are stored in material handling silos awaiting release to the appropriate production lines for packaging before shipment to the warehouse. The manufacturing process had been faced with the challenges of growing sales, increased inventory cost and falling service levels. Increasing demands on the manufacturing facility challenged the historical approach to production planning and control. The increasingly variable demand on the manufacturing operation weakened the reliability of the planning schedule rendering the plan obsolete within hours of issue. The four week time horizon schedule began to reflect a customer order list. The reactive planning and control modus operandi had forced manufacturing into an increasing number of unplanned changeovers with diminishing performance. The firm had effectively moved from a position of flexible spare capacity to a bottleneck over a three year period due to increased complexity and reduction in schedule stability.Improving the reliability and responsiveness of the production schedule became the focus of the organization. In order to reduce the costs of unplanned changeovers, lost production capacity, increased downtime and emergency customer shipments the case study firm investigated the possibility of creating focused factories. Products were relocated to specific production lines based on pack size, the primary driver of changeover time, and classified in terms of Make-To-Order (MTO) and Make-To-Stock (MTS) status to develop a more supportive inventory position. These refinements and changes were expected to improve the productivity of the line and the stability of the schedule.In this study we focus on an arbitrary selection of 10 products (out of 250). For each product the demand is known on a weekly basis. The time-series of the individual products are shown in Fig. 3. We see that the quantities of the first two products dominate. In order to optimize the production process greater understanding of the individual products demand profile has to be gained. We propose to first classify the products:1.Any products revealing a “high” coefficient of variation are flagged red (see “traffic light” in Fig. 3 and first letter in product code was set to R)—indicating MTO production.Time-series with a single significant innovation get an orange traffic-light assigned—requiring the time series to be divided into two sections; an algorithm in Garn and Aitken (in press) shows how the innovation split can be found.All other products are marked as green—suggesting demand profiles that typically include MTS and MTO components.The orange and green flagged time series usually have a hybrid MTS/MTO demand profile. The Garn and Aitken (in press) splitting method delivers the individual Make-To-Stock (MTS) and Make-To-Order(MTO) time-series. A product code was derived as follows: traffic light (G = green, O = orange, R = red); followed by a sequential number (01, 02,…, 10); Savings (S = significant, M = moderate, T = tiny, L = low); and back-order information (N = none, L = low, M = moderate, H = high). There is a necessity to improve the scheduling of the production process. In this example we have a variety of time-series and most products have a time-series that can be split into two components.Let us now return to the total demand. The overall aggregated demand reveals an increasing linear trend (see Fig. 4). This means we are dealing with a non-stationary production planning process. Furthermore, there is a visible innovation after the first year, which can be obtained using the innovation identification algorithm (Garn & Aitken, in press). This suggests that planning for each year should be done separately. The weekly demand has high variability, indicating cost factors caused by staff scheduling constraints.The rough capacity plan was to produce 450k packages in the year 2010. The actual demand in 2010 was 404k packages, which left an excess inventory of 46k packages—10.1 percent below plan.The assumption for 2011 was a growth of 20 percent, due to sales agreements. The plan was to have 404k plus 20 percent packages in 2011. That meant the production plan intended to produce 440k packages taking into account the excess inventory from 2010. However, the actual demand in 2011 was 608k packages—this would have meant lost sales of 30 percent.Let us consider the demand per quarter (Fig. 5). We observe significant changes between the quarters (see Table 2). The absolute average change of consecutive quarters is 27,439 packages, this is a relative average change of 21.7 percent. The planned production was 112,500 packages, which was insufficient for 2011 and a capacity management decision was necessary. An investment doubled the production rate in the second quarter of 2011.For the scheduling it is interesting to know which products have the highest demand. Fig. 6shows that product G02SN is causing 37.7 percent of all demand. Furthermore three products account for 77.2 percent of all demand. The product R04TN is from a volume and cost perspective not important. A comparison of setup cost against shortage cost (lost sales) shows that this product causes losses, in particular since the demand is at the end of the period. So, practically it should not be manufactured. The generated production schedules (see next section) support this and do not produce R04TN. Thus, reducing product variety and improving factory focus.Finding an upper bound for the costs is achieved with the following considerations. Holding cost and shortage cost cannot occur concurrently. Setup costs can be avoided by not producing anything at all. That means the maximal cost factors are:(13)cjmax=[cjs≥cjh]cjs+[cjs<cjh]cjh,where j is the product,cjsandcjhare the product’s shortage and holding costs respectively. Usually shortage cost is higher than holding cost, simplifying the cost bound to be the shortage cost. That means an upper bound for the cost is:(14)m=∑i,j|dij|cjmax.In the case study the maximal cost is $7,543,580 over two years. The individual cost factors and total demand volume are shown in Table 3. The holding cost and shortage cost are in dollar per unit per week. The setup cost occurs when changing from a product to the specified one.Furthermore, product 2 can cause 38.4 percent ($2.89M) damage and product 8, 21.4 percent ($1.61M). Note that shortage cost can sometimes be interpreted as negative revenue, i.e. lost sales or possible revenue. So products 2 and 8 could generate 59.8 percent ($4.50M) of all possible revenues.In Table A2 we have summarized the data requirements to run the iterative generation algorithm for the case study.

@&#CONCLUSIONS@&#
