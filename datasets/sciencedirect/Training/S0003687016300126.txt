@&#MAIN-TITLE@&#
Observer performance in estimating upper arm elevation angles under ideal viewing conditions when assisted by posture matching software

@&#HIGHLIGHTS@&#
On average, observers were virtually unbiased in estimating upper arm elevation to the nearest 1°.Observers were most proficient at estimating 0° and 90°, and least proficient at 60° postures.Within observer variance was considerable, indicating the risk of relying on single observations.If high precision is required & repeated observations are not feasible, inclinometry is suggested.

@&#KEYPHRASES@&#
Measurement error,Working postures,Observation,

@&#ABSTRACT@&#
Selecting a suitable body posture measurement method requires performance indices of candidate tools. Such data are lacking for observational assessments made at a high degree of resolution. The aim of this study was to determine the performance (bias and between- and within-observer variance) of novice observers estimating upper arm elevation postures assisted by posture matching software to the nearest degree from still images taken under ideal conditions. Estimates were minimally biased from true angles: the mean error across observers was less than 2°. Variance between observers was minimal. Considerable variance within observers, however, underlined the risk of relying on single observations. Observers were more proficient at estimating 0° and 90° postures, and less proficient at 60°. Thus, under ideal visual conditions observers, on average, proved proficient at high resolution posture estimates; further investigation is required to determine how non-optimal image conditions, as would be expected from occupational data, impact proficiency.

@&#INTRODUCTION@&#
Body posture is a commonly accepted physical risk factor associated with musculoskeletal disorders (MSDs). While considerable efforts have been made to characterise and quantify the effects of working postures, detailed exposure–response relationships are still lacking, and most large epidemiological studies have failed to show associations between postural exposure factors and MSDs (National Research Council, 2001; Punnett and Wegman, 2004). Insufficient exposure assessment has been cited as a possible explanation (Winkel and Mathiassen, 1994; Burdorf et al., 1997; van der Beek and Frings-Dresen, 1998; Punnett and Wegman, 2004). Thus, valid and reliable postural exposure measurement methods are required to provide meaningful and consistent posture data that can support successful investigations into the role of posture in MSD onset and mediation.To date, a wide range of methods has been used to assess posture, from self-report to observation to direct technical measurements. It has generally been considered that posture estimates become ‘more correct’ as one moves along this spectrum (Winkel and Mathiassen, 1994; van der Beek and Frings-Dresen, 1998). While this hierarchy is supported from a reliability standpoint – tools at lower levels are typically associated with larger methodological variance – it is not as clear whether this supposition holds regarding the validity of a tool. This seemingly paradoxical situation can result since the ability of a measurement tool to produce a faithful measurement depends on the conditions in which the measurements are made and not only on the technical attributes of the device itself. During posture measurement, errors can occur when using highly precise technical devices due to the interaction between the externally mounted device and the soft tissue overlying the rigid bony structures to be measured. A recent publication from our research team (Jackson et al., 2015) challenged the notion of whether direct technical measurement using inclinometry (INC) constitutes a superior, ‘gold standard’ scale on which to measure upper arm elevation angles (UAEA – Table 1) found a systematic bias in INC measured UAEA when compared to ‘true’ angles determined via meticulous, assisted-observation positioning of the arm: INCs underestimated both arm abduction and arm flexion angles by an average of approximately 10° across the 0–180° range of postures tested (Jackson et al., 2015). These findings are concerning in two ways. First, they question whether the results of an INC data collection quantify upper arm elevation postures in a way that matches our inherent understanding of how arm angles should appear. By extension, this also questions the use of INC data as a ‘gold standard’ to which other data are validated. Second, if INC data differ systematically from data obtained using other posture assessment methods, direct comparison of results is questionable. This is paramount to consider since postures determined using different methods or tools are routinely compared without adjusting for difference in scale; for example, direct comparison of arm posture estimates obtained via observation and inclinometry (Juul-Kristensen et al., 2001; Trask et al., 2013, 2014). Utilisation of postural data obtained according to different measurement scales (or differently biased measurement tools) will hinder attempts to elicit clear exposure–response relationships.Observation tools are also routinely used for assessing postures. This group of tools are generally considered to provide a good trade-off between the high error of self-reported data and the seemingly high cost of direct technical measurements (Kilbom, 1994; David, 2005; Bao et al., 2009) - although this cost supposition has recently been questioned (Trask et al., 2013). A wide range of observational tools exist, ranging from checklists performed in real time to assess activities or general workloads, to posture ratings from video sequences or still images, made at differing levels of resolution. Validity and variability (‘reliability’ between and within observers) have been considered for many observation tools (see Takala et al. (2010) for a thorough review). However, only a few studies evaluated methods that required observers to make postural estimates at a high degree of resolution, i.e. to the nearest degree rather than within the range of a posture interval (Ericson et al., 1991; Genaidy et al., 1993; Covalla, 2003; Bao et al., 2009; Dartt et al., 2009; Xu et al., 2011; Qu et al., 2012; Rezagholi et al., 2012). This high degree of resolution would be required for detailed comparisons of results between studies, determining the effects of ergonomic interventions, or establishing exposure–response relationships. Of these papers, two binned the estimated data prior to evaluating the statistical properties (Bao et al., 2009; Dartt et al., 2009), and thus could not report observer agreement or error in high-resolution angle measurements. Five studies evaluated validity by providing estimates of error between observation and ‘true’ angles: two examining static, planar UAEA, and three examining UAEA during simulated work. In all cases, image data for observation was collected in the laboratory under ideal viewing conditions, that is, with good lighting, no visual obstructions, no baggy clothing. Among the planar posture studies, the mean absolute observation errors across the full range of shoulder angles tested ranged from 6° to 9° (Genaidy et al., 1993; Qu et al., 2012) (where ‘truth’ was determined either by goniometer measurement (Genaidy et al., 1993) or digitization of the observed images (Qu et al., 2012)). These error estimates include contributions from within-observer variability between repeated estimates and from bias (if present), but do not discriminate between the two. Only Genaidy reported algebraic mean error and showed a slight underestimation of −1.3° by observers assessing planar arm flexion postures. Of the studies investigating a simulated work task, where UAEAs were not restrained to a single plane (Ericson et al., 1991; Covalla, 2003; Xu et al., 2011), one reported a similar slight underestimation of −3.0°, particularly for angles above 50° (Covalla, 2003) while one reported overestimations of UAEA, with a mean error of approximately 8° (Xu et al., 2011). The third study found that the median observed value overestimated arm elevation by approximately 5° (Ericson et al., 1991). It is therefore difficult to conclude whether observed estimates are biased from the truth under ideal observation conditions, let alone under conditions occurring in real working environments. Variability expressed in terms of variance components within and between observers was only presented in one of the aforementioned ‘high resolution’ posture assessment papers (Rezagholi et al., 2012), and data were only given averaged across the range of angles seen during the task. Within- and between-observer variance estimates are required in addition to measures of the validity to truly understand the practical application of observation as a posture exposure quantification method. Further, to understand whether observers are equally consistent and correct at estimating different UAEAs, information on variance components is required at specific angles rather than just across a range of angles.The aims of this study were therefore (i) to determine the performance (i.e. the bias and within- and between-observer variability) of observers estimating upper arm postures repeatedly via a posture matching computer software program from still images taken under ideal observation conditions; (ii) to determine the extent to which performance is dependent on the posture at which observations are made; and (iii) if observations are biased, to determine whether that bias can be effectively adjusted for via calibration.

@&#CONCLUSIONS@&#
