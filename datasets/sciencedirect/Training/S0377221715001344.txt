@&#MAIN-TITLE@&#
Time-inconsistent multistage stochastic programs: Martingale bounds

@&#HIGHLIGHTS@&#
Stochastic optimization problems are time-inconsistent.Due to time-inconsistency, the risk profile has to be adapted subsequently.A stage-wise, dynamic decomposition is presented.The optimal risk profile evolves as a martingale process.

@&#KEYPHRASES@&#
Stochastic optimization,Risk measure,Average Value-at-Risk,Dynamic programming,Time consistency,

@&#ABSTRACT@&#
Multistage stochastic programs show time-inconsistency in general, if the objective is neither the expectation nor the maximum functional.This paper considers distortion risk measures (in particular the Average Value-at-Risk) at the final stage of a multistage stochastic program. Such problems are not time consistent. However, it is shown that by considering risk parameters at random level and by extending the state space appropriately, the value function corresponding to the optimal decisions evolves as a martingale and a dynamic programming principle is applicable. In this setup the risk profile has to be accepted to vary over time and to be adapted dynamically. Further, a verification theorem is provided, which characterizes optimal decisions by sub- and supermartingales. These enveloping martingales constitute a lower and an upper bound of the optimal value function.The basis of the analysis is a new decomposition theorem for the Average Value-at-Risk, which is given in a time consistent formulation.

@&#INTRODUCTION@&#
Coherent risk measures have been introduced by Artzner et al. in the pioneering papers (Artzner, Delbaen, & Heath, 1997) and (Artzner, Delbaen, Eber, & Heath, 1999). The set of axioms, which are proposed there, is widely accepted nowadays. Approximately 10 years later the same group of authors considered risk measures again in a multistage framework in Artzner, Delbaen, Eber, Heath, and Ku (2007). These authors notice that the Average Value-at-Risk, the most important risk measure, is not time consistent in the sense specified in their paper. Importantly, they relate time-consistency to the fundamental dynamic programming principle, known as Bellman’s principle (cf.  Fleming and Soner, 2006).For giving a precise definition of time-consistency (time inconsistency, respectively) one has to distinguish between time-inconsistent risk measures and time-inconsistent decision problems.Artzner et al. consider the following notion of time-inconsistency in Artzner et al. (2007): a risk measure ρ applied to a random variable Y is said to be time-consistent, if knowing the valueρ(Y|F)for all conditional distributions for any conditioning σ-algebraFis sufficient to calculate its unconditional value ρ(Y). Their counterexample, showing that the Average Value-at-Risk is time-inconsistent in this sense, is reconsidered and resolved in this paper below (Fig. 2).The notion of time-consistent decision problems is related, but slightly different: a multistage stochastic decision problem is time-consistent, if resolving the problem at later stages (i.e., after observing some random outcomes), the original solutions remain optimal for the later stages.Shapiro (2009, p. 144), referring to a tree-structured problem, remarks that for time-consistency of a problem the solution at each stage is not allowed to depend on random parameters, which cannot follow this stage (i.e., in the language of trees, lie in other subtrees): “It is natural to consider the conceptual requirement that an optimal decision at state ξtshould not depend on states which do not follow ξt, i.e., cannot happen in the future. That is, optimality of our decision at state ξtshould only involve future children nodes of state ξt. We call this principle time consistency.”Carpentier, Chancelier, Cohen, de Lara, and Girardeau (2012, p. 249) formulate the property as follows: “The sequence of optimization problems is said to be dynamically consistent if the optimal strategies obtained when solving the original problem at time t0 remain optimal for all subsequent problems. In other words, dynamic consistency means that strategies obtained by solving the problem at the very first stage do not have to be questioned later on.”In order to enforce time-consistency for decision problems significant efforts and investigations have been initiated to identify classes of multiperiod risk measures which lead to time-consistency and allow stagewise decompositions. To this end, nested conditional risk measures have been proposed by Shapiro and Ruszczyński (Ruszczyński, 2010; Ruszczyński & Shapiro, 2006; Shapiro, 2009) (cf. as well Shapiro, 2012) and the recent paper by Carpentier et al. (2012). Here, we follow a different path.First, we will maximize the acceptability rather than minimize risk. This is for ease of presentation of the results. Since acceptability measures can be seen as the negatives of risk measures this is no restriction. Secondly, we stick to the problem of maximizing the acceptability of the final outcome, where the acceptability is measured by a plain distortion measure, not by a nested one. We believe that nested risk or acceptability measures are difficult to interpret and are not what decision makers would understand under multistage risk or acceptability.As a measure for acceptability we use initially the Average Value-at-Risk (AV@R)defined below in (1), and explain later how the results extend to general distortion measures. As illustration of time-inconsistency of decision problems involvingAV@Rconsider the example displayed in Fig. 1. Suppose that the decision has to made, which out of the two tree processes is to be selected for the criterion to maximize the finalAV@R10percent. It can be easily seen that looking at the conditionalAV@R’s at intermediate time 1, the left tree has to be preferred to the right one. Looking at the same criterion, but at time 0, the preference is opposite. Therefore, this introductory example confirms the fact that in general the maximization of theAV@Rof the final outcome leads to time-inconsistency of decisions.This paper is based on a new decomposition of theAV@Rand related measures. The decomposition measures risk on conditional level only, and it recovers the initial risk measure by collecting the conditional risk measures via an expectation. In this setup the risk profile has to be adapted conditionally, such that the conditional risk profile is not static any longer.Additional information changes the perception of risk. The adaptive choice of appropriate measures of risk complies with the course of action of a risk manager who adjusts the preferences whenever additional information is available. The decision maker is less reluctant, if an observation reveals that the future will be bright, but conversely she or he will be more strict if losses at the end become more likely. This gives rise to defining an extended notion of a conditional risk measure, which is not just the same risk measure applied to conditional distributions, but which may be a different functional for different conditional distributions, depending on its respective history.By involving adapted conditional risk measures it is possible to recover dynamic programming principles for multistage stochastic programs. Moreover verification theorems, which are central in dynamic control, are established here for multistage stochastic programs. The dynamic programming equations presented are based on the dual representation of the risk measure, and different to those provided by Shapiro (2009). The presented approach allows a characterization of optimal solutions of a multistage stochastic program in terms of enveloping sub- and supermartingales. It is shown that a solution of a multistage problem evolves as a martingale over time, where different risk measures are encountered at each stage.Dynamic programming equations notably cannot remove the time inconsistency, which is inherent to these problems. But these equations come along with verification theorems, and it is their purpose to enable checking, if a given policy is optimal. By assessing the enveloping sub- and supermartingales it is moreover possible to provide upper and lower bounds, such that the quality of a given multistage policy can be assessed with these sub- and supermartingales as well.Section 2 provides the setting for the Average Value-at-Risk, as this risk measure is basic for the presentation. Next, the conditional version is considered. The decomposition theorem, the central statement of this paper, is contained in Section 4 and Section 5 characterizes its properties. Section 6 introduces the multistage optimization problem. Section 7 exposes the dynamic programming formulation, while the subsequent Section 8 introduces the martingale representations, which are in line with dynamic programming.We reduce the conceptual description of the problem to the Average Value-at-Risk,AV@R. This reduction is justified, as more general coherent risk measures—distortion risk measures—are composed in a linear way of Average Value-at-Risks at different levels. Further, Kusuoka’s theorem provides all version independent (also known as law invariant) risk measures via distortion risk measures (cf., for example, Pflug & Römisch, 2007), such that this reduction is without loss of generality.The Average Value-at-Risk is considered in its concave variant involving the lower quantiles of the distribution function FYof the random variable Y,(1)AV@Rα(Y):=1α∫0αFY−1(u)du(0<α≤1),where α is called level. In this settingAV@Raccounts for profits, which are subject to maximization. Throughout this paper we shall assume that the profit variable Y is aR-valued random variable defined on a general, filtered probability space(Ω,(Ft)t∈{0,1,⋯T},P). For convenience of presentation we assume thatY∈L∞(FT,P)(L1(FT,P)could be chosen in many, but not in all situations).The dual representation of the Average Value-at-Risk at level α is(2)AV@Rα(Y)=inf{E(YZ):0≤Z,αZ≤1andE(Z)=1},where the expectation is with respect to the measure P, the infimum in (2) is among all positive random variables Z ≥ 0 with expectationE(Z)=1(i.e., Z are densities), satisfying the additional truncation constraint αZ ≤ 1, as indicated. The infimum is attained if α > 0, and in this case the optimal random variable Z in (2) is coupled in an anti-monotone way with Y (cf. Nelsen, 1998).The equivalent relation11x+is the positive part of x, that isx+=xif x ≥ 0, andx+=0else.(3)AV@Rα(Y)=maxq∈Rq−1αE(q−Y)+was elaborated by Rockafellar and Uryasev (2002). This representation replaces the infimum in (2) by a maximum, which is very helpful in the context of profit maximization. The maximum in (3) is attained at someq*∈Rsatisfying the quantile condition P(Y < q*) ≤ α ≤ P(Y ≤ q*). For the sake of completeness we mention that the Average Value-at-Risk at levelα=0is defined asAV@R0(Y)=limα→0AV@Rα(Y)=ess inf(Y).The mappingY↦AV@Rα(Y)is concave in the present setting, while the Lorentz curve(4)α↦α·AV@Rα(Y)=∫0αFY−1(u)duis convex in its parameter α. These properties will be exploited to characterize optimal solutions via saddle points.The Average Value-at-Risk, as defined above, is a real-valued function onL∞(FT),whereFTis the sigma algebra measuring the information at the time horizon T. The Average Value-at-Risk quantifies the entire future risk associated with Y at stage 0 in the single valueAV@R(Y). Having multistage stochastic decision problems in mind it is desirable to have an idea of the accumulated risk at an intermediate stage t as well (0 < t < T). To describe this evolution sigma algebrasFt⊂FTare considered, which assemble the information up to time t.Attempts to define a conditional Average Value-at-Risk for a smaller sigma algebraFt⊂FTare contained in Ruszczyński and Shapiro (2006) and in Pflug and Ruszczyński (2005). An extension to this initial definition considers a level parameter α, which depends on the history (we are grateful to Werner Römisch for pointing out the references Cheridito and Kupper ([2009,2011], Section 2.3.1) and Detlefsen and Scandolo (2005)). This setting is broad enough to allow a decomposition.Here the level α is not considered fixed and constant any longer, butFt-measurable instead. We writeαt⊲Ftto express that αtis measurable with respect toFt. For the trivial sigma algebraF0={∅,Ω}the statementα⊲F0notably expresses that α is deterministic, i.e., a constant.Definition 1Conditional Average Value-at-Risk at random levelThe conditional Average Value-at-Risk at random levelαt⊲Ft(0≤αt≤1) of a random variableY∈L∞(FT,P)22The restriction toY∈L∞(FT,P)is made for convenience of presentation. The conditional Average Value-at-Risk is well defined onL1(FT,P)wherever αt< 1.is theFt-random variable(5)AV@Rαt(Y|Ft):=ess inf{E(YZ|Ft)|Z∈L∞(FT),0≤Z,αtZ≤1E(Z|Ft)=1},where1is the random variable being identically 1.33All pointwise relations are required to hold almost surely.It is enough to employ Z ∈ L∞ in (5), as L∞ is dense in the dual. For a complete treatment of the domain and the dual consider Pichler (2013).Although the level αtis random it should be noted that it is measurable with respect toFt,but not with respect to the largerFT.αt⊲Ftdepends on the history only, and this is an important limitation in comparison withY⊲FT.Remark 3E(YZ|Ft)is a random variable, the essential infimum in (5) thus is an infimum over a family of random variables, and the resultingAV@Rαt(Y|Ft)is aFt-random variable itself.The following characterization, used in Pflug and Römisch (2007) to define the conditional Average Value-at-Risk in a simpler context, extends to the situationαt⊲Ft,but replaces the essential infimum by a usual infimum.Proposition 4Characterization of the Average Value-at-RiskSuppose thatαt⊲Ft.(i)The conditional Average Value-at-Risk at random level αt is aFt-random variable satisfyingE[1B·AV@Rαt(Y|Ft)]=inf{E(YZ):0≤Z,αtZ≤1B,E(Z|Ft)=1B}for every setB∈Ft.Moreover the conjugate duality relationAV@Rαt(Y|Ft)=ess infZ∈L∞{E(YZ|Ft)−AV@Rαt*(Z|Ft)}=ess inf{E(YZ|Ft):E(Z|Ft)=1,0≤ZandαtZ≤1}holds, where the conjugate function is the indicator function(6)AV@Rαt*(Z|Ft)={0ifE(Z|Ft)=1,0≤ZandαtZ≤1,−∞else.Notably αt, Z andE(Z|Ft)may have various versions. The defining equation (6) is understood to provide a version ofAV@Rαt*for any such version andAV@Rαt*thus is well-defined.The essential infimumess inf,by the characterizing theorem (Appendix A in Karatzas and Shreve (1998) or Dunford and Schwartz (1957)), is a density provided by the Radon–Nikodým theorem satisfying∫BAV@Rαt(Y|Ft)dP=inf{E[∑k=1K1BkE(YZk|Ft)]:0≤Zk,αtZk≤1,E(Zk|Ft)=1},where the infimum is among feasible Zkand pairwise disjoint setsBk∈FtwithB=⋃k=1KBk. The random variableZ:=∑k=1K1BkZksatisfiesZ=1B·Z,and the equation in the latter display thus rewrites asE[1BAV@Rαt(Y|Ft)]=inf{EYZ:0≤Z,αtZ≤1B,E[Z|Ft]=1B},which is the desired assertion.The second assertion is the conditional equivalent to (2). For this recall the Fenchel–Moreau–Rockafellar duality theorem (cf. Ruszczyński and Shapiro (2006) or Pflug and Römisch (2007, Theorem 2.51) on conditional risk mappings), which states thatAV@Rαt(Y|Ft)=ess infZ∈L∞E(YZ|Ft)−AV@Rαt*(Z|Ft),whereAV@Rαt*(Z|Ft)=ess infY∈L∞E(YZ|Ft)−AV@Rαt(Y|Ft).ThusAV@Rαt*(Z|Ft)≤ess infγ∈RE[(γ1)Z|Ft]−AV@Rαt(γ1|Ft)=ess infγ∈Rγ(E[Z|Ft]−1)and henceAV@Rα*(Z|Ft)=−∞on theFt-set{E(Z|Ft)≠1}.Next suppose that B ≔ {Z < 0} has positive measure, thenE(Z1B|Ft)<0on B. ThusAV@Rαt*(Z|Ft)≤ess infγ>0E(γ1BZ|Ft)−AV@Rαt(γ1B|Ft)≤ess infγ>0γE(Z1B|Ft)=−∞on B. Finally suppose thatC:={αtZ>1}has positive measure, so(7)AV@Rαt*(Z|Ft)≤ess infγ>0E(−γαt1CZ|Ft)−AV@Rαt(−γαt1C|Ft)≤ess infγ>0−γE(αtZ1C|Ft)+γE(1C|Ft)=ess infγ>0−γ(E[(αtZ−1)1C|Ft])=−∞on C by the same reasoning. Combining all three ingredients gives the statement, as they constitute all conditions for the Average Value-at-Risk in (5).The first inequality in (7) is immediate by choosing the particular random variableY=−γαt1C. The second inequality follows from the monotonicity property, as is detailed further in Theorem 11 below.□Given the Average Value-at-Risk conditionally onFt,how can one reassemble the Average Value-at-Risk at time 0? This is the content of the next theorem, which contains a central result on the Average Value-at-Risk in multistage situations. It is the basis for the martingale representation and the verification theorems in multistage stochastic optimization, which are presented in Section 8 then.Theorem 6Decomposition of the Average Value-at-RiskLetY∈L∞(FT)andFt⊂FT.(i)For a (deterministic) constant α ∈ [0, 1] the Average Value-at-Risk obeys the decomposition(8)AV@Rα(Y)=infE[Zt·AV@Rα·Zt(Y|Ft)],where the infimum is among all densitiesZt⊲Ftwith 0 ≤ Zt,αZt≤1andE(Zt)=1. For α > 0 the infimum in (8) is attained.Moreover, if Z is the optimal dual density for (2), then(9)Zt=E(Z|Ft)is the best choice in (8).LetFt⊂Fτ⊂FTbe nested sigma algebras. The conditional Average Value-at-Risk at random levelαt⊲Ft(0≤αt≤1) has the recursive (nested) representation(10)AV@Rαt(Y|Ft)=ess infE[Zτ·AV@Rαt·Zτ(Y|Fτ)|Ft],where the infimum is among all densitiesZτ⊲Fτwith 0 ≤ Zτ,αtZτ≤1andE[Zτ|Ft]=1.Note that α · Ztin the index of the innerAV@Rα·Ztis aFtrandom variable satisfying0≤α·Zt≤1,which means thatAV@Rα·Zt(Y|Ft)is indeed available and almost everywhere well-defined.One might think that a nested decomposition of theAV@Rmight be a consequence of the fact that it can be written in terms of utility functions (having in mind that expected utility allows always a dynamic decomposition). By introducing the family of concave utility functionsUqα(y):=q−1α(q−y)+,theAV@Rαcan be written, following (3), asAV@Rα(Y)=maxq∈REUqα(Y).Obviously, for the conditional distributions(Y|Ft)the maximizing q depends onFt,but this is not the crucial point: in fact, as is the content of the decomposition theorem (Theorem 6), only the extension of the class(Uqα)q∈Rto the much larger class(Uqα)q∈R,α∈[0,1]of utility functions with different q’s and α’s on every atom ofFtallows a decomposition.For any (deterministic) level 0 ≤ α ≤ 1 it holds thatAV@Rα(Y)≤E[AV@Rα(Y|Ft)]≤E(Y);for any randomαt⊲Ft(0≤αt≤1), moreoverAV@Rαt(Y|Ft)≤E[AV@Rαt(Y|Fτ)|Ft]≤E(Y|Ft).The decomposition theorem, Theorem6. We shall assume first that α > 0.LetZ⊲Ftbe a simple function (i.e., a step function with finitely many outcomes) with Z ≥ 0 andEZ=1,i.e.,Z=∑ibi1Biwhere bi≥ 0,Bi∈FtandBi∩Bj=∅whenever i ≠ j. Then, by the characterization (Theorem 4),E[ZAV@Rα·Z(Y|Ft)]=∑ibiE[1BiAV@Rα·Z(Y|Ft)]=∑ibiinf{E[YXi]:0≤Xi,αbi1BiXi≤1Bi,E[Xi|Ft]=1Bi}=inf{∑ibiE[YXi]:0≤Xi,αbi1BiXi≤1Bi,E[Xi|Ft]=1Bi}.AsE[Xi|Ft]=1Bi,together with the additional constraint Xi≥ 0, one infers thatXi=0on the complement of Bi, that is to sayXi1Bi=Xi.DefineX:=∑i1BiXi,thusZX=∑i,jbi1Bi1BjXj=∑ibi1BiXi=∑ibiXiandE[XYZ]=∑ibiE[YXi],such that we further obtain by assembling on the mutually disjoint sets Bi(11)E[Z·AV@Rα·Z(Y|Ft)]=inf{E[YZX]:0≤X,αZX≤1,E[X|Ft]=1}.Note next thatE[XZ]=E[Z·E[X|Ft]]=E[Z·1]=1,and hence (associateZ˜with XZ)E[Z·AV@Rα·Z(Y|Ft)]≥inf{E[YZ˜]:0≤Z˜,αZ˜≤1,E[Z˜]=1}=AV@Rα(Y).It follows by semi-continuity thatE[Z·AV@Rα·Z(Y|Ft)]≥AV@Rα(Y)for all Z ≥ 0 withEZ=1andαZ≤1.To obtain equality it remains to be shown that there is aZt⊲Ftsuch thatAV@Rα(Y)=E[ZtAV@RαZt(Y|Ft)]. For this let Z be the optimal dual variable in Eq. (2), that isAV@Rα(Y)=EYZwith Z ≥ 0,αZ≤1andEZ=1,and defineZt:=E[Z|Ft].Zt⊲Ftis feasible, as 0 ≤ Zt,αZt≤1andEZt=1. DefineX:={ZZtifZt>01ifZt=0and observe that X is P-a.e. well-defined. Moreover 0 ≤ X (as 0 ≤ Z),αZtX=αZ≤1andE[X|Ft]=1,such that X is feasible for (11). One deduces thatE[Zt·AV@Rα·Zt(Y|Ft)]=inf{E[YZtX]:0≤X,αZtX≤1,E[X|Ft]=1}≤EYZtZZt=EYZ=AV@Rα(Y).This is the converse inequality such that assertion (8) follows. The minimum is thus indeed attained forZt=E[Z|Ft],where Z is the optimal dual variable for theAV@Rα,which exists for α > 0.As forα=0recall thatAV@R0(Y)=ess infYandAV@R0(Y)≤AV@R0(Y|Ft),and thusAV@R0(Y)=EZtAV@R0(Y)≤EZtAV@R0(Y|Ft)=EZtAV@R0·Zt(Y|Ft).For the converse inequality choose Zε ≥ 0 withEZɛY≤AV@R0(Y)+ɛ. By the conditionalL1−L∞-Hölder inequality it holds thatAV@R0(Y)+ɛ≥EZɛY≥E(E[Zɛ|Ft]AV@R0(Y|Ft))≥E(E[Zɛ|Ft]AV@R0(Y))=AV@R0(Y),henceAV@R0(Y)≥EZtɛAV@R0·Ztɛ(Y|Ft)−ɛforZtɛ:=E[Zɛ|Ft].The proof for the remaining statement (iii) of the theorem reads along the same lines as above, but conditioned onFt.□Both, Figs. 2 and 3, depict a typical, simple situation with two stages in time, the increasing sigma algebras are visualized via the tree structure.The example in Fig. 2 is due to Artzner et al. (2007). The Average Value-at-Risk of the random variable Y in Fig. 2 isAV@R23(Y)=−1. The intriguing fact here is that the conditionalAverage Value-at-Risk, computed with the initialα=23,isAV@R231(Y|Ft)=+1,which is in conflicting contrast toAV@R23(Y)=−1.However, the decomposition Theorem 6 eliminates the discrepancy by involving the conditional Average Value-at-Risk at random levelαt⊲Ft.Both figures display the optimal variables Z and Z1: Z is the optimal dual for (2), andZ1=E(Z|Ft)is the optimal dual for the decomposition att=1according (9).This section elaborates that the conditional Average Value-at-Risk at random level basically preserves all properties of the usual Average Value-at-Risk. The properties are essential in the following section for multistage stochastic optimization, where the problem is reconsidered for all sigma algebras in the filtration.Theorem 11For the conditional Average Value-at-Risk at random levelαt⊲Ft(0≤αt≤1) the following hold true:(i)Predictability:AV@Rαt(Y|Ft)=YifY⊲Ft;Translation equivariance:44In an economic or monetary environment this is often called Cash invariance instead.AV@Rαt(Y+c|Ft)=AV@Rαt(Y|Ft)+cifc⊲Ft;Positive homogeneity:AV@Rαt(λY|Ft)=λAV@Rαt(Y|Ft)whenever λ is nonnegative, bounded andFt-measurable, λ ≥ 0 andλ⊲Ft;Monotonicity:AV@Rαt1(Y1|Ft)≤AV@Rαt2(Y2|Ft)whenever Y1 ≤ Y2andαt1≤αt2almost surely;Concavity:AV@Rαt((1−λ)Y0+λY1|Ft)≥(1−λ)AV@Rαt(Y0|Ft)+λAV@Rαt(Y1|Ft)forλ⊲Ftand0≤λ≤1almost surely;Lower and Upper bounds:AV@R0(Y)≤AV@R0(Y|Ft)≤AV@Rαt(Y|Ft)≤E(Y|Ft).As for the Predictability just observe thatAV@Rαt(Y|Ft)=ess inf{Y·E(Z|Ft):E(Z|Ft)=1,0≤Z,αtZ≤1},=ess inf{Y·1:E(Z|Ft)=1,0≤Z,αtZ≤1}=YwheneverY⊲Ft,and Translation equivariancefollows fromAV@Rαt(Y+c|Ft)=ess inf{E(YZ|Ft)+cE(Z|Ft):E(Z|Ft)=1,0≤Z,αtZ≤1}=ess inf{E(YZ|Ft)+c:E(Z|Ft)=1,0≤Z,αtZ≤1}=AV@Rαt(Y|Ft)+c.To accept that the conditional Average Value-at-Risk is positively homogeneous observe that the assertion is correct forλ=1A(A∈Ft); by passing to the limit one gets the assertion for simple functions (step-functions) first, then for any nonnegative functionλ∈L∞(Ft).To prove Concavity as stated observe that(1−λ)E(Y0Z|Ft)+λE(Y1Z|Ft)=E(((1−λ)Y0+λY1)Z|Ft)by the measurability assumptionλ⊲Ft,henceAV@Rαt((1−λ)Y0+λY1|Ft)=ess infZ(1−λ)E(Y0Z|Ft)+λE(Y1Z|Ft)≥ess infZ0,Z1(1−λ)E(Y0Z0|Ft)+λE(Y1Z1|Ft)≥(1−λ)ess infZ0E(Y0Z0|Ft)+λess infZ1E(Y1Z1|Ft)=(1−λ)AV@Rαt(Y0|Ft)+λAV@Rαt(Y1|Ft),where Z0 ≥ 0 and Z1 ≥ 0 are chosen to satisfyE(Zi|Ft)=1andαtZi≤1each.To observe the monotonicity property recall thatαt1≤αt2,henceAV@Rαt1(Y1|Ft)=ess infZ{E(ZY1|Ft):Z≥0,αt1Z≤1,E(Z|Ft)=1}≤ess infZ{E(ZY2|Ft):Z≥0,αt1Z≤1,E(Z|Ft)=1}≤ess infZ{E(ZY2|Ft):Z≥0,αt2Z≤1,E(Z|Ft)=1}=AV@Rαt2(Y2|Ft).The Upper boundfinally becomes evident becauseZ=1is feasible for (5), the lower bounds already have been used in (7) (the characterization, Theorem 4) above.□The Average Value-at-Risk, in its respective variable, is convex and concave:(i)Concavity of the Average Value-at-RiskY↦AV@Rαt(Y|Ft)was elaborated in Theorem 11.Convexity of the Average Value-at-Risk, for the deterministic level parameter α, is mentioned in (4). The following Theorem 12 extends this observation for measurable level parameters.AV@Rin its level parameter) Let the random variables αt, Z0, Z1and λ beFtmeasurable with0≤αt≤1,0≤λ≤1,0≤αtZ0≤1and0≤αtZ1≤1,thenZλ·AV@Rαt·Zλ(Y|Ft)≤(1−λ)Z0·AV@Rαt·Z0(Y|Ft)+λZ1·AV@Rαt·Z1(Y|Ft),where Zλ is the convex combinationZλ=(1−λ)Z0+λZ1.Recall that by the definition of the conditional Average Value-at-Risk we have that(1−λ)Z0·AV@Rαt·Z0(Y|Ft)+λZ1·AV@Rαt·Z1(Y|Ft)=ess infE(Y(1−λ)Z0f0|Ft)+ess infE(YλZ1f1|Ft)=ess infE(Y((1−λ)Z0f0+λZ1f1)|Ft),where f0 ≥ 0, f1 ≥ 0,E(f0|Ft)=1,E(f1|Ft)=1,and moreoverαtZ0f0≤1andαtZ1f1≤1in the latter lines of the last display. It follows thatαt((1−λ)Z0f0+λZ1f1)≤1and henceαtZλf≤1forf:=(1−λ)Z0f0+λZ1f1Zλ. Notice that f is nonnegative as well, andE(f|Ft)=E((1−λ)Z0f0+λZ1f1Zλ|Ft)=(1−λ)Z0+λZ1Zλ=1. The latter display continues thus as(1−λ)Z0·AV@Rαt·Z0(Y|Ft)+λZ1·AV@Rαt·Z1(Y|Ft)≥ess infE(YZλf|Ft),where the essential infimum is among all random variables f ≥ 0 withE(f|Ft)=1andαtZλf≤1. Hence(1−λ)Z0·AV@Rαt·Z0(Y|Ft)+λZ1·AV@Rαt·Z1(Y|Ft)≥AV@RαtZλ(YZλ|Ft)=ZλAV@RαtZλ(Y|Ft)by positive homogeneity, and this is the desired assertion.□In addition to the defining equation (5) for the Average Value-at-Risk at random level there is a further representation, which follows the classical equivalence of (2) and (3) (cf. Ruszczyński, 2010, p. 242). The proof is along the lines of the classical equivalence and rather technical.Theorem 13The Average Value-at-Risk at strictly positive random level α > 0 has the additional representationAV@Rα(Y|Ft)=ess sup{Q−1αE[(Q−Y)+|Ft]:Q⊲Ft}where the essential supremum is among all bounded random variablesQ∈L∞(Ft)(Q⊲Ft).It is the purpose of this and the following sections to make time inconsistent stochastic optimization problems, which involve the Average Value-at-Risk or an acceptability functional, available for dynamic programming. The problem we consider here incorporates—in the sense of integrated risk management—the acceptability functional in the objective such as(12)maximizeEY+γ·AV@Rα(Y)subjecttoY∈Y.α > 0 and γ ≥ 0 are positive, deterministic parameters to account for the emphasis that should be given to risk: γ is the risk appetite, the degree of uncertainty the investor is willing to accept in respect of negative changes to its assets, which are described by the Average Value-at-Risk at the level α.The problem formulation (12) applies for optimal investment problems, it can be found in multistage decision models for electricity management as well. In applications (cf. Eichhorn, Heitsch, & Römisch, 2010) a reformulation of (12) to account for the multistage situation is typically considered, which involves a stochastic process ξt(t∈T:={0,1,⋯T}) with values in Ξt.The multistage reformulation is(13)maximizeEH(x,ξ)+γ·AV@Rα(H(x,ξ))subjecttox⊲F,x∈X,whereH:X0×⋯XT×Ξ0×⋯ΞT→Ris a function defined on appropriate spaces ΞtandXt. We writex∈X(orxt∈Xt) to express that the componentxt:Ω→Xtof the processx=(xt)t∈Thas values inXt,which itself is a convex subset of a vector space (Xt⊂Rdtfor some dimension dt, e.g. The setsXtthemselves are deterministic). The constraintx⊲Fis the nonanticipativityconstraint, that isxt⊲Ftfor all t ∈ T.Note that for the sigma algebrasFt=σ(ξ0,ξ1,⋯ξt)generated by the underlying process ξ, the nonanticipativity constraintx⊲Fforces xtto be a function of the process ξt,xt=xt(ξt),as follows from the Doob–Dynkin lemma (cf. Shiryaev, 1996, Theorem II.4.3). This reflects the fact that the decisions xthave to be fixed without knowledge of the future outcomes.We shall require the real-valued function H to be concave in x forx∈X,such thatH((1−λ)x′+λx′′,ξ)≥(1−λ)H(x′,ξ)+λH(x′′,ξ)for any fixed state ξ.By the monotonicity property and concavity of the acceptability functional it holds thus that(14)AV@Rα(H((1−λ)x′+λx′′,ξ))≥AV@Rα((1−λ)H(x′,ξ)+λH(x′′,ξ))≥(1−λ)AV@Rα(H(x′,ξ))+λAV@Rα(H(x′′,ξ)),which means that the mappingx↦AV@Rα(H(x,ξ))is concave as well. Concavity and (14) hold for distortion functionals and their conditional variants, in particular for the Average Value-at-Risk and the conditional Average Value-at-Risk at random level.Remark 14Notational conventionWe shall write H(x) for the random variable H(x) given by H(x)( · ) ≔ H(x, ·). For notational convenience we shall use the straight forward abbreviation ξi: jfor the substringξi:j=(ξi,ξi+1,⋯ξj); in particularξi:i=(ξi),andxi:i−1=(),the empty string.Some papers exclusively treat functions of the formH(x)=∑t=0THt(x0:t)in the present setting. This particular setting is just a special case and included in our general formulation and framework of problem (13).The dynamic programming principleis the basis of the solution technique developed by Bellman (1957) in the 1950s for deterministic optimal control problems. They have been extended later to account for stochastic problems as well, where typically(i)the objective is an expectation andthe transition does not depend on the history, but just on the current state of the system—that is to say for Markov chains.The decomposition of the Average Value-at-Risk elaborated in Theorem 6 is the key which allows to define—in line with the classical dynamic programming principle—a value function with properties analogous to the classical theory. The new value function overcomes the restrictions (i) and (ii), as we shall employ a risk measure in the objective, and the value function explicitly depends on the history. The value function is then used in Section 8 to state the verification theorems.The theory developed below applies to more general acceptability functionals (risk functions), other than the Average Value-at-Risk, it includes in particular all approximations of law invariant acceptability functionals by Kusuoka’s theorem of the formA=∑kγkAV@Rαk,and acceptability functionals of the type(15)A(Y)=∑tEγk·AV@Rαk(Y|Ftk)for someFtk-measurable αtand γt(0≤αt,γt⊲Ftk). However, as these more general acceptability functionals are to be treated analogously we may continue with the simple Average Value-at-Risk in lieu of the more general setting (15).For Markov processes the value function is—in a natural way—a function of time and the current status of the system. In order to derive dynamic programming equations for the general multistage problem it is necessary to carry the entire history of earlier decisions. This is respected by the following definition.Definition 16Value functionLetαt⊲Ftandγt⊲Ftbe measurable with0≤αt≤1and 0 ≤ γt. The value function at stage t is the process(16)Vt(x0:t−1,αt,γt):=ess sup(x0:t−1,xt:T)∈XE[H(x0:T)|Ft]+γt·AV@Rαt(H(x0:T)|Ft),where xt: Tin (16) is chosen such that the concatenated stringx0:T=(x0:t−1,xt,T)satisfiesx0:T∈X.The value functionVtin (16) is measurable with respect toFtfor every t ∈ T. It depends on•the decisionsx0:t−1up to timet−1andthe random model parametersαt⊲Ftandγt⊲Ft.To simplify notation we shall writesupxt:τinstead ofsupxt:τ∈Xt:τ,etc., in what follows.The initial staget=0.The initial problem (13) can be expressed by the value function at initial timet=0and assuming that the sigma-algebraF0is trivial. In this caseα0=αandγ0=γare deterministic, and(17)(13)=supx0:T∈XEH(x0:T)+γ·AV@Rα(H(x0:T))=ess supx0:T∈XE[H(x0:T)|F0]+γ·AV@Rα(H(x0:T)|F0)=V0((),α,γ),which expresses the initial problem (13) in terms of the value function.The intermediate stagst=1⋯T.The decomposition theorem (Theorem 6) above allows to relate the value function at different stages. The recursion obtained can be considered as generalized dynamic programming principle.Assume that α > 0, and H is random upper semi-continuous with respect to x and ξ evaluates in some convex, compact subset ofRn. Then the following hold true.(i)At terminal time T the value function evaluates toVT(x0:T−1,αT,γT)=(1+γT)ess supxTH(x0:T).For any t < τ (t, τ ∈ T) the recursive relation(18)Vt(x0:t−1,αt,γt)=ess supxt:τ−1ess infZt:τE[Vτ(x0:τ−1,αt·Zt:τ,γt·Zt:τ)|Ft],holds true, whereZt:τ⊲Fτ,0 ≤ Zt: τ,αtZt:τ≤1andE[Zt:τ|Ft]=1.A direct evaluation at terminal timet=TgivesVT(x0:T−1,αT,γT)=ess supxT:TE[H(x0:T)|FT]+γT·AV@RαT(H(x0:T)|FT)=ess supxTH(x0:T)+γT·H(x0:T)=(1+γT)ess supxTH(x0:T),because the random variables, conditionally on the entire observations ξ0: T, are constant. The final maximizations overxT:T=xT(ξ0:T)are deterministic, because all stochastic observations are available at this final stage.As for the recursion at an intermediate time (t < T) observe thatVt(x0:t−1,αt,γt)=ess supxt:TE[H(x0:T)|Ft]+γt·AV@Rαt(H(x0:T)|Ft)=ess supxt:Tess infZt:t+1E[E[H(x0:T)|Ft+1]+γt·Zt:t+1·AV@Rαt·Zt:t+1×(H(x0:T)|Ft+1)|Ft]due to the nested decomposition (10) of the Average Value-at-Risk at random level, elaborated in Theorem 6. Theess infis among all random variablesZt:t+1⊲Ft+1satisfyingαtZt:t+1≤1andE(Zt:t+1|Ft)=1. By the discussions in the preceding sections the inner expression is concave in x0: Tand convex inZt:t+1.Zt:t+1is moreover chosen from the σ(L∞, L1) compact setZt:t+1∈{Z∈L∞:0≤Z≤1α}. By Sion’s minimax theorem (cf. Sion, 1958 and Komiya, 1988) one may thus interchange the min  and max  to obtainVt(x0:t−1,αt,γt)=ess supxtess infZt:t+1ess supxt+1:TE[E[H(x0:T)|Ft+1]+γt·Zt:t+1·AV@Rαt·Zt:t+1×(H(x0:T)|Ft+1)|Ft].As H is upper semi-continuous by assumption one may further apply the interchangeability principle (cf. Rockafellar and Wets, 1997, Theorem 14.60, or Shapiro, Dentcheva, and Ruszczyński, 2009, p. 405) such thatVt(x0:t−1,αt,γt)=ess supxtess infZt:t+1E[ess supxt+1:TE[H(x0:T)|Ft+1]+γt·Zt:t+1·AV@Rαt·Zt:t+1×(H(x0:T)|Ft+1)|Ft]=ess supxtess infZt:t+1E[Vt+1(x0:t,αt·Zt:t+1,γt·Zt:t+1)|Ft],which is the desired relation forτ=t+1. Repeating the computation from abovet−τtimes, or conditioning onFτinstead ofFt+1reveals the general result.□The value functionVtintroduced in (16) is a function of some generalαt⊲Ftandγt⊲Ft. To specify for the right and optimal parameters assume that the optimal policyx=x0:Tof problem (13) exists.55Optimal decisions x, and the corresponding optimal dual variables Z are displayed in bold letters.Theorem 18 then gradually reveals the optimal dual variablesZT,ZT−1,⋯and finally Z0 (assuming again that the respectiveargmins of the essential infimumess infexist). The conditionsE(Zτ|Ft)=1(τ > t) imposed on the dual variables suggest to compound the densities and to consider the densitiesZt:τ:=Zt·Zt+1·⋯Zτsuch thatE(Zt:τ|Ft)=ZtandE(Z0:τ|Ft)=Z0:t. With this setting the process Z ≔ (Z0: t)t ∈ Tis a martingale, satisfying moreover 0 ≤ ZtandαZt≤1during all times t ∈ T. The optimal pair (x, Z) is a saddle point for the Lagrangian corresponding to the initial problem (13).This gives rise for the following definition.Definition 19Let α ∈ [0, 1] be a fixed level.(i)Z=(Zt)t∈Tis a feasible (for the nonanticipativity constraints) process of densities if(a)Ztis a martingale with respect to the filtrationFtand0 ≤ Zt,αZt≤1andE(Zt)=1for all t ∈ T.The intermediate densities areZt:τ:={ZτZt−1ifZt−1>00else(0<t<τ),and Z0: τ≔ Zτ.For feasible x and Z we consider the stochastic processMt(x,Z):=Vt(x0:t−1,αZ0:t,γZ0:t)(t∈T)where α and γ are simple real numbers.Recall from (17) that M0 is a constant (asF0is trivial) solving the original problem (13) if (x, Z) are optimal. Above that we shall prove in the next theorem that Mt(x, Z) is a martingale in this case (we refer to the papers (Rockafellar & Wets, 1976; 1978) by Rockafellar and Wets for very early occurrences of martingales in a related context).Theorem 20Martingale propertyGiven thatxandZare optimal, then the process Mt(x, Z) is a martingale with respect to the filtrationFt.Conversely, if Mt(x, Z) is a martingale and theargmaxsets (for x) andargminsets (for Z) in(18)are nonempty, then x and Z are optimal.By the dynamic programming equation (18) and the respective maximality ofZt+1andxt+1we have thatMt(x,Z)=Vt(x0:t−1,αZ0:t,γZ0:t)=ess supxt:tess infZt+1E[Vt+1((x0:t−1,xt),α·Z0:tZt+1,γ·Z0:tZt+1)|Ft]=ess supxt:tE[Vt+1((x0:t−1,xt),α·Z0:t+1,γ·Z0:t+1)|Ft]=E[Vt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]=E[Mt+1(x,Z)|Ft]again by the interchangeable principle. Mt, hence, is a martingale with respect to the filtrationFt.The converse follows from the following corollary.□Verification theorems characterize optimal decisions in Bellman’s principle. For multistage stochastic optimization verification theorems are accessible as well, they are provided by the following corollary.Corollary 21Verification theoremLet x be feasible for(13), and Z be feasible according Definition19.(i)Suppose thatWsatisfiesWT(x0:T−1,αZ0:T,γZ0:T)≥(1+γZ0:T)H(x0:T(ξ0:T))andWt(x0:t−1,αZ0:t,γZ0:t)≥ess supxtE[Wt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft],then the processWt(x0:t−1,αZ0:t,γZ0:t)(t ∈ T) is a supermartingale dominatingV(x0:t−1,αZ0:t,γZ0:t),V≤W.LetUsatisfyUT(x0:T−1,αZ0:T,γZ0:T)≤(1+γZ0:T)H(x0:T(ξ0:T))andUt(x0:t−1,αZ0:t,γZ0:t)≤ess infZt+1E[Ut+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft],then the processUt(x0:t−1,αZ0:t,γZ0:t)is a submartingale dominated byV(x0:t−1,αZ0:t,γZ0:t),U≤V.The proof is by induction on t, starting at the final stage T. Observe first thatUT≤VT≤WTby assumption and (14). ThenUt(x0:t−1,αZ0:t,γZ0:t)≤ess infZt+1E[Ut+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]≤ess supxtess infZt+1E[Vt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]=Vt(x0:t−1,αZ0:t,γZ0:t),and thusU≤V.As forWtobserve thatWt(x0:t−1,αZ0:t,γZ0:t)≥ess supxtE[Wt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]≥ess infZt+1ess supxtE[Vt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]≥ess supxtess infZt+1E[Vt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]=Vt(x0:t−1,α·Z0:t,γ·Z0:t),because it always holds true thatinfzsupxL(x,z)≥supxinfzL(x,z).Wis a supermartingale, becauseWt(x0:t−1,αZ0:t,γZ0:t)≥ess supxtE[Wt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft]≥E[Wt+1(x0:t,α·Z0:t+1,γ·Z0:t+1)|Ft],which is the characterizing property. The proof thatUis a submartingale is analogous.□Among influential papers and attempts to obtain dynamic programming equations for multistage programming are the papers by Shapiro (2009) and Römisch and Guigues (2012), which address the time consistency aspect. A focus on Bellman’s principle is given in Artzner et al. (2007).In this paper we demonstrate by use of an example that a naïve composition of risk measures is not time consistent. We introduce the conditional Average Value-at-Risk at random risk level. The central result is a decomposition, which allows to reassemble the Average Value-at-Risk given just the conditional risk observations. For this purpose it is necessary to give up the constant risk level and to accept a random risk level instead. The random risk level is adapted for each partial observation and reflects the fact that risk has to be quantified by adapted means, whenever information already is available.The risk levels, which have to be applied at different levels, are not known a priori, they come along with the solution of the entire problem. This is of course in line with time inconsistency, which is intrinsic to these types of problems. However, dynamic programming principles can still be derived, they can be stated as verification theorems. Those verification theorems are formulated by employing enveloping super- and submartingales.They can be used to check, if a given policy for a stochastic program is optimal or not. Further, the sub- and supermartingales provide useful lower and upper bounds for the objective of the stochastic program.

@&#CONCLUSIONS@&#
