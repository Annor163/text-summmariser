@&#MAIN-TITLE@&#
Automated high-content morphological analysis of muscle fiber histology

@&#HIGHLIGHTS@&#
We developed an image processing pipeline to automatically analyze muscle fibers.The method can quickly quantify muscle fiber images for high-content analysis.Validation showed that the method achieved high objectivity.The method can help researchers make discovery in muscle-related experiments.

@&#KEYPHRASES@&#
Morphology of muscle fibers,Muscular dystrophy,Segmentation,Quantification,Cross sections,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
To address the need for quick and objective analysis of muscle fibers to develop novel therapies, we present, in this paper, an image processing approach for microscopic images to segment and analyze cross-sections of muscle fibers. In the search for treatments for the large populations with many types of muscular disorders like muscular dystrophy (MD), researchers have to manually examine and analyze the morphology of muscle fibers to identify important biomarkers about the fibers, such as the restoration of lost membrane proteins and presence of endomysial fibrosis or whether they are degenerative or regenerative. Indeed, morphological features of muscle fibers are important biomarkers of muscle health and indicators of success of therapeutic treatments. Manual analysis, however, is time-consuming and error-prone, given that it is subject to inter-observer variations; therefore, our quantitative analysis approach is a needed replacement.Specifically, we developed algorithms to measure muscle fiber morphologies in a high-throughput high-content manner and tested it on images acquired from a preclinical model of Duchenne muscular dystrophy (DMD), which is the most common and severe form of MD [1] that affects 1 in 3500 newborn boys. The method was tested on microscopic images of the tibialis anterior (TA) muscles of mdx (C57BL/10ScSn-Dmdmdx/J) mice, and we show that it achieved high accuracy in identifying muscle fibers, quantifying their parameters, and exporting quantitative results for further statistical analysis. Despite microscopic images of cross-sections of muscle fibers being often challenging to analyze because not only must cross-sections be segmented but individual cross-sections must be identified to measure perimeters, areas, and other features, our image processing approach provided a quick, objective, and quantitative tool to analyze highly complex muscle fiber images. As each image consists of hundreds to thousands of muscle fibers, an image processing method should be highly automatic and robust to handle cross-sections of muscle fibers of different signal intensities, shapes, and sizes. In addition, an automated image processing approach needs to identify areas that did not belong to valid muscle fibers to exclude them from measurement. As a single experiment may create hundreds microscopic images of muscle fibers, it is not suited to manual analysis that cannot keep up with large numbers of images and that involves a human observer who is often forced to manually click points on a computer screen to mark the boundary of a muscle fiber. Given that two observers are unlikely to mark the boundary in the same way, this process is highly subject to inter-observer variation. What’s more, the high complexity of muscle fiber images makes it very difficult, if not impossible, to extract morphological features such as areas, diameters, and elongations. Therefore, there is an urgent need to develop a computerized analysis approach to model and quantify muscle fiber images as part of an overall more efficient and effective process to find new treatments.To process and analyze complex images like cross-sections of muscle fibers, several steps are generally required, including pre-processing, segmentation, and morphological analysis. Pre-processing aims to correct uneven illumination of the images, remove artifacts, and improve image contrast. Segmentation typically focuses on identifying valid objects or extracting signal components from the background. Over the years, many segmentation methods have been proposed to suit various scenarios of image processing. In general, segmentation methods can be categorized as global thresholding or pixel-wise classification. Representative global threshold techniques include Ostu’s method [2] that maximizes inter-class variance of the segmentation results, and k-means segmentation [3] that clusters pixels into two classes such that each pixel belongs to the nearest cluster. Pixel-wise segmentation techniques include watershed segmentation [4], active contours [5], and graph cut [6], and their variations and improvements. For example, to overcome its well known over-segmentation problem, many techniques have been developed to restrain the watershed process by placing seed points into regions to limit the number of final partitions [7]. Active contour-based methods minimize an energy function that includes both internal energy that constrains the deformation of the contour in terms of its first and second order derivative, and external energy that is minimized when the contour deforms to the boundary of the object, e.g., a high gradient value is encountered. These methods, however, may cause leakage in deformation when there are no obvious gradient changes in the images. An improvement is made by the Chan–Vese model that detects objects whose boundaries are not clearly defined by their gradients by minimizing an energy function set up as a minimal partition problem [8] Graph cut is another type of energy minimization approach to segment an image into the foreground and background by searching for a max flow/min cut partition of the image into two disjoint sets, such that the dissimilarity between the two sets, measured as the weight of edges that have been removed, is minimized [9]. In many cases, segmentation of an image is set up as an optimization problem that searches for a solution to achieve a balance between a data fidelity term and a pre-set term that constrains the segmentation result. For example, an area-constrained segmentation method has been proposed by Niethammer and Zach for soft selections of segmentation solutions that counteracts the effect of shrinking bias encountered in many techniques [10]. Bergeest and Rohr developed a segmentation technique based on active contours by using level sets and convex energy functional, i.e., the functional has only one a minimum to reach a global solution that avoids local minima [11].After segmentation, post-processing is often employed to quantify the results and extract morphological features that are of biological and medical significance. For instance, in muscle fiber analysis, the number of muscle fibers in a unit area and the perimeters and areas of muscle fibers are often used to evaluate the health status of the muscle as well as to identify the type of muscle fibers, e.g., degenerative or regenerative. In identifying muscle fiber centers, Liu et al. proposed a learning-based method to find the geometric centers of muscle fibers and then used a snake model to obtain the boundaries [12]. Mula et al. developed a multiple step approach to first enhance the boundaries of muscle fibers and then search for seed points inside each fiber to drive a deformable model to delineate each fiber [13].In this paper, we present an image processing approach that is able to segment cross-sections of muscle fibers in very challenging cases and extract quantitative features for in-depth analysis, the aim of which is to provide computer-aided measurements of morphologies of muscle fibers for researchers to use to develop novel insights on the cellular mechanisms of musculoskeletal diseases. Ultimately, they will be able to more objectively evaluate their experimental approaches and reduce the time needed to analyze large numbers of muscle fibers acquired in experiments.Animal experiments were carried out under the guidance and approval of the Institutional Animal Care and Use Committee of Harvard Medical School. Male mdx mice at the age of 4–8 weeks were purchased from Jackson Lab. To assess how many of the myoblasts might survive post transplantation, the mice were transplanted with wild type myoblasts from C57BL6 mice to assess how many of the myoblasts might survive post transplantation. In preparation for myoblasts transplantation, the hind legs of the mice were given 18Gy irradiation 3 days in advance. Then 1×105 myoblasts suspended in 10μl HBSS (Hank’s Balanced Salt Solution) were injected into each tibialis anterior (TA) muscles at 3 positions. The mice were then maintained for various periods of time before they were euthanized for tissue harvest. The mice were fed with standard pelleted rodent chow and kept in a 12-h light/12-h dark cycle.When the TA muscles were harvested, the mice were deeply anesthetized by intraperitoneal injection of Ketamine (100mg/kg) and Xylazine (10mg/kg) and then intracardially perfused with physiological saline and periodate/lysine paraformaldehyde (4%) solution. After postfixation and dehydration, the muscles were frozen in OCT embedding compound and sectioned coronally at 12µm thickness from the mid-portion of the muscles. For immunohistochemistry, slides were washed with PBS (Phosphate Buffered Saline) and blocked with 5% goat serum, and muscle sections were incubated with a rabbit anti-dystrophin antibody (Sigma, 1:500) followed by incubation with a goat-anti-rabbit Cy3-conjugated secondary antibody (Jackson Lab, Bar Harbor, ME, USA). The images used were acquired by an Olympus IX-70 microscope equipped with a CCD (Charge-Coupled Device) camera. A single image typically has a size of 800×600pixel, with a pixel size of 0.7µm. Approximately 20 to 30 images were collected with a slight overlap in four directions to cover the whole cross-section of the TA muscle. The individual images were then merged to form a mosaic picture.The image processing approach was designed to, step-by-step, detect and segment muscle fibers. At each step, the approach creates intermediate results that are then combined to generate final segmented results.Fig. 1 shows the flowchart of the approach. First, the image is pre-processed for enhancement, noise reduction, and binarization (row one of Fig. 1). Then the pre-processed images undergo a series of processing to correct contours that were not detected as closed, identify enclosed regions in the contours, and verify if they correspond to valid muscle fibers. Rows two to six of Fig. 1 are the steps that incrementally detect and segment muscle fibers by identifying cross-sections.Step one of the approach is a mean subtraction operation to reduce noise and adjust for uneven illumination of an input image. For each pixel, this step subtracts the value of each pixel by the mean of its neighboring pixels as(1)A′ij=Aij−〈Aij〉rwhere(2)〈Aij〉r=∑i=x−rx+r∑j=y−ry+rAij(2r+1)2and i and j are the coordinates of a pixel,Aijis the pixel in coordinates i and j of the original image A.A′ijis the corresponding pixel of the new imageA′. In Eq. (1)〈Aij〉ris the mean pixel intensity inside a square window centered at coordinate i and j with a radius r. Here we note that r is one of parameters of our approach that is to be optimized for satisfactory results. The image is subsequently normalized according to(3)A″ij={A′ij/max(A′)ifA′ij>00ifA′ij≤0wheremax(A′)gives the maximum pixel value of the imageA′. The next step in our approach is binarization such that(4)Bij={1ifA″ij>tbin0ifA″ij≤tbinwhere threshold tbinis determined by trial-and-error and can be optimized jointly with parameter r to generate satisfactory results. Step three eliminates small regions (noise) detected in the binarization process of muscle fiber contours. At this step each enclosed region is compared with a threshold tnoisesuch that, if its area is less than tnoise, then the region is eliminated. After pre-processing, the algorithms proceed to detect individual muscle fibers (row two of Fig. 1). Step four is to detect pairs of pixels separated by one pixel and connect them to close some contours found in the pre-processing stage but are not completely closed. Next, step five detects small connected components with an area less than a threshold tsmallthat are stored as intermediate results and not used in the subsequent processing steps, and only as components larger than tsmallare kept for further processing. In row three, step six marks the larger components and step seven validates whether they are true muscle fibers through convex hull analysis. A shape S is considered as convex if, for any pair of pointsp,q∈S, the straight line segmentpq¯lies completely within the set S. The convex hull of a set S, H(S), is thus the smallest convex set that contains S[3,14]. Hence, the convex hull is the minimal boundary that encloses a finite set of points. In this way, our image processing approach calculates the size of the original object, denoted asSO, and the size of its convex hull, denoted asSH. Then we calculate the regularity ratioλsuch that(5)λ=SOSHas a measurement of regularity of shape S. It is designed, based on our observation, using cross-sections of muscle fibers, especially of large muscle fibers; therefore it is reasonable to checkλagainst a threshold tconvexto determine if a segmented cross-section represents a valid muscle fiber. In row four of Fig. 1, we used the morphological closing operation (step eight) to fill in small holes and gaps and joins narrow breaks. Then we repeated the fiber detection (step nine) and validation (step 10). Steps 11, 12, and 13 in row five of Fig. 1 are the same as steps 4, 9, and 10, respectively.The last boundary enhancement/fiber detection cycle (row six of Fig. 1) starts with dilation at step 14 and then is followed by the procedure to connect nearby pixels at step 15. Dilation helps to close the contour of large fibers that are not yet detected. Next, preliminary detection is performed without fiber validation at step 16, and an opening operation is applied on these detected fibers at step 17. This morphological operation, consisting of erosion followed by dilation, smoothes the boundaries to remove thin protrusions and break narrow connections. Opening is applied before validation on the detected fibers because we observed that some fibers not detected at this stage were joined by a thin link that could be broken by the opening operation. Also, we observed that some large fibers with shapes deformed by noise had their boundaries smoothed at this step, thereby allowing their detection. Finally step 18 performs validation on the detected muscle fibers using the convex hull analysis. Following this step, all detected fibers in the above steps are joined together to generate a final result.We identified four parameters in our approach: (1) r, (2) tbin, (3) tnoise, and (4) tconvex. Because the number of important parameters is small, we determined their optimization by a brute force search of the parameter space. We also determined the optimal selection of the four parameters by comparing the results of automated analysis with those given by manual analysis. In manual analysis, biologists marked muscle fiber boundaries one by one on computer screens and saved the quantification results such as areas and diameters in text files. We discretized the four-dimensional parameter space in a grid structure and applied the image processing approach for each point in this space that corresponded to a different set of parameters. We found the best result for the following configuration of the parameters: r=9, tbin=0.045, tnoise=10, and tconvex=1.15 and found that the most critical parameters are r and tbin. The performance of the algorithms was robust in the presence of small changes in any parameter. There is also the fifth parameter tsmallthat was to 50 in our case. We found that changes in tsmalldid not affect the obtained results significantly; therefore it was not included among the four critical parameters for optimization.

@&#CONCLUSIONS@&#
