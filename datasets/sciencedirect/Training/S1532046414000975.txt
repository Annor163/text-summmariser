@&#MAIN-TITLE@&#
Quantifying the costs and benefits of privacy-preserving health data publishing

@&#HIGHLIGHTS@&#
Study the challenges of sharing patient-specific health data.Develop an analytical cost model to measure trade-off between privacy and utility.Demonstrate the effectiveness of the model on real-life data.

@&#KEYPHRASES@&#
Privacy,Data utility,Health data,Cost model,Monetary value,

@&#ABSTRACT@&#
Cost-benefit analysis is a prerequisite for making good business decisions. In the business environment, companies intend to make profit from maximizing information utility of published data while having an obligation to protect individual privacy. In this paper, we quantify the trade-off between privacy and data utility in health data publishing in terms of monetary value. We propose an analytical cost model that can help health information custodians (HICs) make better decisions about sharing person-specific health data with other parties. We examine relevant cost factors associated with the value of anonymized data and the possible damage cost due to potential privacy breaches. Our model guides an HIC to find the optimal value of publishing health data and could be utilized for both perturbative and non-perturbative anonymization techniques. We show that our approach can identify the optimal value for different privacy models, including K-anonymity, LKC-privacy, and∊-differential privacy, under various anonymization algorithms and privacy parameters through extensive experiments on real-life data.

@&#INTRODUCTION@&#
Electronic Health Record (EHR) systems have been widely deployed in recent years [1]. Typically, an EHR system provides stable and secure storage for large volumes of health data, including patient medical histories, laboratory test results, demographics and billing records. Centralized storage facilitates daily operations of different health service providers and provides an ideal environment for supporting effective health data mining. The goal of health data mining is to efficiently and effectively extract hidden knowledge from a large volume of health data with the goal of improving the operations of health service providers or supporting medical research. Data mining on EHRs has been proven to be beneficial to health service providers, researchers, patients, and health insurers [2].To achieve effective health data mining, the prerequisite is to gain access to high-quality health data. Yet, health data by default is sensitive, and health information custodians (HICs) have the obligation to preserve patients’ privacy [3–5] in order to minimize potential risks. The current practice of health data sharing is primarily based on obtaining consent from patients; however, HICs have faced increasing privacy breaches of different natures [6,7] due to either the negligence of administrative staff or the employment of weak de-identification methods.In the past decade, many new privacy-enhancing techniques have been proposed to thwart different types of privacy attacks [8]. New privacy models and data anonymization methods have been iteratively proposed, broken, and patched with the discovery of new types of privacy attacks [9–11]. Thus, it is very difficult, if not impossible, to claim that the published data is bulletproof for all privacy attacks. Consequently, when an HIC shares patient-specific data with another party, he/she would like to know the answers to the following questions:•Which privacy model and anonymization algorithm should be employed?Given an anonymization algorithm, how do we choose the parameters to provide adequate privacy protection to the patients?How useful is the data after anonymization?What is the probability of a privacy breach on the released data?What are the costs in case of a patient privacy breach?A practical approach is to identify, minimize, and accept the risks by studying the trade-off between privacy protection and information utility. The recent study [12] shows that the number of health service providers reporting cases of data privacy breaches is increasing every year. The data loss includes patients’ sensitive information, medical files, billing information, and insurance records. The average economic impact of data breaches over the last two years is$2.4million. These data loss incidents have negative impacts on the public’s perception of HICs and can result in potential civil lawsuits from patients’ compensation claims [13,14]. Measuring the economic consequence of a privacy breach is beneficial, but also challenging. In this paper, we model the associated costs and benefits of sharing person-specific health information under different data anonymization methods at different privacy protection levels in terms of monetary value.The contributions of this paper are summarized as follows. We study the challenges of sharing patient-specific health data (e.g., EHRs) faced by HICs. Different privacy models, such as K-anonymity[6], LKC-privacy[15] and∊-differential privacy[16], have been proposed to thwart potential privacy attacks on released data at the cost of degradation of data utility. We develop an analytical cost model to search for the optimal trade-off between privacy and data utility in terms of monetary value. To make our proposed model practical, we take into consideration many possible factors, such as the cost of data distortion, the likelihood of a privacy breach, the expected cost of lawsuits and compensation costs, so that HICs can measure the costs and benefits of releasing health data for secondary and commercial uses. Our model is suitable for both non-perturbative and perturbative anonymization techniques. Finally, we demonstrate the effectiveness of our proposed model by performing an extensive experimental evaluation on real-life data. Nevertheless, we would like to point out that the cost model proposed in this paper is by no means the only feasible model. In fact, there might exist many other reasonable models that may yield different monetary values for anonymized health data. This fact does not undermine our contributions as our goal is to provide a practical basis for HICs to make prudent decisions.The rest of the paper is organized as follows. In Section 2, we review the related work. In Section 3, we present several ways of quantifying the degree of privacy protection and information utility, followed by an overview of two anonymization algorithms and a problem statement. In Section 4, we provide details of our proposed analytical cost model. In Section 5, we evaluate our proposed model by extensive experiments on real-life person-specific data. In Section 6, we discuss the criteria and the integration of cost factors in our model. Finally, we conclude the paper and discuss possible future work in Section 7.

@&#CONCLUSIONS@&#
