@&#MAIN-TITLE@&#
An improved iterated greedy algorithm with a Tabu-based reconstruction strategy for the no-wait flowshop scheduling problem

@&#HIGHLIGHTS@&#
We propose an improved IG algorithm for the no-wait flowshop scheduling problem.The proposed algorithm is incorporated with a Tabu-based reconstruction strategy.Simulation results confirm the advantages of utilizing the new reconstruction scheme.Our algorithm is more effective than other competitive algorithms in the literature.43 new upper bound solutions for the problem have been made available.

@&#KEYPHRASES@&#
No-wait flow shop,Iterated greedy algorithm,Tabu search,Makespan,

@&#ABSTRACT@&#
This paper proposes a Tabu-mechanism improved iterated greedy (TMIIG) algorithm to solve the no-wait flowshop scheduling problem with a makespan criterion. The idea of seeking further improvement in the iterated greedy (IG) algorithm framework is based on the observation that the construction phase of the original IG algorithm may not achieve good performance in escaping from local minima when incorporating the insertion neighborhood search. To overcome this limitation, we have modified the IG algorithm by utilizing a Tabu-based reconstruction strategy to enhance its exploration ability. A powerful neighborhood search method that involves insert, swap, and double-insert moves is then applied to obtain better solutions from the reconstructed solution in the previous step. Empirical results on several benchmark problem instances and those generated randomly confirm the advantages of utilizing the new reconstruction scheme. In addition, our results also show that the proposed TMIIG algorithm is relatively more effective in minimizing the makespan than other existing well-performing heuristic algorithms.

@&#INTRODUCTION@&#
The no-wait flowshop scheduling problem (NWFSP) is an important branch of ‘zero buffer’ scheduling problems. It arises due to the processing characteristics of certain products, where each process follows the previous one immediately [1]. Application domains of the NWFSP include chemical processing [2], plastic molding [3], food processing [3] and steel rolling [4]. Apart from these conventional industries, the NWFSP is also important for some advanced manufacturing systems such as just-in-time production systems [5], flexible manufacturing systems [6], and robotic cells [7] where jobs are continuously processed with no in-process waiting time. In this study, we consider the NWFSP with the objective of minimizing the makespan. The makespan of a schedule is defined as the completion time of the last job leaving the system. This criterion is important and widely studied, since a minimum makespan usually implies a high utilization of the machines and thus results in low processing costs.The NWFSP is a typical example of combinatorial optimization problems [8]. When the problem size increases, these problems become complicated and are difficult to solve by exact methods like branch-and-bound or mixed integer programming techniques. To tackle this challenge, quite a number of metaheuristic methods have been designed, since they are usually able to find a high quality solution for middle- and large-scale problems within reasonable computational time. Representative algorithms include the genetic algorithm (GA) [9], estimation of distribution algorithm (EDA) [10], discrete particle swarm optimization (DPSO) [11], block-based evolutionary algorithm (BBEA) [12], discrete artificial bee colony algorithm (DABC) [13], and ant colony optimization (ACO) [14], among others. These algorithms have produced competitive results for many combinatorial optimization problems.Although population-based metaheuristic algorithms can provide excellent results, they are in general fairly sophisticated and very sensitive to algorithm parameters such as the crossover probability, mutation probability and population size [15]. This makes it difficult to obtain the same results when re-implementing a reported algorithm. As Pan and Ruiz [16] pointed out, simple and easily adaptable algorithms are highly desirable. The iterated greedy (IG) algorithm [17] is an example of such algorithms. It can provide comparable or even better computational results with simple and general search mechanisms.The IG algorithm consists of two main phases: destruction and construction. In the destruction phase, some elements are removed from the current solution. In the construction phase, the removed elements are reinserted into the solution by applying a greedy constructive heuristic. A local search phase to improve the reconstructed solution may also be integrated into the algorithm's framework. Although the local search is optional, we have observed that it contributes significantly to the effectiveness of the IG algorithm. As reported by some related work in the literature (e.g., see [17,18]), the IG algorithm with a local search step performs better than when no local search is used. In addition, most of the relevant studies have incorporated local search into the algorithm framework, e.g., see [17–20,16,21,22]. These results indicate that the local search step is an important component of the IG algorithm. In this regard, the IG algorithm can also be viewed as a method that iteratively applies a neighborhood search scheme to obtain a local optimal solution and a greedy perturbation scheme to escape from local minima.Despite its simplicity and effectiveness, the IG algorithm has obvious limitations when solving large-scale problems. On the one hand, the algorithm adopts a “single solution” search strategy with a greedy insertion reconstruction technique. It may not achieve good solution diversity compared to population-based search methods. On the other hand, a neighborhood search method is usually applied once the reconstruction phase is completed, which over emphasizes on the exploration of discovered local minima regions. These facts indicate that it may be beneficial if the exploitation ability of the IG algorithm is improved.The above-mentioned limitations of the IG algorithm motivate us to investigate for further improvement of the algorithm's structure. In the original perturbation scheme, randomly removed jobs are reinserted greedily into the current partial solution one by one to build a complete solution. However, we notice that this insertion reconstruction strategy is similar to the commonly used neighborhood search method based on insert moves. It may lead to repeated and excessive search as well as poor exploitation in the search process, since the algorithm may get stuck at local minima solutions with respect to insertion operations. To overcome this, we propose a Tabu-based construction method in the perturbation scheme to avoid repeated search and introduce solution diversities. More precisely, a succession of Tabu lists are built and maintained in the construction phase to prevent each removed object from being inserted at previously visited positions. After the reconstruction, a more powerful neighborhood structure based on insert, swap and double-insert moves is adopted to further enhance the exploration ability.The contributions of this work can be summarized as follows:•We have modified the structure of the IG algorithm by introducing a Tabu-based insertion strategy in the reconstruction phase. Advantages of utilizing the new reconstruction scheme are confirmed via empirical results on benchmark problem instances of the NWFSP.We have analyzed the performance of the proposed Tabu-mechanism improved iterated greedy (TMIIG) algorithm and reported computational results comparing it against other well-performing algorithms for the NWFSP. Our results show that the proposed algorithm is the most effective one. In addition, we have updated 43 new upper bound solutions for the benchmark instances of the NWFSP, which can be a good reference for other studies in the future.The rest of the paper is organized as follows. The next section provides the problem formulation and a literature review on the NWFSP with a makespan criterion. In Section 3, we present the TMIIG algorithm for the problem at hand. The effectiveness of the proposed algorithm is verified through numerical experiments and results are discussed in Section 4. Finally, Section 5 summarizes the paper and highlights some possible future research directions.

@&#CONCLUSIONS@&#
