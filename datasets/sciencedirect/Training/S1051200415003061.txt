@&#MAIN-TITLE@&#
Minimum variance estimation for linear uncertain systems with one-step correlated noises and incomplete measurements

@&#HIGHLIGHTS@&#
A compensation multi-step random delays and packet dropout model is adopted.The minimum-variance estimators are proposed for the addressed system.A sufficient condition on the existence of the steady-state estimators is given.

@&#KEYPHRASES@&#
Minimum-variance estimators,Uncertain system,Projection theorem,Correlated noises,Network-induced uncertainties,

@&#ABSTRACT@&#
This paper deals with state estimation problem for linear uncertain systems with correlated noises and incomplete measurements. Multiplicative noises enter into state and measurement equations to account for the stochastic uncertainties. And one-step autocorrelated and cross-correlated process noises and measurement noises are taken into consideration. Using the latest received measurement to compensate lost packets, the modified multi-step random delays and packet dropout model is adopted in the present paper. By augmenting system states, measurements and new defined variables, the original system is transformed into the stochastic parameter one. On this basis, the optimal linear estimators in the minimum variance sense are designed via projection theory. They depend on the variances of multiplicative noises, the one-step correlation coefficient matrices together with the probabilities of delays and packet losses. The sufficient condition on the existence of steady-state estimators is then given. Finally, simulation results illustrate the performance of the developed algorithms.

@&#INTRODUCTION@&#
As is well known, if the system model under consideration is exactly known, Kalman filter is an optimal filter in the minimum variance sense for linear systems [1]. Under different hypotheses on the processes involved in the observation equation, corresponding algorithms have been proposed, such as Unscented Kalman filter, Extended Kalman filter, Particle filter and so on [2]. However, in the network environment, the standard observation model becomes inappropriate due to the existence of network-induced uncertainties like packet dropouts, transmission delays, missing measurements, and/or disorder. Accordingly, modeling the observation process is vitally important to the filtering or state estimation problem for the networked control systems (NCSs).Studies on filtering or state estimation with one or two, even three network-induced uncertainties have attracted considerable attention in the past few decades. For instance, using an innovation analysis approach, [3] presented the optimal linear estimators for the systems with multiple packet dropouts. Given measurements transmitted by different sensors subject to random packet dropouts, [4] discussed least-squares linear estimation problem using covariance information. For random delayed systems, the optimal and suboptimal estimators [5] and recursive filtering and smoothing algorithms [6] were proposed. Taking packet dropouts, missing measurements as well as random measurement delays into account, [7] designed adaptive filtering schemes. Differently from the aforementioned observation models, [8] developed a model to describe multi-step transmission delays and packet dropouts by introducing some Bernoulli distributed random variables. Then, the optimal linear estimators for single sensor were derived. Based on the novel model in [8], [9,10] developed corresponding estimation algorithms for different systems. To be specific, [9] extended the results in [8] to the multi-sensor distributed case, and derived a distributed fusion filter. By means of the reorganized innovation approach, [10] investigated the optimal estimator for the linear systems with and without time-stamped data packets. However, multi-step random delays and packet losses model used in [8–10] can result in complete loss of packets at times, which affect the performance of proposed estimator. To overcome this deficiency, the latest measurement transmitted successfully can be used for the estimation. The resultant model is described in the problem formulation section, called as the compensation multi-step random delays and packet losses model, or compensation model for short.In many engineering applications, the process noise and measurement noise are assumed to be correlated. As pointed out in [11], the radar system is a typical example of this aspect. On this account, a great number of estimation results concerning systems with correlated noises have been obtained. To mention a few, [12] designed the optimal robust non-fragile Kalman-type recursive filter for a class of uncertain systems with finite-step autocorrelated measurement noises and multiple packet dropouts. Compared with the results in [12], a globally optimal filtering was proposed in [13] by exploiting sufficiently the statistical properties of correlated noises. Considering the correlation between the signal and the observation noise, the least-squares linear smoothing problem was investigated in [14]. Recently, [15] has coped with the optimal least-squares linear estimation problem, in which one-step correlated and cross-correlated parameter matrices other than correlated noises were considered. For the distributed filtering problem subject to correlated noises, a distributed Kalman filtering fusion algorithm [16], the distributed weighted robust Kalman filter [17], and optimal sequential and distributed fusion schemes [18] were developed, respectively.On the other hand, parameter uncertainties inevitably exist in the system model because of model reduction, varying parameters and so on. In general, parameter uncertainties include deterministic uncertainties and stochastic uncertainties. Multiplicative noises, as we all known, are regarded as the stochastic uncertainties. Hence, so far, many valuable results with respect to state estimation for uncertain systems have been reported. Specifically, an exact, closed-form minimum variance filter [19], the optimal linear estimators [20] and a robust distributed state fusion Kalman filter [21] were proposed, respectively. Merging the stochastic uncertain terms into the process and observation noises of the original system, a robust Kalman filter was presented in [22]. Considering the parameter uncertainties may occur in a probabilistic way, [23] addressed the distributed filtering problem in terms of linear matrix inequalities. Both deterministic uncertainties and stochastic uncertainties being considered, [24] designed a robust finite-horizon Kalman filter for discrete time-varying uncertain systems. Recently, [25] designed optimal linear estimators for NCSs with stochastic uncertainties, multiple sensors and packet losses of both sides from sensors to an estimator and from a controller to an actuator. Although [20] and [25] derived the optimal estimators for uncertain system with compensation model, but multi-step random delay and correlated noises were not involved.Up to now, to the best of the authors' knowledge, the minimum variance estimation problem for the uncertain systems with compensation multi-step random delays and packet losses, one-step autocorrelated and cross-correlated noises has not been considered yet, which motivates the present study. It should be note that the stochastic uncertainties together with correlated noises can bring many difficulties in designing the optimal estimators, not to mention the challenges brought from compensation multi-step random delays and packet losses model. Compared with the observation model adopted in [8], the compensation model in the present paper can use the latest measurement data transmitted successfully to compensate lost packets at some time. To transform the original system into the stochastic parameterized one, some new variables are defined. In particular, random variableρl+1is introduced, which brings some difficulties in dealing with the relationships among this variable, other random variables and resultant stochastic coefficient matrices. Based on the stochastic parameter system, the filter, multi-step predictor and smoother are proposed via the innovation analysis approach. The designed estimators are optimal in the minimum variance sense, and consider the effect from multiplicative noises, one-step correlated noises together with multi-step delays and packet losses. In this sense, our work isn't a simple generalization of some existing results. In addition, estimation algorithms developed in the current paper can be applied to close loop control, target tracking, communications, fault diagnosis and so on.The organization of the paper is as follows. Section 2 gives the problem under consideration. In Section 3, two lemmas and the main theorems on the design of minimum-variance estimators are provided. Furthermore, the sufficient condition on the existence of steady-state estimators is discussed. The performance of the proposed estimators is illustrated in Section 4 by a numerical example and some conclusions are drawn in Section 5. Proofs of the results in Section 3 are given in Appendices A–C.Notations. Throughout the paper, the notations used are standard.Rmrepresents the m-dimensional Euclidean space.Imand 0 mean the identity matrix and zero matrix with appropriate dimensions, respectively.δt,ldenotes the Kronecker delta function, which is equal to zero ift≠l, and one ift=l.Prob(⁎)stands for the occurrence probability of the event ⁎.E(x)is the expectation of x.ρ(A)represents the spectral radius of matrix A.sym{⁎}denotes⁎+⁎T. If not explicitly stated, all matrices are assumed to be of compatible dimensions.Consider the following discrete time-varying linear system with multiplicative noises:(1)x(t+1)=(A(t)+∑i=1rαi(t)Aμ,i(t))x(t)+B(t)w(t)(2)z(t)=(C(t)+∑k=1sβk(t)Cμ,k(t))x(t)+v(t)wherex(t)∈Rnis the system state, and the initial statex(0)has meanx¯0and varianceP0.z(t)∈Rmis the measurement.αi(t)∈Randβk(t)∈Rrepresent mutually uncorrelated zero-mean multiplicative noises with varianceQαiandQβk, respectively. r and s are known positive integers.w(t)∈Rhandv(t)∈Rmare, respectively, the one-step autocorrelated and cross-correlated process noise and measurement noise.A(t),Aμ,i(t),B(t),C(t), andCμ,k(t)are known time-varying matrices with appropriate dimensions. Also,x(0)is assumed to be uncorrelated withαi(t),βk(t),w(t)andv(t).The network-induced uncertainties, such as random delays and packet losses, always occur during the measurement z(t) being sent to the estimator. For this reason, in our present work,y(t)received by the estimator is modeled as follows:(3)y(t)=ρ0(t)z(t)+(1−ρ0(t))ρ1(t−1)z(t−1)+⋯+Πi=0l−1(1−ρi(t−i))ρl(t−l)z(t−l)+ρl+1(t)y(t−1)where l is the largest transmission delay,ρi(t)satisfyρ0(t)=η0(t),ρi(t)=Πk=0i−1(1−ηk(t+k))ηi(t+i)(i=1,2…l)andρl+1(t)=(1−ρ0(t))(1−ρ1(t−1))…(1−ρl(t−l)).ηi(t)are mutually uncorrelated Bernoulli distributed random variables satisfying thatProb{ηi(t)=1}=νiandProb{ηi(t)=0}=1−νi(0≤νi≤1). In addition, we assume thatηi(t)are independent ofx(0),w(t),v(t),αi(t)andβk(t).To make the compensation model (3) more understandable, a simple demonstration of data transmission underl=2is given in Table 1, from which the main difference between the model in [8] and model (3) can be observed.Table 1 shows thatz(1),z(2),z(4),z(9)andz(10)are received on-time,z(5)is delayed one step,z(3)is delayed two steps,z(6),z(7)andz(8)are lost in [8], while the lost data are respectively compensated for byy(2),y(6)andy(7)in model (3).Assumption 1The process noisew(t)and the measurement noisev(t)are one-step autocorrelated and cross-correlated noises, which satisfy(4){E(w(k)wT(t))=Qkδk,t+Qk,k−1δk,t+1+Qk,k+1δk,t−1,E(v(k)vT(t))=Rkδk,t+Rk,k−1δk,t+1+Rk,k+1δk,t−1,E(w(k)vT(t))=Skδk,t+Sk,k−1δk,t+1+Sk,k+1δk,t−1.To be specific, the process noisew(k)is correlated withw(k−1)andw(k+1)with covariancesQk,k−1andQk,k+1, respectively. Moreover,w(k)is correlated withv(k),v(k−1)andv(k+1)with covariancesSk,Sk,k−1andSk,k+1, respectively. And the same is true forv(k).Remark 1The random variablesρi(t)(i=0,1,…,l+1)have the following statistical properties:(5)E[ρ0(t)]=ρ‾0=ν0,E[ρi(t)]=ρ‾i=Πk=0i−1(1−νk)νi,i=1,2,…,l.E[ρl+1(t)]=ρ‾l+1=Πi=0l(1−ρ‾i),E[(ρi(t)−ρ‾i)2]=ρ‾i(1−ρ‾i),E[ρi(t)ρj(t)]=0(i≠j),E[ρi(t)ρj(k)]=ρ‾iρ‾j(t≠k),i,j=0,1,…,l,E[ρ0(t)ρl+1(t)]=0,E[ρi(t)ρl+1(t)]=ρ‾iΠj=1l(1−ρ‾j),(i=1,2,…,l).Let(6)Ui(t)=ρi(t)z(t)+(1−ρi(t))Ui+1(t−1),i=1,2…l−1Ul(t)=ρl(t)z(t)Then the system (1)–(3) becomes a parameterized one:(7)X(t+1)=A˜(t)X(t)+B˜(t)W(t)(8)y(t)=C˜(t)X(t)+ρ0(t)v(t)whereX(t+1)=[xT(t+1),U1T(t),…,UlT(t),yT(t)]T,W(t)=[wT(t),vT(t)]T, andA˜(t)=[Aˆ(t)00ρ1(t)Cˆ(t)0(1−ρ1(t))Im⋮⋮⋮ρl−1(t)Cˆ(t)00ρl(t)Cˆ(t)00ρ0(t)Cˆ(t)(1−ρ0(t))Im0…00…00⋮⋱⋮…(1−ρl−1(t))Im0…00…0ρl+1(t)Im],B˜(t)=[BT(t)00…000ρ1(t)Imρ2(t)Im…ρl(t)Imρ0(t)Im]T,C˜(t)=[ρ0(t)Cˆ(t)(1−ρ0(t))Im0…ρl+1(t)Im],withAˆ(t)=A(t)+∑i=1rαi(t)Aμ,i(t)andCˆ(t)=C(t)+∑k=1sβk(t)Cμ,k(t).Noting thatA˜(t),B˜(t)andC˜(t)includeρi(t),αi(t)andβk(t), the following notations are introduced to simplify the presentation.(9)E[A˜(t)]=A‾(t),E[B˜(t)]=B‾(t),E[C˜(t)]=C‾(t),(10)A˘(t)=A˜(t)−A‾(t)=∑i=0l+1(ρi(t)−ρ‾i)Ai(t)+Ae(t)+∑i=0lρi(t)Aei(t),(11)B˘(t)=B˜(t)−B‾(t)=∑i=0l(ρi(t)−ρ‾i)Bi(t),(12)C˘(t)=C˜(t)−C‾(t)=(ρ0(t)−ρ‾0)C0(t)+ρ0(t)C1(t)+(ρl+1(t)−ρ‾l+1)C2(t),(13)Ae(t)=∑i=1rαi(t)QA,i(t),Ae0(t)=∑k=1sβk(t)Q0,k(t),Aei(t)=∑k=1sβk(t)Qi,k(t)(i=1,2,⋯,l),(14)C1(t)=∑k=1sβk(t)Qμ,k(t),whereA‾(t)=[A(t)00…00ρ‾1C(t)0(1−ρ‾1)Im…00⋮⋮⋮⋮⋱⋮ρ‾l−1C(t)00…(1−ρ‾l−1)Im0ρ‾lC(t)00…00ρ‾0C(t)(1−ρ‾0)Im0…0ρ‾l+1Im],B‾(t)=[BT(t)00…000ρ¯1Imρ¯2Im…ρ¯lImρ¯0Im]T,C‾(t)=[ρ¯0C(t)(1−ρ¯0)Im0…ρ¯l+1Im],A0(t)=[00⋯0⋮⋮⋮⋮00⋯0C(t)−Im⋯0],Al(t)=[00⋯0⋮⋮⋮⋮C(t)0⋯000⋯0],Ai(t)=[00⋯0⋯0C(t)0⋯−Im⋯000⋯0⋯0]→i+1block row,↓i+2block column,i=1,2,⋯,l−1Al+1(t)=[00⋯0⋮⋮⋮⋮00⋯000⋯Im],QA,i(t)=[Aμ,i(t)000⋮⋮00],Qi,k(t)=[00⋮⋮Cμ,k(t)0⋮⋮00]→i+1block row,i=1,2,…,l.Q0,k(t)=[0000⋮⋮Cμ,k(t)0],Be(t)=[B(t)000⋮⋮0000],B0(t)=[00⋮⋮00⋮⋮0Im],Bi(t)=[00⋮⋮0Im⋮⋮00]→i+1block row,i=1,2,…,l.C0(t)=[C(t)−Im0⋯0],Qμ,k(t)=[Cμ,k(t)0⋯0],C2(t)=[00⋯Im].Remark 2From (4), the statistical properties ofW(t)andv(t)are given by(15){E[W(k)WT(t)]=Mkδk,t+Mk,k−1δk,t+1+Mk,k+1δk,t−1,E[W(k)vT(t)]=Nkδk,t+Nk,k−1δk,t+1+Nk,k+1δk,t−1,whereMk=[QkSkSkTRk],Mk,k−1=[Qk,k−1Sk,k−1Sk−1,kTRk,k−1],Mk,k+1=[Qk,k+1Sk,k+1Sk+1,kTRk,k+1],Nk=[SkRk],Nk,k−1=[Sk,k−1Rk,k−1],Nk,k+1=[Sk,k+1Rk,k+1].The objective of this paper is to give the filterXˆ(t|t), multi-step predictorXˆ(t+h|t)(h>0)and smootherXˆ(t+h|t)(h<0)for the augmented system (7)–(8). Thus, for the original system (1)–(3), the estimatorsxˆ(t+h|t)=[In,0,⋯,0]Xˆ(t+h|t)are accordingly obtained.In this section, utilizing the well-known projection theory, the minimum variance filter, multi-step predictor and smoother will be proposed. To begin with, we give some lemmas needed in the sequel.Lemma 1LetT˘(t)andZ˘(t)be time-varying stochastic matrices,Ω(t)=E[φ(t)ψT(t)], defineΞT˘(t)Z˘(t)(Ω(t))=E[T˘(t)φ(t)ψT(t)Z˘T(t)], then the following results can be obtained(16)ΞA˘(t)A˘(t)(q(t))=E[A˘(t)X(t)XT(t)A˘T(t)]=∑i=0l+1ρ‾i(1−ρ‾i)Ai(t)q(t)AiT(t)−∑i=0l∑j=0,j≠ilρ‾iρ‾jAi(t)q(t)AjT(t)+∑i=1rQαiQA,i(t)q(t)QA,iT(t)+∑i=0l∑k=1sρ‾iQβkQi,k(t)q(t)Qi,kT(t)+sym{−ρ‾0ρ‾l+1A0(t)q(t)Al+1T(t)+ρ‾0Πjl(1−ρ‾j)∑i=1lρ‾iAi(t)q(t)Al+1T(t)}(17)ΞA˘(t)C˘(t)(q(t))=E[A˘(t)X(t)XT(t)C˘T(t)]=ρ‾0(1−ρ‾0)A0(t)q(t)C0T(t)−∑i=1l+1ρ‾0ρ‾iAi(t)q(t)C0T(t)−ρ‾0ρ‾l+1A0(t)q(t)C2T(t)+ρ‾0Πj=1l(1−ρ‾j)∑i=1lρ‾iAi(t)q(t)C2T(t)+ρ‾l+1(1−ρ‾l+1)Al+1(t)q(t)C2T(t)+ρ‾0∑k=1sQβkQ0,k(t)q(t)Qμ,kT(t)(18)ΞC˘(t)C˘(t)(q(t))=E[C˘(t)X(t)XT(t)C˘T(t)]=ρ‾0(1−ρ‾0)C0(t)q(t)C0T(t)+ρ‾0∑k=1sQβkQμ,k(t)q(t)Qμ,kT(t)+ρ‾l+1(1−ρ‾l+1)C2(t)q(t)C2T(t)−ρ‾0ρ‾l+1C0(t)q(t)C2T(t)−ρ‾0ρ‾l+1C2(t)q(t)C0T(t)(19)ΞA˘(t)B˘(t)(Φ1(t))=E[A˘(t)X(t)WT(t)B˘T(t)]=∑i=0lρ‾i(1−ρ‾i)Ai(t)Φ1(t)BiT(t)−∑i=0l∑j=0,j≠ilρ‾iρ‾jAi(t)Φ1(t)BjT(t)−ρ‾0ρ‾l+1Al+1(t)Φ1(t)B0T(t)+ρ‾0Πj=1l(1−ρ‾j)∑i=1lρ‾iAl+1(t)Φ1(t)BiT(t)(20)ΞC˘(t)B˘(t)(Φ1(t))=E[C˘(t)X(t)WT(t)B˘T(t)]=ρ‾0(1−ρ‾0)C0(t)Φ1(t)B0T(t)−∑i=1lρ‾0ρ‾iC0(t)Φ1(t)BiT(t)−ρ‾0ρ‾l+1C2(t)Φ1(t)B0T(t)+ρ‾0Πj=1l(1−ρ‾j)∑i=1lρ‾iC2(t)Φ1(t)BiT(t)withΦ1(t)=E[X(t)WT(t)]=B‾(t−1)Mt−1,tandq(t)=E[X(t)XT(t)]which will be calculated inLemma 2.ProofProof is given in Appendix A. □Lemma 2The state covariance matrix of system(7), defined asq(t)=E[X(t)XT(t)], can be calculated recursively by(21)q(t+1)=ΞA˘(t)A˘(t)(q(t))+A‾(t)q(t)A‾T(t)+A‾(t)Φ1(t)B‾T(t)+B‾(t)Φ1T(t)A‾T(t)+ΞA˘(t)B˘(t)(Φ1(t))+ΞB˘(t)A˘(t)(Φ1T(t))+Λ1(t)whereq(0)=[P0+x¯0x¯0T000]andΛ1(t)=E[B˜(t)W(t)WT(t)B˜T(t)]given in(60).ProofProof is given in Appendix B.  □To facilitate subsequent discussion, we defineXˆ(m|t)=E{X(m)|Yt}, which denotes the estimation ofX(m)with observationsYt=[yT(0),yT(1),⋯,yT(t)]T. Consequently, the estimation errorX˜(m|t)=X(m)−Xˆ(m|t), the error covariance matrixP(m|t)=E[X˜(m|t)X˜T(m|t)]and the innovatione(t)=y(t)−yˆ(t|t−1)with covariance matrixJ(t)are also defined. In particular,P(t+1|t),P(t|t)are called the prediction and filter error covariance matrix, respectively.Theorem 1Consider the system(7)–(8)satisfyingAssumption 1, the optimal linear filter and predictor are recursively computed by(22)Xˆ(t|t)=Xˆ(t|t−1)+G(t)e(t)(23)Xˆ(t+1|t)=A‾(t)Xˆ(t|t−1)+B‾(t)K(t−1)e(t−1)+F(t)e(t)(24)e(t)=y(t)−C‾(t)Xˆ(t|t−1)−ρ‾0L(t−1)e(t−1)(25)G(t)=[P(t|t−1)C‾T(t)+ρ‾0Φ2(t)−ρ‾0F(t−1)J(t−1)LT(t−1)]J−1(t)(26)F(t)=[Γ1(t)+Γ2(t)]J−1(t)(27)K(t−1)=ρ‾0Nt,t−1J−1(t−1)(28)L(t−1)=ρ‾0Rt,t−1J−1(t−1)(29)J(t)=ΞC˘(t)C˘(t)(q(t))+C‾(t)P(t|t−1)C‾T(t)−ρ‾02L(t−1)J(t−1)LT(t−1)+ρ‾0Rt+sym{[ρ‾0(1−ρ‾0)C0(t)−ρ‾0ρ‾l+1C2(t)]Φ2(t)+ρ‾0C‾(t)Φ4(t)}(30)P(t+1|t)=[A‾(t)−F(t)C‾(t)]P(t|t−1)[A‾(t)−F(t)C‾(t)]T+F(t)Rˇ(t)FT(t)−F(t)SˇT(t)−Sˇ(t)FT(t)+Qˇ(t)(31)P(t|t)=P(t|t−1)−G(t)J(t)GT(t)where(32)Γ1(t)=ΞA˘(t)C˘(t)(q(t))+A‾(t)P(t|t−1)C‾T(t)+[ρ‾0(1−ρ‾0)A0(t)+ρ‾0A‾(t)−ρ‾0∑i=1l+1ρ‾iAi(t)]Φ2(t)−ρ‾0A‾(t)F(t−1)J(t−1)LT(t−1)(33)Γ2(t)=ΞB˘(t)C˘(t)(Φ1T(t))+B‾(t)Φ3T(t)C‾T(t)+ρ‾0(Be(t)+B0(t))Nt−ρ‾0B‾(t)K(t−1)J(t−1)LT(t−1)(34)Φ2(t)=E[X(t)vT(t)]=B‾(t−1)Nt−1,t(35)Φ3(t)=E[X˜(t|t−1)WT(t)]=B‾(t−1)Mt−1,t−ρ‾0F(t−1)Nt,t−1T(36)Φ4(t)=E[X˜(t|t−1)vT(t)]=B‾(t−1)Nt−1,t−ρ‾0F(t−1)Rt−1,t(37)Rˇ(t)=ΞC˘(t)C˘(t)(q(t))+ρ‾0Rt−ρ‾02L(t−1)J(t−1)LT(t−1)+sym{[ρ‾0(1−ρ‾0)C0(t)−ρ‾0ρ‾l+1C2(t)]Φ2(t)+ρ‾0C‾(t)Φ4(t)}(38)Qˇ(t)=ΞA˘(t)A˘(t)(q(t))−B‾(t)K(t−1)J(t−1)KT(t−1)B‾T(t)+Λ1(t)+sym{ΞA˘(t)B˘(t)(Φ1(t))+A‾(t)Φ3(t)B‾T(t)}(39)Sˇ(t)=ΞA˘(t)C˘(t)(q(t))−ρ‾0B‾(t)K(t−1)J(t−1)LT(t−1)+ΞB˘(t)C˘(t)(Φ1T(t))+[ρ‾0(1−ρ‾0)A0(t)−ρ‾0∑i=1l+1ρ‾iAi]Φ2(t)+B‾(t)Φ3T(t)C‾(t)+ρ‾0A‾(t)Φ4(t)+ρ‾0[Be(t)+B0(t)]NtMoreover, the initial values are chose to beX(0|−1)=[x¯0T,0T]T,G(−1)=0,F(−1)=0,e(−1)=0,K(−1)=0,L(−1)=0,P(0|−1)=[P0000]andJ(−1)=0.ProofProof is given in Appendix C. □Remark 3The algorithms proposed in Theorem 1 are inspired by the optimal estimator design in [8], where multi-step random delays and packet losses existing both the sensor-to-estimator channel and the controller-to-actuator channel. In the current paper, we consider the case of random delays and packet losses only occurring in the sensor-to-estimator channel, and adopt the compensation multi-step model to avoid the packet losing completely. On the other hand, the considered system in [8] is the time-varying linear one with the noises being cross-correlated at the same time instant. However, in our paper, the addressed system is the stochastic uncertain systems with one-step autocorrelated and cross-correlated noises. These above factors constitute the main difference between [8] and our paper. In addition, whenl=0and the noises are cross-correlated at the same time instant, the estimator in this paper reduces to that in [20], which demonstrates our algorithms can generalize the results of [20].Remark 4The system under consideration is comprehensive, which involves the multiplicative noises, one-step correlated noises, l-step delays and multiple packet dropouts. These factors are all taken into account in our algorithms. For example,QαiandQβkare used to quantify the uncertainties.ρ‾j(j=0,1,2⋯,l)characterize the occurrence probabilities of delays and packet dropouts. Particularly,ρ‾l+1is used to describe the compensation probability. Moreover, the introduction of one-step correlated noises gives rise toK(t−1),L(t−1)ande(t)depending one(t−1), which are different from the estimator in [8].The minimum-variance filter has been provided in Theorem 1. On this basis, multi-step predictor and smoother will be proposed in the following.Theorem 2Consider the system(7)–(8)satisfyingAssumption 1, the optimal linear h-step(h>1)predictor is calculated by(40)Xˆ(t+2|t)=A‾(t+1)Xˆ(t+1|t)+B‾(t+1)K(t)e(t)(41)Xˆ(t+h|t)=A‾(t+h−1)Xˆ(t+h−1|t),(h>2)with the corresponding prediction error matrices(42)P(t+2|t)=A‾(t+1)P(t+1|t)A‾T(t+1)+Λ1(t+1)+ΞA˘(t+1)A˘(t+1)(q(t+1))−B‾(t+1)K(t)J(t)KT(t)×B‾T(t+1)+sym{ΞA˘(t+1)B˘(t+1)(Φ1(t+1))+A‾(t+1)Φ3(t+1)B‾T(t+1)}and(43)P(t+h|t)=A‾(t+h−1)P(t+h−1|t)A‾T(t+h−1)+Λ1(t+h−1)+ΞA˘(t+h−1)A˘(t+h−1)(q(t+h−1))+sym{ΞA˘(t+h−1)B˘(t+h−1)(Φ1(t+h−1))+A‾(t+h−1)Φ3(t+h−1)B‾T(t+h−1)}ProofProof is omitted.  □Theorem 3Consider the system(7)–(8)satisfyingAssumption 1, the optimal linear fixed-lag h-step(h<0)smoother is given as follows(44)Xˆ(t+h|t)=Xˆ(t+h|t−1)+Θ(t+h|t)e(t)with the smoothing gain matrix(45)Θ(t+h|t)=[Σh(t)C‾T(t)−ρ‾0Θ(t+h|t−1)J(t−1)LT(t−1)]J−1(t)whereΣh(t)=E[X(t+h)X˜T(t|t−1)].Ifh=−1,(46)Σ−1(t)=P(t−1|t−2)[A‾(t−1)−F(t−1)C‾(t−1)]T+Φ1(t−1)B‾T(t−1)−ρ‾0Φ2(t−1)FT(t−1)−F(t−2)J(t−2)[B‾(t−1)K(t−2)−ρ‾0F(t−1)L(t−2)]TIfh<−1,(47)Σh(t)=Σh(t−1)[A‾(t−1)−F(t−1)C‾(t−1)]T−Θ(t+h|t−2)J(t−2)[B‾(t−1)K(t−2)−ρ‾0F(t−1)L(t−2)]TThe smoothing error covariance matrix can be calculated by(48)P(t+h|t)=P(t+h|t−1)−Θ(t+h|t)J(t)ΘT(t+h|t)ProofThe proof of Theorem 3 is omitted here.  □Remark 5It is worthwhile to note that, as a consequence of one-step correlated noises, two cases of step length h must be considered during the derivation of (42)–(43) and (46)–(47). Moreover, as|h|increases, the estimation error becomes greater, which will be illustrated in the simulation example.If we assume the coefficient matrices in (1)–(3) and the one-step correlation coefficient matrices are time-invariant, sufficient condition on the existence of the steady-state estimators is established in this section.Define(49)Ω=A‾⊗A‾+∑i=0l+1ρ‾i(1−ρ‾i)Ai⊗Ai−∑i=0l∑j=0,j≠ilρ‾iρ‾jAj⊗Ai−ρ‾0ρ‾l+1Al+1⊗A0+ρ‾0Πj=1l(1−ρ‾j)∑i=1lρ‾iAl+1⊗Ai−ρ‾0ρ‾l+1A0⊗Al+1+ρ‾0Πj=1l(1−ρ‾j)∑i=1lρ‾iAi⊗Al+1+∑i=1rQαiQA,i⊗QA,i+∑i=0l∑k=1sρ‾iQβkQi,k⊗Qi,kTheorem 4Letρ(Ω)<1and the pair(A‾−SˇRˇ−1C‾,ϒ)be stabilizable, where ϒ satisfiesϒϒT=Qˇ−SˇRˇ−1SˇT, thenP(t+1|t)in(30)converges to the unique positive semi-definite solution Σ, which satisfies the following algebraic equation:(50)Σ=[A‾−FC‾]Σ[A‾−FC‾]T+FRˇFT−FSˇT−SˇFT+Qˇwhere q is the unique positive semi-definite solution ofq(t)in(21), given as(51)q=ΞA˘A˘(q)+A‾qA‾T+A‾Φ1B‾T+B‾Φ1TA‾T+ΞA˘B˘(Φ1)+ΞA˘B˘(Φ1T))+Λ1In addition,K=limt→∞⁡K(t),L=limt→∞⁡L(t),J=limt→∞⁡J(t),F=limt→∞⁡F(t),G=limt→∞⁡G(t), and(52)Xˆ(t+1|t)=(A‾−FC‾)Xˆ(t|t−1)+(B‾K−ρ‾0FL)e(t−1)+Fy(t)ProofFrom the filtering theory in [1], the sufficient condition to guarantee the convergence ofP(t+1|t)andq(t)can be readily obtained. □Remark 6Note thatρ(Ω)<1in Theorem 4 is not replaced byρ(A)<1. This is because that Ω is not a block quasi-lower-triangular or quasi-upper-triangular matrix with the diagonal elements beingA‾⊗A‾, thus the stability of A dose not deduce the stability of Ω.Two simulation examples are provided in this section to show the effectiveness of the proposed algorithms.Example 1Consider the following discrete-time uncertain system with 2-step delays and packet dropouts(53)x(t+1)=[0.800.90.2]x(t)+α(t)[0.10.050.20.1]x(t)+[10.5]w(t)z(t)=[12]x(t)+β(t)[0.20.15]x(t)+v(t)y(t)=ρ0(t)z(t)+(1−ρ0(t))ρ1(t−1)z(t−1)+(1−ρ0(t))×(1−ρ1(t−1))ρ2(t−2)z(t−2)+ρ3(t)y(t−1)wherew(t)andv(t)satisfyw(t)=ξ(t)+ξ(t−1)andv(t)=w(t)+γ(t).w(t)andγ(t)are supposed to be uncorrelated.γ(t)andξ(t)are generated by Gaussian white noises with zero means and covariances 0.05 and 0.1, respectively. Assume thatVar(α(t))=2,Var(β(t))=2,xˆ(0|−1)=[0,0]TandP0=0.3I2.Based on the estimation algorithms proposed in Theorem 1, the optimal linear filterxˆ(t|t)is given Fig. 1, from which, we can see thatxˆ(t|t)can track the real curvex(t)well. Fig. 2shows the comparison curve of estimation variances aboutxˆ(t|n)(n=t,t−1,t+1,t−2), which demonstrates that the 2-step predictor has the worst performance, while the smoother has the best one. This means that as prediction step length|h|increases, the estimation variances become larger. Fig. 3indicates the filter error variances againstQα,Qβranging from 0 to 2. The filter error variances againstρ‾0,ρ‾1ranging from 0.1 to 1 are illustrated in Fig. 4. Define mean square error (MSE) and accumulation error (AE) asMSE(k)=∑i=1N(x(i)(k)−xˆ(i)(k))2/NandAE(t)=∑k=1tMSE(k), respectively. Comparisons among [8,20] and our work are displayed in Figs. 5–6. When delay rate is larger, Fig. 5 shows that the filter proposed in [20] performs worse than our filter. Fig. 6 indicates that, when packet dropout rate is larger, our filter has more advantages over that in [8] underu(t)=0. The main reasons are that many efforts have been made for our filter to compensate the effects of multi-step delays, packet dropouts as well as correlated noises. These simulation results demonstrate the feasibility of our algorithms.Example 2In the simulation, we consider an Internet-based three-tank system (ITTS) which consists of a traditional three-tank system (TTS), a networked camera, two NetCon systems, a PC and the Internet used for data transmission. TTS is a nonlinear multi-input multi-output laboratory equipment which is made up of three plexiglass tanks connected in series with each other. A networked camera is employed to monitor the process, two NetCon systems are used for the implementation of remote control via Internet and a PC is used for downloading the algorithms.As is known, TTS is described by a nonlinear continuous-time model, which can be transformed into a discrete-time linear one after linearizing and discretizing, see [26]. Owing to linearization and discretization of the original systems together with the fluctuation of liquid surface caused by the inflow from the pumps, modeling uncertainties unavoidably exist. Here, we assume the liquid levels of the three tanks are the system statex(t). The height measurements of TankT1and TankT2represent the measurementsz(t). The measurements received by the estimator in UK isy(t). Our aim is to estimate the liquid levels of TTS through the received incomplete measurementsy(t). The coefficient matrices are adopted from [27]:A(t)=[0.99080.00000.00910.00000.98560.00720.00910.00720.9836],Aμ,1(t)=[00000−0.0001000.0001]B(t)=[64.66270.00070.29780.000764.49080.23580.29780.235864.4271],C(t)=[100010],Cμ,1(t)=[00.0001−0.00030−0.00030.0002].In addition,w(t)andv(t)satisfyw(t)=ζ(t)+ζ(t−1)andv(t)=103w(t), whereζ(t)is Gaussian white noise with zero means and covariances10−12.Var(α(t))=0.05,Var(β(t))=0.02,xˆ(0|−1)=[0.4,0.3,0.35]T,P0=2.5×10−5I3and a constant control signalu=[3.8×10−5,2.4×10−5,1.2×10−5]T. Meanwhile, the incomplete measurement modely(t)is assumed to be the same as in Example 1,ρ‾0=0.95,ρ‾1=0.005andρ‾2=0.0023. Figs. 7–10respectively give the optimal linear filters and its estimation variances curve. From these figures, it is observed that our estimation algorithms have a good tracking performance and the filter can reach steady-state. Comparison of the AEs under two cases: case 1:ρ‾0=0.7,ρ‾1=0.06andρ‾2=0.012; Case 2:ρ‾0=0.9,ρ‾1=0.02andρ‾2=0.004are shown in Figs. 11–12. It is observed that, the tracking performance becomes better as the on-time arrival rateρ‾0becoming larger.

@&#CONCLUSIONS@&#
