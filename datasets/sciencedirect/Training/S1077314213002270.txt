@&#MAIN-TITLE@&#
Matching mixtures of curves for human action recognition

@&#HIGHLIGHTS@&#
Gaussian mixture model framework for clustering motion curves.Matching training and probe motion curves using the longest common subsequence.Reduce the length of the time series using dimensionality reduction techniques.Categorize a probe video sequence using nearest neighbor classification scheme.

@&#KEYPHRASES@&#
Human action recognition,Optical flow,Motion curves,Gaussian mixture modeling (GMM),Clustering,Dimensionality reduction,Longest common subsequence,

@&#ABSTRACT@&#
A learning-based framework for action representation and recognition relying on the description of an action by time series of optical flow motion features is presented. In the learning step, the motion curves representing each action are clustered using Gaussian mixture modeling (GMM). In the recognition step, the optical flow curves of a probe sequence are also clustered using a GMM, then each probe sequence is projected onto the training space and the probe curves are matched to the learned curves using a non-metric similarity function based on the longest common subsequence, which is robust to noise and provides an intuitive notion of similarity between curves. Alignment between the mean curves is performed using canonical time warping. Finally, the probe sequence is categorized to the learned action with the maximum similarity using a nearest neighbor classification scheme. We also present a variant of the method where the length of the time series is reduced by dimensionality reduction in both training and test phases, in order to smooth out the outliers, which are common in these type of sequences. Experimental results on KTH, UCF Sports and UCF YouTube action databases demonstrate the effectiveness of the proposed method.

@&#INTRODUCTION@&#
Action recognition is a preponderant and difficult task in computer vision. Many applications, including video surveillance systems, human–computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system. The goal of human activity recognition is to examine activities from video sequences or still images. Motivated by this fact our human activity recognition system aims to correctly classify a video into its activity category.In this paper, we address the problem of human action recognition by representing an action with a set of clustered motion curves. Motion curves are generated by optical flow features which are then clustered using a different Gaussian mixture [1] for each distinct action. The optical flow curves of a probe sequence are also clustered using a Gaussian mixture model (GMM) and they are matched to the learned curves using a similarity function [2] relying on the longest common subsequence (LCSS) between curves and the canonical time warping (CTW) [3]. Linear [1] and nonlinear [4] dimensionality reduction methods may also be employed in order to remove outliers from the motion curves and reduce their lengths. The motion curve of a new probe video is projected onto its own subspace by a projection matrix specified by that video, and then the action label of the closest projection is selected according to the learned feature vectors as the identity of the probe sequence. The LCSS is robust to noise and provides an intuitive notion of similarity between curves. Since different actors perform the same action in different manners and at different speeds, an advantage of the LCSS similarity is that it can handle with motion curves of varied lengths. On the other hand, CTW, which is based on the dynamic time warping [5], allows the spatio-temporal alignment between two human motion sequences. A preliminary version of this work was presented in [6]. One of the main contributions of this paper is that the training sequences do not need to have the same length. When a new probe sequence comes, it is matched against all the training sequences using the LCSS similarity measure. This measure provides a similarity between motion curves without enforcing one-to-one matching. An optimal matching is performed using dynamic programming, which detects similar pairs of curve segments [2].However, training an action recognition system with only the knowledge of the motion of the current subject it is on its own a challenging task. The main problem is how we can ensure the continuity of the curves along time as an action occurs uniformly or non-uniformly within a video sequence. Unlike other approaches [7,8], which use snippets of motion trajectories, our approach uses the full length of motion curves by tracking the optical flow features. Another question concerns the optimal model that one should adopt for recognizing human actions with high accuracy. This is accomplished by a statistical measure based on the data likelihood. The different lengths of the video sequences and therefore the respective lengths of the motion curves is another problem that is addressed. The large variance between benchmark datasets shows how the algorithm may be generalized. All these problems are discussed here and proper solutions are proposed. To this end, we have conducted experiments on several datasets [9–11] that would help us to understand how human activity recognition works.Concatenating of optical flow features along time allows us to collect time series that preserve their continuity along time. It is true that correspondence is missing. However, this is the main assumption in many works [12–14]. If data association were used the resulting feature curves would have short duration and would be incomplete, as the features disappear and reappear due to occlusion, illumination, viewpoint changes and noise. In that case, a combination of sparse approach of clustering curves with variant lengths and tracking approaches should be used [15,16]. This is not the central idea in this paper, as the nature of the feature curves drastically changes.In the rest of the paper, the related work is presented in Section 2, while the extraction of motion curves, the clustering and the curve matching are presented in Section 3. In Section 4, we report results on the KTH [9], the UCF Sports [10] and the UCF YouTube [11] action classification datasets. Finally, conclusions are drawn in Section 5.

@&#CONCLUSIONS@&#
