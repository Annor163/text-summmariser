@&#MAIN-TITLE@&#
Brain activity detection by estimating the signal-to-noise ratio of fMRI time series using dynamic linear models

@&#HIGHLIGHTS@&#
We propose a new interpretable model-based approach to detect brain activity in fMRI.The model makes no assumptions about the stimulation paradigm.We demonstrate the ability of the model to analyse resting-state fMRI studies.

@&#KEYPHRASES@&#
Bayesian analysis,Dynamic linear models,fMRI,Resting-state,

@&#ABSTRACT@&#
This work shows an example of the application of Bayesian dynamic linear models in fMRI analysis. Estimating the error variances of such a model, we are able to obtain samples from the posterior distribution of the signal-to-noise ratio for each voxel, which is used as a criterion for the detection of brain activity. The benefits of this approach are: (i) the reduced number of parameters, (ii) the model makes no assumptions about the stimulation paradigm, (iii) an interpretable model based approach, and (iv) flexibility. The performance of the proposed method is shown by simulations and further results are presented on the application of the model for the analysis of a real fMRI data set, in order to illustrate some practical issues and to compare with previously proposed techniques. The results obtained demonstrate the ability of the model to detect brain activity, even when the stimulus paradigm is unknown, constituting an alternative to data driven approaches when dealing with resting-state fMRI.

@&#INTRODUCTION@&#
During the last few decades, functional Magnetic Resonance Imaging (fMRI) has contributed to the development of a more profound knowledge of brain functioning in both neuroscience and disease by providing a measure of brain activation, observing hemodynamic response. This paper describes a new approach for determining which parts of the brain show activation in response to an endogenous or exogenous stimulus in blood oxygen level dependent (BOLD) contrast [26] fMRI data.A fMRI study, which can be interpreted as a three dimensional movie of the brain, results in a vast amount of noisy data with a complicated spatiotemporal correlation structure. In BOLD fMRI statistical analysis, there are two main approaches: data driven and model driven. The former reduces the whole spatiotemporal data set into certain multivariate components with similar characteristics. By contrast, the latter fits a model to the observed data, taking into account the prior information provided by neuroscientific rationale or previous experiments. The two approaches are therefore fundamentally different in perspective and assumptions [20].Data driven procedures include Independent Component Analysis (ICA) [24,1], principal component analysis [9] and cluster analysis [14,4], among others. These techniques attempt to characterise reliable patterns in the data, and relate those patterns to physiological activity post hoc. As stated in Lindquist [21], while these methods provide a fair amount of flexibility, not containing any model information, they capture regularities whatever the source, and, therefore, they are highly susceptible to noise and components are often dominated by artifacts.Regarding model driven literature, inference about brain activity in fMRI data is commonly addressed through the General Linear Model (GLM) analysis, introduced by Friston et al. [10], in which a linear dependency of the BOLD signal and the hemodynamic response function (HRF) is assumed. Generally, the stimulus pattern is fit simply as a box-shaped wave, which is then convolved with an HRF template. Several kernels have been considered for the HRF template, including Poisson [11], Gaussian [10], and gamma [19,2]. The convolution approach is attractive for its simplicity. However, it imposes restrictions to the model, e.g. it forces antisymmetry and monotonicity on each half cycle, as mentioned by Crellin, Hastie and Johnstone in the published discussions of Lange and Zeger [19]. As stated by Lindquist and Wager [22], among others, using the canonical HRF in the general linear model can be a very restrictive assumption, commonly making model driven approaches unable to analyse studies in which the subject neither undergoes a controlled stimulation nor performs a precisely defined task, as it is the case of resting-state studies in physiology and pathology.Here we propose a less restrictive model driven approach, which makes no assumptions on the shape of the HRF or the stimulation paradigm presented during the experiment. In fMRI time series analysis, an increase of signal followed by a slow decay to baseline (or inactivity level in the case of resting-state) is generally expected in the active regions of the brain. Hence, it is reasonable to assume that the SNR, defined as the ratio of the signal variance to the variance of the system noise, is larger for active than for non-active voxels, due to the signal fluctuations observed in the brain [8,3]. The estimation of the SNR for each voxel is therefore a key factor in the detection of brain activity, for which we propose the employment of dynamic linear models (DLM), under a Bayesian paradigm.Taking into account the quantity of data and that, in most cases, we have prior information about activity, Bayesian statistics constitute an ideal framework to carry out signal and image processing, being a natural but rigorous theory for combining prior and experimental information, see for instance Fitzgerald et al. [7] and Fitzgerald [6]. As stated by Zhang et al. [35], who provide a review of the most relevant Bayesian models for fMRI data analysis developed in recent years, Bayesian approaches have great potential in fMRI applications, as they allow flexible modelling of spatial and temporal correlation in the data [34].In addition, DLM provides a very rich class of models for the analysis of time series data: see West and Harrison [33], the overview by Migon et al. [25], and references therein. DLM considers a time series as the output of a dynamic system perturbed by random disturbances. They allow natural interpretation of a time series as the combination of several components, such as trend, seasonal or regressive components. Therefore, they are flexible enough to capture the main features of a wide range of different data. At the same time, they have a powerful probabilistic structure, allowing many of the relevant inferences to be carried out exactly using the Kalman filter [18]. Thus computations can be implemented by recursive algorithms, computing the conditional distribution of the quantities of interest, given the available information. In this sense, they are naturally treated within a Bayesian framework.The rest of the paper is structured as follows: in Section 2 we formally state the model, Section 3 outlines the algorithm implemented to make inferences about the unknown parameters, Section 4 presents the results obtained for simulations from the model, simulated data, and a real data set and Section 5 is devoted to conclusions and future directions of research.Let us assume that the time series for a voxel in a fMRI study,y1:T={yt}t=1,…,T, follows a constant DLM defined by(1)yt=μt+vt,vt∼N(0,V)(2)μt=Gtμt−1+wt,wt∼N(0,W=rV)where V and W are unknown constants and the error sequences are independent, both within and between them.Equation (1) is called the observation equation for the model, defining the sampling distribution forytconditional on the level,μt. Notice that, givenμt,ytis independent of all the other observations and parameter values.Equation (2) is the evolution, state or system equation, defining the time evolution of the signal level. The conditional independence property shows a one-step Markov evolution so that, givenμt−1and the values ofGtand W,μtis independent of the past. That is, givenμt−1, the distribution ofμtis fully determined independently of values ofyt−1and the level values and observations prior to timet−1. The deterministic component of the evolution is the transition from stateμt−1toGtμt−1, a linear transformation ofμt−1. Here we assume thatGtis known, and following the recommendations of Petris et al. [28] to optimise the performance of the algorithm used (see Section 3) for the model proposed, we defineGt=G=0.9, leading to an autoregressive model for the level of the series.The SNR for each voxel, defined as the ratio of the signal variance to the variance of the system noise, can be estimated using this DLM model as(3)r=WVwhich is a broadly accepted measure for comparing performance characteristics between different time series [33,28]. Two examples of time series with different SNR are shown in Fig. 1. A low SNR, like in (a), leads to a typical locally constant level, whereas in (b) the SNR is 100 times larger, resulting in much greater variation in the level.As we are interested in estimating the unknown parameters of the model –μt, V, W – a fully Bayesian analysis is developed. The model is then completed with the initial information about the level at timet=0that describes our prior beliefs aboutμ0, V, and W. In particular, assume that prior information about the unknown parameters is available and summarised by a gamma distribution forϕ=V−1, a Gaussian distribution forμ0and, following the recommendations of Gelman [12], a log normal prior distribution for W. Formally, define prior distributions forμ0, V, and W by(4)μ0∼N(m0,C0)(5)ϕ∼G(αV,βV)(6)W∼log⁡N(mW,σW2).Note that the flexibility of these prior distributions allows the incorporation of prior knowledge. In case that it is not available, we may use instead a non-informative version of the proposed prior distributions (i.e. with large variances). In our case, we useαV=βV=10,m0=mW=0, andC0=σW2=100.The choice of a conjugate prior distribution for V leads to a gamma posterior distribution of V conditional ony1:Tandμ0:T,(7)V|y1:T,μ0:T∼G(αV+T2,βV+12∑t=1T(yt−μt)2).On the contrary, the posterior distribution of W conditional onμtand V does not have a known form,W|μ0:T∝W−T2−1exp⁡{−12σW2[(log⁡(W)−mW)2]}exp⁡{−12W∑t=1T(μt−Gtμ−1)2}.Lastly, letRt=G2Ct−1+W, andQt=Rt+V, then the posterior distribution ofμtat time t is recursively defined byμt|yt,μt−1,V,W∼N(mt,Ct)withmt=Gμt−1+RtQt(yt−Gμt−1)andCt=Rt−(RtQt)2Qt(see West and Harrison [33] for further details).For each fMRI experiment, the analysis is performed on a slice-by-slice basis, and only those voxels inside the brain are analysed. Firstly, each voxel's time series is standardised so that its variance is 1 and its mean is 0.WhenGt, V, and W are known, the Kalman filter [18] can be used to perform inference about the latent processμt. In practise these parameters are unknown and numerical integration methods, such as MCMC, are required for the Bayesian statistical analysis.In our case, the set of unknown parameters can be partitioned in two blocks: V and W; and(μ1,…,μT). In particular, following Petris et al. [28], we use a Gibbs sampling scheme for posterior inference, in four steps:(1)DrawV(k)fromp(V|μ0:T(k−1),y1:T), as defined in equation (7);Drawμ0:T(k)fromp(μ0:T|V(k),W(k−1),y1:T);SimulateW(k)from full conditional density of W givenμ0:T(k),Obtainr(k)=W(k)V(k),It is important to note that using a Bayesian framework allows us to not only obtain a point estimation but to compute the posterior distribution of r, which also enables us to compute the probability of any event of interest. For instance, the probability that the SNR of a time series is above some threshold,(8)P(r>r0|y)=1K∑kI(r(k)>r0).We decide the value of this threshold,r0, based on the control of the false discovery rate, as explained in Genovese et al. [13]. For the N voxels being tested, the procedure is as follows: (i) select a bound, q, for the false discovery rate; (ii) order the probabilities, in our case,p=1−P(r>r0|y), and (iii) find the largest i for whichp(i)≤iNqc(V), where (i) denotes the ordering index. In the discussion, Genovese et al. [13] give recommendations on the choice of q andc(V)in the framework of neuroimaging data analysis.

@&#CONCLUSIONS@&#
This research describes the employment of DLM to analyse the time series for a voxel in a fMRI experiment. Estimating the error variances of such a model and using Bayesian inference, we are able to obtain samples from the posterior distribution of the SNR for that voxel. This enables us to provide not just a point estimate of the SNR for each voxel but also to compute the probability of any event of interest. The results obtained demonstrate the ability of the model to detect brain activity.The benefits of this approach are: (i) the reduced number of parameters in the DLM, (ii) the model makes no assumptions about the stimulation paradigm, (iii) a model based approach, hence more interpretable than a data driven one, and (iv) potential of including a wide range of other features like spatial dependencies, linear or seasonal trends, etc., due to the flexibility of DLM.In model driven approaches like the GLM, a canonical HRF is often used. According to Lindquist and Wager [22], this can be a restrictive assumption. As the model proposed makes no assumptions on the shape of the HRF and allows a dynamic temporal modelling, it does not suffer from most of the issues that model based approaches have.It is also important to emphasise here that the model makes no assumptions about the stimulation paradigm presented during the experiment. As stated in Lindquist [21], in many areas of physiological inquiry – including studies on memory, motivation and emotion – or in resting-state experiments, it may not be reasonable to assume that the experimental paradigm is known. Therefore, the GLM cannot be directly applied to these data sets and alternative methods are needed. Typically, researchers adopt a data driven approach like ICA, with the main drawback of a more complicated interpretation of the results. Therefore, this new approach, being model based, is able to deal with experiments with endogenous brain activity, such as resting-state fMRI data, as demonstrated.Although HRF estimation is out of the scope of this work, which aims at addressing the activity detection problem, it is important to note that the level,μt, contains all the information about the HRF for each voxel. This allows us to compute any estimate of interest, as for example the magnitude of the response, the time-to-peak, or the duration of activation.DLM is a powerful tool, unexplored in the analysis of fMRI data. In order to deal with HRF estimation, other DLM can be explored as, for example, dynamic regression or seasonal models [32].This work has several limitations. Firstly, this method relies on the identification of voxels with high SNR which, apart from neuronal activity, might in some cases carry SNR spatial dependency [5], or physiological noise [15]. It is thus important to count on a neuroscientist for the clinical interpretation of the results. Secondly, detection of active voxels may be improved by considering spatial dependencies in the model. Future versions of our model will include spatial prior information in order to perform a fully Bayesian spatiotemporal analysis of the whole brain. Thirdly, the model is concerned with single subject data. It is a matter of future work to extend it in order to incorporate information from a group of subjects. Multi-subject fMRI data is intrinsically hierarchical in nature and, therefore, Bayesian inference is an ideal framework for performing it. Lastly, the model is applied to a dataset acquired with a 3T MR scanner. Further work is needed on the applicability of the method to scanners with other magnetic fields or its dependence on fMRI acquisition parameters, if it is to be applied for supporting clinical decisions. It is important to remark again that, in the interpretation of the results obtained, it is the job of the neuroscientist to recognise those patterns that are genuinely neuronal and relevant for the patient under study.