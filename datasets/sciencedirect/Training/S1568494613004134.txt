@&#MAIN-TITLE@&#
Discovering driving strategies with a multiobjective optimization algorithm

@&#HIGHLIGHTS@&#
When driving a vehicle, several objectives have to be considered.The existing algorithms combine objectives into a weighted-sum cost function.We designed a multiobjective algorithm for discovering driving strategies.The presented algorithm outperforms the existing algorithms.

@&#KEYPHRASES@&#
Driving strategy,Traveling time,Fuel consumption,Driving optimization,Multiobjective optimization,Black-box approach,

@&#ABSTRACT@&#
When driving a vehicle along a given route, several objectives such as the traveling time and the fuel consumption have to be considered. This can be viewed as an optimization problem and solved with the appropriate optimization algorithms. The existing optimization algorithms mostly combine objectives into a weighted-sum cost function and solve the corresponding single-objective problem. Using a multiobjective approach should be, in principle, advantageous, since it enables better exploration of the multiobjective search space, however, no results about the optimization of driving with this approach have been reported yet. To test the multiobjective approach, we designed a two-level Multiobjective Optimization algorithm for discovering Driving Strategies (MODS). It finds a set of nondominated driving strategies with respect to two conflicting objectives: the traveling time and the fuel consumption. The lower-level algorithm is based on a deterministic breadth-first search and nondominated sorting, and searches for nondominated driving strategies. The upper-level algorithm is an evolutionary algorithm that optimizes the input parameters for the lower-level algorithm. The MODS algorithm was tested on data from real-world routes and compared with the existing single-objective algorithms for discovering driving strategies. The results show that the presented algorithm, on average, significantly outperforms the existing algorithms.

@&#INTRODUCTION@&#
Driving a vehicle along a given route is a complex process that consists of a series of control actions that are applied to the vehicle by taking into account the vehicle and route states. A set of connections between the states and control actions is a driving strategy. The cost of driving by applying a driving strategy mainly depends on the fuel consumption; however, when the fuel consumption is reduced, the traveling time increases. Consequently, the two objectives, i.e., the traveling time and the fuel consumption, are in conflict with each other. Improving one of the objectives deteriorates the other. Moreover, the extreme reduction of one objective leads to an unacceptable value for the other objective. Therefore, both objectives have to be taken into account simultaneously when constructing a driving strategy.The existing techniques for discovering driving strategies use single-objective optimization methods in combination with predictive control [1]. They can be divided into two groups: model-based approaches and black-box approaches. Model-based approaches require a knowledge about the applied vehicle model and are usually analytical, while black-box approaches use vehicle models without any knowledge of vehicle operation and are usually numerical. The selection among them mainly depends on whether the knowledge about the vehicle model is available or not, and whether a black-box simulator is available or not. However, the black-box approach is preferable from the user point of view as the knowledge about the vehicle model is usually unavailable.Model-based techniques aim to minimize either the weighted sum of the fuel consumption and the traveling time, or the fuel consumption only while considering the traveling time as a constraint. To optimize both objectives simultaneously, Huang et al. [2] used constrained nonlinear programming for predictive control, which is a gradient-based method that finds the global optimum if the optimized function is convex. Ivarsson et al. [3], on the other hand, used an analytical method appropriate only for routes with small gradients. Other approaches presented by Melnik [4], and Howlett et al. [5] aim at optimizing only the fuel, or more generally, energy consumption. Both constructed a set of equations describing the vehicle and the environment, and implemented algorithms that calculate the optimal velocity of either a road vehicle [4] or a train [5]. This velocity is obtained by equation differentiation. Similarly, Khmelnitsky [6] presented an analytical approach to calculate the optimal control actions of a train by minimizing the energy consumption on short segments. In addition, he implemented a numerical approach that combines several optimal control actions for short segments to obtain the optimal control actions for longer routes. Akcelik and Biggs [7] used an analytical method to optimize acceleration and deceleration profiles. These profiles aim at minimizing the fuel consumption and the traveled route, and were optimized on short routes, since only acceleration and deceleration phases were tested. Other researchers focused on obtaining good vehicle models to allow for control of the vehicle. Such approaches are suitable when target vehicle behavior is known, in contrast to the previously presented search approaches suitable when the target behavior is unknown. For example, Strum et al. [8] applied neural and fuzzy systems to learn the driving model and control the vehicle. The goal was to drive the vehicle as close as possible to a predefined speed profile. Tanaka and Sano [9] modeled a vehicle with a fuzzy model, and derived control rules from the model. The goal was to control the trajectory of the vehicle along a given reference trajectory.The black-box techniques mainly use dynamic programming methods to find the driving strategies, as presented in the following examples. The weighted sum of the traveling time and the fuel consumption was minimized by several authors. Monastyrsky and Golownykh [10], and Hooker et al. [11], on the one hand, searched for the global optimum, which can be done only for limited route lengths, while Hellstrom et al. [12], on the other hand, continuously optimized only a finite route length ahead of the vehicle. Other examples try to minimize only the energy consumption, while the traveling time is considered as a constraint. Hellstrom et al. [13] introduced an algorithm that optimizes the driving by controlling the throttle, brakes and gears of a vehicle. In contrast, Johannesson et al. [14] described an algorithm that schedules the charging and discharging of an energy-storage system for a hybrid bus. Researchers also optimized vehicle position on the route. For example, Diehl and Bjornberg [15] optimized vehicle parking in front of a wall. To that end, they implemented a dynamic programming algorithm that minimized the traveling time and distance to the wall.The previously presented single-objective methods have several disadvantages. Primarily, they find only one driving strategy and have to be used each time the requirements, e.g., the time constraint, change. Moreover, when a weighted sum is used, the driving strategy very much depends on the selected weights [16]. In addition, it is not clear how to select the weights. Therefore, if the driving strategy is not acceptable or when the requirements change, the algorithm has to be restarted with different weights. To find a set of driving strategies that meet the various requirements, a multiobjective method has to be used.The multiobjective technique finds a set of driving strategies that are incomparable since no driving strategy is better in both objectives than any other driving strategy. Such driving strategies are nondominated [17]. The set of nondominated driving strategies makes it possible to select a different strategy when the requirements change without restarting the algorithm or whenever the objectives are a matter of choice [18]. This is also suitable for users frequently traveling on the same route since each time they can apply a driving strategy with a different trade-off between the traveling time and the fuel consumption based on current requirements. The multiobjective approach is also more convenient than the single-objective approach since no constraints and/or weights have to be specified [19]. Moreover, Van Willigen et al. [20] presented the idea of deploying nondominated driving strategies in adaptive cruise control of future intelligent vehicles. In this case, a user can enter his/her preferences into the vehicle's cruise control at real time. Setting preferences corresponds to real-time selection of the driving strategy with the preferred values of the objectives. Searching for driving strategies by modeling a real vehicle driving on a real route as a black box and using a multiobjective optimization algorithm has not been proposed and evaluated yet.In this paper we present a two-level Multiobjective Optimization algorithm for discovering Driving Strategies (MODS) on a given route that minimizes the traveling time and the fuel consumption. The lower-level algorithm is a deterministic multiobjective algorithm based on a breadth-first search [21] and Nondominated Sorting Genetic Algorithm (NSGA-II) [17]. The algorithm searches for driving strategies and minimizes the traveling time and the fuel consumption. The upper-level algorithm is a single-objective evolutionary algorithm that searches for the optimal values of the input parameters for the lower-level algorithm. The initial implementation of the lower-level algorithm was presented in [22].The paper is further organized as follows. The implemented driving simulation is presented in Section 2. Section 3 describes an initial implementation of MODS, called MODS1, and an enhanced version of the algorithm, called MODS2. Section 4 presents the numerical experiments performed with MODS1, MODS2 and two traditional algorithms, i.e., predictive control and dynamic programming. It also presents the obtained driving strategies and the test cases that show how the vehicle state changes when the found driving strategies are applied to the vehicle. The results are discussed in Section 5. Finally, Section 6 concludes the paper with some ideas for future work.This section presents the black-box vehicle simulation model that simulates the vehicle driving along a predefined route.A route R is represented as a vector of segments. Each segmentRiRis defined with a touple〈siR,riR,αiR,vlim,iR★〉, where the components are:•lengthsiR,turning radiusriR,inclinationαiR,velocity limitvlim,iR★.The driving simulation simulates the vehicle driving along a predefined route. The requested input data are:•the current vehicle stateV={vV,sV},the current fitness values F={t, c},the throttle or braking percentage ɛV,the gear gV,the route step that has to be traveled ΔsV,travel,The route length that has already been traveled by the vehicle, sV, is used to determine the current segmentRisV, where the vehicle is located. The index of the current segmentisVis determined as follows:(3)isV=min∑k=1isk>sVi.The current segment defines the data about the current vehicle position on the route as follows: the inclination of the current segmentαCS=αisV, the inclination of the next segmentαNS=αisV+1, the velocity limit of the current segmentvlim,CS=vlim,isV, and the velocity limit of the next segmentvlim,NS=vlim,isV+1. Moreover, the route to the next segment sNS is:(4)sNS=∑k=1isVsk−sV.These data are used to determine the appropriate control action {ɛV, gV} that is applied to the vehicle with respect to the current vehicle position on the route, as described in Section 3.The simulation is performed in several time steps Δt by applying the vehicle simulator presented in Section 2.3 until the traveling along the route ΔsV,travel has been simulated. More precisely, the remaining route to be traveled is initialized as ΔsV,remain=ΔsV,travel. The simulation is made in time steps until ΔsV,remain=0. After each time step, the vehicle simulator returns the traveling time Δt★, the consumed fuel Δc, the traveled routeΔsV,travel★and the updated vehicle velocityvV,new. The time step Δt differs from Δt★ during the last step, when usually less time is spent traveling. Afterwards, the remaining route to be traveled is updated asΔsV,remain,new=ΔsV,remain−ΔsV,travel★,ΔsV,remain=ΔsV,remain,new, and V and F are updated as follows:•sV,new=sV+ΔsV,travel★,tnew=t+Δt★,cnew=c+Δc,vV=vV,new,sV=sV, new,t=tnew,c=cnew.We implemented a vehicle simulation model based on the vehicle description from [24]. The forces acting on the vehicle are listed in Table 1. They are combined together as follows [24]:(5)Fa=FEM−FEB−FTB−FW−FA−Ft.The engine moving force FEM is 0 if the throttle percentage is 0 (ɛV≤0). Otherwise, it is calculated as follows [24]:(6)FEM=TEIG,gVIDrWη,(7)TE=ɛVTE,max,(8)TE,max=fTE,max(nE),(9)nE=nWIG,gVID,(10)nW=vV2πrW,where TE is the engine torque,IG,gVis the gear ratio for gear gV, ID is the differential ratio, rW is the wheel radius, η is the vehicle transmission's mechanical efficiency, TE, max is the maximum engine torque,fTE,max(nE)is the maximum torque function, nE is the engine speed, and nW is the wheel speed.The engine braking force FEB is 0 if the throttle percentage is greater than 0 (ɛV>0). Otherwise, it is calculated as follows [24]:(11)FEB=TEBIG,gVIDηrW,(12)TEB=kEBnE+nEB,(13)kEB=max(TE)/3−min(TE)max(nE)−min(nE),(14)nEB=min(TE)−kEBmin(nE),where TEB is the engine braking torque.The tire braking force FTB is 0 if the braking percentage is 0 (ɛV≥0). Otherwise, it is [25]:(15)FTB=−ɛVμmVgcosαCS,where μ is the tire braking force percentage, mV is the vehicle mass, and αCS is the current segment inclination.The wheel friction force is [24]:(16)FW=crmVgcosαCS,where cr is the rolling-resistance coefficient.The aerodynamic drag force is [24]:(17)FA=0.5ρvV2Axcx,where ρ is the air density, Ax is the vehicle frontal area, and cx is the vehicle's aerodynamic coefficient.The tangential component of the force of gravity is [24]:(18)Ft=mVgsinαCS.The inertial acceleration is [24]:(19)aV=FamV.The traveling time Δt★ is initialized as Δt★=Δt. The vehicle velocity is updated as follows [24]:(20)vV,new=vV+aVΔt★.If, as a result of a driving strategy, the vehicle velocity becomes negative (vV,new<0), only the initial traveling is taken into account until the vehicle velocity is zero (vV,new=0). Consequently, the traveling time has to be updated as:(21)Δt★=−vVaV.The traveled routeΔsV,travel★is [24]:(22)ΔsV,travel★=vVΔt★+aVΔt★22.If the traveled route is longer than allowed (ΔsV,travel★>ΔsV,remain), the traveling time is reduced:(23)Δt★=ΔsV,remainvV;ifaV=0,−vV+vV2+2aVΔsV,remainaV;otherwise,the traveled routeΔsV,travel★is updated using Eq. (22), and the vehicle velocityvV,newis updated using Eq. (20).The vehicle has the following limits: the maximum engine speed and the maximum vehicle velocity. These limits are taken into account as follows. The updated engine speed nE,new is:(24)nE,new=vV,new2πrWIG,gVID.If nE,new>max(nE), then nE,new=max(nE) and the vehicle velocity is updated as follows:(25)vV,new=2πrWnE,newIG,gVID.Next, the vehicle velocity is checked. IfvV,new>max(vV), thenvV,new=max(vV)and the engine speed nE,new is updated using Eq. 24.Finally, the fuel consumption Δc is calculated as follows [24]:(26)Δc=fc(TE,nE)PEΔt★,(27)PE=2πTEnE,where fc(TE, nE) is the fuel-consumption function and PE is the engine power.When the simulation begins, the vehicle is not moving (vV=0). The vehicle can start moving only if the first gear is selected (gV=1). This is due to the fact that the engine's operation is limited by the minimum engine speed, in addition to the maximum engine speed. Consequently, if the engine speed is lower than the minimum engine speed, the engine does not produce any engine torque (TE, max=0) and the vehicle cannot start moving. However, this limit is applied only if the first gear is not selected. On the other hand, if the first gear is selected, the engine speed is set to the minimum engine speed. Consequently, the engine produces engine torque (TE, max>0) and the vehicle can start moving.This section presents the two-level Multiobjective Optimization algorithm for discovering Driving Strategies (MODS) along a given route that minimizes the traveling time and the fuel consumption. The lower-level algorithm called LL-MODS is a deterministic, multiobjective algorithm that searches for a set of nondominated driving strategies and minimizes the traveling time and the fuel consumption. The upper-level algorithm, UL-MODS, is a single objective evolutionary algorithm that searches for the optimal input parameters for the lower-level algorithm. The final result is a set of nondominated driving strategies found with the best solutions at the upper level. The scheme of MODS is shown in Fig. 1.There are two versions of the MODS algorithm. The first one is the initial implementation of MODS, called MODS1, and consists of LL-MODS1 and UL-MODS1. The second version, MODS2, is the enhanced implementation of MODS, and consists of LL-MODS2 and UL-MODS2. Both versions correspond to Fig. 1, but differ in the algorithm's details. They are presented in the following sections.The initial design and implementation of the algorithm for discovering driving strategies MODS, called MODS1, is presented here.The lower-level algorithm LL-MODS1 is a deterministic algorithm that searches for driving strategies and aims at minimizing both the traveling time t and the fuel consumption c. Similarly to the breadth-first search [21], it starts with a driving strategy with no control actions and inspects all the neighboring driving strategies. Then for each of the neighboring driving strategies in turn, it inspects their neighboring driving strategies, and so on. A neighboring driving strategy s2 of driving strategy s1 is a clone of s1 that includes also the control action for the next route step. One neighboring driving strategy exists for each possible control action. This process continues for subsequent route steps until the entire route is simulated.A driving strategy is represented as a set of connections between the vehicle and route states, on the one hand, and the control actions applied to the vehicle, on the other hand. More precisely, the vehicle and route state space is a six-dimensional space discretized into hypercubes [26]. The six dimensions of the state space are shown in Table 2.The control actions applied to the vehicle are combinations of the throttle and braking percentages ɛV, and gears gV. The gears are discrete and stored in the vector Dg. On the other hand, the state-space dimensions and the throttle and braking percentage are not discrete. Therefore, they have to be discretized with vectors of interval splits for each space dimension, as shown in Table 3. A set of these vectors is called a hypercube discretization and this has to be given in advance.A hypercube represents a rule:ifvV∈[Dv,ivV,Dv,ivV+1),αCS∈[Dα,iαCS,Dα,iαCS+1),αNS∈[Dα,iαNS,Dα,iαNS+1),vlim,CS∈[Dv,ivlim,CS,Dv,ivlim,CS+1),vlim,NS∈[Dv,ivlim,NS,Dv,ivlim,NS+1),sNS∈[Ds,isNS,Ds,isNS+1)thencontrol action {ɛV, gV},where the indexesivV,iαCS,iαNS,ivlim,CS,ivlim,NS, andisNSare determined by the current vehicle and route state. These data are stored in a vector:(28)Sj=(ivV,iαCS,iαNS,ivlim,CS,ivlim,NS,isNS,ɛV,gV).A set of such vectors S={Sj} is a driving strategy.LL-MODS1 starts with a single empty driving strategy Sempty where none of the hypercubes stores a control action (Line 1 in Algorithm LL-MODS1). Afterwards, the vehicle driving is simulated using the simulator presented in Section 2 until the traveling along the entire route has been simulated or becomes infeasible (Lines 21–26). This is done in several route steps ΔsV where in each route step the current vehicle and route state is used to determine the current hypercube. If the hypercube stores the control action (Lines 7–8), this control action is used for one route-step simulation and prediction for NP−1 steps (Line 20), where the number of predicted steps NP has to be given in advance. On the other hand, if the control action does not exist, e.g., the initial driving strategy has no control actions, the driving strategy is cloned for each possible control action, the appropriate control action is stored in the hypercube (Lines 10–16), and this control action is used for one route-step simulation and prediction for NP−1 steps (Line 20). The driving simulation and prediction (Line 20) are performed using the simulator presented in Section 2. The current vehicle state{vV,sV}and the fitness values {t, c} as inputs for the simulator are obtained with the functionsV(S)={vV,sV}and F(S)={t, c}. These functions return the state and fitness values of the vehicle driving that has already been simulated using the driving strategy S (Line 20). Since the driving strategies are cloned (Line 12), the number of driving strategies grows exponentially. To maintain a constant number of driving strategies Spop, the number of driving strategies is reduced (Line 29). This is carried out using the Fast Nondominated Sort and Crowding Distance mechanisms from the Nondominated Sorting Genetic Algorithm (NSGA-II) [17]. When the traveling along the entire route has been simulated, the algorithm finds a set of nondominated driving strategies (Line 35) by applying the Fast Nondominated Sort mechanism from NSGA-II, and returns it as the result (Line 36). The LL-MODS1 algorithm is as follows.AlgorithmLL-MODS11:Spop={Sempty}2:Sfinal={}3:repeat4:Spop,nextStep={}5:forallS∈Spopdo6:Spop,temp={}7:if currently observed hypercube of driving strategy S stores control action then8:Spop,temp={S}9:else10:for allɛV∈Dɛdo11:for allgV∈Dgdo12:Sclone=S.clone()13:Sclone.addInCurrentHypercube(ɛV, gV)14:Spop,temp.add(Sclone)15:end for16:end for17:end if18:for all Stemp∈Spop,tempdo19:{ɛV, gV}=Stemp.getCurrentHypercube()20:simulateDriving(V(Stemp), F(Stemp), ɛV, gV, ΔsVNP)21:ifStemp simulated driving along entire route and feasible after first step22:Stemp=Stemp.getFirstSimulatedStep()23:Sfinal.add(Stemp)24:else ifStemp feasible then25:Spop,nextStep.add(Stemp)26:end if27:end for28:end for29:reduceNumberOfDrivingStrategies(Spop,nextStep)30:for allSnextStep∈Spop,nextStepdo31:SnextStep=SnextStep.getFirstSimulatedStep()32:end for33:Spop=Spop,nextStep34:until Spop={}35:Sfinal=getNondominatedDrivingStrategies(Sfinal)36:return SfinalThis section presents a single-objective evolutionary algorithm UL-MODS1 that searches for the optimal sets of input-parameter values for the already described lower-level algorithm. More precisely, it applies selection, crossover and mutation on a population of sets of input-parameter values over a number of generations to search for the optimal sets.The set of input-parameter values is stored in an upper-level solution and encoded as a vector of Boolean values and one integer value forming a chromosome. The vector defines the hypercube discretization that consists of a subset of interval splits given with the finest discretization. The finest discretization has to be given in advance as:(29){Dv,finest,Ds,finest,Dα,finest,Dɛ,finest}.The hypercube discretization is defined with the vector of Boolean values D, the length of which is:(30)|D|=|Dv,finest|+|Ds,finest|+|Dα,finest|+|Dɛ,finest|.This vector is used to define the hypercube discretization as follows. If a Boolean value in this vector is true, the corresponding interval split is included into the hypercube discretization. A larger number of selected interval splits results in a more finely discretized state space and more control actions that can be applied to the vehicle. Otherwise, a more coarsely discretized state space is obtained and less control actions can be applied to the vehicle. The obtained hypercube discretization is given as follows:(31)Dv={v;v=Dv,finest,i,Di=true∧i=1,…,|Dv,finest|},(32)Ds={s;s=Ds,finest,i,Di=true∧i=|Dv,finest|+1,…,|Dv,finest|+|Ds,finest|},(33)Dα={α;α=Dα,finest,i,Di=true∧i=|Dv,finest|+|Ds,finest|+1,…,|Dv,finest|+|Ds,finest|+|Dα,finest|},(34)Dɛ={ɛ;ɛ=Dɛ,finest,i,Di=true∧i=|Dv,finest|+|Ds,finest|+|Dα,finest|+1,…,|Dv,finest|+|Ds,finest|+|Dα,finest|+|Dɛ,finest|}.The integer value in the chromosome represents the number of predicted steps NP, which is between 1 and the maximum value NP,max. The maximum number of predicted steps NP,max has to be given in advance.An example of a hypercube discretization is as follows. If the finest discretization is defined as Dv,finest={50, 100}, Ds,finest={10, 20, 40}, Dα,finest={0.05, 0.1} and Dɛ,finest={0, 1}, and if D={true, true, false, true, false, false, true, false, true}, then Dv={50, 100}, Ds={20}, Dα={0.1} and Dɛ={1}.UL-MODS1 uses a scheme that was already presented in Fig. 1. More precisely, it operates with a set of upper-level solutions called the population and uses multipoint crossover and mutation operators. The crossover is performed by selecting Ncr crossover points and exchanging data between each second pair of consecutive crossover points with the probability pcr. The mutation of the Boolean values is carried out by negating them, while the NP is mutated by assigning it a random value between 1 and NP,max[27]. Each of these values is mutated with the probability pmut. After the crossover and mutation, an upper-level solution is evaluated in two steps. First, the lower-level algorithm LL-MODS1, already presented in Section 3.1.1, finds nondominated driving strategies using the input-parameter values defined by the upper-level solution. When the driving strategies are found, they are stored in the upper-level solution. Second, the driving strategies contained by all the upper-level solutions in the population are included into a set of driving strategies and the hypervolume [28] covered by this set is calculated. The upper-level solution replaces its parent if the hypervolume increases after the replacement. These procedure is repeated for each upper-level solution in the population in each generation, where the population size is Spop and the number of generations is Ngen. The algorithm returns a set of nondominated driving strategies obtained from all the upper-level solutions in the population.To further improve the quality of the driving strategies found with MODS1, we enhanced the algorithm obtaining MODS2. The scheme of MODS2 is the same as the scheme of MODS1.The lower-level algorithm LL-MODS2 was obtained from the LL-MODS1 presented in Section 3.1.1 by adding the weighted-sum approach similar to the one used in predictive control [1]. This approach uses a weight ω to combine the objectives into a single cost function (Line 25 in Algorithm LL-MODS2). This function is used to evaluate all the possible control actions {ɛV, gV} during each step (Lines 18–31) and therefore to select the best one (Line 28). The obtained algorithm, however, differs significantly from predictive control algorithms in terms of the usage of ω. More precisely, predictive control algorithms use only one weight at a time, while LL-MODS2 searches for the best weight for each hypercube. Consequently, the hypercubes of a driving strategy store the weights ω (Line 12), which are used to select the best control action each time the hypercube is observed. The weights are discretized and stored in the vector Ω, which has to be given in advance. For example, a driving strategy obtained with LL-MODS2 can store large weights (low fuel consumption is preferred) for horizontal route segments, and small weights (a short traveling time is preferred) for uphill route segments. Such a strategy cannot be obtained with predictive control algorithms. Therefore, LL-MODS2 explores a larger set of possible driving strategies than predictive control algorithms and consequently can find better driving strategies than predictive control algorithms. On the other hand, it is hard to explore such a large search space efficiently. Therefore, the search space is limited by reducing the number of possible weights. More precisely, LL-MODS2 uses ω∈Ω, where ωmin≤ω≤ωmax (Lines 10–14). Consequently, the algorithm has two additional input parameters with respect to LL-MODS1: ωmin, ωmax∈Ω. The enhanced lower-level algorithm LL-MODS2 is as follows.AlgorithmLL-MODS21:Spop={Sempty}2:Sfinal={}3:repeat4:Spop,nextStep={}5:for allS∈Spopdo6:Spop,temp={}7:if currently observed hypercube of driving strategy S stores weight then8:Spop,temp={S}9:else10:for allω∈Ω, ωmin≤ω≤ωmax11:Sclone=S.clone()12:Sclone.addInCurrentHypercube(ω)13:Spop,temp.add(Sclone)14:end for15:end if16:for allStemp∈Spop,tempdo17:ω=Stemp.getCurrentHypercube()18:fbest=∞19:{ɛV,best, gV,best}=null20:for allɛV∈Dɛdo21:for allgV∈Dgdo22:Sclone=Stemp.clone()23:simulateDriving(V(Sclone), F(Sclone), ɛV, gV, ΔsVNP)24:{t, c}=F(Sclone)25:fnew=cω+t(1−ω)26:iffnew<fbestthen27:fbest=fnew28:{ɛV,best, gV,best}={ɛV, gV}29:end if30:end for31:end for32:simulateDriving(V(Stemp), F(Stemp), ɛV,best, gV,best, ΔsV)33:ifStemp simulated driving along entire route and feasible then34:Sfinal.add(Stemp)35:else ifStemp feasible then36:Spop,nextStep.add(Stemp)37:end if38:end for39:end for40:reduceNumberOfDrivingStrategies(Spop,nextStep)41:Spop=Spop,nextStep42:until Spop={}43:Sfinal=getNondominatedDrivingStrategies(Sfinal)44:return SfinalThe upper-level algorithm UL-MODS2 was obtained from the UL-MODS1 presented in Section 3.1.2 by including two additional values into the existing chromosome, i.e., the minimum weight, ωmin, and the maximum weight, ωmax. In this case, the crossover operator remains the same, while the mutation of these values is performed by assigning them randomly selected values from Ω, taking into account the constraint ωmin≤ωmax.The time complexity of the MODS algorithm is the complexity of the lower-level algorithm combined with the complexity of the upper-level algorithm. Regarding MODS1, the time complexity of the lower-level algorithm LL-MODS1 is calculated as follows. Route of length s is divided into route steps of length ΔsV, therefore s/ΔsV simulation steps are performed to simulate the entire route. At each route step, all the Spop driving strategies are used to simulate one route step. More precisely, each driving strategy is cloned for each possible control action, where the number of control actions is |Dɛ,finest|·|Dg|. Afterwards, NP,max route steps are predicted for each driving strategy. Finally, nondominated sorting procedure is applied to reduce the number of driving strategies. Its time complexity isO(numberOfObjectives·populationSize2)=2Spop2. Therefore, the time complexity of LL-MODS1 is:OLL-MODS1=OsΔsVSpop·|Dɛ,finest|·|Dg|·(NP,max+2Spop2).The upper-level algorithm UL-MODS1 selects two solutions Spop/2-times in each generation Ngen, performs crossover and mutation (O(|D|)), and evaluates the new solutions with the lower-level algorithm (OLL-MODS1). Therefore, the time complexity of MODS1 is:OMODS1=ONgenSpop2(|D|+OLL-MODS1).The time complexity of the MODS2 algorithm is as follows: the time complexity of LL-MODS2 is similar to the complexity of LL-MODS1. The differences are the following: (1) each driving strategy is cloned for each possible weight instead of control action (number of weights is |Ω|), (2) when predicting NP,max route steps for each driving strategy, all possible control actions are tested (total number of steps is |Dɛ,finest|·|Dg|·NP,max). Therefore, the time complexity of LL-MODS2 is:OLL-MODS2=OsΔsVSpop·|Ω|·(|Dɛ,finest|·|Dg|·NP,max+2Spop2).The time complexity of MODS2 is almost the same as the time complexity of MODS1. The only difference is OLL-MODS2 in the expression instead of OLL-MODS1:OMODS2=ONgenSpop(|D|+OLL-MODS2).In practice, the following values are constant: ΔsV, Spop, |Dɛ,finest|, |Dg|, NP,max, Ngen, |D|, and |Ω|. Consequently, the time complexity of both MODS1 and MODS2 is O(s), i.e., proportional to the route length.The space complexity of both MODS1 and MODS2 algorithms depends on the data stored in driving strategies. A driving strategy is a set of six-dimensional hypercubes that store either control actions ({ɛV, gV}) in case of MODS1, or weights (ω) in case of MODS2. The number of hypercubes of a driving strategy is |Dv,finest|3·|Dα,finest|2·|Ds,finest|. The lower-level algorithm stores Spop driving strategies. In addition, the upper-level algorithm stores Spop upper-level solutions, each consisting of |D| input-parameter values and Spop driving strategies from the lower-level algorithm. Therefore, the space complexity of MODS isO(Spop(|D|+Spop·|Dv,finest|3·|Dα,finest|2·|Ds,finest|)).Since, in practice, Spop, |D|, |Dv,finest|, |Dα,finest|, and |Ds,finest| are constant, the space complexity of MODS is O(1), i.e., constant.When simulating the vehicle driving along a route, preferred control actions or weights are stored only in those hypercubes of a driving strategy that correspond to the vehicle and route state during the simulation. For example, if a hypercube does not correspond to a segment of the route, it will not get assigned a control action or weight, but will remain empty. Since the number of simulated steps is s/ΔsV, only up to s/ΔsV hypercubes will get assigned a control action or weight. Since, in practice, ΔsV is constant, the actual space complexity of the MODS algorithm is O(s), i.e., proportional to the route length.

@&#CONCLUSIONS@&#
We have designed and tested a Multiobjective Optimization algorithm for discovering Driving Strategies (MODS) that minimizes the traveling time and the fuel consumption along a given route. MODS is a two-level algorithm, the upper-level being a single-objective evolutionary algorithm searching for the best input parameters for the lower-level multiobjective algorithm that finds the best nondominated driving strategies using given inputs. Such set of strategies enables the user that frequently travels on the same route to each time select a driving strategy with appropriate trade-off between the traveling time and the fuel consumption, depending on the current requirements. In addition, nondominated driving strategies can be deployed in adaptive cruise control of future intelligent vehicles as suggested by Van Willigen et al. [20]. In this case, a user can enter his/her preferences in terms of traveling time and fuel consumption into the vehicle's cruise control at real time. Setting preferences corresponds to real-time selection of the driving strategy with the preferred values of the objectives.We designed and tested the initial version of MODS, MODS1, and the enhanced version, MODS2. Both algorithms were compared with two traditional algorithms, i.e., the predictive control (PC) and the dynamic programming (DP). Tests on data from real-world routes using a simulator showed that MODS2 performed significantly better than the other algorithms. This is no great surprise, since it is in general the case that multiobjective algorithms exhibit advantages over single-objective algorithms. An additional analysis of the obtained driving strategies showed that PC and DP tend to produce driving strategies with a more constant vehicle velocity, while MODS1 and MODS2 tend to produce driving strategies with a more volatile vehicle velocity. Moreover, the driving strategies that produce a more volatile vehicle velocity were better than the driving strategies that produce a more constant vehicle velocity. Finally, the results confirm that MODS2 can be applied also in online simulation when segments of up to 150 meters are considered at each simulation step.In our future work we will test MODS on additional routes. One possibility for testing the influence of the driving simulator on the quality of driving strategies is to include speed control in the vehicle simulator and compare the obtained results with the current results. It would be interesting to compare driving strategies, obtained with MODS, with human driving strategies. To that end, volunteers will be invited to demonstrate their strategies on the simulator. A particular challenge would also be to postprocess the optimized driving strategies and present them to a user in a compact and comprehensible form.