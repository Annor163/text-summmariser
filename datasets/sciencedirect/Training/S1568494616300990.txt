@&#MAIN-TITLE@&#
Solving minimum constraint removal (MCR) problem using a social-force-model-based ant colony algorithm

@&#HIGHLIGHTS@&#
In the present study, an ant colony algorithm was used to solve a discrete MCR problem. During the solving process, the social force model was used to improve the ant colony algorithm, such that it would not easily fall into local extreme and became suitable for solving the MCR problem. The results of the simulation experiments revealed that our algorithm was superior to the exact algorithm and greedy algorithm in terms of solution quality and running time.

@&#KEYPHRASES@&#
Ant colony algorithm,Discrete MCR,Motion planning problem,Robot path planning,Social force model,

@&#ABSTRACT@&#
The minimum constraint removal (MCR) motion planning problem aims to remove the minimum geometric constraints necessary for removing a free path that connects the starting point and the target point. In essence, discrete MCR problems are non-deterministic polynomial-time (NP)-hard problems; there is a “combinatorial explosion” phenomenon in solving such problems on a large scale. Therefore, we are searching for highly efficient approximate solutions. In the present study, an ant colony algorithm was used to solve these problems. The ant colony algorithm was improved based on the social force model during the solving process, such that it was no longer easy for the algorithm to fall into local extreme, and the algorithm was therefore suitable for solving the MCR problem. The results of the simulation experiments demonstrated that the algorithm used in the present study was superior to the exact algorithm and the greedy algorithm in terms of solution quality and running time.

@&#INTRODUCTION@&#
ATH planning is an important part of robot research and is also an important joint point of robotics and artificial intelligence (AI). The primary objective of path planning is to search for a free path from the initial state (including the location and posture) to the target state (including the location and posture) in an environment where there are some obstacles by a certain analysis standard; the robot will avoid all the obstacles safely and collision-free during its movement process on this path, which is also the shortest [1].Determining a collision-free free path between two points is one of the most fundamental problems in robot technology. For most robot path-planning problems, the objectives are to search for an obstacle-free path from the initial state to the target state. The obstacles that a robot encounters may be inconvenient but are not insurmountable in most actual situations. For instance, an obstacle in indoor navigation may be a closed gate, which the robot is able to open. The obstacle in automatic outdoor navigation may be a rugged terrain, which is passable for the robot; under such circumstances, the price for overcoming the obstacle is very high, and there is risk to a certain degree; however, it is not impossible. In this situation, it is more suitable to search for a path with the least obstacles. In other words, it may be necessary to know the minimum obstacle set that obstructs the free path between two points (similar to a road under construction where the developer will remove the minimum existing obstacles in the environment to complete the road construction). When this point is considered, a new problem naturally arises: if there is no obstacle-free path from the initial state to the target state, what is the minimum number of obstacles that need to be removed on any path from the starting point to the target point? Hauser first proposed this problem in 2012 and called it the minimum constraint removal (MCR) problem because the minimum constraints (obstacles) are required to be removed to open up an obstacle-free path in the environment [2]. The objective of a MCR motion-planning problem is to remove the necessary minimum geometric constraints on a free path that connects the starting point and the target point. An MCR motion planning problem describes a problem in which a probabilistic path map motion planner solves an MCR problem in a continuous configuration space by constructing increasingly accurate path maps and efficiently solves the discrete MCR problem on these maps [3]. Using the method that reduced the minimum set cover, Hauser proved that discrete MCR problems were non-deterministic polynomial-time (NP)-hard problems [2]. In addition, at the 2013 Association for the Advancement of Artificial Intelligence conference (AAAI-13), Erickson and LaValle also proved that discrete MCR problems were NP-hard problems [4]; the result was quite intriguing to them because the corresponding path existing problem could be easily solved through the breadth-first search of the map [5]. Gorbenko et al. considered the discrete minimum constraint removal motion planning problem that can be used for a motion planning formulation with explanations for failure, and an efficient approach was presented to solve the problem [6]. Krontiris et al. proved that searching for solutions in MCR problems is computationally expensive; this leads to approximate methods. And they investigated alternatives in this context and evaluated their performance in terms of such tradeoffs. Solutions that follow a bounded-length approach, seem to provide a good balance between minimizing constraints, computational cost and path length [7].Discrete MCR problems are NP-hard problems and also route optimization problems [8]. A simple description: searching for the shortest path, P, with the least amount of obstacles from the starting point, s, to t when n vertices are given. For any solution of a discrete MCR problem, it is necessary to compare the solution with all other feasible paths to determine whether the solution is the optimum. However, there is an exponential number of comparisons; hence, it is impossible to verify any solution within the polynomial time. In essence, MCR problems are N-hard combinational optimization hard problems. The perfect method for solving MCR problems is a global search. However, when n is relatively large, it is almost impossible to accurately find the optimal solution using the global search method. Therefore, researchers have started searching for a high-efficiency approximate solving method.Hauser presented a large amount of new theoretical results of discrete MCR problems in [3] and described two types of search algorithms that proved to be good in practice—greedy algorithms and exact algorithms; in addition, Hauser used these two types of algorithms to solve discrete MCR problems. The motion planner was proved to produce the optimal MCR with a probability close to one due to more time spent; in addition, effective sampling strategies were used to improve its convergence rate. Hauser also provided three application examples: generating failure reasons that could be determined, motion planning in an undetermined environment and repositioning moveable obstacles. However, we believe that after discrete MCR problems have been determined to be NP-complete problems, the focus of the study on discrete MCR problems should be shifted to the use of intelligent heuristic algorithms to solve discrete MCR problems.The black shadows in Fig. 1(a) represent obstacles, while the rest of the figure represents the free zone. The left top corner and the right bottom corner are the given starting vertex, qsand the target vertex, qg. The robot is required to search for the shortest path with the least amount of obstacles to be removed from the starting vertex, qsto the target vertex, qg. The figure shows that there are at least two obstacles (O3 and O5) on the path connecting the starting point and the target point that need to be removed. The aforementioned problem is described in a map. One point in each zone is selected as the vertex. If the vertex is in the free zone, it is not marked. If the vertex is in the obstacle zone, the vertex is marked with the number of the obstacle. For instance, if the vertex is marked with 1, the vertex is covered by obstacle 1; if the vertex is marked with 1, 3 and 5, the vertex is in a zone covered by obstacles 1, 3 and 5. Fig. 1(b) shows the full description. The initial vertex is s, and the target vertex is t; a partition of the continuous space generates a discrete MCR problem on the map. Every node is marked as the subset of the obstacles that “cover” the node. MCR is the minimum obstacle subset that covers all the nodes on the path from the starting point, s, to the target point, t.The mathematical definition of the MCR problem is as follows [3]:Continuous MCRInput. d-dimensional configuration space C⊆Rd; n obstacle zones O1, …, On⊆C; these zones are all open sets, and the extreme points are qs, qg∈C.Definition 1The definition of the cover function C(q):C→2{1,…,n} is the obstacle set that violates the configuration q:C(q)={i|q∈Oi}. For a subset of the same configuration space A⊆C, the definition of its corresponding cover function, C(A), is all the vertices, q, of the alliance cover of C(q) (q∈A), or C(A)={i|A∩Oi≠ϕ}.For one subset S⊆{1, …, n}, we define that S− can reach q′ starting from q. If there is a continuous path y(s):[0, 1]→C, the path starts from q and ends at q′, and it also satisfies C(y(s))⊆S, s∈[0, 1].Output. MCR S* is the shortest path between qsand qg.Correspondingly, MCR is a minimum set (not necessarily the only minimum set). Therefore, qscan be reached by S* starting from qg. However, according to the sample method, the discrete MCR is an important sub-problem, which is described as follows:Discrete MCROutput. Figure G=(V, E); cover functionC[v]; start and end vertices s, t∈V. InC[v], the subset of {1, …, n} is used to mark every vertex,v, indicating which constraints are applied tov.Output. S* is the smallest subset of {1, …, n}. In addition, there is a path, P, from s to t in Figure G, and for all the vertices,v∈P,C[v]⊆S*The above definitions directly expand similar concepts of continuous MCR to discrete MCR. What interests the researchers is to find a solution for the number of MCR. This new type of MCR problem is significantly different from the previous motion-planning problems—it exhibits the curse of dimensionality and the complexity of combinations in a continuous space. It is necessary to enumerate the subsets of the constraint set (the number of subsets ranges from several hundred to several thousand) to find the optimal solution. Therefore, we are searching for a highly efficient approximate solution.There are two types of MCR problems—continuous MCR problems and discrete MCR problems [3]. Discrete MCR problems have been proved to be NP-hard problems. The first type of method for solving discrete MCR problems is the accurate global search algorithm; this method can be used to effectively solve discrete MCR problems, and the solutions are relatively accurate. However, this method is not suitable for solving problems on a large scale, as there may be a “combinational explosion” phenomenon [9]. The second type of method is based on AI algorithms, such as finding the solution using greedy algorithms. The advantages of greedy algorithms are that they are easy to design and can often find good approximate solutions. For most problems, greedy algorithms make a decision prematurely; therefore, these algorithms cannot find the optimal solution. Generally, optimal solutions cannot be found using greedy algorithms because not all the feasible solutions are tested. For instance, for all the greedy algorithms for NP-complete problems, optimal solutions are not ensured [10,11]. After discrete MCR problems have been determined to be NP-complete problems, we believe that the focus of the study on discrete MCR problems should be shifted to use intelligent heuristic algorithms to solve discrete MCR problems.An ant colony algorithm is a type of swarm intelligence algorithm, which has been widely used in recent years [12–14]. Reshamwala et al. described the various techniques for the robot path planning using the Ant colony Algorithm. And also provided the brief comparison of the three techniques described in the paper [15]. Yao et al. proposed a heterogeneous feature ant colony optimization (HFACO) algorithm to solve the robot path planning problem, the experiment results show that HFACO can find a better path in a shorter period of time compared to the classical ACO algorithms [16]. But when the swarm scale is relatively large, premature and stagnation phenomena tend to occur in ant colony algorithms, which prevent their further applications, To improve the algorithm for solving discrete MCR problems in terms of efficiency and reliability, the ant colony algorithm (station ant colony optimization (SACO) was improved based on the social force model during the solving process in the present study, such that the algorithm would not easily fall into local extreme, and became suitable for solving discrete MCR problems.In 2000, Helbing et al. proposed a social-force model based on Newtonian dynamics; the expression of each force was used to describe different motives and effects of an individual [17,18].Individual actual behavior and subjective consciousness as well as the effect among individuals and obstacles can all be equivalent to the action of a force on the individual, i.e., the driving force, the interaction between individuals and the interaction between the individual and the obstacle. The resultant force of all of these forces is exerted on the individual, and an acceleration is generated. In the present study, we referred to the aforementioned model and used it in the ant colony algorithm. A detailed description is as follows:Definition 3The driving force reflects the motive of an ant individual that moves to the destination at a desired speed, denoted asfi0; the calculation formula forfi0is(1)fi0(t)=mivi0(t)ei0(t)−vi(t)τi,where τirepresents the adaptation time for ant individual i; mirepresents the mass of ant individual i;ei0(t)represents the desired moving direction; andvi0(t)andvi(t)represent the desired speed and the actual speed of ant individual i at time t, respectively.The interaction between ant individuals j and i, also known as the repulsive force, denoted as fij(t) is(2)fij(t)=w(θij)fijs(t)(3)fijs(t)=Aexp[ri+rj−dijBnij,where riand rjrepresent the radii of ants i and j, respectively; dij=||ri−rj|| represents the distance between ant individuals i and j;nij=(nij1,nij2)=(ri−rj)/dijrepresents the standardized unit vector of ant individual j that points to i; A and B represent the parameters of the social force model; A determines the intensity of the repulsive force, while B determines the variation speed of the repulsive force with respect to distance; θijrepresents the angle between the movement direction of ant individual i,vi(t)and nij; andw(θij)represents the correction factor of the repulsive force between ant individuals.The interaction between an ant individual and an obstacle is similar to that between ant individuals; the calculation formula is as follows:(4)fiw=Aexpri−diwBniw+kgri−diwniw−kgri−diwvi.tiwtiw,whereniw=niw1,niw2represents the unit vector of the obstacle that points to ant i, andtiw=−niw2,niw1;diwrepresents the distance between the ant individual and the obstacle; and kg represents the amplitude of the repulsive force of the obstacle for ant i and is a control parameter of the social force model.The accelerationΔvmi(t)is generated at time t:(5)Δvmi(t)=mivi0(t)ei0(t)−vi(t)/τi+∑j(≠i)fij(t)+∑WfiW(t)min is set as the number of vertices; m is set as the number of ants; τij(t) represents the residual information on path (i, j) at time t; tabukrecords the set of the vertices that ant k has traversed;Pijk(t)represents the transition probability for ant k from vertex i to vertex j at time t.(6)pijk(t)=[τij(t)]α⋅[ηij(t)]β∑s∈allowedk[τis]α⋅[ηij]β,ifj∈allowedjpijk(t)=0,otherwisehere allowedkrepresents the vertices that the ant is allowed to select at the next step; α represents the information heuristic factor; β represents the desired heuristic factor; and ηij(t) represents the heuristic function, and its calculation formula is defined as follows:(7)ηij(t)=1Cij,where Cijrepresents the number of obstacles between vertices i and j; ηij(t) represents the relative value of the obstacles that the ant encounters from vertices i to j. For ant k, a smaller value of Cijindicates a larger value of ηij(t) and a larger value ofPijk(t); therefore, paths with a small number of obstacles are favorable. Clearly, the heuristic function represents the desired degree of a small number of obstacles for the ant that moves from vertex i to j.The pheromone-updating strategy is a key step in ant colony algorithms. If pheromones are updated too fast, the algorithm will fall into a local optimum and even stagnation. If pheromones are updated too slowly, the convergence rate will be too slow to search for the optimal path. In the present study, a global and local pheromones combined method was used. The formula for global pheromone updating is as follows: after the ant has traversed all the vertices, the information content is updated; the pheromone on path (i, j) at time t+n is adjusted according to the following formulas:(8)τij(t+n)=(1−ρ)τij(t)+Δτij(t)(9)Δτij(t)=∑k=1mΔτijk(t)(10)Δτijk(t)=QLkiftheantkuseedge(i,j)0otherwise,where Q represents the pheromone intensity; Lkrepresents the path length of one cycle that the kth ant completes; ρ represents the pheromone volatile coefficient;Δτijkrepresents the concentration of pheromones that the kth ant left on path (i, j) during this cycle, which is calculated using formula (10); and Δτijrepresents the sum of the concentrations of pheromones that all the ants released on path (i, j) during this cycle.In addition, after the ant finds a sub-feasible solution, the pheromones on the path (i, j) of the sub-feasible solution are also updated locally:(11)τij=(1−λ)τij+λτ0,λ∈(0,1),where λ represents the pheromone volatile coefficient, τ0 is a constant, andτ0=1/nOmin5,Omin5represents the mean value of the 5 most recent optimal objectives.In the present study, the individuals in the ant colony were first classified into free individuals and non-free individuals using probability. The calculation formula for the probability of an ant becoming a free individual is(12)ρα=Rdα23.6,where Rdαrepresents the relative distance between ant α and the target. When the random number, rand≤ρα, ant α becomes a free individual; otherwise, ant α becomes a non-free individual.To prevent the algorithm from falling into a local optimum, the probability selection mechanism was used for free individuals. Ant i(i=1, 2, …, m) selects the next vertex according to the transition probability (determined by information content). For non-free individuals, ant i selects the next vertex according to the transition probability (determined by information content) and the acceleration; the ant's next vertex is calculated using the following formula:(13)probij(t)=Pijk(t)+εΔvmi(t),where ε is a coefficient, ε∈(0, 1).The steps of the algorithm are as follows:Step 1:The parameters of the algorithm are set: ant colony size, m; ant's adaptation time, τ; maximum iteration number, tmax; social force model parameters, A, B and kg. In addition, pheromones are initiated. The ant is placed at the initial vertex s.Population initialization. The population is classified according to (12); the free individual population and non-free population are formed.For ants that belong to the free individual population, their Cijand transition probability,Pijk(t), are calculated. Each ant selects the next path vertex according to formula (6); if the pheromones on the path from this vertex to its adjacent vertex are all 0, the ant returns to the last vertex.For ants that belong to the non-free individual population, their Cijand transition probability,Pijk(t), are calculated. In addition, the social driving force and the acceleration of each ant are calculated. Each ant selects the next path vertex according to formula (13). If the pheromones on the path from this vertex to its adjacent vertex are all 0, the ant returns to the last vertex.The optimal solution of the objective function of this cycle is calculated. The pheromones on the path of the optimal solution of this cycle are updated globally according to formula (8). In addition, the pheromones on the path of the optimal solution of this cycle are updated locally according to formula (11). The optimal solutions of all the cycles are recorded.If all the ants converge to a path that reaches the target vertex t, or the maximum iteration number, the cycle is terminated; otherwise, return to Step 3.Output the solution.Fig. 2shows flow chart for the proposed algorithm.To verify the effect of the improved algorithm, many simulation experiments were performed in the present study. Under different types of experimental environments, the exact algorithm, the greedy algorithm and the SACO algorithm used in the present study were used to find solutions. The parameter settings for the simulation experiment for the SACO algorithm are as follows: number of ants, m=30; maximum iteration number, tmax=50; weights of pheromone and obstruction information, α=1 and β=2; constant, C=100; ants’ adaptation time, τ=0.1; social force model parameters, A=2×103, B=0.08 and kg=2.4×105kgm−1s−1. An example of data format used in the experiments is shown below:Beginparam start:= 1;//starting pointparam goal:= 4;//target pointset V:= 1 2 3 4;//vertexset E:= (1,2) (2,1) (1,3) (3,1) (2,3) (3,2) (2,4) (4,2) (3,4) (4,3);//edgeset S:= A B C D E F G;//obstacleset SV:= (1,A) (1,B) (1,E) (2,B) (2,E) (2,G) (4,B) (3,C) (3,A) (3,G);//indicating that the obstacle covers some vertexEndPython language was used to write the experimental data generation program, grid_data.py, which was then used to generate the date files necessary for the experiments. In addition, 3 experiments were compared.

@&#CONCLUSIONS@&#
