@&#MAIN-TITLE@&#
Two metaheuristic approaches for the multiple traveling salesperson problem

@&#HIGHLIGHTS@&#
Two metaheuristic approaches are proposed.First approach is based on artificial bee colony algorithm.Second approach is based on invasive weed optimization algorithm.Our approaches are compared with previous approaches on two different objectives.Our approaches outperformed all the previous approaches on both the objectives.

@&#KEYPHRASES@&#
Artificial bee colony algorithm,Constrained optimization,Invasive weed optimization algorithm,Multiple traveling salesperson problem,Swarm intelligence,

@&#ABSTRACT@&#
The multiple traveling salesperson problem (MTSP) is similar to famous traveling salesperson problem (TSP) except for the fact that there are more than one salesperson to visit the cities though each city must be visited exactly once by only one salesperson. For this problem, we have considered two different objectives. First one is to minimize the total distance traveled by all the salespersons, whereas the second one is to minimize the maximum distance traveled by anyone salesperson. This latter objective is about fairness as it tries to balance the workload among salespersons. MTSP, being a generalization of TSP under both the objectives, is alsoNP-Hard. In this paper, we have proposed two metaheuristic approaches for the MTSP. The first approach is based on artificial bee colony algorithm, whereas the second approach is based on invasive weed optimization algorithm. We have also applied a local search to further improve the solution obtained through our approaches. Computational results on a wide range of benchmark instances show the superiority of our proposed approaches over all the other state-of-the-art approaches for this problem on both the objectives.

@&#INTRODUCTION@&#
The multiple traveling salesperson problem (MTSP) is an extension of famous traveling salesperson problem (TSP), where more than one salesperson are present to visit the cities though each city must be visited exactly once by only one salesperson. Given a set of n cities to be visited by a salesperson, the TSP seeks the shortest possible tour for the salesperson that visits each city exactly once and return to the starting city. However, in case of MTSP, there are m salespersons instead of one to visit n>m cities and we have to find the tours for all m salespersons. The starting and ending cities are called depots, and the remaining cities are called intermediate cities. There are several versions of MTSP depending on the number of depots.•Single depot case, all the m salespersons have to start and end at a given single depot.m depots case, every salesperson have to start and end at their own depot.2m depots case, every salesperson have to start and end at their own 2 depots, i.e., starting and ending depot are different for every salesperson.>1 and <2m depots case, it is hybridization of above specified cases.Like several previous works on MTSP, in this paper, we have considered the single depot case, i.e., all salespersons have to start and end their tour in the same city called depot, and followed the principle that every salesperson must have to visit at least one city in addition to the depot, i.e., every tour has a non-zero tour length. We have considered two objectives for the MTSP problem. The first objective is to minimize the total distance traveled by all the salespersons, i.e., minimizing the sumtotal of the tour lengths of all the salespersons. The second objective is to minimize the maximum distance traveled by anyone salesperson. The main idea behind this objective is to balance the workload among all salespersons. Throughout this paper, we will refer to the first objective as objective1, and, to the second objective as objective2. Both these objectives of the MTSP areNP-Hard as for m=1, they reduce to the TSP which isNP-Hard [1]. The MTSP is more difficult than the TSP because first we have to find which cities to assign to each salesperson, and then the optimal ordering among the cities assigned to each salesperson.Compared to TSP, a wider range of real world problems specially those pertaining to scheduling and routing reduce to MTSP, e.g. print press scheduling [2], pre-print advertisement scheduling [3], bank crew scheduling [4], workload balancing [5], school bus routing [6], and designing satellite surveying systems [7]. Despite of this fact, only few approaches exist in literature to solve MTSP. Tang et al. [8] proposed a genetic algorithm (GA) with one-chromosome representation for MTSP problem and solved the hot rolling production scheduling problem using it. Malmborg [9] and Park [10] used a two-chromosome representation in their genetic algorithm based approaches for the vehicle scheduling problem (VSP). This representation can be adapted for MTSP also. Carter and Ragsdale [11] proposed a genetic algorithm using a new two-part chromosome representation and related genetic operators. Brown et al. [12] proposed a grouping genetic algorithm to solve MTSP by deriving chromosome representation and genetic operators from the grouping genetic algorithm proposed in [13]. Actually, MTSP is a grouping problem, i.e., a problem which seeks an optimal assignment of entities (cities in case of MTSP) according to a given objective function into different groups (tours in case of MTSP) subject to some constraints. Grouping genetic algorithms [13] are tailor-made for solving grouping problems. Both Carter and Ragsdale [11] and Brown et al. [12] have shown the superiority of their proposed approaches by comparing the results of their respective approaches with those of the two genetic algorithms that use one-chromosome and two-chromosome representations. Singh and Baghel [14] proposed another grouping genetic algorithm using a different chromosome representation and different crossover & mutation operators. This genetic algorithm used steady-state population replacement method instead of the commonly used generational model. This genetic algorithm outperformed all the previous approaches on both the objectives on the benchmark instances considered in [11,12]. Liu et al. [15] presented an ant-colony optimization (ACO) algorithm for solving the MTSP. This ACO uses a combination of pheromone values and information regarding the distance among cities to construct tours. It also employs a local search that uses both inter-tour and intra-tour operators. Inter-tour operators modify more than one tour simultaneously in a bid to improve the solution, whereas inter-tour operators works on a single tour at a time. Computational results had shown this ACO algorithm to be competitive with other approaches on both the objectives. Recently, Yuan et al. [16] proposed a new crossover operator called two-part chromosome crossover (TCX) for solving the MTSP using a genetic algorithm and showed its superiority over the genetic algorithm of Carter and Ragsdale [11] only. They have also reported the results of their proposed approach on some new instances. Though, they have not compared their approach with those in [14,15], their results are inferior to these approaches. Bektas [17] provides an excellent survey on exact and heuristic solution approaches to the MTSP and its variations, and their real world applications.A lot of swarm intelligence based approaches have been proposed in the literature to solve TSP (e.g. [18–25]). However, very few swarm intelligence based approaches exist in the literature for MTSP. To our knowledge, the ACO approach of Liu et al. [15] described in the previous paragraph is the only swarm intelligence based approach for the MTSP. In addition, Ghafurian and Javadian [26] presented another ACO approach for solving a variation of MTSP where they have considered the multi-depot case and imposed lower and upper bounds on the number of cities that a salesperson can visit and the objective was to minimize the total distance traveled by all the salespersons. Both these approaches are based on ACO only. Absence of any other swarm intelligence based approach for the MTSP and the success of ACO approach of Liu et al. [15] in solving the MTSP (as mentioned already, results obtained through this approach are comparable with those obtained with any other state-of-the art approach on both the objectives) has motivated us to develop new swarm intelligence based approaches for the MTSP.In this paper, we have proposed two new swarm intelligence based metaheuristic approaches for the MTSP. Our first approach is based on artificial bee colony (ABC) algorithm, whereas the second approach is based on invasive weed optimization (IWO) algorithm. In fact, two slightly different versions of ABC algorithm have been presented in this paper. In the first version, neighboring solutions are generated more or less at the same distance from the original solution throughout the execution of ABC algorithm, whereas in the second version, the expected distance of the neighboring solution from the original solution is gradually reduced from a pre-defined initial value to a pre-defined final value over the iterations of the algorithm. Our ABC and IWO approaches are designed keeping in mind the grouping nature of the MTSP. The solutions obtained through these approaches are improved further through a local search. The performance of the proposed approaches is compared with the state-of-the-art approaches on both the objectives. Computational results clearly show the superiority of all our proposed approaches over existing approaches.The rest of this paper is organized as follows: Section 2 provides an introduction to the artificial bee colony algorithm. Section 3 describes our ABC approach to the MTSP problem. Section 4 provides an introduction to the invasive weed optimization algorithm, whereas Section 5 describes our IWO approach to the MTSP problem. Computational results are presented in Section 6. Finally, Section 7 provides some conclusions and directions for future research.The artificial bee colony (ABC) algorithm is a recent metaheuristic technique developed by Karaboga [27] on getting inspiration from the intelligent foraging behavior of natural honey bee swarm. Entomologists classify the foraging bees into scout, employed and onlooker bees depending on the function they are performing currently. Scout bees look for new food sources in the vicinity of the hive. As soon as a scout bee finds a food source, this scout bee is reclassified as employed bee. Employed bees are responsible for collecting the nectar from food sources and bringing it to hive and sharing information about their food sources with the onlooker bees. Onlooker bees wait in the hive for employed bees to share information about their food sources. To share the information with onlooker bees, the employed bees perform dances in a common area in the hive, which is called dancing area. Through dance, an employed bee convey vital information regarding its food source such as the direction in which it is located, distance from hive, and nectar amount of food source. Onlooker bees watch numerous dances before selecting a food source. The probability with which an onlooker bee selects a food source, is proportional to nectar amount of that food source. If the nectar amount of a food source is good, more onlooker bees will choose that food source. After performing the dance in the dance area the employed bee goes back to its food source along with all those onlooker bees which chose this food source Once an onlooker starts exploiting a food source, it is reclassified as an employed bees. When a food source is completely exhausted, all the employed bees associated with it leave it, and become scouts or onlookers. Hence, the scout bees do the job of exploration, whereas the employed and onlookers bees do the job of exploitation.Motivated by this intelligent foraging behavior of honey bees, Karaboga [27] proposed the ABC algorithm in 2005. ABC algorithm was extended further by [28–40] etc. In the ABC algorithm, each food source represents a candidate solution to the problem under consideration, and, the nectar amount of a food source represents the fitness of the solution represented by that food source. Like real bees, in this algorithm also, artificial bees are classified into same three groups, viz. scout, employed, and onlooker bees with similar functions. The ABC algorithm assumes that there is only one employed bee for every food source, i.e., the number of employed bees is same as the number of food sources. Usually, the number of onlooker bees are also taken to be equal to the number of employed bees. The employed bee of an exhausted food source becomes a scout, and, as soon as it finds a new food source, it again becomes employed. The action of a scout bee is mimicked by generating a new food source (solution) randomly and associating the scout bee in consideration with this newly generated food source to make it employed again. We will use food source and solution interchangeably throughout the description of ABC algorithm.The ABC algorithm is an iterative algorithm. It starts by associating all employed bees with randomly generated food sources (solution). Then during each iteration every employed bee determines a food source in the neighborhood of its currently associated food source and evaluates its nectar amount (fitness). If its nectar amount is better than that of its currently associated food source then that employed bee moves to this new food source leaving the old one, otherwise it continues with its old food source. When all employed bees finished this process, they share the nectar information of their food sources with onlookers, each of whom selects a food source using some probabilistic selection criterion. Usually, the selection criterion prefers good food sources over bad ones so that more onlooker bees will be assigned to good food sources which in turn result in more exploitation in the vicinity of these food sources.After all onlookers have selected their food sources, each of them determines a food source in the neighborhood of their associated food sources and calculates its fitness. The best food source among all the neighboring food sources determined by the onlookers associated with a particular food source ‘i’ and food source i itself, will be the new location of the food source i. If a solution corresponding to a particular food source does not improve even after specified number of trials, then that food source is assumed to be exhausted and its associated employed bee abandons it and become a scout. This scout is again made employed by associating it with a new food source which is usually generated randomly. Once the new location of each food source is determined, another iteration of ABC algorithm begins. The whole process is repeated until termination condition is satisfied. The exact procedure for determining a new food source in the neighborhood of a particular food source for employed and onlooker bees depends on the problem under consideration.In essence, the ABC algorithm is based on the fact that the neighborhood of good solutions has higher probability of containing even better solutions in comparison to the neighborhood of poor solutions. That is why more onlookers are selected for good solutions so that their neighborhood can be explored more thoroughly. However, if a solution is locally optimal with respect to the whole neighborhood then any attempt to improve it is bound to fail. This is where the concept of scout bees is helpful. Instead of determining whether a solution is locally optimal or not, which is a computationally expensive process as it involves exploring the whole neighborhood, the ABC algorithm assumes that if a solution does not improve over certain number of trials say ‘limitnoimp’, then it is deemed to be locally optimal, and a randomly generated solution replaces this solution.Karaboga et al. [41] provides an excellent survey on ABC algorithm and its applications.Our approach is a combination of an ABC algorithm and a local search heuristic. The best solution obtained through the ABC algorithm is improved further by using the local search.The main features of our ABC algorithm for the MTSP are as follows.We have used encoding of [14] to represent a solution for MTSP. This encoding represents a solution as a set of m tours, i.e., there is no ordering among the tours.Our fitness function is same as the objective function. As we are considering two different objectives for the MTSP, viz. minimizing total distance traveled by all the salespersons and minimizing the maximum distance traveled by anyone salesperson, therefore, we have two different fitness functions. In either case, fitness function value needs to be minimized.Each initial employed bee solution is generated according to the following procedure where m is the number of salespersons and n is the number of cities.1.The procedure begins by selecting m different cities randomly from among cities other than depot, and assigns each of these cities to one of m salespersons randomly. Remaining cities will be treated as unassigned cities which are assigned to the tours one-by-one in an iterative manner by subsequent steps.Select an unassigned city uniformly at random and insert it into one of the salesperson's tour. The city will be assigned to a tour according to one of the two methods. The first method for objective1 is to assign the city to the particular salesperson's tour whose cost increases least by this insertion. To determine this it has to check all possible insertion positions in every salesperson tour. The first method for objective2 is to assign the city to the particular salesperson tour whose cost increases least by this insertion only when it's not a longest salesperson tour. A city will be assigned to the longest salesperson tour only when its cost increases least and assigning that city to any other tour make that tour the longest tour. The second method is same for both objectives, i.e., it selects a salesperson tour at random and inserts the selected city into selected salesperson tour at a position where insertion results in least increase in tour length. The first method is used with probability Pmethod, otherwise the second method is used.Repeat step 2 until all cities are assigned.Step 1 ensures that in the generated solutions, every salesperson visits at least one more city in addition to the depot, i.e., every tour has a non-zero tour length.We have used binary tournament selection method for selecting a food source for an onlooker. In this binary tournament selection method, first two food sources (employed bee solutions) are chosen randomly and better of the two food sources is selected with probability Ponlookand worse of the two with probability (1−Ponlook). We have tried roulette wheel selection also, but it is not giving better results as the fitness values of food sources are large and nearer to each other. The pseudo code of binary tournament selection is given in Algorithm 1.Algorithm 1Pseudo code of binary tournament selectionIn order to generate a solution in the neighborhood of a solution S, we copy each tour of S one-by-one to the neighboring solution. However, each city from a tour of S is copied to the corresponding tour of the neighboring solution with probability Pcopyonly, otherwise the city is included in the list of unassigned cities. All these unassigned cities will be inserted into the neighboring solution by following the same procedure as used in the Section 3.3. Initially, we generated neighboring solutions by keeping probability Pcopyfixed throughout the ABC algorithm. Later, we observed that the solutions should not be perturbed by large amounts to generate a neighboring solution at the latter iterations as the solutions are close to optimal, so we have proposed variable probability method inspired by spatial distribution concept in IWO (see next section), i.e., generating neighboring solutions by varying Pcopyaccording to the number of iteration. The Pcopyvaries from a pre-defined initial value, Pmincopy, to a pre-defined final value, Pmaxcopy. The value of Pcopyin an iteration iter is determined using the following formula:Pcopy:=Pmaxcopy−Pmincopyitermax(iter)+Pmincopywhere itermaxis maximum number of iterations allowed. The version of ABC algorithm with fixed value of Pcopythroughout will be referred to as ABC(FC), whereas the version with variable Pcopywill be referred to as ABC(VC). A solution associated with an employed bee will be replaced by its neighboring solution only when its fitness is worst than the neighboring solution. Otherwise the employed bee will continue with the existing solution. The pseudo code of generating neighboring solution is given in Algorithm 2.Algorithm 2Method for generating neighboring solutionWe have used different number of employed bees and onlooker bees. For objective1, if an employed bee solution is not improved even after a predetermined number of attempts limitnoimp, then employed bee associated with that food source can abandon it and become a scout. However, there is a upper limit of one on the number of scout bees in an iteration, i.e., in an iteration there may not be even a single scout bee, whereas in another iteration there may be one scout bee. In our approach, the number of scout bees in an iteration is equal to one if any employed bee's associated food source has not been improved over last limitnoimptrials, otherwise it is equal to zero. The employed bee associated with the food source that has not been improved for highest number of trials among all the food sources, and, if that highest number of trials is greater than limitnoimpthen that employed bee becomes a scout bee.A scout bee is again turned into an employed bee by generating a solution randomly and associating it with the scout bee under consideration. The solution for a scout is generated in the same manner as an initial solution.The best solution obtained through ABC algorithm is further improved by applying a local search. As part of the local search, we have applied 2-opt move repeatedly on all the tours of the best solution one-by-one for both the objectives. The 2-opt algorithm that we have used basically considers each pair of two edges in the tour one-by-one and deletes this edge pair from the tour and reconnects the two resulting paths through edges other than the deleted ones. There is only one way to reconnect the two paths so that we can still have a valid tour. If the cost of the newly reconnected tour is less than the original tour then newly reconnected tour is retained, otherwise original tour is restored. After this next pair of edges is considered. We have applied 2-opt move repeatedly on a tour till there is no improvement in the solution quality.After the 2-opt local search, we have applied another heuristic for objective2. This heuristic consists of removing a random city from the longest salesperson tour and assigning it to a randomly selected salesperson's tour at the best possible position provided this action leads to a reduction in the length of the longest tour. In order to find the best possible position in the selected tour, we have to check all possible insertion positions in the tour. This process is repeated for some limited number of times. We have also tried a modified version of this heuristic for objective1 where we remove a random city from a randomly selected salesperson's tour and try to assign it to another randomly selected salesperson's tour at the best possible position, but we never got an improvement in the results of any of our proposed approaches by doing so, and therefore, this strategy is not used for objective1.The pseudo code of our ABC approach is given in Algorithm 3, where neand noare, respectively, the number of employed and onlooker bees. Generate_Neighboring_Solution(S) function returns a solution in the neighborhood of the solution S as per the procedure described in Section 3.5. Select_and_Return_Index(S1,S2,…,Sne) selects a solution from solutionsS1,S2,…,Snefor an onlooker bee using binary tournament selection method (Section 3.4) and returns the index of the solution selected. The function Local_Search(best) applies the local search described in Section 3.7 on the best solution obtained through ABC algorithm in an attempt to further improve its quality.Algorithm 3Pseudo code of ABC approachInvasive weed optimization (IWO) is a new metaheuristic technique inspired by the robust process of weed colonization and distribution in an ecosystem. Weeds pose a serious challenge to agriculture because of their tendency to grow and reproduce in an intrusive and rapid manner, thereby adversely affecting the growth of desirable, cultivated plants. Weeds can adapt according to their environment and as a result posses great surviving ability.Since the development of first IWO algorithm by Mehrabian and Lucas [42] in 2006, several different variants of the original algorithm have been proposed, e.g. see [43–50] etc. In the IWO algorithm, each weed plant represents a possible solution to the problem under consideration and the fitness of a weed means the fitness of the solution being represented by that weed.The IWO algorithm is an iterative algorithm. It starts with randomly generated solutions (weed plants or weeds in short). Then during each iteration each weed produces certain number of seeds (child solutions) depending on its fitness. Here the number of seeds a weed can produce are mapped linearly from sminto smaxaccording to its fitness. The generated seeds are randomly distributed around the generating weed usually by normally distributed random numbers with mean equal to zero, but varying variance. This step causes a sort of randomized local search around each weed plant. Exact method of generating seed solutions varies from problem to problem and even for the same problem varies from one approach to the other. However, the standard deviation (S.D.) σ, of the random function will be reduced from a pre-defined initial value, σinitial, to a pre-defined final value, σfinal, over iterations of the algorithm. Usually, this reduction is achieved by recomputing S.D. at every iteration iter using the following expression:σiter:=itermax−iteritermaxnmi(σinitial−σfinal)+σfinalHere itermaxis maximum number of iterations, σiteris S.D. at present iteration, and nmi is nonlinear modulation index. Once a seed has been produced, it is assumed to be immediately grown into a weed. When all weeds complete the process of producing new seeds, then competitive exclusion phase starts. All the newly produced weeds will be included in the colony of weeds as long as the number of weeds in the colony is less than the maximum number of weeds allowable in the colony nmax. Once the number of weeds in the colony reaches nmax, only the fittest nmaxweeds, among the existing ones and newly produced ones, are retained in the colony. After completion of competitive exclusion phase, another iteration of IWO algorithm begins. This process repeats till the IWO algorithm terminates.While designing our IWO approach, we have borrowed several concepts from our ABC approach. Like our ABC approach, our IWO approach is a combination of an IWO algorithm and a local search heuristic. The best solution obtained through the IWO algorithm is improved further by using the local search. Solution encoding and fitness function used is also same as our ABC approach. Other salient features of our IWO algorithm for the MTSP problem are described in subsequent sections.Initial weed solutions equal to number of initial solutions (ni) are generated randomly in the same manner as described in Section 3.3.Each member of the population of weed solutions (weeds in short) generates certain number of seed solutions (seeds in short) depending on its own and the colony's lowest and highest fitness. The number of seeds each solution can produce are ranged linearly from minimum possible seed production value (smin) to a maximum possible seed production value (smax).The number of solutions present in the colony (nc) at a particular instant is divided into (smax−smin)+1 groups of more or less equal size by sorting the solutions based on fitness. Every individual group of solutions have their own number of seed solutions to generate which is ranged between sminand smaxin such a way that good solutions can produce more solutions in comparison to bad ones. The pseudo code for determining number of seeds is given in Algorithm 4.Algorithm 4Method for determining number of seedsEach weed will produce seeds equal to number determined by Algorithm 4. Each seed is produced in a manner analogous to the neighboring solution generation in ABC algorithm (Section 3.5). Here we generated neighboring solution by using variable probability.Due to generation of seed solutions, number of solutions in the colony will reach its maximum permissible value nmaxafter some iterations. When this happens, the competitive exclusion procedure starts eliminating the solutions with poor fitness. The competitive exclusion works as follows: Once the maximum number of solutions in the colony is reached, whenever an iteration completes, i.e., each solution in the colony has produced seed solutions, all the solutions including newly generated seed solutions are sorted according to their fitness. Next, solutions with lower fitness are eliminated to maintain the maximum permissible population (nmax) in a colony. In this way, solutions with better fitness survive and are allowed to reproduce.The best solution obtained through IWO algorithm is further improved by applying a local search which is same as described in Section 3.7.The pseudo code of our IWO approach is given in Algorithm 5, where ncalways represents the total number of weeds in the colony at any instance of time and niis the number of weeds present in the colony at initialization. Sort_The_Weeds(nc) is a function which sorts weeds into descending order according to their fitness. Function No_of_Seeds(Wp) returns the number of seeds a weed Wpcan produce as per the method described in Section 5.2, whereas Generate_Seed_Solution(W) function returns a seed solution around the solution W (Section 5.3). Local_Search(best) function tries to improve the best solution obtained through IWO approach using the local search described in Section 5.5.Algorithm 5Pseudo-code of IWO approachWe have implemented both ABC and IWO approaches in C and executed them on a Linux based 2.83GHz Core 2 Quad system with 4 GB RAM. In our experiment with ABC(FC) for objective1, we have used a population of 100 employed bees (ne), 150 onlooker bees (no), Pcopy=0.5, Pmethod=1, Ponlook=0.8, limitnoimp=100 and itermax=1000. For objective2 also all parameters are same except for Pmethod, which is set to 0.95, and there is no limitnoimp. In our experiment with ABC(VC) for objective1, we varied the Pcopyfrom 0 to 1, whereas for objective2 it is varied from 0.2 to 0.8. The parameters of IWO for objective1 are as follows: number of initial solutions ni=100, maximum number of solutions allowed in colony nmax=100, Pmethod=1, smax=5, smin=1, itermax=1000, and Pcopyis varied from 0 to 1. Whereas for objective2, ni=50, nmax=100, Pmethod=0.95, smax=5, smin=1, itermax=1000, and Pcopyis varied from 0.2 to 0.8. For objective 2, the heuristic in local search is applied 1000 times. All these parameter values have been chosen empirically.We have tested our approaches ABC(FC), ABC(VC), and IWO on the same test problems as used in [11,12], and [16]. Twelve test problems were used in [11] which are Euclidean, two dimensional symmetric problems. Among these 12 test problems, there are three problems with 51 cities, one for each value of m∈{3, 5, 10}, four test problems with 100 cities, one for each value of m∈{3, 5, 10, 20} and 5 test problems with 150 cities, one for each value of m∈{3, 5, 10, 20, 30}. Test problems used in [12] are taken from TSPLIB and have 51, 100 and 150 cities and same values of m for each city. So there are twelve test problems in this data set also. Eight new test problems have been used in [16]. There are three test problems, one for each value of m∈{10, 15, 30}, with 128 cities. This 128 city graph instance is taken from Stanford graph base (http://people.sc.fsu.edu/∼jburkardt/datasets/cities/cities.html). Remaining five problems are small problems whose details are given in Section 6.4. Except for test problems introduced in [16], our approaches ABC(FC), ABC(VC), and IWO have been executed on each test problem ten independent times, each time with a different random seed. For test problems introduced in [16], our approaches have been executed on each test problem thirty independent times, each time with a different random seed. This is done to allow a fair comparison with previously proposed approaches. All previously proposed approaches were executed ten independent times on each instance except those proposed in [16] which are executed thirty times on each instance.For benchmarking, we have compared our approaches with previous approaches available in the literature. The two-part chromosome representation based genetic algorithm of [11] will be referred to as GA2PC, the grouping genetic algorithm proposed in [12] will be referred to as GGA-BRC. The genetic algorithm with one chromosome representation will be referred to as GA1C and the genetic algorithm with two chromosomes representation will be referred to as GA2C. The GA1C and GA2C were used in [11,12] for comparison purpose. The steady state grouping genetic algorithm proposed by [14] will be referred to as GGA-SS. The ant colony optimization based approach proposed by [15] will be referred to as ACO. The two-part chromosome crossover operator proposed by [16] will be referred to as TCX. It is to be noted that all the references mentioned in this paragraph compares the results of various approaches in terms of average solution quality only on both the objectives on instances of [11,12], and, that is why, we have also done the comparison in terms of average solution quality only on these instances. For the instances introduced in [16], Yuan et al. reported the best as well as average solution quality along with standard deviation of solution values obtained by TCX, and therefore, on these instances, we have done the comparison in terms of these three parameters. In any case, we have reported the best solution and standard deviation of solution values for all our proposed approaches on all the instances.As all our approaches use a local search at the end to further improve the best solution, we will present two sets of detailed results for our approaches – first set of results are obtained with local search and second set of results are obtained without using the local search. This is needed to show the superiority of our approaches over previously proposed approaches even without the local search. However, except for one group of instances, all graphical comparisons with previously proposed approaches are done using the results of our approaches with local search only. This is done partly due to space considerations and partly due to the fact that there are not much difference in results obtained with and without local search on all but one group of instances.Tables 1 and 2compare the performance of ABC(FC), ABC(VC), and IWO with GA1C, GA2C, GA2PC, GGA-SS, ACO, TCX in terms of average solution quality for objective1 and objective2 both on each of the 12 test problems used in [11]. For ABC(FC), ABC(VC) and IWO, Table 1 reports the results obtained with local search, whereas Table 2 reports the results without using the local search Data for GA1C, GA2C, and GA2PC are taken from [11]. Data for GGA-SS, ACO and TCX are taken from [14–16] respectively. GGA-BRC was not executed on these instances. These tables also reports the best solution found and standard deviation (S.D.) of solution values on each instance for ABC(FC), ABC(VC), and IWO. Tables 3 and 4summarize the results by providing the number of instances out of a total of 12 where our approaches obtained better (<), same (=) or worse (>) solutions in comparison to other approaches.Tables 1–4 clearly show the superiority of our approaches over previously proposed approaches on both the objectives irrespective of the use of local search. Average solution quality of our approaches are always better than GA1C, GA2C, GA2PC and TCX on both the objectives and are always better than GGA-SS on objective1 irrespective of whether the local search has been used or not. For objective2, only GGA-SS obtained better solutions on more instances than ABC(FC) without local search. In all the remaining cases, our approaches obtained better solutions on more or equal number of instances than any previously proposed approaches. As far as comparison among our three approaches is concerned, on these 12 instances IWO performed the best among the three and ABC(FC) performed the worst among the three.For objective1, local search has improved average solution quality on 6, 3 and 0 instances respectively for ABC(FC), ABC(VC) and IWO, whereas for objective2, corresponding numbers are 7, 7 and 1. However, all improvements are small only.Figs. 1–3graphically compare the average solution quality of ABC(FC), ABC(VC), IWO, GA2PC, GGA-SS, ACO and TCX on instances of [11] under objective1, whereas Figs. 4–6do the same under objective2. We have not included GA1C and GA2C in the graphical comparison because they performed the worst among all the approaches as can be seen from Table 1 or Table 2 and they were introduced in [11] with the purpose of comparison with GA2PC only. These six figures are drawn utilizing the results of our approaches with local search. These figures reaffirm the superiority of our approaches over other approaches in a clear manner. From these figures, it can be clearly observed that GA2PC performed the worst and IWO performed the best among all the seven approaches compared. It can be clearly seen that on objective1, results of GA2PC and TCX are far worse than the results of all other approaches, whereas on objective2, this holds only in case of the results of GA2PC.Tables 5 and 6compare the performance of ABC(FC), ABC(VC) and IWO with GA1C, GA2C, GGA-BRC, GGA-SS and ACO in terms of average solution quality for objective1 and objective2 both on each of the 12 test problems used in [12]. Table 5 reports the results of our approaches obtained via local search, whereas Table 6 reports the results of our approaches without using the local search. Data for GA1C, GA2C, and GGA-BRC are taken from [12]. Data for GGA-SS, and ACO are taken from [14,15] respectively. These tables also report the best solution found and standard deviation (S.D.) of solution values on each instance for ABC(FC), ABC(VC), and IWO. Tables 7 and 8summarize the results by providing the number of instances out of a total of 12 where our approaches obtained better (<), same (=) or worse (>) solutions in comparison to other approaches. It is to be noted that these instances are not used in [16] for evaluating the performance of TCX. Figs. 7–9graphically compare the average solution quality of ABC(FC), ABC(VC), IWO, GGA-BRC, GGA-SS and ACO on instances of [12] under objective1, whereas Figs. 10–12do the same under objective2. GA1C and GA2C were included in [12] with the sole purpose of comparison with GGA-BRC only and they performed the worst overall among all the approaches as can be seen from Table 5 or Table 6, and, therefore, we have not included them in the graphical comparison. These six figures are drawn utilizing the results of our approaches with local search.Observations similar to previous section can be made here also. On these instances also, our approaches are superior to previously proposed approaches on both the objectives irrespective of the use of local search except for ABC(FC) whose results with and without local search are inferior to ACO on more number of instances. Average solution quality of our approaches is always better than GA1C, GA2C and GGA-BRC on both the objectives irrespective of whether the local search has been used or not. In fact, results of GA1C, GA2C and GGA-BRC are much worse than all the other approaches. In all the remaining cases, our approaches obtained better solutions on more or equal number of instances than any previously proposed approaches. As far as comparison between our three approaches is concerned, ABC(FC) performed the worst among three on these instances, whereas ABC(VC) performed the best among the three on objective1 and IWO performed the best among the three on objective2.For objective1, local search has improved average solution quality on 6, 1 and 0 instances respectively for ABC(FC), ABC(VC) and IWO, whereas for objective2, corresponding numbers are 5, 4 and 0. However, all improvements are small only.Tables 9 and 10compare the performance of ABC(FC), ABC(VC), and IWO with TCX in terms of best and average solution quality as well as standard deviation of solution values over 30 runs for objective1 and objective2 both on each of the 3 test problems used in [16]. Data for TCX is taken from [16]. Table 9 reports the results of our approaches with local search, whereas Table 10 reports the results of our approaches without using the local search. Figs. 13 and 14graphically compare the performance of ABC(FC), ABC(VC), IWO with and without local search with TCX under objective1, whereas Figs. 15 and 16do the same under objective2. Figs. 13 and 15 compare the various approaches in terms of average solution quality, whereas Figs. 14 and 16 compare the various approaches in terms of quality of the best solution. In these figures, our approaches without local search are indicated by adding suffix “-NLS” to their names, viz. ABC(FC)-NLS, ABC(VC)-NLS and IWO-NLS. These tables and figures clearly show the superiority of our approaches over TCX on both the objectives on these 3 instances. Even the results of our approaches without local search are much better than TCX. As far as comparison among our proposed approaches is concerned, IWO performed consistently better on both the objectives irrespective of whether the local search is used or not. In some cases under objective2, best and average solution quality obtained through ABC(FC) is better than ABC(VC). Here, local search is able to improve the best and average solution quality of ABC(FC), ABC(VC) and IWO significantly on all 3 instances under both the objectives.To check the optimality gap of proposed TCX approach, Yuan et al. [16] introduced a new set of 5 small sized MTSP test problems named 11a, 11b, 12a, 12b, and 16. Test problems 11a, 12a and 16 respectively consist of the first 11 cities, the first 12 cities, and the first 16 cities from 51 city test problem of [11], where as 11b and 12b test problems are derived from sp11_dist, uk12_dist instances available from http://people.sc.fsu.edu/∼jburkardt/datasets/cities/cities.html. For all these test problems, m is set to 3. Optimal values for these test problems are determined by using an exhaustive search [16]. We have also considered these instances so that we can compare our approaches with TCX in terms of optimality gap also. For none of our proposed approaches, local search is able to improve the results on either objective on these instances, so we present our results in one table only.Table 11reports the results of TCX, ABC(FC), ABC(VC) and IWO for both the objectives on each of these 5 test problems in terms of best and average solution quality and standard deviation of solution values over 30 runs. Data for TCX is taken from [16]. TCX is able to find optimal solution in all the 30 runs only on 3 instances for objective1 and 3 instances for objective2. All our approaches find optimal solution in each of the 30 runs on both the objectives on all the 5 instances except for the IWO which is not able to find optimal solution in all the runs on 16 cities test problem for objective1. In this case also, IWO has an standard deviation of 2 only, whereas TCX has the standard deviation of 8.

@&#CONCLUSIONS@&#
In this paper, we have proposed two metaheuristic approaches, viz. artificial bee colony and invasive weed optimization for the single depot multiple traveling salesperson problem. We have proposed two versions of ABC algorithm. In the first version called ABC(FC), neighboring solutions are generated more or less at the same distance from the original solution throughout the ABC algorithm. The second version called ABC(VC) is inspired by the spatial distribution concept in invasive weed optimization algorithm. In ABC(VC), the expected distance of the neighboring solution from the original solution is reduced from a pre-defined initial value to a pre-defined final value over the iterations of the algorithm. The best solution obtained through our approaches is improved further using a local search. We have evaluated and compared our proposed approaches with the state-of-the-art approaches on the benchmark instances available in the literature. This performance evaluation and comparison has been done using two different MTSP objective functions, viz. the objective of minimizing total distance traveled by all the salespersons, and the objective of minimizing the maximum distance traveled by anyone salesperson. Computational results on a wide range of benchmark instances show the superiority of our approaches over all the other state-of-the-art approaches on both the objectives. Our approaches are superior overall even in the situation where no local search is used. As far as comparison among our proposed approaches is concerned, ABC(FC) performed the worst among the three. Though the IWO performed the best among the three, performance of ABC(VC) is also close to IWO.Our approaches have been proposed for MTSP with a single depot, a possible future work is to extend our approaches to MTSP with more than one depot. Since many practical problems can be casted as a MTSP, our approaches can be applied to these problems also. As our approaches are designed keeping in mind the grouping nature of MTSP, similar approaches can be developed for other grouping problems also. The concept of reducing the expected distance of the neighboring solution from the original solution over the iterations of the algorithm, which has been used in ABC(VC), can be helpful while designing ABC algorithm for any problem where the original solution need to be perturbed by a large amount in the beginning to generate a neighboring solution and this degree of perturbation has to be reduced as the algorithm progresses in order to get good results. We have used 2-opt moves in our local search which is an intra-tour operator. In place of 2-opt moves, other intra-tour operators like 3-opt and double-bridge moves may be tried to improve the performance of this local search. We have not used any inter-tour operator in our local search for objective1. As mentioned in Section 3.7, we have tried one inter-tour operator, but it has not been able to improve the results for any of our approaches. Inter-tour operators like removing a city from one tour and inserting it into the best possible position among all tours or swapping cities between tours may also be tried in the local search to improve its performance for objective1. For objective2, we have used an inter-tour operator that consists of removing a city randomly from longest tour and inserting this city into a randomly chosen tour at the best possible position provided this action yields a reduction in the length of the longest tour. For objective2, we can also try swapping the cities of longest tour with the cities of some other tours provided such swaps reduce the length of the longest tour.