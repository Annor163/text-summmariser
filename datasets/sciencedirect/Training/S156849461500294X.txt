@&#MAIN-TITLE@&#
Intelligent switching adaptive control for uncertain nonlinear dynamical systems

@&#HIGHLIGHTS@&#
A switching adaptive control scheme using a Hopfield-based dynamic neural network (SACHNN) for nonlinear systems with external disturbances is proposed.The IAC's limitation ofgˆ(x)>εcan be solved by simply switching the IAC to the DAC, where ɛ is a positive desired value.The Hopfield dynamic neural network (HDNN) is used to not only design DAC but also approximate the unknown plant nonlinearities in IAC design.

@&#KEYPHRASES@&#
Hopfield dynamic neural network,Adaptive control,Switching control,

@&#ABSTRACT@&#
In this paper, we aim at proposing a switching adaptive control scheme using a Hopfield-based dynamic neural network (SACHNN) for nonlinear systems with external disturbances. In our proposed scheme, an auxiliary direct adaptive controller (DAC) ensures the system stability when the indirect adaptive controller (IAC) is failed; that is,gˆ(x)approaches to zero, wheregˆ(x)is the denominator of an indirect adaptive control law. The IAC's limitation ofgˆ(x)>εthen can be solved by simply switching the IAC to the DAC, where ɛ is a positive desired value. The Hopfield dynamic neural network (HDNN) is used to not only design DAC but also approximate the unknown plant nonlinearities in IAC design. The designed simple structure of HDNN keeps the tracking performance well and also makes the practical implementation much easier because of the use of less and fixed number of neurons.

@&#INTRODUCTION@&#
Most of control design techniques are based on the understanding of the plant under consideration and its surrounding environment. However, in real-world applications lots of the controlled plants are too complex for us to fully understand the system dynamics through the basic physical processes. Therefore, an identification technique was proposed for control design methods to obtain a progressive understanding of the controlled plant. Adaptive control is a famous identification-technique-based control design. It provides a systematic approach for automatically adjusting controllers on-line, in order to achieve or to maintain a desired performance level of control system when the parameters of the plant dynamic model are unknown and/or change in time. In general, the adaptive control techniques can distinguish between an indirect method (one calls this method as an indirect adaptive control (IAC) in the field of control design) and a direct method (one calls this method as a direct adaptive control (DAC) in the field of control design) [1–7].The basic idea of IAC is that a controller ensures the system stability with the estimation of the plant parameters from the available input–output measurements. This scheme is termed as indirect because the adaptation of the controller parameters can be done in two stages. First, the plant model parameters are estimated on-line and the controller is then calculated depending on the current estimated plant model. IAC also has been referred to as explicit adaptive control because the design of controller is based on an explicit estimation plant model. Therefore, the resulting parameter estimates are normally accurate enough for the purposes of monitoring and prognosing the machine health, which are of significant practical importance for industrial applications. In contrast, the plant model of DAC is parameterized in terms of the controller parameters, which are estimated directly without intermediate calculations. The adaptive control laws and the parameter adaptation laws of DAC are simultaneously synthesized for the sole objective of reducing the output tracking error. However, this synthesized design causes the drawbacks that the adaptive control laws and the parameter estimation must be concerned simultaneously in the design process, and certain tracking error must be chosen as driving signals due to limitation of gradient type in the parameter estimation law. Unfortunately, in real-world implementations the actual tracking errors are normally very small such that the direct adaptive control law is thus prone to be corrupted by other factors, such as the sampling delay and noise. Therefore, the parameter estimates in DAC are normally not accurate enough for the purposes of the prognostics and the machine component health monitoring [3,8,9].IAC has been used for real-world implementations to provide system stability and to achieve superior performance of the output tracking in many researches [2–4,10]. However, one condition g(x)>0 (org(x)<0) must be held in these researches, where g(x) is an unknown nonlinear continuous function of affine systems. That is, if the nonlinear function g(x) is close to zero, the control law is expected to contain an unstable term1/gˆ(x), wheregˆ(x)is the approximation of g(x). In these cases, boundedness of control input cannot be ensured. According to the assumption of g(x)>0, a projection algorithm and a second control component were proposed in [1–5,10] to keep the system stability. Furthermore, a direct control law for affine nonlinear systems was proposed in [6] instead of the indirect control law. However, there still exist DAC inherent problems. Therefore, we aim at proposing a switching adaptive control scheme, where the IAC switches to the DAC as soon asgˆ(x)approaches to zero. It is clear that the unstable term1/gˆ(x)can be simply avoided in our proposed scheme. Note that the stability during whole control process, even at the moment of switching between IAC and DAC, can be guaranteed.Neural networks (NNs) can be classified into two types, a static NN and a dynamic NN. In a static NN, signals flow from input units to output units in a forward direction. In a dynamic NN, dynamic elements are involved in the structure of the NN, for example the elements of feedback connections. The famous static NNs (SNNs), i.e. the feed-forward fuzzy neural network (FNN) and feed-forward radius basis function network (RBFN), are frequently used as a powerful modeling tool [3,8,9,11,26]. Although they have achieved much theoretical success, their complex structures make the practical implementation difficult and the number of the hidden neurons in the NNs’ hidden layers is hard to determine. In addition, SNNs are quite sensitive to the unlearned changes, and they are also unable to represent the dynamic system mapping without the aid of tapped delay. However, the tapped delay will result in long computation time, high sensitivity to external noise, and a large number of neurons [12]. These drawbacks severely affect the applicability of SNNs. An important motivation to promote DNNs is because a smaller DNN can provide the same functionality as a much larger SNN [13]. Furthermore, depending on their dynamic memory, DNNs have good performances on the applications of identification, state estimation, trajectory tracking, and robust against un-modeled dynamic. A Hopfield dynamic neural network (HDNN) is one of famous DNNs proposed by Hopfield J.J. in 1982 and 1984 [14,15]. HDNN can be easily realized by a Hopfield circuit and has the property of decreasing in energy by finite number of node-updating steps. In HDNN, the analysis of fundamental properties, stability, convergence and equilibrium for discrete and continuous systems were proposed in [16,17].In this paper, the control object is to force the system output to track a given reference signal without the condition ofgˆ(x)>εfor nonlinear affine systems. In the proposed SACHNN the HDNNs are used to not only output the direct adaptive control force but also approximate the unknown plant nonlinearities for the indirect adaptive controller. Furthermore, a compensation controller is merged to SACHNN to dispel the effect of the approximation error and the bounded external disturbance. The saving weights of SACHNN are on-line tuned by adaptive laws derived in the sense of Lyapunov Theorem.Let S⊂Rnand Q⊂Rnbe open sets, Ds⊂S and DQ⊂Q be compact sets. Consider a nth-order nonlinear dynamic system of the form(1)x(n)=f(x)+g(x)u+dy=xwherex=[x1x2…xn]T=[xx˙…xn+1]Tis the state vector. f:Ds→R and f:DQ→R are the uncertain continuous functions; u∈R is the continuous control input and y∈R is the continuous output, which is assumed to be measurable; d∈R is bounded external disturbance. The control objective is to force the system output y to follow a given bounded reference signal yr∈R. The error vector e is defined as(2)e=[e,e˙,…,e(n−1)]T=[e1,e2,…,en]T∈Rn,where e=yr−x1=yr−y. If f(x) and g(x) are given and the system is free of external disturbance, the ideal controller can be designed as(3)uideal=1g(x)[−f(x)+yr(n)+kcTe],wherekc=knkn−1…k1T. Substituting (3) into (1), we have the following error dynamics(4)e(n)+k1e(n−1)+⋯+kne=0.If ki, i=1, 2, 3, …, n are chosen so that all roots of the polynomial H(s)=sn+k1sn−1+⋯+knlie strictly in the open left half of the complex plane, thenlimt→∞e(t)=0. This implies that the control law uidealcan be used for any initial conditions. However, since f(x) and g(x) are unknown or perturbed, the ideal feedback controller uidealin (3) cannot be implemented.The developed controller u can be expressed as the following form [18].(5)u=uh+uc,where uh=αuD+(1−α)uIis the adaptive controller, in which α∈[0, 1] is a weighting factor. Note that even though the factor α is chosen as 0 or 1 according to the switching condition, the proof of global stability of close-loop system is not restricted to this condition. In (5), uDstands for DAC and uIstands for IAC; uCis a compensation controller supposed to compensate the effect of external disturbance and the approximation error. More specifically, uIcould be expressed as the indirect controller as(6)uI=1gˆ(x)(−fˆ(x)+yr(n)+kcTe),wherefˆ(x)andgˆ(x)are the estimate of nonlinear functions f(x) and g(x), respectively. The basic idea of the choice of the factor α is that α=1 if the IAC is only used and α=0 if the DAC is only used. For simplicity purpose, we denotefˆ(x)byfˆandgˆ(x)bygˆin the following. By substituting (5) and (6) into (1), the error dynamics equation can be expressed as(7)e˙=Ae−BkcTe+Bc[guideal−gαuI−g(1−α)uD−gus−d]e1=DTe,whereA=010…0⋮⋱⋱⋱00……0100……0∈Rn×n,B=00⋮1∈Rn×1,D=10⋮0∈Rn×1,anduideal=1g[−f+yr(n)+kcTeˆ]A HDNN is used to output the direct control force uDand approximate the unknown functions f and g in the indirect controller uIin this paper.Consider a HDNN described by the following nonlinear differential equation [19](8)χ˙=Aχ+BWσ(V1χ)+BΨφ(V2χ)γ(u¯)whereχ=χ1χ2…χnT∈Rnis the state vector of the HDNN,u¯=u¯1u¯2⋯u¯mT∈Rmis the input vector, σ:Rr→Rk, A∈Rn×nis Hurwitz matrix, B=diag{b1, b2, …, bn}∈Rn×n, W∈Rn×k, V1∈Rr×n, Ψ∈Rn×l, V2∈Rs×n, φ:Rs→Rl×n, and γ:Rm→Rn. In (8), w and Ψ are the weight matrices describing output layer connections, V1 and V2 are the weight matrices describing the hidden layer connections, σ(·) is a sigmoid vector function responsible for nonlinear state feedbacks, and γ(·) is a differentiable input function. If the HDNN in (8) satisfies the conditions of r=s=l=n, V1=V2=In×n, and φ(·)=In×n, it is called a simple HDNN and can be expressed as(9)χ˙=Aχ+BWσ(χ)+BΨγ(u¯).Following by the literatures [16,17,19], we choosek=n,A=diag−a1−a2⋯−anwith ai>0, i=1, 2,…,n,γ(u¯)=u¯oT∈Rnwith n≥m, and o∈Rn−mbeing a zero vector. Express Ψ=[ΘΘr]T, where Θ∈Rn×mand Θr∈Rn×(n−m). Therefore, Eq. (9) can be modified as(10)χ˙=Aχ+BWσ(χ)+BΘ(u¯).The structure of the HDNN is shown in Fig. 1. In Fig. 1, the ith output of the neurons can be expressed as(11)χ˙i=−aiχi+biWiTσ(χ)+biΘiT(u¯),i=1,2,⋯,nwhereWiT=wi1wi2…winandΘiT=[θi1θi2…θin]are the ith rows of w and Θ, respectively.Solving the differential Eq. (11), we obtain the ith output of the DHNN(12)χi=bi(WiTξW,i+ΘiTξΘ,i)+e−aitχi(0)−e−aitbi,[WiTξW,i+ΘiTξΘ,i(0)]where χi(0) is the initial state of χi; ξW,i∈Rmand ξΘ,i∈Rmare the solutions of(13)ξ˙W,i=−aiξW,i+σ(χ)and(14)ξ˙Θ,i=−aiξΘ,i+u¯;ξW,i(0) and ξΘ,i(0) are initial states of ξW,iand ξΘ,i, respectively. Note that owing to ai>0 the terms e−aitχi(0) ande−aitbi[WiTξW,i(0)+ΘiTξΘ,i(0)]in (12) are expected to exponentially decay with time. It is known that a special case of the DNN is chosen ai=1/(RiCi) and bi=1/Ci, where the ith resistance Riand the ith capacitance Cimust be bigger than 0 [20,21]. The sigmoid function vectorσ(χ)=σ1(χ1)σ2(χ2)⋯σn(χn)Tis defined by a hyperbolic tangent function, which is shown as(15)σ(χi)=tanh(κiχi),i=1,2,…,n,where κiis the slope of tanh(·) at the origin. The hyperbolic tangent function is bounded by −1<tanh(·)<1. Note that the structure of the proposed HDNN is quite simple and the hyperbolic tangent function has the advantages, such as smoothness, boundedness, and being monotone [22].The output of the HDNN expressed in (12) can be used to produce uDand approximate unknown functions f and g of uI. The system (1) is an SISO nonlinear system, and thus the control signal and the unknown nonlinearities are scalar value. Therefore, the HDNN contains only one neuron. That is, the subscript i can be eliminated from (13) and rewritten as(16)χ=1C(WξW+ΘTξΘ)+e−(1/RC)tχ(0)−1Ce−(1/RC)t[WξW(0)+ΘTξΘ(0)],where χ(0) is the initial value of χ; R and C represent the resistance and capacitance, respectively. Fig. 2shows the HDNN only has a single neuron. W and ξWare scalar value, and the input of the HDNN isu¯=u¯1…u¯m. It should be emphasized that this kind of structure is quite simple.The approximated direct control uDand the approximation functionsfˆ, andgˆcan be respectively expressed by the simple HDNN asuˆD(WˆuˆD,ΘˆuˆD|e),fˆ(Wˆfˆ,Θˆfˆ|x), andgˆ(Wˆgˆ,Θˆgˆ|x), where both e and x are the inputs of the simple HDNN.Assumption 1LetwuˆD=WˆuˆDTΘˆuˆDT,wgˆ=WˆgˆTΘˆgˆT,wfˆ=WˆfˆTΘˆfˆT,and e and x belong to the compact sets. The optimal weighting vectorwfˆ*=argminwfˆ∈Owfˆsupx∈Ux|f(x)−fˆ(wfˆ|x)|lies in a convex regionOwfˆ=wfˆ∈R(m+1):wfˆvwfˆ,wgˆ*=argminwgˆ∈Owgˆsupx∈Ux|g(x)−g(wgˆ|x)|, lies in a convex regionOwgˆ=wgˆ∈R(m+1):wgˆ≤Vwgˆ,andwuˆD*=argminwuˆD∈OwuˆDsupe∈Ue|uˆD*(e)−uˆD(wuˆD|e)|lies in some convex regionOWuˆD=WuˆD∈R(m+1):WuˆD≤vWuˆD. The radiusOwfˆ,Owgˆ, andOwuˆDare design parameters.The uncertain nonlinear function g(x) is bounded by(17)αg(x)≤g(x)≤βg(x).gl=αg(x) and gu=βg(x) are small constants and both αg(x) and βg(x) could be positive or negative.ωTis assumed to satisfy(18)ωT≤εc,where ɛcis a positive constant.Substituting (6) anduˆD*in (7), we can rewrite the error dynamics (7) as(19)e˙=Ae−BKcTe+αB(fˆ(Wˆfˆ,Θˆfˆ|x)−(fˆ(Wˆfˆ*,Θˆfˆ*|x))+αB(gˆ(Wˆgˆ,Θˆgˆ|x)−(gˆ(Wˆgˆ*,Θˆgˆ*|x))ul+g(1−α)B(uˆD*(WuˆD*,ΘˆuˆD*|e)−uˆD(WuˆD*,ΘˆuˆD*|e))−gBus−Bd+B(Δfˆ+Δgˆ+ΔuˆD)whereΔf˙=α(fˆ(Wfˆ*,Θfˆ*|x)−f(x)),Δgˆ=α(gˆ(Wgˆ*,Θgˆ*|x)−g(x)), andΔuˆD=g(1−α)(uˆD(WˆuˆD,ΘˆuˆD|e)−uD). By using Eq. (16), Eq. (19) can be expressed as(20)e˙=Ace+αB(1Cfˆ(Wˆfˆξfˆw+ΘˆfˆTξfˆΘ)+e−(1/RfˆCfˆ)tufˆ0−e−(1/RfˆCfˆ)t1Cfˆ(Wˆξfˆw0+ΘˆfˆTξfˆΘ0)−fˆ(θfˆ*,wfˆ*|x))+αB(1Cgˆ(Wˆgˆξgˆw+ΘˆgˆTξgˆΘ)+e−(1/RgˆCgˆ)tugˆ0−e−(1/RgˆCgˆ)t1Cgˆ(Wˆgˆξgˆw0+ΘˆgˆTξgˆΘ0)−gˆ(θgˆ*,wgˆ*|x))uI+g(α−1)B1CuˆD(WˆuˆDξuˆD,w+ΘˆuˆDTξuˆD,Θ+e−(1/RuˆDCuˆD)tuuˆD0−e−(1/RuˆDCuˆD)t−1CuˆD(WˆuˆDξgˆw0+ΘˆuˆDTξuˆD,Θ0)−uˆD(θuˆD*,wuˆD*|e))−gBuc−Bd+B(Δfˆ+Δgˆ+ΔuˆD)whereAc=A−BKcT. By definingW˜fˆ=W˜fˆ−W˜fˆ*,W˜gˆ=W˜gˆ−W˜gˆ*,W˜uˆD=W˜uˆD−W˜uˆD*,Θ˜fˆ=Θ˜fˆ−Θ˜fˆ*,Θ˜gˆ=Θ˜gˆ−Θ˜gˆ*andΘ˜uˆD=Θ˜uˆD−Θ˜uˆD*, we can have(21)e˙=Ace+αB(1Cfˆ(Wˆfˆξfˆw−e−(1/RfˆCfˆ)tW˜fˆξfˆw0)+1Cfˆ(ΘfˆTξfˆΘ−e−(1/RfˆCfˆ)tΘ˜fˆTξfˆΘ0))+αB1Cgˆ(Wˆgˆξgˆw−e−(1/RgˆCgˆ)tW˜gˆξgˆw0)+1Cgˆ(ΘgˆTξgˆΘ−e−(1/RgˆCgˆ)tΘ˜gˆTξgˆΘ0)uI+gB(α−1)1CuˆD(WˆuˆDξuˆD,w−e−(1/RuˆDCuˆD)tW˜uˆDξuˆD,w0)+1CuˆD(ΘuˆDTξuˆD,Θ−e−(1/RuˆDCuˆD)tΘ˜uˆDTξuˆD,Θ0)−gBuc−Bd+BΔfˆ+BΔgˆ+BΔuˆDLemma 1LetWˆfˆ0∈ΩfˆW,Wˆfˆ0∈ΩfˆΘ,Wˆgˆ0∈ΩgˆW,Wˆgˆ0∈ΩgˆΘ,WˆuˆD0∈ΩWˆuˆD, andWˆuˆD0∈ΩΘˆuˆD, whereWˆfˆ0,Θˆfˆ0,Wˆgˆ0,Θˆgˆ0,WˆuˆD0, andΘˆuˆD0are the initials ofWˆfˆ,Θˆfˆ,Wˆgˆ,Θˆgˆ,WˆuˆDandΘˆuˆD, respectively.Mfˆw,MfˆΘ,Mgˆw,MgˆΘandMuˆDare the boundness of the adjusted weights. If the adaptive laws are designed as(22)Wˆ˙fˆ=−W˜˙fˆ=βfˆWCfˆeTPB(ξfˆW−e−(1/RfˆCfˆ)tξfˆW0)if(|Wˆfˆ|<MfˆW)or(|Wˆfˆ|=MfˆWandeTPBWˆfˆ(ξfˆW−e−(1/RfˆCfˆ)tξfˆW0)≥0)Pr[βfˆWCfˆeTPB(ξfˆW−e−(1/RfˆCfˆ)tξfˆW0)]if(|Wˆfˆ|=MfˆWandeTPBWˆfˆ(ξfˆW−e−(1/RfˆCfˆ)tξfˆW0)<0)(23)Θˆ˙fˆ=−Θ˜˙fˆ=βfˆΘCfˆeTPB(ξfˆΘ−e−(1/RfˆCfˆ)tξfˆΘ0)if(|Θˆfˆ|<MfˆΘ)or(|Θˆfˆ|=MfˆΘandeTPBΘˆfˆ(ξfˆΘ−e−(1/RfˆCfˆ)tξfˆΘ0)≥0)Pr[βfˆΘCfˆeTPB(ξfˆΘ−e−(1/RfˆCfˆ)tξfˆΘ0)]if(|Θˆfˆ|=MfˆΘandeTPBΘˆfˆ(ξfˆΘ−e−(1/RfˆCfˆ)tξfˆΘ0)<0),(24)Wˆ˙gˆ=−W˜˙gˆ=βgˆWCgˆeTPB(ξgˆW−e−1RgˆCgˆtξgˆW0)if(|Wˆgˆ|<MgˆW)or(|Wˆgˆ|=MgˆWandeTPBWˆgˆ(ξgˆW−e−1RgˆCgˆtξgˆW0)≥0)Pr[βgˆWCgˆeTPB(ξgˆW−e−1RgˆCgˆtξgˆW0)]if(|Wˆgˆ|=MgˆWandeTPBWˆgˆ(ξgˆW−e−1RgˆCgˆtξgˆW0)<0),(25)Θˆ˙gˆ=−Θ˜˙gˆ=βgˆΘCgˆeTPB(ξgˆΘ−e−(1/RgˆCgˆ)tξgˆΘ0)if(|Θˆgˆ|<MgˆΘ)or(|Θˆgˆ|=MgˆΘandeTPBΘˆgˆ(ξgˆΘ−e−(1/RgˆCgˆ)tξgˆΘ0)≥0)Pr[βgˆΘCgˆeTPB(ξgˆΘ−e−(1/RgˆCgˆ)tξgˆΘ0)]if(|Θˆgˆ|=MgˆΘandeTPBΘˆgˆ(ξgˆΘ−e−(1/RgˆCgˆ)tξgˆΘ0)<0),(26)Wˆ˙uˆD=−W˜˙uˆD=βuˆD,wCuˆDeTPB(ξuˆD,w−e−(1/RuˆDCuˆD)tξuˆD,w0)if(|WˆuˆD|<MuˆD,w)or(|WˆuˆD|=MuˆD,wandeTPBWˆuˆD(ξuˆD,w−e−(1/RuˆDCuˆD)tξuˆD,w0)≥0)Pr[βuˆD,wCuˆDeTPB(ξuˆD,w−e−(1/RuˆDCuˆD)tξuˆD,w0)]if(|WˆuˆD|=MuˆD,wandeTPBWˆuˆD(ξuˆD,w−e−(1/RuˆDCuˆD)tξuˆD,w0)<0),and(27)Θˆ˙uˆD=−Θ˜˙uˆD=βuˆD,ΘCuˆDeTPB(ξuˆD,Θ−e−(1/RuˆDCuˆD)tξuˆD,Θ0)if(|ΘˆuˆD|<MuˆD,Θ)or(|ΘˆuˆD|=MuˆD,ΘandeTPBΘˆuˆD(ξuˆD,Θ−e−(1/RuˆDCuˆD)tξuˆD,Θ0)≥0)Pr[βuˆD,ΘCuˆDeTPB(ξuˆD,Θ−e−(1/RuˆDCuˆD)tξuˆD,Θ0)]if(|ΘˆuˆD|=MuˆD,ΘandeTPBΘˆuˆD(ξuˆD,Θ−e−(1/RuˆDCuˆD)tξuˆD,Θ0)<0),whereβfˆw,βfˆΘ,βgˆw,βgˆΘ,βuˆD,W, andβuˆD,Ware the positive learning rates; the symmetric positive definite matrix P satisfies the following Riccati-like equation(28)AcTP+PAc+Q+PB(1ρ2−1δ)BTP=0,whereQis a symmetric positive matrix and 1/ρ2−1/δ≤0. ThenWˆfˆ≤MfˆW,Θˆfˆ≤MfˆΘ,Wˆgˆ≤MgˆW,Θˆgˆ≤MgˆΘ,WˆuˆD≤MWˆuˆDandΘˆuˆD≤MΘˆuˆDfor all t≥0.Suppose theAssumption 1holds. Consider the plant(1)with the control law(5)and the adaptive laws(22)–(27). The compensation controller ucis given as(29)uc=12δgLBcTPe,where gLis a known constant satisfying gL<g(x)<∞. Then, the overall control scheme guarantees the following properties:(30)i)12∫0teTQedτ≤a+b∫0tΔ2dτFor 0≤t<∞, where a and b are constants and Δ includes approximation error and external disturbances.ii)the tracking errorecan be expressed in the terms of the lumped uncertainty as(31)e≤2V(0)+ρ2Δ2λmin(P),where V(0) is the initial value of a Lyapunov function candidate defined later and λmin(P) is the minimum eigenvalue ofP.Define the Lyapunov function candidate as(32)V=12eTPe+12ηfˆWW˜fˆ2+12ηfˆΘΘ˜fˆTΘ˜fˆ+12ηgˆWW˜gˆ2+12ηgˆΘΘ˜gˆTΘ˜gˆ+12ηuˆD,WW˜uˆD2+12ηuˆD,ΘΘ˜uˆDTΘ˜uˆD,whereηfˆW=βfˆW,ηfˆΘ=βfˆΘ,ηgˆW=βgˆW,ηgˆΘ=βgˆΘ,ηuˆD,W=βuˆD,W/g,andηuˆD,Θ=βuˆD,Θ/g. Differentiating Eq. (32) with respect to time and using the error Eq. (21) yield(33)V˙=12eTP[Ace+αB1Cfˆ(W˜fˆξfˆW−e−(1/RfˆCfˆ)tW˜fˆξfˆW0+1Cfˆ(Θ˜fˆTξfˆΘ−e−(1/RfˆCfˆ)tΘ˜fˆTξfˆΘo))+αB1Cgˆ(W˜gˆξgˆW−e−(1/RgˆCgˆ)tW˜gˆξgˆW0)+1Cgˆ(Θ˜gˆTξgˆΘ→−e−(1/RgˆCgˆ)tΘ˜gˆTξgˆΘo)uI+gB(1−α)1CuˆD(W˜uˆDξuˆD,W−e−(1/RuˆDCuˆD)tW˜uˆDξuˆD,W0)+1CuˆD(Θ˜uˆDTξuˆD,Θ−e−(1/RuˆDCuˆD)tΘ˜uˆDTξuˆD,Θo)−gBus−Bd+BΔfˆ+BΔgˆ+BΔuD]+12[Ace+Bα1Cfˆ(W˜fˆξfˆW−e−(1/RfˆCfˆ)tW˜fˆξfˆW0)+1Cfˆ(Θ˜fˆTξfˆΘ−e−(1/RfˆCfˆ)tΘ˜fˆTξfˆΘo)+Bα1Cgˆ(W˜gˆξgˆW−e−(1/RgˆCgˆ)tW˜gˆξgˆW0)+1Cgˆ(Θ˜gˆTξgˆΘ−e−(1/RgˆCgˆ)tΘ˜gˆTξgˆΘo)uI+gB(1−α)1CuˆD(W˜uˆDξuˆD,W−e−(1/RuˆDCuˆD)tW˜uˆDξuˆD,W0)+1CuˆD(Θ˜uˆDTξuˆD,Θ−e−(1/RuˆDCuˆD)tΘ˜uˆDTξuˆD,Θo)−gBus−Bd+BΔfˆ+BΔgˆ+BΔuˆD]TPe+1ηfˆWW˜fˆW˜˙fˆ+1ηfˆΘΘ˜fˆTΘ˜˙fˆ+1ηgˆWW˜gˆW˜˙gˆ+1ηgˆΘΘ˜gˆTΘ˜˙gˆ+1ηuˆD,WW˜uˆDW˜˙uˆD+1ηuˆD,ΘΘ˜uˆDTΘ˜˙uˆDManipulating Eq. (33), we can have(34)V˙=12eT(AcTP+PAc)e+αeTPB1Cfˆ(W˜fˆξfˆW−e−(1/RfˆCfˆ)tW˜fˆξfˆW0)+1Cfˆ(Θ˜fˆTξfˆΘ−e−(1/RfˆCfˆ)tΘ˜fˆTξfˆΘo)+αeTPB1Cgˆ(W˜gˆξgˆW−e−(1/RgˆCgˆ)tW˜gˆξgˆW0+1Cgˆ(Θ˜gˆTξgˆΘ−e−(1/RgˆCgˆ)tΘ˜gˆTξgˆΘo))uI+g(α−1)eTPB1CuˆD(W˜uˆDξuˆD,W−e−(1/RuˆDCuˆD)tW˜uˆDξuˆD,W0)+1CuˆD(Θ˜uˆDTξuˆD,Θ−e−(1/RuˆDCuˆD)tΘ˜uˆDTξuˆD,Θo)−geTPBuc−eTPBd+eTPBΔfˆ+eTPBΔgˆ+eTPBΔuˆD+1ηfˆWW˜fˆW˜˙fˆ+1ηfˆΘΘ˜fˆTΘ˜˙fˆ+1ηgˆWW˜gˆW˜˙gˆ+1ηgˆΘΘ˜gˆTΘ˜˙gˆ+1ηuˆD,WW˜uˆDW˜˙uˆD+1ηuˆD,ΘΘ˜uˆDTΘ˜˙uˆDBy defining(35)VWfˆ=αW˜fˆ1CfˆeTPBξfˆW−e−(1/RfˆCfˆ)tξ0fˆW+1ηfˆWW˜˙fˆ,(36)VΘfˆ=αΘ˜fˆT1CfˆeTPBξfˆΘ−e−(1/RfˆCfˆ)tξ0fˆΘ+1ηfˆΘΘ˜˙fˆ,(37)VWgˆ=αW˜gˆ1CgˆeTPBξgˆW−e−(1/RgˆCgˆ)tξgˆW0+1ηgˆWW˜˙gˆ,(38)VΘgˆ=αΘ˜gˆT1CgˆeTPBξgˆΘ−e−(1/RgˆCgˆ)tΘ˜gˆTξgˆΘ0u1+1ηgˆΘΘ˜˙gˆ,(39)VWD=g(α−1)W˜u˜D1Cu˜DeTPBξu˜D−e−(1/Ru˜DCu˜D)tξu˜D0+1ηu˜DW˜˙u˜D,(40)VΘD=g(α−1)Θ˜u˜D1Cu˜DeTPBξu˜D,Θ−e−(1/Ru˜DCu˜D)tξu˜D,Θ0+1ηu˜DΘ˜˙u˜D,(41)Δ=Δfˆ+Δgˆ+ΔuˆD−d,we can simplify Eq. (34) as(42)V˙=12eT(AcTP+PAc)e−geTPBuc+eTPBΔ+VWfˆ+VΘfˆ+VWgˆ+VΘgˆ+VWD+VΘDSubstituting uc, as shown in (29), into Eq. (42), we have(43)V˙=12eT(AcTP+PAc)e−12δggLeTPBcTPe+eTPBΔ+VWfˆ+VΘfˆ+VWgˆ+VΘgˆ+VWD+VΘD.Due to the facts δ>0 and g/gL≥1, we can rewrite the equation as(44)V˙≤12eT(AcTP+PAc−1δPBcTP)e+eTPBΔ+VWfˆ+VΘfˆ+VWgˆ+VΘgˆ+VWD+VΘD.Substituting (28) into (44), we have(45)V˙≤12eT(−Q−1ρ2PBcTP)e+eTPBΔ+VWfˆ+VΘfˆ+VWgˆ+VΘgˆ+VWD+VΘD=−12eTQe−121ρBcTPe−ρ(Δ−d)2+12ρ2Δ2+VWfˆ+VΘfˆ+VWgˆ+VΘgˆ+VWD+VΘD.Using (23), otherwise, we can rewrite (35) as(46)VWfˆ=0if(|Wˆfˆ|<MWfˆ)or(|Wˆfˆ|=MWfˆandeTPBWˆfˆ(ξWfˆ−e−(1.RfˆCfˆ)tξWfˆ0)≥0)−αCfˆeTPBWˆfˆT(ξWfˆ−e−(1/RfˆCfˆ)tξWfˆ0)||Wˆfˆ||2W˜fˆWˆfˆif(|Wˆfˆ|=MWfˆandeTPBWˆfˆ(ξWfˆ−e−(1.RfˆCfˆ)tξWfˆ0)<0)Next, considering the termsVWfˆ,VΘfˆ,VWgˆ,VΘgˆ,VWD,andVΘDin (42), we only show the proof ofVWfˆ≤0andVΘfˆ≤0for simplicity.First, because of the conditions thatWˆfˆ=MWfˆ,eTPBWˆfˆ(ξWfˆ−e−(1/RfˆCfˆ)tξWfˆ0)<0andWfˆ*belongs to the constraint setOwfˆ, we haveWˆfˆ=MWfˆ≥Wfˆ*. Using this fact, we obtainW˜fˆWˆfˆ=12(Wfˆ*−Wˆfˆ2−W˜fˆ2)≤0.Thus, Eq. (46) can be rewritten as(47)VWfˆ=−α2CfˆeTPBWˆfˆT(ξWfˆ−e−(1/RfˆCfˆ)tξWfˆ0)||Wˆfˆ||2(Wfˆ*2−Wˆfˆ2−W˜fˆ2)≤0.Similarly, we obtain(48)VΘfˆ=0f(|Θˆfˆ|<MΘfˆ)or(|Θˆfˆ|=MΘfˆandeTPBΘˆfˆ(ξΘfˆ−e−(1/RfˆCfˆ)tξΘfˆ0)≥0)−αCfˆeTPBΘˆfˆT(ξΘfˆ−e−(1/RfˆCfˆ)tξΘfˆ0)||Θˆfˆ||2Θ˜fˆΘˆfˆif(|Θˆfˆ|=MΘfˆandeTPBΘˆfˆ(ξΘfˆ−e−(1/RfˆCfˆ)tξΘfˆ0)<0)and Eq. (48) can be rewritten as(49)VΘfˆ=−α2CfˆeTPBΘˆfˆT(ξΘfˆ−e−(1/RfˆCfˆ)tξΘfˆ0)||Θˆfˆ||2(Θfˆ*2−Θˆfˆ2−Θ˜fˆ2)≤0.Using the same knowledge thatVWfˆ≤0,VΘfˆ≤0,VWgˆ≤0,VΘgˆ≤0,'VWD≤0,andVΘD≤0,we have(50)V˙≤12eTQe+12ρ2Δ2.Integrating both sides of the inequality of the equation yields(51)V(t)−V(0)≤−12∫0teTQedτ+ρ22∫0tΔ2dτFor 0≤t<∞. Since V(t)≥0, we obtain(52)12∫0teTQedτ≤V(0)+ρ22∫0tΔ2dτ.(ii) From Eq. (52) and since12∫0teTQedτ≥0, we have(53)2V(t)≤2V(0)+ρ2μ.0≤t<∞It is obvious that eTPe≤2V, for any V. Because P is a positive definite symmetric matrix, we have(54)λmin(P)e2=λmin(P)eTe≤eTPe.Then, we obtain(55)λmin(P)e2≤eTPe≤2V(t)≤2V(0)+ρ2Δ2.This equation implies the bound of tracking errore. If initial state V(0)=0, tracking errorecan be arbitrarily small by choosing adequate ρ.□It is obvious that Theorem 1 is held if the weighting factor α is staying in the interval [01]; that is,α∈01. Therefore, the control law (5) can be rewritten as(56)u=uI+ucifgˆ>εS(α=0)uD+ucotherwise(α=1),and Theorem 1 can still be proven. In (56), ɛSis the switching threshold.This paper investigates mainly on SISO systems. However, it can be easily extended to MIMO systems via an input–output linearization technique [23]. A description on the derivations toward a similar design approach for MIMO systems is given in Appendix.In this section, two examples are presented to illustrate the effectiveness of the proposed method. It should be emphasized that our proposed method does not need to know the exact dynamics of the controlled system.Example 1Chaotic dynamic systems are known for their complex, unpredictable behavior and extreme sensitivity to initial conditions as well as parameter variations. Consider a second-order chaotic dynamic system, a well-known Duffing's equation, which describes a special nonlinear circuit or a pendulum moving in a viscous medium under control [24]:(57)x˙=x2x˙2=−px¨−p1x+p2x3+qcos(wt)+u+dy=x1,where p, p1, p2, q and w are real constants, x1(t) is the displacement at time t, and x2(t) is the first derivative of x1(t) with respect to time. Depending on the choices of these constants, the solutions of system (57) may display various periodic orbits chaotic behaviors [25]. Assume the system is free of external disturbance in this example and p=0.4, p1=–1.1, p2=1.0, w=1.8, q=1.95 and [x1x2]T=[00]T. The reference signals are respectively chosen as yr(t)=sin(0.5t)+cos(t) (for case 1) and a step function (for case 2), and the switch boundaries are set to ɛs=0.03 for these two cases. In these two cases, the initial parameters of SACHNN are chosen as [x1x2]T=[00]T,ξfˆw0=0,ξfˆΘ0=00,ξgˆw0=0,ξgˆΘ0=00,ξuˆD,W0=0,ξuˆD,Θ0=00,Θˆfˆ0=11TandΘˆuˆD0=11T.MfˆW,MfˆΘ,MgˆW,MgˆΘ, andMuˆD,Θare set to 1.36×10−3, andWˆfˆ0,Wˆgˆ0,andWˆuˆD0are random within [−1000 1000]. These settings are chosen through the trial-and-error method to achieve favorable control performance. The learning rates of weights adaption are selected asβfˆW=150,βfˆΘ=150,βgˆW=150,βgˆΘ=150,βuˆD,W=500, andβuˆD,Θ=500; the slopes of tanh(·) at the origin are respectively selected as κ=18 forfˆ(⋅)andgˆ(⋅)and κ=100 foruˆD; gLand δ=0.2 are selected for the compensation controller. All of the resistance and capacitance are chosen as R=5Ω and C=0.005F. Solving the Riccati-like Eq. (28) for a choice of Q=3I, Kc=[375]T, we haveP=5.83.90.5;3.96.50.8;0.50.80.5. The reference signals yr, the system states x1, and x2 are shown in Fig. 3(for case 1) and Fig. 6 (for case 2). In Figs. 4 and 7, Fig. 4(a) (for case 1) and Fig. 7(a) (for case 2) show the associated control input u, as shown in Eq. (57). Fig. 4(b) (for case 1) and Fig. 7(b) (for case 2) show the indirect control input uI. Fig. 4(c) (for case 1) and Fig. 7(c) (for case 2) show the direct control input. Fig. 4(d) (for case 1) and Fig. 7(d) (for case 2) show the compensation control input uc. Figs. 5 and 8show the variations ofgˆx. The switching boundaries mean the moments while we switch the adaptive controller from the IAC (or DAC) to the DAC (or IAC). From Figs. 3–8, we observe that the output of the system well tracks the reference signal throughout the whole control process even thoughgˆxstays near zero, as shown in Figs. 5 and 8, or the tracked signal drops from 1 to 0, as shown in Fig. 6.Consider the following nonlinear dynamic system described as(58)x˙1=x2x˙2=x3x˙3=x1x2+u+d,where d=0.5sin(t) is the external bounded disturbance, and x1, x2, and x3 stand for the system states. The reference signals are respectively chosen as yrt=sin(0.5t)+cos(t) (for case 1) and a step function (for case 2), and the switch boundaries are respectively set to ɛs=0.5 (for case 1) and ɛs=0.08 (for case 2). The initial parameters of SACHNN are chosen as[x10x20x30]T=[000]T(for case 1) and[x10x20x30]T=[0.900]T(for case 2),ξfˆw0=0,ξfˆΘ0=000,ξgˆw0=0,ξgˆΘ0=000,ξuˆD,W0=000,ξuˆD,Θ0=000,Θˆfˆ0=000TΘˆgˆ0=000TandΘˆuˆD0=000T.MfˆW,MfˆΘ,MgˆW,MgˆΘ, andMuˆD,Θare set to 1.36×10−3, andWˆfˆ0,Wˆgˆ0,andWˆuˆD0are randomly selected within [0,1]. These initial settings are chosen through the trial-and-error method to achieve favorable control performance. All of the resistance and capacitance are chosen as R=5ΩandC=0.005F. Solving the Riccati-like Eq. (28) for a choice of Q=3I, Kc=[375]T, we haveP=5.83.90.5;3.96.50.8;0.50.80.5. In the case 1, the learning rates of weights adaption are selected asβfˆW=150,βfˆΘ=150,βgˆW=150,βgˆΘ=150,βuˆD,W=5000, andβuˆD,Θ=5000; the slopes of tanh(·) at the origin are respectively selected as κ=200 forfˆ(⋅),gˆ(⋅), anduˆD; gL=0.1 and δ=0.02 are selected for the compensation controller. In the case 2, the learning rates of weights adaption are selected asβfˆW=150,βfˆΘ=150,βgˆW=150,βgˆΘ=150,βuˆD,W=5000, andβuˆD,Θ=5000; the slopes of tanh(·) at the origin are respectively selected as κ=200 forfˆ(⋅),gˆ(⋅), anduˆD; gL=0.1 and δ=0.02 are selected for the compensation controller. The reference signals yr, the system states x1 and x2, and disturbance d are shown in Fig. 9(for case 1) and Fig. 12 (for case 2). In Figs. 10 and 13, Fig. 10(a) (for case 1) and Fig. 13(a) (for case 2) show the associated control input u, as shown in Eq. (57). Fig. 10(b) (for case 1) and Fig. 13(b) (for case 2) show the indirect control input uI. Fig. 10(c) (for case 1) and Fig. 13(c) (for case 2) show the direct control input. Fig. 10(d) (for case 1) and Fig. 13(d) (for case 2) show the compensation control input uc. Figs. 11 and 14show the variations ofgˆx. The switching boundaries mean the moments while we switch the adaptive controller from the IAC (or DAC) to the DAC (or IAC). From Figs. 9 to 14, we observe that the output of the system well tracks the reference signal throughout the whole control process even thoughgˆxstays near zero, as shown in Figs. 11 and 14, or the tracked signal drops from 1 to 0, as shown in Fig. 12.

@&#CONCLUSIONS@&#
A SACHNN with a compensating controller for a class of unknown nonlinear dynamic systems is proposed in this paper. It is a flexible design methodology by the trade-off between indirect and direct adaptive control according to a predefined threshold value, which is used to define how near to zero the approximatorgˆ(x)is. According to the Lyapunov synthesis approach, the free parameters of the SACHNN can be tuned on-line by a state feedback control law and adaptive laws. The direct adaptive controller is activated to force the states to be within the constraint set as soon as the approximatorgˆ(x)approaches to zero. On the other hand, if the indirect adaptive controller works well, the direct adaptive controller is deactivated. In the simulation results, two nonlinear systems are fully illustrated to track sinusoidal signals.