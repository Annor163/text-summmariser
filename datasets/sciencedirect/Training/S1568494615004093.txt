@&#MAIN-TITLE@&#
Profit-based feature selection using support vector machines – General framework and an application for customer retention

@&#HIGHLIGHTS@&#
A novel profit-based feature selection method for churn prediction with SVM is presented.A backward elimination algorithm is performed to maximize the profit of a retention campaign.Our experiments on churn prediction datasets underline the potential of the proposed approaches.

@&#KEYPHRASES@&#
Data mining,Feature selection,Support vector machines,Churn prediction,Customer retention,Maximum profit,

@&#ABSTRACT@&#
Churn prediction is an important application of classification models that identify those customers most likely to attrite based on their respective characteristics described by e.g. socio-demographic and behavioral variables. Since nowadays more and more of such features are captured and stored in the respective computational systems, an appropriate handling of the resulting information overload becomes a highly relevant issue when it comes to build customer retention systems based on churn prediction models. As a consequence, feature selection is an important step of the classifier construction process. Most feature selection techniques; however, are based on statistically inspired validation criteria, which not necessarily lead to models that optimize goals specified by the respective organization. In this paper we propose a profit-driven approach for classifier construction and simultaneous variable selection based on support vector machines. Experimental results show that our models outperform conventional techniques for feature selection achieving superior performance with respect to business-related goals.

@&#INTRODUCTION@&#
Classification is a very relevant task in many profit-driven applications, such as e.g. credit scoring or customer retention [3]. It has been shown that the performance of a classifier can be improved by concentrating on the most relevant features used for classifier construction. Such variable selection has important advantages: first, a low-dimensional representation of the objects enhances the predictive power of classification models by decreasing their complexity. Having less features also leads to more parsimonious models which in turn contributes to reduce the risk of overfitting [9] caused by the curse of dimensionality[19,30].Additionally, it allows a better interpretation of the classifier, which is particularly important in business analytics. Many machine learning approaches are usually labeled as black boxes by practitioners, who therefore tend to be reluctant to use the respective methods [10]. A better understanding of the process that generates the data is therefore of crucial importance in business analytics for decision-making, e.g., by identifying those attributes that permit explaining customers’ decisions [7].In the past, statistically inspired techniques have been the most frequently used approaches to validate both classifiers as well as feature selection methods. Recently, profit-based measures have been suggested for classifier validation [35]. In this paper we go one step further and adapt the idea of profit-driven metrics also to the task of feature selection by introducing several embedded methods combining the method Holdout support vector machine (HOSVM) [26] with various validation measures.To the best of our knowledge, profit-driven feature selection is a novel approach that has not yet been covered in the data mining and machine learning literature. Most of the work in business analytics and feature selection applies traditional, statistically grounded techniques without taking into account profit-related issues. Our experiments underline that the proposed methods outperform alternative techniques and provide classifiers with highly relevant features, thus reducing the risk of overfitting while increasing the related profit at the same time.The remainder of the paper is organized as follows: Section 2 describes the cost benefit analysis in the context of customer retention. Section 3 presents support vector machines for classification and the feature selection techniques studied in this work. The proposed profit-based approach for feature selection and classification is presented in Section 4. Section 5 provides experimental results using real-world datasets. A summary of this paper can be found in Section 6, where we provide its main conclusions and address future developments.Trying to retain customers that are about to leave the company is one of the most important tasks in the service industry, mainly in the banking and telecommunications sector. This is driven by the increasing number of customers willing to change their provider, and the strong competition for attracting new ones. Therefore, there is an urgent need to develop and apply accurate models in order to identify current customers who are most likely to leave the company in a given period of time. Churn can be observed in two different ways, voluntary, meaning that the customer decides to terminate the contract, or involuntary, where the company decides to finish the contract with the customer [4]. In the present work we focus on churn as a voluntary decision.If a company is able to identify potential churners, the next step is to develop marketing campaigns, and retention strategies focusing on this particular group, thus enhancing customer loyalty and leading to major benefits, such as e.g.:•Loyal engaged customers, can generate 1.7 times more revenue than other customers [18].A direct impact on profitability: a 5% increment in the customer retention rate may lead to a 18% reduction in operational costs [18].A decrease of money misspending, focusing resources on churn candidates instead of the whole customer database, reducing marketing and operational costs [15].According to this, the churn rate is explicitly included in the following customer lifetime value (CLV) formula [4]:(1)CLV=∑t=1∞m(1−c)t−1(1+r)t−1=m(1+r)(r+c)where c is the annual churn rate and m stands for the mean of the annual profit contribution per customer. Parameter r is the annual discount rate. There are two classical approaches to determine this value. The first one is the company's weighted average cost of capital (WACC). The second one is to use the discount rate of the particular industrial sector. Given this formula, and understanding the CLV as the net present value of the profit for a customer, a decreasing churn rate will impact heavily on the company's profitability.Churn phenomena can be modeled either with time-dependent techniques [4], or with single period future predictions. In the first category, this kind of models tries to not assume that the churn will occur in a given period, determining probabilities of churning up to a number of months, and taking into consideration time-varying covariates [4]. In the latter, we find approaches aiming to predict if a customer decides to churn in the next period, where the most common approaches are based on statistical methods, such as logistic regression [8,23,29], non-parametric statistical models such as k-nearest neighbor [13], decision trees [39], and other machine learning techniques [15,36]. A review on customer churn prediction modeling can be found in [37]. Here we use SVM classifiers to predict churn in a single period. Churn rates usually are below 5% [35] for this kind of classification models, leading to the class-imbalance problem as will be seen in Section 5.In this section we present the foundations of SVM for binary classification and the different feature selection strategies available in the literature, and we provide a brief description of each method used in this work.Among existing classification methods, support vector machine provides several advantages such as adequate generalization to new objects due to the structural risk minimization principle, absence of local minima via convex optimization, and representation that depends on only a few data points (the support vectors). All these features reduce the risk of overfitting in classification [34]. Additionally, the introduction of kernel functions for nonlinear classification enhances performance via flexible classifiers, in contrast to traditional techniques such as logistic regression.LetFbe the feature set,xi∈R|F|the feature vector and yi∈{−1, 1} the class label of object i, i=1, …, N.T={(xi,yi);i=1,…,N}denotes the training set.In our case, xiis the feature vector describing customer i and yiindicates his/her class label; churners (non-churners) are identified by yi=1 (yi=−1).Linear SVM constructs an optimal hyperplane f(x)=w⊤x+b which tries to correctly separate one class from the other. To achieve this optimal hyperplane, SVM aims to maximize its margin, defined as the sum of the distances (with a given metric) between the hyperplane to the closest positive and negative training patterns. This is equivalent to minimizing the Euclidian norm of w[34]. Given that a perfect separation between the two classes is not always possible, a slack variable ξiis introduced for each training vector xi, i=1, …, N whereby C is used as a penalization parameter to control the training error [34] as shown in model (2).(2)minw,b,ξ12∥w∥2+C∑i=1Nξis.t.yi·(w⊤xi+b)≥1−ξi,i=1,…,N,ξi≥0,i=1,…,N.The previous formulation can be extended to nonlinear classifiers by using the kernel trick: the training samples are mapped into a higher dimensional domainHthrough the function ϕ:x→ϕ(x)∈H[31]. A kernel function K(x, y)=ϕ(x)⊤·ϕ(y) defines an inner product in spaceH, leading to the following dual formulation:(3)maxα∑i=1Nαi−12∑i,s=1NαiαsyiysK(xi,xs)s.t.∑i=1Nαiyi=0,0≤αi≤C,i=1,…,N.In this work we use both linear SVM as well as the kernel-based formulation with Gaussian kernel, which usually achieves very good results and is a common choice in the literature [26,31]. This kernel function has the following form:(4)K(xi,xs)=exp−||xi−xs||22σ2where σ>0 controls the kernel width.There are three main approaches developed for feature selection (for further information see [19]):•Filter methods: These methods take place before applying any classification algorithm, and use statistical properties of the features aiming at filtering out the ones that contribute less information. Classical examples are χ2statistic, which measures how independent the distribution of each feature against the class labels is [33], Information Gain (also known as mutual information) which uses information entropy in order to decide how relevant a given feature is [5,33], and the Fisher criterion score (F), which estimates each feature's relevance independently of the others, as shown in (5):(5)F(j)=μj+−μj−(σj+)2+(σj−)2whereμj+(μj−) is the mean of the jth feature's values in the positive (negative) class andσj+(σj−) is the corresponding standard deviation.Wrapper methods: These methods go through the set of features in order to score possible feature subsets regarding their predictive potential. This approach is computationally demanding because it has an exponential size on the input, but in most cases provides better results than filter methods [19,24]. The most popular wrapper strategies are sequential forward selection (SFS) and sequential backward elimination (SBE). SFS starts with an empty set of features, and then tries out the features one at a time, and includes in each iteration the most relevant one (according to a particular classification method) of the remaining set. SBS is the opposite of the first method, starting with the entire feature set and calculates one by one their statistical significance, eliminating in each iteration the least significant one.Embedded methods: These models perform feature selection simultaneously with classifier construction, which means searching in the combined space of both hypotheses and features. Similar to wrapper methods, this approach is specific for each classification method, and therefore includes the relation of the feature dependencies with the classifier. However, embedded methods are computationally less intensive than wrapper methods [19].These three feature selection strategies are depicted in Fig. 1. Backward elimination approaches are the most common strategy for wrapper or embedded feature selection due to the before-mentioned advantages [19]. Therefore we used this strategy for feature selection.One popular embedded method, which is relevant for the remainder of this paper, is known as recursive feature elimination (RFE-SVM) [20]. The goal of this approach is to find a subset of size r among|F|variables (r<|F|), eliminating those features whose removal leads to the largest margin of class separation. Since the margin is inversely proportional to the Euclidean norm of the weight vector, this value can be rewritten in terms of the dual variables of SVM:(6)W2(α)=∑i,s=1NαiαsyiysK(xi,xs).The RFE-SVM algorithm can be extended in several ways. In particular, in [26] we proposed a modification of the contribution measure (6) based on the misclassification errors instead of the margin. The backward elimination algorithm was also modified, including a holdout step: the classifier was trained on a training subset, while the number of misclassified instances was computed on a validation subset extracted from the training set, leading to the HOSVM method.Feature selection can also be an unsupervised task [1]. Unsupervised feature selection focus on a target concept rather than on class labels, where observations that are close to each other in the feature space should belong to the same target concept [41,42]. Some approaches that follow this principle using spectral graph theory are SPEC [41] and Laplacian Score [22]. In the same context, Zhang and Hancock [40] proposed a feature selection strategy based on hypergraph clustering.We propose different embedded methods for profit-based feature selection using support vector machines which are inspired by HOSVM [26]. The rationale behind our approaches is that we eliminate those features whose removal has the least impact on the final profit, considering the respective costs and benefits. This will be measured using profit-based metrics, namely MPC and EMPC, as well as using the H measure, leading to the feature selection methods called HOSVMMPC, HOSVMEMPC, and HOSVMH, respectively.To evaluate the respective models, a variety of performance measures has been proposed in the literature [35]. Section 4.2 provides a detailed description of such metrics. In Section 4.3 we present our methods for profit-based feature selection and classification. While in this paper we focus on churn prediction, the respective methods are introduced in a rather generic way to facilitate their use in different applications.For a given sample x, a classifierCwill produce a score s∈[0, 1], where by convention a high score means the corresponding customer is more likely to churn. A threshold value t is defined to provide a crisp classification of all customers based on their scores. All instances with s≤t are classified as non-churners (y=−1), whereas instances for which s>t are classified as churners (y=1).Following the notation presented in [35], we define:•Prior probabilities: π−1 and π1 are the prior probabilities of a given sample to belong to class −1 or 1, respectively.Probability distributions: For a given score s, the probability density functions for non-churners and churners are f−1(s) and f1(s), respectively, whereas the cumulative density functions are denoted by F−1(s) and F1(s).Cost–benefit terms: We define b−1 (b1) as the benefit of a correctly classified non-churner (churner), and c−1 (c1) as the cost of a misclassified non-churner (churner). We also define θ=(b1+c1)/(b−1+c−1) as the cost–benefit ratio to simplify notation. Both, the optimal threshold as well as the profit will depend only on this ratio of costs and benefits.The literature proposes various performance measures for classification models; see e.g. [12]. A frequently used measure is the AUC, which is the area under the ROC curve. A receiver operating characteristic (ROC) curve is a graphical representation of the classification performance with varying threshold t, or, in other words, a plot of the sensitivity versus one minus the specificity, i.e. F−1(t) as a function of F1(t):Sensitivity=F−1(t),Specificity=1−F1(t),AUC=∫F−1(s)f1(s)ds.The area under the ROC-curve is often used to assess a classifier's performance. In simple terms, the AUC of a classification method is the probability that a randomly chosen positive observation will be ranked higher than a randomly chosen negative one [16]. A larger AUC indicates better performance. Sensitivity and specificity are useful to compute the AUC, and also to obtain the contribution metrics used in our proposal. In particular, the profit function is computed based on sensitivity and specificity.The problem with traditional measures, such as AUC, is that they implicitly make unrealistic assumptions about misclassification costs [21,38]. Several performance metrics have been proposed to overcome this problem. Those relevant for the present work on churn prediction will be described, but first we analyze the cost benefit structure of customer churn models.When setting up a customer retention campaign, a fraction η of the customers with the highest propensity to churn is contacted (incurring a cost of f per person) and an incentive to stay leading to a monetary cost d is offered. Among these customers there are true would-be churners and false would-be churners. We assume that in the latter group everyone accepts the incentive and does not churn, because they did not have the intention in the first place [38]. For the former group, on the other hand, a fraction γ accepts the offer and thus results in an earned customer lifetime value (CLV) (Eq. (1)), whereas the fraction (1−γ) effectively churns despite the incentive. In the other fraction (1−η) of customers, which is not contacted, all would-be churners churn, and all non-churners stay with the company. This process is summarized in the following formula [29]:(7)Profit=Nη[(γCLV+d(1−γ))π−1λ−d−f]−A,where η is the targeted fraction of customers, CLV is the customer lifetime value (see Eq. (1)), d is the cost of the incentive (offer), f is the cost of contacting the customer, and A are the fixed administrative costs. The lift coefficient λ is the fraction of churners in the targeted fraction η of customers divided by the base churn rate for all the customers π−1[35]. Finally, γ is interpreted as the probability of a contacted churner accepting the incentive and thus not churning. Here CLV, A, f, and d are positive, and for coherence CLV>d. In this scheme it is clear that η depends on the choice of the threshold t, and this enables the company to decide upon the fraction of customers to be targeted by the retention campaign.We study the average profit instead of the total profit, and discard the fixed cost, A, since this cost is independent to the choice of classifier. We define the average classification profit of a classifier for customer churn as follows:(8)PC(t;γ,CLV,δ,ϕ)=CLV(γ(1−δ)−ϕ)π−1F−1(t)−CLV(δ+ϕ)·π1F1(t).whereδ=dCLVandϕ=fCLV. We also note that b−1=CLV(γ(1−δ)−ϕ), and c1=CLV(δ+ϕ).Given a training set of customersTwith featuresFwe study three different measures, described as follows:•The maximum profit criterion for customer churn (MPC): If we assume that all the parameters in Eq. (8) are known, for a given classifierCwe will obtain a deterministic performance measure. Taking the maximum value over all possible thresholds, we have the following assessment metric [35]:(9)MPC=maxtPC(t;γ,CLV,δ,ϕ).This way we obtain the fraction of the customers that should be targetedη¯mpcin order to maximize the profit generated by the retention campaign, given by:(10)η¯mpc=π−1F−1(T)+π1F1(T),with(11)T(γ)=argmaxtPC(t;γ,CLV,δ,ϕ).The expected maximum profit measure for customer churn (EMPC): In this particular case and following [38], we model γ, the probability of a churner accepting the incentive, as a Beta distributed random variable, leading to the following formula for the expected maximum profit for a classifierC:(12)EMPC=∫γPC(T(γ);γ,CLV,δ,ϕ)·h(γ)dγ,with T(γ) being the optimal threshold (Eq. (11)) and h(γ) the probability density function for γ. The parameters α and β related to the Beta distribution of γ were obtained from a previous work in churn prediction [38]. Analogous to MPC, the percentage of the customers targeted in the retention campaign for this metric is equal to:(13)η¯EMPC=∫γ[π−1F−1(T(γ))+π1F1(T(γ))]·h(γ)dγ,It is important to note the influence of γ in this equation since it has a direct impact on the cost benefit ratio:(14)θ=b1+c1b−1+c−1=δ+ϕγ(1−δ)−ϕThe H-measure: Hand [21] proposed the H measure as an alternative to the AUC. The difference between H-measure and MP-measures is that H only focusses on costs. Hence, the focus is not on the expected maximum profit, but on the expected minimum loss, defining the average classification loss Q as:(15)QC(t;c,b)=b·[cπ−1(1−F−1(t))+(1−c)π1F1(t)],with c=c0/c−1+c1 and b=c−1+c1. Here, the cost–benefit ratio on which the optimal threshold T depends, is θ=(1−c)/c.Calculating the value of the expected minimum loss requires assumptions on the probability density functions of both b and c. Assuming that b and c are independent, and definingw(b,c)as the joint probability density function of b and c, whereas u(c) andv(b)are the marginal probability density functions of c and b, respectively, the explicit relationship between these densities isw(b,c)=u(c)·v(b). Hence, the expected minimum loss L is equal to:(16)L=E[b]∫01QC(T(c);b,c)·u(c)dc,with E[b]=1 for an appropriate choice for the unit in which b is measured. We assume that c follows a Beta distribution with parameters α and β, characterized as follows:(17)uα,β(x)=xα−1·(1−x)β−1B(1,α,β)ifx∈[0,1],0else,with α, β>1, and:(18)B(x,α,β)=∫0xtα−1·(1−t)β−1dt.Finally, to arrive at the H measure, a normalization is performed to obtain a performance measure bounded by zero and one:(19)H=1−∫01QC(T(c);b,c)·u(c)dcπ0∫0π1c·u(c)dc+π1∫π11(1−c)·u(c)dc,here u(c) is shorthand notation for uα,β(c). The denominator gives the misclassification loss for the worst classifier, namely a random classifier. Note also that the integration over c∈[0, 1] corresponds to an integration over θ∈[0, +∞), and thus of a ROC curve tangent slope going from plus infinity to zero.Since we are dealing with class-imbalanced data, we first redefine the Holdout SVM algorithm to incorporate a resampling step. We propose and empirically study two strategies: random undersampling and a combination of random undersampling with SMOTE, an intelligent resampling technique. The purpose of the algorithm is to find a subsetK(K⊆F)of features, such that the performance of the SVM classifier using this subset's features is maximized, considering a training setT. This set is split into a training subsetTRand a validation subsetV. The training subsetTRis resampled into a new subsetTR′, where the classifier is constructed, in order to achieve a balanced classification problem. The validation subset is finally used to construct a suitable loss function for the churn prediction problem. Accordingly, the Holdout approach for profit-based feature elimination and classification is provided in Algorithm 1.Algorithm 1Holdout algorithm for profit-based feature elimination and classificationInput: The original set of featuresFOutput: An ordered vector of featuresF†1.F†←∅2. repeat3.(TR,V)←HoldoutusingT4.TR′←Resampling(TR)5.Λ←SVMTrainingusingTR′6.I←argminI∑j∈ILOSS(−j)(Λ,TR′,V),I⊂F7.F←F\I8.F†←(F†,I)9. untilF=∅The SVM classifier trained inTR′(Step 5) is given by Λ=(α, b), and this information is an input forLOSS(−j)(Λ,TR′,V), the novel loss functions we propose in this work. Here we suggest to calculate measures MPC, EMPC, and H using subsetVwhen attribute j is removed. Intuitively, the attribute whose removal leads to a higher profit (or a lower cost, for the H metric) has to be eliminated from the dataset. To adapt these metrics, we first notice that our proposals only differ with the original versions of MPC, EMPC, and H in the computation of the score (and therefore the probability distributions), while the cost and benefits of a given solution as well as the definition of γ are not affected. Following the ideas of the contribution measures for RFE-SVM and HOSVM, we definesk(−j), i.e. the score of a samplek∈Vwhen attribute j is removed as follows:(20)sk(−j)(Λ,TR′,V)=∑i∈TR′αiyiK(xi(−j),xkv(−j))+bwherexi(−j)is a sample from the resampled training subset when attribute j is removed andxkv(−j)means validation object k with feature j removed. To reduce the algorithm's computational complexity, the vector α is assumed to be equal to the solution of formulation (4) even if one attribute has been removed, as suggested in [20].The following loss functions are proposed for Step 6 of the algorithm, where the only difference between the original metrics is the redefinition of probability distributions based on the new score formula s(−j):•H measure:(21)LOSS(−j)(Λ,TR′,V)=H(s(−j))Maximum profit (MPC):(22)LOSS(−j)(Λ,TR′,V)=MPC(s(−j))Expected maximum profit (EMPC):(23)LOSS(−j)(Λ,TR′,V)=EMPC(s(−j))Using these loss functions in Step 6 of the algorithm leads to the three variants of our proposed approach called HOSVMH, HOSVMMPC, and HOSVMEMPC, respectively.Finally, in Step 6 the algorithm determines a setIof features to be eliminated. While one could choose a single element ofF, this would be inefficient if there are many irrelevant features. On the other hand, removing too many features at a time increases the risk of eliminating relevant features [20].

@&#CONCLUSIONS@&#
In this work we present a backward elimination approach for classification and embedded feature selection using SVM. The proposed method studies three different evaluation measures suitable for class-imbalance problems, and, in particular, for churn prediction problems: the H measure, the MPC metric, and the EMPC measure. While the H measure provides a framework to explicitly consider the misclassification costs as a measure of predictive performance [21], MPC [35] and EMPC [38] go one step further and incorporate the benefits of retention campaigns into the churn prediction task, resulting in very powerful and goal-oriented metrics for model assessment. The main difference between MPC and EMPC is that the latter considers the decision of a potential churner to accept a retention incentive as a random variable, and then computes the expected profit of the retention campaign for telecommunication companies.In contrast to the available literature on this topic, which aims at selecting the best model among various classification methods using statistically motivated performance measures, our objective is to provide a framework that allows the adequate selection of the hyperparameters and the right features for classifier construction, focusing on one method, namely support vector machines, but using profit-based performance measures. Our approach presents the following advantages, based on a comparison with other feature selection approaches for support vector machines in churn prediction applications:•The proposed method allows to explicitly incorporate costs and benefits obtained from the classification task for churn prediction, leading to a feature selection process especially designed for this particular application.The proposed approach achieves better predictive performance than other feature selection techniques in churn prediction problems, considering both traditional assessment metrics (such as AUC) and profit-based measures.Our strategy is very flexible and allows using different kernel functions for nonlinear feature selection and classification using SVM. Furthermore, it can also be extended to other classification methods than SVM.There are several opportunities for future work. The feature selection process can be extended to other business analytics applications, such as e.g. credit scoring [6,32]. While the EMPC metric can be adapted to incorporate the costs and benefits of accepting or rejecting loan applicants, logistic regression can be set as the baseline classifier, which is the most common classification method for this task due to regulatory reasons [32]. Additionally, the costs of variable acquisition and usage can be incorporated into the model, enriching the feature selection process. A step in this direction was presented in [25], where the features’ costs are explicitly incorporated into the model via binary variables and a budget constraint. Another venue for future research would be the extraction of business rules from a developed SVM-model in order to gain interpretability; see e.g. [27].