@&#MAIN-TITLE@&#
A framework for estimating relative depth in video

@&#HIGHLIGHTS@&#
A method for generating sparse, relative depth estimates from video.Depth estimates can be generated without access to past or future frames.Depth maps are created through efficient filter-based propagation.Results are favourable when compared to more expensive SfM+MVS techniques.

@&#KEYPHRASES@&#
Depth estimation,2D-to-3D conversion,Video processing,Image processing,Edge-aware filtering,Label interpolation,

@&#ABSTRACT@&#
We present a method for efficiently generating dense, relative depth estimates from video without requiring any knowledge of the imaging system, either a priori or by estimating it during processing. Instead we only require that the epipolar constraint between any two frames is satisfied and that the fundamental matrix can be estimated. By tracking sparse features across many frames and aggregating the multiple depth estimates together, we are able to improve the overall estimate for any given frame. Once the depth estimates are available, we treat the generation of the depth maps as a label propagation problem. This allows us to combine the automatically generated depth maps with any user corrections and modifications (if so desired).

@&#INTRODUCTION@&#
Depth information is useful for a variety of different image processing applications [1]. One such application is 2D-to-3D conversion whereby a single “2D” image or video is converted into a stereoscopic “3D” image or video, often through Depth-based Image Rendering (DBIR) [2]. DBIR is only possible if a depth map is available.A depth map is a monochromatic image where each pixel indicates how far that particular pixel in the original image is from the camera. Obtaining a depth map is a non-trivial procedure as there are many different ways to accomplish this. One such method is to apply computer vision techniques [3] such as Structure from Motion (SfM) and Multi-View Stereo (MVS) to obtain highly accurate depth maps for each frame in a video. These techniques are extremely powerful; the results that they return are representative of the actual imaged scene up to some scale factor.However, a complete reconstruction is often unnecessary. DBIR, for instance, is used to generate a stereo pair that is pleasant to view but not necessarily one that reflects the actual camera setup. In this case, a relative depth map is sufficient as the ordering between objects is more important than their actual depths [4].In our earlier work [5], we treated the tracking and depth estimation separately. We also made no attempt at rejecting frame pairs where there was insufficient camera motion. Here, we unify the tracking and estimation into a single depth estimation framework and make the method more resistant to degenerate camera configurations. We still treat the map generation as a labelling problem but we improve on the propagation method. We also provide several different strategies for performing the propagation.Our primary contribution in this paper is a novel framework for estimating sparse, relative depth in a computationally efficient fashion. Our secondary contributions are demonstrating how edge-aware filters can be used to generate dense depth maps and addressing certain numerical issues that arise with using these filters. We demonstrate this framework on a variety of footage to demonstrate its efficacy in different scenarios.

@&#CONCLUSIONS@&#
