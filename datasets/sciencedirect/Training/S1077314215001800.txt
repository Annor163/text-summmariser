@&#MAIN-TITLE@&#
MODS: Fast and robust method for two-view matching

@&#HIGHLIGHTS@&#
A novel algorithm for wide-baseline matching called MODS is presented.View synthesis for affine detectors boosts performance.Iterative scheme “do only as much as needed” principle reduces runtime.New challenging extreme zoom and viewpoint datasets are presented.

@&#KEYPHRASES@&#
Wide baseline stereo,Image matching,Local feature detectors,Local feature descriptors,

@&#ABSTRACT@&#
A novel algorithm for wide-baseline matching called MODS—matching on demand with view synthesis—is presented. The MODS algorithm is experimentally shown to solve a broader range of wide-baseline problems than the state of the art while being nearly as fast as standard matchers on simple problems. The apparent robustness vs. speed trade-off is finessed by the use of progressively more time-consuming feature detectors and by on-demand generation of synthesized images that is performed until a reliable estimate of geometry is obtained.We introduce an improved method for tentative correspondence selection, applicable both with and without view synthesis. A modification of the standard first to second nearest distance rule increases the number of correct matches by 5–20% at no additional computational cost.Performance of the MODS algorithm is evaluated on several standard publicly available datasets, and on a new set of geometrically challenging wide baseline problems that is made public together with the ground truth. Experiments show that the MODS outperforms the state-of-the-art in robustness and speed. Moreover, MODS performs well on other classes of difficult two-view problems like matching of images from different modalities, with wide temporal baseline or with significant lighting changes.

@&#INTRODUCTION@&#
The wide baseline stereo [1] problem—the automatic estimation of a geometric transformation and the selection of consistent correspondences between view pairs separated by a wide baseline—has received significant attention in the last 15 years [2,3]. State-of-art local feature detectors [4–7] and descriptors [6–8] allow to match images of a scene with a viewing angle difference up to 60° for planar objects [9] and 30° for non-planar 3D objects [10]. Fast detectors [11,12] and binary descriptors [13–15] make matching significantly faster at the cost of decreasing tolerance to scale, rotation and affine changes. At the other end of the spectrum of wide baseline problems, the ASIFT matching scheme [16,17], increased the range of handled viewing angle differences up to the 80° at the cost of a significant slow-down.We propose a novel two-view matching algorithm called MODS—matching on demand with view synthesis—that handles viewing angle difference even larger than the state-of-the-art ASIFT algorithm, without a significant increase of computational costs over “standard” wide and narrow baseline approaches. The performance gain is achieved by introducing a number of improvements to the wide-baseline matching process.First, MODS employs a combination of different detectors. It is known that different detectors are suitable for different types of images [9] and that some detectors are complementary in the type of structures in the image they respond to Aanaes and Dahl [18]. Moreover, we show that the combination of the different detectors allows increasing the average speed of the matching and to match pairs of images which cannot be solved by any of the detectors alone. The results indicate that searching for the “best” detector leads to data- and problem-specific outcomes and that exploiting multiple detectors is superior to any single one.Second, we introduce an iterative scheme which follows the “do only as much as needed” principle. Progressively more powerful yet slower detectors and descriptors are applied, together with more images synthesized on-demand, until sufficient support for a two-view geometry estimate is obtained. Such on demand approach finesses an apparent robustness vs. speed trade-off, avoiding the slowdown for easy wide baseline problems brought by the time-consuming operations needed for solving the most challenging pairs.Third, a novel tentative correspondences generation strategy is presented which generalizes the standard first to second closest distance ratio [6]. The selection strategy which shows performance superior to the standard method is applicable to any vector descriptor like SIFT [6], LIOP [19] and MROGH [20].The parameters of the MODS algorithm were optimized and its performance thoroughly evaluated. The optimization included the selection of the particular sequence of feature detectors, the choice of the number and parameters of images synthesized to facilitate matching and the parameter setting of the individual detectors.The performance of the MODS algorithm was validated on several publicly available datasets and it was compared to the state-of-the-art in both speed and robustness, i.e. the ability to recover the two-view geometry reliably. We show that MODS significantly outperforms prior approaches in both robustness and speed. We have collected a set of image pairs for evaluating MODS on wide baseline problems with very large angular difference between views. These form the Extreme View Dataset. The dataset with the ground truth and the source code of the MODS algorithm is available on the authors web-page.11Available at http://cmp.felk.cvut.cz/wbs/index.html.

@&#CONCLUSIONS@&#
An algorithm for two-view matching called MODS algorithm was introduced. The most important contributions of the algorithm are its ability to adjust its complexity to the problem at hand, and its robustness, i.e. the ability to solve a broader range of wide-baseline problems than the state of the art. This is achieved while being fast on simple problems.The apparent robustness vs. speed trade-off is finessed by the use of progressively more time-consuming feature detectors, and by on-demand generation of synthesized images that is performed until a reliable estimate of geometry is obtained. The MODS method demonstrates that the answer to the question “which detector is the best?” depends on the problem at hand, and that it is fruitful to focus on the “how to combine detectors” problem.We are the first to propose view synthesis for two-view wide-baseline matching with affine-covariant detectors, which is superficially counter-intuitive, and we show that matching with the Hessian-Affine or MSER detectors outperforms the state-of-the-art ASIFT. View synthesis performs well when used with simple and very fast detectors like ORB, which obtains results similar to ASIFT but in orders of magnitude shorter time.Minor contributions include an improved method for tentative correspondence selection, applicable both with and without view synthesis and a modification of the standard first to second nearest distance rule increases the number of correct matches by 5–20% at no additional computational cost.The evaluation of the MODS algorithm was carried out both on standard publicly available datasets as well as a new set of geometrically challenging wide baseline problems that we collected and will make public. The experiments show that the MODS algorithm solves matching problems beyond the state-of-the-art and yet is comparable in speed to standard wide-baseline matchers on easy problems. Moreover, MODS performs well on other classes of difficult two-view problems like matching of images from different modalities, with large difference of acquisition times or with significant lighting changes.