@&#MAIN-TITLE@&#
A novel artificial bee colony algorithm with Powell's method

@&#HIGHLIGHTS@&#
A modified search equation is proposed.Powell's method is used as a local search tool to enhance the exploitation of ABC.Further, a novel ABC is presented.Numerical simulation demonstrates the effectiveness of PABC.

@&#KEYPHRASES@&#
Evolutionary algorithms,Artificial bee colony algorithm,Search equation,Powell's method,

@&#ABSTRACT@&#
Artificial bee colony (ABC) algorithm is a relatively new optimization technique which has been shown to be competitive to other population-based algorithms. However, there is still an insufficiency in ABC regarding its solution search equation, which is good at exploration but poor at exploitation. To address this concerning issue, we first propose a modified search equation which is applied to generate a candidate solution in the onlookers phase to improve the search ability of ABC. Further, we use the Powell's method as a local search tool to enhance the exploitation of the algorithm. The new algorithm is tested on 22 unconstrained benchmark functions and 13 constrained benchmark functions, and are compared with some other ABCs and several state-of-the-art algorithms. The comparisons show that the proposed algorithm offers the highest solution quality, fastest global convergence, and strongest robustness among all the contenders on almost all test functions.

@&#INTRODUCTION@&#
The algorithms for global optimization problems are of increasing importance in many fields of science and engineering. They can be divided into two categories: derivative-based methods and derivative-free methods. For a variety of reasons there have always been many real-world problems where derivatives are unavailable or unreliable. Thus, as an important branch of derivative-free methods, evolutionary algorithms (EAs) have shown considerable evolutionary algorithms (EAs) have shown considerable success in solving optimization problems characterized by nonconvex, discontinuous, non-differentiable and so on, and attracted more and more attention in recent years. The most prominent EAs proposed in the literatures are genetic algorithm (GA) [1], particle swarm optimization (PSO) [2], differential evolution (DE) [3], ant colony optimization (ACO) [4], biogeography-based optimization (BBO) [5] and artificial bee colony (ABC) algorithm [6] and so on.In this paper, we concentrate on ABC, developed by Karaboga [6] in 2005 based on simulating the foraging behavior of honey bee swarm. Numerical comparisons demonstrated that the performance of ABC is competitive to that of other population-based algorithms with an advantage of employing fewer control parameters [7–10]. Due to its simplicity and ease of implementation, ABC has captured much attention and has been applied to solve many practical optimization problems [11–13] since its invention.However, the solution search equation of ABC is good at exploration but poor at exploitation [14], which results in the poor convergence. To improve the performance of ABC, a number of variant ABC algorithms have, hence, been proposed to achieve these goals. One active research trend is to study search equation. Until now, various search equations have been suggested, such as [14–20]. The most representative of them is that inspired by PSO, Zhu and Kwong [14] proposed an gbest-guided ABC (GABC) by incorporating the information of global best (gbest) solution into the solution search equation to improve the exploitation. Hybridization of ABC with other operators have also been studied widely, such as [21–28]. For example, Kang et al. [23] used the Rosenbrock's rotational direction method to implement the exploitation phase and proposed the Rosenbrock ABC algorithm. Alatas [24] introduced the chaotic maps into the initialization and chaotic search into the scout bee phase and proposed the chaotic ABC. It is necessary to emphasize that our work falls in both of the categories.We note that Powell's method [29] has a strong ability of local search. In order to make use of the good exploitation of Powell's method, we propose an improved ABC algorithm-Powell ABC (PABC) for global optimization in this paper. First, a new search equation is employed to generate a candidate food position in the onlookers phase to improve the search ability. Next, Powell's method is incorporated to ABC as a local search tool to enhance the exploitation of the algorithm. Therefore, ABC and Powell's method have complementary advantages, and the proposed algorithm can result in a faster and more robust method. The efficiency of the new algorithm was tested by a suite of unimodal/multimodal benchmark functions.The rest of this paper is organized as follows. Section 2 summarizes artificial bee colony algorithm. Powell's method is reviewed in Section 3. The proposed PABC approach is presented in Section 4. Section 5 presents and discusses the experimental results. Finally, the conclusion is drawn in Section 6.ABC is a recently introduced optimization algorithm proposed by Karaboga [6] in 2005 which is inspired by the intelligent foraging behavior of honeybee swarm. In ABC, the colony of artificial bees is divided into three groups: employed bees, onlookers and scouts. Half of the colony consists of the employed bees, and another half consists of the onlookers. Employed bees are responsible for searching available food sources and gathering required information. They also pass their food information to onlooker bees. The onlookers select good food sources from those found by the employed bees to further search the foods. When the quality of the food source is not improved through a predetermined number of cycles, the food source is abandoned by its employed bee. And then the employed bee becomes a scout and starts to search for a new food source in the vicinity of the hive.In ABC, the position of a food source corresponds to a possible solution to the optimization problem, and the nectar amount of each food source represents their quality (fitness) of the associated solution. The number of the employed bees equals to the number of food sources. At the initialization step, ABC generates a randomly distributed initial population P of SN solutions (food source positions), where SN denotes the size of employed bees or onlooker bees. Each initial solution Xi={xi,1, xi,2, ..., xi,D} is produced randomly within the range of the boundaries of the parameters as follows:(2.1)xi,j=xmin,j+rand(0,1)(xmax,j−xmin,j),where i=1, 2, …, SN, j=1, 2, …, D and D is the number of optimization parameters; xmin,jand xmax,jare the lower and upper bounds for the dimension j, respectively.After the initialization, the population of the food sources (solutions) is subjected to repeated cycles of the search processes of the employed bees, onlookers and scouts. Each employed bee always remembers its previous best position and produces a new position within its neighborhood in its memory. If the new food source has equal or better quality than the old source, the old source is replaced by the new source. Otherwise, the old source is retained. After all employed bees finish their search process, they will share the information about nectar amounts and positions of food sources with onlookers. Each onlooker chooses a food source depending on the probability value associated with the food source and searches the area within its neighborhood to generate a new candidate solution. And then, as in the case of the employed bee, the greedy selection is applied again. When the nectar of a food source is abandoned, the corresponding employed bee becomes a scout. The scout will randomly generate a new food source to replace the abandoned position.An onlooker bee chooses a food source depending on the probability value piassociated with that food source, where(2.2)pi=fiti∑j=1SNfitj,and fitiis the fitness value of solution i. In this way, the employed bees exchange their information with the onlookers.In order to produce a candidate food position Vifrom the old one Xiin memory, ABC uses the following expression:(2.3)vi,j=xi,j+ϕi,j(xi,j−xk,j),where k∈{1, 2, ..., SN} and j∈{1, 2, ..., D} are randomly chosen indexes; k has to be different from i, and ϕijis a random number in the range [−1, 1].If a position cannot be improved further through a predetermined number of cycles, then that food source is assumed to be abandoned. The value of predetermined number of cycles is an important control parameter of ABC, which is called limit for abandonment. Assume that the abandoned source is Xi. Then the scout produces a food source randomly as in Eq. 2.1 to replace with Xi.Powell's method, strictly Powell's conjugate gradient descent method, is an algorithm proposed by M.J.D. Powell [29] for finding a local minimum of a function. The function need not be differentiable, and no derivatives are taken.The method minimizes the function by a bi-directional search along each search vector, in turn. The new position can then be expressed as a linear combination of the search vectors. The new displacement vector becomes a new search vector, and is added to the end of the search vector list. Meanwhile the search vector which contributed most to the new direction, i.e. the one which was most successful, is deleted from the search vector list. The algorithm iterates an arbitrary number of times until no significant improvement is made. The detailed pseudo-code of Powell's method procedure is presented as follow.Algorithm 1(Powell's method)01:Initialize the starting point X1, independent vectors di=ei(i=1, 2, ..., D), the tolerance for stop criteria ɛ, set f(1)=f(X1), Xc(1)=X1, k=1.02:While (stopping criterion is not met, namely |▵f|>ɛ) do03:Fori=1 to Ddo04:If (k≥2) then05:di=di+106:End If07:Xi+1=Xi+λidi, λiis determined by Minimizing f(Xi+1)08:End For09:di+1=∑1Dλi*di=XD+1−XD, Xc(k+1)=XD+1+λkdi+1, f(k+1)=f(Xc(k+1))10:k=k+1, X1=Xc(k), ▵f=f(k)−f(k−1)11: End WhileTo improve the performance of ABC, one active research trend is to study its search equation. Until now, various search equations have been suggested, such as [14–20]. The most representative of them is that inspired by PSO, which, in order to improve the exploitation and take advantage of the information of the global best (gbest) solution to guide the search of candidate solutions, Zhu and Kwong [14] presented the following solution search equation in GABC:(4.1)vi,j=xi,j+ϕi,j(xi,j−xk,j)+ψi,j(yj−xi,j),where the third term in the right-hand side of Eq. 4.1 is a new added term called gbest term, yjis the jth element of the global best solution, ψi,jis a uniform random number in [0,1.5]. However, since the guidance of the last two terms may be in opposite directions, it may cause an “oscillation” phenomenon. This phenomenon causes inefficiency to the search ability of the algorithm and delays convergence.However, we note that a well-designed search equation is usually beneficial to enhance the performance of the algorithm. Hence, we present a new search equation as follows:(4.2)vi,j=xk,j+rand(0,1)(xbest,j−xk,j),where rand(0, 1) denotes a uniformly distributed random number in (0, 1), k is an integer uniformly chosen from the range [1, SN] and is also different from i, and Xbestis the best individual with the best fitness in the current population. The new search equation has two obvious advantages. Firstly, owing to the guidance of the only one term - (xbest,j−xk,j) and with Xbest, Eq. 4.2 can not only easily avoid the oscillation phenomenon, but also improve the search ability of the algorithm. Secondly, what's more, since the vector Xkfor generating candidate solution is selected from the population at random and, consequently, it has no bias to any special search directions, Eq. 4.2 can try to keep the exploration. Furthermore, it can be seen from the simulation results in Section 5 that the novel search equation has more superior performance.In order to clearly investigate the working of Eq. 4.2, we call the basic ABC adopting Eq. 4.2 as BABC. Thus, the only difference between ABC and BABC is that BABC uses Eq. 4.2 to generate a candidate solution in the onlookers phase. Next, the population distribution characteristics in ABC and BABC process are investigated so as to analyze the bee behavior resulting from Eq. 4.2. Fig. 1shows the population distribution of the Sphere function with D=2 in [−10,10] observed at various stages of ABC and BABC, respectively. We can directly see from Fig. 1 that compared to ABC, BABC can converge to global optimum rapidly with the help of Xbest. Specially, following the initialization, the bees of ABC start to explore throughout the search space. Then, the bees converge to the best solution very slowly. However, with the guidance of Xbest, BABC can pull many bees to swarm together toward the optimal region. Then, the population converges to the global optimum quickly.It is well known that both exploration and exploitation are necessary for EAs. In practice, the exploration and exploitation contradict with each other, and in order to achieve good optimization performance, the two abilities should be well balanced. However, Zhu and Kwong [14] have pointed out that the solution search equation of ABC is good at exploration but poor at exploitation.The Powell's method is a classical local direct search algorithm, making no use of the objective function derivatives. Its advantages are simple and efficient; however it is easily entrapped in a local optimum and its convergence is extremely sensitive to the initial start point. In other words, the Powell's method is good at exploitation but poor at exploration.Therefore, to deal with the poor exploitation of ABC, an idea to combine ABC with the Powell's method is addressed in this paper; the rationale behind this is that such a hybrid approach expects to enjoy the merits of ABC with those of the Powell's method. In other words, ABC good at exploration contributes to the hybrid approach in a way to ensure that the search is less likely to be trapped in local optima that often arise from employing a pure local search technique, while the Powell's search part of the hybrid approach makes the search converge faster than basic ABC. Additionally, an improved search equation is used to produce a candidate food position in the onlookers phase to improve the search ability. Roughly speaking, the hybrid approach can usually achieve an ideal balance between the exploration and the exploitation.In view of the above, a new algorithm is proposed. The main steps of the algorithm are summarized as follows. After the initialization, it employs ABC to improve the solution quality by adjusting the position of the food. During ABC process, in order to enhance the performance of the search, the onlooker produces a modification on the position by the new search equation. Next, for every T cycles of ABC, Powell's method is activated to perform a local search using a random position (point) as the starting point to find a better solution. Then turn to the employed bees phase and repeat the above steps until a specified stop condition is met.Based on the above explanation, the pseudo-code of the proposed algorithm is given below:Algorithm 2(Powell artificial bee colony algorithm (PABC))01:Set the population size SN, give the maximum number of function evaluations, Max.FE02:Use (2.3) to create an initial population {Xi|i=1, 2, …, SN}, calculate the function values of the population {fi|i=1, 2, …, SN}, find the best solution Xbest, set triali=0, i=1, 2, …, SN and Gen=103:While (stopping criterion is not met, namely FE<Max.FE) do04:Fori=1 to SNdo % the employed bee phase%05:Randomly choose j∈{1, 2, …, D} and k∈{1, 2, ldots, SN} that has to be different from i,randomly produce ϕi,j∈[−1, 1]06:Generate a new food source Viaccording tovi,j=xi,j+ϕi,j(xi,j−xk,j)07:Iff(Vi)<f(Xi) then08:Xi=Vi, triali=009:Else then10:triali=triali+111:End If12:End For13:Fori=1 to SNdo % the onlookers phase%14:Randomly choose j∈{1, 2, …, D} and k∈{1, 2, ldots, SN} that has to be different from i and best15:Generate a new food source Viaccording tovi,j=xk,j+rand(0,1)(xbest,j−xk,j)16:Iff(Vi)<f(Xi) then17:Xi=Vi, triali=018:Else then19:triali=triali+120:End If21:End For22:Ifmod(Gen, T)=0 do % the Powell's method phase%23:Randomly choose k∈{1, 2, ldots, SN} that has to be different from best, generate a newsolution U according to uj=xk,j+rand*(xbest,j−xk,j), j=1, 2, ···, D24:Use the U as a starting point and generate a new solution Vkby Powell's method25:Iff(Vk)<f(Xk) then26:Xk=Vk, trialk=027:Else then28:trialk=trialk+129:End If30:End If31:Ifmax(triali)>limitthen % the scouts phase%32:replace Xiwith a new solution produced by Eq. 2.1.33:End If34:Gen=Gen+1 and memorize the best solution Xbestachieved so far35:End While (FE=Max.FE)In Table 1, we provide the average CPU time of the Powell’ method and PABC on 30-dimensional functions f1−f20, and 100-dimensional functions f21 and f22 based on 30 independent runs. Ratio which means the percentage of the time which the PABC spends on the Powell’ method, is also reported in table. The CPU time is recorded after each run of the algorithm is continued till the maximum allowed number of FEs or optimum value found.From Table 1, it can be seen that owing to adopting the the Powell’ method, the computational time of PABC is increased at one run. However, the ration is less than 0.1 on 11 problems and is not more than 0.25. This situation is acceptable. Although the computational time of PABC is higher than that of ABC at the same maximum iteration, PABC could find the high-quality solution in fewer iterations than ABC. Thus the actual computation time of PABC may be reduced in relative to original ABC.The control parameter T needs to be tuned. In this section, four different kinds of thirty-dimensional (30-D) test functions are used to investigate the impact of this parameter. They are the Sphere, Schwefel 2.22, Rosenbrock and Weierstrass functions as defined in Table 2. PABC runs 30 times on each of these functions, and the mean values of the final results are presented in Fig. 2. As all test functions are minimization problems, the smaller the final result, the better it is. From Fig. 2, we can observe that T can influence the results. When T is 1*D, we obtain a faster convergence velocity and better result on the Sphere function. For the other three test functions, better results are obtained when T is around 2*D. Hence, for convenience, the control parameter T is set at 2*D for all test functions in our experiments.In this section, the proposed approach is used to minimize a set of 20 scalable benchmark functions of dimensions D=15, 30 or 60 and a set of 2 functions of dimensions D=50, 100 or 200, as shown in Table 2. These benchmark functions are widely adopted to test the performance of global optimization algorithms [9,14,31,32]. For convenience, according to different dimensions, these functions are divided into the low-, middle- and high-dimensional functions. For example, the low-dimensional functions contain 15-dimensional functions f1−f20, and 50-dimensional functions f21 and f22, etc.Summarized in Table 2 are the 22 scalable benchmark functions. f1−f6 and f8 are continuous unimodal functions. f7 is a discontinuous step function, and f9 is a noisy quartic function. f10 is the Rosenbrock function which is unimodal for D=2 and 3 but may have multiple minima in high dimension cases [33]. f11−f22 are multimodal and the number of their local minima increases exponentially with the problem dimension. In addition, f14 is the only bound-constrained function investigated in this paper. Table 2 also gives the search range (column 2). Moreover, “Accept” (column 3) is defined for each test function. If a solution found by an algorithm falls between the acceptable value and the actual global optimum, the run is judged to be successful.In order to testify the efficiency of the proposed algorithm, PABC is compared with classical ABC, GABC [14], ALEP [34], FEP [35], OGA/Q [31], EDA /L [36], CEP [37], LEA [32], the classical DE [3], jDE [38], SaDE [39], JADE [40], the classical PSO [2], FIPS [42], HPSO-TVAC [43], CLPSO [44] and OLPSO-G [30]. For a fair comparison among ABCs, they are tested using the same settings of the parameters, that is, the population size SN=100 [8], limit=200 [21]. Furthermore, we set the maximum number of function evaluations to be 50,000, 100,000 and 200,000 in the case of D= low, middle and high. All results reported are obtained based on 50 independent runs. For other algorithms, we follow the parameter settings in the original paper of ALEP [34], FEP [35], OGA/Q [31], EDA /L [36], CEP [37], LEA [32], the classical DE [3], jDE [38], SaDE [39], JADE [40], the classical PSO, FIPS [42], HPSO-TVAC [43], CLPSO [44] and OLPSO-G [30]. See Table 3. For clarity, the results of the best algorithms are marked in boldface.The mean and the standard deviation of the results obtained by each algorithm for f1−f22 are summarized in Tables 4–6. An interesting result is that the three ABC-based algorithms have most reliably found the minimum of step function(f7). It is a region rather than a point in f7 that is the optimum. Hence, this problem may relatively be easy to solve with a 100% success rate. Important observations about the solution accuracy of different algorithms can be made from the results presented in Tables 4–6 on the other 21 test functions. For the low- and middle-dimensional functions, PABC is significantly better than ABC and GABC on 21 and 20 test functions except that GABC is superior to ABC and PABC on Schwefel 2.21 function (f6). For the high-dimensional functions, PABC always outperforms ABC and GABC on 21 test functions. Specially, only PABC is capable of finding the global optimum on Rastrigin, NCRastrigin and Griewank functions in all dimensions, whereas the other two algorithms could not be efficient in solving these three functions.In order to compare the convergence rate and reliability of different algorithms, more experimental results are given and compared in Tables 7–9. The results given there are the average FES (AVEN) needed to reach the threshold expressed as acceptable solutions specified in Table 2. In addition, successful rate (SR%) of the 50 independent runs for each function are also compared. Note that the AVEN are calculated only for the runs that have been “successful”. For convenience of illustration, we also plot the convergence graph for some test functions in Figs. 3and 4, respectively. It can be observed from Tables 7–9, Figs. 3 and 4 that PABC is faster than ABC and GABC on all the test functions. PABC has the highest successful rate of 97%, 95.45% and 89.81% in different dimensions, followed by GABC and ABC. Particularly, PABC result in higher algorithm reliability with 100% successful rate on all the test functions except Schwefel 2.21, Quartic and Michalewicz function in some cases.In the 9th columns of Tables 4–6, we report the statistical significance level of the difference of the means of the results produced by best and the second best algorithms (with respect to their final accuracies). Note that here ‘+’ indicates the t value is significant at a 0.05 level of significance by two-tailed test, ‘.’ stands for the difference of means is not statistically significant and ’NA’ means not applicable, covering cases for which the two algorithms achieve the same accuracy results. It also clearly indicates that the proposed PABC is superior to ABC and GABC on almost all the functions.In Table 10, PABC is compared with some variants of evolutionary algorithms. These algorithms include ALEP, FEP, OGA/Q, EDA /L, CEP and LEA. The results of the compared algorithms are all derived directly from their corresponding references. NA represents the results are not available in the corresponding reference. The results show that PABC yields good performance and does best on 7 of 9 test functions with the smallest FES. While, OGA/Q surpasses PABC on functions Sphere and Schwefel 2.22.Further experimental results are listed in Tables 11and 12. PABC is compared with the classical DE, jDE, SaDE and JADE in Table 11. The results of these variant DEs are based on the reports in the literature [40,41]. Additionally, PABC is compared with the classical PSO, FIPS, HPSO-TVAC, CLPSO and OLPSO-G in Table 12. The results of these variant PSOs are based on the reports in the literature [30]. It is clear that PABC works best in almost all the cases and achieves overall better performance than other competitive algorithms.In order to analyze the modifications respectively, we call the basic ABC with the new search equation as ABC1, and the basic ABC with the Powell's method as ABC2. We compare the convergence performance of the different ABCs on the 22 30-dimensional functions to see that how much the new search equation and the Powell's method make contribution to improving the performance of the algorithm respectively. The results are summarized in Table 13. It can be observed that, ABC1 is superior to ABC and PABC on 21 and 3 functions, which implies that both the new search equation and the Powell's method have positive effect on the performance of the algorithm. On the other hand, the experimental results and comparisons verify that the new search equation and the Powell's method indeed help ABC with them perform better than ABC with either or neither one on most of the test functions. Moreover, the new search equation and the Powell's method work together to improve the performance of ABC rather than contradict each other.When PABC is applied to optimize the constrained benchmark problems, PABC adopts the same technique as in [45] to handle the constraints. In order to evaluate the performance of PABC algorithm, we use a set of 13 benchmark problems described in [45]. The results of PABC are compared with the results of other methods in relevant literatures including SMES [46], GA, DE, PSO and ABC [45]. These algorithms follow the parameter settings in the original papers [45] and [46]. Comparative results of the mean solutions of the investigated algorithms are presented in Table 14. From Table 14, it can be seen that PABC ranks on the top for the most test functions. While SMES is better than PABC on function g13,

@&#CONCLUSIONS@&#
