@&#MAIN-TITLE@&#
Dynamics of an optimal maintenance policy for imperfect repair models

@&#HIGHLIGHTS@&#
The history of the system is considered in order to decide whether to maintain it.The equipment is maintained whenever the failure intensity goes above a threshold.This random policy will incur in lower costs than the periodical, fixed age policy.Estimation for imperfect repair models uses maximum likelihood and bootstrap methods.Application to a data set regarding failures of engines of off-road trucks is shown.

@&#KEYPHRASES@&#
Reliability,Bootstrap confidence bands,Continuous wear-out,Counting processes,Minimal repair,

@&#ABSTRACT@&#
A preventive maintenance policy that considers information provided by observing the failure history of a repairable system is proposed. For a system that is to be operated for a long time, it is shown that the proposed policy will have a lower expected cost than a periodical one which does not take into account the failure history. Statistical inference using both maximum likelihood point estimates and bootstrap confidence intervals is discussed. The proposed policy is applied to a real situation involving maintenance of off-road engines owned by a Brazilian mining company. A simulation study compares the performance between the maintenance policy proposed and the periodical one.

@&#INTRODUCTION@&#
Many equipments used in everyday life are not discarded after they fail. This means that, immediately after a failure, a repair is made which makes the equipment operational once more. On the other hand, some prescheduled maintenance actions are also performed periodically. Hence, for instance, a car owner should make some non-scheduled repairs (e.g. replacing a flat tire) and also take the vehicle to a dealer to be serviced regularly. Designing appropriate maintenance policies helps to maintain the equipment running longer and, hence, minimize operation costs.Since the early work of Barlow and Hunter (1960), much of the literature regarding optimal maintenance of repairable systems has assumed both minimal repair (MR) and perfect maintenance (PM). MR, also known as as bad as old in the engineering literature, is a corrective action performed after each failure which, supposedly, returns the system to exactly the same condition it was immediately before it failed. Prescheduled PMs or as good as new actions are preventive actions which completely renew the system. However, since the MR assumption is too restrictive, attention has been given recently to imperfect repair (IR) models, which assume that the repair action after a failure is neither minimal nor perfect, in the sense that it restores the system to a condition which is somewhere in between the as bad as old and the as good as new conditions (see, for instance, Kijima, Morimura, & Suzuki, 1988; Doyen & Gaudoin, 2004; Pan & Rigdon, 2009).Let N(t) be the number of failures up to time t. In MR models, the failure history of the system does not affect the failure intensity and hence, the process N(t) has independent increments and is usually modeled as a non-homogeneous Poisson process (NHPP). Therefore, the optimal PM policy should determine an optimal PM periodicityτP, in the sense that PMs should be performed at times τP, 2 τPand so on. More precisely, denote by λ(t), CRand CMrespectively the intensity of the process and the fixed costs of the MR and PM actions. LetC(τ)=CM+CRN(τ)be the total cost between two successive PMs performed τ units of time apart andH(τ)=C(τ)/τbe the corresponding cost per unit of time. Since for an NHPP we have thatEN(t)=Λ(t)=∫0tλ(u)du,the expected cost per unit of time isEH(τ)=[CM+CRΛ(τ)]/τ. Deriving and equating to zero this expression we obtain that the optimal period τPmust be the solution of(1)B(τ):=τλ(τ)−Λ(τ)=CMCR,orτP=B−1(CM/CR),where we have assumed that λ(t) is increasing and limt → ∞B(t) > CM/CR. This is the solution of Barlow and Hunter (1960). Note that, when λ(t) is increasing, B(t) is as well, as can be seen from the fact thatB′(t)=tλ′(t)(cf. also Definition 1 below). Further developments can be found among others in Glasser (1967), Bassin (1973), Gilardoni and Colosimo (2007)2011), Oliveira, Colosimo, and Gilardoni (2012) and Gilardoni, Oliveira, and Colosimo (2013). We note that a slightly more general set up is possible, in the sense that one could assume above (and also in the rest of the paper) that the costs of the PM and MR actions are random variables which are independent of the history of the system and have expected values CMand CR.The optimal policy mentioned above is a periodical age-dependent policy, in the sense that the unit is maintained at a fixed age τP(for a classification of maintenance policies see Wang, 2002; Das & Sarmah, 2010). There is an extensive literature regarding extensions of the periodical age-dependent policy, including systems which are subject to several types of failures or allowing the optimal policy to perform a PM after the system has reached a predetermined age or a fixed number of failures, whichever comes first (Chien & Sheu, 2006; Colosimo, Santos, Gilardoni, & Motta, 2010; Huynh, Castro, Barros, & Berenguer, 2012).The maintenance policy (1) can be easily extended for IR models since, from a purely mathematical point of view, an IR model is a general counting process with a random intensity λ(t). LetΛ(t)=∫0tλ(u)dube the cumulative intensity,Φ(t)=EN(t)=EΛ(t)andϕ(t)=Φ′(t). In the engineering literature (cf. Crowder, Kimber, Sweeting, and Smith, 1994, or Rigdon and Basu, 2000), ϕ(t) is called the rate of occurrence of failures (ROCOF) function and is, essentially, an unconditional version of the intensity λ(t) (for a discussion about these concepts in IR models see Section 2 below). Now, the expected cost per unit of time becomesEH(τ)=[CM+CRΦ(τ)]/τand, hence, the optimal solution isτP=B−1(CM/CR),where nowB(t)=tϕ(t)−Φ(t)[compare with (1)]. However, when one has access to the failure history of the equipment when deciding the maintenance policy, the previous solution is not optimal for IR models. From a mathematical viewpoint, the reason is that, since the resulting process N(t) will not have independent increments, the failure history provides information about the future reliability of the system. Consequently, it should be taken into account when determining the optimal policy. For instance, if it has been decided to perform a PM at τPand there is a failure just before that moment, the IR assumption implies that the repair will improve the reliability and, therefore, it will make sense to wait to perform the PM until some moment after τP. Notwithstanding, most of the literature regarding IR models still focus on the idea of optimal periodicity (cf. Kijima et al., 1988; Yevkin & Krivtsov, 2013). Hence, the objective of this paper is to understand how the information provided by the failure history of the system can be used to determine maintenance policies for IR models which improve the optimal periodical policy mentioned above.We begin by considering a situation whereby one has access to the failure history up to time s. Based on that information, and assuming that the system is deteriorating over time (see Definition 1 and Lemma 1 below for a precise definition of this concept), we find an optimal maintenance policy which minimizes the total expected cost of operating the system for an additional T units of time. More precisely, we consider operating the equipment between s ands+Tand determine the optimal number of PMs n* and the optimal times between successive PMsτ1*,…,τn**. We call this situation static in the sense that the only information available is the failure history up to s (i.e. no new information becomes available while the optimal policy is being implemented). In the special case that the maintenance period T → ∞, we find that (i) the first PM should be performed at a time instants+τ1*such thatϕ(s+τ1*|N(t):t≤s)=ϕ[B−1(CM/CR)]and (ii) after this first PM, additional PMs should be performed everyB−1(CM/CR)units of time (cf. Theorem 4 below). This approach motivates a dynamic one in the following sense. Suppose that the operator of the equipment obtains now this static policy using the information provided by the failure history up to s and, after a short period of time ds, recomputes the policy using the information up tos+dsand so on. Now the time of the first PM is being recalculated every time and will stay always ahead of the current time, unless, for some time t, we have that the correspondingτ1*=0. This means that a PM will occur if and only if(2)λ(t)=ϕ[B−1(CM/CR)].This suggests considering a maintenance policy that performs PMs at (random) timesτD=inf{t>0:λ(t)≥ϕ[B−1(CM/CR)]}. We note that, for the special case of the NHPP,ϕ(t)=λ(t)and hence τDbecomes deterministic and coincides withτP=B−1(CM/CR).For the deterministic policy τP, it follows from the fact thatτP=B−1(CM/CR)[i.e.τPϕ(τP)−Φ(τP)=CM/CR], that the expected cost per unit of time is(3)EH(τP)=CM+CRΦ(τP)τP=CRϕ(τP).Similarly, we have that(4)EH(τD)=ECM+CRN(τD)τD,although further simplification is not possible here because τDis random. To compare the policies, we show in Theorem 5 that, for a system that is deteriorating over time,(5)CRϕ(τP)=EH(τP)≥E[τDH(τD)]E(τD).Suppose that the system is to be maintained for T units of time. We argue in Section 4that, as T → ∞, (5) implies that using the dynamic policy τDwill result in lower expected cost than using the periodic policy τP. However, this fact does not imply thatEH(τP)≥EH(τD),essentially because τDis random and, hence,E[τDH(τD)]/E(τD)is not equal toEH(τD). In a sense, while (5) refers to each of the policies being used repeatedly for a long time, the comparison betweenEH(τP)andEH(τD)refers to a single use of each one of them. In Section 6we present a Monte Carlo study which compares the expected cost per unit of time for the periodic and dynamic policies for the Kijima et al. (1988) IR model. The results suggest that, at least for the scenarios considered in the simulation,EH(τP)≥EH(τD).Besides the static and the dynamic approach discussed in Sections 3 and 4 and the Monte Carlo study in Section 6, the rest of the paper is organized as follows. Section 2 sets up the notation and gives a brief introduction to counting processes (CP) and IR models. We also introduce the notion of a system which is deteriorating continuously over time, which we call Continuous Wear-out (CWO), and show that it is equivalent to the intensity of the process being itself a submartingale. In order to implement the dynamic policy τD, one has to estimate the thresholdϕ[B−1(CM/CR)]for the IR model. Hence, Section 5 discusses how to obtain maximum likelihood estimates (MLE) and bootstrap confidence intervals for the Kijima et al. (1988) virtual age model. Section 7 contains an application regarding maintenance of off-road engines used in a mining company. Final remarks are given in Section 8.Counting processes. From a modeling point of view, an IR model is a CP such that the failure regime changes every time a failure occurs. Hence, to set up the notation that will be used in the rest of the paper, we begin this section with a brief review of the theory of CPs. The reader interested in more technical details can consult Andersen, Borgan, Gill, and Keiding (1993) or, for a gentler introduction to the topic, Aalen, Borgan, and Gjessing (2008).Essentially, a CP {N(t): t ≥ 0} is a collection of random variablesN(t)=N(t,ω)defined in a probability space(Ω,F,P)such that, with probability one,•N(0)=0,the maps t ↦ N(t) are continuous from the right andeitherΔN(t)=0orΔN(t)=1,whereΔN(t)=N(t)−N(t−)=N(t)−limh↓0N(t−h).Therefore, N(t) starts atN(0)=0,stays at that value until a random time T1 > 0, when it jumps toN(T1)=1and stays there until another random time T2 > T1, when it jumps toN(T2)=2and so on. The random variables{Tn:n=1,2,…}are known as the jump or, in our case, failure times of N(t). In order to model the past of the process, N(t) is supposed to be adapted to a sequence of increasing σ-fields{Ft:t≥0},known as a filtration, in the sense that the collection {N(s) : s ≤ t} isFt-measurable. In the sequel we will assume that the filtration does not include information external to the CP. More precisely, this means thatFt=σ{N(s):s≤t}is the (minimal) σ-field generated by the collection {N(s) : s ≤ t}, also known as the internal filtration. We note that, in this case, conditioning onFtcan be seen informally as conditioning on the event{T1=t1,…,TN(t)=tN(t),TN(t)+1>t},where TN(t) is the last failure time before t. We will assume below that N(t) is integrable, in the sense thatE[N(t)]<∞for every t. Moreover, in order to apply the optional sampling theorem (OST) in Theorem 5, we will need the stronger assumption that N(t) is uniformly integrable, in the sense thatlimA→∞E{N(t)I[N(t)>A]}=0uniformly in t.A special family of CPs occurs when the intensity λ(t) is deterministic, in this case the process is termed an NHPP. In this case, and only in this case, N(t) has independent increments in the sense that the random variatesN(d)−N(c)andN(b)−N(a)are independent for 0 ≤ a < b ≤ c < d. This allows one to show that, for every 0 ≤ s < t,N(t)−N(s)follows a Poisson distribution with meanΛ(t)−Λ(s)=∫stλ(u)du.A process {X(t) : t ≥ 0} adapted to a filtrationFtis called a martingale if for every s < t we have thatE[X(t)|Fs]=X(s). It is called a submartingale ifE[X(t)|Fs]≥X(s). If a martingale X(t) is integrable, we must have thatEX(t)=EE[X(t)|F0]=EX(0)for every t. Similarly,EX(s)≤EX(t)for s < t if X(t) is an integrable submartingale. A fundamental result known as the Doob–Meyer decomposition states that every submartingale X(t) can be uniquely expressed asX(t)=Λ(t)+M(t),where Λ(t) is an increasing predictable process and M(t) is a martingale. Informally, the process Λ(t) is predictable if Λ(t) can be determined from the knowledge of {Λ(s) : s < t}. For our purpose, it is enough to know that every left-continuous process is predictable.Since the trajectories t ↦ N(t, ω) are non-decreasing for (almost) all ω, it is immediate from the definition above that N(t) is a submartingale. Hence, by the Doob–Meyer decomposition, there exists a unique increasing predictable process Λ(t) such thatM(t)=N(t)−Λ(t)is a martingale. We will also assume that the process Λ(t) is absolutely continuous with respect to Lebesgue measure, in which case we can writeΛ(t)=∫0tλ(s)ds. The processes λ(t) and Λ(t) are called respectively the (conditional) intensity and the cumulative intensity (or compensator) of N(t). The term conditional here is used because it can be shown that an alternative definition for λ(t) isλ(t)=limh↓01hE[N(t+h)−N(t)|Ft]=limh↓01hP[N(t+h)−N(t)=1|Ft](see, for instance, Aalen, 1978). It follows from the decompositionM(t)=N(t)−Λ(t)and the fact thatEM(t)=0thatEN(t)=EΛ(t)=E∫0tλ(s)ds=∫0tEλ(s)dsfor every t.An interesting problem is whether the deterministic times inEX(t)=EX(0)(for a martingale) or inEX(s)≤EX(t)(for a submartingale) can be substituted by random times. A mapτ:Ω→R∪{∞}is called a stopping time if the event{ω∈Ω:τ(ω)≤t}∈Ftfor every t ≥ 0. Essentially, a stopping time is a random time such that, in order to decide whether τ ≤ t, it is enough to know the history up to t (i.e., stopping times are not allowed to look into the future). For instance, the failure times Tndefined above are stopping times. The OST states that•if τ is a stopping time such thatP(τ<∞)=1and M(t) is a uniformly integrable martingale, thenEM(τ)=EM(0)andif τ and σ are stopping times such thatP(τ≤σ<∞)=1and X(t) is a uniformly integrable martingale, thenEX(τ)≤EX(σ).ROCOF and conditional ROCOF functions. We define the mean function of the processΦ(t)=EN(t)and the ROCOF functionϕ(t)=(d/dt)Φ(t). It follows from the previous discussion thatΦ(t)=EN(t)=EΛ(t)andϕ(t)=Eλ(t). In a sense, the ROCOF function ϕ(t) is an unconditional version of the intensity λ(t). Hence, for an NHPP, for which λ(t) is deterministic, the intensity and ROCOF functions coincide.Below we will also be interested in a family of functions which are somewhere in between the intensity and the ROCOF functions, insomuch as they measure the rate of failures at a given time conditional on some distant past. The reason is that, in order to decide a maintenance policy for the time interval(s,s+T)given the failure history up to time s, the operator of the repairable equipment under consideration will have to considerE[N(t)−N(s)|Fs]for t > s. Accordingly, we will define for s ≤ t the conditional mean and ROCOF functionsΦ(t|Fs)=E[N(t)|Fs]=N(s)+E[N(t)−N(s)|Fs]andϕ(t|Fs)=limh↓0[Φ(t+h|Fs)−Φ(t|Fs)]/h. Note that (i)Φ(t)=Φ(t|F0),ϕ(t)=ϕ(t|F0)and (ii)Φ(t|Ft)=N(t)andϕ(t|Ft)=λ(t). In order for the maintenance problem to make sense, we will assume in the sequel that, conditional on any given historyFs,the system deteriorates over time.Definition 1We say that the CP N(t) has the CWO property if the mapst↦ϕ(t|Fs)are (P-a.s.) increasing for all t > s ≥ 0. The process has the strict continuous wear-out (SCWO) property if the mapst↦ϕ(t|Fs)are strictly increasing for all t > s ≥ 0.From a mathematical viewpoint, CWO means that the conditional expectations are increasing. Hence, the following Lemma is not surprising.Lemma 1A CP N(t) has the CWO property if and only if the intensity λ(t) is a submartingale.If the process has the CWO property, we have thatE[λ(t)|Fs]=ϕ(t|Fs)≥ϕ(s|Fs)=λ(s). Hence, λ(t) is a submartingale. Conversely, if λ(t) is a submartingale and s < t1 < t2,ϕ(t2|Fs)=E[λ(t2)|Fs]=E{E[λ(t2)|Ft1]|Fs}≥E[λ(t1)|Fs]=ϕ(t1|Fs).□Conditional distribution of the failure times. CPs can also be described through the conditional distribution of the failure times given the past. Indeed, this representation is quite convenient for IR models (cf. Doyen & Gaudoin, 2004; Lindqvist, 1998). LetFTn+1|t1,…,tn(t),fTn+1|t1,…,tn(t),λTn+1|t1,…,tn(t),andΛTn+1|t1,…,tn(t)be respectively the conditional cdf, pdf, hazard and cumulative hazard functions ofTn+1given thatT1=t1,…,Tn=tn. Note that, since we are using the internal filtration,λTn+1|t1,…,tn(t)=limh↓01hP(t<Tn+1≤t+h|T1=t1,…,Tn=tn;Tn+1>t)=limh↓01hP[N(t+h)−N(t)=1|Ft]=λ(t)for t ≥ tn, so that the conditional hazard ofTn+1coincides with the intensity of the process for t ≥ tn. Hence,ΛTn+1|t1,…,tn(t)=∫0tλTn+1|t1,…,tn(u)du=∫tntλ(u)du=Λ(t)−Λ(tn),(6)FTn+1|t1,…,tn(t)=1−exp{ΛTn+1|t1,…,tn(t)}=1−exp{−Λ(t)+Λ(tn)}andfTn+1|t1,…,tn(t)=λTn+1|t1,…,tn(t)exp{ΛTn+1|t1,…,tn(t)}=λ(t)exp{−Λ(t)+Λ(tn)}for t ≥ tn. We note that this allows one to simulate failures according to an IR model. Essentially, one definest0=0,generates the first failure time t1 from (6) withn=0,then, conditionally on t1, generates t2 from (6) withn=1and so on until reaching a predetermined number of failures or a predetermined truncation time.Likelihood functions. There are essentially two ways to observe the failure history of an equipment such as those we address here. Either the system is observed up to a certain predetermined time T, or it is observed until reaching a fixed number of failures n. We say that the observation (design) is respectively time or failure truncated. The likelihood for the failure truncated case is quite simple:(7)L(λ)=∏j=1nfTj|t1,…,tj−1(tj)=[∏j=1nλ(tj)]e−∑j=1n[Λ(tj)−Λ(tj−1)]=[∏j=1nλ(tj)]e−Λ(tn),where 0 < t1 < ⋅⋅⋅ < tnare the n observed failure times and we have definedt0=0.For the time truncated case, suppose one has observed n failures at times0<t1<…<tn<T. This event is the same as{T1=t1,…,Tn=tn;Tn+1>T}. Hence, the likelihood is(8)L(λ)=∏j=1nfTj|t1,…,tj−1(tj)×P[Tn+1>T|T1=t1,…,Tn=tn]=[∏j=1nλ(tj)]e−∑j=1n[Λ(tj)−Λ(tj−1)]×e−Λ(T)+Λ(tn)=[∏j=1nλ(tj)]e−Λ(T).We note, however, that the last expression in both (7) and (8) are deceptively simple for IR models, because explicit expressions for the cumulative intensity Λ(tn) or Λ(T) are difficult to obtain and, hence, for computation purposes, we actually useΛ(tn)=∑j=1n∫tj−1tjλ(u)duorΛ(T)=∑j=1n∫tj−1tjλ(u)du+∫tnTλ(u)du.Imperfect repair models. Usually, IR models are specified as a counting process which (i) starts att=0with a reference or base deterministic intensity λR(t) and (ii) has a rule which determines how the intensity changes immediately after a failure. For instance, virtual age (VA) models start with a deterministic function λR(t) and define an associated process V(t), the virtual age of the system, whereby the intensity process isλ(t)=λR[V(t)]. Special cases areV(t)=θtN(t)+t−tN(t)=t−(1−θ)tN(t)(Kijima et al., 1988), where θ is a parameter associated with the efficacy of the repair:θ=1implies thatV(t)=tand the repair is minimal;θ=0implies thatV(t)=t−tN(t)and the repair becomes perfect. In the former case the counting process becomes an NHPP with deterministic intensityλ(t)=λR(t),while in the latter we have a renewal process. Usually, one expects the parameter θ to be between 0 and 1, in which case the efficacy of the repair is somewhere in between MR and PM, although θ > 1 is also possible. Doyen and Gaudoin (2004) define a whole class of VA models by lettingV(t)=t−θ∑j=0min{m−1,tN(t)−1}(1−θ)jtN(t)−j. They call this the arithmetic reduction of age with memory m (ARAm) model (note that using this nomenclature, the Kijima et al. (1988) model mentioned before is the ARA1 model). By analogy, the ARA∞ model, introduced by Brown, Mahoney, and Sivazlian (1983) corresponds toV(t)=t−θ∑j=0tN(t)−1(1−θ)jtN(t)−j. Fig. 1shows the simulated realizations and intensity for an ARA1 model with power law intensityλR(t)=(β/η)(t/η)β−1.We consider here the following situation. At time s the operator of the equipment has the informationFsand should decide on a maintenance policy for a period of T > 0 units of time starting at s. In other words, we have the informationFsat time s and should decide how many times and when to perform PM in the time interval[s,s+T). We will assume that no further information will become available during this period. We are especially interested in the properties of the optimal policy when T is large. We will also assume that the process satisfies SCWO and hence, that the ROCOF function ϕ(t) is strictly increasing.We will denotePM(s,T)=(n;τ1,…,τn|s,T)the policy that performs n PMs at the timess+τ1,s+τ1+τ2,…,s+τ1+⋯+τn. Of course, we must have thatτ1+⋯+τn≤T. Note that the τi’s are the times between PMs. (see Fig. 2). The total expected costC(n;τ1,…,τn|s,T)of such a policy is computed as follows. First, note that there are n PMs which cost nCM. Second, between s ands+τ1there areN(s+τ1)−N(s)failures which, conditionally onFs,have expected costCR[Φ(s+τ1|Fs)−Φ(s|Fs)]=CR[Φ(s+τ1|Fs)−N(s)]. Next, fori=2,…,n,since the system renews after each PM, the number of failures betweens+∑j=1i−1τjands+∑j=1iτj,has the same distribution as N(τi) and the associated expected cost isCRΦ(τi|F0)=CRΦ(τi). Finally, the number of failures betweens+∑j=1nτjands+Thas the same distribution asN(T−∑j=1nτj)and the expected cost isCRΦ(T−∑j=1nτj). Hence,(9)C(n;τ1,…,τn|s,T)=nCM+CR{Φ(s+τ1|Fs)−N(s)+∑i=2nΦ(τi)+Φ(T−τ1−⋯−τn)}.We will say that a policyPM*(s,T)=(n*;τ1*,…,τn**|s,T)is optimal if for any other policy we have thatC(n*;τ1*,…,τn**|s,T)≤C(n;τ1,…,τn|s,T).We begin by noting that under this set up the system is renewed ats+τ1and from then on the problem proceeds without information. Hence, we have the following Lemma, which suggests that in order to obtain an optimal policy in the general set up one has to understand the structure of the optimal policy in the no information case.Lemma 2IfPM*(s,T)=(n*;τ1*,…,τn**|s,T)is optimal, thenPM*(0,T−τ1*)=(n*−1;τ2*,…,τn**|0,T−τ1*)is also optimal.The problem without information. To determine the optimal policy PM*(0, T) we will first minimize with respect toτ1,…,τnassuming n fixed. It follows from (9) that∂C∂τi(n;τ1,…,τn|0,T)=CR[ϕ(τi)−ϕ(T−τ1−⋯−τn)]for 1 ≤ i ≤ n. Since we are assuming that ϕ is strictly increasing, it follows that(10)τ1*=⋯=τn**=T−τ1*−⋯−τn**=Tn*+1.In other words, given the optimal number of PMs n*, the optimal policy partitions the interval (0, T) into(n*+1)equal length intervals to choose the PM epochs.Next, we plug the optimalτi*’s into the cost function to obtainC*(n|0,T)=nCM+CR(n+1)Φ[(n+1)−1T].If n were a continuous variable, the optimum would be obtained differentiating C*. This would give∂C*∂n=CM+CR[Φ[(n+1)−1T]−Tn+1ϕ[(n+1)−1T]]=CM−CRB[(n+1)−1T]=0,where, as before,B(t)=tϕ(t)−Φ(t)[note that this definition is consistent with (1) since, for an NHPP,λ(t)=ϕ(t)]. Since B is strictly increasing, this would give the solution(11)n*=TB−1(CM/CR)−1.Since it is easy to prove that C* is convex, this implies that the actual (integer) n* should be one of the integers next to (11). Therefore, ifT≤B−1(CM/CR),thenn*=0. Otherwise, we can write that(12)n*=TB−1(CM/CR)−1+ϵ(0,T)where|ϵ(0,T)|≤1. This and Eq. (10) give the following result.Theorem 3Under SCWO, the optimal policyPM*(0,T)=(n*;τ1*,…τn**|0,T)satisfies(10)and(12). Moreover, we have thatlimT→∞Tn*=limT→∞τi*=B−1(CM/CR)The general static problem. IfPM*(s,T)=(n*;τ1*,…τn**|s,T)is optimal, then Lemma 2 and (10) give that(13)τ2*=⋯=τn**=T−τ1*n*.Hence, we only need to determineτ1*and n*. From (13) and (9) it follows that the function to minimize isC*(n,τ1)=nCm+CR{Φ(s+τ1|Fs)−N(s)+nΦ[n−1(T−τ1)]}.Differentiating and equating to zero we obtain that(14)1CR∂C*∂τ1=ϕ(s+τ1|Fs)−ϕ[n−1(T−τ1)]=0(15)∂C*∂n=CM+CR{Φ[n−1(T−τ1)]−T−τ1nϕ[n−1(T−τ1)]}=CM−CRB[n−1(T−τ1)]=0.This leads to the following result.Theorem 4Under SCWO, the optimal policy PM*(s, T) satisfies Eqs.(13),(14)andn*=T−τ1*B−1(CM/CR)+ϵ(s,T),where|ϵ(s,T)|≤1. Moreover,(16)limT→∞Tn*=limT→∞τi*=B−1(CM/CR)(i=2,…,n)(17)limT→∞ϕ(s+τ1*|Fs)=ϕ[B−1(CM/CR)].The previous section discussed a static situation in the sense that the operator of the equipment learnt the failure historyFsand had to program a maintenance policy using that and only that information. However, it may be more realistic to consider a situation in which the optimal policy can be revised as more information becomes available over time.Suppose that at each time s the operator learnsFsand revises the previous maintenance policy computing PM*(s, T). For large T, it should then be clear that the only relevant equation is (14). In other words, suppose that PM*(s, T → ∞) specifies a PM ats+τ1*. If new informationFs+h(h<τ1*) becomes available shortly after s and this information is used to obtain a new optimal policyPM*(s+h,∞),the fact that a PM was previously scheduled ats+τ1*is no longer relevant. Therefore, if we consider a process where new information is becoming available continuously over time and the corresponding policies are being revised accordingly, a PM will occur if and only if (14) holds forτ1=0for some s. In other words, a PM will occur at t if and only if (2) holds. More precisely, in this case the maintenance policy is a (random) stopping timeτD=inf{t>0:λ(t)≥ϕ[B−1(CM/CR)]}. Note that, for an NHPP, the intensity is deterministic andϕ(t|Ft)=ϕ(t)=λ(t)and hence (2) becomes (1). Note also that for a virtual age model withλ(t)=λR[V(t)],(2) becomes(18)V(t)=λR−1{ϕ[B−1(CM/CR)]}:=τVA,meaning that the system will be maintained whenever the virtual age reaches a threshold (i.e. the dynamic policy is periodical in the virtual age scale).Implementation of the dynamic policy (2) is straightforward: one needs to compute (an estimate of) the single quantityϕ[B−1(CM/CR)]and check it against (an estimate of) the intensity of the process. For instance, for the ARA1 model discussed before, we haveλ(t)=λR[t−(1−θ)tN(t)]and hence (2) becomes(19)λR[t−(1−θ)tN(t)]=ϕ[B−1(CM/CR)]or, equivalently,(20)t−tN(t)=θtN(t)+λR−1{ϕ[B−1(CM/CR)]}.In other words, at each failure the operator computes the right hand side of (20). This is the waiting lapse until the next PM provided that no new failures occur before it. On the contrary, if a new failure occurs before the PM is performed, (20) is computed again to obtain a new PM lapse and so on.Suppose that the system is maintained according to the policy τD. In other words, the CP begins att=0and runs until the first timet=τD,1such thatλ(t)=ϕ[B−1(CM/CR)]. At this time there is a PM which renews the system, so that, in fact, it is as if an independent realization N2(t) begins, which runs for for additionalt=τD,2units of time and so on. After m PMs are performed following this policy, the system will have run for∑i=1mτD,iunits of time and the total cost will be∑i=1m[CM+CRNi(τD,i)]=∑i=1mτD,iHi(τD,i). Since the random variables τD, iand Hi(τD, i) (i=1,…,m) are independent and identically distributed, it follows from the Law of Large Numbers that, for large m, the cost per unit of time will be(21)∑i=1mτD,iHi(τD,i)∑i=1mτD,i=m−1∑i=1mτD,iHi(τD,i)m−1∑i=1mτD,i≈E[τDH(τD)]EτD.A similar reasoning applies if the system is maintained according to τPalthough, since τPis deterministic and fixed, the cost per unit of time will be in this case(22)∑i=1mτPHi(τP)∑i=1mτP=m−1∑i=1mHi(τP)≈EH(τP)].The following theorem states that, for a system that is deteriorating over time, the right hand side of (21) is smaller than that of (22).Theorem 5Suppose that the process N(t) has the CWO property and is uniformly integrable and that the intensity λ(t) has only negative (downward) jumps. Then(5)holds.First, note from Lemma 1 that the intensity λ(t) is a submartingale and hence has a Doob–Meyer decompositionλ(t)=γ(t)+R(t)with γ(t) being an increasing process and R(t) a martingale. Hence, we have for every s and t thatH(t)−H(s)=CM+CR[N(s)+N(t)−N(s)]t−CM+CRN(s)s=−t−stH(s)+CRt∫stλ(u)du+CRM(t)−M(s)t=−t−stH(s)+CRt[uλ(u)]st−CRt∫studλ(u)+CRM(t)−M(s)t=t−st[CRλ(s)−H(s)]+CR[λ(t)−λ(s)]−CRt∫studλ(u)+CRM(t)−M(s)t=t−st[CRλ(s)−H(s)]+CR∫stt−utdλ(u)+CRM(t)−M(s)t=t−st[CRλ(s)−H(s)]+CR∫stt−utdγ(u)+CR∫stt−utdR(u)+CRM(t)−M(s)t≥t−st[CRλ(s)−H(s)]+CR∫stt−utdR(u)+CRM(t)−M(s)tbecause∫stt−utdγ(u)≥0since the integrator γ(u) is increasing and the integrandt−1(t−u)is positive for t > s and negative for t < s. Now, substituting above τDfor s and τPfor t and noting that∫0tudR(u)is also a martingale, it follows from the OST that(23)E[H(τP)−H(τD)]−E{τP−τDτP[CRλ(τD)−H(τD)]}≥CRτPE{R(τP)−R(τD)−∫τDτPudR(u)+M(τP)−M(τD)}=0.Now, from the definition of τD, the right-continuity of λ and the fact that λ(t) has only downward jumps, it follows thatλ(τD)=ϕ(τP). Also, sinceB(τP)=τPϕ(τP)−Φ(τP)=CM/CR,we have thatEH(τP)=[CM+CRΦ(τP)]/τP=CRϕ(τP). Substituting these two expressions into (23) we get thatEτDτPCRϕ(τP)−1τPE[τDH(τD)]≥0,which is equivalent to (5).□Consider K independent, identical repairable systems, where nifailures are observed in the ith system (i=1,2,…,K). We denote by Ti, j(i=1,2,…,K;j=1,2,…,ni) the random variable representing the jth failure of the ith system and by ti, jits observed value. If the ith system is time truncated, it is observed until the predetermined timeti*. If it is failure truncated, it is observed until the predetermined number of failures ni. We consider a Power Law Process (PLP) reference intensityλR(t)=(β/η)(t/η)β−1and correspondingΛR(t)=∫0tλR(u)du=(t/η)β. The vector of model parameters isμ=(β,η,θ),where θ measures the efficacy of the repair. In order to have SCWO, we further assume that β > 1.Substitutingλ(ti,j)=λR[ti,j−(1−θ)ti,j−1]andΛ(ti,j)−Λ(ti,j−1)=ΛR[ti,j−(1−θ)ti,j−1]−ΛR(θti,j−1)into (7) and (8) we obtain(24)L(μ)=∏i=1K{∏j=1niλR[ti,j−(1−θ)ti,j−1]×e−ΛR[ti,j−(1−θ)ti,j−1]+ΛR(θti,j−1)}×e−ΛR[ti*−(1−θ)ti,ni]+ΛR(θci),whereci=ti*orci=ti,nidepending on whether the ith system is time or failure truncated.In order to estimate the right hand side of (19) we proceed as follows. First, we maximize numerically (24) to obtain the maximum likelihood estimates (MLEs)(β^,η^,θ^). The mean Φ(t) and ROCOF ϕ(t) functions are now (deterministic) functions of the model parameters. Hence, at least in theory, the MLEs could be substituted by their expression in terms of (β, η, θ) to obtain the MLE of those functions. However, since there is no closed form for Φ(t) and ϕ(t), we used a Monte Carlo step inside the estimation procedure instead. More precisely, once that(β^,η^,θ^)have been obtained, we simulate M systems with the estimated parameters(β^,η^,θ^)and used them to approximateΦ^(t)andϕ^(t)following the procedure explained below. In fact, we take the Monte Carlo size M large enough to make the approximation error at least one order of magnitude less than the MLEs error. Hence, in practice, the relevant uncertainty in the final estimates would depend only on the precision of the MLEs.To compute the approximations toΦ^(t)andϕ^(t),we use the fact that the SCWO property implies that ϕ(t) is increasing and, hence, Φ(t) is convex. Therefore, once the auxiliary Monte Carlo experiment is run, in order to take into account the convexity restriction, we letΦ^(t)be the Greatest Convex Minorant (GCM) of the Nelson–Aalen estimator of Φ(t). Then, sinceϕ(t)=Φ′(t),we letϕ^(t)be the right derivative ofΦ^(t)(see, for instance, Boswell, 1966; Gilardoni & Colosimo, 2011). This works quite well for the large Monte Carlo size we are using and, unlike other nonparametric procedures, does not require setting up tuning parameters. The estimatesΦ^(t)andϕ^(t)can now be used to compute(25)B^(t)=tϕ^(t)−Φ^(t).InvertingB^(t)we obtain an estimate ofτP=B−1(CM/CR). Likewise, the right hand side of (20) can be estimated now after noting that, for the PLP reference intensity,λR−1(x)=η[ηx/β]1/(β−1).We note that, since the right hand sides of (19) and (20) do not depend on the history of the system, the Monte Carlo simulation has to be done only once during the entire process.Due to the fact that Φ(t) and ϕ(t) are estimated using an auxiliary Monte Carlo simulation, the calculation of standard deviations using the Delta Method is difficult. Instead, we propose to compute confidence intervals based on a parametric bootstrap. Suppose we want a confidence interval for τVA. A bootstrap sample of τVAcan be obtained as follows:1.Use the MLEsβ^,η^andθ^to generate K systems under the imperfect repair model desired with the same truncation structure as the original data set.Use the generated data set to maximize (24) and compute the MLEsβ^(b),η^(b)andθ^(b).Use the Monte Carlo simulation described above to compute estimatesΦ^(b)(t),ϕ^(b)(t)and then(B^−1)(b)(t).Given a cost ratio CM/CR,τVA(b)is obtained from (18).Repeat the procedure above B times to obtain(τ^VA(1),…,τ^VA(B)). The sample percentiles can then be used to construct the desired confidence interval for τVA.In this section we present a simulation study conducted in order to provide a better understanding of the economic impact of implementing the dynamic policy proposed in the previous sections. Monte Carlo experiments were carried out to estimate the costs per unit of time for the dynamic and periodical policies in different scenarios. We note that the comparison addresses a point which is slightly different from the result in Theorem 5, in the sense that here we are comparingEC(τP)andEC(τD),while the result in Theorem 5 refers toE[τPC(τP)]/τP=EC(τP)andE[τDC(τD)]/EτD.The simulations were done using a script written in R, a language and environment for statistical computing (www.R-project.org, v.2.15). The performance of each policy was measured computing the mean cost per unit of time for the periodical and dynamic policy. For each scenario, failure times were generated forN=100,000systems according to an ARA1 model with a PLP reference intensity. The 120 scenarios were defined by combining•β=1.5, 2.0, 2.5 and 3,θ=0.1, 0.3, 0.5, 0.7 and 0, 9,CMCR=13,15and115andboth the periodical and the dynamic policies.The η value remained fixed at 15,000 units of time since it is essentially a scale parameter and has no important consequence in the comparison of the policies. The procedure to run the simulation for each scenario and policy is described below.For the periodical maintenance policy, we first obtained the optimal PM period τPfor each scenario. Then, for each of the Monte Carlo replications, failures were generated up to τP. The observed number of failures was then used to compute the actual cost per unit of time,[CM+CR×number of failures]/τP. The average of theN=100,000replications of these actual costs is reported in Table 1 under the columns labeled periodical, together with their standard deviation.Since the truncation time τDis random, the procedure for the dynamic policy is more complicated. We first computed the right hand side of (20) usingtN(t)=0to obtain a provisional value of τD. Then, we generated a failure time for the given scenario and replication. If the failure occurred after the provisional τD, we stopped and computed the corresponding cost per unit of time[CM+CR×0]/τD. Otherwise, we recomputed the right hand side of (20) to obtain a new provisional τDand generated a new failure. If this new failure occurred after the tentative τD, we stopped and computed now the cost[CM+CR×1]/τDand so on, until a PM was effectively realized. The average and standard deviation of theN=100,000replications of the cost per unit of time for each scenario is reported in Table 1 under the columns labeled dynamic.In addition to the point estimates for the cost reported in Table 1, Fig. 3plots the same point estimates versus β and θ. The main findings are described below.•For both policies, the mean costs decrease as the efficiency of repair θ decreases [see Fig. 3(a) to (c)]. In other words, the better the repair the lower the mean cost. However, this effect is more evident for the dynamic policy. In addition, for the same degree of repair, the mean costs for the dynamic policy are lower than the respective ones for the periodical policy. We note however that we have assumed that repair actions with different degrees have the same cost. A very important point to be observed from Table 1is that the differences in costs between the two policies are inversely proportional to θ. In general, as we get closer to MR (i.e. θ↑1), we have lower differences between the costs under the two policies.For smaller values of the cost ratio CM/CR, the mean costs per unit time for a given policy tend to be practically the same, no matter the effect of the repair. This pattern can be observed for both policies, although it is more evident for the dynamic policy. In practice, this result indicates that if one is dealing with much higher CRcosts, there is not much difference if one assumes IR of any degree or MR.For both policies, an increase in β leads to a decrease in the mean cost. This can be explained by the fact that, under such policies, a stronger convexity for the intensity function determines shorter intervals between PM actions and, consequently, less failures are observed in the systems.Finally, the point estimates of the mean costs are consistently lower for the dynamic than for the periodical policy.Off-road trucks are used to transport loose materials such as minerals and waste in mining operations. Good performance of this equipment is essential for the financial health of this kind of business. Due to the high costs involved, a great concern is the implementation of sound maintenance policies in order to prolong their life and reduce expenses generated by the occurrence of unexpected failures. In the case studied here, the company wanted to adopt a maintenance policy that favored preventive maintenance, as opposed to repair actions taken after failures. More precisely, the company declared that a repair was 23 percent more expensive than a maintenance (i.e. the cost ratioCM/CR=1/1.23).The data set consists of 208 failure times, in hours of operation, recorded for a sample of 193 diesel engines used in off-road trucks. The number of failures per engine ranged from zero up to 4. Out of the 193 engines, 52 were time truncated due to the fact that their last inspection time corresponds to a preventive maintenance.Fig. 4 (a) plots the mean cumulative number of failures versus time. The convex shape of this function indicates that failures tend to occur more frequently as the system age increases. Therefore, it seems reasonable to assume SCWO and to search for a PM policy in order to avoid frequent failures.We fitted the ARA1-PLP model. The MLEs and 95 percent confidence intervals (computed using the observed information) wereβ^=2.458(2.185; 2.765),η^=15,586(14, 605; 16, 633) andθ^=0.471(0.330; 0.673). The large value ofβ^gives strong evidence that the systems are deteriorating, while the fact that the efficiency of repair estimateθ^is significantly different from zero and one, suggests that the history has to be considered when determining a maintenance policy.To compute estimates for Φ(t), ϕ(t) and B(t) we ran the Monte Carlo simulation described in Section 5, withM=10,000. The estimated ROCOFϕ^(t)and correspondingB^(t)are shown respectively in Fig. 4(b) and (c). An estimate ofτP=B−1(CM/CR)is obtained interpolating the function in Fig. 4(c). Table 2shows point estimates and bootstrap 95 percent confidence intervals usingB=10,000for several cost ratios. Likewise, having computedϕ^(t)andB^(t)and using the fact that for the PLP intensity we have thatλ^R−1(x)=η^[η^x/β^]1/(β^−1),one can computeτ^VA=λ^R−1ϕ^[B^−1(CM/CR)]}. These values and corresponding 95 percent confidence intervals are also shown in Table 2.Consider the cost ratioCM/CR=1/1.23. The estimates in Table 2 are interpreted as follows:•Under a MR PLP model, an estimate of the optimal preventive PM period is 15,815 hours, with a 95 percent confidence interval from 13,632 to 18,082 hours. For a new system, this is how long the company should wait for the first PM action, no matter how many failures occur until then.Under an IR ARA1-PLP model, an estimate of the optimal virtual time for the first preventive PM based on the dynamic approach isτ^VA=11,373hours, with a 95 percent confidence interval from 10,978 to 12,023 hours. For a new system, the company should wait untilV^(t)=t−(1−θ^)tN(t)=τ^VAfor the first PM action. In practice, it means that the PM action will occur att=τ^VAif no failure occurs until then. If any failure is observed beforeτ^VA=11,373hours, the optimal time to the first PM must be recalculated according to (20) and so on.We proposed a dynamic method to estimate the optimal PM policy for repairable systems. This dynamic policy updates the optimal PM time continuously as the information provided by the failure history of the system becomes available.The dynamic policy was derived for a fully general IR model, in the sense of a system whose failures occur according to an arbitrary counting process, with the only restriction that the system is deteriorating continuously over time. This assumption, which we called Continuous Wear-out, was shown to be equivalent to the intensity of the counting process being itself a submartingale. When compared to the usual periodical maintenance policy of Barlow and Hunter (1960), we proved in Theorem 5 that, if both used over a long period of time, the dynamic policy will tend to incur in lower operating costs than the periodical one.In Sections 5 and 7 we considered implementing both the dynamic and periodical policies in the context of the ARA1 virtual age model (Doyen & Gaudoin, 2004; Kijima et al., 1988). We showed how to obtain MLEs for the model parameters and used a Monte Carlo step to compute approximations to the MLEs of the ROCOF and related functions, for which there is no closed form expression. Our proposal also includes a parametric bootstrap to obtain confidence intervals for the model parameters and for the periodical and dynamic maintenance policies.Finally, to better understand the implications of the dynamic policy, as well as the result proved in Theorem 5, Section 6 reported on the main findings of a simulation study conducted in order to compare the performance of the periodical and dynamic policies. It showed that the expected operating cost per unit of time may be much lower when using the dynamic policy, especially when either (i) the cost ratio CM/CRis large or (ii) the effect of the repair is far from the MR case.

@&#CONCLUSIONS@&#
