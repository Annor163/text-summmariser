@&#MAIN-TITLE@&#
Automated lung segmentation and smoothing techniques for inclusion of juxtapleural nodules and pulmonary vessels on chest CT images

@&#HIGHLIGHTS@&#
Fully automatic lung segmentation and smoothing techniques are proposed.The method can include juxtapleural nodules and pulmonary vessels properly.Experimental results show the effectiveness of our approach.The average processing time is over 20 times faster than manual segmentation.

@&#KEYPHRASES@&#
Lung segmentation,Juxtapleural nodule,Pulmonary vessel,Fuzzy c-means clustering,Curvature threshold,

@&#ABSTRACT@&#
Segmentation of the lung is often performed as an important preprocessing step for quantitative analysis of chest computed tomography (CT) imaging. However, the presence of juxtapleural nodules and pulmonary vessels, image noise or artifacts, and individual anatomical variety make lung segmentation very complex. To address these problems, a fast and fully automatic scheme based on iterative weighted averaging and adaptive curvature threshold is proposed in this study to facilitate accurate lung segmentation for inclusion of juxtapleural nodules and pulmonary vessels and ensure the smoothness of the lung boundary. Our segmentation scheme consists of four main stages: image preprocessing, thorax extraction, lung identification and lung contour correction. The aim of preprocessing stage is to encourage intra-region smoothing and preserve the inter-region edge of CT images. In the thorax extraction stage, the artifacts external to the patient's body are discarded. Then, a fuzzy-c-means clustering method is used in the thorax region and all lung parenchyma is identified according to fuzzy membership value and connectivity. Finally, the segmented lung contour is smoothed and corrected with iterative weighted averaging and adaptive curvature threshold on each axis slice, respectively. Our method was validated on 20 datasets of chest CT scans containing 65 juxtapleural nodules. Experimental results show that our method can re-include all juxtapleural nodules and achieve an average volume overlap ratio of 95.81±0.89% and an average mean absolute border distance of 0.63±0.09 mm compared with the manually segmented results. The average processing time for segmenting one slice was 2.56s, which is over 20 times faster than manual segmentation.

@&#INTRODUCTION@&#
According to the American Cancer Society, lung cancer is the leading cause of cancer death in both women and men, killing more than 150,000 people per year—more than colon, breast, ovarian and prostate cancers combined in the U.S [1]. The existence of lung cancer is usually indicated by the identification of pulmonary nodules. Early detection of potentially cancerous pulmonary nodules may be a way to improve a patient's chances for survival [2]. Computed tomography (CT) based computer aided diagnoise/detection (CAD) is the most commonly used diagnosis technique because of its high sensitivity of small pulmonary nodules and flexible representation of the human thorax [3]. Accurate segmentation and quantitative assessment of the lung from CT images are of great importance in routine clinical practice for assessing the existence and severity of specific diseases and for monitoring responses to therapies. However, accurate segmentation of the lung CT images with nodules is not an easy task because of the highly varied properties of pulmonary nodules such as shape, size, intensity, and location. In [4], Armato et al. showed that 5–17% of the lung nodules in their test data was missed due to the inaccurate preprocessing segmentation, depending on whether or not the segmentation algorithm was adapted specifically to the nodule detection task. Other problems leading to the inaccurate lung segmentation [5] can be summarized as (a) false positive inclusion of other organs outside the lung, (b) nonsmooth exclusion of the trachea and pulmonary vessels in the hilar regions, and c) posterior and anterior attachments between left and right lungs.Although radiologists are able to identify the lung boundary slice by slice, it is extremely time-consuming and prone to intra- and inter-observer variability [6]. Therefore, the availability of an automated, reliable, and accurate computerized segmentation tool for this purpose could be of great value. Thresholding method combined with region growing [7,8] is commonly used to extract lung parenchyma, by which those tissues having higher gray level than the selected threshold are excluded from the thoracic region. Nevertheless, since the juxtapleural nodules have similar densities with their surrounding tissues, these juxtapleural nodules, together with their surrounding tissues, will be removed from the lung area and will never be recognized in the later stages. Furthermore, high density pulmonary vessels are also ruled out from the lung area, which bring about indentations and salience in the lung boundary near the mediastinum.To compensate for the lost juxtapleural nodules and ensure the smoothness of the lung boundary, several methods have been proposed to correct the lung contours. In [9], a rolling ball algorithm was applied to the lung contours segmented by thresholding to avoid the loss of the juxtapleural nodules. However, as is pointed out in [10], due to the extremely varied sizes of juxtapleural nodules, it is difficult to select a proper rolling ball radius that is suitable for all juxtapleural nodules. In [11], Gurcan et al. designed an indentation detection method for ameliorating the initial lung contour. Bellotti et al. [12] put forward a new active contour, called glued elastic band, to correct the contour of lung parenchyma. Both two above methods highly rely on the predefined threshold, unfortunately, it cannot be chosen automatically but empirically. Pu et al. [13] proposed an adaptive border marching algorithm (ABM) to correct the lung boundary. The problem with ABM is that the border marching with fixed threshold may failed in some slices. For example, the lung lobe containing juxtapleural nodule needs a smaller threshold while the lung lobe without juxtapleural nodule and containing convex region requires higher threshold. Varshini et al. [14] proposed an improved ABM algorithm with two thresholds to solve this problem. In [15,16], a segmentation-by-registration scheme is used to segment and correct the lung boundary. This type of methods works well on the lungs even containing (substantial) pathologic abnormalities. But the creation of a model used in registration is not a trivial issue due to the high density pathologies in varying degrees of severity.In addition to the abovementioned studies, a few algorithms [17,18] based on curvature information are used to correct the lung border with juxtapleural nodules and pulmonary vessels. The motivation for the curvature-based method comes from the observation that a rapid change in curvature usually indicates a nodule, large vessel or bronchus. But for initial rough contour it is difficult to compute an accurate curvature, since the smoothness of the contour has a great impact on curvature calculation due to the second derivatives involved. Generally, in order to smooth the lung contour, morphological erosion and dilation operations were commonly used techniques [16,19,20]. However, designing a proper structuring element (SE) is still a problem since a large size SE may cause over-segmentation, and vice versa.In this study, we propose an accurate lung segmentation method in thorax CT images and an efficient scheme for smoothing and correcting the segmented lung boundary for including juxtapleural nodules and pulmonary vessels. Our approach begins with image filtering via nonlinear anisotropic diffusion. Then, a fuzzy-c-means clustering method is used to extract initial lung boundary. Finally, a correction scheme based on adaptive curvature threshold is proposed to re-include juxtapleural nodules and pulmonary vessels. To compute an accurate curvature, a scheme termed “iterative weighted averaging” is used to smooth the rough lung contour in advance.Comparing to the works discussed in the literature, the work presented in this paper is different in the following ways:(1)We develop a fully automatic approach for segmenting lung boundary in chest CT images which does not need any user interaction.The proposed method can re-include all juxtapleural nodules and properly include the pulmonary vessels near the mediastinum.Additionally, our method can produce a smooth lung boundary instead of using morphological smoothing.The remainder of this paper is organized as follows: Section 2 provides a detailed description of our method. The experimental results are presented with a brief discussion in Section 3. And the paper concludes in Section 4.Our segmentation method consists of four main stages: image preprocessing, thorax extraction, lung identification and lung contour correction, as displayed in Fig. 1. We explain the proposed method in detail.The purpose of preprocessing is to reduce image noise, which benefits the following clustering step, since image clustering algorithms can be sensitive to noise. Linear low-pass filtering gives poor results as it incurs even more edge blurring and detail loss. However, nonlinear anisotropic diffusion filtering can overcome this drawback by introducing an implicit edge detection step into the filtering process so as to encourage intra-region smoothing and preserve the inter-region edge. The basic nonlinear anisotropic diffusion is characterized by the partial differential equation model given by [21](1)∂I∂t=div(c(∥∇I∥)∇I)where ∥.∥ and div denote the L2 norm and the divergence of the associated quantities, respectively; ∇ represents the gradient of the diffusing image I; and c(.) is a diffusivity function, also referred to as the diffusion coefficients, which is chosen locally as a function of the modulus of the image intensity gradient(2)c(∥∇I∥)=e−(∥∇I∥/ω)2ω is referred as the diffusion constant and determines the filtering behavior. A commonly used discrete version of (1) is given by the forward Euler numerical approximation with the initial condition of the original image(3)Ij(n1+1)=Ij(n1)+τ[div(e−(∥∇Ij(n1)∥/ω)2∇Ij(n1))]where τ is the step size of the independent variable t used to approximate ∂I/∂t; n1 is the discrete-time index (or the iteration number); andIj(n1)stands for the image intensity at the position j and the iteration number n1. For a 2D image I, j ranges from 1 to M×N, where M and N are the size of I.In this step, rough extraction of the thorax based on thresholding is performed. The goal of extracting thorax is to discard the artifacts external to the patient's body to a certain extent. Accurate extraction of the thorax using thresholding is not an easy task due to the following reasons. First, fat and the bed where patient lies are close to each other and has similar Hounsfield unit [HU] number, which limits the use of thresholding methods. Second, partial volume effects caused by the limited resolution of the imaging system raise more difficulties. Fortunately, precise extraction is not necessarily required in our method since primary purpose of the thorax extraction is to reduce computational cost in the following clustering step. As shown in Fig. 2, fat, bone, muscles and vascular tree in the thorax have high CT numbers. On the contrary, lung parenchyma, airway and background have low CT numbers, so a mean value of two peaks (lung parenchyma, airway and fat) is used to binarize the images. After image binarization, 2D hole filling [22] algorithm is used and the thorax is extracted by searching the largest connected components.The lung identification stage is implemented by three steps: air-filled regions including lung parenchyma and airways are firstly detected by fuzzy c-means method; secondly, the large airways (primarily the trachea and main bronchi) are eliminated from air-filled regions by region-growing algorithm; thirdly, the left and right lungs are separated by analyzing the remaining connected components slice by slice, as shown in Fig. 3.Fuzzy segmentation has been favored over hard segmentation in some medical image applications since partial volume effects and image noise reduce the accuracy of hard segmentation. To cope with the limits of hard segmentation, a fuzzy c-means (FCM) clustering method is employed to classify pixels into several tissue categories.FCM is a well-known clustering technique used in non-supervised image segmentation for pixel classification [23]. In FCM method, a set of tissue classes is first determined. Each pixel is then classified by its membership values of tissue classes according to its intensity. Membership value of a certain class indicates the likelihood of the pixel belonging to that class. Each tissue class has a centroid. The objective of FCM clustering is to compute the membership values for each pixel so that they are clustered around the centroid of each class. FCM can be written as the minimization of the weighted inter-class sum of the squared error objective function JFCM.(4)JFCM=∑c=1C∑j=1Jujc2∥Ij−vc∥2wherevcis the centroid of class c and C is the total number of tissue classes; ujcis the membership value of pixel j for class c and requires ujc∈[0, 1] subject to∑c=1Cujc=1; J is the total number pixels in the image and Ijis the image intensity at the position j. The objective function is minimized when a large membership is assigned to a pixel close to the centroid of a class and a small membership value is assigned to a pixel far away from the centroid. This is a nonlinear problem and can be solved iteratively. During each iteration, a new set of membership functions and class centroids are computed. The following steps describe the FCM method:(1)Set the initial values for class centroids,vc,c=1,...,C.Compute the membership values(5)ujc=∥Ij−vc∥−2∑l=1C∥Ij−vl∥−2Compute the new centroid for each class(6)vc=∑j=1Jujc2Ij∑j=1Jujc2Repeat steps (2) and (3) until the algorithm converges. Convergence is reached when the maximum changes over all centroids between two iterations is less than a predefined small threshold value ϵ (0.001 in current algorithm).The presented technique for detecting the air-filled regions is based on one 2D transverse slice using FCM. We design a scheme to propagate the segmentation to 3D space. First, the segmentation is computed on the top slice of air-filled regions localization. Then, the segmentation is propagated to subsequent slice using the centroid of current segmentation as initialization. The propagation stops at the bottom slice where lung area disappears. We have defined four classes in the chest CT images: air-filled regions (including lung parenchyma and airway), fat, bone, other tissues (including muscles and vascular tree), as depicted in Fig. 2. Four membership values are computed for each pixel. As is known that FCM method can converge faster and more efficiently if they are initialized close to the desired centroid. The initial value of each class centroid is estimated from histogram. Specifically, we calculate the first and second derivatives of the histogram, and the initial estimations are defined as the CT numbers in the histogram with zero-crossings in the first derivative and negative second derivatives. For example, in Fig. 2, four CT values (125 HU, 925 HU, 1059 HU and 1297 HU) are used as the initial centroids for four tissue classes (air-filled regions, fat, other tissues and bone), respectively.Once the fuzzy membership values are obtained, we determine a hard segmentation by assigning each pixel solely to the class that has the highest membership value for that pixel. After performing the hard segmentation, each of the separated regions is a closed, then, we use 2D hole filling algorithm [22] to detect the air-filled regions.After detecting the air-filled regions, the trachea and main bronchi still remain in the result. To ensure these structures do not contribute to the segmented lung regions, the trachea and main bronchi are extracted and eliminated from the segmented air-filled region. The location of the trachea is automatically identified by searching the large, circular and air-filled region near the center on the top axial slices of the scan. If no suitable region is detected in the top slices, the bottom slices of the scan are inspected to be able to handle cases that were scanned in a reverse direction. Then, a seed point is identified based on the center-of-mass location of the segmented trachea region in this slice. From this seed point, a 2D region-growing technique [24] is used to expand the identified trachea region. Regions in the current slice provide potential seed point positions for the next slice. Region growing ceases when the size of the region on a new slice increases dramatically, which indicates the main bronchi has merged into the low-density lung parenchyma.After the large airways elimination, we analyze the remaining connected components slice by slice. This results either in one (both left and right lungs merge together) or two (both two lungs are separated). If the lungs represent one connected component, the lungs are separated using a dynamic programming approach similar to the technique described by [16]. Dynamic programming is applied to find the maximum cost path through a graph with weights proportional to pixel gray-level of the original image. The maximum cost path corresponds to the junction line position. The search area for the dynamic programming is determined in three dimensional, starting from the center of gravity of the lung region. Let xcgbe the x-coordinate of the center of gravity. The search area on axial slices is now defined as all pixels (x, y) for which xcg−10≤x≤xcg+10 instead of xcg−5≤x≤xcg+5 used in [16], as depicted in Fig. 3d. From our experiment, we found this region to be more accurate to detect the anterior (or posterior) junction line. Pixels outside this range are not considered since it is unlikely that the anterior (or posterior) junction line locates in this area.The juxtapleural nodules tend to be excluded from the lung segmentation result in the previous step due to its density that is similar with thorax; moreover, high density pulmonary vessels are also ruled out from segmentation result which give rise to indentations and salience in the lung boundary near the mediastinum. To solve these problems, a correction algorithm based on adaptive curvature threshold is proposed.Curvature is an important feature for the lung contour where juxtapleural nodules and pulmonary vessels locate since these positions often have larger curvature values. However, it is difficult to compute an accurate curvature for each point on the initial rough contour since the behavior of the curvature is quite sensitive to local perturbations due to the second derivatives involved. In such case, one may wish to smooth the contour in advance. To do so, we first use a fast and stable scheme termed “iterative weighted averaging” to smooth the lung contour, then, a correction algorithm based on adaptive curvature threshold is described.Iterative weighted averaging [25] is a commonly used method to smooth the signal by means of averaging the neighborhood. LetSj(0)=(xj,yj)be a two-dimensional signal (i.e., lung contour in each slice) at the position j before smoothing. The smoothed signalSj(n2+1)on (2s+1) neighborhoods at the (n2+1)th iteration is simply(7)Sj(n2+1)=∑i=−si=sSj+i(n2)di+swith(8)∑i=−si=sdi+s=1The coefficients diare set symmetrically relative to the center, that is ds+i=ds−i(i=−s, ..., s.). The expression (8) is equivalent to∑i=02sdi=1. The choice of the coefficients di(i=0, ..., 2s.) is flexible, as long as it satisfies the above two conditions.In particular, if s is set as 1, the iterative weighted averaging can be extended to include the nearest-neighbors(9)Sj(n2+1)=Sj−1(n2)d0+Sj(n2)d1+Sj+1(n2)d2withd0+d1+d2=1Taking d0=d2=q and d1=1−2q, where q is a constant, this reduces to(10)Sj(n2+1)=q(Sj−1(n2)+Sj+1(n2))+(1−2q)Sj(n2)rearrangement of terms leads to(11)Sj(n2+1)−Sj(n2)=q(Sj−1(n2)−2Sj(n2)+Sj+1(n2))which is a discrete approximation of the linear diffusion equation(12)∂S∂t=q∇2SIn this paper, diis chosen as Newton–Cotes coefficient in the mathematical subfield of numerical analysis since it satisfies the aforementioned two conditions. The expression of Newton–Cotes coefficient diwith the equal sample size h can be formulated as(13)di=(−1)m−imi!(m−i)!∫0m∏k≠ik=0m(t−k)dti=0,...,2s.where m=2s. Noted that diis irrelevant to h if Sjis sampled with the equal step size, which makes the iterative weighted averaging easy to perform.After lung identification in previous step, an edge-tracing algorithm [24] is used to track the lung region automatically for each slice and form a closed initial contour. Starting from the jth edge point on the initial contour atSj∈ℝ2, all other edge points are stored in counter-clockwise direction. The edge points with the equal sample length h can be derived by linear interpolation. GivenSj(n2)in the n2th iteration for point j, the (n2+1)th iteration based on three neighbors can be given below:(14)Sj(n2+1)=16Sj−1(n2)+23Sj(n2)+16Sj+1(n2)Fig. 4shows the smoothing results using iterative weighted averaging on a representative lung contour after 5 iterations. Compared with Fig. 4a and b, we can see that the lung contour is well smoothed, which is useful for correction based on curvature threshold in the next step.As is described before, the juxtapleural nodules and pulmonary vessels locate at the concave regions and the corresponding bending radii are much smaller compared with those of the whole lung parenchyma. Thus, these concave points with larger curvature values should be corrected, which is associated with three problems such as (1) how to represent the curvature of a point, (2) how to judge the convexity–concavity of a point, and (3) how to determine the curvature threshold for correction. Next, we will solve the above three problems one by one.For an arc composed of three successive points i−1, i and i+1 on the contour, let ribe the radius of the arc; κi, the curvature of the arc; li, the Euclidean distance between i and i−1/i+1; andwi, the height of the arc, i.e., the Euclidean distance from i to the line connecting i−1 and i+1 (see Fig. 5). The relationship between ri, liandwiis formulated as below:(15)wi=li22ri=li22κiIn the correction algorithm, licorresponds to the Euclidean distance between edge points, so it has a constant value for the equidistant sample, denoted as l. The expression (15) implies that the heightwiof an arc is inverse proportional to the radius riand proportional to the curvature κi. Therefore,wican be treated as a measure of riand κi. For simplicity, the heightwiand radius riof an arc are also viewed as the height and radius of point i, respectively.In order to judge the convexity–concavity of a point i on a closed contour, we define a reference vector Fi, which originates from point i, plumbs the line connecting i−1 and i+1, and always directs to the inside of the contour. If the heightwiis extended to a vector Withat originates from point i, then, the point where the height vector Wihas opposite direction with reference vector Fiis concave, otherwise is convex. For example, in Fig. 6, point 1 and 3 are concave and point 2 is convex. The convexity–concavity of a point i can be indicated by adding a sign to the value ofwiand denoted aswi˜.(16)wi˜=wiifiisconvex,−wiifiisconcave.The curvature threshold is used as the criteria for selecting the points to be corrected. As is noted that juxtapleural nodules and pulmonary vessels commonly locate at the concave parts of the contour and have very small bending radius, so those concave points with very large curvature values should be refined. Let η be the curvature correction threshold;Qbe the sequence of all pixels on a contour; andw¯(Q)be the average of height magnitudes for the sequenceQ. Our correction algorithm can be summarized below:(1)For an initial contourQ, apply the iterative weighted averaging method to get a smoothed contour, then, compute the average of height magnitudesw¯(Q)and setη=w¯(Q).Resample the contourQwith the equal step length l.For each pointi∈Q, compute the height magnitudewi, the height vector Wi, the reference vector Fi, and the concavitywi˜. Ifwi˜<0andwi>η, then it will be amended: connecting its two neighbors i−1 and i+1 with a line and removing it from the sequenceQ.Repeat steps (2) and (3) until the length of the contourQdoes not change.In this correction algorithm, the first step is used to smooth the initial contour and determine the proper curvature threshold for correction. The second step is used to keep the sample length l a constant and assure the correction algorithm stability. The third step is used for judgement and correction.Next, we will explain the selection of the curvature correction threshold in detail. To determine a proper curvature threshold for correction, we need consider the shape feature of a lung contour. Generally, a normal lung contour on each slice is not only smooth but has a approximated crescent-shaped outline, so it can be partitioned into two parts according to convexity–concavity. For a normal contourQ, letQ1andQ2be the sequence of all concave and convex pixels, respectively. AsQ2has a smaller bending radius than that ofQ1on average, we havew¯(Q1)<w¯(Q)<w¯(Q2). Thus, for a normal contour, our correction algorithm will not execute when choosingw¯(Q)as the curvature correction threshold becauseQ1has a larger bending radius than average andQ2is convex. But for a diseased contourQ′containing juxtapleural nodules or pulmonary vessels, the pixels where juxtapleural nodules and pulmonary vessels locate are concave and have much larger curvature than average, when choosingw¯(Q′)as the curvature correction threshold, these pixels will be amended while other pixels with larger curvature but convex or concave but smaller curvature are well protected.In this section, we first discuss the parameter settings used in our method. Then, we compare the result of our method with that of manual segmentation by an expert. All our implementation are programmed in Matlab R2010a environment and operated on a personal computer, equipped with an Intel Core 2 E6500 processor at 2.93GHz and 4GB RAM.For our study, 20 multidetector computed tomography (MDCT) thorax scans of patients with pulmonary nodules were utilized. The images were generated by 2 kinds of MDCT scanners (in 10 cases by Somatom Sensation 64 of the Siemens Medical System; in 10 cases by Brilliance 64 of the Philips Medical Systems). Each patient was imaged by a common protocol (120kV/Auto mA, helical pitch: 1.35/1) without any contrast enhancement, and the images were created using a normal reconstruction kernel. The image size varied from 512×512×210 to 512×512×540 voxels. The in-plane resolution of the images ranged from 0.58×0.58 to 0.82×0.82 mm and the slice thickness from 0.6 to 1.0 mm. All the manual segmentation results by an expert are available at the time of experiment.Several parameters have been used in our algorithm. Table 1lists these parameters and the values used in current algorithm.The iteration number n1 and the time step τ of nonlinear anisotropic diffusion filtering influenced the segmentations of the following FCM method. From numerous experiments, the optimal value of the number of iterations was determined as 3 and the time step was set as 0.15, at which the computational efficiency was maximized without sacrificing the segmentation accuracy.The iteration number n2 and the sample size h of iterative weighted averaging influenced the degree of contour smoothness and thereby influenced the computation of curvature threshold for correction. The constant distance l assured the stability of lung correction process. We performed a number of experiments on the effects of smoothness and correction results with respect to the parameter variations. In this paper, the optimal parameters n2, h and l were respectively set as 5, 0.6 and 0.8 based on our numerous experiments with consideration of maximizing the performance of our correction algorithm. We have not found that slight changes of three parameters greatly affect the correction results.Based on the above parameters, our method was applied to 20 datasets. Among 20 datasets, in total of 307 lung nodules (maximum diameter range: 1.2–17 mm; mean: 3.9 mm) were determined by a consensus panel of two radiologists, of which 65 were juxtapleural nodules.The segmentation results were evaluated by re-inclusion ratio of juxtapleural nodules, accuracy evaluation and processing time. Fig. 7shows the segmentation results on the representative 2D slices between manually edited ground truth and our proposed segmentation. From Fig. 7, we can draw that our method was successfully applied to re-include the juxtapleural nodules (Fig. 7a and b). By testing against the 20 datasets, our experiments show that all of the juxtapleural nodules were re-included in the segmented lung regions after lung contour correction irrespective of its size and shape. Also, the pulmonary vessels near the mediastinum can be properly included and the entire lung contour can be well smoothed (Fig. 7c and d). As is observed in Fig. 7, there are some differences in the hilar area between manual segmentation and our proposed method. However, as illustrated in [5], it remains unclear at what points the segmentations are supposed to cut through the major bronchi and vessels in the hilar area where they enter the lung. Manual delineations also show much variance around the hilum, depending on definitions (or a lack thereof) and personal preferences with respect to smoothness. Thus, we believe our method based on iterative weighted averaging and adaptive curvature threshold provides a good basis for lung segmentation and smoothing. Fig. 8shows a 3D surface-rendered view of the segmented lungs before and after contour correction, respectively. The corresponding visualization result is obtained by Marching cubes algorithm [26].The accuracy evaluation was quantitatively performed using the following four measures [16,17]: volumetric overlap fraction, mean absolute border distance, false positive error and false negative error.• For two binary volumes Vautoand Vmanu, the volumetric overlap fraction is defined as the volume of their intersection divided by the volume of their union,(17)VOF(Vauto,Vmanu)=|Vauto⋂Vmanu||Vauto⋃Vmanu|• Given two borders Bautoand Bmanu, let dmin(p, Bmanu) be the minimum distance of a point p on the border Bautoto the border Bmanu, andd¯min(Bauto,Bmanu)be the average minimum distance from all points on the border Bautoto the border Bmanu. The mean absolute border distance between Bautoand Bmanuis defined as(18)MABD(Bauto,Bmanu)=0.5*[d¯min(Bauto,Bmanu)+d¯min(Bmanu,Bauto)]• False positive (negative) error is the ratio of the total number of automatically (manually) segmented voxels, which are not included in the manual (automatic) segmentation result to the total number of manually segmented voxels.Table 2shows the comparison of our proposed segmentation to the manually defined ground truth for 20 different datasets using the above metrics. The average of mean absolute border distance was 0.63±0.09 mm. The average of false positive error and false negative error was 1.89±0.89% and 2.39±0.73%, respectively. The volume of our proposed method and manually segmented volume was also shown in Table 2. The average of volumetric overlap fraction was 95.81±0.89%. Less than 5% in the volume overlap error is generally acceptable in clinical practice. Therefore, it shows that the proposed algorithm is accurate segmentation scheme of the lung in CT images for the volume measurement in clinical practice.The processing time for each step of our proposed method is summarized in Fig. 9. Except for the lung identification step, other three steps were run in parallel computing. The average total processing time per set of CT scans was 778.28 s and the average processing time to segment each slice was 2.56 s. About 1 min was required for the expert to manually segment two lungs in a slice. Thus, our method was high-efficiency. The mean calculation time in each step of our method was 96.53 s in image preprocessing, 20.72 s in the thorax extraction, 590.38 s in lung identification, and 70.66 s in lung contour correction for 304 slices on average. The processing time of the first three steps was proportional to the number of images for each dataset. The processing time exhausted on the lung contour correction step depended on the number of juxtapleural nodules and pulmonary vessels to be corrected per scan.In our method, adaptive curvature threshold is used for correcting the segmented lung contour to re-include juxtapleural nodules and pulmonary vessels. Compared with the works presented in [9,11,12], our threshold is automatically determined and varies on different slices. This help to avoid the erroneous inclusion caused by a single threshold. Moreover, since designing a proper SE is difficult, we introduce “iterative weighted averaging” scheme instead of using morphological smoothing presented in [17,20], to get a smooth lung contour. By this way, the curvature threshold can be calculated more accurate.We recognize the proposed technique still needs further improvement. As the examples in Fig. 10demonstrate, lung contour smoothing based on iterative weighted averaging will miss local sharp features of lung regions. If a small juxtapleural nodule is coincidently located at such “sharp” regions, it may be missed in the segmented lung volume. This limitation contributes to the majority of the undersegmentation in the evaluation of lung volume segmentation (Table 2). It is difficult to overcome this limitation or dilemma because the smoothness property of iterative weighted averaging will definitely lead to the missing of very details with high curvatures. Furthermore, it is necessary to smooth the initial rough contour for computing an accurate curvature since the behavior of the curvature is quite sensitive to local perturbations due to the second derivatives involved. However, as the examples in Fig. 11show, if the final segmentation results are given by the region merging between lung identification and lung contour correction, the undersegmentation errors caused by this dilemma will be alleviate largely.

@&#CONCLUSIONS@&#
