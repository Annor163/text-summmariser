@&#MAIN-TITLE@&#
Combining situated Cognitive Engineering with a novel testing method in a case study comparing two infusion pump interfaces

@&#HIGHLIGHTS@&#
Infusion pump interface designed with situated Cognitive Engineering was validated.Usability validation took place by comparison with a reference interface.A novel process tracing technique was used for analysis.Task performance increased with novel interface.Novel method was feasible for validating safety of medical devices.

@&#KEYPHRASES@&#
Medical device usability testing,Infusion pump,Human-machine interaction,

@&#ABSTRACT@&#
We validated the usability of a new infusion pump interface designed with a situated Cognitive Engineering approach by comparing it to a reference interface using a novel testing method employing repeated measurements and process measures, in addition to traditional outcome measures. The sample consisted of 25 nurses who performed eight critical tasks three times. Performance measures consisted of number and type of errors, deviations from a pre-established normative path solution, task completion times, number of keystrokes, mental effort and preferences in use. Results showed that interaction with the new interface resulted in 18% fewer errors, 90% fewer normative path deviations, 42% lower task completion times, 40% fewer keystrokes, 39% lower mental effort and 76% more subjective preferences in use. These outcomes suggest that within the scope of this case study, combining the situated Cognitive Engineering approach with a novel testing method addresses various shortcomings of earlier testing methods.

@&#INTRODUCTION@&#
While infusion pumps contribute to patient care, they are not without risks. From 2005 to 2009, around 56,000 adverse drug events associated with the use of infusion pumps were reported (Center for Devices and Radiological Health, 2011). Many of those use-related hazards were related to user-interface design deficiencies (Center for Devices and Radiological Health, 2010), the critical impact of which on the patient's safety is a well-known problem (Obradovich and Woods, 1996; Vicente et al., 2003). Approaching designs using Human Factors engineering has proven to be an effective means to enhance positive performance outcomes, such as fewer errors, less time to performance tasks and lower mental effort (Lin et al., 1998; Syroid et al., 2012).Nevertheless, the current practice in studying medical device technology has methodological shortcomings, as evidenced by an extensive literature study in this field (Schraagen and Verhoeven, 2013). First, previous studies lack a profound analysis of the user-device interaction by mainly focusing on final task outcomes (errors) and completion time as primary performance measures (Schraagen and Verhoeven, 2013). It has been suggested that only 69.5% of the practitioners pressed keystrokes contributing towards the goal state that is aimed to be achieved (Nunnally et al., 2004). Hence, merely measuring erroneous task outcomes undervalues the impact of complex menu structures on the process of task completion, and thus the occurrence of near accidents. Secondly, past studies draw their conclusions upon single user-device interactions, and are therefore unable to investigate the impact of learning effects on the infusion pump's usability (Garmer, 2002; Schraagen and Verhoeven, 2013). Lastly, previous studies lack a combination of subjective and objective measures in order to gain a more complete picture of the user-device interaction (Hornbæk, 2006).The aforementioned shortcomings in studying medical device technology potentially limit the informative value with respect to the effectiveness of Human Factors engineering in medical device design. The aim of this study is to evaluate the usefulness of a novel testing method, in a case study involving the comparison of two infusion pump interfaces. The study compared an existing infusion pump interface with a new infusion pump interface that has been designed with a situated Cognitive Engineering Human Factors approach. The novel testing method utilized in this study addresses the current limitations in the study of medical device design. Specifically, this study addresses these shortcomings by combining qualitative and quantitative analyses with objective and subjective measures in a usability validation study with repeated measures. Hence, the main aim of this study is to investigate whether this novel testing method would address shortcomings of previous methods.As reviewed by Schraagen and Verhoeven (2013), contemporary methods for studying medical device technology mostly report traditional outcome measures rather than ‘process tracing techniques’ placing emphasis on cognitive processes. To address this shortcoming, we introduce a novel, replicable method for a standardized representation of the user's task completion process. Our proposed method is feasible for qualitative or quantitative research, as well as mixed-method approaches. We applied the Goals, Operators, Methods, and Selection rules (GOMS) model (John and Kieras, 1996) as a framework for data coding to achieve a formal representation of task execution processes. In addition, introduction of novel interaction design requires initial learning (MacKenzie and Zhang, 1999) and may even be hampered by inappropriate transfer (Besnard and Cacitti, 2005). In order to capture performance differences beyond the first encounter, we explored the impact of task repetition on performance.

@&#CONCLUSIONS@&#
Using our novel testing method, we showed that (1) the inclusion of repeated measures is a relevant add-on for revealing learning effects and (2) both focusing on task outcomes and on process measures reveals a more realistic picture of the user-device interaction and the high-risk system's stability.This study also showed that following a standardized Human Factors design approach does not automatically result in an exhaustive detection of usability problems (see also Schmettow et al., 2013) and a complete elimination of use errors.