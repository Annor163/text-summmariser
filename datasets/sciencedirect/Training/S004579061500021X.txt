@&#MAIN-TITLE@&#
Design, implementation and evaluation of a smartphone position discovery service for accurate context sensing

@&#HIGHLIGHTS@&#
We analyze the impact of smartphone carry positions on readings provided by sensors.We use accelerometer, gyroscope and light sensors to detect position information.Two-stage method based on position is shown to enhance fall classification accuracy.

@&#KEYPHRASES@&#
Smartphone,Position discovery,Sensing,Pervasive computing,

@&#ABSTRACT@&#
Detecting user context with high accuracy using smartphone sensors is a difficult task. A key challenge is dealing with the impact of different smartphone positions on sensor values. Users carry their smartphones in different positions such as holding in their hand or keeping inside their pants or jacket pocket, and each of these smartphone positions affects various sensor values in different ways. This paper addresses the issue of poor accuracy in detecting user context due to varying smartphone positions. It describes the design and prototype development of a smartphone position discovery service that accurately detects a smartphone position, and then demonstrates that the accuracy of an existing context aware application is significantly enhanced when run in conjunction with this proposed smartphone position discovery service.

@&#INTRODUCTION@&#
Modern smartphones embody a large set of sensors that can be utilized to learn a wealth of information about a user’s surrounding environment. Researchers view the availability of such sensors as an opportunity for developing context-aware applications that can provide services tailored for each user’s context. Context-aware mobile computing is not a new research topic, for example, a survey paper [1] covering advances in this field was published more than a decade ago. Despite the concept being there for a while, a breakthrough for the number of context-aware applications offered in smartphones application markets (e.g., App Store for Apple iOS or Google Play for Android OS) is yet to happen. For the most part, the current context-aware applications do not meet users’ high expectations from technology.A key problem with current context aware applications is that they typically provide low level of accuracy, particularly when used in an environment different from what was conceived at the application development stage. A major reason leading to low accuracy is the wide variety of ways a user may carry his/her smartphone, henceforth referred to as smartphone position. Users carry their smartphones in different positions, e.g. in hand, in purse, in pants pocket, in shirt pocket, etc. Sometimes, their smartphones are in covered positions, in purse or pockets, while uncovered at other times, watching a video or talking on the phone. Sensor values of different sensors naturally vary based on smartphone position, which in turn impacts the accuracy of the context derived from these values.This article takes a bottom-up approach to derive a generic solution to the smartphone position problem. First, in this Introduction Section, we reflect to the reader the severity of the problem by providing motivating examples from the literature for context-aware applications that behave poorly when dealing with varying smartphone positions. Next, we analyze the impact of the smartphone position on raw sensor data. This is important since context derivation algorithms start from raw sensor data collected from smartphone sensors. To do this, we conducted a range of experiments that involved collecting sensor data from several different users carrying their smartphones in several different positions. Analysis of the raw sensor values collected from different smartphone position shows that the level of smartphone position impact on raw sensor data ranges from no impact at all for the case of GPS to a considerably high impact as in the case of gyroscope and accelerometer. The details of the analysis can be found in Section 3 of the article.Based on the analysis of the impact of smartphone position on raw sensors data, we have designed, implemented and evaluated a smartphone position discovery service. This service utilizes the sensor values collected from some carefully chosen sensors and detects the smartphone position with very high accuracy. It runs orthogonal to any other context aware service or application. The article describe the design, implementation and a detailed evaluation of this service. The utility of the service was demonstrated by showing that the accuracy of an existing context-aware application is significantly improved when it following the two-stage classification technique.To summarize, our contributions are as follows:1.We present a detailed study for the impact of smartphone positions on raw data for sensors that are common in current commercially available smartphones.Based on this study, we built a smartphone position discovery service that detects the smartphone position with high accuracy. This service can run in conjunction with context-aware applications to provide them with the current smartphone position.We integrated the service with an existing context-aware application for fall classification and demonstrated improvement in accuracy for this application when using the service.Before we indulge into the details of our solution, it is important to reflect to the reader the severity of the smartphone position problem by giving examples of context-aware applications that suffers from low accuracy when dealing with arbitrary carry positions.Consider three different context-aware applications each utilizing different sensor(s). SurroundSense [2] performs logical localization such as detecting if the user is currently having coffee at Starbucks, partying and shopping at Wal-Mart. The application is able to achieve logical localization by harnessing online sensor data from camera, microphone, and accelerometer sensors and comparing them with previous knowledge about the place. Smartphone position is a major obstacle for SurroundSense. For instance, if the smartphone is in a covered position, e.g. Hip Pocket, Pants Pocket, or Jacket Pocket, the system will not be able to take the required image to perform the color fingerprinting for the location. We believe that applications like SurroundSense can consult the smartphone position discovery service in order to take the required image when the phone is in reliable positions. We also believe that the sensor data from microphone and accelerometer would benefit from smartphone position by excluding the disadvantageous positions for the corresponding measured context.Next, lets consider an application that uses the microphone sensor. Researchers in [3] have developed an audio-based cough counting system running on a smartphone to monitor the health of patients with respiratory diseases. The application requires the patient to place the smartphone either in the shirt pocket or attached to a neck strap. In fact, the authors acknowledge that the chosen two positions do not represent an optimum choice in terms of patient comfort. However, the application needed to stick to these positions to achieve acceptable accuracy. We believe that smartphone position discovery service can play an important role if integrated with the cough counting system. Users can be given the chance to carry their smartphones freely and coughs will only be counted in suitable positions, i.e. when the smartphone is in the upper body region. In the data usage statistics of smartphones reported in [4], it was shown that user-smartphone interaction durations can be as high as 500min a day. We believe that with such long interaction durations between the user and the smartphone, the cough system would still have enough opportunity to capture audio in favored positions without restricting the users to place their smartphones in specific positions.Finally, we take an example for a context-aware application that is based on the accelerometer sensor. Here the benefit of smartphone position knowledge is not just bound to taking a go/no-go decision to capture contexts as in the previous two examples. Some applications provide better accuracy if trained for a single position. The fall classification application in [5] detects the type of fall from four different fall categories namely forward trips, backward slips, left lateral falls, and right lateral falls. The output of this application can be used by experts in the field of elderly care to develop fall prevention mechanisms and to assist first responders in providing more customized emergency procedures. In order to detect the type of fall, the application uses supervised machine-learning classifier with training data collected beforehand. Despite the fact that the experiment used a smartphone for data collection, users were not given the chance to carry the smartphone freely. Rather, the used smartphone was attached to the backside of a belt and users were asked to wear this belt and simulate the different categories of falls. Restricting the smartphone position in the experiment surely results in higher accuracy since the unification of position in both training and test data reduces the variability in the data, thereby, putting fewer burdens on the classifier. Nevertheless, we believe that such restriction in terms of smartphone position limits the practicality of the application.To overcome the problem caused by arbitrary smartphone positions, we propose a two steps approach for such context-aware applications. First, the offline training for the classifier can be done with different smartphone positions to generate a classifier trained for each position. Second, with the presence of the smartphone position discovery service, the application will know in advance the current smartphone position and choose the classifier corresponding to that specific position during the classification process. To demonstrate the potential improvement in accuracy that this approach can achieve, we have conducted two experiments to detect the above-mentioned four types of falls (similar to [5]). In the first experiment, both the training data and the test data were collected at arbitrary smartphone positions by allowing the user to put the smartphone either in pants pocket, hip pocket or jacket pocket. The confusion matrix for this experiment is shown in Table 1. In the second experiment, three training files, each containing the four types of falls, were collected for three mentioned smartphone positions. Afterwards, the user was asked to simulate the required four types of falls and the classifier was pointed to the training file corresponding to the smartphone position, assuming the smartphone position is known in advance. The confusion matrix of the second experiment is shown in Table 2.We notice that with arbitrary position (Table 1), the classifier fails significantly to distinguish the left lateral fall from the right lateral fall. Also, slips are being confused with right lateral falls in many occasions. The overall accuracy for the arbitrary positions experiment is 72.22%. We now turn into evaluating the ideal solution of assuming a smartphone position known in advance (Table 2). The results show a significant improvement for all fall categories with an overall accuracy of 94.8%. We conclude from these two experiments that with the knowledge of the smartphone position, the accuracy of fall classification improves dramatically, and in general the accuracy of any context aware application is likely to improve. However, the assumption of a complete knowledge of smartphone position is not a valid one. Any service that provides smartphone position information to a context aware application will most likely be not 100% accurate. So, given that a smartphone position discovery service is not 100% accurate, the question we hope to answer is whether the accuracy of a context aware application based on that position discovery service would still be higher than when that application does not use the position discovery service. We address this for the same experiment in Section 4.3 after presenting the implementation details for the smartphone position discovery service. So far, we have provided specific detailed examples of context-aware applications that can benefit from the smartphone position service. However, we anticipate that the service can provide utility to emerging context-aware application fields such as smart shopping [6,7], smart health [8] and smart living [9].The rest of the article is organized as follows. Next section provides literature review for existing body of works that tackled the smartphone position problem. Then, Section 3 provides an extensive analysis of the impact of different smartphone carry positions on raw sensors data. Section 4 describes the design, implementation and evaluation of the position discovery service. Finally, Section 5 concludes the paper.

@&#CONCLUSIONS@&#
