@&#MAIN-TITLE@&#
Automatic preference learning on numeric and multi-valued categorical attributes

@&#HIGHLIGHTS@&#
Learning preferences implicitly is a challenging task in the design of recommenders.Our approach infers preferences by analyzing choices without any explicit feedback.Choices considered are defined by numerical and multi-valued categorical criteria.

@&#KEYPHRASES@&#
Recommender systems,Preference learning,Aggregation operators,Fuzzy sets,Ranking,

@&#ABSTRACT@&#
One of the most challenging tasks in the development of recommender systems is the design of techniques that can infer the preferences of users through the observation of their actions. Those preferences are essential to obtain a satisfactory accuracy in the recommendations. Preference learning is especially difficult when attributes of different kinds (numeric or linguistic) intervene in the problem, and even more when they take multiple possible values. This paper presents an approach to learn user preferences over numeric and multi-valued linguistic attributes through the analysis of the user selections. The learning algorithm has been tested with real data on restaurants, showing a very good performance.

@&#INTRODUCTION@&#
Nowadays it is practically unconceivable to select our summer holiday destination or to choose which film to see in the cinema this weekend without consulting specialized sources of information in which, in some way or another, our preferences can be specified to aid the system to recommend us the best choices. That is because we live in an era where there are so many data easily available that it is impossible to manually filter every piece of information and evaluate it accurately. Recommender Systems (RS) have been designed to do this time-consuming task for us and, by feeding them with information about our interests, they are capable enough to tell us the best alternatives for us in a personalized way.The preferences of the user are stored in a structure called user profile. In this work, as usual in the literature, it will be considered that each decision alternative is represented through a set of values assigned to a certain set of predetermined attributes or criteria. In these situations, the user profile must somehow represent the preference of the user with respect to each of the possible values of the attributes. With this information, the RS may rate and rank the corpus of available decision alternatives and show it to the user to help him/her to make the final choice. The representation of the preferences, the recommendation process and the automatic management of the dynamic evolution of the preferences are three of the most challenging issues in the development of this type of systems [24].Concerning the latter problem (how to learn automatically the preferences of the users), the RS requires some kind of information from the users to guide the learning process. This feedback may be obtained implicitly, explicitly or combining both approaches. Explicit feedback forces users to evaluate items, indicating how relevant or interesting they are to them using some numeric or linguistic scale. These systems offer high performance and simplicity [25,26,29,33]. However, explicit feedback has some serious limitations: the user must spend some time and effort, the rating action distracts the attention of the user from his/her standard workflow, and a subjective numerical or linguistic scale is needed to rate each item [12]. Moreover, users are usually reluctant to spend time giving explicit feedback and some studies argue that only 15% of the users would supply it even if they were encouraged to do so [30].On the other hand, implicit feedback is obtained by monitoring the actions of the users and automatically inferring their preferences. The amount of collected data is consequently very large, the computation needed to derive the profile adaptations is extensive, and the confidence in their suitability is likely to be relatively low. This approach has been less explored, although some existing methods have shown promising results (e.g. [3,9,24,32]). This paper discusses an unsupervised way to infer the user interests over numerical and multi-valued categorical attributes, which observes the user interaction and does not require any explicit information from him/her [17].The basic idea of the preference learning framework proposed in this paper is shown in Fig. 1. There is a set of alternatives that can be recommended to the user as solutions of a decision problem, represented with a set of predetermined criteria. These options are evaluated and ranked according to the current preferences of the user, stored in his/her profile. The user is shown the ranked list of alternatives, and his/her preferred option is selected. The preference learning algorithms analyze the option chosen by the user and the alternatives that were ranked above it in order to decide which changes must be made to the user profile so that it captures better the user preferences and the next recommendation is more accurate. It can be seen that the adaptation process is iterative and, the more choices are made by the user, the more information will the system have to find out his/her preferences. Therefore, this framework will be especially suitable in those cases in which the user is confronted with frequent decisional problems (e.g. which news to read every morning, which messages to read from a social network every day). Due to its progressive, continuous and dynamic nature, it will also be applicable in realistic settings in which the preferences of the user are not static but change dynamically over time [22,23].The rest of the paper is organized as follows. Section 2 includes a brief description of the previous work of the authors in the area of preference learning over single-valued linguistic and numeric attributes, explaining how the interests of users over the values of these kinds of criteria are learned. Section 3 presents a new approach to learn preferences over the values of categorical attributes when the decision alternatives can take multiple linguistic values in a single attribute. Section 4 describes a novel expressive preference function on numeric attributes and how the parameters that define this function can be automatically learned. In Section 5 the case study where our approach has been tested (restaurant recommendation) is explained, describing the data set used and the results obtained. Section 6 gives an overview of related work on multi-criteria preference learning and analyses previous proposals. Finally, Section 7 outlines the main conclusions of the paper and identifies some lines of future research.

@&#CONCLUSIONS@&#
Two main contributions with respect to our previous work have been presented in this paper. The first one consists in managing multi-valued categorical attributes in the alternatives of a RS, allowing more expressivity in their representation. The system considers a single preference for each possible value and aggregates them to find out the preference over the whole attribute. The consideration of multi-valued attributes is mandatory when working with alternatives such as the ones presented in this paper (e.g. “Types of Food” in a restaurant).The second contribution, which is learning the numeric preference function, allows shaping a more expressive and personalized representation of the user’s preferences over each numeric attribute, defining a preference function with 5 parameters. This additional expressivity helped to improve the profile learning process by reducing the learning error around 7%.As future work, three interesting lines can be considered. As pointed out in Section 3, an aggregation policy can be considered in the aggregation of the preferences in a single categorical attribute, other than the use of the common “average” policy. Research can be made in this area in order to learn the aggregation policy that fits more with the user interests. Another interesting line to consider is to incorporate information about the five parameters that define the ideal numeric preference function in the distance measure used to evaluate the algorithm (Eq. (12)) since, currently, just the ideal value of preference is being considered. Finally, it would also be very interesting to build a mathematical model, based on the minimization of a loss function, that might permit a more rigorous and theoretical analysis of the performance of the proposed preference learning method.