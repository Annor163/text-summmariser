@&#MAIN-TITLE@&#
A hybrid variable neighborhood search for solving the hybrid flow shop scheduling problem

@&#HIGHLIGHTS@&#
We propose a novel hybrid variable neighborhood search (HVNS) algorithm for hybrid flow shop (HFS) scheduling problems.A well-designed decoding mechanism is presented to schedule jobs with more flexibility.Considering the problem structure, eight neighborhood structures are developed.A kinetic energy sensitive neighborhood change approach is proposed.A dynamic neighborhood set update mechanism is utilized.An effective EDA-based global search approach is presented.

@&#KEYPHRASES@&#
Hybrid flow shop scheduling problem,Chemical-reaction optimization,Estimation of distribution,Variable neighborhood search,

@&#ABSTRACT@&#
This paper proposes a hybrid variable neighborhood search (HVNS) algorithm that combines the chemical-reaction optimization (CRO) and the estimation of distribution (EDA), for solving the hybrid flow shop (HFS) scheduling problems. The objective is to minimize the maximum completion time. In the proposed algorithm, a well-designed decoding mechanism is presented to schedule jobs with more flexibility. Meanwhile, considering the problem structure, eight neighborhood structures are developed. A kinetic energy sensitive neighborhood change approach is proposed to extract global information and avoid being stuck at the local optima. In addition, contrary to the fixed neighborhood set in traditional VNS, a dynamic neighborhood set update mechanism is utilized to exploit the potential search space. Finally, for the population of local optima solutions, an effective EDA-based global search approach is investigated to direct the search process to promising regions. The proposed algorithm is tested on sets of well-known benchmark instances. Through the analysis of experimental results, the high performance of the proposed HVNS algorithm is shown in comparison with four efficient algorithms from the literature.

@&#INTRODUCTION@&#
In modern manufacturing and production systems, production scheduling plays an important role in increasing production efficiency and profit. In recent years, the flow shop scheduling problem (FSSP) has been investigated by more and more researchers because of its important role in a realistic production systems. The hybrid flow shop (HFS) scheduling problem, as one branch of the classical FSSP, is more complex because of the addition of machine selection. In 1988, Gupta proved that HFS is a NP-hard problem [1]. Recent and comprehensive reviews on HFS can be found in [2,3], which illustrate the published HFS literature before 2010. It can be concluded from the two literature reviews that: (1) there are more than 200 current papers discussing the problem; (2) more and more algorithms, including exact algorithms, dispatching rules, heuristics, and meta-heuristics, have been used for solving HFS; and (3) HFS has played an important role in present production systems. For instance, in most production systems with a flexible scheduling environment, such as the oil food, paper, textile, chemical and cosmetic industries, HFS plays a key role and becomes an important factor that can lead to improvements in production efficiency.The branch and bound (B&B) algorithm proposed for solving the HFS was published in 1970 (Rao [4]). After that, many published papers have discussed the HFS with many different algorithms. We can classify these algorithms by the stage size of the considered problems. There are three types of problem, that is, two-stage, three-stage, and m-stage. The two-stage problem is the HFS with two consecutive stages, while the m-stage problem is the m stage series.To solve the two-stage HFS, in 1988 Gupta studied an HFS for which there is only one machine at the second stage [1]. In 1991, the B&B approach was introduced by Brash and Hunsucker [5]. After that, many different types of approaches have been developed. In 1994, Gupta solved the two-stage HFS problem with separable setup and removal times [6]. In 2003, Lin and Liao [7] studied the two-stage HFS problem with setup time and dedicated machines. Lee and Kim [8] introduced the B&B approach to solve the two-stage HFS with any number of identical parallel machines at the second stage. Haouari et al. [9] considered the problem without any machine number constraints at any stage.To solve the three-stage HFS, in 1998 Riane et al. [10] developed an efficient heuristic to minimize makespan in a three-stage HFS problem. Jin et al. [11] modeled a real printed circuit board manufacturing system by a HFS with three stages, and solved the problem by GA. Carlier and Neron [12] proposed an exact algorithm for solving the multi-processor flow shop. The benchmark problems generated by them were used by many studies as test problems. In 2004, Babayan and He [13] presented an agent-based approach for a three-stage HFS with identical parallel machines.To solve the HFS with m-stages, in 1998 Portmann et al. [14] introduced an enhanced version of the branch and bound algorithm crossed with GA. In 2001, Neron et al. [15] proposed an algorithm using energetic reasoning and global operations for an HFS with up to five stages. The HFS with multiprocessor task problems was studied by Oguz and Ercan [16] with a GA approach. Ruiz and Maroto [17] developed a GA for HFS with sequence dependent setup times and machine eligibility. Janiak et al. [18] applied three constructive algorithms and three meta-heuristics based on Tabu Search (TS) and SA, to solve the HFS with cost-related criteria. Niu et al. [19] developed a quantum-inspired immune algorithm for HFS. In 2010, Kahraman et al. [20] investigated a parallel greedy algorithm for solving the multistage HFS. Engin et al. [21] developed an efficient GA for an HFS with multiprocessor task problems. In 2012, Liao et al. [22] proposed an approach using PSO and bottleneck heuristic for the problem. The other meta-heuristics were also used for solving HFS with multi-stages, such as ant colony optimization (ACO) [23,24] and artificial immune systems (AIS) [25,26].Variable Neighborhood Search (VNS) is a recent and effective meta-heuristic for solving both continuous and global optimization problems. By systematic changes of the neighborhood structures within the search, VNS is capable of escaping from the local optima [27–43]. By simulating the behavior of molecules in chemical reactions, an efficient chemical-reaction optimization (CRO) algorithm was proposed by Lam and Li [44] to optimize combinatorial problems. In recent years, CRO has been applied to solve many continuous and discrete optimization problems [44–46]. The estimation of distribution algorithm (EDA) was introduced by Mühlenbein and Paaß [47]. In EDA, global statistical information was extracted from the current population. Meanwhile, a probabilistic model was constructed that represents the global information and characterizes the distribution of promising solutions in the search region [47–50].In this study, we make a hybridization of the VNS, CRO, and EDA. To enhance the exploration ability of the proposed algorithm, we assign a certain KE value for each individual solution. A kinetic-energy-based neighborhood change procedure is introduced that can avoid being stuck at the local optima and thus further increase the exploration ability. In addition, after collecting a group of local optima solutions by a VNS process, an EDA-based global search process is performed on the local optima population to search global optimal solutions, which can further enhance the exploitation and exploration ability of the proposed algorithm. The rest of this paper is organized as follows: The Problem Formulation deals with the job/task allocation details together with the stage by stage work flow. Next The Related Algorithms deal with how VNS was construed by others. Then the technical approach is briefly discussed in the The Proposed HVNS algorithm. Further, The Experimental Results provide a fair account of results derived and compare them with other algorithms in the literature to demonstrate the performance of HVNS. Finally, Conclusions provide a concise description of solving the hybrid flow shop scheduling problem of our work.In an HFS, there are n jobs to be processed on m machines in a predefined order. The m machines are grouped into k stages in series. In each stage i, there are miidentical machines in parallel, where mi≥1, and there are at least two parallel machines in one stage. Each job should visit each stage following the same production flow: stage1, stage2, …, stagek. When a job arrives at a stage i, it can select exactly one machine from miavailable identical machines. The assumptions for the considered HFS in this study are given as follow.•Each machine in the same stage can process only one job at a time;Each job can be operated by only one machine at a time;All of the jobs and machines are available at time zero;Preemption is not allowed, that is, any job cannot be interrupted before the completion of its current operation;Setup times are negligible and problem data are deterministic and known in advance;Overlap of operations is not allowed, that is, each operation of the same job should not start until the previous operation has completed its work;There is an unlimited intermediate buffer between two successive stages.The aim of HFS is to assign an optimal machine for each job at each stage, and schedule each job on each machine to minimize the makespan or the maximum completion time. The mathematical model can be found in [2,17,22].In 1997, VNS was introduced by Mladenovic and Hansen [27] for solving the traveling salesman problem (TSP). After that, VNS has been applied by more and more researchers to solve continuous and global optimization problems. In 2010, Hansen et al. [28] gave a comprehensive survey of VNS. The survey literature shows that since it was first proposed in 1997, VNS has seen rapid development and enhancement in two aspects, i.e., methods and applications.Very recently, VNS has been the focus of substantial research. The recent developments with VNS are also taken in two fields: (1) designing improved VNS by combining other dispatching rules, heuristics, meta-heuristics, and local search methods and (2) applying VNS for new applications. In 2009, Wang and Tang [29] developed a population-based VNS for the single machine total weighted tardiness problem. By combining VNS with GA, Wen et al. [30] presented a hybrid genetic based VNS for task scheduling in a heterogeneous multiprocessor system. Stenger et al. [31] investigated a routing problem arising in the last-mile delivery of small packages by using an improved VNS that embeds cyclic-exchange neighborhoods and an adaptive mechanism. Yazdani et al. [32] developed a parallel VNS for the flexible job-shop scheduling problem (FJSP). Recently, more and more literature has addressed solving scheduling problems using VNS. For parallel machine scheduling problems, Behnamian et al. [33] proposed a hybrid algorithm using ACO, SA and VNS; Driessel et al. [34] developed several variants of VNS; in 2012, Bilyk and Mönch [35] investigated VNS for planning and scheduling of jobs on unrelated parallel machines. For HFS problems utilizing VNS, Naderi et al. [36] proposed a VNS that uses advanced neighborhood search structures for flexible flow line problems with sequence dependent setup time and preventive maintenance activity; Tavakkoli-Moghaddam et al. [37] presented a memetic algorithm for HFS with processor blocking. The other recent applications of VNS include vertex separation problems [38], resource allocation problems [39], TSP [40], location routing [41], multilevel lot-sizing problems [42], and facility layout problems [43].The basic VNS employs a set of pre-defined neighborhoods. By sequentially exploring these neighborhoods, local optima solutions in different neighborhood structure can be obtained, and thus, better solutions can be reached through this process. In VNS, one solution in the current neighborhood is selected as the incumbent solution. Then, local search is performed on the selected solution to generate several neighboring solutions. By comparing the neighboring solutions with the incumbent one, the current solution will be replaced by the best solution found thus far or remain its state if no better solution is found. Then, the neighborhood will turn to the first one if a better solution is found or turn to the next one if the incumbent solution remains itself. By systematically changing the current neighborhood, VNS directs the search to a promising field, and thus, global optimal solutions will be found. The main steps of the basic VNS are given as follows [27]:Step 1. Set system parameters that include the set of neighborhood structure Nk, k=1, …, kmax, and an initial solution x;Step 2. Repeat the following steps until the stop condition is satisfied.Step 3. Generate a solution xT at random from the kth neighborhood of x;Step 4. Apply some local search methods with x′ as the initial solution; denote x″ as the best obtained solution;Step 5. If the obtained solution x″ is better than the incumbent, replace it with the former and continue the search with the first neighborhood structure, that is, set k=1; otherwise, set k=k+1.In 2010, Lam and Li [44] introduced CRO, which loosely mimics what happens to molecules in a chemical reaction system and tries to capture the energy in the reaction process. The molecules represent the solution for the considered problem, while the change in molecular structure is tantamount to switching to another feasible solution. Each molecule possesses two types of energies, i.e., potential energy (PE) and kinetic energy (KE). PE corresponds to the objective function of a molecule, while the KE of a molecule symbolized its ability to escape from a local minimum. In the basic CRO, there are four elementary reactions, i.e., the on-wall ineffective collision, decomposition, inter-molecular ineffective collision, and synthesis. Meanwhile, CRO has a buffer to collect the kinetic energy produced by on-wall ineffective collisions and to help the molecules to escape from the local optima.The main steps of the basic CRO are given as follows [44–46]:Step 1. Set system parameters;Step 2. Perform the following steps until the stop condition is satisfied.Step 3. If the inter-molecular condition is satisfied, perform step 4; otherwise, perform step 5.Step 4. Randomly select two or more molecules from the current population; if the synthesis condition is satisfied, perform synthesis operation on the selected two molecules; otherwise, perform inter-molecular collision on them;Step 5. Randomly select one molecule; if the decomposition condition is satisfied, perform decomposition operation on the selected individual; otherwise, perform on-wall collision on it.In 1996, Mühlenbein and Paaß [47] proposed a new evolutionary algorithm, called the estimation of distribution algorithm (EDA). Unlike other meta-heuristics, such as the genetic algorithm (GA) and particle swarm optimization (PSO), EDA uses a probabilistic model to utilize global statistical information to generate new offspring, which is very different from crossover or mutation operators.The main steps of the basic EDA are given as follows [47–50]:Step 1. Set system parameters.Step 2. Randomly generate a population of initial solutions.Step 3. Evaluate each solution, and select good individuals with respect to their fitness.Step 4. Generate a new distribution of probability based on the selected individuals.Step 5. Generate new offspring from the estimated distribution.Step 6. If a stop condition is satisfied, then stop the algorithm; otherwise, go back to step 3.In the proposed algorithm, each solution is represented by a string of integers that are commonly used in most of the literature for HFS [2,17,50]. Each integer in the string corresponds to a job number. Thus, the length of the string equals to n. Consider an example problem with three stages and five jobs, the parallel machine in each stage and the processing time of each operation is given in Table 1. Suppose that one solution is represented by {2, 4, 3, 1, 5}, which means that in the first stage, then the scheduling sequence is J2, J4, J3, J1, and J5.It is notable that the solution encoding given above contains no machine selection (routing) information in each stage. Therefore, we should consider both machine selection and operation scheduling in the decoding process. The common method is as follows [2,17,50]: (1) in the first stage, schedule each job according to their sequence in the solution representation, and assign each job to the first available machine; (2) in the following stages, assign the first available machine for the arriving job.In this study, to decode the solution representation in all of the stages, except the first one, we introduce two decoding methods as follows.•Solution-Dependent Rule, denoted by SDR. In the SDR rule, the concurrently arriving jobs will be scheduled according to their occurrence order in the solution representation. It should be noted that, the SDR rule is commonly used in the current literature [2,17,50]. However, by using the SDR rule, the concurrently arriving jobs will be scheduled in a relatively deterministic order at each stage. For the given example in Solution representation, when the two jobs J4 and J1 arrive at the second stage at the same time, that is, with the same completion time at the first stage, if only one available machine is waiting for scheduling them, then J4 will be scheduled first according to the SDR rule;Random Rule, denoted by RR. In the RR rule, the jobs will be scheduled in a random order. The detailed steps are given as follows. First, at each stage, except the first, sort each job into a set Rsin a random way. Second, when more than one job arrives at a stage concurrently and there are not enough available machines for them, then schedule them according to their order in Rs. For the given example in Solution representation, when J4 and J1 arrive at the second stage concurrently while only one machine is waiting for them, then J4 and J1 will be scheduled in a random way.It should be noted that the proposed RR method considers the following realistic production characteristics: (1) there is usually more than one job arriving concurrently at the same stage; (2) the number of available machines is usually less than the number of concurrent arriving jobs. By using the decoding heuristics discussed above, the detailed decoding process is given as follows:Step 1: In the first stage, schedule each job one by one according to their sequence in the solution representation. For the above example solution listed in Solution representation, in the first stage, the job scheduling sequence is J2, J4, J3, J1, and J5. When one job is to be scheduled, it will select the earliest available machine. If there are several available machines with the same available time, the job will randomly select one.Step 2: In the other stages, each job will be scheduled as soon as it completes its previous operation. The machine selection strategy is the same as in the first stage, that is, to select the earliest available machine for the arrived operation. If more than one parallel available machine is available, then randomly select one from them. When several jobs arrive concurrently at the same time with too few available machines at the stage, we use the RR rule.Fig. 1gives the Gantt chart for the above example solution listed in Solution representation. In Fig. 1, each operation is represented by a pair of number, i.e., the job number and the stage number. For example, in Fig. 1, the first operation scheduled on the machine M1 is denoted by (2, 1), which denotes that the job J2 in the first stage is scheduled first on M1. In the second stage, there is only one machine, and thus, each job is scheduled one by one on M3. The last completed job is J5 on M4, with the completion time 25. Therefore, the maximum completion time (makespan) of the given solution is 25.In this study, considering the problem structure, eight neighborhood structures are proposed, which are given as follows:•Swap two positions structure, denoted by N1. (1) Randomly select two job numbers in the solution representation; (2) Swap the two selected jobs in the scheduling string.Insertion structure, denoted by N2. (1) Randomly select two positions, r1 and r2, in the solution representation, where r1<r2; (2) Insert the job at the position r2 before r1 in the scheduling string.Reverse the elements between two positions structure, denoted by N3. (1) Randomly select two positions, r1 and r2, in the solution representation. (2) Reverse the job numbers between the positions r1 and r2 in the scheduling string.Swap elements structure, denoted by N4, with an example given in Fig. 2(a). (1) Randomly select two positions, r1 and r2, in the solution representation, where r1<r2; (2) Swap each pair of elements between the positions r1 and r2 in the scheduling string. The detailed steps are as follows: (a) let p=r1, and q=r2; (b) swap the two elements p and q in the solution representation; let p=r1+1, and q=r2−1; (3) repeat step (b) until p≥q.Swap the elements with the first and the last element structure, denoted by N5, with an example given in Fig. 2(b). (1) Randomly select two positions, r1 and r2, in the solution representation, where r1<r2; (2) swap the element at the positions r1 with the head element, and swap the element at the positions r2 with the tail element.Insert elements before the first and after the last structure, denoted by N6, with an example given in Fig. 2(c). (1) Randomly select two positions, r1 and r2, in the solution representation, where r1<r2; (2) Insert the element at the positions r1 before the head position, and insert the element at the positions r2 after the tail position.Swap elements at one point structure, denoted by N7, with an example given in Fig. 2(d). (1) Randomly select one position, r1, in the solution representation, except the head position and the tail position. (2) Swap the two elements before and after the positions r1.Insert at one point structure, denoted by N8, with an example given in Fig. 2(e). (1) Randomly select one position, r1, in the solution representation, except the head position and the tail position; (2) Insert the element after the position r1 at the position just before r1.We assign a certain KE value for each individual solution and introduce a kinetic-energy-based neighborhood change procedure (KE_NeighborhoodChange), which updates the incumbent solution and the KE value for the current solution. By using the kinetic energy sensitive procedure, the proposed algorithm can avoid being stuck at the local optima, and thus, increase the exploitation and exploration ability.In VNS, if a better neighboring solution is found, the neighborhood index k will be set to the first position, which makes the next neighborhood to be accessed potentially different from the current one. A disadvantage is that the search process will jump to other search regions even when it finds a better solution in the current neighborhood. In contrast to the traditional VNS, the neighborhood set is updated dynamically in the proposed algorithm by inserting the promising neighborhood into the first position. That is, if a better solution is found in the current neighborhood, the corresponding neighborhood will be accessed again in the following search process until no better solution is obtained. Therefore, the first neighborhood has a higher probability of being accessed. The above process makes the algorithm completely exploit the promising search region until local optima are reached.The detailed steps of the proposed procedure are given in Fig. 3.In this study, after collecting a group of local optima solutions by the VNS process, an EDA-based global search process will be performed on the local optima population to search for global optimal solutions. The probabilistic model is the main issue for EDA and the performance of the algorithm is strongly dependent on it; therefore, the best choice of model is crucial. In general, two key issues should be considered for the probabilistic model of EDA, i.e., the building of the model, and the update of the model.To construct a probabilistic model for the current population solutions, we first select Bsize solutions with relatively low fitness values. Let t be the generation index, nij(t) be the number of times of appearance of job i before or in the position j in the subset of the selected Bsize solutions in generation t. The value of nij(t) refers to the importance of the order of the jobs in the scheduling sequence, which indicates the probability of the global statistical information. Let pij(t) be the probability for job i to appear before or at the position j, which means that from the global statistical point, job i should be scheduled no later than position j. Let (pi1(t), pi2(t), …, pin(t)) be the probabilistic model for each element of job i in generation t. Then, we can obtain the completed probabilistic model as follows.(1)P(t)=p11(t)p12(t)...p1n(t)p21(t)p22(t)...p2n(t)............pn1(t)pn2(t)..pnn(t)The construction process for pij(t) is given as follows, similar to [49].(2)pij(0)=∑k=1Bsizeχijk(0)i⋅BsizeThe update process for pij(t) is given as follows, similar to [49].(3)pij(t+1)=α×∑k=1Bsizeχijk(t+1)i⋅Bsize+(1−α)×pij(t)where, α is the study rate, which is range between 0 and 1;(4)χijk(t)=1Ifjobiappearsbeforeorinthepositionjinsolutionk0OtherwiseThe EDA based global search process is given in Fig. 4.The detailed steps of the proposed HVNS algorithm are as follows:Step1: Initialization phase.Step 1.1 Set the population size Psize.Step 1.2 Initialize the population in a random way. That is, randomly sequence each job in the solution representation for each initial individual.Step2: Evaluate each solution in the population. Select the best solution as the current incumbent individual.Step3: If the stopping criterion is satisfied, output the best solution; otherwise, perform steps 4–6.Step4: VNS local search phase.Step 4.1 Let t=1, and repeat steps 4.2–4.7 until t>tmax.Step 4.2 Let k=1, and repeat steps 4.3–4.6 until k>kmax.Step 4.3 Generate an initial neighboring solution x′ around the incumbent solution in the kth neighborhood.Step 4.4 Local search phase: Generate Nsneighboring solutions, select the best one as x″.Step 4.5 Neighborhood change phase: By using the proposed neighborhood change procedure KE_NeighborhoodChange as illustrated in Fig. 3, update the current incumbent solution and the value of k.Step 4.6 Store every local optima solution for each neighborhood structure into a set LO.Step 4.7 Let t=t+1.Step5: EDA based global search phase.Step 5.1 From the local optima solutions set LO, which is generated in step 4.6, select Bsize best solutions to construct the initial population for the EDA based global search procedure.Step 5.2 Construct the initial probabilistic model based on the selected initial population.Step 5.3 Generate Bsize new solutions based on the initial population and the initial probabilistic model.Step 5.4 If the stop condition satisfies, go to step 6; otherwise, perform steps 5.5–5.6.Step 5.5 Update the probabilistic model by using formula (3).Step 5.6 Generate Bsize new solutions by the new estimation distribution model. Evaluate each solution and go back to step 5.4.Step6: Go back to step 3.

@&#CONCLUSIONS@&#
In this study, a hybrid VNS algorithm combining the CRO and EDA is proposed for solving the hybrid flow shop scheduling problem. A detailed encoding and decoding mechanism is developed for the problem. The main contributions of the proposed HVNS are as follows:(1)To enhance the exploitation ability of the proposed algorithm, a dynamic neighborhood set update mechanism is embedded in the HVNS;To avoid being stuck at the local optima and jump out of the valley, a kinetic-energy-based neighborhood change approach is proposed;To utilize the global statistical information from local optima solutions found by the VNS procedure and direct the search to promising region, an EDA-based global search method is investigated in the HVNS.The Carlier and Neron's benchmark problems with different problem scales are tested to make detailed comparisons between HVNS and other efficient algorithms from the literature. Experimental results show the robustness and efficiency of the proposed algorithm. Objective for further research are as follows:(1)To improve the local search ability of the algorithm and enhance the balance between the exploitation and exploration to increase the simulation result reliability;To consider the problem structure, design efficient neighborhood structures and increase the global search ability of the algorithm;To apply the proposed algorithm to solving other potential applications, such as the HFS with preventive maintenance activities, HFS with setup time, and fuzzy HFS problems.