@&#MAIN-TITLE@&#
Elite-guided multi-objective artificial bee colony algorithm

@&#HIGHLIGHTS@&#
A novel multi-objective optimization algorithm based on ABC is proposed.The elite-guided solution generation strategy is proposed to exploit the neighborhood of the solutions based on the guidance of the elite.A novel fitness calculation method is presented to calculate the selecting probability.The proposed approach is highly competitive with other algorithms.

@&#KEYPHRASES@&#
Multi-objective optimization,Evolutionary algorithm,Artificial bee colony,Multi-objective artificial bee colony,

@&#ABSTRACT@&#
Multi-objective optimization has been a difficult problem and a research focus in the field of science and engineering. This paper presents a novel multi-objective optimization algorithm called elite-guided multi-objective artificial bee colony (EMOABC) algorithm. In our proposal, the fast non-dominated sorting and population selection strategy are applied to measure the quality of the solution and select the better ones. The elite-guided solution generation strategy is designed to exploit the neighborhood of the existing solutions based on the guidance of the elite. Furthermore, a novel fitness calculation method is presented to calculate the selecting probability for onlookers. The proposed algorithm is validated on benchmark functions in terms of four indicators: GD, ER, SPR, and TI. The experimental results show that the proposed approach can find solutions with competitive convergence and diversity within a shorter period of time, compared with the traditional multi-objective algorithms. Consequently, it can be considered as a viable alternative to solve the multi-objective optimization problems.

@&#INTRODUCTION@&#
Multi-objective optimization, which involves more than one objective function, has been applied in many fields such as manufacturing optimization [1,2], engineering design [3], and chemical engineering [4]. For example, while buying a car, minimizing cost and maximizing comfort are the two objectives needed to be optimized. Usually, there are conflicts among these objectives, for instance, the car with better comfort would cost more, which lead to the difficulty of optimizing the multiple objectives. Therefore, when dealing with multi-objective optimization, the trade-off analysis that needs to be taken between the conflicting objectives, and then the Pareto optimal solutions [5] can be obtained.Evolutionary algorithms (EA) can explore the Pareto optimal solutions for the multi-objective optimization problems that are too complex to be solved by the exact methods within a reasonable computation time [6]. Due to their inherent parallelism and their capability to exploit the similarities of solutions by recombination, they are able to approximate the Pareto optimal solutions after several iterations. Over the past two decades, many biologically inspired algorithms have been proposed to solve the multi-objective optimization problems, such as Pareto-archived evolution strategy (PAES) [7], Pareto envelope-based selection algorithm II (PESA-II) [8], improved strength Pareto evolutionary algorithm (SPEA2) [9], non-dominated sorting genetic algorithm II (NSGA-II) [10], multi-objective particle swarm optimization (MOPSO) [11], indicator-based evolutionary algorithm (IBEA) [12], multi-objective evolutionary algorithm based on decomposition (MOEA/D) [13], archived multi-objective simulated annealing (AMOSA) [14], and preference-inspired co-evolutionary algorithm (PICEA) [15]. These algorithms search for the optimal solution set by iterative evolution. The quality of the solution has being improved as the study continues in depth.By modeling the intelligent behavior of honey bee swarm, artificial bee colony (ABC) algorithm proposed by Karaboga [16] is a new swarm intelligence method. It has been found to be successful in a wide variety of optimization tasks [17], and has got the widespread concern of researchers [18–21]. For multi-objective optimization, some researches combine ABC with the fast non-dominated sorting method in NSGA-II and propose the MOABC algorithm [22–25]. The vector evaluated artificial bee colony (VEABC) [26] classifies the bee colonies based on the number of optimized objectives. Each colony separately evaluates one single goal and exchanges their information to obtain the optimal solution set. A Pareto-based discrete artificial bee colony algorithm was proposed for solving multi-objective flexible job shop scheduling problems [27]. In this algorithm, a crossover operator and an external Pareto archive set were designed, and several local search approaches were designed to balance the exploration and exploitation capability. Hybrid multi-objective artificial bee colony (HMOABC) algorithm [28] is proposed for solving the burdening process optimization. The mechanisms about the intelligent foraging behavior of bees and diversified selection were added. Recently, a new multi-objective artificial bee colony algorithm by dividing the searching space (dMOABC) was proposed [29]. In this algorithm, three colonies are used to search in different regions of the searching space and share information. The diversity of the archived solutions is controlled by a self-adaptive grid.However, in the current multi-objective optimization algorithms based on ABC, any dimension of the feasible solution changes based on the information of the neighbor solutions. This relatively random change cannot ensure that the new candidate solution is superior to the previous one. In this paper, we present a novel multi-objective optimization algorithm called the “elite-guided multi-objective artificial bee colony” (EMOABC) algorithm. The elite-guided solution generation strategy is proposed to accelerate the convergence speed and improve the solution quality. In order to judge the quality of solution, the fast non-dominated sorting and population selection strategy from NSGA-II [10] are applied. A novel fitness calculation method is also presented, because the original single-objective fitness calculation method is not applicable for multi-objective optimization. In order to evaluate the performance of the EMOABC, we compared EMOABC algorithm with NSGA-II, MOPSO, and MOABC on a set of well-known benchmark functions in terms of four indicators: GD, ER, SPR, and TI. The experimental results show that EMOABC algorithm has the ability to provide competitive performance on most of the test problems.The remainder of this paper is organized as follows. An introduction to multi-objective optimization is presented in Section 2. The original ABC algorithm is described in Section 3. Section 4 specifies the details of the proposed EMOABC algorithm and the multi-objective optimization strategies. Section 5 presents a comparative study of the proposed EMOABC with other algorithms on a number of benchmark functions. Finally, the conclusion is given in Section 6.Let x be a n-dimensional vector of decision variables, x=(x1, x2, …, xn), and S be the search space. For the single objective optimization function min(f(x)), which is just a scalar function, the optimal solution can be achieved by directly comparing the objective values. f*(x) is the global minimum solution if and only if:(1)∀x∈S:f*(x)≤f(x).When there is more than one objective, the problem becomes a multi-objective optimization problem.Definition 1Multi-Objective Optimization problemA multi-objective optimization problem (MOP) can be stated as follows:(2)MinimizeF(x)=[f1(x),f2(x),…,fu(x)],Subject tox∈S.where u is the number of the objectives. The absolute optimal solution needs to make multiple targets optimal simultaneously. However, due to the mutual restriction of decision variables among multiple targets, it is difficult to obtain the absolute optimal solution. So that the solution of the multi-objective optimization problem is usually described by a Pareto optimal set [11], which is defined based on Pareto dominance. Assuming that K=[1, 2, …, u], the definition of Pareto set is given below.A vector v is said to dominate w (v≺w) if and only if:(3)∀k∈K:fk(v)≤fk(w)∧∃k∈K:fk(v)<fk(w).In the feasible region S, a point x*∈S is Pareto optimal if and only if it satisfies one of the following two conditions:(1)∀x∈S, ∀k∈K, fk(x*)=fk(x),∃k∈K, fk(x*)<fk(x).All the Pareto optimal solutions constitute the Pareto optimal set P*.Definition 4Pareto-frontFor Pareto optimal set P*, the Pareto-front (PF*) is defined as:(4)PF*≔{[f1(x),f2(x),…,fu(x)]|x∈P*}.The artificial bee colony (ABC) algorithm is a new swarm intelligence method which simulates intelligent foraging behavior of honey bees. It searches the optimal solution by the random but targeted evolution of the candidate solution group.In the original ABC algorithm, each food source represents a feasible solution of the problem to be solved, and the nectar quality of the food source denotes the fitness of this feasible solution, indicating the quality of this solution. The bees are classified into three groups:(1)Employed bees. They are responsible for exploiting the neighborhood of the food source and sharing their information with bees waiting in the hive.Onlookers. They wait in the hive and choose a food source to exploit depending on the information. When they find a better food source, they will notify the appropriate employed bee to update its position.Scouts. When there is no update after several iterations, which means the algorithm has fallen into the local optimum, the employed bee will become a scout and randomly find a new food source to start a new search.The ABC algorithm tends to converge gradually through collaboration of these three kinds of bees, and obtains the optimal or near-optimal solution in the feasible space. The main steps of the algorithm can be summarized as follows:Step 1. InitializationGenerate the initial solution population randomly and then calculate the objective function value of each solution in the population.Step 2. Employed bee phaseEach employed bee searches the neighbor of the food source to produce a new solution. Then calculate the objective function value and apply the greedy selection strategy to update the position.Step 3. Onlooker phaseEach onlooker selects a food source in the population depending on the selecting probability associated with that food source, and searches its neighbor to produce a new solution. Then, calculate the objective function value and apply the greedy selection strategy to update the position.Step 4. Scout phaseSend the scout to the search area for discovering a new food source.Step 5. Memorize the best food source found so far.Step 6. If a termination is not satisfied, go to step 2; otherwise stop the procedure and return the best food source found so far.Currently, some studies have employed the ABC algorithm for solving multi-objective optimization problems, such as MOABC algorithm [1,22–25] combining ABC with the non-dominated sorting of NSGA-II [10]. However, in local searching strategy of MOABC, any one dimension of the feasible solution changes based on the information of neighbor solutions. This relatively random change cannot ensure that the new candidate solution is better than the previous one. In order to improve the quality of the solution, the Gbest-guided artificial bee colony (GABC) algorithm was proposed [30] for the single-objective optimization, which takes advantage of the information of current global best solution to guide the local searching in order to improve the exploitation. Based on this, we propose the elite-guided multi-objective artificial bee colony (EMOABC) algorithm for multi-objective optimization which guides the local searching by the elite set.The flowchart of the EMOABC algorithm is given in Fig. 1. The EMOABC algorithm is constituted of four parts: Initialization, send employed bees, send onlookers and send scouts, which will be explained in the following Section 4.3. Besides, it also involves some multi-objective optimization strategies, like fast non-dominated sorting method and population selection strategy, which is described in Sections 4.2.1 and 4.2.2 respectively.Let the number of food source (solution) be SN. The population is P={x1, x2, …, xSN}, in which d is the index of the solution, d∈{1, 2, …, SN}. xdis a n-dimensional vector of decision variables,xd=(xd1,xd2,…,xdn).xdidenotes the dimension i of xd, which is limited between lower bound lbiand upper bound ubi,lbi≤xdi≤ubi. In the initialization phase of the EMOABC algorithm, the initial feasible solutions are generated randomly by Eq. (5).(5)xdi=lbi+rand(0,1)⋅(ubi−lbi)And then calculate the objective function value of each solution xd, as the fitness value f(xd). Here we are considering multi-objective optimization, according to Eq. (2), the value of objective function is a vector, f(xd)=[f1(x), f2(x), …, fu(x)].In multi-objective optimization, due to the various objectives are conflicting, it is difficult to sort and select the solutions simply according to their values. Fast non-dominated sorting method [10] is applied to determine the dominance relationship among the feasible solutions in the population, providing the basis for selecting further solutions. And the population selection strategy is applied to select the optimal feasible solutions from the population.Its basic idea is to sort the solutions of the population based on their dominance relationship. For each solution xdin population P, two values would be recorded as compared with every other solution q in P: (1) domination count nd, the number of solutions which dominate the solution xd, i.e. if q≺xd, then nd=nd+1; (2) dominated set Sd, a set of solutions that the solution xdcan dominate, i.e. if xd≺q, then Sd=Sd∪{q}.If nd=0, then xd·rank=1. Otherwise, we visit each member of its Sdand reduce its ndby one. Then put the solution which ndbecomes 0 into a new list Q, and set rank of the members in Q to be 2, which means Q is the second non-dominated front. This process will continue until all fronts are identified.The crowding distance of each solution xd·distance is the estimate of the density of solutions in population, which can help to increase diversity in the selection and evolution of the solutions.Once the non-dominated sorting is completed, xd·distance can be calculated. Firstly, sort the solutions in the population according to each objective function value in ascending order. Secondly, for each objective function, the distance value of solutions with minimum and maximum function value are assigned with an infinite value ∞. All other intermediate solutions are assigned with the absolute normalized difference in the function values of two adjacent solutions. Lastly, xd·distance is calculated as the sum of individual distance values corresponding to each objective.The detailed steps can be found in [10].However, after exploiting by employed bees or onlookers, the number of feasible solutions in the population will be more than SN. Therefore, population selection strategy must be designed to select SN feasible solutions to generate a new population. For each solution xd, we have the non-dominated rank xd·rank and the crowding distance xd·distance. Suppose xdand xeare two feasible solutions, and the selection strategy designed based on these properties is as follows:(1)If xd·rank<xe·rank, then we put xdinto the new population. That is, between two solutions with differing non-domination ranks, we prefer the solution with the lower rank. If it exceeds the population size SN, then the crowding distances will be compared.If xd·rank=xe·rank and xd·distance>xe·distance, then put xdinto the new population. That is, if both solutions belong to the same front, then we prefer the solution that is located in a less crowded region.Select the solution with the lower rank for better quality evolution, and prefer the solution with larger distance to make the distribution of the population more evenly, thus improving the diversity of the solution.In the iteration process, all the feasible solutions will be exploited. Set the maximum cycle number to be MCN. Each cycle contains the behaviors of employed bees, onlookers, and scouts. Assign one employed bee and one onlooker to each food source, thus both the number of employed bees and onlookers are equal to the number of food source SN.In the local searching strategy of the original ABC algorithm, any one dimension of the feasible solution moves toward the neighbor solution. This relatively random change makes feasible solution become superior or inferior at the same probability, and thus cannot ensure that the new candidate solution is better than the previous one.The novel elite-guided solution generation strategy is proposed in this paper. Each employed bee searches the neighborhood of the food source based on the guidance of the elite, which can improve the quality of the solution effectively while ensuring the efficiency. A concept of elite set is given first herein based on non-dominated sorting.Definition 5Elite SetIdentify the set of solutions in the first non-dominated front as the elite set (ES):(6)ES=ES∪{xd},if(xd.rank=1)After initialization, the elite set will be memorized. Each employed bee will attach to one solution, and exploit its neighborhood based on the guidance of elite. The new local searching equation added with the elite-guided solution generation strategy is as follows.(7)vdi=xdi+ϕdi*(xdi−xei)+ψdi*(yi−xdi),yi∈ESwherevdis the location of the new food source and i is a dimension selected from the m-dimension array randomly, i∈{1, 2, …, m}. Each local searching only changes the value of the ith dimension of the feasible solution.xdi+ϕdi*(xdi−xei)is the original local searching strategy which makes the value of the ith dimension of the feasible solution move toward the neighbor xe, whereϕdiis a random number within the range [−1, 1];xdidenotes the ith element of the food source xdattached to by the employed bee d;xeiis the ith element of xe; e∈{1, 2, …, SN} and e≠d, where e is randomly generated.ψdi*(yi−xdi)is the elite-guided strategy. The feasible solution moves close to the elite solution in a planned way, which can consequently accelerate the convergence effectively. Whereψdiis a random number in the range of [0, 2]; yirepresents the ith element of the solution selecting from ES randomly.Ifvdiis out of the bound [lb, ub], the bound value will be used. After that, we calculate the objective function value ofvd, f(xd)=[f1(x), f2(x), …, fu(x)].Since there are SN employed bees, 2×SN solutions will be obtained up to now. xd·rank and xd·distance can be calculated through the fast non-dominated soring method. SN optimal solutions would be selected as the new population P based on population selection strategy.For the new population, the solutions with rank=1 also will be memorized as ES.Before onlookers exploiting, we should calculate the selection probability based on the fitness of solution. In the original ABC algorithm, the fitness of the feasible solution is defined through the value of the objective function f(xd) [31]:(8)fit(xd)=11+f(xd)However, in multi-objective optimization herein, because the number of objective function is more than one. The value of objective function f(xd)=[f1(x), f2(x), …, fu(x)], which is a u-dimensional vector, thus Eq. (8) is no longer applicable. A novel multi-objective fitness calculation method is proposed to deal with the situation.Because the measurements of the multiple objectives are different, they should be normalized before the calculation of fitness. The normalization formula is as follows:(9)f′k(xd)=maxfk−fk(xd)maxfk−minfk,ifmaxfk≠minfk1,ifmaxfk=minfkwheremaxfk=maxd=1SNfk(xd)andminfk=mind=1SNfk(xd). After normalization,f′k(xd)∈[0,1]. Then fit(xd) can be calculated by Eq. (10). Obviously, the smaller the objective function value of the feasible solution is, the greater the fitness of the solution will be.(10)fit(xd)=1u×∑k=1uf′k(xd)Each onlooker selects a solution according to the selection probability which is proportional to the nectar quality. The selecting probability pdis calculated as follows [31].(11)pd=0.9×fit(xd)maxd=1SNfit(xd)+0.1Then, each onlooker would select the food source depending on the selecting probability. It generates a random number in the range of (0, 1). If the number is greater than pd, then the onlooker will not move; otherwise the onlooker will attach itself to xd, and exploit its neighborhood as the employed bee does. Obviously, according to this selection method, the food source with higher fitness would attract more onlookers in this phase.After all onlookers exploiting, there are more than SN solutions. The fast non-dominated soring method and population selection strategy also will be applied to select SN optimal solutions as the new population P. And the solutions with rank=1 will be memorized as ES.If a solution is not updated after limit iterations, then this food source will be abandoned. The associated employed bee would become a scout, and generate a new food source randomly by Eq. (5).After all the food sources being explored, the next iteration begins. The whole evolutionary process will be repeated until it satisfies the end condition.In order to verify the effectiveness of our algorithm, we compare EMOABC algorithm with some other multi-objective optimization algorithms, such as non-dominated sorting genetic algorithm II (NSGA-II), multi-objective particle swarm optimization (MOPSO), and multi-objective artificial bee colony without elite-guided (MOABC). The parameters of these algorithms were presented as follows.NSGA-II [10]: The crossover probability was 0.9 and the mutation probability was 0.1. The simulated binary crossover operator and polynomial mutation [32] were applied. Both the distribution indexes for crossover and mutation operators were 20.MOPSO [11]: The repository size was SN. The inertia weight w was 0.4 and the learning factors c1 and c2 were random numbers in the range of [0, 1]. The number of grids per each dimension was 30.MOABC: limit was 20. The original local searching strategyvdi=xdi+ϕdi×(xdi−xei)was applied, and xewas the neighbor solution.EMOABC: limit was 20. The elite-guided solution generation strategy as Eq. (7) was applied, and yirepresents the ith element of the solution selected from ES randomly.In order to allow a quantitative assessment of the performance of multi-objective optimization algorithms, some evaluation metrics are applied. Their meaning and equation are given below.(1) Generational distance (GD) [33]: It describes how far the elements of PF obtained by each algorithm is away from those in the true Pareto optimal front PF*. It should be noticed that smaller GD indicates shorter distance between all the generated elements and those of PF*, which means the solutions are close to the PF*, thus the quality of algorithm is better. GD can be calculated as follows:(12)GD=∑d=1SNpd2SN.where SN is the number of feasible solutions obtained by each algorithm, and pddenotes the Euclidean distance between f(xd) in PF and the nearest member of PF*:(13)pd=minx∈P*(Euclidean distance(f(xd),f(x))).(2) Error ratio (ER) [34]: It indicates the percentage of generated solutions that are not members of PF*, which also is a metric reflecting the quality of solutions. The calculation equation is as follows:(14)ER=∑d=1SNedSN.where ed=0, if xdis a member of P*, and ed=1, otherwise. ed=0 means all the solutions generated by the algorithm belong to P*, thus the solution has the best quality.(3) Spread (SPR) [10]: It measures the extent of spread achieved among the obtained solutions. The calculation equation is as follows:(15)Spread=∑k=1udke+∑d=1SN−1p¯−pd∑k=1udke+(SN−1)*p¯where pdis the consecutive Euclidean distance between dth and (d+1)th solutions andp¯is the average of all pd.dkeis the Euclidean distance between the extreme solutions of P* and the boundary solutions of the obtained non-dominated set P corresponding to kth objective function. A good distribution would make all distances diequal tod¯and would makedke=0, making the metric to take a value zero. The metric takes a higher value with worse distributions of solutions within the extreme solutions.(4) Execution time (TI): It is the execution time of algorithms, which is a metric reflecting the performance of algorithms. The efficiency of the algorithm is better with the smaller TI. Because the computer operating system may perform some actions together with the MATLAB execution, such as the check for updates. The execution time of an algorithm is not very precision in strict terms. But we focus on the comparison of the efficiency of these algorithms.In the experiments, the population size was 100. The maximum number of cycles was 300. And each experiment was repeated 30 times independently and the average result was memorized.The experiments of this section were performed on a PC using an Intel Core i3 550 (3.2GHz), 4 GB RAM, Windows 7 (32 bit), and MATLAB R2010b.Firstly, we verify the performance of the proposed algorithm on a set of two-objective benchmark functions, including ZDT1, ZDT2, ZDT3, ZDT4, ZDT6 [35]. The variable dimension and boundary of each function are shown in Table 1.The Pareto optimal set (PF*) of ZDT problems have been collected11Pareto of ZDT: http://www.cs.cinvestav.mx/∼emoobook/apendix-d/apendix-d.html.. The comparison of results among the four algorithms considering the metrics previously described are shown in Table 2. And the best average results obtained with respect to each metric are shown in boldface.As shown in Table 2, for the GD metric, EMOABC performs best with respect to ZDT1 and ZDT6, and it also can produce competitive results on ZDT2 and ZDT3. NSGA-II can obtain better results on ZDT2, ZDT3 and ZDT4. With respect to the ER metric, EMOABC is best for ZDT1, ZDT3 and ZDT6, much better than other algorithms. And for the SPR metric, EMOABC performs best with respect to ZDT4 and ZDT6, and it also can produce competitive results on the ZDT1 and ZDT2. It should be noted that EMOABC and MOABC are much faster than NSGA-II and MOPSO with respect to the TI metric.Furthermore, it can be observed that EMOABC performs slightly better than MOABC on the above metrics for all the ZDT problems, even though EMOABC is a little slower than MOABC.Besides the quantitative comparison of the algorithms, the graphical results obtained by these algorithms are given in Fig. 2. It can be observed that EMOABC can produce the results that not only have good convergence but also have appropriate distribution over the Pareto front on ZDT1, ZDT3 and ZDT6. Fig. 2(d) show that all the algorithms have difficulty in solving ZDT4, but EMOABC can produce competitive results on it.For testing multi-objective optimization, DTLZ problem family was proposed [36]. The main feature of DTLZ is that the number of objectives can be arbitrarily specified. The mathematical representation of DTLZ problems are given in Table 3[37]. The Pareto optimal set (PF*) of the DTLZ problems have been collected22Pareto of DTLZ: http://www.cs.cinvestav.mx/∼emoobook/apendix-e/apendix-e.html.. The comparison of results among the four algorithms considering the metrics previously described are shown in Table 4. And the best average results obtained with respect to each metric are shown in boldface.As shown in Table 4, for the GD metric, EMOABC performs best with respect to DTLZ2 and DTLZ6, and it can produce competitive results on DTLZ4, DTLZ5 and DTLZ7. NSGA-II can obtain better results with respect to DTLZ1, DTLZ3, DTLZ4, DTLZ5 and DTLZ7. With respect to the ER metric, EMOABC is best for DTLZ2, DTLZ4, DTLZ5, DTLZ6 and DTLZ7, which is better than all other algorithms. And for the SPR metric, EMOABC is best only on DTLZ7 problem, but its results are competitive on DTLZ1, DTLZ3 and DTLZ6, which is worse than NSGA-II. But for the TI metric, EMOABC and MOABC are much faster than NSGA-II and MOPSO.Furthermore, it can be observed that EMOABC performs slightly better than MOABC at the above metrics for most of the DTLZ problems, although EMOABC is very little slower than MOABC.Fig. 3shows the graphical results produced by these algorithms. It can be observed that EMOABC can produce the results that not only have good convergence but also have appropriate distribution over the Pareto front on DTLZ2, DTLZ 4, DTLZ 5, DTLZ 6, DTLZ 7.We performed an analysis of the impact of the parameters of our EMOABC on its performance. In this paper, we used the twelve test functions previously described, as well as the four metrics mentioned before.The experiments of this section were performed on a PC using an Intel Core i5-4590 (3.3GHz), 4 GB RAM, Windows 7 (32 bit), and MATLAB R2010b.We modified the population size (SN) of EMOABC to analyze the effect. We performed runs when SN is 50, 100, 150, 200, and 250, respectively. The maximum number of cycles was 300. Each experiment was repeated 30 times. And the comparison of results is shown in Table 5.As shown in Table 5, we can notice that with the SN increases, the value of GD metric decreases, which means the solutions are close to the true Pareto set. However, with respect to ER, it decreases for most of DTLZ problems. That is because we prefer the solution with larger distance in the population selection strategy, which brings a bad influence to the quality of solutions. For the SPR metric, the value fluctuates slightly and decreases more or less. Besides, it is easy to notice that with the SN increases, the efficiency becomes worse with respect to TI metric.We varied the maximum number of cycles (MCN) of EMOABC to analyze the effect. We performed 100, 200, 300, 400, and 500 iterations. The population size was 100. Each experiment was repeated 30 times. And the comparison of results is shown in Table 6.With respect to GD and ER metric, as the number of iterations increases, it decreases gradually. Thus more cycles can make the solution more close to the true Pareto set. However, with respect to SPR metric, it fluctuates slightly and decreases more or less. The reason is that the added elite-guided strategy makes the feasible solution move close to the elite solution, which has a bad influence on the diversity of solutions to a certain extent. It is easy to notice that with the MCN increases, the value of TI metric increases too.

@&#CONCLUSIONS@&#
