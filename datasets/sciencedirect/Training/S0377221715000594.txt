@&#MAIN-TITLE@&#
A practicable branch and bound algorithm for sum of linear ratios problem

@&#HIGHLIGHTS@&#
The algorithm works by globally solving an equivalent bilinear programming.The main computations involve solving a sequence of linear programming problems.A new accelerating technique based on outer space region is proposed.The algorithm economizes the required computations by branching in outer space.

@&#KEYPHRASES@&#
Global optimization,Sum of linear ratios,Branch and bound,Accelerating technique,,

@&#ABSTRACT@&#
This article presents a practicable algorithm for globally solving sum of linear ratios problem (SLR). The algorithm works by globally solving a bilinear programming problem (EQ) that is equivalent to the problem (SLR). In the algorithm, by utilizing convex envelope and concave envelope of bilinear function, the initial nonconvex programming problem is reduced to a sequence of linear relaxation programming problems. In order to improve the computational efficiency of the algorithm, a new accelerating technique is introduced, which provides a theoretical possibility to delete a large part of the investigated region in which there exists no global optimal solution of the (EQ). By combining this innovative technique with branch and bound operations, a global optimization algorithm is designed for solving the problem (SLR). Finally, numerical experimental results show the feasibility and efficiency of the proposed algorithm.

@&#INTRODUCTION@&#
The sum of linear ratios problems have broad applications in management science, system engineering, optimization designing, transportation planning, finance and investment, bond portfolio optimization, cluster analysis, engineering optimization, geometric application, computer vision, biodiversity conservation, data envelopment analysis, and so on, see Almogy and Levin (1970), Bajalinov (2003), Cploantoni, Manes, and Whinston (1969), Schaible (1996), Konno and Watanabe (1996), Drezner, Schaible, and Simchi-Levi (1990), Schaible (1981), Stancu-Minasian (1997), Rao (1971), Schaible and Shi (2003), Billionnet (2013), Du, Cook, Liang, and Zhu (2014), Jeyakumar, Li, and Srisatkunarajah (2013), Kao (2014), Lim and Zhu (2013) and Yang, Li, Chen, and Liang (2014), and whose mathematical modelling can be stated as follows:(SLR):{maxf(x)=∑i=1pδiφi(x)ψi(x)s.t.x∈D≜{x∈Rn|Ax≤b,x≥0},where D is a nonempty bounded set, the numerator φi(x) and the denominator ψi(x) are all affine functions defined on Rnwith assumption that ψi(x) ≠ 0 for any x ∈ D, δi, i = 1, 2, …, p, are all arbitrary real numbers. Since ψi(x) is a continuous function defined on D, from the intermediate value theory, this implies ψi(x) < 0 or ψi(x) > 0 for all x ∈ D. If ψi(x) < 0, we can replaceφi(x)ψi(x)with−φi(x)−ψi(x),the problem remains essentially unchanged, so that we can always assume that ψi(x) > 0 for all x ∈ D. Moreover, as the set of solutions is bounded, in fact, if there exists some x ∈ D such that φi(x) < 0, we can replaceφi(x)ψi(x)with[φi(x)+Mψi(x)]ψi(x),where M is a constant so large that [φi(x) + Mψi(x)] ≥ 0 for any x ∈ D, the problem still remains essentially unchanged. Therefore, we can also assume that φi(x) ≥ 0. In all, without loss of generality, in the following, we can always assume that φi(x) ≥ 0 and ψi(x) > 0, i = 1, 2, …, p, for all x ∈ D. Naturally that some numerical problems can arise as a denominator vanishes, i.e., if there exists some ratioφi(x)ψi(x),which degrades into an affine function φi(x), for this case, the affine function φi(x) can be regarded as a ratio whose denominator is a constant 1, that is to say, φi(x) can be looked asφi(x)1,the problem can still be solved by using the algorithm proposed in this paper.In last decades, various solution approaches have been proposed for globally solving the special form of the sum of linear ratios problem (SLR). For instance, parametric simplex method (Konno, Yajima, and Matsui, 1991), outer approximation method (Benson, 2010), image space method (Falk and Palocsay, 1994), unified monotonic approach (Phuong and Tuy, 2003), interior point algorithm (Nesterov and Nemirovskii, 1995), heuristic method (Konno and Abe, 1999), simplicial branch and bound duality-bounds algorithm (Benson, 2007), concave minimization method (Benson, 2004a), branch and cut technique (Costa, 2010), branch and bound algorithms (Bazaraa, Sherali, and Shetty, 2006; Jiao, 2009; Jiao and Chen, 2008; Konno and Fukaishi, 2000; Kuno, 2002; 2005; Lin, 2008; Shen and Wang, 2008; Shi, 2011; Wang and Shen, 2008; Wang, Shen, and Liang, 2005), and so on. Although many algorithms can be used to solve special form of sum of linear ratios problem, as far as we know, only Shen and Wang (2006) present a branch and bound algorithm for maximizing the sum of linear ratios with coefficients. In addition, several algorithms (Benson, 2002a; 2002b; Dai, Shi, and Wang, 2005; Fang, Gao, Sheu, and Xing, 2009; Gao, Mishra, and Shi, 2012; Jaberipour and Khorram, 2010; Jiao, Wang, and Chen, 2013; Pei and Zhu, 2013; Shen and Jin, 2010; Shen, Duan, and Pei, 2009; Wang and Zhang, 2004) have been developed for globally solving sum of nonlinear ratios problems.In this paper, we will present a branch and bound algorithm for globally solving the sum of linear ratios problem (SLR) by utilizing new accelerating technique. The main features of our algorithm are given as follows. (1) We consider general sum of linear ratios problem, the investigated mathematical modeling in this article is more general than other one considered. (2) The algorithm works by globally solving a bilinear programming problem (EQ) that is equivalent to the problem (SLR). By utilizing convex envelope and concave envelope of bilinear function, the equivalent problem (EQ) is reduced to a sequence of linear relaxation programming problems. (3) In order to improve the computational efficiency of the proposed algorithm, a new accelerating technique based on outer space is raised, it offers a possibility to cut away a large part of the investigated region where there does not exist the global optimal solution of the problem (EQ), and which can be looked as an accelerating installation for global optimization of the problem (SLR). (4) The proposed algorithm economizes the required computations by conducting the branch-and-bound search in Rprather than in Rnor R2p, where p is the number of ratios in the objective function of the problem (SLR) and n is the number of decision variables in the (SLR). (5) The proposed algorithm is convergent to the global optimal solution through the successive refinement partition of the outer space region and solving a sequence of linear relaxation programming problems (LRP). Finally, numerical results show that our algorithm can be used to effectively solve the sum of linear ratios problem (SLR).The organization of this paper is as follows. The equivalent problem (EQ) of the (SLR) and its linear relaxation programming (LRP) which is established by utilizing convex envelope and concave envelope of bilinear function are given in Section 2. Section 3 presents and validates an innovative algorithm by combining branch and bound operations with accelerating technique. In Section 4, several test examples in recent literatures and several randomly generated problem of various dimensions are used to verify the feasibility and efficiency of our algorithm, and numerical results are given. Finally, some concluding remarks are given in Section 5.In order to globally solve the sum of linear ratios problem (SLR), first we transform the problem (SLR) into an equivalent nonconvex programs problem (EQ). In the following, our main computation is to globally solve the equivalent problem (EQ).Without loss of generality, we assume thatδi>0,i=1,2,…,T;δi<0,i=T+1,T+2,…,p;li0=minx∈Dφi(x),ui0=maxx∈Dφi(x),i=1,2,…,p;Li0=1maxx∈Dψi(x),Ui0=1minx∈Dψi(x),i=1,2,…,p.Since φi(x) and ψi(x) are all affine functions over the set D, the value ofli0,ui0,Li0andUi0can be easily obtained by solving linear programming problems. Obviously, for each i = 1, 2, …, p, we have0≤li0≤ui0,0<Li0≤Ui0.DefineΩ0={(t,s)∈R2p∣li0≤ti≤ui0,Li0≤si≤Ui0,i=1,2,…,p},and consider the following equivalent nonconvex programs problem:(EQ):{maxg(t,s)=∑i=1Tδitisi+∑i=T+1pδitisis.t.φi(x)−ti≥0,i=1,2,…,T,φi(x)−ti≤0,i=T+1,T+2,…,p,siψi(x)≤1,i=1,2,…,T,siψi(x)≥1,i=T+1,T+2,…,p,x∈D,(t,s)∈Ω0.The key equivalent theorem for the problems (SLR) and (EQ) is given as follows.Theorem 1If (x*, t*, s*) is a global optimum solution of the problem (EQ), then we can get thatti*=φi(x*),si*=1/ψi(x*),i=1,2,…,p,and x* is a global optimum solution of the problem (SLR). On the contrary, if x* is a global optimum solution of the problem (SLR), defineti*=φi(x*)andsi*=1/ψi(x*)(i=1,2,…,p),then (x*, t*, s*) is a global optimum solution of the problem (EQ).The proof can be easily followed by the monotonicity of the function, therefore it is omitted here.□By Theorem 1, we can follow that, for solving the problem (SLR), we may globally solve its equivalent problem (EQ) instead. Besides, it is easy to understand that the problems (SLR) and (EQ) have the same global optimal value.In this subsection, we will establish the linear relaxation programming of the problem (EQ), which can offer the upper bound of the global optimal value for the (EQ) in the proposed branch and bound algorithm. By utilizing special structure of objective function and constraint functions for the (EQ), the proposed method for yielding this linear relaxation programming problem depends on overestimating or underestimating the objective function and constraint functions of the (EQ). By Horst and Tuy (1993), McCormick (1976), Tuy (1998) and Benson (2004b), we can propose an approach for generating this linear overestimating function of the objective function for the problem (EQ), which is given by the following Theorem 2.Theorem 2Consider the rectangle LR = {(t, s) ∈ R2∣l ≤ t ≤ u, L ≤ s ≤ U}, where l, u, L and U are all non-negative constants satisfying 0 ≤ l ≤ u, 0 < L ≤ U. For any (t, s) ∈ LR, define the functions g(t, s), gLR(t, s) and gLR(t, s) as follows:g(t,s)=ts,gLR(t,s)=min{Ut+ls−lU,Lt+us−uL},gLR(t,s)=max{Lt+ls−lL,Ut+us−uU}.Then, the following conclusions hold:(i)For any (t, s) ∈ LR, g(t, s), gLR(t, s) and gLR(t, s) satisfygLR(t,s)≤g(t,s)≤gLR(t,s).Let Δt = u − l, Δs = U − L, thenlim▵s→0gLR(t,s)=lim▵s→0g(t,s)=lim▵s→0gLR(t,s).Let LR = {(t, s) ∈ R2∣l ≤ t ≤ u, s = b}, then we havegLR(t,s)=g(t,s)=gLR(t,s).(i) For any (t, s) ∈ LR, by the definition of convex envelope and concave envelope of the bilinear function and Benson (2004b), obviously, we havegLR(t,s)≤g(t,s)≤gLR(t,s).The conclusion (i) holds.(ii) By the definition of gLR(t, s), g(t, s) and gLR(t, s), we havegLR(t,s)−g(t,s)=min{Ut+ls−lU,Lt+us−uL}−ts=min{Ut+ls−lU−ts,Lt+us−uL−ts}=min{(t−l)(U−s),(u−t)(s−L)}≤min{(t−l)(U−L),(U−L)(u−t)}=(U−L)×min{(t−l),(u−t)}≤ΔsΔt,g(t,s)−gLR(t,s)=ts−max{Lt+ls−lL,Ut+us−uU}=min{ts−(Lt+ls−lL),ts−(Ut+us−uU)}=min{(t−l)(s−L),(U−s)(u−t)}≤min{(t−l)(U−L),(U−L)(u−t)}=(U−L)×min{(t−l),(u−t)}≤ΔsΔt.Since Δt is a bounded value, this implies that∣gLR(t,s)−g(t,s)∣→0and∣g(t,s)−gLR(t,s)∣→0asΔs→0.Therefore, we havelim▵s→0gLR(t,s)=lim▵s→0g(t,s)=lim▵s→0gLR(t,s).(iii) For each (t, s) ∈ LR, since s = b, we have L = b = U. Therefore, we haveg(t,s)=ts=bt,gLR(t,s)=min{Ut+ls−lU,Lt+us−uL}=min{bt+lb−bl,bt+bu−bu}=bt,gLR(t,s)=max{Lt+ls−lL,Ut+us−uU}=max{bt+lb−lb,bt+ub−ub}=bt.Thus, we can get thatgLR(t,s)=g(t,s)=gLR(t,s),and the proof is complete.□In the following, by utilizing Theorem 2, we will construct the upper bounding function of the objective function for the (EQ). Assume that Ω denotes Ω0 or a sub-rectangle of Ω0 that is generated by the branching process, where Ω = Ω1 × Ω2 × … × Ωp, with Ωi= {(ti, si) ∈ R2∣li≤ ti≤ ui, Li≤ si≤ Ui}, i = 1, 2, …, p. Obviously, li, ui, Li, Uisatisfy 0 ≤ li≤ ui, 0 < Li≤ Ui. For each i ∈ {1, 2, …, p}, for each (ti, si) ∈ Ωi, definegi(ti,si)=tisi,giLR(ti,si)=min{Uiti+lisi−liUi,Liti+uisi−uiLi},giLR(ti,si)=max{Liti+lisi−liLi,Uiti+uisi−uiUi},and let Gi(ti, si) denote overestimating function of δigi(ti, si). Then, for each i ∈ {1, 2, …, p}, by Theorem 2, we haveδigi(ti,si)≤Gi(ti,si)={δigiLR(ti,si),i=1,2,…,T,δigiLR(ti,si),i=T+1,T+2,…,p.Thus, for any (t, s) ∈ Ω, summing Gi(ti, si) over all terms i (i = 1, 2, …, p) and denoting the sum∑i=1pGi(ti,si)as G(t, s), we haveg(t,s)≤G(t,s)=∑i=1pGi(ti,si),forany(t,s)∈Ω.Also, sinceLiψi(x)≤siψi(x)≤1,i=1,2,…,T;Uiψi(x)≥siψi(x)≥1,i=T+1,T+2,…,pand(1)|siψi(x)−Liψi(x)|≤|si−Li|·|ψi(x)|≤1L0i·|Ui−Li|→0as|Ui−Li|→0,(2)|Uiψi(x)−siψi(x)|≤|Ui−si|·|ψi(x)|≤1L0i·|Ui−Li|→0as|Ui−Li|→0.Therefore, by the above discussion, we can construct the homologous approximation linear relaxation programming (LRPΩ) of the (EQ) over Ω as follows.(LRPΩ):{maxG(t,s)=∑i=1pδiris.t.ri≤Uiti+lisi−liUi,i=1,2,…,T,ri≤Liti+uisi−uiLi,i=1,2,…,T,ri≥Liti+lisi−liLi,i=T+1,T+2,…,p,ri≥Uiti+uisi−uiUi,i=T+1,T+2,…,p,φi(x)−ti≥0,i=1,2,…,T,φi(x)−ti≤0,i=T+1,T+2,…,p,Liψi(x)≤1,i=1,2,…,T,Uiψi(x)≥1,i=T+1,T+2,…,p,x∈D,(t,s)∈Ω.Based on the construction method of the linear relaxation programming problem (LRP), obviously every feasible point for the (EQ) in subregion Ω is feasible to the (LRPΩ), and the optimal value for the (LRPΩ) is more than or equal to that of the (EQ) in subregion Ω. Thus the linear relaxation programming problem (LRPΩ) provides a valid upper bound for the optimal value of the (EQ) in subregion Ω. And by Theorem 2, and (1) and (2), it is easy to see that the problem (LRPΩ) will approximate the problem (EQΩ) as ‖U − L‖ → 0.In this section, in order to design an effective algorithm for solving the problem (EQ), in the following, first we will introduce two fundamental operations: partition of ratio α and accelerating technique. Next, combining the two principal operations with the previous bounding technique together, an accelerating branch and bound algorithm is presented for globally solving the problem (EQ).In this subsection, the branching operation is performed in outer space Rp, where p is the number of ratios. Assume that Ω = {(t, s) ∈ R2p∣li≤ ti≤ ui, Li≤ si≤ Ui, i = 1, 2, …, p}⊆Ω0, α ∈ (0, 1), the branch operation is given as follows.(i)Letq∈argmax{Ui−Li,i=1,2,…,p}.Letγq=Lq+α(Uq−Lq).Ωqis subdivided into two 2-dimensional rectanglesΩq′andΩq′′,Ωq′={(tq,sq)∈R2∣lq≤tq≤uq,Lq≤sq≤γq},Ωq′′={(tq,sq)∈R2∣lq≤tq≤uq,γq≤sq≤Uq}.LetΩ′=Ω1×Ω2×…×Ωq−1×Ωq′×Ωq+1×…×Ωp,Ω′′=Ω1×Ω2×…×Ωq−1×Ωq′′×Ωq+1×…×Ωp.From the above branching operation, we can notice that the intervals [li, ui] of ti(i = 1, 2, …, p) never be partitioned by the branching processes. Hence, these branching operations only occur in an outer space of dimension p, i.e. the proposed algorithm economizes the required computations. For some subsequence K of {1, 2, …}, according to the proposed branching operation, the limitation rectangleΩq∞=⋂k∈KΩqkis a line segment in R2, which is parallel to the tq-axis.For any rectangle Ωk⊆Ω0, in the process of iteration k, we want to check whether or not Ωkcontains a global optimal solution of the EQ(Ω0), whereΩk=Ω1k×Ω2k×…×Ωq−1k×Ωqk×Ωq+1k×…×Ωpk,withΩqk={(tq,sq)∈R2∣lq0≤tq≤uq0,Lqk≤sq≤Uqk}.The proposed accelerating technique aims at replacing the rectangle Ωkwith a smaller rectangle Ω′ without losing any global optimal solution of the EQ(Ω0).Theorem 3Assume thatfis a known lower bound of the optimal objective value v of the EQ(Ω0), for any sub-range Ωk⊆Ω0, the following conclusions hold:(i) If RUBk<f, then there is no optimum solution for the EQ(Ω0) over Ωk.(ii) If RUBk≥f, then, for each μ ∈ {1, 2, …, T}, there exists no global optimum solution for the EQ(Ω0) overΩ¯k; for each μ ∈ {T + 1, T + 2, …, p}, there exists no global optimum solution for the EQ(Ω0) overΩ¯¯k,whereRUBk=∑i=1Tδiui0Uik+∑i=T+1pδili0Lik,ρμk={f̲−RUBk+δμuμ0Uμkδμuμ0,μ∈{1,2,…,T},f̲−RUBk+δμlμ0Lμkδμlμ0,μ∈{T+1,T+2,…,p},Ω¯k=Ω1k×Ω2k×…×Ωμ−1k×Ω¯μk×Ωμ+1k×…×ΩTk×ΩT+1k×…×Ωpk,Ω¯¯k=Ω1k×Ω2k×…×ΩTk×ΩT+1k×…×Ωμ−1k×Ω¯¯μk×Ωμ+1k×…×Ωpk,withΩ¯μk={(tμ,sμ)∈R2∣lμ0≤tμ≤uμ0,Lμk≤sμ<ρμk}⋂Ωμk,μ∈{1,…,T},Ω¯¯μk={(tμ,sμ)∈R2∣lμ0≤tμ≤uμ0,ρμk<sμ≤Uμk}⋂Ωμk,μ∈{T+1,…,p}.(i) If RUBk<f, thenmax(t,s)∈Ωk∑i=1pδitisi=∑i=1Tδiui0Uik+∑i=T+1pδili0Lik=RUBk<f̲.Therefore, there does not exist global optimum solution for the EQ(Ω0) over Ωk.(ii) If RUBk≥f, then: for each μ ∈ {1, 2, …, T}, for∀(t,s)∈Ω¯k,for each i = 1, 2, …, p, we have0≤li0≤ti≤ui0,0≤Lμk≤sμ<ρμk(i=μ),0≤Lik≤si≤Uik(i≠μ).Hence, we havemax(t,s)∈Ω¯k∑i=1pδitisi=max(t,s)∈Ω¯k∑i=1,i≠μTδitisi+max(t,s)∈Ω¯kδμtμsμ+max(t,s)∈Ω¯k∑i=T+1pδitisi<∑i=1,i≠μTδiui0Uik+δμuμ0ρμk+∑i=T+1pδili0Lik=∑i=1,i≠μTδiui0Uik+δμuμ0×f̲−RUBk+δμuμ0Uμkδμuμ0+∑i=T+1pδili0Lik=∑i=1,i≠μTδiui0Uik+f̲−RUBk+δμuμ0Uμk+∑i=T+1pδili0Lik=RUBk+f̲−RUBk=f̲.Therefore, there is no global optimum solution for the EQ(Ω0) overΩ¯k.Similarly, for each μ ∈ {T + 1, T + 2, …, p}, and for∀(t,s)∈Ω¯¯k,for each i = 1, 2, …, p, we have0≤li0≤ti≤ui0,0≤ρμk<sμ≤Uμk(i=μ),0≤Lik≤si≤Uik(i≠μ).Hence, we havemax(t,s)∈Ω¯¯k∑i=1pδitisi=max(t,s)∈Ω¯¯k∑i=1Tδitisi+max(t,s)∈Ω¯¯kδμtμsμ+max(t,s)∈Ω¯¯k∑i=T+1,i≠μpδitisi<∑i=1Tδiui0Uik+δμlμ0ρμk+∑i=T+1,i≠μpδili0Lik=∑i=1Tδiui0Uik+δμlμ0×f̲−RUBk+δμlμ0Lμkδμlμ0+∑i=T+1,i≠μpδili0Lik=∑i=1Tδiui0Uik+f̲−RUBk+δμlμ0Lμk+∑i=T+1,i≠μpδili0Lik=RUBk+f̲−RUBk=f̲.Therefore, there does not exist global optimum solution for the EQ(Ω0) overΩ¯¯k.□By Theorem 3, the new accelerating technique provides a possibility for deleting the whole or a large part of the currently investigated sub-rectangle in which the global optimum solution of the EQ(Ω0) does not exist.Combining the former linear relaxation bounding method, branching operation and new accelerating technique together, the proposed algorithm for solving the problem (SLR) may be stated as follows.Step 0 (Initialization). Initialize the iteration counter k = 0, convergence error ɛ ≥ 0. For each i = 1, 2, …, p, compute the value ofli0,ui0,Li0andUi0,and solve the LRP(Ω0) by using simplex method to obtain its optimal solution (x0, t0, s0) and optimal value UB(Ω0), respectively. Letx*=x0,t*=t0,si*=1ψi(x0),i=1,2,…,p,obviously, (x*, t*, s*) is a feasible solution for the EQ(Ω0). LetUB0=UB(Ω0)andf̲=g(t*,s*)=∑i=1pδiti*si*.If UB0 −f≤ɛ, stop; then (x*, t*, s*) and x* are ɛ-global optimal solutions for the EQ(Ω0) and the (SLR), respectively. Otherwise, set F = ∅, k = 1, Ω1 = Ω0, the set of all active node Θ1 = {Ω1}, and go to Step 1.Step 1 (Accelerating). For the investigated sub-rectangle Ωk, we use new accelerating technique described in Section 3.2 to cut away a large part of the sub-rectangle or the whole sub-rectangle in which there exists no global optimal solution of the EQ(Ω0), and still denote the remaining sub-rectangle by Ωk.Step 2 (Branching). Partition Ωkinto two sub-rectangles Ωk, 1, Ωk, 2⊆Ωkaccording to the partition of ratio α, and denote the collection of new partitioned sub-rectangles byΩ¯k.Step 3 (Bounding). Solve the (LRP) to obtain UB(Ωk, τ) and (xk, τ, tk, τ, sk, τ) for eachΩk,τ∈Ω¯k,where τ ∈ {1, 2}, and lets¯ik,τ=1/ψi(xk,τ),i=1,2,…,p,τ=1,2.If UB(Ωk, τ) <f, letΩ¯k:=Ω¯k∖Ωk,τ,otherwise, update the lower bound by settingf̲=max{f̲,g(tk,τ,s¯k,τ)},if possible.Set xk, τand(xk,τ,tk,τ,s¯k,τ)be the currently known best feasible solution for the (SLR) and the EQ(Ω0), respectively. Let x* = xk, τand(x*,t*,s*)=(xk,τ,tk,τ,s¯k,τ).The remaining partition set is now denoted byΘk:=(Θk∖Ωk)∪{Ω¯k},and update the upper bound by settingUBk=maxΩ∈ΘkUB(Ω).Step 4 (Termination). If UBk−f≤ɛ, then the algorithm terminates, meanwhile, we follow that (x*, t*, s*) and x* are ɛ-global optimum solutions for the EQ(Ω0) and the (SLR), respectively. Otherwise, let k = k + 1, and return to Step 1.In this subsection, the global convergence of the proposed algorithm is given as follows.Theorem 4The above algorithm either terminates finitely with the global optimum value of the (SLR), or generates an infinite sequence {xk} of solutions such that any accumulation point of which is a global optimal solution for the problem (SLR).If the proposed algorithm terminates finitely in iteration k, then when termination, solve the linear relaxation programming problem LRP(Ωk) to obtain its optimal solution (xk, tk, sk), and lettings¯ik=1/ψi(xk),i=1,2,…,p,then, obviously,(xk,tk,s¯k)is a feasible solution for the problem EQ(Ω0). By Theorems 1 and 2 upon termination of the proposed algorithm, we can follow thatUBk≥v,v≥g(tk,s¯k),f(xk)=g(tk,s¯k),g(tk,s¯k)+ɛ≥UBk.Combining the above inequality together, we havef(xk)+ɛ=g(tk,s¯k)+ɛ≥UBk≥v≥g(tk,s¯k)=f(xk),i.e.v≥f(xk)≥v−ϵ.Hence, when the proposed algorithm terminates finitely in iteration k, it follows that f(xk) is the ε-global optimal value of the (SLR).If the proposed algorithm generates an infinite sequence {xk, tk, sk} of solutions by solving the linear relaxation programming LRP(Ωk), and lettings¯ik=1/ψi(xk),i=1,2,…,p,then we can obtain an infinite sequence{xk,tk,s¯k}of feasible solutions for the EQ(Ω0). Set (x*, t*) be an accumulation point of {(xk, tk)}, without loss of generality assume thatlimk→∞(xk,tk)=(x*,t*). By the continuity of the function ψi(x), we have(3)limk→∞1/ψi(xk)=1/limk→∞ψi(xk)=1/ψi(x*).By branching operation and Theorem 2, we havelimk→∞Ωk=⋂k∈KΩ1k×⋂k∈KΩ2k×…×⋂k∈KΩpk=Ω1∞×Ω2∞×…×Ωp∞=Ω∞withΩik={(ti,si)∈R2∣li0≤ti≤ui0,Lik≤si≤Uik}andΩi∞={(ti,si)∈R2∣li0≤ti≤ui0,si=si*}.Therefore, we have(4)limk→∞Lik=si*=limk→∞Uik.Also since1/ψi(xk)=s¯ik∈[Lik,Uik],i=1,2,…,p,we have(5)Lik≤1ψi(xk)=s¯ik≤Uik.By (3), (4) and (5), we have1/ψi(x*)=limk→∞1ψi(xk)=limk→∞s¯ik=si*.Therefore, (x*, t*, s*) is also a feasible solution for the EQ(Ω0), also since {UB(Ωk)} is a decreasing sequence of real numbers bounded below by v, we have(6)g(t*,s*)≤v≤limk→∞UB(Ωk).By updating process of upper bound, we have(7)limk→∞UB(Ωk)=limk→∞G(tk,sk),where (tk, sk) is an optimal solution for the LRP(Ωk). By Theorem 2 (ii) and (iii), and the continuity of function g(t, s), we have(8)limk→∞G(tk,sk)=limk→∞[∑i=1TδigiLR(tik,sik)+∑i=T+1pδigiLR(tik,sik)]=g(t*,s*).By the previous equations (6)–(8), we havelimk→∞UB(Ωk)=v=g(t*,s*).Consequently, (x*, t*, s*) is a global optimum solution for the problem EQ(Ω0). From the equivalent Theorem 1, we can follow that x* is a global optimum solution of the problem (SLR). The proof is completed.□Costa (2010) presents a branch and cut technique for solving a weighted sum of linear ratios problem. It is an improvement of the approach presented in Costa (2007) which is basically a branch and bound method. In the technique of Costa (2010), the region to be trimmed by the cut is only the non-dominated region. Based on duality bounds, Benson (2007) proposes a simplicial branch and bound approach for solving the sum of linear ratios problem. It is an adaptation of the proposed approach in Benson (2002b) for the special form of the sum of linear ratios problem and it relaxes some of the necessary assumptions to solve sum of nonlinear ratios problems, and it only requires that the numerators are not equal to 0. In Benson (2007), the proposed algorithm performs a branching operation in Rpthat iteratively partitions the initial p-dimensional simplex S0 into smaller p-dimensional subsimplicies, where p is the number of ratios. This branching process is performed by an operation called simplicial bisection. In this paper, based on linear relaxation bounding method and new accelerating technique, we present a novel branch and bound algorithm for solving the sum of linear ratios problem. The proposed algorithm in this paper involves partitioning a hyper-rectangle region, which is defined in a space of dimension 2p, and which is constructed by the minimum and maximum of the numerators and the reciprocals of the denominators for the ratios over the feasible region, branching process only takes place in a space of dimension p, where p is also the number of ratios in objective function. For each generated sub-region, the algorithm of Costa (2010) solves on average p/2 linear programming problems of dimension n + 1 with m + 2p + 1 constraints. For each partitioned sub-region the algorithm presented in Benson (2007) solves a linear programming problem of dimension 2(p + 1) + m with (p + 1)(n + 1) constraints. However, for each generated sub-rectangle the proposed algorithm in this paper solves one linear programming problem of dimension n + 2p with m + 2p constraints. The numerical comparisons of computational performances for these algorithms are very difficult since there are no computational results in Benson (2007).To verify the performance of our algorithm, several test examples in recent literatures and a randomly generated test problem are implemented on microcomputer, the algorithm is programmed in C + + software, and all linear relaxation programming problems are solved by using simplex method. These test examples and their numerical results are given as follows.Example 1(Phuong and Tuy, 2003).{max37x1+73x2+1313x1+13x2+13+63x1−18x2+3913x1+26x2+13s.t.5x1−3x2=3,1.5≤x1≤3.Solving this problem by the proposed algorithm, with ε = 10−6 and α = 0.5, after 1 iteration, a global ε-optimal solution (x1, x2) = (3, 4) is found with objective function value 5, the number of linear relaxation programming problems that were solved is 1.Using the three algorithms in Phuong and Tuy (2003), with ε = 0.01, the global ε-optimal solution (x1, x2) = (3.000000, 4.000000) can also be found with optimal value 5.000000, after 11, 10 and 7 iterations, respectively.Example 2(Pei and Zhu, 2013).{max4x1+3x2+3x3+503x2+3x3+50+3x1+4x2+504x1+4x2+5x3+50+x1+2x2+5x3+50x1+5x2+5x3+50+x1+2x2+4x3+505x2+4x3+50s.t.2x1+x2+5x3≤10,x1+6x2+3x3≤10,5x1+9x2+2x3≤10,9x1+7x2+3x3≤10,x1,x2,x3≥0.Solving this problem by our algorithm, with ε = 10−9 and α = 0.55, after 1289 iterations, a global ε-optimal solution (x1, x2, x3) = (1.1111, 1.36577e − 005, 1.35168e − 005) is found with objective function value 4.0907, the number of linear relaxation programming problems that were solved is 2579.Using the method in Pei and Zhu (2013), with ε = 10−5, after 1640 iterations, a global ε-optimal solution (x1, x2, x3) = (0.0013, 0.0000, 0.0000) is found with objective function value 4.0001.Example 3.{max0.9×−x1+2x2+23x1−4x2+5+(−0.1)×4x1−3x2+4−2x1+x2+3s.t.x1+x2≤1.50,x1−x2≤0,0≤x1,x2≤1.Solving this problem by the proposed algorithm, with ε = 10−6 and α = 0.5, after 1 iteration, a global ε-optimal solution (x1, x2) = (0, 1) is found with objective function value 3.575, the number of linear relaxation programming problems that were solved is 1.Example 4(Phuong and Tuy, 2003).{max∑i=15〈ci,x〉+ri〈di,x〉+sis.t.Ax≤b,x≥0.wherec1=(0.0,−0.1,−0.3,0.3,0.5,0.5,−0.8,0.4,−0.4,0.2,0.2,−0.1),r1=14.6d1=(−0.3,−0.1,−0.1,−0.1,0.1,0.4,0.2,−0.2,0.4,0.2,−0.4,0.3),s1=14.2c2=(0.2,0.5,0.0,0.4,0.1,−0.6,−0.1,−0.2,−0.2,0.1,0.2,0.3),r2=7.1d2=(0.0,0.1,−0.1,0.3,0.3,−0.2,0.3,0.0,−0.4,0.5,−0.3,0.1),s2=1.7c3=(−0.1,0.3,0.0,0.1,−0.1,0.0,0.3,−0.2,0.0,0.3,0.5,0.3),r3=1.7d3=(0.8,−0.4,0.7,−0.4,−0.4,0.5,−0.2,−0.8,0.5,0.6,−0.2,0.6),s3=8.1c4=(−0.1,0.5,0.1,0.1,−0.2,−0.5,0.6,0.7,0.5,0.7,−0.1,0.1),r4=4.0d4=(0.0,0.6,−0.3,0.3,0.0,0.2,0.3,−0.6,−0.2,−0.5,0.8,−0.5),s4=26.9c5=(0.7,−0.5,0.1,0.2,−0.1,−0.3,0.0,−0.1,−0.2,0.6,0.5,−0.2),r5=6.8d5=(0.4,0.2,−0.2,0.9,0.5,−0.1,0.3,−0.8,−0.2,0.6,−0.2,−0.4),s5=3.7A=[−1.8−2.20.84.13.8−2.3−0.82.5−1.60.2−4.5−1.84.6−2.01.43.2−4.2−3.31.90.70.8−4.44.42.03.7−2.8−3.2−2.0−3.7−3.33.5−0.71.5−3.14.5−1.1−0.6−0.6−2.54.10.63.32.8−0.14.1−3.2−1.2−4.31.8−1.6−4.5−1.34.63.34.2−1.21.92.43.4−2.9−0.5−4.11.73.9−0.1−3.9−1.51.62.3−2.3−3.23.90.31.71.34.70.93.9−0.5−1.23.80.6−0.2−1.50.5−4.23.6−0.6−4.81.5−0.30.6−3.60.23.8−2.80.13.3−4.32.44.11.71.0−3.34.4−3.7−1.1−1.4−0.62.22.51.3−4.3−2.9−4.12.7−0.8−2.93.51.24.31.9−4.0−2.61.82.50.61.3−4.3−2.34.1−1.10.00.4−4.5−4.41.2−3.8−1.91.23.0−1.1−0.22.5−0.1−1.72.91.54.7−0.34.2−4.4−3.94.44.7−1.0−3.81.4−4.71.93.83.51.52.3−3.7−4.22.7−0.10.2−0.14.9−0.90.14.31.62.61.5−1.00.81.6]b=(15.7,31.8,−36.4,38.5,40.3,10.0,89.8,5.8,2.7,−16.3,−14.6,−72.7,57.7,−34.5,69.1)T.Solving this problem by the proposed algorithm, with ε = 10−3 and α = 0.5, after 927 iterations, a global ε-optimal solution(x1,x2,…,x12)=(6.24409,20.0249,3.79672,5.93972,0,7.43852,0,23.2833,0.515015,40.9896,0,3.14363)is found with objective function value 16.2619, the number of linear relaxation programming problems that were solved is 1855.Using the method in Phuong and Tuy (2003), with ε = 10−2, after 620 iterations, a global ε-optimal solution(x1,x2,…,x12)=(6.223689,20.060317,3.774684,5.947841,0,7.456686,0,23.312579,0.000204,41.031824,0,3.171106)is found with objective function value 16.077978.Example 5{max∑i=1pδi∑j=1ndijxj+gi∑j=1ncijxj+his.t.∑j=1nakjxj≤bk,k=1,2,…,m,xj≥0.0,j=1,2,…,n,where gi, hi, dij, cij, bk, akj, i = 1, 2, …, p, k = 1, 2, …, m, j = 1, 2, …, n, are all randomly generated in the unit interval [0.0, 1.0]; δi, i = 1, 2, …, p, are randomly generated between 0 and 1.In Example 5 and Table 1, the following notations have been used: p represents the number of linear ratios in the objective function; n denotes the dimension of the problem; m denotes the number of the constraints; Ave. LP represents the average number of linear relaxation programming problems that were solved; Ave. time stands for the average CPU time of the algorithm in seconds. In Table 1, Ave. LP and Ave. time are obtained by randomly running our algorithm for 10 test problems.From the numerical results in Table 1, when we fix the value of n and m in Example 5, it is obvious that the average number of linear relaxation programming problems that are solved and the average CPU time of the algorithm increase with the increase of the number of ratios in objective function.From the above numerical results, it can be seen that our algorithm can be used to globally solve the problem (SLR). Test results also indicate that the proposed algorithm is robust and effective.In this paper, we present a practicable branch and bound algorithm for globally solving the sum of linear ratios problem (SLR). First, to globally solve the problem (SLR), the original problem (SLR) is equivalently transformed into the EQ(Ω0). Second, through utilizing convex envelope and concave envelope of bilinear function, a linear relaxation programming problem LRP(Ω0) of the EQ(Ω0) was established, and which can provide a reliable upper bound for the EQ(Ω0). Third, a new accelerating technique is introduced, it offers a possibility to delete the whole investigated region or a part of the currently investigated region in which there does not exist the global optimal solution of the equivalent problem EQ(Ω0), and which can be seen as an accelerating device for global optimization algorithm of the problem (SLR). Fourth, the proposed algorithm economizes the required computations by conducting the branch-and-bound search in Rprather than in Rnor R2p, where p is the number of ratios in the objective function of the problem (SLR) and n is the number of decision variables for the problem (SLR). Finally, numerical results show that the proposed algorithm can reduce the rapid growth of the branching tree during the algorithm search, and which can be used to globally solve the sum of linear ratios problem (SLR) within a practical amount of computational time.

@&#CONCLUSIONS@&#
