@&#MAIN-TITLE@&#
Control of leader–follower formation and path planning of mobile robots using Asexual Reproduction Optimization (ARO)

@&#HIGHLIGHTS@&#
We consider path planning in leader–follower formation with the obstacle avoidance using the potential field method.We compare the performances of 4 methods by simulations and real experiment on e-Puck robots.Experimental results, higher performance and fast convergence time to the best solution of the ARO demonstrate that this method is more appropriate for real time control application.

@&#KEYPHRASES@&#
Path optimization,Artificial potential field,Asexual Reproduction Optimization (ARO),Simulated Annealing (SA),Improved Harmony Search and Cuckoo Optimization Algorithm (COA),

@&#ABSTRACT@&#
This paper presents the optimal path of nonholonomic multi robots with coherent formation in a leader–follower structure in the presence of obstacles using Asexual Reproduction Optimization (ARO). The robots path planning based on potential field method are accomplished and a novel formation controller for mobile robots based on potential field method is proposed. The efficiency of the proposed method is verified through simulation and experimental studies by applying them to control the formation of four e-Pucks robots (low-cost mobile robot platform). Also the proposed method is compared with Simulated Annealing, Improved Harmony Search and Cuckoo Optimization Algorithm methods and the experimental results, higher performance and fast convergence time to the best solution of the ARO demonstrated that this optimization method is appropriate for real time control application.

@&#INTRODUCTION@&#
In recent years, control of multi-agent systems has been widely considered, due to their usage in formation control and swarming of agents which could be mobile robots, undersea, ground or air vehicles/robots [1]. Such systems are of interest due to many benefits, for example, when a task is too complex for a single agent to figure it out, multi agent system cooperates in order to accomplish it, and also the performance of the system may be improved. The agents of a multi-agent system may be easier to build, cheaper, more flexible and more fault tolerant than a single agent designed for each separate complex task [2,3]. The application like exploring, surveillance, logistics, data mining and security services can be easily modelled as a multi agent system.Formation control, obstacle avoidance and stability with agent-failed are some type of the problems of multi-agent systems. In formation control, different control topologies can be selected based on the specific structures. There may be one or more leaders in the group, while the other robots follow them in a specified way, in which each robot has onboard sensing and computation ability. In general, global knowledge is not available to each robot and a centralized controller is not used; therefore, the design of the controller for each robot has to be based on the local information. If there is no leader, then each robot should be coordinated with the others by relying on some global consensus to obtain the common goal [5]. Several control approaches have been emerged to address the multi-agent formation problems, like leader–follower strategy [5,6], virtual structure approach [7,8] and behaviour-based method [9,10]. Depending on robot characteristics such as computational capability and communication limitations or in the specific task to be performed by the formation, different control strategies have been developed in the field of multi-robot systems [1].In a leader–follower strategy, the leaders have the desired trajectory, which can help the whole system, and the other agents follow the leaders by the relative knowledge achieved from their neighbours and the leaders [5]. In this method, the leader has no feedback from the followers that tends to cause system instability; also, in practice some state variables of agents may not be measured. In this case, decentralized observer is designed for each agent in [6,7]. There are several methods for providing formation control such as: non-linear system theory based methods [11], fuzzy and neural networks [12,13], reinforcement learning [14] and artificial potential field based methods [4,15].Path planning is a problem of space traversing without collision with the environment. The goal of collision-free path planning is to find a suitable continuous path of a robot from the start configuration to the target state while avoiding collision with the obstacles. Path planning algorithms have several applications like industrial robotics [16] and biological molecules modelling [17]. Many techniques have been proposed to overcome this problem, such as fuzzy logic techniques [18], evolutionary algorithms [19,20], ant colony optimization [21], artificial potential field methods (APF) [22,23], neural networks approaches [24], hybrid techniques [25] and nonlinear optimal control [26].Potential field method is popularly used for mobile robot path planning [1]. The principle part is an artificial potential field which “attracts” the robot to the target, and “repulses” it from the obstacles, which can be implemented quickly and provide acceptable results without requiring many clarification. Indeed, it is suitable for real-time implementation requiring only local gradient information, without requiring global information [27]. Therefore it is an applicable method for robotic researches and also several studies have reported different extensions for it. E.g., in [28] fuzzy-based potential field methods are used for robot manipulators’ motion planning, in [29] potential field is used for soccer robots obstacle avoidance. The authors in [30,31] have used potential field, for a mobile robot to track a moving targets. Potential field based controllers are also used for robots multi-robot systems formation [4,15].The main disadvantage of potential field method is the problem of local minimum, which is the result of unpredictable shape of total potential field after the superposition of attractive and repulsive potential fields [32]. Several authors have tried to solve this problem by presenting new potential functions [31,33–36]. Volpe and Khosla introduced a superquadric artificial potential function [33], which model a wide range of shapes range from rectangles to ellipse taking advantage super quadric formulas. But it can only use when a single obstacle exists and not be applicable for more than one obstacle [33]. Harmonic potential functions which provides a potential field without local minima is proposed by Kim and Khosla [34], and Connolly in Ref. [35] in the same time, based on the Laplace potential. It is a well known method for robot motion planning [37], however the simplest form of this method can only model point robots. For nonpoint robots a situation called the “structural local minimum” may be happen [34].Also, there exist other inherent limitations in potential field methods [36,38]; (i) No passage between closely spaced obstacles. (ii) Oscillations in the presence of obstacles. (iii) Oscillations in narrow passages. (iv) Goals no-reachable with obstacles nearby (GNRON). To overcome the problems, several techniques have been presented [38,39].It has been shown that, the heuristic and metaheuristic optimization methods like evolutionary computation optimization, are the effective techniques to avoid local minima [40–45]. Simulated Annealing (SA) is an optimization method which models the physical process of recrystallization of atoms in heated metal during its cooling [40]. Thus atoms move to minimum energy configuration. In [46], the approach of potential field becomes better by using Simulated Annealing algorithm and the optimal path is obtained without considering each agent's dynamics. In [29,39], Genetic Algorithm (GA), combined with potential field method, obtained the optimal potential field functions.Harmony Search (HS) is a metaheuristic algorithm, which has been proposed by Geem et al. [41]. HS was using musical process of searching for a perfect state of harmony. The harmony in music is analogous to the optimization solution vector, and the musicians’ improvisations are analogous to local and global search schemes in optimization techniques. Improved Harmony Search (IHS) algorithm, is the power of the HS with the fine-tuning feature of mathematical techniques, which enhances accuracy and convergence rate of HS [42].Cuckoo Optimization Algorithm (COA) [43], an optimization algorithm which is inspired by lifestyle of a bird called Cuckoo. Special characteristics of cuckoos in egg laying and breeding had been the basic motivation for development of this algorithm. Each individual in the algorithm has a habitat around which she starts to lay eggs. COA has an acceptable estimation of global minimum and suitable for optimization problems.Asexual Reproduction Optimization (ARO) is an individual based and model free optimization algorithm which is inspired from asexual reproduction, that can nicely find the global minimum of a cost function that may possess several local minima in an astonishing time, possessing advantages of both population-based and individual-based algorithms, by adaptively exploration and exploitation [44,45]. It has several advantages which give it preference in comparison with other algorithms. It is an individual based algorithm and has a remarkable fast convergence time, unlike the population-based algorithms such as: GA, PSO, COA and ant colony optimization which take a lot of time to converge. Consequently, it is very appropriate to implement in real time application especially for real time control, filtering, signal processing and data mining [47,48]. Individual based algorithm such as: Tabu Search (TS) and SA are quick but they are not guaranteed to find the optimal solution in reasonable time. In addition, the mentioned algorithms deal with parameters tuning due to the lack of optimum parameters setting. For example, bad parameter setting for PSO, could lead to its failure [49]. But ARO does not require any parameter tuning, or any selection mechanism. In [47] ARO is used for minimum-delay link determination in networked control systems and in [48] is used for structure learning in the Bayesian networks.In this paper, we consider the path optimization problem of some agents in leader–follower formation for mobile robots with double integrator dynamics. Potential field method is used for path planning in presence of obstacle and nonholonomic constraint is considered for robots. Also some factors such as maximum linear and angular speed of the robot are considered. Then the path planning is generalized into a multi agent system in a leader–follower structure. In this study, we consider a leader robot as a moving target, which the followers track it, in a specific distance taking advantage of potential field method. The proposed method is also used to solve the GNRON problem. In formation, the leader and follower robots should have the same heading angle relative to the horizon axis during moving towards the target. Also, the oscillations of robots in narrow passages and presence of obstacles are reduced. The defined cost functions in order to perform path planning and formation are optimized by ARO, Improved Harmony Search (IHS), Cuckoo Optimization Algorithm (COA) and Simulated Annealing (SA) methods. The performances of optimization methods are compared by the results of simulations and real experiment on four e-Puck robots. Experimental results indicate that ARO method is more suitable for real time control applications.The outline of this study is as follows. In Section 2, we explain a brief introduction of Simulated Annealing, Improved Harmony Search and Cuckoo Optimization Algorithm. In Section 3 we present ARO method. In section 4, the path optimization problem is introduced and the obstacle avoidance algorithm is explained, also the problem is generalized into a multi agent problem. In Section 4, we present the simulation results in MATLAB and Webots platform and finally demonstrate that the simulation results are experimentally validated on two mobile robot platform and we wrap it up with conclusion in Section 5.Simulated Annealing (SA) is an optimization technique that proposed in [40], attempts to find the global minimum of a cost function that may possess several local minima. SA is able to deal with cost functions with quite arbitrary degrees of nonlinearities, discontinuities and stochasticity and can process quite arbitrary boundary conditions and constraints imposed on them. It has been shown [50] that SA is a quick method to implement in real time applications. The method works by imitating the physical process whereby a heated solid is slowly cooled so that when eventually its structure is frozen, which happens at a minimum energy configuration. The slow cooling gives atoms more chances of finding configurations with lower internal energy than the initial ones. At first, a random initial placement is selected and the temperature should be initialized very high. The next step is perturbing the initial placement randomly in its neighbourhood. The algorithm determines whether the new point is better or worse than the current point by evaluating cost function. If the new point is better than the current point, it becomes the next point. If the new point is worse than the current point, the algorithm decides whether to accept it or not according to the probabilistic function that will be defined later. The temperature is updated by lowering it according to a deterministic “cooling schedule”. The probabilistic function is defined as below:(1)P=eρ((Jo−Jn)/T)where Jois the value of cost function in the previous step, Jnis the value of the cost function in the next step, ρ is the probability factor, and T is the temperature parameter. If the temperature is too high, then the value of the probabilistic function is almost “1” which means in the primary steps, every move is acceptable even if the cost function increases (decreases). This feature helps in the way that the algorithm does not stick in local minima (maxima) and leads to the global minimum (maximum). By decreasing the temperature, the value of the probabilistic function decreases. This means the probability of having a move that increases (decreases) the cost function, decreases. Just like the nature, in high temperature, it's more often to go to any position by atoms. However, in low temperature, they are willing to go to positions in which they can lose energy; so these well-organized structures are made.Harmony Search (HS) is inspired from improvisation process of music players and proposed by Geem et al. [41]. Each musician improvisation process consists of three possible choices: (i) playing any famous note from his memory; (ii) playing a note in vicinity of previous selected note; (iii) selecting a note randomly. These three choices are the basic rules of HS which are applied in algorithm, by harmony memory considering rate (HMCR) and pitch adjusting rate (PAR) parameters. The HMCR is the probability of choosing a note from the Harmony Memory (HM) and PAR, is the probability of playing a note in vicinity of previous selected one.HS initializes a population of solution vectors randomly and saved them in HM. Then generates a new harmony vector using the rules. If new vector, overcomes the worst harmony in the HM, according to a fitness function, the worst harmony vector is replaced by the new one.For generating a new solution vector the algorithm may select value of each decision variable either from HM, with the probability of HMCR or randomly, with the probability of (1-HMCR). Then with the probability of PAR, decision variables which are chosen from HM are selected for pitch-adjusting. In pitch-adjustment the decision variable xiis replaced as followxi←xi±rand×bwwhere bw is an arbitrary distance bandwidth.HS is good at identifying the high performance regions of the solution space at a reasonable time, but it cannot make an effective balance between global and local search and gets into trouble in performing local search for numerical applications. PAR parameter plays a very important role in fine-tuning of optimized solution vectors, and it is effective in adjusting convergence rate to optimal solution. Therefore [42] proposed Improved Harmony Search (IHS) algorithm which uses dynamic increasing PAR parameter, and decreasing the bandwidth (bw) instead of fixed values, in order to solve the mentioned problem. PAR and bw change dynamically with generation number as follow:(2)PAR(gn)=PARmin+PARmax−PARminNI×gnwhere PAR(gn) is pitch adjusting rate for each generation, PARminand PARmaxis minimum and maximum pitch adjusting rate respectively, NI is number of solution vector generations and gn is generation number.(3)bw(gn)−bwmaxexp(c⋅gn),c=ln(bwmin/bwmax)NIwhere bw(gn) is bandwidth for each generation, bwminand bwmaxis minimum and maximum bandwidth respectively.Cuckoo Optimization Algorithm (COA), an optimization algorithm which is inspired by lifestyle of a bird called Cuckoo. Special characteristics of this bird in egg laying and breeding had been the basic motivation for development of this algorithm. Each individual in the algorithm has a habitat around which she starts to lay eggs [43]. Finding the optimal solution and fast convergence are some merits of COA.COA starts with an initial population of cuckoos. In COA, decision variables are formed as an array (1×Nvar), which is called habitat and show current living position of cuckoo. The initial population is a candidate habitat matrix of size Np×Nvarwhere Npis population size. This population laid their eggs in the nest of other kind of birds. Each cuckoo lays from 5 to 20 eggs in specified range, named ELR (egg laying radius) [43]. ELR is defined as follow:(4)ELR=∝×Numberofcurrentcuckoo'seggsTotalnumberofeggs×(varhi−varlow)∝ is an integer, supposed to handle the maximum value of ELR, the varhiand varloware variable limits. The eggs which have more similarities to the host birds’ eggs have a chance to survive and grow up. The density of the survived eggs in an area shows the suitability of that area. Cuckoo tends to area which is more suitable for laying eggs. Therefore the position with more survived eggs is the term that COA optimizes. The remained eggs hatch and turn into a mature cuckoo. The habitat of each newly grown cuckoo is evaluated. In the new population, the cuckoos who live in worst habitats should be killed to limit the population to the possible maximum number of cuckoos can live in environment. In the next step the cuckoos are clustered and the best group is selected as goal habitat. Then the new cuckoo population immigrates towards this best habitat. Each cuckoo flies λ of all the way to the best habitat and also has deviation of φ radians. Then, this new cuckoo population starts to lay eggs in some random nests inside its egg laying radius. This procedure is repeated until the stopping criteria are satisfied [43].Asexual Reproduction Optimization (ARO) is an effective optimization technique inspired from budding method of asexual reproduction, known as a remarkable biological phenomenon, which proposed in [44,45]. In this method, each individual is indicated by a binary string, similar to the binary representation in evolutionary techniques. A decision variable vector, X=(x1, x2, …xn); →X∈Rn, is called an individual in ARO, and each variable is considered as the chromosome made by a number of bits, called genes. Therefore, a chromosome with a length of L, is considered such that the first bit represents the sign of the individual. The next L bits show the integer part while the last L2 bits present the decimal part of the chromosome. As a result L=L1+L2+1 and the length of an individual becomes Li=n×L. Fig. 1shows the ARO chromosome.In ARO supposed that each solution in the search space (S) is an organism in its environment. Also, it is supposed that there are limited resources in the environment such that only the most deserving individual can survive. To start the algorithm, an individual is randomly initiated in the distinctive domain of S, and then the individual reproduces an offspring labelled bud by a particular operator called reproduction mechanism. The parent and its offspring compete to survive according to a performance index or a fitness function. If the bud wins the competition, its parent will be discarded. Therefore, the bud is replaced with its parent and it becomes the new parent. If the parent triumphs then, the bud will be thrown away. The algorithm repeats as indicated in Table 1, until the stopping criteria are satisfied. In order to reproduce, a copy of parent named larva is produced. Then a substring with g bits g∼Uniform[1, Li] in larva is randomly chosen. Then bits of the substring mutate such that in any selected gene, 1 is replaced by 0 and vice versa.After that, for each bit of substring which randomly selected from larva, a random number distributed in [0, 1] is generated. If this number is less than 0.5, the bit will be selected from the parents; otherwise it will be selected from larva, until bud is completed (see Fig. 2). Loosely speaking, merging is performed. The number of bits going to be altered, g, is a random number. When g is large, more exploration is expected and vice versa, while the exploitation applied is done based on the aforementioned procedure; this means that the amount of exploration is merely controlled by g; As a result, bud is generated similar to its biological model. On the other hand, during mutation, crossover is implicitly occurred. Finally, the bud fitness is evaluated and compared with its parent fitness. At last, the most merited is capable of subsisting to reproduce [44,45]. ARO has a number advantage over the other algorithms.As mentioned in this section, ARO is an individual-based algorithm, in contrast with the population-based algorithms which taking a lot of energy to evolve, ARO uses a little energy that leads to fast convergence time and make it suitable for real time applications. Adding on, due to deficiencies of optimum parameters setting some algorithms like Simulated Annealing, are difficult to execute. In some studies ARO is compared with other popular optimization algorithms such as genetic algorithm and particle swarm optimization and the results have shown that ARO, have a remarkable performance and fast convergence with respect the other optimization algorithms [44,45]. In addition, ARO is a model free algorithm, which can be suitable applied to different optimization problems.In this study, a differential wheeled mobile robot is assumed. The nonholonomic constraint for a two-wheeled differentially driven nonholonomic mobile robot with coordinates X, Y and heading angle θ can be written as:(5)X˙sinθ−Y˙cosθ=0(6)X˙=Vx,Y˙−Vy→VxVy=tanθω=θ˙(7)V=Vx2+Vy2where Vxand Vy, represents the robot's velocity in direction of x-axis and y-axis respectively. V and ω, represents the robot's linear and angular velocity respectively. The dynamic of the robot and the cost function which is used to avoid the obstacle is defined. A continuous time model for a robot can be defined as a second orders differential equation:(8)x˙_=v_v˙=u_wherex_is the position of the robot,v_is the velocity of the robot andu_is the control action. The goal here is to find the control action. The control action determines the robot velocity, in which the specified target is reachable in presence of obstacles. Therefore the cost function is defined as:(9)JL=||uL2_||+||X_t−X_L||2−e−||X_t−X_L||×∑j=1M1||X_L−X_obsj||−1rj2whereX_tis the position of the target,X_Lis the position of the robot,X_Obsjis the position of the jth obstacle, rjis the radius of the jth obstacle, M is the total number of the obstacles andu_Lis the leader robot control action. The obstacle is represented by circle in the plane and cylinder in the space.Then, in order to employ the potential field approach, the obstacle position should be taken into account in cost function. For solving such a problem, the control action is defined as:(10)uL=αL(X_t−X_L)+pLv_L||X_obsj−X_L||>rj,j=1,2,…,MαL(X_t−X_L)+pLv_L+∑j∈obsLhLjX_obsj−X_L||X_obsj−X_L||2o.w.whereobsL={j||X_obsj−X_L||≤rj,1≤j≤M},v_Lis the velocity of the robot, PL, hLj<0 and αL>0 are constant values. Obviously, it shows that the control action decreases as it comes nearer to the target. ThepLv_Lterm prevents the robot from oscillation around the target. It actually acts like a damper.ThehLj((X_obsj−X_L)/(||X_obsj−X_L||2))term shows how the control action forces the robot to avoid the obstacle.The cost function is optimized by using the ARO, SA, IHS, COA methods which were explained in previous sections and the simulation results are bring in next sections. For optimizing the cost functions in every time steps, we assume that the next place of the robot is:Xl_asmd=X_l+ρsinγ_in whichρ<vmax×Tis a constant value for increasing the precision of the control action and avoiding robots oscillation. vmaxis the robot's maximum linear speed and T is the time step.After optimizing the cost function by ARO methods,γ_is selected in order to find the suitableXl_asmd.Xl_asmdis used just for calculating the control action and it is not the definite position of leader. After obtainingXl_asmd, by calculating the control action, the nonholonomic robot's linear speeds and angular velocities are determined by (6) and (7) equations.Then the robot moves with these linear speed and angular velocity during the time step. Since each robot has limited linear speed and angular velocity, the calculated velocities should be limited to[0,vmax]andωmin,ωmaxrespectively. When one of them exceeds its limit, it is set equal to that limit value. The algorithm continues until the robot reaches the target. This control design procedure for path planning can be summarized in the following steps:Step1. Considering the assumed position for leader robot;Xl_asmd=X_l+ρsinγ_.Step2. Optimizing the cost function and obtainingγ_.Step3. Calculating the control action.Step4. Calculating the robot's linear speed and angular velocity.Step5. Limiting the linear speed and angular velocity to,[0,vmax]andωmin,ωmaxrespectively.Step6. Updating the robot's linear speed and angular velocity.In a leader–follower structure, an agent must be selected as a leader and N other agents as followers. The leader moves along a trajectory and the follower robots must follow the leader in specific distance and heading angle so that the structural formation can be kept fixed. The follower and leader robots must have the similar heading angles to each other. As shown in Fig. 3, the follower's desired positions and heading angles are:xf→xfdyf→yfdθf→θ1In this study, the follower robots are not aware of the leader's velocity. According to the explanation of the leader–follower structure, the cost function of the leader can be defined similar to Eq. (9), because there is no feedback from the followers to the leader. Hence, the leader's path can be optimized exactly as done in the previous section.(11)JFi=||uFi2_||+||X_Li−X_Fi−D_i||2−e−||X_Li−X_Fi−Di||×∑j=1M1||X_Fi−X_obsj||−1rj2whereX_Fiandu_Fiis the position and control action of the ith follower robot respectively. For the follower, the important task is to preserve the formation. The control action of the follower is then proposed as:(12)uFi=αFi(X_L−X_Fi−D_i)+pFiv1_Fi||X_obsj−X_FI||>rj,j=1,2,…,MαFi(X_L−X_Fi−D_i)+pFiv1_Fi+∑j∈obsihFijX_obsj−X_Fi||X_obsj−X_Fi||2o.w.whereobsi={j||X_obsj−X_Fi||≤rj,1≤j≤M}andv_Fiis the velocity of the ith follower robot. The PFi, kij<0 and αFi>0 are constant values. In order to fix the distance and direction between the leader and ith follower, a vector, namedD_iis added. When a minimal allowed distance between followers (LF) is violated, and collision danger appears,||X_Fk−X_Fi||≤LF, then, the control action of the follower is proposed as the following:(13)ufi=αFi(X_L−X_Fi−D_i)+pFiv1_fi+∑k∈colliqikX_Fk−X_Fi||X_Fk−X_Fi||2||X_obsj−X_FI||>rij,i=1,2,…,MαFi(X_L−X_Fi−D_i)+pFiv1_fi+∑j∈obsihFijX_obs−X_Fi||X_obsj−X_Fi||2+∑k∈colliqikX_Fk−X_Fi||X_Fk−X_Fi||2o.w.wherecolli{k||X_Fk−X_Fi||≤LF,1≤k≤N,k≠i}and The qik<0 is constant value. Theqik((X_Fk−X_Fi)/(||X_Fk−X_Fi||2))shows that how the control action avoids the robots collision. Now cost function is optimized by using the Asexual Reproduction Optimization (ARO), Simulated Annealing (SA), Improved Harmony Search and Cuckoo Optimization Algorithms like the previous section. After calculating the control action, the robot's linear speed and angular velocity are achieved (V1fi, ω1fi). Suppose that the follower robots move with these linear speeds and angular velocity (with specific line spacing), the robots assumptive heading angle is then calculated (θ1fi).Finding an angular velocity ω2fifor followers is required in order to have the same real heading angle in relation to leader robot.The cost function is determined afterwards, in order to determine the optimal angle:(14)Jθi=||uθi||2+(θ1fi−θL)2where θ1fiand θ1 are the follower robot and the leader robot's heading angles regarding to the horizon axis respectively. uθiis the control action for controlling the follower robot's heading angle which proposed as:(15)uθi=αθi(θL+θ1fi)+Pθiω2fiwhere αθi>0 and Pθi<0 are constant values. The Pθiωfiterm prevents the robot oscillation. The cost function is optimized by using the ARO, IHS, COA and SA methods. The results are compared in the next experiment section. After obtaining the control action the desired robot's angular velocity ω2fiis calculated. Here we assumed that: V2fi=0. In order to achieve the follower robot's final linear speed and angular velocity, the previous linear speeds and angular velocities ((V1fi, ω1fi) and (V2fi, ω2fi)) are weighted as following:(16)ωf=β1ω1fi+β2ω2fiβ1+β2(17)Vf=β1V1fi+β2V2fiβ1+β2=β1V1fiβ1+β2where β1 and β2 are weighting factors. For obtaining the best weighting factors, which can minimize both distance and heading angle errors, the cost function is defined as below:(18)Jw=||X_L−(X_Fi+T(β1v1_fi/(β1+β2))−Di_||||X_L−X_Fi−Di_||+(θ1−(θFi+T((β1ω1fi+β2ω2fi)/(β1+β2)))θ1−θfiwhere T, is the time step. The following cost function is normalized error with respect to position and heading angle of follower robots in the next time step. Then, the Jw, β1 and β2 are found. So, taking advantage of (16) and (17) equations the follower robot's angular velocity and linear speed are obtained.Since each robot has limited linear speed and angular velocity, the calculated velocities should be limited to[0,vmax]andωmin,ωmaxrespectively. When one of them exceeds the limit, then it is set equal to that limit value. In our work, finding a shortest path has priority over formation.Therefore, the formation may not occur near an obstacle, because a shortest obstacle-avoiding path is preferred here. However, the follower robots try to have the minimum distance and heading angle error while avoiding the obstacles. Fig. 4explains more about our proposed algorithm.This control design procedure for robot formation can be summarized in the following steps:Step 1. Considering the assumed position for follower robot;Xl_Fiasmd=X_Fi+ρsinγ_.Step 2. Optimizing the Jfiand obtainingγ_.Step 3. Calculating the control action.Step 4. Calculating the linear speed and angular velocity (V1fi, ω1fi).Step 5. Supposing that the follower robot moves with these linear speed and angular velocity at this time step and calculating the assumptive heading angle θ1fi.Step 6. Optimizing the Jθiand finding an angular velocity (ω2fi) for follower robots in order to have a same heading angle with the leader.Step 7. Optimizing the Jwand finding optimal weighting factors (β1 and β2).Step 8. Calculating the follower robots’ linear speed and angular velocity by weighting (V1fi, ω1fi) and (V2fi, ω2fi).Step 9. Limiting the linear speed and angular velocity to,[0,vmax]andωmin,ωmaxrespectively.Step 10. Updating the robot's linear speed and angular velocity.In this section, we present simulation results in MATLAB and Webots platform to support our claim about the effectiveness of the proposed controller based on ARO algorithm. In this order we have reported simulation results in MATLAB and Webots for Simulated Annealing, Improved Harmony Search and Cuckoo Optimization Algorithm methods too, to have a better comparison.Also we design the experiments for four e-Puck robots formation control, and the results bring in this section.In simulation experiments (MATLAB and Webots software), one of the obstacles is placed near the target to show that the follower robots can keep the formation near the target in the presence of obstacle. Also, two obstacles are placed close each other, to support that the robots can find a way to avoid obstacles without oscillations.MATLAB: Fig. 5 shows robots’ trajectories, obstacles and target's positions. As shown in Fig. 5, a target is placed in (11, 11) and four obstacles are placed in (0.75, 2.5), (3, 5.6), (5, 4.8) and (11, 9.2), with the radius of 0.5, 0.4, 1.1 and 0.4 respectively. We assumed a margin around the obstacles circle in the plane for some security reasons too. The leader robot reaches a random placed target-zone and stays there.Fig. 6shows the distance errors which are defined as: Distance Error=XL−XF=D=||XL−XF=D|| and the heading angle errors between the leader and followers (heading angle error=θL−θF).The optimization algorithm shows a good performance, and the leader robot moves along the path while avoiding the obstacle and the follower robot moves to its waypoint to make a formation. The numerical information used in simulation, is tabulated in Table 2.As shown in Fig. 5when the leader is in position A, it encounters with an obstacle. In this case the follower robots try to make the formation until they are not close to obstacles. If the followers encounter with an obstacle, the formation may not occurs in order to avoid obstacle and consequently the distance and heading angle errors are increased. When the leader passes the obstacle (position B) and moves towards the target. In this case some of followers are close to obstacles (follower1 and follower2), so the formation does not occur until they pass the obstacle.Webots: The e-Puck is a small-sized differential drive robot which is very suitable for multi agent experimentation. The e-Pucks are integrated in the Webots simulation software for easy programming, simulation and remote control of real robots. The maximum speed of e-Puck's wheel is 2π rad/s.(19)v=vleft+vright2=r2(ωright+ωleft)(20)ω=vleft−vrightL=rL(ωright−ωleft)which v and ω indicate robot's linear speed and angular velocity respectively, vleft,rightand ωleft,rightare linear speed and angular velocity of robot's wheels respectively, r=2.05cm is wheel's radius and L=5.3cm is the distance between the left and right wheels. Therefore ωmax=4.86rad/s and vmax=12.88cm/s. The calculated linear speed and angular velocity should be in specified ranges [0 12.88] and [−4.86 4.86], respectively.By considering the linear speed and angular velocity of leader and follower robots Eqs. (14) and (15), robots’ wheels speed are calculated. If one of them exceeded a limit, it was set equal to that limited value. The robot's wheel speed should be in [−2πrad/s 2πrad/s]. We assigned leader'sωmax,vmax=1/2follower'sωmax,vmaxin order to make the formation possible. Here the time step is 64ms, which means the robots’ speed are updated every 64ms. Fig. 7shows the simulation environment in Webots and Fig. 8 shows the robots’ trajectory, obstacles and target's position.As shown in Fig. 8when the leader is in position A, it encounter with an obstacle. In this case the followers try to make the formation until they are not close to obstacles. If the followers encounter with an obstacle the formation may not occurs in order to avoid obstacle and consequently the distances and heading angle errors increase.Fig. 9shows the distance errors and robots’ heading angle errors. When the leader passes the obstacle (position B), moves towards the target. In this case some of followers are close to obstacles (follower1 and follower2), so the formation does not occur until they pass the obstacle.Fig. 10shows the leader robot and the follower robots’ linear and angular velocities. As illustrated in this figure, leader robot moves with maximum linear speed. Passing through an obstacle is accompanied by a change in leader robot's speed and fluctuation of the waves, and after that the robot's speed returned to its maximum speed.The leader robot's speed is dramatically reduced, when it is close to the target. Similarly, the leader robot angular velocity has maximum changes when it reaches near the obstacle. The follower robots move with maximum linear speed in order to decrease the distance from leader and make the formation. Then in order to keep the formation and avoid the obstacles their speeds are adjusted.The leader's maximum linear speed and angular velocity are 6.35cm/s and 2.35rad/s, respectively. The follower's maximum linear speed and angular velocity are 12.7cm/s and 4.7rad/s, respectively. Other numerical information used in this simulation is addressed in Table 3. The robots stop when they reach the target.In this experiment, we demonstrated that the simulation results are experimentally validated on two mobile robot platforms. We used two mobile robot e-Pucks, in this experiment.Fig. 11shows an e-Puck robot, which is about 7cm, differential wheeled robot. An overhead camera is used for robots localization in QT (a cross platform application framework). UDP communication between QT and MATLAB is used to send the robots’ position to MATLAB with the mean value of 0.095s. After performing formation algorithm, the follower robot's speed is sent to robot by means of bluetooth connection with the mean value of 0.086s.This process takes 0.223s on the average, therefore the time step is considered 0.223s. In this experiment the robots formation is considered. The leader robots moved with a constant velocity (3.6cm/s, −0.05rad/s).The velocity limits in simulation by Webots are considered here too. This figure also shows both the e-Puck robots at the initial position and after making the formation.ARO: Fig. 12shows the robots trajectory, distance error (||XL−XF−D||) and the heading angle error between leader and follower (θl−θf). This figure also shows the follower robot's linear and angular velocity. Table 4is listed the numerical information used in this real experiment.In this experiment we would like to compare our results which are simulated in MATLAB and Webots by various optimization methods, Simulated Annealing (SA), Improved Harmony Search (IHS) and Cuckoo Optimization Algorithm (COA) and proposed method Asexual Reproduction Optimization (ARO).ARO had performed better performance, especially near the obstacles. Due to the lack of optimum parameters setting, the SA and COA methods might get in trouble.In contrast, ARO does not require any parameter tuning. The main disadvantage of SA and COA methods, is that there is not a rigorous theoretical foundation for determining the parameters. Selection of these parameters is problem dependent and the designer needs to do some experimental studies in order to determine proper values which will provide a good optimization in a reasonable amount of computational time.This experimentation can absorb a large amount of time especially when the algorithm is being applied to a new type of design. Despite this difficulty in all of the experiments the required parameters for optimization algorithms (SA, COA and HIS methods) are chosen, so that the best results are obtained.MATLAB: In Fig. 13, the followers’ distance error for ARO, IHS, COA and SA methods of formation are shown. The heading angle errors of formation are almost similar to each other, so in this experiment the comparison has been done just on the distance errors.As it shown, the ARO has the best performance and can avoid obstacles, make formation and reach to goal with the least error. The SA method has the worst performance and as it shown in Fig. 13(d), the follower2 and follower3 have collided with obstacles.Webots: Due to the better performance of Improved Harmony Search (IHS) in comparison with Cuckoo Optimization Algorithm (COA) and Simulated Annealing (SA), in previous simulation results in Webots and MATLAB software, here just the comparison of ARO and IHS is presented.As shown in Fig. 14, the distance errors of formation are almost similar to each other, except the end of the path where an obstacle has been placed near the goal.Unlike the ARO, the IHS method could not keep the formation near that obstacle. Adding on, with the IHS based controller, robots oscillation and heading angle errors are more than ARO based controller. Also the leader and the followers heading angle are not similar to each other at the end of the path.Fig. 15illustrates the distance and heading angle errors in the real experiments which have done by ARO and SA based methods. In real experiment ARO presented better performance similar to the simulation results and the robots move smoothly. The formation in ARO has less error rate than SA, indicated that ARO has a better convergence rate to zero.

@&#CONCLUSIONS@&#
