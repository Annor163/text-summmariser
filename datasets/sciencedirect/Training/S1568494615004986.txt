@&#MAIN-TITLE@&#
ITGO: Invasive tumor growth optimization algorithm

@&#HIGHLIGHTS@&#
A new heuristic optimization algorithm inspired by tumor growth was proposed.A new mechanism and different search strategies was proposed.Proposed algorithm was compared with the well-known algorithms such as ABC, DE, PSO.

@&#KEYPHRASES@&#
Invasive tumor growth,Meta-heuristic algorithm,Levy flight,Swarm intelligence,Evolutionary computation,

@&#ABSTRACT@&#
This paper proposes a new optimization algorithm named ITGO (Invasive Tumor Growth Optimization) algorithm based on the principle of invasive tumor growth. The study of tumor growth mechanism shows that each cell of tumor strives for the nutrient in their microenvironment to grow and proliferate. In ITGO algorithm, tumor cells were divided into three categories: proliferative cells, quiescent cells and dying cells. The cell movement relies on the chemotaxis, random walk of motion and interaction with other cells in different categories. Invasive behaviors of proliferative cells and quiescent cells are simulated by levy flight and dying cells are simulated through interaction with proliferative cells and quiescent cells. In order to test the effectiveness of ITGO algorithm, 50 functions from CEC2005, CEC2008, CEC2010 and a support vector machine (SVM) parameter optimization problem were used to compare ITGO with other well-known heuristic optimization methods. Statistical analysis using Friedman test and Wilcoxon signed-rank statistical test with Bonferroni–Holm correction demonstrates that the ITGO algorithm is better in solving global optimization problems in comparison to the other meta-heuristic algorithms.

@&#INTRODUCTION@&#
We often encounter optimization problems in scientific and technological research and development. These problems can be considered as different problems: continuous or discrete; constrained and unconstrained; multimode and unimodal; and multi-objective and single objective. The meta-heuristic methods were widely used to solve these problems, and the essence is to design an algorithm to approximate and solve the optimization problems [1]. In the last three decades, a great interest has been devoted to meta-heuristics method. Metaheuristics method can be divided into three categories [2]: evolutionary computation (also called evolutionary algorithms), swarm intelligence algorithm and physical phenomena algorithms.Evolutionary computation (EC) is the general term for several optimization algorithms that are inspired by the Darwinian principles of nature's capability to evolve living beings well adapted to their environment. Some classical algorithms such as genetic algorithms [3], evolution strategies [4], evolutionary programming [5], and genetic programming [6] have been widely accepted and used in many research fields and applications. Although the technologies of these algorithms are different, they share a common ideology, which is to imitate the individual's evolution through mutation, selection, recombination operation, thus resulting in a better solution. There are some new evolutionary algorithms, including Estimation of Distribution Algorithms (EDA) [7], Differential Evolution (DE) [8–11], Simulated Annealing (SA) algorithm [12], Tabu search [13] and Variable Neighborhood Search (VNS) [14]. Coevolutionary Algorithms (CoEA) [15,16], and Cultural Algorithms (CA) [17]. Estimation of Distribution Algorithms, also referred to as Probabilistic Model-Building Genetic Algorithms (PMBGA), was introduced in the field of evolutionary computation, for the first time by Mühlenbein and Paaß. Differential Evolution (DE) algorithm is a very popular algorithm used to solve many continuous optimization problems. Coevolutionary Algorithm (CoEA) is another type of evolutionary algorithm; such algorithm mimics the intimate relationship between different species such as predators and prey, hosts and parasites, or insects and the flowers that they pollinate-influence each other's evolution. Inspired from the cultural evolution process in nature, Cultural Algorithms (CAs) are proposed. The term cultural evolution has been more recently used to refer to the idea that the processes producing cultural stability and change are analogous in important respects to those of biological evolution. CAs consist of three components: a population space; a belief space; the communications protocol [18,17].Swarm intelligence (SI) algorithm is a novel distributed model for solving optimization problems, which is inspired by the collective behavior of insects or animals. SI refers to one individual without intelligence, but the intelligent characteristics emerge through cooperation with each other. In intelligent system, the population is a set of individuals that are able to communicate with each other and the local environment, and a group of individuals distributed in search space should work in cooperation to solve problems. For swarm intelligence algorithms, individuals without centralized control are able to solve complex problems. In 1995, inspired by the behavior of birds, James Kennedy and Russell Eberhart put forward particle swarm optimization (PSO) [19–21] as a global optimization technique; M. Dorigo and her colleagues proposed ant colony optimization (ACO) [22,23] for the hard combinatorial optimization problems by mimicking the ants foraging behaviors. Inspired by the social foraging behavior of Escherichia coli bacteria, Passino introduced a bacterial foraging optimization algorithm (BFOA) in 2002 [24]. Studies on honey bees’ balance exploitation of known food sources and exploration for new and potentially better food sources in a dynamic environment, the bee colony optimization metaheuristic (BCO) [25] and artificial bee colony algorithm (ABC) [26,27] were proposed. Biogeography-based optimization algorithm (BBO), developed by Dan Simon in 2008, imitates the biological system under different environments, and balances the immigration and emigration of different species [28]; Cuckoo Search algorithm (CS) [29] proposed by Xin-she Yang et al. in 2009, was inspired by the cuckoo brood parasitism behavior; Bat algorithm (BA) [30] is an effective global optimization method, which was inspired by the characteristics of the bats which emit ultrasond. Glowworm swarm optimization (GSO) [31] was inspired by the behaviors of a group of firefly which exchanges information by fluorescence. Teaching-learning-based optimization (TLBO) was proposed based on the effect of a teaching on the score of learners in a class [32]; Gray wolf optimizer (GWO) was proposed based on the behavior of capturing prey of the gray wolf swarm [2].The third main branch of meta-heuristics is the physical phenomena algorithms. Such optimization algorithms typically mimic physical rules due to some physical phenomena. The mechanism of these algorithms is different from EAs or SIs, in which a random set of search agents move and communicate throughout search space according to physical rules. This movement is implemented, for instance, using gravitational force, weights, ray casting, inertia force, electromagnetic force, and so on. Some of the most popular algorithms are Gravitational Search Algorithm (GSA) [33,34], Gravitational Local Search (GLSA) [35], Black Hole (BH) algorithm [36], Big-Bang Big-Crunch (BBBC) [37], Central Force Optimization (CFO) [38], Charged System Search (CSS) [39], Curved Space Optimization (CSO) [40], Ray Optimization (RO) [41] algorithm, and Small-World Optimization Algorithm (SWOA) [42]; Galaxy-based Search Algorithm (GbSA) [43], and Quantum-behaved particle swarm optimization (QPSO) [44,45].Tree-seed algorithm (TSA) [46] can be seen as a tree growth model based on the relation between trees and their seeds. In this framework, seeds are produced by the trees and the best seed for a tree can substitute for this tree. In other words, the growth of a tree is based on the seeds produced by it. The most important point is the two update rules for the producing seeds for a tree. The first update rule is achieved by the interaction between the best tree location and the randomly selected tree location in population, which can be seen as an exploitation for the local search operation, and the second update rule is achieved by the interaction between the present tree location and the randomly selected tree location in population, which can be seen as an exploration for the global search operation. The search tendency (ST) parameter controls the selection of the two update rules, which finishes the balances between the exploration and the exploitation.Gray wolf optimizer (GWO) [2] mimics the leadership hierarchy and hunting mechanism of gray wolves in nature. Four types of gray wolves such as alpha (leader), beta (leader), delta (leader) and omega (commoner) are classified as two layers for simulating the leadership hierarchy; the four main steps of encircling prey, hunting prey, searching for prey and attacking prey are implemented for search in optimization problems. The update rule of encircling prey is achieved by the interaction between the gray wolf and prey, and the position of hunting prey is guided by the three best gray wolfs (alpha, beta and delta). The exploration and the exploitation are implemented by the searching and attacking operation.Artificial algae algorithm (AAA) [47] is inspired by the living behaviors of microalgae, photosynthetic species. Under sufficient nutrient conditions, the algal colony receives enough light, and it grows and reproduces itself. The algorithm is based on the main three operations: evolutionary process, adaptation process and the movement of microalgae. For the evolutionary process, in any randomly selected dimension, algal cell of the smallest algal colony (corresponding to the worst solution) dies and algal cell of the biggest colony (corresponding to the best solution) replicates itself, which can speed up the convergence. In adaptation process, each algal colony has a starvation value. When one algal colon (solution) has a big starvation value, it will be guided by the best algal colon (solution). In the movement of microalgae, a new mutation method can be seen in this step, which is called ‘Helical movement’. For each algal colony (solution), randomly choose the j algal colony (the better solution) from the population and three dimensions to update the old solution by the three different search direction, which is the key in this algorithm.Cuckoo Search algorithm (CS) [29] was inspired by the obligate brood parasitism of some cuckoo species by laying their eggs in the nests of other host birds (of other species). It can be seen as two main steps. In the first step, it can be seen as the search method of simplified particle swarm optimization. The moving direction of each particle was guided by the use of the global optimal solution. This solution like an attractive factor combined the current best individual with the global best particle. The second step uses the approximate differential evolution rules with a probability P. Select two different individuals randomly from the population to update the current individual, so as to get a better solution. It can enhance the global search ability of the algorithm.Gravitational Search Algorithm (GSA) [34] is driven by the simulation of a collection of masses which interact with each other based on the Newtonian gravity and laws of motion. The algorithm is a centralized control algorithm, without the need for the guiding by a global best individual. Each individual j in the population attracts the individual i, the attractive force is inversely proportional to the distance of two individuals, and proportional to the product of mass (fitness) of two individuals. Individual i was affected by all other individuals to search for appropriate best solutions. If individual j is near the individual i and the fitness value is better, so it is more important for the i individual. This is a good algorithm that not only considers the distance between individuals, but also considers the fitness value of two individuals.Teaching-Learning-Based Optimization (TLBO) [32] can be divided into Teaching Phase and Learner Phase. In the teaching stage, the best learner (solution) was recommended from the population as a teacher (best solution), calculates the average scores in a class (average position of the population), and a teacher improves the score of each learner (individual) according to the average scores in a class; in learner stage, for each learner Xiin the class, a new learner Xjwas chosen randomly from the class, and a forward direction or opposite direction of study was used to update the solution Xi.In fact, exploration is the process of visiting entirely new regions of a search space, whilst exploitation is the process of visiting those regions of a search space within the neighborhood of previously visited points. The success of meta-heuristic methods to solve optimization problems depends on the balance of exploration (diversification) and the exploitation (intensification) [48]. However, all metaheuristic algorithms employ both the exploration and exploitation aspects but they use different approaches and operators. In other words, all search algorithms have a common framework. So, the No Free Lunch (NFL) theorem [49] is worth mentioning here. This theorem has logically proved that there is no meta-heuristic best suited for solving all optimization problems. That is, a particular meta-heuristic may show very good results on a set of problems, but the same algorithm may shows poor performance on a different set of problems. Obviously, NFL makes this field of study highly active which results in enhancing current approaches and proposing new meta-heuristics every year. This also motivates our attempts to develop a new meta-heuristic inspired by the mechanism of invasive tumor growth.In this context, the first contribution of our work is a new framework for swarm intelligence algorithm. There are three populations with different levels according to their nutrient concentration (fitness), that is, proliferative cell population, quiescent cell population and dying cell population. The cells in the high level population can guide the cells in the low level population. The interactions between three populations accomplish the global search task. The second contribution is the five search strategies (five operations) corresponding to the different four roles of tumor cell. In this search mechanism, the proliferative cells search by a levy flight, which enhances the local search ability; the quiescent cells search by the proliferative cells and mutation, which can be seen as the balance between the global search and local search; the dying cells search by the proliferative cells and quiescent cells, which enhances the global search ability; the invasive cells search by the proliferative cells, which enhances the local search ability and speed up the convergence; all the cells in tumor can achieve the random walk, which enhances the local search ability. The five strategies simulate the growth mechanism of the tumor.In this paper, we proposed a new metaheuristic algorithm called invasive tumor growth optimization (ITGO). The rest of the paper was organized as follows. Section 2 introduces the mechanism of invasive tumor growth. Section 3 describes ITGO model and algorithm. Section 4 presents experimental simulations compared with well-known meta-heuristic algorithms, results, and analysis. Section 5 discusses the other parameters of ITGO algorithm. Finally, the work is concluded in Section 6.Tumor is an abnormal growth of tissue. Induced by the oncogenic disorder, abnormal proliferation of clonal cell clusters lead to formation of tumors, which cannot be controlled by the body's internal regulating mechanism [50,51]. From the point of view of the system science, the tumor can be regarded as a complex linear dynamic system that can self-organize. The tumor cells proliferate and invade into surrounding tissue as seen in Fig. 1[52]. They can also travel through lymphatic or blood vessel and infiltrate into the distal organs [53]. The growth of tumor is a complex process, influenced by the interactions between tumor cells and their microenvironment, including their surrounding cells, as well as the extracellular matrix (ECM), chemical signals, as well as metabolic substrates such as oxygen and glucose [53].In the early stage of tumor growth, tumor cells obtain nutrients through diffusion. Nutrient diffuses from nearby blood vessel to tumor, and establishes a gradient from outside to interior of tumors. Diffusion equations have been used to describe this process [54–56,52,57,58]. The distribution of nutrient concentration of tumor cells is shown in Fig. 2; we also use a diffusion equation for nutrient, n:(1)∂n∂t=Dn∇2n+σe−φc−λnwhere n, D, σ, φ, and λ are the nutrient concentration, diffusion coefficient, production, consumption, and natural decay rates of the nutrient, respectively. To survive and grow, a tumor cell consumes nutrients at a certain rate, if the nutrient concentration around it in the microenvironment is lower than the specified value, it will become a quiescent cell or dying cell or apoptosis (dead). The consumption of nutrient also reduces nutrient concentration [59]. Many cellular signaling pathways that regulate migration have been described in recent years. A cell has a persistent random walk of motion [57,58,60]. Cell migration can be driven by various factors such as the directed response to gradients in pressure and chemical substances (nutrient concentrations), etc.Therefore, it is generally assumed that tumor can be regarded as an isotropic sphere. A concentric spatial layered structure consists of an outer rim of proliferating cells, an intermediate layer of viable, but dormant, quiescent cells, and an inner necrotic core [57]. In the outer layer of tumor with relatively higher nutrient concentration, cells were called ‘proliferative cells’ (these cells move fast); in the middle layer of the tumor with medium nutrient concentrations, these cells were called ‘quiescent cells’ (they are not still, they move slowly); in the inside layer with lower nutrient concentrations, these cells were called dying cells (they move very slowly). Tindall and Please [58] proposed a tumor growth model which considers that the tumor has a chemotaxis phenomenon, that is to say, tumor cells will move in the direction toward the nutrient gradient. Dorie et al. [56] use experiments to explain that proliferative cells and quiescent cells move toward the outer layer of the tumor. Proliferative cells, quiescent cells and dying cells have different behaviors. Vitro experiments show that proliferative cells may turn into quiescent cells or dying cells, and quiescent cells may also turn into proliferative cells or dying cells according to the nutrient concentration in microenvironment [56,52]. Most studies on continuum mathematical models of avascular tumor growth accept the assumption that all cells within a tumor have a common velocity. Some studies supposed that the tumor is porous media and the velocity of the tumor can be expressed in terms of the pressure [61]. Pettet et al. [62] and Tindall et al. [58] have considered the possibility of different cell velocities due to chemotaxis, movement of cells along a chemical concentration gradient either toward or away from the chemical stimulus. For simplicity they assumed two types of cells, proliferating and necrotic. Moreover, Sherrat and Chaplain [60] have assumed that the cell movement is due to “contact inhibition of migration”. They have considered that the cells can be in three states: proliferation, quiescence and necrosis and the diffusion is taken into account. It is generally accepted that the invasive behavior of tumor is the outcome of many complex interactions occurring among the tumor cells, and between a tumor and its host microenvironment [53]. Tumor invasion itself is a complex multistep process involving homotype detachment, enzymatic matrix degradation, integrin-mediated heterotype adhesion, as well as active, directed and random motility [63]. Yang Jiao et al. [52] proposed an invasion of tumor growth model to simulate the behavior of tumor cell.Summarized from the mechanism of tumor growth, tumor cells have the following characteristics:(1)In order to survive and grow, tumor cells must get enough nutrients, and the tumor cells have invasive ability.Tumor cells will move toward the direction of higher nutrient concentrations.There is a complex interaction between tumor cells.They have a random walk of motivation.When nutrient concentration is lower than a certain value, the proliferative cells may turn into quiescent cells; when nutrient concentration is lower than the minimum value, the quiescent cells turn into dying cells, or even apoptosis.Nutrient concentration corresponds to different types of tumor cells.A cell may be one of the two classes of phenotypes: either invasive or non-invasive [52]. The invasive cells (it is a special cell with invasive behavior) live at the outer of tumor. The non-invasive cells remain in the primary tumor and can be proliferative, quiescent, dying, or necrotic cell (dead), depending on the nutrient supply they get. For avascular tumor growth, our focus here, the nutrients available to the tumor cells are essentially the nutrient concentrations that diffuse into the tumor through its surface. As the tumor grows, the amount of nutrient supply, which is proportional to the tumor, cannot meet the needs of all cells, leading to the development of necrotic, dying and quiescent regions.In order to solve the optimization problem, we propose an optimization model of invasive tumor growth. In this model, we assume that the tumor cells have the following characteristics:(1)Considering the invasion of tumor cells, tumor cells were divided into four layers: invasive cells, proliferative cells, quiescent cells, and dying cells.Tumor is a complex dynamic system; there are interactions between different cell layers. All the cells move toward the direction of high nutrient concentration.Invasive cells will guide the moving direction of proliferative cells.The proliferative cells have the intrusive behavior by mutation.Proliferative cells will guide the moving direction of quiescent cells; quiescent cells will have the interaction with neighbors.In dying cells region, nutrient concentration is low, so dying cells will move toward the direction of the proliferative cells and the quiescent cell.Dying cells would be death due to the low nutrient concentration.The state of invasive cells, proliferative cells, quiescent cells and dying cell varies with the nutrient concentration.If tumor cells cannot get sufficient nutrient in the chemotaxis function, cell will perform a random walk behavior.In our model, ‘nutrient’ corresponds to ‘fitness’ of heuristic algorithm, and ‘nutrient concentration’ corresponds to the ‘fitness value’. A tumor cell growth means the search of an agent (or particle). As shown in Fig. 2, the black area presents the necrotic cells (each cell is called ‘Ncell’) of tumor; in this region, cells have been death without adequate nutrient. The vertical line gray balls represent the dying cells (each cell is called ‘Dcell’), if they get enough nutrient, they will move and turn into quiescent cells or the proliferative cells; the horizontal line red balls present the quiescent cells (each cell is called ‘Qcell’), which is located in the middle layer of tumor, in this region, nutrient concentration is at the medium level, and these cells will move toward the direction of proliferative cells (each cell is called ‘Pcell’). At the same time, quiescent cells have interaction among themselves. The grid line blue and oblique line green ball are located in the outermost layer of tumor; they represent the proliferative cell and invasive cells (each cell is called ‘Icell’); in the outermost layer, they can obtain highest nutrient and they are active. Fig. 2 shows the diffusion of nutrient in tumor corresponding to the tumor growth of each cell. ‘I, P, Q, D, N’ in Fig. 2 present the different nutrient concentration region corresponding to the ‘Icell’ (invasive cell), ‘Pcell (proliferative cell)’, ‘Qcell’ (quiescent cell), ‘Dcell’ (dying cell), ‘Ncell’ (necrotic cell), respectively. The deep and shallow color from outside to inside presents the different nutrient concentration for different cells in tumor.In the process of tumor growth, each cell wants to get enough nutrients to facilitate its growth. In order to survive and grow, each cell moves with a variety of ways to get the most nutrients (fitness). In our model, the cells of tumor were divided into four levels according to the nutrient concentration from high to low: Proliferative cells (Pcell), Quiescent cells (Qcell), Dying cells (Dcell) and Invasive cells (Icell). In order to grow, different cells have different behaviors and interactions. The detail is described as following.The proliferative cells must have adequate nutrient to grow. Study on the mechanism of tumor growth indicates that nutrient is conveyed to each cell of tumor by diffusion, just like the ‘heat conduction’. The nutrient spreads from the outer layer to the inner layer of the tumor. The proliferative cells were located in the outermost layer of a tumor; therefore, cells in this layer can easily obtain sufficient nutrients, they are more active and they grow fast. These cells grow by a special way and have a strong invasive ability. In order to reflect the intrusive behavior of proliferative cells, we use the levy flight [64,65] to simulate it. In fact, many natural phenomena exhibit the features of Levy flight, such as the flying of albatross, the flying of Drosophila and the feeding way of other animals, even the hunting mode of human is a Levy flight. Some physical phenomena also exhibit these characteristics of Levy flight, such as fluorescent particle diffusion, noise, etc. The intrusive behavior of proliferative cells can also be viewed as a Levy flight.(2)Pcelli,j(t+1)=Pcelli,j(t)+α⋅Levy(s)Pcelli,jpresents the position of proliferative cell,Levy(s)presents the intrusive behavior of the proliferative cell. We can see that, it moves occasionally short distance or long distance; α is the control size of step.(3)α=rand⋅FesMax_feswhere Fes is the current number of fitness evaluation consumed, and Max_fes is the max number of fitness evaluations consumed.Researches of tumor mechanism show that, in early stage of tumor growth, tumor cells grow in a linear velocity, and in the late stage, the bulk of quiescent cells and dying cells almost no longer move or move slowly, only the proliferative cells grow fast in a special way. Formula (3) shows that, α control the size of the moving step of each proliferative cell, in the early stage, proliferative cells moves not very fast; but in the late stage, proliferative cell moves more long distance according to the step ofLevy(s)and α. It conforms to the mechanism of tumor growth.Levy distribution usually appears in a simplified form, as follows:(4)Levy(s)∼s−1−ω,(0<ω≤2)Broadly speaking, Levy flight is a random walk and the step size obeys Levy distributions, and walk direction obeys uniform distribution. To perform the Levy distributions, we use the Levy distribution characterized with Mantegna law [64,65] to select the step length vector. In Mantegna law, the step size is designed as follows:(5)step=u|v|1/ωwhere u, v obeys normal distribution, i.e.,(6)u∼N(0,σu2),v∼N(0,σv2)(7)σv=Γ(1+ω)sin(πω/2)Γ(1+ω)/2ω2(ω−1)/21/ω(8)σu=1ω is a constant, where ω∈[0.3, 1.99] according to the literary [65,66].Quiescent cells are located in the middle layer of the tumor. According to the nutrient diffusion mechanism of the tumor, we can see that these cells can obtain nutrient only at a moderate level of nutrient concentration. Because the nutrient is not enough, the quiescent cell grows relatively slowly. In order to grow, these cells mainly move through interaction with proliferative cells and themselves to get more nutrients. Due to insufficient nutrient concentration, these cells have the intrusive behavior by mutation.The Quiescent cells move toward the higher nutrient concentrations, which is guided by proliferative cells and they interact with each other.(9)sQcelli,j(t+1)=Qcelli,j(t)+β⋅step⋅(hPcellp,j(t)−Qcelli,j(t))+β⋅step⋅((Qcellx,j(t)−Qcelly,j(t))),rand<0.5Qcelli,j(t)+β⋅step⋅(cPcellp,j(t)−Qcelli,j(t))+β⋅step⋅((Qcellx,j(t)−Qcelly,j(t))),rand>0.5(10)Qcelli,j(t+1)=Qcelli,j(t),rand<eFesMax_fes−1sQcelli,j(t+1),else(11)β=rand(0,1)⋅normal(0,1)Here, hPcellp,j(t) is the historical best position of proliferative cell, cPcellp,j(t) is the current position of proliferative cell. Qcelli,j(t) is the old position of quiescent cell and sQcelli,j(t+1) is the current position of quiescent cell. The step presents the step size of Levy flight such as formula (5); β presents the control size of step, rand(0, 1) means the random distribution, normal(0, 1) means the normal distribution as formula (11); p is integer, which indicates a proliferative cell chosen randomly from the subpopulation of proliferative cell; x, y are integers (x≠y), which indicate two quiescent cells near the i quiescent cell. Formula (10) presents the mutation of Quiescent cell.The dying cells are located in the third layer of the tumor. They can only obtain the rare nutrient with lower nutrient concentration, are not dead, but still alive and grow. In order to survive, these cells mainly get more nutrients through interaction with proliferative cells and quiescent cells. Because the living environment is not good (rare nutrient), some cells in this layer will die, and a few cells grow through interaction, are lucky to survive and may even turn into the quiescent cell or proliferative cell.In dying cells region, nutrient concentration is very low, so these cells move toward the direction of quiescent cells and proliferative cells with a higher nutrient concentration.(12)Dcelli,j(t+1)=Dcelli,j(t)+γ⋅(cPcellp,j(t)−Dcelli,j(t))+γ⋅((Qcellx,j(t)−Dcelli,j(t)))Dcelli,j(t) indicates the position of the old dying cell, Dcelli,j(t+1) indicates the position of the current dying cell, Qcellx,j(t) indicates the position of quiescent cell, cPcellp,j(t) indicates the position of proliferative cell (the current best position), p is integer, which indicates a proliferative cell chosen randomly from the subpopulation of proliferative cells; x is integer, which indicates a quiescent cell chosen randomly from the subpopulation of quiescent cells, where γ=rand[−1, 1]. Formula (12) shows that cPcellp,j(t) and Qcellx,j(t) guide Dcelli,j(t) to move for growth.The invasive cells are considered as mutant daughters of the proliferative cells [52], which can gain nutrient and motility that allow them to leave the outer layer of tumor and invade into surrounding microenvironment (other layer of the tumor). We consider that the invasive cells can move from the outer layer to the inner layer of tumor.In the dying cells region, if the nutrient concentration of dying cells was lower than the average nutrient concentration of dying cell subpopulation, the dying cell will be apoptosis (dead); when the proliferative cell has obtained enough nutrients and completed the growing behavior, cloning will happen, that is, a mutant daughter of it called invasive cell will be born. When dying cell is apoptosis, the invasive cell will replace it. Formula (13) presents a new cell which is born randomly in the tumor, Formula (14) shows that a mutant daughter of a current best proliferative cell is born, which is an invasive cell Icelli,j(t+1). Formula (15) shows that a dying cell is apoptosis and replaced by the invasive cell Icelli,j(t+1).(13)newCelli,j(t)=Random(i,D),D∈[Dmin,Dmax](14)Icelli,j(t+1)=cPcellp,j(t)+η⋅(newCelli,j(t)−cPcellp,j(t))(15)Dcelli,j(t+1)=Icelli,j(t+1)Here, η∈rand[0, 1] presents the growth speed, Random(i, D) produces a new solution randomly in the search space.Cell migration is most commonly and widely described as a persistent random walk motion [66,67]. All the cells in the tumor have the characteristics of random walk. When the proliferative cells, quiescent cells and dying cells are unable to get enough nutrients through the interaction or mutation, these cells grow with a random walk way to get the nutrients.Each cell in tumor has a cycle of life. When a cell is not affected by other chemotaxis within the specified cycle of life, the cell performs a random walk as formula (16). Here,newCelli,j(t)presents a new cell born using formula (13).(16)Celli,j(t+1)=Celli,j(t)+λ⋅newCelli,j(t)||newCelli,1:D(t)||where||newCelli,j:D(t)||is an Euclidean norm. λ∈rand[−1, 1].Based on the invasive tumor growth model, we design the invasive tumor growth optimization algorithm. The main function of our algorithm was shown in Algorithm 1 (ITGO()). In order to realize the invasive tumor growth optimization algorithm, six steps were adopted. In the first step, we set the size of the population (a population consists of many tumor cells), and max number of fitness evaluations consumed (Max_fes), etc. The second step sorts according to the nutrient concentration (fitness value) of each cell, the high nutrient concentrations of cells were identified as proliferative cells (Pcell, accounted for 20% of the total number of cells), the middle nutrient concentration of cells were identified as quiescent cells (Qcell, accounted for 60% the total number of cells), the low nutrient concentration of cells were identified as dying cells (Dcell, accounted for 20% the total number of cells). In order to grow, Pcell, Qcell and Dcell use a different way to get adequate nutrients. The third step implements the growth of proliferative cells (Pcell). Because the ‘Pcell’ has the highest nutrient concentration, it grows fast, and the detail of its growth is described by Algorithm 2 (ProliferativeCellGrowth()). The fourth step implements the growth of quiescent cell. As the nutrient concentration of these cells belongs to the middle level, most of them grow through interaction with proliferative cell and their neighbors to get nutrients, as seen in Algorithm 3 (QuiescentCellGrowth()). The fifth step implements the growth of dying cells. As nutrient concentration of these cells is very low, most of them run through interaction with proliferative cells and quiescent cells to get enough nutrients, as seen in Algorithm 4 (DyingCellGrowth()). The sixth step implements the growth of invasive cell. In this step, the invasive cell is born due to the mutation of proliferative cell; because the tumor in the space is limited, the new intrusive cell will replace the dying cell with too lower nutrient concentrations for survival, as described in Algorithm 5 (InvasiveCellGrowth()). In the process of tumor growth, all the cells will occasionally perform random walks, and this is the characteristic of tumor cell, as described in Algorithm 6 (RandomWalk()).Algorithm 1ITGO (Np, Psize, Qsize, Dsize, Gc, Max_fes, Fes, Err, Beta, Max_gc).Input:population size (Np), number of proliferative cells (Psize=20% Np), number of quiescent cells (Qsize=60% Np), number of dying cells (Dsize=20% Np), growth cycle of tumor cell (Gc), max number of fitness evaluations consumed (Max_fes), number of fitness evaluation consumed (Fes), stopping criteria (Err), Levy parameter (Beta), max number of growth cycle (Max_gc).Output:the global best cell in population.1.Fes=0;2.Generate an initial tumor cells population by uniformly and randomly sampling from the feasible solution space;3.Fes=Fes+Np;//compute the fitness evaluations4.While (Fes<Max_fes and absolute error >Err)5.Sort the tumor cells according to the fitness value of each cell in the population (ascending order);6.Choose Psize cells (20%) with the best fitness value in tumor cells as proliferative cells (PCells);7.Choose Qsize cells (60%) with the middle fitness value in tumor cells as quiescent cells (QCells);8.Choose Dsize cells (20%) with the low fitness value in tumor cells as dying cells (DCells);9.ProliferativeCellGrowth (Pcells, Psize, Gc, Fes, Beta, Max_Gc);10.QuiescentCellGrowth (Pcells, Psize, Qcells, Qsize, Gc, Fes, Beta, Max_Gc);11.DyingCellGrowth (Pcells, Psize, Qcell, Qsize, Dcells, Dsize, Gc, Fes, Max_Gc);12.InvasiveCellGrowth (Pcells, Psize, Dells, Dsize, Fes);13.Combine three subpopulations (PCells, QCells, DCells) as a new tumor cells population;14.End while15.Output the global best Cell in tumor cells population;In Algorithm 2 (ProliferativeCellGrowth()), the lines 2–6 present the possibility of proliferative cell growth.FesMax_fescan be seen as a liner function (Formula (3)). α is the control size of step, andLevy(λ)is the step length of Levy flight. As other meta-heuristic algorithms, at the late of the iteration, most individuals (cells) gather into a local optimum. So the proliferative cells growing with a greater probability ensure that the algorithm can jump out of the local optimal solution. As seen as the line 7–line 15, when the value of Gc (i) is greater than Max_gc (growth cycle threshold), the cell performs random walks. This means that when the proliferative cell cannot update the historical position (hPcell) for a long time, and it performs a random walk, so as to find the position with rich nutrient (fitness).Algorithm 2ProliferativeCellGrowth (Pcells, Psize, Gc, Fes, Beta, Beta, Max_Gc).Input:proliferative cells subpopulation (PCells), number of proliferative cells (Psize=20% Np), growth cycle of tumor cell (Gc), number of fitness evaluation consumed (Fes), Levy parameter (Beta), max number of growth cycle (Max_gc).Output:historical proliferative cells subpopulation (hPCells), current proliferative cells subpopulation (cPCells)1.fori=1: Psize//p is the number of Pcells2.forj=1: D//Dimension D3.now Pcell(i,j)=Pcells(i,j)+α⋅Levy(λ);//Formulae (3)–(8)4.end for5.Calculate the fitness evaluation of now Pcell(i);6.Fes=Fes+1;7.If now Pcell(i) has more Nutrient (best fitness value)8.cPcell(i)=now Pcell(i);9.else10.hPcell(i)=Pcell(i);11.Gc (i)=Gc (i)+1;12.end if13.IfGc (i)>Max_gc14.RandomWalk (cPcell(i), Gc(i));15.end if16.end for(2) For Algorithm 3 (QuiescentCellGrowth()) performs the growth process of quiescent cells. Codes represent the interaction between quiescent cells and other cells. Historical best position hPcell(p,j) and current best position cPcell(p,j) lead the quiescent cell to move alternately so that the quiescent cell can get adequate nutrients. Code lines 15–19 show the mutation of quiescent cell, and exp(Fes/Max_fes−1) is the rate of mutation.Algorithm 3QuiescentCellGrowth (Pcell, Psize, Qcells, Qsize, Gc, Fes, Beta, Max_Gc).Input:historical proliferative cells subpopulation (hPCells), current proliferative cells subpopulation (cPCells), quiescent cells subpopulation (QCells), number of proliferative cells (Psize=20% Np), number of quiescent cells (Qsize=60% Np), growth cycle of tumor cell (Gc), number of fitness evaluation consumed (Fes), Levy parameter (Beta), max number of growth cycle (Max_gc).Output:updated Qcells (array)1.fori=1:Qsize//Qsize is the number of Qcells2.Select the p cell randomly from PCells subpopulation as Pcells(p);3.Calculate the distance between all the Qcells (except Qcells(i)) and the Qcells(i) and sort;4.Choose two Qcells nearest to the Qcells(i) as Neighbors: Qcell(x), Qcell(y), x≠y;5.Using levy flight ‘step’ by beta;//Formulae (4)–(8)6.Calculates the control size of ‘step’ b;//Formula (11)7.forj=1:D8.If rand<=0.59.now Qcell(i,j)=Qcells(i,j)+b*step*(hPcells(p,j)−Qcells(i,j)) +b*step(Qcells(x,j)−Qcells(y,j);10.else11.now Qcell(i,j)=Qcells(i,j)+b*step*(cPcells(p,j)−Qcells(i,j))+b*step. (Qcells(x,j)−Qcells(y,j);12.end if13.//formulae (9) and (11)14.end for15.forj=1:D16.If rand<exp(Fes/Max_fes−1)//formula (10)17.now Qcell(i,j)=Qcells(i,j);18.end if19.end for20.Calculate the fitness evaluation of now Qcell(i);21.Fes=Fes+1;22.If now Qcell(i) has more Nutrient (Fitness value)23.Qcells(i)=now Pcell(i);24.else25.Gc(Psize+i)=Gc (Psize+i)+1;26.end if27.IfGc(Psize+i)>Max_gc28.RandomWalk(Qcells(i),Gc(Psize+i));29.end if30.end for(3) Algorithm 4 (DyingCellGrowth()) performs the process of dying cells. Lines 4–7 show that the position of dying cell was updated according to Formula (12), and a new proliferative cell and a new quiescent cell lead the dying cell to move for a better nutrient. In lines 10–17, the dying cell will run random walks like the proliferative cell or the quiescent cell.Algorithm 4DyingCellGrowth (Pcells, Psize, Qcells, Qsize, Dcells, Dsize, Gc, Fes, Max_Gc).Input:current proliferative cells subpopulation (cPCells), number of proliferative cells (Psize=20% Np), quiescent cells subpopulation (QCells), number of quiescent cells (Qsize=60% Np), Dying cells subpopulation (Dcells), number of dying cells (Dsize=20% Np), growth cycle of tumor cell (Gc), number of fitness evaluation consumed (Fes), max number of growth cycle (Max_gc).Output:updated DCells1.fori=1:Dsize%Dsize is the number of Dcells2.Select the u cell randomly from Pcells subpopulation as Pcells(u);3.Select the v cell randomly from Qcells subpopulation as Qcells(v);4.forj=1:D5.now Dcell(i,j)=Dcells(i,j)+y*(cPcells(u,j)−Dcells(i,j))+y (Qcells(v,j)−Dcells(i,j);6.//Formula (12)7.end for8.Calculate fitness evaluation of now Dcell(i);9.Fes=Fes+1;10.If now Ncell(i) has more Nutrient (better Fitness value)11.Dcell(i)=now Dcell(i);12.else13.Gc(Psize+Qsize+i)=Gc(Psize+Qsize+i)+1;14.end if15.IfGc(Psize+Qsize+i)>Max_gc16.Random Walk (Dcells(i), Gc(Psize+Qsize+i));17.end if18.end for(4) Algorithm 5 (InvasiveCellGrowth()) performs the growth process of the invasive cells. If the nutrient concentration of a dying cell is lower than the average nutrient concentrations of all the dying cells, a invasive cell ‘Icell(i,j)’ is born by the mutation of proliferative cell ‘cPcell(i,j)’, and the dying cell was replaced by the invasive cell.Algorithm 5InvasiveCellGrowth (Pcells, Psize, Dcells, Dsize, Fes).Input:current proliferative cells subpopulation (cPCells), number of proliferative cells (Psize=20% Np), Dying cells subpopulation (Dcells), number of dying cells (Dsize=20% Np), number of fitness evaluation consumed (Fes).Output:updated Dcells1.fori=1:Dsize//Dsize is the number of Dcells2.Select the u cell randomly from cPCells subpopulation as cPcell(u);3.Calculate average nutrient concentration (fitness value) of all cells in Dcells subpopulation as M;4.If the Nutrient concentration of Dcells(i) is not better than M;5.Now cell(i)=rand(1,D);//Formula (13)6.forj=1:D7.Icell(i,j)=cPcell(i,j)+rand*(Nowcell(1,j)-cPcell(i,j));//Formula (14)8.end for9.Calculate fitness evaluation of Icell(i);10.Fes=Fes+1;11.IfIcell (i) has more Nutrient (better fitness value)12.Dcell(i)=Icell(i);//Formula (15)13.end if14.end for(5) Algorithm 6 (RandomWalk()) performs the random walk of any tumor cell. When a tumor cell moves by a random walk, the growth cycle ‘Gc’ was set to zero. It means that the random walk will stop, and a normal moving will begin.Algorithm 6RandomWalk (cell, Gc, Fes).Input:any cell in the three tumor cells subpopulations, the growth cycle of one cell (Gc), number of fitness evaluation consumed (Fes)Output:cell, Gc1.Nowcell=rand(1,D);//Formula (13)2.newCell=cell+a*Nowcell/(Nowcell*Nowcell’);//Formula (16)3.Calculate fitness evaluation of newCell;4.Fes=Fes+1;5.If the Nutrient concentration of newCell is better than cell;6.cell=newCell;7.Gc=0;8.end ifIn order to explain the mechanism of ITGO algorithm, we discuss four aspects about our algorithm. Firstly, we discuss the feature of Levy flight. One dimension of the step size for a proliferative cell and a quiescent cell was test. This can help us to understand the mechanism of search by Levy flight. Secondly, we discuss the search trajectory of a proliferative cell, a quiescent cell and a dying cell. Here, we finished a simple experiment with Fun 4 in Table 1. This helps us to understand the search mechanism of our algorithm. Thirdly, we discuss the exploration and exploitation of the different search strategies for the different tumor cells. Fourth, we analyze the convergence of our algorithm.Levy flight is a Markov process, and walking step satisfies a heavy tailed (heavy-tailed) Levy distribution. In Levy flight, local search of short walking distance and occasionally global search of longer walking distance occurs, so some solutions in the near optimum value can search and enhance the local search ability. On the other hand, some solutions can obtain the global optimal value with far enough searching space, so as to ensure that the algorithm will not fall into a local optimum. As shown in Fig. 3, x coordinate is the numbers of fitness evaluations (FEs, 100,000), y coordinate is the search step value of one-dimensional Levy flight. It can be seen in Fig. 3 that Levy flight has a jumping search step length. Fig. 3(a) shows the search step of proliferative cell, when the iteration number (Fes numbers) increases, the control step size grows linearly (seen as Eq. (3)), so the Levy step size is gradually increased, which reflects the stronger invasive behavior of proliferative cells in the latter. We know that at the later search of our algorithm, all the solutions (the position of proliferative cells) are accumulated at the local optimum. To jump it out, Levy step size must be increased for the proliferative cell in a large search space. Fig. 3(b) shows the searching step of quiescent cells, using the control step size as formula (11); it can be seen that the control step size of quiescent cell is relatively steady. This conforms to the growth mechanism of invasive tumor growth in reality. In the whole search process of our algorithm, quiescent cells were guided by the proliferative cells, we use the same levy step size, that is to say, local search of short walking distance and occasionally global search of longer walking distance occurs in the whole search process for quiescent cells, which achieved the balance of local search and global search.Here, we present the evolution process of our algorithm. Fig. 4(a) is a shifted unimodal function with Noise. In 2-dimension space, ITGO algorithm was ran for 186 fitness evaluation numbers, which obtains the global optimum value −450, the global optimal solution is X=35.6267, y=−82.9124. As mentioned above, we know that the population was divided into the main three subpopulations: proliferative cell subpopulation, quiescent cell subpopulation and dying cell subpopulation. Different cell has different behavior corresponding to different search pattern. Fig. 4(b) presents the searching trajectory of a proliferative cell. All the positions of proliferative cells located in the better solution spaces (better solution set). So they can obtain better solution. The levy flight behaviors help them to jump out the local optimum easy. Fig. 4(c) presents the searching trajectory of a quiescent cell. All the positions of quiescent cells located in the general solution spaces (general solution set). These cells search in relatively wide solution space, and they can obtain better solution guided by the proliferative cell, which helps them obtain the global optimum solution. Fig. 4(d) presents the searching trajectory of a dying cell. All the positions of dying cells located in the large solution spaces (large solution set), because these cells have lower nutrient concentration (fitness value). The search in a large solution space increases the diversity of our algorithms. A dying cell obtains global optimal solution guided by a proliferative cell and a quiescent cell.To better explain our algorithm, we discuss more aspects about the exploration and exploitation. In the search process of the proliferative cell,Levy(s)presents the search in different regions and control size of step α achieves the balance of exploration and exploitation. In the early search stage, whenFesMax_fes≤0.5, α obtains a more small value, each proliferative cell visits those regions of a search space within the neighborhood of previously visited points, it can be seen as an exploitation, whilst in the late search stage, whenFesMax_fes>0.5, α perhaps obtains a more large value, each proliferative cell visits entirely new regions of a search space, it can be seen as an exploration. In the search process of quiescent cells, we consider the balance of exploration and exploitation too. As quiescent cell population is the main body of the tumor, many cells should search including exploration and exploitation. In formula (9), we can see that each quiescent cell is guided by the historical best position of proliferative cell hPcellp,j(t) and the current position of proliferative cell cPcellp,j(t) alternately, which means that, each quiescent cell searches in a large region to find a best position, and it can be seen as an exploration, whilst the two neighbor's operation ensures that the quiescent cell visits the neighbor regions, which can be seen as an exploitation. In the search process of the dying cells, formula (12) means that each dying cell is guided by the proliferative cell and the quiescent cell, and it can be seen as an exploration. Because each dying cell (each agent) visits new regions according the position of the proliferative cell and the quiescent cell. Two leaders (proliferative cell and the quiescent cell) were chosen in different populations randomly, which can enhance the diversity of our algorithm. In the search process of invasive cells, an exploration is achieved. Formulae (13) and (14) mean that an invasive cell visits a more larger search region nearby the proliferative cell. Especially, for the multimodal problems, in the late search process, many proliferative cells may obtain different local optimums. So the invasive cell ensures that they can jump out the local optimum, and find the best position, that is, they can enhance the exploration ability of our algorithm. Formula (15) means that some bad solution (dying cell) can be replaced by the best solution (invasive cell). In addition, the random walk can be seen as an exploitation.newCelli,j(t)||newCelli,1:D(t)||means a small value in the search region. So the random walk can be seen as a small fluctuation for all the tumor cells, that is, each tumor cell can visit its neighbor region. Due to this mechanism of exploration and exploitation, our algorithm has better search ability.Our proposed algorithm is a population-based optimization algorithm, in which the state of the tumor cell population will transfer to a new state with different probability, so we can use a Markov chain model [68] for the theoretical analysis. The mathematical description is as follows:Definition 1Each individual state is decided by the position of each tumor cell, that is, Xi=(xi1, xi2, …, xiD), D is the dimension.All the state of each individual constitutes the individual state space:X=X,X∈Ω,Ω is all the feasible solution set.Definition 2All the individual's present state constitutes the present tumor cell population state space, that is,y=X1,X2,…,Xi,…,XNP, NP is the population size.All the state of tumor cells population is described asY=y=X1,X2,…,Xi,…,XNP,Xi∈X,1≤i≤NP.Definition 3One step transition probability for individuals isOne step transition probability for tumor cell populations isProbability distribution is:P(TY(yi)=yj)=Πn=1NPP(Ty(Xin)=Xjn).Definition 5(Convergence in Probability [68,69])LetX(t),t=0,1,2,…be a population sequence generated by a population-based stochastic algorithm, the stochastic sequenceX(t)weakly converges in probability to the global optimum, if and only if:limt→∞PX(t)∩G*≠∅=1where G* is the set of the global optima of an optimization problem. That is, the algorithm holds with convergence in probability.According to the definitions above, we can discuss the convergence of our proposed algorithm. In the search space, each individual search in a finite dimension and each tumor cell population state space is composed of all the finite individuals. We can also see that one step transition probability of the tumor cell populations P(TY(yi)=yj) is dependent on the one step transition probability of all the individuals. In addition, one step transition probability of one individual P(Ty(Xi)=Xj) is only related to the Xiat the i time. We can infer that it is a finite homogeneous Markov chain model. Especially, the search steps of our proposed algorithm are dependent on the five operations for different tumor cell. All the search steps of our proposed algorithm cannot search the whole search space except the invasive cell and the random walk. Because new individuals can be generated in the global search space for the invasive cell growth and the random walk of the tumor cells, we can infer that our proposed algorithm can converge in probability to the global optimum, that is,limt→∞PX(t)∩G*≠∅=1. The proof of our proposed algorithm can be a new subject in future.In order to verify the performance of the proposed algorithm, we compare ITGO to the seven well-known algorithms (PSO, DE, ABC, BBO, GSA, CS and TLBO) and other improved algorithms (cPSO, QIGSA and rcGA). We choose the 25 Benchmark functions from CEC 2005 [70]. In these functions, F1–F5 are unimodal functions and F6–F25 are multimodal functions. Especially, F6–F12 are basic functions and F13–F25 are expanded functions. The global optimums of F7 and F25 functions are outside of the initialization range. To solve the large scale global optimization problem, we choose the five benchmark functions from CEC2008 [71] and 20 benchmark functions from CEC2010 [72]. In CEC 2008, F1 and F2 are unimodal functions. F3, F5, F6 are Multimodal Functions. Details are shown in Tables 1 and 2.In general, separable problems are considered to be easy, while the fully nonseparable ones usually are the most difficult problems. In between these two extreme cases, there are various kinds of partially separable problems. Matter of fact, real-world optimization problems will most likely consist of different groups of parameters with strong dependencies within but little interaction between the groups. In CEC2010, four types of high-dimensional problems were designed to reflect the real problem, that is: separable functions; partially separable functions, in which a small number of variables are dependent while all the remaining ones are independent; partially separable functions consist of multiple independent subcomponents, each of which is m-nonseparable; and fully nonseparable functions. F1–F3 are separable functions, F4–F18 are partially separable functions and F19–F20 are fully nonseparable functions. Details are shown in Table 2.For these algorithms, parameter settings are shown in Table 3.The tests of all algorithms are rooted on a uniform standard:(1)For CEC2005, dimension is 10, population size is 30, and MAX_FES (total fitness evaluations number)=1e5 [70].For CEC2008, dimension is 100, population size is 30, and MAX_FES=5e5 [71].For CEC2010, dimension is 1000, population size is 100, and MAX_FES=3e5 and 3e6 [72].For purposes of avoiding any negative effects of the structure of the initial population during the tests, the benchmark problems were solved 25 times by using a different initial population each time. If the absolute error obtained by the algorithm is smaller than err=1e−15 then stop. The data such as the global minimum value, maximum, mean, standard deviation and median obtained as a result of the tests have been saved for detailed statistical analysis. All the tests were implemented by using Matlab 7.8. Statistical analyses were realized by SPSS software.The Wilcoxon signed-rank test [82–84] and the Friedman's test [84] were used to compare ITGO with other algorithms. In the statistical tests conducted for this paper, Bonferroni–Holm correction method is based on the correction of p-value [84]. When using Wilcoxon's test in our experimental study, the first step is to compute the R+ and R− related to the comparisons between ITGO and the rest of algorithms. Let R+ be the sum of ranks for the problems in which the first algorithm outperformed the second, and R− the sum of ranks for the opposite. Once they have been obtained, their associated p-values can be computed. The null hypothesis H0 was used for the Wilcoxon Signed-Rank Tests for purposes of this paper. The statistical significance value used to test H0 hypothesis is τ=0.05. If in any test a p-value that is smaller than or equal to significance level τ value is produced, then the H0 hypothesis for that test is rejected and the alternative hypothesis is selected.In order to compare the performance of all the algorithms, Friedman's test was used. It is a multiple comparisons test that aims to detect significant differences between the behaviors of two or more algorithms. The first step in calculating the test statistic is to convert the original results to ranks. At the end, average ranks are used to comparison.The experiments were divided into four groups: (1) experiment on basic global optimization; (2) comparison with the improved other algorithms; (3) experiment on large scale global optimization compared with classical algorithms; (4) experiment on large scale global optimization compared with improved PSO. In experiments (1) and (2), we use the 25 benchmark functions from CEC 2005 and 5 benchmark functions from CEC 2008 to test for PSO, DE, BBO, GSA, TLBO, CLPSO, cPSO, QIGSA, rcGA and ITGO. In these benchmark functions, it maybe unimodal or Multimodal or Non-separable or separable or Shifted or Rotated, and it is not easy to obtain the global optimum of these functions, shown as Fig. 7. In experiment (3), in order to solve the Large Scale Global Optimization, we choose the 20 benchmark functions from CEC2010 to test the performance of CLPSO, DE, ABC, BBO, GSA, CS, TLBO and ITGO (MAX_FES=3e5), In these functions, it may be Separable or Partially separable or Fully nonseparable functions; In experiment (4), for the higher dimensional 20 benchmark functions, MAX_FES=3e6, we compare ITGO with the CLPSO, GOPSO [72], DNSCLPSO [72] and DNSPSO [72].Two parameters were used in ITGO, namely beta, and Max_gc. Nevertheless, a complete evaluation on all possible combinations of these parameters is impractical. The parameter tuning strategy, as reported in [85,86], is used to find an appropriate parameter combination of ITGO for the good performances. In order to find the better parameter setting, we choose the six problems with different characteristics, that is, one unimodal function (F2) and five multimodal functions (F9, F12, F16, F19 and F22). Especially, F9 is a shifted function, F16, F19 and F22 are rotated hybrid functions. Parameter beta ranges in [0.3,1.9] and MAX_gc ranges in dimension*[0.1,1.1] (dimension=10). We first initialize the parameter combination of [beta, MAX_gc] as the mean values of their respective lower and upper boundary values, i.e., [1.1, 0.6*10], beta and MAX_gc are integers. Based on this initial combination, we adjust the parameters one at a time. We first vary parameter beta from 0.3 to 1.9 with MAX_gc are being fixed. Then we choose the best beta value due to the best fitness evaluation value. In the next step, we fix the beta value and adjust MAX_gc from 1 to 11. ITGO algorithm with each different parameter setting is ran 20 times for the six functions. Mean fitness evaluation values are recorded in Tables 4 and 5. Figs. 5 and 6show the curve of mean fitness evaluation values for each function. Firstly, we discuss the influence of parameter Beta for the performance of ITGO. From Fig. 5 and Table 4, we can see that when Beta values are 1.6, 1.1, 1.9, 1.7, 0.4 and 1.1, F2, F9, F12, F16, F19 and F22 functions obtain the best fitness evaluation value. It means that for most problems (F2, F9, F16, F22), Beta value should be set as a middle value. For especial problem, Beta value can be set as a more big or small value (F19 and F12). In order to choose the best Beta parameter value, Frandman test is used here. The three columns of Table 4 show the mean rank value of Frandman test. The two columns of Table 4 show the order of ITGO for the different Beta values. Black font shows the best one. We can see that when Beta=1.1, the performance of ITGO is the best. Secondly, we discuss the influence of parameter Max_gc for the performance of ITGO. From Fig. 6 and Table 5, we can see that, when MAX_gc values are 3, 9, 1, 7, 3 and 5, F2, F9, F12, F16, F19 and F22 functions obtain the best fitness evaluation value. It means that MAX_gc should not be set as too large value (F2, F12, F16, F19 and F22) except F9. It can be explained according to the formula (16). We know that MAX_gc is the cycle of growth for each tumor cell and it is a disturbance for the tumor cells. If MAX_gc is set too large, the random walk operator is less to be used, and it is not good to help the ITGO leave from the local optimum. Then, we use the Frandman tests to choose the best MAX_gc value. From Table 5, we can see that, when MAX_gc=7, mean rank value is best and the order of ITGO is 1. At the end, the experimental findings suggest that we can set the parameter combination [beat, MAX_gc] as [1.1,0.7*10] in the performance evaluation.In this experiment, Table 6shows the minimum, maximum, means, standard deviation and the median of the fitness evaluation values after 25 times runs for PSO, DE/best/2/bin, BBO, GSA, TLBO, GWO and ITGO algorithms. The black font in Table 6 indicates the winner. In Table 7, we use the Wilcoxon signed-rank test by the means in Table 6 to compare the PSO, DE/best/2/bin, BBO, GSA, TLBO, GWO and ITGO algorithm. The comparison results among ITGO and PSO, DE/best/2/bin, BBO, GSA, TLBO, GWO algorithms are summarized as in the last two rows of Table 7, which means that ITGO wins inwfunctions, ties intfunctions and loses in l functions, compared with its competitors. ‘ITGO’ shown in Table 7 means that ITGO is the winner and blank in grid unit of Table 7 means that ITGO is the loser. The ‘ITGO’ with black font shows the comparison results of ITGO and PSO, DE/best/2/bin, BBO, GSA, TLBO, GWO algorithms with the means. The statistical results show that the performance of the ITGO algorithm outperforms other algorithms.In Table 8, we use the Wilcoxon Signed-Rank Test and Bonferroni–Holm correction method to compare ITGO with PSO, DE/best/2/bin, BBO, GSA, TLBO and GWO. The Bonferroni–Holm procedure adjusts the value of α in a step-down manner. Let p1, p2, …, pk−1 be the ordered p-values (from smallest to largest), so that p1≤p2≤, …, ≤pk−1, and let H1, H2, …, Hk−1 be the corresponding hypotheses. The Bonferroni–Holm procedure rejects H1 to Hi−1 if i is the smallest integer such that pi>α/(k−1). In Tables 9 and 10, we use the Friedman's test. In order to achieve better comparison, the means data set was selected from Table 6 to be analyzed by Wilcoxon Signed-Rank Test, Friedman's test and Bonferroni–Holm correction method. As for the Wilcoxon Signed-Rank Test and Bonferroni–Holm correction method, the comparison results show that the null hypothesis was rejected, that is to say, the alternative hypothesis was accepted and the performance of ITGO is better than the others. As for the Friedman's test, the average ranks show that ITGO is better than the others.Fig. 7is the convergence curves of the 7 algorithms for the 10 benchmark functions. These 10 functions are multimodal functions. Especially, F13, F15, F18, F19, F20, F22, F23, F24 and F25 are expanded functions, while F12 are basic functions. For multi-modal problems, the performance of ITGO is better than PSO, DE/best/2/bin, BBO, GSA, TLBO, GWO. For F13, F18, F19, F20, F24 and F25, the performance of TLBO is better than PSO, DE/best/2/bin, BBO, GSA, GWO. For F12, the performance of BBO is better than PSO, DE/best/2/bin, GSA, GWO and TLBO. For F15 and F22, the performance of GSA is better than PSO, DE/best/2/bin, BBO, TLBO and GWO. For F23, the performance of GWO is better than PSO, DE/best/2/bin, BBO, GSA and TLBO.In this experiment, Table 11shows the means and standard deviation of the error values after 25 times runs for cPSO, rcGA, QIGSA and ITGO algorithms. The black font in Table 11 presents the winner. We use the Wilcoxon signed-rank test for the means in Table 11 to compare the cPSO, rcGA and QIGSA with ITGO algorithm. The comparison results among ITGO and cPSO, QIGSA, rcGA algorithms are summarized as in the last rows of Table 11, which means that ITGO wins inwfunctions, ties intfunctions and loses in l functions, compared with its competitors. Table 12shows the comparison results by Wilcoxon signed-rank test with Bonferroni–Holm correction method. For ITGO vs cPSO, ITGO vs rcGA and ITGO vs QIGSA, p-values are less than α/i, so all the H0 hypothesizes were rejected. That is, the performance of ITGO is better than cPSO, rcGA and QIGSA significant. Tables 13 and 14, show the results by Friedman's test, which shows that ITGO is better than all the others.Fig. 8is the convergence curves of the 4 algorithms for the six benchmark functions. F3 is unimodal function and F6, F10, F14, F16 and F20 are multimodal functions. Especially, F14, F16 and F20 are expanded functions. Regardless of the problems being unimodal or multimodal problems, the performance of ITGO is better than cPSO, rcGA and QIGSA. For F3 and F14, the performance of cPSO is better than rcGA and QIGSA. For F6, F10 and F16, the performance of rcGA is better than cPSO and QIGSA. For F20, the performance of QIGSA is better than cPSO and rcGA.In order to verify the capability of ITGO algorithm for solving large scale optimization problems, we use the 20 benchmark functions from CEC 2010 to compare ITGO with PSO, DE/best/2/bin, DE/2/exp, GbABC, BBO, GSA, TLBO, GWO, CLPSO and CS. Some of these functions may be singly separable or partially separable or fully nonseparable, which reflects the parameter optimization problem in reality. We set MAX_FES=3E5. The minimum, maximum, means, standard deviation and the median of the fitness evaluation values of the 11 algorithms are shown in Table 15. Tables 16–18show the comparison results of ITGO, PSO, DE/best/2/bin, DE/2/exp, GbABC, BBO, GSA, TLBO, GWO, CLPSO and CS using the Wilcoxon signed-rank test, Bonferroni–Holm correction method and Friedman's test for the means data set from Table 15. As for Wilcoxon signed-rank test and Bonferroni–Holm correction method, shown in Table 16, we consider H0 hypothesis where the results of two algorithms A and B have no significant difference. As seen from the statistical results, when α/i=8.857E−5, 8.857E−5, 8.857E−5, 0.0071, 0.0083, 0.01, 0.0125, 0.0167, 0.025 and 0.05, which compare ITGO with PSO, DE/best/2/bin, DE/2/exp, GbABC, BBO, GSA, TLBO, GWO, CLPSO and CS, p-values are less than α/i, so all the H0 hypotheses were rejected. As for the Friedman's test, average ranks show that ITGO is better than the others.Fig. 9is the convergence curves of the 11 algorithms for the 10 benchmark functions. F1 function is separable function; F6, F8, F9, F12, F13, F17 and F18 are partially separable functions. All these functions are high-dimensional problems. Fig. 9 shows that whether it is separable or partially separable or fully nonseparable, the performance of ITGO outperforms other 10 algorithms. For F1 function, the performance of GbABC outperforms other algorithms except ITGO. For F6 function, the performance of DE/best/2/bin outperforms other algorithms except ITGO. For F8 function, the performance of DE/2/exp outperforms other algorithms except ITGO. For F9 function, the performance of GbABC outperforms other algorithms except ITGO. For F12 function, the performance of GbABC outperforms other algorithms except ITGO. For F13 function, the performance of DE/2/exp outperforms other algorithms except ITGO. For F17 function, the performance of GbABC outperforms other algorithms except ITGO. For F18 function, the performance of GbABC outperforms other algorithms except ITGO. It shows that GbABC has good performance to solve many high-dimensional problems except ITGO.In this experiment, we choose the current improved PSO algorithms such as CLPSO, GOPSO, DNSCLPSO and DNSPSO to compare with ITGO. The results of CLPSO, GOPSO, DNSCLPSO and DNSPSO are copied from [71]. The results are shown in Table 19. We set MAX_FES=3E6. Table 20shows the comparison results of ITGO, CLPSO, GOPSO, DNSCLPSO and DNSPSO by the Wilcoxon signed ranks test and Bonferroni–Holm correction method. The result shows that there are significant differences for ITGO vs CLPSO, ITGO vs GOPSO, ITGO vs DNSCLPSO except ITGO vs DNSPSO. Tables 21 and 22show the results of the statistical analysis by the Friedman test. Average rank of ITGO is equal to 1.85, less than CLPSO, GOPSO, DNSCLPSO.Support vector machine (SVM) is a statistical classification method based on the VC (Vapnik–Chervonenkis) statistical learning theory and the structural risk minimization principle proposed by Vapnik et al. [87]. As a state-of-the-art algorithm, it has been used widely in many fields, such as novelty detection [88], image recognition [89], fault diagnosis [90], and so on. Given a training dataset {(x1, y1), (x2, y2), …, (xl,yl)}∈(x×y)l}, i=1, 2, …, l. xi∈x⊂Rnis the input vector, yi={−1, +1} is the class number.w⋅x+b=0is the maximum margin separating hyper plane. w is a orthogonal vector to the hyper plane. In order to separate the training samples into different categories, we should maximize the margin1/||w||, that is to minimize||w||2. SVM can be seen as a quadratic optimization problem:(17)min12||w||2+C∑i=1lξis.t.yi(w⋅ϕ(xi))+b)+ξi≥1(ξi≥0,i=1,2,…,l)C is the penalty parameter which imposes a trade-off between training error and generalization, ξiis a slack variable.The optimal problem of Eq. (17) can be converted to the dual problem as follows by Lagrange method:(18)min12∑i,j=1lyiyjαiαjK(xi⋅xj)−∑j=1lαjs.t.∑i=1lyiαi=0(0≤αi≤C,i=1,2,…,l)φ(·) denotes the mapping function which maps the input vectors into the high dimensional feature space and K(·, ·) denotes the kernel function. The generally used kernel functions are given as follows:Linear kernelK(xi,xj)=xiTxj.Polynomial kernelK(xi,xj)=(xiTxj+l)d, d, l is parameter.RBF kernel K(xi, xj)=exp(−||xi−xj||2/2σ2), σ is parameter.Sigmoid kernelK(xi,xj)=tanh(βxiTxj+b), β, b is parameter.In our instance, we choose RBF kernel function to solve practical problem. The setting of parameters (C, σ) directly influences the performance of SVM. It is a SVM parameter optimization problem. We choose two benchmark datasets with different dimensions from the repository of the machine learning databases [91], namely, Glass and Wine. The glass identification dataset contains six different types of glass, that is, float-processed building windows, non-float processed building windows, float-processed vehicle windows, containers, tableware and headlamps. There are nine attributes, namely, refractive index, sodium, magnesium, aluminum, silicon, potassium, calcium, barium and iron. The wine dataset contains chemical analyses of wines derived from three different cultivars, with 13 attributes, namely, alcohol, malic acid, ash, alkalinity of ash, magnesium, total phenols, flavonoids, nonflavonoid phenols, proanthocyanidins, color intensity, hue, OD280/OD315 of diluted wines and praline.In order to verify the performance of our proposed algorithm, we compare ITGO-SVM with PSO-SVM, DE-SVM, WQPSO-SVM, GS-SVM, BBDE-SVM and ICDF-GS-SVM. The average accuracy of 10-fold cross-validation is used for the fitness. Population size is 30 and the max fitness evaluations MAX_FES=1000. For ITGO, parameter beta=1.1, MAX_gc=7. Parameter setting of PSO, DE/best/2, WQPSO are adopted by the paper [19,73,92].Table 23shows the description of glass and wine data set and it indicates that they are multi-class classification problems. For this, we use the LIBSVM tool provided by Chih-Jen Lin [93]. Table 24shows the comparison results of ITGO-SVM, DE-SVM, PSO-SVM and QWPSO-SVM. It is obvious that ITGO-SVM has better accuracy than DE-SVM, PSO-SVM and QWPSO-SVM for the glass and wine dataset. Fig. 10shows the convergence curve of ITGO-SVM, DE-SVM, PSO-SVM and QWPSO-SVM. It means that ITGO-SVM has not only better accuracy but also fast convergence speed. Table 25shows the comparison results of ITGO-SVM, GS-SVM, BBDE-SVM and ICDF-GS-SVM. The results of GS-SVM, BBDE-SVM and ICDF-GS-SVM are obtained by the paper [94]. ITGO-SVM has better accuracy than GS-SVM, BBDE-SVM and ICDF-GS-SVM too.In our proposed algorithm, we use two parameters (beta and Max_gc) under the following assumption: the number of proliferative cells (p), quiescent cells (q) and dying cells (d) are 20%, 60% and 20% of the numbers of tumor cells, in which (p, q, d) can be seen as a percentage as 1:3:1 for the total number of the tumor cells. Though the detailed analysis of many experiments has verified the performance of ITGO algorithm in Section 4, the other three parameters (p, q, d) have not been discussed. According to the mechanism of real world tumor growth, the quiescent cells are the main body of the tumor with more cells. Meanwhile, the proliferative cells and dying cell are the secondary parts of the tumor with few cells. So, the parameter tuning is to vary the percentage of p:q:d. For simplicity, p and d equals to 1, and q ranges in [1,10]. As mentioned above, ITGO algorithm with each different parameter setting is ran 20 times for the six functions with one unimodal function (F2) and five multimodal functions (F9, F12, F16, F19 and F22), in which parameter beta=1.1 and MAX_gc=7 due to the before tuning. Mean fitness evaluation values are recorded in Table 26and Frandman test is used too. From the results in Table 26, we can see that the best parameter combination is p:q:d=1:8:1 (order=1). It means that the performance of ITGO algorithm is better when the number of proliferative cells (p), quiescent cells (q) and dying cells (d) are 10%, 80% and 10% of the numbers of tumor cells (population size=30). In addition, it shows that the performance is the worst when the parameter combination is as p:q:d=1:1:1 (1/3,1/3,1/3). It means that the number of quiescent cells is must large than the number of proliferative cells and dying cells for the better performance of our proposed algorithm, which can provide that one proliferative cell has more than one times opportunity to guide one quiescent cell for the better solution. At the end, the experimental findings suggest that we can set the parameter combination [beta, MAX_gc, p, q, d] as [1.1,0.7*10,1,8,1] in the performance evaluation. In particular, for some multimodal functions (F12, F22), parameter combination [beta, MAX_gc, p, q, d] as [1.1,0.7*10,1,2,1] can also be considered due to the best performance for ITGO algorithm.

@&#CONCLUSIONS@&#
This paper proposes a new metaheuristic algorithm, named ITGO. This algorithm mimics the process of invasive tumor growth. The tumor cells were divided into four types: proliferative cells, quiescent cells, dying cells and invasive cells. Different cells have different growing patterns. In order to imitate the intrusive behavior of tumor cells, we use the levy flight. According to the value of nutrient concentration, only the proliferative cells, quiescent cells and invasive cells have invasive behavior. When the nutrient concentration is too lower, the dying cell loses its invasive ability, even, may die without enough nutrients for living.In ITGO algorithm, a quiescent cell grows by guidance of a proliferative cell and interaction with its neighbors. In order to increase the diversity, a proliferative cell was selected randomly from proliferative cell population in each iteration. The historical best position and the current position were used together. The quiescent cells have an adaptive probability of mutation. The proliferative cell in the algorithm has strong intrusive behavior. Invasion probability is represented as a linear function, which describes the process of proliferative cell growth in tumor. This indicates that, at late growth stage, the proliferative cell will have stronger invasive ability. As for a dying cell, because it can only get nutrient of low concentration, it must be dead at a certain probability. Death was decided by the average nutrient concentrations. In general, the search strategy inspired by tumor growth mechanism enhances the exploration ability of ITGO algorithm.There are some points about ITGO algorithm we can discuss, because it is similar to some other metaheuristic algorithms, for instance, particle swarm optimization or differential evolution or artificial bee colony, etc. Indeed, there are many differences between ITGO algorithm and them. For particle swarm optimization, each agent (particle) searches by the global agent (‘leader’, only one) and historical information, while there are five different operations for the different agent (cell) in ITGO algorithm. For the quiescent cell, it searches by many ‘global agents’ (many leaders), not only one global agent; for the dying cell, it searches by many ‘global agents’ (many high level leaders) and many ‘local agents’ (many middle level leaders). For differential evolution, cross and mutation operations are used in the whole population. Different from it, only the quiescent cells in ITGO algorithm use the cross and mutation operations, and the cross rate is a self-adaptive method. For the artificial bee colony (ABC), there are two populations with three roles (employed bees, onlookers and scouts). Employed bees belong to the actual populations and onlookers belong to the virtual population (it is the same population as employed bees). In addition, onlookers and employed bees use almost the same operation with cross and mutation and it is like the differential evolution. When the onlooker in the population cannot search a better solution for a long time, it will be replaced by a new bee called scout. Different from it, in ITGO algorithms, there are three actual populations (proliferative cells population, quiescent cells population and dying cells population) with four roles (proliferative cells, quiescent cells, dying cells and invasive cells). There are five different operations in ITGO algorithms, that are simulated to the different behaviors of tumor cells including the growth of proliferative cell, the growth of quiescent cell, the growth of dying cell, the growth of invasive cell and the random walk for all the cells. So, ITGO algorithm provides a new framework with three populations, four roles and five search rules.The performance of our proposed ITGO algorithm is checked with the recent and well-known optimization algorithms such as PSO, DE/best/2/bin, DE/2/exp, CLPSO, BBO, GbABC, CS, GSA, TLBO, GWO, cPSO, QIGSA, rcGA, GOPSO, DNSCLPSO and DNSPSO by experimenting with different benchmark problems with different characteristics such as, multimodality, separability, regularity, and dimensionality. The effectiveness of ITGO method is also checked for different performance criteria, mean solution, median solution, min solution, predetermined stopping criteria, convergence rate, etc. with different statistical methods such as Friedman test and Wilcoxon signed-rank statistical test with Bonferroni–Holm correction. The results show better performance of ITGO algorithm over other natured-inspired optimization methods for the considered benchmark functions. Also, the ITGO method shows better performance with less computational efforts for the large scale problems, i.e., problems with high dimensions. This method can be used for the optimization of engineering design applications.