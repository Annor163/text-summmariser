@&#MAIN-TITLE@&#
Learnable high-order MGRF models for contrast-invariant texture recognition

@&#HIGHLIGHTS@&#
A new learnable high-order ordinal Markov–Gibbs field model of textures.Fast analytic learning of up to 8th-order potentials and iteraction structures.Texture-specific local binary/ternary patterns for accurate retrieval.Learning shapes, sizes, and numbers of patterns for every query image.Learned descriptors outperform conventional hand-picked ones.

@&#KEYPHRASES@&#
High-order ordinal MGRF,Contrast/offset invariance,Texture retrieval,Arbitrary-shaped LBP/LTP,Analytical learning,

@&#ABSTRACT@&#
Frequent in practice spatially variant contrast/offset deviations that preserve image appearance hinder classification based on signal co-occurrence statistics. Contrast/offset-invariant descriptors of ordinal signal relations, such as local binary or ternary patterns (LBP/LTP), are popular means to overcome this drawback. This paper extends conventional LBP/LTP-based classifiers towards learning, rather than prescribing most characteristic shapes, sizes, and numbers of these patterns for semi-supervised texture classification and retrieval. The goal is to discriminate a particular texture represented by a single training or query sample from other types of textures. The proposed learning framework models images as samples from a high-order ordinal Markov–Gibbs random field (MGRF). Approximate analytical estimates of the model parameters guide selecting characteristic patterns of a given order, the higher order patterns being learned on the basis of the already found lower order ones. Comparative experiments on four texture databases confirmed that classifiers with the learned multiple LTPs from the 3rd to 8th order consistently outperform more conventional ones with the prescribed 9th-order fixed-shape LBP/LTPs or a few other filters.

@&#INTRODUCTION@&#
Texture analysis and recognition belong to basic image processing and computer vision tools and are widely used in many applications, including industrial inspection, remote sensing of the Earth’s surface, computer-aided medical diagnostics, content-based image retrieval (CBIR), and so forth (see, e.g., [1–6] to cite only a few. As shown in [7], local and global texture descriptors [8,9] have become important and efficient additions to the earlier colour and shape ones in the CBIR. An effective retrieval based on basic texture elements, or textons, was introduced in [10].Contrast-invariant texture recognition. Visual appearance of natural materials depends to a large extent on illumination, viewing directions, and imaging geometry. Therefore, analysis and retrieval of real-world textures requires invariance to at least main perceptive (contrast/offset) and geometric, e.g., affine, projective, or non-rigid variations between images captured under a variety of viewing conditions.Most of conventional texture descriptors [11,12] account for local signal co-occurrences via, e.g., integral characteristics of grey level co-occurrence matrices [13] or outputs of linear Gabor filters [14] and wavelets [15–17]. However, the real-world textured objects are often viewed under arbitrarily varying illumination, and signal magnitudes may be also affected by spatially variant sensor noise [18]. The resulting image deviations make the co-occurrence-based texture descriptors fragile and notably degrade their image retrieval and classification performance. Leung and Malik [19] used three-dimensional textons to classify materials photographed under real-world conditions. But the required multiple co-registered images captured from known viewpoints under fixed illumination decrease the robustness to changing orientation or scaling.The famous VZ classifier by Varma and Zisserman [20] described appearances of natural materials from a single image with no prior viewing or illumination knowledge by using probability distributions of textons built by clustering outputs of a bank of rotation invariant filters. The VZ exemplifies a large group of texture descriptors employing deviation-invariant filters to deal with varying illumination and sensing conditions. Local descriptors in [21] also combine outputs of linear filters in a rotation/contrast/scale-invariant way.Image filtering describes a high-dimensional space of signal co-occurrences with computationally feasible low-dimensional (mostly, scalar) projections. The more the types of global and local signal deviations to deal with, the more intricate the filters to be designed, reducing the discriminability of textures and aggravating the recognition accuracy [22]. Moreover, joint intensity distributions over a compact pixel neighbourhood have outperformed filtering the same neighbourhoods [23], i.e., ensured much better performance than both the VZ and local rotation, contrast, and scale invariant descriptors [21,24] on a very difficult UIUC database [25].Local binary/ternary patterns. Most frequent spatially variant perceptive deviations, caused by illumination and sensor noise, keep appearance of a natural texture due to preserving ordinal relations between closely-spaced signals. Popular local binary or ternary patterns (LBP/LTP) [26], accounting only for such relations, are thus powerful and practical contrast/offset-invariant descriptors and have already solved various practical image analysis tasks, including visual inspection and classification of textured objects.The basic LBP [27] has a predefined star-like circular central-symmetric shape and quantifies the binary ordinal relations between a central pixel (an origin) and each of its eight equidistant and evenly spaced close- or long-range neighbours. An empirical marginal of such quantified relationships over an image is the ordinal descriptor, which is robust to any monotone transformation of the pattern-wise grey scales and has impressive computational efficiency and discriminative capabilities.The above conventional descriptors employ the local filters and LBP/LTPs of a fixed hand-picked shape, namely, the N × N squares of small size (N=3,5,7) or the star-like circular structures, respectively. At the same time, unique appearances of many translation invariant textures are characterised by spatial repetitiveness of only specific statistics of local relationships (interactions) between the intensities. The early texture models, such as, e.g., simple 2nd-order auto-regressive, or Gauss–Markov random fields in [28], used a learnable spatially invariant linear predictive filter of a fixed small size to reveal such statistics and classify the textures.As was shown later [29], learning a unique spatial pattern of multiple close- and long-range pairwise interactions yields a more efficient MGRF model of texture. A characteristic neighbourhood, uniting the learned pairwise interactions of every single pixel, and corresponding marginals of individual pairwise intensity co-occurrences are the model-based image descriptors, which can be used, in particular, for texture classification and synthesis.High-order MGRFs, being generally more powerful than 2nd-order MGRFs due to accounting statistics of much richer interactions between multiple signals [30] and have shown promising results in image denoising, segmentation and restoration. However, the lack of efficient learning and inference algorithms remains the main challenge and limits applicability of these models. The classic N2-order FRAME [31] and FoE [32] models capture characteristic interaction patterns implicitly, by describing all intensity co-occurrences over the N × N square windows placed, ultimately, around every pixel by K marginals of original (FRAME) or transformed (FoE) outputs of K filters; K ≤ N2. Given a training image, the FRAME filters are selected in a computationally intensive sequential way from a hand-picked collection of linear orthogonal filters (often, the 2D Gabor filters with spatially oriented Gaussian-weighted sinusoidally-shaped coefficients), including also a few nonlinear filters. At each step, the maximal distance between the marginals collected for all the remaining filters over the training image and a texture, synthesised with the current model, indicates the next filter to be placed into the model. The FoE employs initially orthogonal linear filters, being principal components of the training N2-element vectors of signal cooccurrences. The output of each filter is transformed with a hand-picked non-linear parametric potential function. The filters and parameters of their transforming potentials are refined by minimising the training image energy. Both the models account for almost no spatially variant perceptive deviations and thus have limited abilities to learn adequate appearance descriptors.More recent 3rd- and 4th-order MGRFs in [33] used simple hand-picked clique structures, namely, pixel triples along the coordinate axes or 2 × 2 rectangles. A conditional high-orderPnPotts random field of region labels, given a piecewise-homogeneous texture, with a special parametric polynomial potential, was developed specially for the graph-cut based segmentation [34,35]. Other recent high-order MGRFs [36–39] focus on transforming high-order energy functions to low-order representations, such as linear or boolean functions, to reduce the optimal statistical inference to minimization of an equivalent 2nd-order energy function. Some global image properties, such as connectedness [40,41], can be also modelled with potentials depending on all the pixels. The model parameters are set up either manually [35] or by an iterative search for local minimum of a specific regularised energy function [40]. However, it is difficult to use all these MGRFs for texture modelling and recognition under spatially variant perceptive deviations.Overview of the paper. This paper introduces and employs a new generic MGRF, which inherits the 2nd- and higher-order ordinal pixel-to-neighbours interactions from a generalised LBP/LTP, but allows for learning most characteristic patterns of arbitrary shapes, adapted to appearance of each training texture. The model is robust to local perceptive variations due to using ordinal relations and has also a limited rotational invariance due to its in-built adaptation by minimising the total interaction energy of a given texture.Novelties of the paper are four-fold. (i) Unlike most of the high-order models with hand-picked square or circular interaction structures of fixed sizes, shapes of our structures can be arbitrary and are learned to better characterise each training texture. (ii) In so doing, potentials of our MGRF are learned analytically, in a computationally efficient way, rather than hand-picked among specific parametric functions as in a large group of the high-order MGRFs that act as smoothing or global connectivity priors in image segmentation and facilitate statistical inference based on graph-cut or belief propagation optimisation. (iii) Characteristic interaction structures and potentials learned for our model (of up to the 8th order in this paper) are texture-specific descriptors, usable in other applications. (iv) The proposed high-order ordinal model is robust to spatially variant perceptive variations over the textures.Performance of the proposed high-order model with the learned LTPs was evaluated experimentally on 1072 digital textures from four popular image databases, including the recent Outex and older Brodatz collections. These experiments confirmed that our texture retrieval accuracy is consistently higher than for the known fixed-structure LBP/LTPs and descriptors derived from the VZ filters and the FRAME and FoE models.The paper is organized as follows. Section 2 outlines the prior work. The proposed generic high-order ordinal MGRF and its learning are detailed in Section 3. Section 4 discusses experimental validation of these descriptors, and Section 5 concludes the paper and outlines the future work.LetQ={0,…,Q−1}andR={r=(x,y):x=0,…,X−1;y=0,…,Y−1}denote a finite set of grey levels and a finite 2D arithmetic lattice supporting grey-scale textured images,g:R→Q,with signalsg=[g(r):r∈R],respectively. Fig. 1illustrates a fixed central-symmetric (circular) shape of a basic(K+1)th-order LBP [27,42,43] where g0, 0 and{gr:i:i=0,…,K−1}are grey values at the central pixel,r=(x,y),of the pattern inR,and at itsK−1equispaced neighbours,(x+ξi,y+ηi). The latter, sitting on a circle of radius r, have the coordinate offsets,(ξi=−rcos(2πiK),ηi=−rsin(2πiK))from the LBP centre (origin), called often the reference, or leading pixel. When the neighbours with non-integer coordinates fall between the lattice sites, their signals are interpolated [26]. The binary ordinal relations between the central and each of the neighbouring grey values are concatenated in a counterclockwise sequential way to represent the LBP with a binary number:(1)LBPK:r(x,y)=∑i=0K−1s(gr:i−g0,0)2i,wheres(u)=1if u ≥ 0 and 0 otherwise; g0, 0 ≡ g(x, y) andgr:i≡g(x+ξi,y+ηi).A multi-resolution LBP [26] extends the basic LBP by using several LBPs with different radii r. The three-resolution LBP with(r=1,K=9,n=59);(r=2,K=17,n=243),and(r=3,K=25,n=555)accounting for only n uniform patterns in [44] is called below the classic LBP. Spectral features of an LBP marginal obtained by the discrete Fourier transform (LBP-HF) [45] have performed in texture classification and face recognition better than the earlier classic LBP. The alternative ILBP [46] and MBP [47] replace the central grey value g0, 0 in Eq. (1) with the mean or median grey value, respectively, of the whole shape including the centre. An LTP in [48] encodes the pairwise ordinal relations between the grey values more in detail. To become more robust to image noise, a fuzzy LBP (FLBP) [49,50] employs two fuzzy membership functions instead thresholding, and a shift LBP (SLBP) [51] implementation makes the FLBP five times faster.This paper uses sufficient statistics of the contrast-offset invariant MGRF introduced in Section 3, i.e., empirical marginals (normalised histograms over the image g) of values of the learned LBPs as ordinal texture descriptors. The like marginals for the classic LBP, LBP-HF, SLBP and LTP, as well as descriptive marginals from the VZ, FRAME, and FoE serve as the control methods (most of their MATLAB codes are available online, e.g., [52,53]). At the recognition stage, the training (query) descriptors and the like descriptors for other images are compared and discriminated using conventional inter-distribution statistical tests, such as the chi-square metrics [26,44].The LBP itself is not rotation-invariant. To define a rotation-invariant LBP, its numerical code for each neighbourhood is compared in [43] to one of the 36 individual patterns by rotating the neighbourhood until one match is achieved. The marginals of the matching frequencies over the image are used as the rotation-invariant LBP descriptors. An alternative approach in [54,55] used the MGRF models with the arbitrary-shaped(K+1)-order local patterns, but in contrast to the LBP, accounted for the complete ordinal relations between theK+1grey values. Fig. 2(a) illustrates the difference between the partial and complete ordinal interactions by showing all the interactions taken into account for a 4th-order pattern. Because the cardinality of the set of the complete ordinal relations grows much faster than the cardinality of the set of(K+1)-order LBPs, this former approach remains feasible only up to the 4th and 5th-order ordinal MGRF, i.e., forK=3or 4. According to experimental results, such learned 3rd- and 4th-order models outperformed, in application to texture classification, the learned earlier 2nd-order MGRFs accounting for multiple pairwise signal co-occurrences [29,56], but rank below the classifiers using the classic LBPs. An introduced below new learnable MGRF with multiple high-order ordinal interactions quantified with the arbitrary-shaped LBPs or LTPs has less limitations.The proposed MGRF describes a texture with a collection of the empirical marginals, i.e., marginal probability distributions of the LTPs supported by spatially repetitive pixel configurations of arbitrary shapes. The configurations act as cliques of the interaction graph linking all the mutually interacting pixel pairs. Each such(K+1)-order clique is defined by K coordinate offsets(ξi,ηi):i=0,…,K−1}of its components from the origin. Unlike a majority of the known translation invariant MGRFs, including those invariant also to local perceptive signal deviations, both the shapes of the(K+1)-order cliques and the potentials, quantifying statistical strengths of ordinal interactions between theK+1pixels with the numerically coded LTPs, are learned from the training or query data, rather than are hand-picked.To preserve visual appearance, let admissible spatially variant perceptive deviations keep at least local differential appearance, i.e., signs of differences between the closely located signals. Then joint ternary relations,{>,=,<},between the signals at the clique origin and its neighbours in Fig. 2(b) are computationally feasible partial contrast/offset-invariant local image descriptors. The joint ternary relations of the orderK+1form 3Kdistinct LTPs, e.g., 729 and 2187 patterns for the 7th- and 8th order, respectively.An LTP on a clique of orderK+1quantifies partial ordinal relations between signals on the clique, namely, the K close- and/or long-range ternary relations between the signal in a leading pixel, considered the clique origin, and its K neighbours. The(K+1)-order MGRF model of each particular texture has its own learned geometric shapes of the cliques stratified into one or more families of the translation invariant same-shape cliques and own Gibbs potentials learned for each family. Given a training subset of images of a particular texture, the approximate potentials for all arbitrary-shaped candidate clique families of each order are first estimated analytically and then used to select the most characteristic families from a pool of the candidates by comparing their Gibbs energies. After the characteristic 2nd-order families are learned, the found shapes are used for building the higher-order ones. Based on a conjecture that lower-order cliques being constituents of a characteristic high-order one are characteristic by themselves, the sequential learning proposed below will greatly decease the numbers of candidates for the higher-order cliques.An MGRF of images from the parent populationG=Q|R|is defined by a Gibbs probability distribution (GPD),P=[P(g):g∈G;∑g∈GP(g)=1],such that each probability, P(g), is factored over the maximal cliques of an interaction graph,Γ=(R,A). The graph has nodes at pixels,r∈R,and describes conditional signal dependencies by edges, or arcs(r,r′)∈A⊆R2,connecting interdependent (interacting) pixel pairs, called neighbours. Each GPD, P, is specified by a set of cliques in Γ supporting non-trivial (non-constant) factors and potentials (logarithms of these factors).A translation-invariant(K+1)-order interaction structure onRis a system,C,of A, A ≥ 1, clique families,Ca;⋃a=1ACa=C. Each family has an own shape of cliques,ca:r∈Ca,with origins at pixels,r∈R,and a(K+1)-variate potential function,Va=[Va(q,q1,…,qK):(q,q1,…,qK)∈QK],depending on ternary ordinal relationships>,=,<between the origin signal,q=g(r),and its K neighbours,qk=g(rk)∈ca:r; rk≠ r, in each clique. The GPD for this translation- and contrast/offset invariant MGRF is:(2)P(g|V)=1ZVexp(−∑a=1A∑ca:r∈CaVa(g(s):s∈ca:r))where s denotes the vertices in each clique ca: rand the negated exponent(3)EV(g)=∑a=1A∑ca:r∈CaVa(g(s):s∈ca:r)is the total interaction (Gibbs) energy. The partition function ZVnormalises the distribution over the entire parent population:ZV=∑g∈Gexp(−EV(g)).LetTKbe a finite set of values of the LBP or LTP of orderK+1. Then the GPD of Eq. (2) is rewritten as(4)P(g|V)=1Zexp(−|R|∑a=1Aρa∑τ∈TKVa(τ)Fa(τ|g))=1Zexp(−|R|VTF(g))whereTdenotes transposition;VT=[VaT:a=1,…,A]is the potential vector-column concatenating the potentials for all the clique families:VaT=[Va(τ):τ∈TK],and the vector-column image descriptor F(g) concatenates vectors of the scaled empirical marginals of the LBP/LTP values over the clique families:FT(g)=[ρaFaT(g):a=1,…,A]with the scalesρa=|Ca||R|. Here,FaT(g)=[Fa(τ|g):τ∈TK]is the vector of empirical marginal probabilities Fa(τ|g) of the pattern valuesτ∈TKover the clique familyCafor the image g, or the relative number of cliques supporting the pattern value τ in this clique family. The exponential family representation of the GPD in Eq. (4) allows for extending the fast analytical framework [29,56], which learns a generic 2nd-order MGRF, onto the higher-order models.As universallyknown in statistics [57,58], the log-likelihood:ℓ(V|g∘)=1|R|logP(g∘),of a training image, g°, for the GPD of Eq. (4):ℓ(V|g∘)=−VTF(g∘)−1|R|log∑g∈Gexp(−|R|VTF(g))is unimodal in the space of potentials V, providing the Hessian matrix of the descriptors F(g) is non-singular and definite negative at zero gradient point,V=V∘,defining the MLE. The gradient,∇ℓ(V), and Hessian, Hℓ, i.e., the first and second log-likelihood derivatives by V, are as follows:(5)∇ℓ(V)=∂ℓ(V|g∘)∂V=−F(g∘)+E{F(g)|V}Hℓ=∂2ℓ(V|g∘)∂2V=−C{F(g)|V}whereE{…}denotes the mathematical expectation:E{F(g)|V}=∑g∈GF(g)P(g)|Vand C{F(g)|v} is the covariance matrix of the sample frequencies, which is always definite non-negative. When the covariance matrix in Eq. (5) is non-singular, i.e., positive definite, the exact MLE of the potentials is unique and makes the empirical descriptor equal to the expected one:(6)F(g∘)=E{F(g)|V}≡∑g∈GF(g)P(g)|V∘)Because the right-hand-side mathematical expectation in Eq. (6) is generally intractable, the learning framework introduced in [29,56] finds instead an approximate MLE by replacing the log-likelihood with its truncated Taylor’s series decomposition at the vicinity of the origin,V=0,of the potential space:(7)ℓ(V|g∘)≈ℓ(0|g∘)+VT∇ℓ(0)+12VTHℓV=ℓ(0|g∘)+VT(E{F(g)|0}−F(g∘))−12VTC{F(g)|0}VAs the origin 0 defines an independent random field (IRF) of images with equiprobable pixel-wise signals, the expectation,Firf=E{F(g)|0},and covariance matrix, Cirf of the aforementioned higher-order ordinal descriptors can be found either analytically, or at least empirically from a set of images sampled of the IRF.The resulting approximate MLE of the potentials maximises the truncated series of Eq. (7):(8)V˜∘=Cirf−1(Firf−F(g∘))In particular, for the 2nd-order signal co-occurrences, described with their empirical marginal probabilities over the clique family [29,56], all the expected descriptors for the IRF are equal toFirf(q,q′)=ɛ2and their covariance matrix is closely approximated with a diagonal matrix of the variancesɛ2(1−ɛ2)Iwhere I is the identity matrix andɛ=1Q. In this case the potentials are directly proportional to the differences of the marginals:V˜∘=Q4Q2−1(Firf−F(g∘)). Probabilities of the ternary relations{>,=,<}between the signal pairs in this IRF are0.5(1−ɛ),ɛ,0.5(1−ɛ),respectively, and so the probability of each value τ of the(K+1)-order LTP depends only on the numbers{k>(τ);k=(τ),k<(τ)};k>(τ)+k=(τ)+k<(τ)=K,of its individual relations:Firf(τ)=ɛk=(τ)(0.5(1−ɛ))K−k=(τ). The like approximation of the covariance matrix with the diagonal matrix of the variancesFirf(τ)(1−Firf(τ))for each LTP value results in the approximate potentials:(9)V˜a∘(τ)=Firf(τ)−Fa(τ|g∘)Firf(τ)(1−Firf(τ));τ∈TKThe characteristic clique families are found by analysing the partial interaction energies for a large search pool of the candidates. In the experiments below (Section 4), intra-clique pixel x- and y-offsets for the 2nd-order candidate families have been limited to the ranges[−50,50]and [0, 50], respectively, giving in total the 5, 150 candidates. Algorithm 1details learning 2nd-order characteristic clique families.The most characteristic (least-energetic) families were selected by separating an empirical distribution of the family-wise interaction energies with the unimodal thresholding [59]. The selection threshold corresponds on the distribution curve to the point at the maximal distance from a straight line from the peak energy to the last non-empty position of the energy distribution, i.e, to the least energy or the maximal negated energy. Fig. 3 illustrates learning the characteristic 2nd-order clique families for the Brodatz texture D1 from the distribution of the negated energies for all the 5150 candidates with the absolute x- and y-coordinate offsets |ξ| ≤ 50; |η| ≤ 50.The energy distributions for some textures are multi-modal, especially, for the sets of the higher-order candidates. For simplicity, in the experiments below a proper lower-energy threshold is determined by iterating the unimodal thresholding until the number of the selected clique families is in a prescribed range [50, 200] for the 2nd-order and [20, 50] for the higher-order families. This heuristic iterative search circumvents a more complicated estimation of the dominant energy modes, while produces reasonably small numbers of the characteristic clique families of each order under consideration, which are sufficient for capturing and discriminating the learned textures [55].A very similar process of learning potentials for and structures of the higher-order clique families has only two differences. (i) The number|TK|of distinct numerical codes for the(K+1)-order LTPs grows as 3K, e.g., from 9 to 2187 for the 3rd- to 8th-order families, respectively. (ii) Although the candidate 2nd-order families exhaust all the coordinate offsets in a search window, the like initial search pool of all possible 3rd- or higher-order shapes within the same window is impractical due to its exponential growth, e.g., more than 1.3 × 107 candidates just for the 3rd-order models. To have a feasible search pool of each order, our sequential learning Algorithm 2assumes that every characteristic high-order conditional signal dependency in textures of our interest implies all the lower-order ones, so that the higher-order cliques can be built gradually from the already selected characteristic lower-order ones. Fig. 4 illustrates the selection of the 3rd-, 5th-, and 8th-order cliques for describing the texture D1.Adding a next node to an already built lower-order shape specifying the clique family has one practical constraint: the distance between the new node and each previous one must exceed a certain prescribed or experimentally found threshold, d, shown in Fig. 5. For example, if two clique elements are too close, the formed candidate 3rd-order clique is actually too similar to the original 2nd-order one. To capture longer-range shapes and decrease the number of the candidate families, only the offsets exceeding the threshold take part in building the higher-order cliques (d=4was empirically set up in our experiments in Section 4).After the characteristic cliques and their potentials for the ordinal MGRF model are learned from a training, or query texture,g[l]∘,of a particular class, l, any other texture, g, is compared to the training one using the obtained model descriptors – the sufficient statistics, F(g) andF(g[l]∘),whereF(g)=[Fa(g):a∈A]is the vector of empirical marginals (probabilities of signal patterns) over all the clique families. The χ2-distance (Dχ2) between these statistics is used as the similarity metric for classification or retrieval:(10)D∘(g)=χ2(F(g[l]∘),F(g))Rotational invariance of our 2nd- or higher-order LTP-based MGRF model is achieved, just as in [43], by matching both the LBP codes, corresponding to the LTP for each pixel neighbourhood, to their rotationally equivalent individual codes, i.e., by rotating the neighbourhood until finding the exact match. Alternatively, the characteristic cliques learned for the training texture can be rotated until finding the lowest interaction energy for or the highest similarity of a given test texture.

@&#CONCLUSIONS@&#
This paper proposes a new framework for learning texture-specific contrast/offset-invariant high-order MGRF models of images described in terms of multiple arbitrary-shaped LBPs or LTPs, which are considered ordinal signal configurations supported by K-order clique families on an interaction graph;K=2,3,…,8. Given a training or query image, our learning framework builds a K-order MGRF model of this class of textures by recovering both the translation-invariant interaction structure, i.e., the number and shapes of characteristic repetitive patterns, and their corresponding Gibbs potentials. First, the analytical approximate MLEs of the potentials are computed from the empirical marginals for the numerically coded candidate LBPs or LTPs. Then, the partial Gibbs energies totalling the potentials over every translation-invariant clique family are used to determine the characteristic families sequentially, by building the next-order cliques from the already selected lower-order ones.Experimental results on the four texture databases show that the marginals of the LTP values over the learned high-order characteristic clique families act as highly efficient texture descriptors. The χ2-distances between such training and test descriptors outperform by the texture retrieval accuracy the like descriptors for the classic fixed-shape LBPs and LTPs, as well as for the learned filters from the well-known high-order FRAME and FoE models. The descriptors based on the RFS filters from the highly efficient VZ classifier perform very similarly to our model, but at the expense of their considerably higher computational complexity and hence much slower retrieval.However, the learning actually hindered the performance for a few classes of textures, partly, because of simplifications in building higher-order cliques from the lower-order ones by adding new characteristic dependencies on the basis of their relative energies. These problems will be explored in our future work on improving the effectiveness of high-order contrast/offset-invariant texture descriptors, including the proposed arbitrary-shaped texture-specific LTPs. While this paper focussed on texture retrieval with a single query image of a goal class, such descriptors could be applied also to more general texture classification and object recognition problems.The learned LTPs are well suited for describing various textures, which are spatially homogeneous in that their contrast/offset-invariant statistics of local signal co-occurrences are spatially (translationally) repetitive, e.g., for regular (mosaic-like) and stochastic textures. Due to learning from a single query, or training texture, the already found descriptors can be directly applied to any texture database for retrieving textures of the same class. But, in principle, a net of such position-dependent descriptors can be learned for a spatially inhomogeneous texture, too, given a sufficiently large set of co-aligned training images.