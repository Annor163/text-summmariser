@&#MAIN-TITLE@&#
Extending helicopter operations to meet future integrated transportation needs

@&#HIGHLIGHTS@&#
Work Domain Analysis was used for concept design.A Head Up Display (HUD) was developed to assist pilots landing in degraded visual conditions.The HUD increased awareness and reduced workload in degraded conditions.

@&#KEYPHRASES@&#
Helicopters,Head up display,Cognitive work analysis,

@&#ABSTRACT@&#
Helicopters have the potential to be an integral part of the future transport system. They offer a means of rapid transit in an overly populated transport environment. However, one of the biggest limitations on rotary wing flight is their inability to fly in degraded visual conditions in the critical phases of approach and landing. This paper presents a study that developed and evaluated a Head up Display (HUD) to assist rotary wing pilots by extending landing to degraded visual conditions. The HUD was developed with the assistance of the Cognitive Work Analysis method as an approach for analysing the cognitive work of landing the helicopter. The HUD was tested in a fixed based flight simulator with qualified helicopter pilots. A qualitative analysis to assess situation awareness and workload found that the HUD enabled safe landing in degraded conditions whilst simultaneously enhancing situation awareness and reducing workload. Continued development in this area has the potential to extend the operational capability of helicopters in the future.

@&#INTRODUCTION@&#
In most cities the dominant car-road transport system is already reaching a saturation point (Tibbs, 1998). This issue is going to be exacerbated when we consider that by 2040 the world's population is expected to reach nine billion, with 64% of the world living in urban areas (Ministry of Transport (2013)). Therefore, the future transport environment is an issue that concerns us all, whether a car owner or a regular user of public transport, increased demands on the current transport infrastructure means that the future transport system will look very different from today. Tibbs (1998) argued that scenarios for future transport systems need to address the likelihood of a fundamental shift away from the car-road system. In the 1950s it was predicted that rotorcraft would be essential in the transport systems of overly populated countries before the end of the 20th century, but they have not realised their full potential in industrialised countries (British Helicopter Association, BHA, 2014). There are more helicopters in military service than civilian operation and commercial passenger-carrying operations are generally confined to corporate or offshore domains. The unique characteristics of helicopters means that they have the potential to result in radical changes to the urban transport environment (Dodge and Brooks, 2013). Increased helicopter transport is already evident in a recent review by the National Transport Safety Board (NTSB, 2011) which reported that in relation to air taxi operations between 2004 and 2010 helicopter flight activities increased by 97 percent while fixed wing flight activity decreased by 28 percent. Currently, one of the biggest limitations on rotary wing flight is their inability to fly safely in degraded visual environments (DVE) during critical phases of flight (such as approach and landing). This paper presents a study that developed and evaluated a Head up Display (HUD) concept to assist rotary wing pilots landing in DVE. The HUD was developed with the assistance of Work Domain Analysis phase of the Cognitive Work Analysis method as an approach for analysing the cognitive work of landing the helicopter in order to identify the critical information requirements associated with this task.The current operational environment for helicopters varies greatly with role, but helicopters generally operate outside of direct air traffic control, at low altitudes and under visual flying conditions (BHA, 2014). This means that helicopters are used in operational contexts that are not suitable for fixed wing aircraft, including medical rescue over land, search and rescue over water or mountains, rapid corporate passenger transfer, oil platform transfer, police search, television broadcasting and firefighting. Helicopters tend to perform take-off and landing manoeuvres that are unlike fixed wing aircraft, generally being steep and with greatly reduced landing distances at both managed and unmanaged landing sites (Dodge and Brook, 2013). This benefit of helicopter flight is also the helicopter's greatest hazard as these manoeuvres can be dangerous and in remote locations. So unless this phase can be made safer and more consistently enabled the risk has the potential to negate the benefit of helicopter flight (Nascimiento et al., 2014).Helicopters are to aeroplanes, what motorcycles are to automobiles; there are fewer of them but they have disproportionately higher accident rates. Estimates suggest that accident rates for helicopters are ten times higher than for fixed wing operations (Nascimiento et al., 2014). A primary cause of rotary wing accidents is degraded visibility caused by poor weather. A DVE is one in which ocular visibility is reduced due to light levels (e.g. night), weather phenomena (e.g. fog) or atmospheric conditions (e.g. dust) (Hart, 1988). Baker et al. (2011) found that bad weather was the second most common precipitating factor (after mechanical failure) for fatal and nonfatal crashes in their analysis of 178 Gulf of Mexico helicopters accidents. Furthermore, the bad weather accidents resulted in the largest number of deaths (40 percent of all deaths). Due to the nature of helicopter operations, in remote locations and in emergency operational contexts, the likelihood of encountering DVE can be significant. Accident data has suggested that inadvertent Instrument Meteorological Conditions (IMC) flights (i.e. starting in visual flight conditions and unintentionally entering instrument flight rules) is one of the major causes of helicopter accidents, particularly when pilots are not trained to IMC level (Hart, 1988). These accidents are caused by spatial disorientation and subsequent loss of control and commonly lead to controlled flight into terrain. Aside from the increased safety risk, DVE presents one of the most disruptive factors in civil aviation and is a leading contributing factor to flight delays at major commercial airports (Allan et al., 2001; Pejovic et al., 2009).The operational benefits afforded to helicopters and the associated contexts of use have driven an increased demand for their use in DVE in a civilian setting (Baker et al., 2011; BHA, 2014). Furthermore, the ability to fly at low altitudes makes rotary wing aircrafts more susceptible to issues arising from low visibility for greater proportions of flight, not just critical phases. A primary challenge in civil aviation is the creation of safe operational environments for rotary wing aircrafts to operate in DVE. If helicopters are going to become an increasingly viable mode in the future transport system there is a need to increase operational effectiveness and safety. The implementation of HUDs is one way of achieving this.HUDs have been commonly used in military aviation for a number of years but are increasingly being used in commercial flight operations and for other applications such as driving (Harris, 2011; Jakus et al., 2014). A HUD interposes images on a transparent layer between the pilot and windshield, allowing the pilot to simultaneously look at the HUD symbology and the outside world. The images are focused at infinity which means that the pilot does not have to re-focus their eyes when transferring their gaze from HUD symbology to the outside environment. Generally, the content of the HUD includes primary flight information normally found on the primary flight display, additional flight path symbology (e.g. ‘Highway in the sky’) and conformal, graphical, representations of the outside environment (Alexander et al., 2003; Thomas and Wickens, 2004; Harris, 2011). A HUD allows the pilot to fly ‘eyes out’ rather than switching attention to head-down displays (HDD) inside the cockpit. The objective of a HUD is to replicate the operational benefits of clear-day flight operations regardless of the actual outside visibility condition, thus increasing operational capacity and reducing accidents caused by low visibility conditions.One of the most important requirements of a helicopter cockpit is good visual characteristics (Lovesey, 1975). At low altitudes in good visibility, helicopter pilots use visual cues in the immediate surroundings to identify terrain features and determine their orientation, rate and direction of movement, height and distance. In low visibility the spatial and temporal resolution of visual cues are reduced and can result in diminished situation awareness and increased workload (Hart, 1988). The presentation of information via a HUD in a manner that does not require the pilot to divert visual attention and cognitive resources into the cockpit has the ability to optimise workload and enhance situation awareness (Snow & Reising, 1999; Fadden et al., 1998; Snow and French, 2002). Conformal symbology is often included on HUDs to increase the realism of the presented information. Conformal, or scene-linked, symbology allows information to be displayed at a static position relative to the real world; an example of this would be the outline of a helipad displayed on the HUD which remains overlaid on top of the view of the helipad in the outside world, regardless of what part of the HUD the pilot is looking at. Conformal symbology leads to faster detection of changes in symbology and improved flight path tracking accuracy (Fadden et al., 1998; Snow and French, 2002).HUDs however may cause the detection of unexpected events to be degraded by attention capture when the pilot's attention shifts away from the outside environment and remains too focused on processing information presented by the HUD (Fadden et al., 1998; Thomas & Wickens, 2004; Jakus et al., 2014). An overly cluttered HUD can be detrimental to pilot situation awareness and the overlay of symbology can obscure objects and may disrupt effective scanning (Yeh et al., 2003; Harris, 2011). To optimize the benefits of HUDs, designers must preserve the most useful and unambiguous visual cues pilots naturally use so that information is processed intuitively by pilots (Foyle et al., 1992; Harris, 2011; Fadden et al., 1998).Helicopter flight operations represents a complex socio-technical system made up of numerous interacting parts, both human and non-human, operating in dynamic, ambiguous and safety critical domains. The complexities in these systems present significant challenges for modelling and analysis. CWA is a structured framework for considering the development and analysis of these complex socio-technical systems (Jenkins et al., 2009; Vicente, 1999; Rasmussen, 1986). The framework guides the analyst through the process of answering the question of why the system exists, what activities can be conducted within the domain as well as how this activity can be achieved and who can perform them, identifying competencies required. CWA has been applied in a variety of domains including the military (Jenkins et al., 2008; McIlroy and Stanton, 2011; Stanton and Bessell, 2014), driving (Cornelissen et al., 2013, 2014), aviation (Ahlstrom, 2005; Stanton and Plant, 2010, 2011), rail (Stanton et al., 2013) and nuclear power plants (Walker et al., 2014) and has seen a range of applications including system modelling, training needs analysis, interface design and requirements specification (Walker et al., 2014).CWA consists of five phases each modelling a different set of constraints. For a detailed description of each phase and the associated tools the reader is directed to additional texts including Vicente (1999), Jenkins et al. (2009) and Read et al. (2015). Whilst each phase of the analysis process builds upon the last, McIlroy and Stanton (2011) argued that not all phases are required to be used equally and it is down to the analyst to decide which phases are necessary to answer the research question under investigation. To address the research aims of this paper, the first phase of the CWA process, Work Domain Analysis (WDA) was utilised to analyse the cognitive work of landing a helicopter in DVE in order to identify the critical information requirements associated with this task.WDA identifies the constraints on workers’ behaviour that are imposed by the physical context in which workers operate (Naikar et al., 2006). WDA is conducted at the functional, rather than behavioural level, defining the task environment in which activity is conducted. WDA was developed as a way of structuring information in terms of the means-ends links that form the relationships within a system (Rasmussen, 1985). The relationships capture the affordances of the system, what needs to be done and understanding the available means for completing these ends. Lintern (2006) has called this phase a design artefact because the systematic organisation of information supports the design process. Vicente (1999) recommends that the WDA phase is constructed using an Abstraction Decomposition Space and data are represented via an Abstraction Hierarchy (AH). The AH models a system at a number of levels of abstraction (see Fig. 1); at the highest level the overall Functional Purpose of the system is considered, followed by the Values and Priority Measures (criteria that the work system uses for measuring its progress towards the Functional Purpose). Next, the Purpose-Related Functions define the general functions of the work systems that are necessary for achieving the Functional Purpose, followed by the Object-Related Processes (functional capabilities and limitations of Physical Objects in the work systems that enable the Purpose-Related Functions). Finally, at the lowest level the Physical Objects describes the individual components within the system.The analysis was conducted with the CWA software tool developed by the Human Factors Integration Defence Technology Centre. The AH was populated via consultation sessions with four Subject Matter Experts (SMEs) who were experienced helicopter pilots and had worked in various operational contexts including the military, private passenger transport, and search and rescue. These sessions involved the construction of AHs assisted by experienced Human Factors researchers. This information was supplemented with documentation to support domain familiarisation including flight manuals, simulator observations and videos of DVE landing. The individual AHs were amalgamated into one representative AH (see Fig. 1) and was verified by a test pilot. The functional purpose captures the reason why the system exists. Here, the functional purpose of the situation is to ‘establish hover and land’ this encompasses the purpose of the situation as it is the prerequisite to ensure you are ready to land. The next level down, values and priority measures, captures the criteria that can be used to determine how well the system is achieving its functional purpose. To ensure a successful approach and maintenance of hover is achieved the values and priority measures were defined as; ‘aircraft altitude decreased’, ‘maximise smooth transition of aircraft’, ‘minimise time to conduct approach and hover’ and ‘avoid collisions and impact with hazards/third parties’. The middle level, purpose related functions, lists the functions that have the ability to influence one or more of the values and priority measures. They link the purpose-independent processes of the physical objects (described in the next level) with the more abstract measure of system performance (in the values and priority measures), thus joining the AH together. In this analysis the purpose related functions include; ‘aircraft performance’, ‘external conditions’, ‘third party activity’ and ‘pilotage’. In the second level from the bottom, the object-related processes (O-RP) capture the affordances that are provided by the physical objects (described below) in order to perform the purpose related functions. For example, the physical object of environmental markers (grass, trees etc.) affords knowledge of maintaining position, awareness of groundspeed, wind direction and strength, image of world and localisation of position. The lowest level, physical objects, lists the physical components of the system. For this analysis, physical objects consisted of any piece of information, internal or external to the cockpit, which enables the pilot to achieve the functional purpose. Fundamental cockpit objects such as seats, harnesses and windows all provide important affordances to the cockpit; however the analysis needs to be kept as manageable as possible so the boundary was set to omit them. Example physical objects include; windsock, weather report, compass, surface, radio altimeter, flight controls and airframe world references.Each level of the AH is linked together by means-ends links through the use of the how-what-why triad. Any node can be taken to answer the question of ‘what’ it does (e.g. ‘external conditions’ in the purpose related function level). The connected nodes in the level below answer the question of ‘how’ this can be achieved (e.g. ‘wind direction and strength’, ‘clearances’ ‘freedoms and constraints on flight’, ‘undercarriage motion feedback’ and ‘image of world’ in the object-related processes level). The level above the node answers the question of ‘why’ is it needed (e.g. ‘aircraft altitude decrease’, ‘maximise smooth transition of aircraft’, ‘minimise time to conduct approach and hover’ and ‘avoid collisions and impact with hazards/third parties’ in the values and priority measures).As described in the introduction, one of the objectives of future helicopter transport is to increase all conditions operational capacity to allow helicopters to operate in DVE thus increasing their operational effectiveness and their potential utility in the future transport system. Foyle et al. (1992) has argued that the challenge for Human Factors engineers is to design visual displays that represent the most useful visual cues that pilots most naturally use. The WDA undertaken focused on the situation of coming into an approach to maintain a hover in preparation for landing in a DVE. The tasks required to achieve the functional purpose of the system are represented by the O-RP and these need to be represented on the HUD to ensure it adequately facilitates the task. The HUD concept consists of the physical objects necessary to achieve the functions defined in the AH and is presented in Fig. 2. Table 1depicts the mapping between the object-related processes level of the AH and the symbology included on the HUD.The HUD contained the following 2D flight instruments: conformal compass, heading readout, airspeed indicator, conformal horizon line, attitude indicator, vertical speed indicator, air speed indicator, wind direction and strength indicator, and distance to go readout. To assist with the hover/landing task the HUD included the following elements:1.Flight path vector (acts as a touch down indicator, this becomes visible to the pilot when losing altitude, it represents the point on the ground they will hit if the current velocity is maintained) (item 1 in Fig. 2)3D augmented reality “tree” (these provide a visual reference point for the pilot when landing) (item 2 in Fig. 2)Arrows against the trees provide the pilot with visual references for height and speed as the aircraft is descending (item 3 in Fig. 2)Runway grid and runway markings (item 4 in Fig. 2)Obstacles (3D augmented reality used to represent obstacles and hazards such as gas towers shown as item 5 in Fig. 2)The HUD was intending to simulate the actual environment and therefore colours were chosen to reflect this, e.g. green for the trees and runway and blue for the horizon line. It is argued that traditional approaches to colour usage will be challenged in the next generation of aircraft cockpits because of the potential advances in technology (Biggin, 2011). However, in this HUD the use of colour was also aligned with accepted standards for the use of colour in cockpits, including keeping the colour palette as small as possible and conforming to colour stereotypes, such as red for warning and amber for caution (FAA, 2007). The descent arrows, obstacles and other indicators were magenta as this is a commonly used colour in the cockpit for this type of information symbology (Biggin, 2011).The study employed a 2 × 2 within-subjects design. The independent variables were weather condition (clear sky or DVE/fog) and symbology used (with or without the HUD). The order of presentation of the conditions was counterbalanced between the participants.Six male subjects aged 37–65 (mean = 51.00, SD = 10.29) were voluntarily recruited for the study via advertisement posters placed at local airfields and around the university campus. The sample size reflects the niche population that was selected from and recorded debrief sessions were conducted to maximise the data produced from a smaller sample size. All subjects were qualified, instrument rated, rotary wing pilots with varying amounts of experience; flying hours ranged between 108 and 8300 h (mean = 3804, SD = 3468). Pilots were recruited from a range of operational contexts including; Search and Rescue, private transport and the military. All participants had flown within a year of the study. The two military pilots (P1 and P6) had experienced using a HUD before, the other pilots had not. Ethical permission for this study was granted by the Research Ethics Committee at the University of Southampton and all subjects provided informed written consent. Participants were informed that simulator sickness was not likely to be an issue but they could stop the task at any point of they felt unwell. Simulator sickness was not explicitly monitored for, nor was it reported.A fixed-based flight deck simulation facility at the University of Southampton was used in its rotary wing configuration. The simulator comprises a two-seater cockpit (including external cabin) with five multi-function display units. The external screen is projected onto three screens providing an 180° degree field of view. Participants were seated in the right-hand seat as which was configured for the rotary wing controls. The simulated environment runs on Prepar3D (previously Microsoft flight simulator software). The flight scenario was located over a runway at the Norfolk naval base, Virginia, USA, using the Bell 206 flight model. The Prepar3D software is highly customisable and allowed the required weather conditions to be simulated. In the clear sky condition the clear weather setting was selected and in the DVE the highest fog setting was used (approximately 300 m visibility).Head down Display: The Head down display (HDD) was displayed to the pilots on the outer right multi-function display unit in the simulator. This was available to the pilots in all four conditions. The HDD was part of the Prepar3D software and consisted of analogue flight instruments for helicopters in a standard configuration, including: attitude indicator, airspeed indicator, a compass, heading indicator, altimeter, vertical speed indicator and torque indicator.Head up Display: The HUD concept (described in Section 2.3) was created using GL Studio. This is a software tool specifically developed for interface display design and provides the ability for its display instruments to be controlled from external applications (e.g. Prepar3D). A two-way data interface was developed to allow flight data to be transferred from Prepar3D and synchronised symbology to be transferred from GL studio. During the flight conditions with the HUD, the concept was overlaid onto the simulated environment using a ghost window application that is freely downloadable from the internet.Two questionnaires were administered after each experimental condition had been flown. The post-landing assessment (PLA) questionnaire was developed by an industry partner in the project funding this work. The questionnaire asks participants to rate their awareness of seven flight parameters (desired heading, desired rate of descent, desired groundspeed, power status, required landing point, drift and outside environment) from 1 (low) to 7 (high). These components represented different aspects of situation awareness under investigation. At the end of each flight a de-brief session was held so that the researchers could probe the pilots about reasons for their ratings on the PLA.The Bedford Workload Rating scale (Roscoe and Ellis, 1990) is an uni-dimensional mental workload assessment technique developed to assess pilot workload. The technique involves a hierarchal decision tree to assess workload via an assessment of spare capacity whilst performing a task. Participants follow the decision tree to derive a workload rating for the task under analysis (Stanton et al., 2013). A scale of 1 (low workload – workload insignificant) to 10 (high workload – task abandoned) is used.

@&#CONCLUSIONS@&#
