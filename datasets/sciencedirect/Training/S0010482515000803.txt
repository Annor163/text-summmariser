@&#MAIN-TITLE@&#
Automatic identification of oculomotor behavior using pattern recognition techniques

@&#HIGHLIGHTS@&#
Classification of three types of eye movements: saccades, blinks and fixations.Statistical features distinguish the three types of eye movements.Classification by a cascade of three classifiers with overall accuracy 95.9%.

@&#KEYPHRASES@&#
Saccades,Microsaccades,Blinks,Fixation,Classification,Neural network,Velocity threshold algorithm,

@&#ABSTRACT@&#
In this paper, a methodological scheme for identifying distinct patterns of oculomotor behavior such as saccades, microsaccades, blinks and fixations from time series of eye׳s angular displacement is presented. The first step of the proposed methodology involves signal detrending for artifacts removal and estimation of eye׳s angular velocity. Then, feature vectors from fourteen first-order statistical features are formed from each angular displacement and velocity signal using sliding, fixed-length time windows. The obtained feature vectors are used for training and testing three artificial neural network classifiers, connected in cascade. The three classifiers discriminate between blinks and non-blinks, fixations and non-fixations and saccades and microsaccades, respectively. The proposed methodology was tested on a dataset from 1392 subjects, each performing three oculomotor fixation conditions.The average overall accuracy of the three classifiers, with respect to the manual identification of eye movements by experts, was 95.9%. The proposed methodological scheme provided better results than the well-known Velocity Threshold algorithm, which was used for comparison. The findings of the present study indicate that the utilization of pattern recognition techniques in the task of identifying the various eye movements may provide accurate and robust results.

@&#INTRODUCTION@&#
Gesture, speech and eye movements are frequently analyzed by experts in order to explain human behavior. As a result, eye movements have enjoyed burgeoning attention in recent years as a tool for studying human behavior [1]. Perhaps the most important reason for their usefulness is that eye movements indicate the focus of visual attention although covert attention can be focused away from the point of visual fixation [2]. The eyes do not remain still when viewing a visual scene; they have to move constantly to build up a mental “map” from interesting parts of the scene [3]. The main reason for this is that only a small central region of the retina, the fovea, is able to perceive with high acuity.According to Leigh and Zee [4], four basic types of eye movements can be identified: (1) Saccades, that are fast voluntary movements, which bring the fovea in the region of interest within the visual field, (2) smooth eye pursuit, that involves a slow continuous movement of both eyes in order to follow a moving visual stimulus in the visual field, (3) vergence, that is the disconjugate slow movements of the eyes that converge or diverge in order to foveate an object in three-dimensional space, and (4) fixation, that is the inhibition of all eye movements which keeps the eyes locked on a particular location in the orbit. When fixing the gaze, there exist microscopic and unnoticed motions of the eye, called fixational eye movements. Furthermore, saccades can be divided into two distinct groups: major saccades, that are easily observed even with naked eye and minor saccades that are virtually unobservable without special instrumentation [5]. The smallest saccades, called ‘microsaccades’, are involuntary eye movements produced during attempted visual fixation. They are the largest and fastest of the fixation eye movements [6].Saccades have been extensively examined in normal vision towards the understanding of human behavior [7]. Apart from the study of normal vision, saccadic deviations have been also measured in special groups, such as patients with psychiatric disorders (such as attention deficit hyperactivity disorder (ADHD) and schizophrenia), young children and elderly people in an attempt to differentiate saccadic characteristics between those conditions and normal controls [8].Although eye movements have become increasingly popular as a tool for investigating behavior, the analysis of movements can be often extremely difficult and tedious [9]. A major objective for eye movement analysis could be the identification of the main eye movement types with no or minimal user intervention. Towards to this direction, eye movement characteristics have been analyzed in many studies and the visual behavior during specific tasks has been successfully modeled in an automatic manner. In [10], an analysis of eye movement using tracing methods in three conditions (equation solving, reading and gaze-based interfaces) from seven participants has been conducted. In order to identify fixation points and saccades, methods based on sequence-matching and Hidden Markov Models were used, resulting in identification of eye movements as accurately as human experts, but in significantly less time with an overall accuracy ranging between 87.5% and 93.7%. In another study, machine learning methods were used to improve the accuracy of detecting Mild Cognitive Impairment (MCI) in 60 participants, by modeling eye movement types such as fixations, saccades, and re-fixations during the Visual Paired Comparison task [11]. The features used were the fixation duration, re-fixations, saccade orientation and the pupil diameter which were fed as inputs to a Support Vector Machine (SVM) classifier. Using this classification algorithm, age-matched normal control subjects were distinguished from MCI subjects with an overall accuracy of 87.0%.In a recent study, a set of 90 features, that describe the eye movement data, were collected from 10 participants under five activities: copying a text, reading a printed paper, taking hand-written notes, watching a video, and browsing the web [12]. The features included, among other, the mean and the variance of the saccade signal amplitude, the maximum electro-oculographic (EOG) signal amplitudes, the rate of small or large saccades, and the positive and the negative saccades in horizontal or vertical direction. These features were ranked and evaluated using the minimum redundancy maximum relevance feature selection method along with an SVM classifier in order to automatically discriminate these five activities resulting in 80.2% overall accuracy. In [13] a new velocity-based algorithm that makes the saccade detection less sensitive to variations in noise level was suggested. The algorithm includes a data driven threshold for peak and saccade onset/offset detection, an adaptive threshold adjustment based on local noise levels, physical constraints on eye-movements to exclude noise and new recommendations for minimum allowed fixation and saccade duration. The algorithm detects saccades and postsaccadic oscillations in the presence of smooth pursuit movements with 92.0–96.0% specificity and 80.0–90.0% sensitivity. In another study, a method for the detection of saccades, blinks, postsaccadic oscillations and fixations in the acceleration domain was presented [14]. The method was a two-step procedure that involved the identification of approximate saccadic intervals and saccadic onset and offset detection. The method was applied on eye-tracking signals from 33 subjects that performed three different tasks and provided sensitivity between 66.7% and 97.8% and specificity between 82.8% and 99.9%. In another study, the development of robust and accurate microsaccade detection techniques was presented, based on unsupervised clustering techniques [15]. The new clustering method validated using an eye-movement database included recordings from 20 adult subjects (12 men, 8 women) with normal or corrected-to normal vision that maintained fixation on a centrally presented target, and simulated eye-movement data. The clustering method compared other microsaccade-detection techniques conclude to higher performance both for binocular and monocular data. The median error rate in the method proposed in [16] was 0.25 errors per second, while the median error rate in the clustering method was 0.1 errors per second. The sensitivity of detecting microsaccades for both methods is more than 75%, using manual labeling as the gold standard. Also, in [17], participants were asked to fixate a small dot on a computer display and microsaccades were detected in two dimensional velocity space by using thresholds for peak velocity and a minimum duration, implemented as an improved version of an algorithm proposed earlier [16].The purpose of the proposed study was to develop a methodology for the automatic classification of eye movements of healthy individuals into four categories: saccades, microsaccades, blinks and fixation. Towards this direction, 2335 oculomotor signals from 1392 individuals have been processed, in order to automatically identify specific characteristics of the saccadic eye movements [18]. The proposed methodology involves an array of three neural network classifiers: the first classifier discriminate blinks from non-blinks, the second one separates fixation from all types of saccades and finally the third one which differentiates microsaccades from major saccades. To our knowledge, it is the first attempt towards the automatic identification of different types of eye movement characteristics, including saccades and microsaccades, from a very large database of oculomotor signals.This study used the oculomotor dataset from the ASPIS sample (Athens Study for Psychosis Proneness and Incidence of Schizophrenia) according to Smyrnis et al. and Evdokimidis et al. [18,19]. A sample of 1778 young male subjects aged 18–24 years were recruited from the Greek Air Force. These agreed to participate in the study after giving written informed consent. These individuals performed a battery of eye movement tasks (smooth eye pursuit, saccade, antisaccade, visual fixation) and cognitive tasks and they also completed questionnaires for a detailed psychometric analysis. Each subject from the ASPIS sample has been codified with a unique number code. The correlation between the subjects and the codes has been destroyed. The subject׳s horizontal eye movements (angular displacement) were recorded from the right eye only using the IRIS SCALAR infrared device (spatial resolution: 2min of arc) [19]. A chin rest was used to stabilize the head. A 12-bit A/D converter was used for data acquisition (Advantech PC-lab Card 818L). The data were sampled at 600Hz, providing 30,000 samples for time duration of 50s.The participants performed three fixation conditions [19]. In the first fixation condition, the participants were instructed to simply fixate a visual target on the center of the computer monitor (white cross0.3°×0.3°) for 50s. In the second fixation condition, the participants were asked to fixate again a central target and ignore targets that might appear to the right or the left. For each trial four distracting targets were used; two small,0.3°×0.3°white crosses and two large,0.1°×0.1°crosses, each presented for 500ms at random intervals during the 50-s fixation period. The distracting targets could appear at a random distance of2°−9°and a random direction at left or at right from the center. Finally, in the third fixation condition, the participants were asked to keep their eyes fixating in the primary position (straight ahead) in front of a black screen and avoid making eye movements.Before each active fixation condition, a calibration procedure was performed that consisted of saccadic movements at targets located10°to the right and left of a central fixation target (seeFig. 1a). In some cases, due to the motion of the individual and/or the instability of the device that was placed on the participant׳s head, the calibration signal was corrupted by noise (see Fig. 1b). The signals from these participants were excluded from the study. Furthermore, there were cases that the calibration signals were not corrupted by noise but the recorded signals presented a strong noise component (Fig. 1c). These noisy signals were smoothed using a bandpass filter as it is presented in Fig. 1d.A total set of 2335 oculomotor signals from 1392 individuals were finally selected for further analysis. Two experts of Eginition Hospital in Athens (Smyrnis and Evdokimidis) identified the types of the eye movements in a set of signals by visual examination. The experts marked the “center” point of each type of eye movement (blinks, saccades and microsaccades). Then, a window of proper size was centered at each marked point (seeFig. 2) and the corresponding signal segment was extracted for subsequent analysis.Thus, for the blinks or (micro)saccades the positions of the time windows were not overlapped. Two time windows W1 and W2 are used for the detection of blinks and saccades/fixations, respectively. Furthermore, for each saccade identified by the experts, the segments of the signal of length W2 that lie just before and after the saccade were selected as fixations. Since the duration of blinks is usually larger (100–400ms) [20], than the duration of saccades (6–300ms) [6], the length of the windows W1 and W2 is set to 400ms (corresponding to 240 data samples) and 13ms (corresponding to 8 data samples), respectively. In total, from the 2335 available signals, 16,012 time intervals (200ms before the center point and 200ms after were selected) containing blinks and 316,612 time intervals (6.5ms before the center point and 6.5ms after were selected) containing saccades and microsaccades were identified from the experts.The proposed methodological scheme for the classification of three types of eye movements, consists of three main processes (seeFig. 3):a)Preprocessing.Feature Extraction.Classification using Artificial Neural Networks.This module aims to (a) to remove linear trends (detrending) from the recorded signals, and (b) calculate the angular velocity of the detrended signals. A linear trend typically indicates a systematic increase or decrease in the data. A systematic shift can result, for example, from sensor drift. Analysis focusing on short-term fluctuations of the data requires removal of trends in order to improve the results, as is the case in the present study. The most common detrending process, which was adopted in the present study, usually consists of removing the linear trends (seeFig. 4).It has been observed that the distribution of the velocity of eye׳s movement, namely the time derivative of the angular deviation, is characterized by two distinctive peaks: one peak for low velocities (less than 100°/s) that corresponds to fixations and one peak for high velocities (larger than 300°/s) that corresponds to saccades [10]. This fact provides a sufficient discrimination of saccadic eye movements from other types of eye movements based on velocity. The velocity is computed as the (angular) distance between the current point and the next (or previous) point, divided by the time difference between samples [21]. Analytically, since the recorded data measure the angular deviation of eye, a(t), the angular velocity of the eye movement, ω(t), at a given time t, is given by the first derivative of the angular deviation:(1)ω(t)=da(t)dtThe first derivative must be estimated robustly, taking into account that eye-movement data often include much smaller eye movements (tremor, drifts and flicker) than those related to the phenomena that are to be investigated in the present study. These small eye movements will introduce fluctuations in ω(t) that will severely hamper the subsequent analysis, thus these fluctuations have to be discarded. Therefore, the signal a(t) was firstly smoothed by means of the convolution with a smoothing kernel, h(t) and then the derivative of the smoothed version was computed:(2)ω(t)=d(α⁎h)(t)dt=(α⁎dhdt)(t)where ⁎ denotes convolution.In this study, the Gaussian kernel was used:(3)h(t)=12πσe−(t2/2σ2)where the parameter σ determines the level of the smoothing. After experimentation, σ=1 was selected as the most appropriate value of the parameter. The velocity signal for different values of σ is presented inFig. 5. As can be seen in Fig. 5a and b, low values of the parameter σ result to noisy signals, which is a drawback in identification of onset/offset of saccades. On the other hand, high values of the parameter σ result in excessively smoothed signals, as it is shown in Fig. 5d, so microsaccades are misinterpreted as fixation. In Fig. 5c, the velocity signal is calculated using the parameter value σ=1, resulting in a smoothed signal with more transparent differences between the types of eye movement.The angular velocity of the detrended signal is shown inFig. 6, where the experts have identified different types of eye movements such as blinks (labeled with numbers 1, 2 and 3) as well as saccades (labeled with number 4). As can be observed from Fig. 6, blinks are clearly visible both in the detrended angular deviation and the angular velocity. A typical characteristic of a blink is the short coherence of two large peaks in the recorded signal: one positive and one negative. However, the discrimination between saccades and blinks is not often too obvious. For example, in the signal presented in Fig. 6, in spite of the high angular deviation of the eye (number 4 in Fig. 6a), the duration of this movement exceeds the average length of a blink that is 100–400ms [20]. Such parts of the signal are considered as a sequence of saccades (number 4 in Fig. 6b).Finally, inFig. 7, the angular deviations (a–c) and the corresponding angular velocity signals (d–f) are given for three different types of eye movements such as blinks, saccades and fixation points, as identified by the experts.The first step towards the accurate discrimination of the different types of eye movements is the computation of relevant features from the angular deviation and velocity signals. Initially, two time windows, W1 and W2 that slide over each signal (deviation or velocity) are used. Then, for each signal and for each position of these windows over a signal, seven (7) features are computed:1)Max value, referred to the maximum value of the angular deviation signal and the maximum value of the angular velocity signal.Mean value, which is the average value of each signal according to:(4)x¯=1n∑i=1nxiwherexi,i=1,2,…,nare the sample values of the signal (angular deviation or velocity) and n is the number of the signal values.Standard deviation, which is a measure of the dispersion of a set of dataxifrom its meanx¯according to:(5)σ^=∑i=1n(xi−x¯)2n−1Kurtosis, which measures the relative peakedness or flatness of the distribution of signal values. It is defined as the fourth statistic moment of the distribution of the data, according to the following equation:(6)K=1n∑i=1n(xi−x¯σ^)4Skewness, which is a measure of the asymmetry of distribution of the signal values around the sample mean. If the skewness is negative (positive), the data are spread out more to the left (right) of the mean than to the right (left). The skewness of the normal distribution (or any perfectly symmetric distribution) is zero. The skewness of a distribution is defined as follows:(7)S=1n∑i=1n(xi−x¯)3σ^3The energy of the signal, which is defined as follows:(8)Es=∑i=1n(xi)2The entropy, which is a measure of uniformity of the distribution of the values of the signal:(9)H(x)=−∑k=0M−1pklog2pkFor the Gaussian kernel, it can be shown [23] that the optimal choice forhis:(12)h=(4σ^53M)15≈1.06σ^M−1/5whereσ^is the standard deviation of the samples.The features estimated using the time windows W1 and W2 are used for the detection of blinks (saccades and fixation intervals).The classification of eye movements is achieved using an array of three Artificial Neural Networks (ANN) classifiers. An ANN is an information processing system, which contains a large number of highly interconnected processing units called neurons. These neurons work together in a distributed matter to learn from the input information, to coordinate internal processing and to optimize their final output [24]. The four eye movements of interest are blinks, saccades, micro-saccades and fixation (no movement), where microsaccades are saccades with amplitude less than0.5°[25]. Since there are four movements of interest, a hierarchical structure containing three binary classification levels is used, as shown inFig. 8.The first classifier discriminates between non-blinks (class C1,1) and blinks (class C1,2). The non-blinks dataset contains saccades or fixations. The feature vectors for the blink and non-blink datasets are computed using the window W1. If a non-blink is detected, the second classifier is activated, which discriminates between non-fixation (class C2,1) and fixation (class C2,2). The non-fixation dataset contains saccades and microsaccades. The feature vectors for the fixation and non-fixation datasets are computed using the window W2. Finally, if a non-fixation is detected, the third classifier is applied in order to discriminate between saccades (class C3,1) and microsaccades (class C3,2).Each classifier is implemented as a feed-forward neural network with one hidden layer and one output (seeFig. 9). After experimentation, the optimal number of neurons in the hidden layer was considered to be 10 and the maximum number of training epochs was equal to 1000. Trials were conducted for the choice of the optimal number of neurons in the hidden layer. Each classifier consists of one hidden layer with 5, 10, 15 and 20 neurons. A subset of the dataset is used as input to each classifier and the variations of the performance were observed. Specifically, the performance of each classifier presents lower values when the number of the neurons was 5, while the performance presents small variations when the number of neurons was 10, 15 or 20. In order to eliminate the complex, 10 neurons were used in this study. The output layer consists of one neuron, encoding the two classes. The output values are between 0 and 1, values below 0.5 classified in class1 and values below 0.5 are classified into class 1 and values above 0.5 are classified into class 2. In order to avoid overtraining, each classifier is implemented as a feed-forward neural network with one hidden layer and one output and achieves an accepted generalization in the classification, three data sets were selected: training set, validation set, and testing set. Each ANN was trained using the training set and the weights corresponded to the epoch that the best performance was achieved on the validation set were saved.Each classifier was trained 10 times, using the scaled conjugate gradient backpropagation algorithm, with different, randomly selected training, validation and testing sets [26]. The training sets comprised feature vectors from 60% of the available signals, namely 1401 signals. The feature vectors from the rest 20% of the signals (467 signals) were used for validation purposes during the training and the feature vectors from the final 20% of the signals (467 signals) were used for testing each neural network. Since each signal contained different number of blinks and saccades, the size of the training, validation and testing sets varied between runs. For the first classifier (blinks vs. nonblinks), 649,236 feature vectors were totally, extracted using window W1. In particular, the average number of the training feature vectors were 405,738 for blinks and non-blinks, the average number of the testing feature vectors for the class C1,1 (non-blinks) was 118,791 and for the class C1,2 (blinks) was 2958. For the second classifier (fixation vs. non fixation), 633,224 feature vectors, extracted by means of window W2, from the time intervals that did not contain blinks. The average number of the training feature vectors was 413,122 feature vectors, whereas the average number of the testing feature vectors for the class C2,1 (non-fixation) was 21,456 and for the class C2,2 (fixation) was 88,595. Finally, for the third classifier (saccades vs. microsaccades) 127,750 feature vectors, using window W2, from the time intervals that did not contain blink or fixation, were used. The average number of the training feature vectors was 76,650 feature vectors, the average number of the testing feature vectors for the class C3,1 (non-microsaccades) was 12,267 and for the class C3,2 (microsaccades) was 13,283.The sensitivity and specificity of each type of eye movement are calculated as:Sensitivity=NumberoffeaturevectorsofeyemovementclassifiedcorrectlyTotalnumberoffeaturevectorsofeyemovementSpecificity=NumberoffeaturevectorsofothereyemovementsclassifiedcorrectlyTotalnumberoffeaturevectorsofothereyemovementsSpecifically, the performance of each classifier was assessed by means of the following measures:•Specificity for classifier i, SPECi=100×Mi,1/Ni,1Sensitivity for classifier i, SENSi=100×Mi,2/Ni,2Overall Accuracy for classifier i, ACCi=100×(Mi,1+Mi,2)/(Ni,1+Ni,2)

@&#CONCLUSIONS@&#
In this study, an automatic classification methodology for identifying various types of eye movements was presented. The accuracy of the proposed methodology for the various discriminations tasks and fixation conditions was above 87.2%, indicating that it could be used for supporting the evaluation of oculomotor signals. Due to the simplicity of the automatic proposed methodology and the fast execution time, it could be used easily used in clinical practice, making feasible its future integration in clinical routine in real-time implementations.None declared.