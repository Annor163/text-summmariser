@&#MAIN-TITLE@&#
Vision-based endoscope tracking for 3D ultrasound image-guided surgical navigation

@&#HIGHLIGHTS@&#
A camera tracking method by combining 3D ultrasonography with endoscopy is proposed.This self-contained framework does not require any external tracking devices.It addresses potential issues in conventional visual tracking for fetoscopy.Endoscope tracking ability was demonstrated in phantom and ex vivo placenta imaging.Potential contribution may extend to other minimally invasive procedures.

@&#KEYPHRASES@&#
Vision-based tracking,Surgical navigation,Ultrasound imaging,Endoscopy,Minimally invasive fetal surgery,

@&#ABSTRACT@&#
This work introduces a self-contained framework for endoscopic camera tracking by combining 3D ultrasonography with endoscopy. The approach can be readily incorporated into surgical workflows without installing external tracking devices. By fusing the ultrasound-constructed scene geometry with endoscopic vision, this integrated approach addresses issues related to initialization, scale ambiguity, and interest point inadequacy that may be faced by conventional vision-based approaches when applied to fetoscopic procedures. Vision-based pose estimations were demonstrated by phantom and ex vivo monkey placenta imaging. The potential contribution of this method may extend beyond fetoscopic procedures to include general augmented reality applications in minimally invasive procedures.

@&#INTRODUCTION@&#
This work is motivated by the clinical need for surgical navigation in minimally invasive fetal surgery, as well as the operational limitations of existing techniques. One example of minimally invasive fetal surgery is the treatment of twin-to-twin transfusion syndrome (TTTS) [1]. This condition is life-threatening and must be treated before birth, typically between 17 and 26 weeks of gestation [2,3]. To minimize medical complications from a large uterine incision, minimally invasive fetal endoscopic surgeries have been introduced [4,5]. However, minimal access to the surgical site results in limited visibility and dexterity.Therefore, it is important to equip surgeons with surgical navigation technologies that ease the operational constraints of minimally invasive fetoscopic surgery. Positional information and spatial awareness are important prerequisites for most, if not all, surgical navigation applications. To address this need, a self-contained method that combines 3D ultrasonography and endoscopy for fetoscopic camera tracking is proposed in this work.A wide range of research and development efforts have focused on instrument tracking in minimally invasive procedures. However, applying existing state-of-the-art techniques to fetoscopic procedures and endoscopic tissue imaging remains challenging. In this section, we will discuss some popular options and their limitations for fetoscopic procedures.A common approach for instrument localization is to use optical tracking systems [6–8]. These external localization systems usually require an appropriately equipped operating theater and a team of specialized technical personnel to support the operation. In addition, they are associated with certain operational constraints. For example, lines-of-sight between the optical tracker and markers must be cautiously maintained by the surgical team to avoid disrupting the tracking process [9]. Previous studies [10–12] on surgical navigation applications in fetal surgery have used optical tracking systems for instrument localization that require the attachment of markers to surgical instruments and registration between multiple coordinate systems.While electromagnetic trackers do not require strict maintenance of lines-of-sight, they are prone to noise, especially in a modern operating room that is filled with electronic devices. To address unstable performances due to noise, multisensor data fusion using an electromagnetic tracking device and an inertia measurement unit (IMU) attached to the surgical tool being tracked has been proposed [13]. The use of an IMU has also been commonly applied to the sub-task of orientation tracking [14]. This approach is an attractive option for the development of low-cost tracking applications. However, it remains challenging in practice because of issues related to tracking initialization, drift errors, and accuracy. In addition, an instrument can only be tracked when it is equipped with the tracking sensors and properly calibrated.Apart from tracker-based approaches, vision-based tracking for surgical navigation has also been studied extensively [15]. The relevant options for our application include those that exploit the simultaneous localization and mapping (SLAM) framework to solve tracking as a Structure-from-Motion (SfM) problem [16–18]. Shape-from-Shading methods [19] are not suitable for fetoscopic imaging due to the unpredictable characteristics of the amniotic medium and the need to minimize illumination, which may be harmful to the fetus's eye. Although this method offers an elegant solution that is free from most of the operational limitations associated with external sensors, vision-based camera tracking alone is inadequate for our application. In addition to the issue of initialization, the absence of rich texture in fetoscopic placental imaging also makes it extremely challenging to acquire sufficient feature points for accurate pose estimation. This problem is further exacerbated by the close proximity of the camera and scenes during fetoscopic procedures.A self-contained tracking framework that exploits information from ultrasound and endoscopic imaging is proposed in this study. The designed approach is based on ultrasound image-based localization to register the initial camera position with its scene geometry, followed by subsequent vision-based tracking. This development is relevant to the application of surgical navigation in ultrasound image-guided fetoscopic procedures.

@&#CONCLUSIONS@&#
