@&#MAIN-TITLE@&#
Pattern Matching based Classification using Ant Colony Optimization based Feature Selection

@&#HIGHLIGHTS@&#
The underlying principle of PMC is that it classifies by matching patterns.The advantage of PMC is its simple classification procedure with high performance.To improve classification accuracy, ACO based Feature Selection for PMC is proposed.Experimental results show that PMC is competent with many instance based classifiers.PMC has less evaluation time when compared to the gravitation based methods.

@&#KEYPHRASES@&#
Classification,Pattern matching,Feature selection,Ant Colony Optimization,

@&#ABSTRACT@&#
Classification is a method of accurately predicting the target class for an unlabelled sample by learning from instances described by a set of attributes and a class label. Instance based classifiers are attractive due to their simplicity and performance. However, many of these are susceptible to noise and become unsuitable for real world problems. This paper proposes a novel instance based classification algorithm called Pattern Matching based Classification (PMC). The underlying principle of PMC is that it classifies unlabelled samples by matching for patterns in the training dataset. The advantage of PMC in comparison with other instance based methods is its simple classification procedure together with high performance. To improve the classification accuracy of PMC, an Ant Colony Optimization based Feature Selection algorithm based on the idea of PMC has been proposed. The classifier is evaluated on 35 datasets. Experimental results demonstrate that PMC is competent with many instance based classifiers. The results are also validated using nonparametric statistical tests. Also, the evaluation time of PMC is less when compared to the gravitation based methods used for classification.

@&#INTRODUCTION@&#
Machine learning is the development of algorithms that allow computers to learn based on empirical data. The goal of Machine learning is to build computer systems that adapt and learn from their experience. Machine learning can be either supervised or unsupervised. An example of supervised learning is classification. It is defined as the task of learning from instances described by a set of features (attributes) and a class label. The result of learning is a classification model that is capable of accurately predicting the class label of unlabelled samples.Several algorithms such as artificial neural networks [28], decision tree, support vector machines (SVMs) [42], instance based learning methods [1] and nature-inspired techniques such as genetic programming [10] have been proposed in literature for classification. Among these, decision tree, back-propagation network (BPN) and SVM classifiers are popular, and can be applied to various areas [7,21]. However, choosing the best kernel function is necessary for SVM. The usually preferred kernel function is Radial Basis Functions (RBF). RBF gives optimal performance only when the parameters are set properly. Lin et al. [23] adopted a simulated annealing approach and a particle swarm optimization approach for parameter setting and feature selection for SVM. However, SVM and BPN classifier does not handle missing values effectively [35].Linear Discriminant Analysis (LDA) is a commonly used classification method. It can provide important weight information for constructing a classification model. LDA often suffers from the small sample size problem when the number of dimensions of the data is much greater than the number of data points. Lin et al. [34] have proposed a particle swarm optimization (PSO) method to enhance the classification accuracy of LDA. However this method is sensitive to parameter settings.Although many classification algorithms exist in literature, instance based methods are attractive due to its simplicity. The Nearest Neighbor (NN) algorithm [6] is an instance based method which employs a simple classification procedure. Neighborhood based methods are attractive primarily due to their simplicity and good performance. However, the major problem with these methods is that they severely deteriorate with noisy data or high dimensionality, their performance becomes very slow, and their accuracy tends to deteriorate as the dimensionality increases, especially when classes are not separable or they overlap [22].In recent years, new instance based methods have been proposed to overcome the drawbacks existing in NN classifiers. One such approach is Data Gravitation based Classification (DGC) proposed by Peng et al. [32,40,44]. The basic principle of DGC algorithm is to classify data samples by comparing the data gravitation between the different data classes [32]. The algorithm creates data particles using the maximum distance principle. However, the drawback of this method is that it reduces the accuracy, especially in the area away from the data particle centroid and along the border between classes [2]. Cano et al. [2] have proposed another instance based method called Weighted Data Gravitation based Classification (DGC+) and is proved to achieve greater classification accuracy than DGC approach [32]. However, the computational complexity of DGC+ is considerably higher. To overcome the drawbacks existing in NN classifiers and gravitation based models, a simple instance based algorithm based on pattern matching is proposed.In this paper, a novel instance based algorithm called Pattern Matching based Classification (PMC) is proposed to classify unlabelled samples based on the similarity between the feature values of the instances in the dataset and the unlabelled sample. PMC classifies the unlabelled samples by matching the features of the unlabelled sample with that of the features of the instances in the dataset. The instances in the dataset having the maximum number of matching features are grouped. PMC votes for the majority class label in the group to classify the unlabelled sample. A probabilistic approach is used to predict the target class of the unlabelled sample when more than one class label have the same majority. To improve the classification accuracy of PMC algorithm, an Ant Colony Optimization based Feature Selection approach based on the idea of PMC is used.Experiments have been carried out on 35 data sets collected from the KEEL [3] and UCI [12] repositories. The experiments have been carried out for different problem domains, number of instances, attributes, and classes. It is shown that PMC is competent with the recent instance based algorithms obtaining significantly better results in terms of predictive accuracy and Cohen's kappa rate [4,5]. The result of statistical analysis such as Iman and Davenport test [24] and Bonferroniâ€“Dunn tests [9,14,33] show that there are significant differences in the results of the algorithms. Also, the computational complexity of PMC algorithm is less when compared to the gravitation based approaches such as DGC+ and DGC.The paper is organized as follows. Section 2 presents the related work. Section 3 describes the proposed PMC algorithm. Section 4 describes the feature selection for PMC. Section 5 describes a case study. The experimental study is described in Section 6. Section 7 describes the results of the experiments. The time performances of PMC, DGC+ and DGC are compared in Section 8. Section 9 presents the discussion and Section 10 presents some concluding remarks.

@&#CONCLUSIONS@&#
