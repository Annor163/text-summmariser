@&#MAIN-TITLE@&#
A bifurcation identifier for IV-OCT using orthogonal least squares and supervised machine learning

@&#HIGHLIGHTS@&#
The second automated approach to classify hundreds of coronary OCT frames as bifurcation or nonbifurcation.An important step to improve studies of atherosclerotic plaques in bifurcation regions.Geometrical features of vessel cross-section are selected by orthogonal least squares method.The lumen segmentation is comparable to measurements provided by other methods in the literature.

@&#KEYPHRASES@&#
Optical coherence tomography,Segmentation,Intravascular,Classification,Orthogonal least squares,Bifurcation,Machine learning,

@&#ABSTRACT@&#
Intravascular optical coherence tomography (IV-OCT) is an in-vivo imaging modality based on the intravascular introduction of a catheter which provides a view of the inner wall of blood vessels with a spatial resolution of 10–20μm. Recent studies in IV-OCT have demonstrated the importance of the bifurcation regions. Therefore, the development of an automated tool to classify hundreds of coronary OCT frames as bifurcation or nonbifurcation can be an important step to improve automated methods for atherosclerotic plaques quantification, stent analysis and co-registration between different modalities. This paper describes a fully automated method to identify IV-OCT frames in bifurcation regions. The method is divided into lumen detection; feature extraction; and classification, providing a lumen area quantification, geometrical features of the cross-sectional lumen and labeled slices. This classification method is a combination of supervised machine learning algorithms and feature selection using orthogonal least squares methods. Training and tests were performed in sets with a maximum of 1460 human coronary OCT frames. The lumen segmentation achieved a mean difference of lumen area of 0.11mm2 compared with manual segmentation, and the AdaBoost classifier presented the best result reaching a F-measure score of 97.5% using 104 features.

@&#INTRODUCTION@&#
Optical coherence tomography (OCT) is an imaging modality based on the technology of low-coherence interferometry. This technology has many similarities with ultrasound imaging, but instead of sound, it uses the scattering of electromagnetic radiation as the signal source. Intravascular optical coherence tomography (IV-OCT) is an in-vivo application of OCT based on the introduction of an intravascular catheter for viewing the inner wall of blood vessels. IV-OCT has many advantages over other modalities such as intravascular ultrasound, due to a superior resolution of 10μm to 20μm, which allows the visualization of tissues at the microscopic scale [1]. Several past studies evaluated the utility of IV-OCT [2,3], and analyzed the differences between IV-OCT and intravascular ultrasound (IVUS) [4]. The acquisition and analysis of vessel images by IV-OCT enable new applications such as the development of automated techniques for lumen area quantification, tissue characterization, and atherosclerotic plaques analysis.Zarins et al. [5] and Ingebrigtsen et al. [6] show the correlation between bifurcation regions and presence of plaques. Consequently, Gonzalo et al. [7] and Dilleti et al. [8] developed methods to analyze coronary atherosclerotic plaques at bifurcation using IVUS and IV-OCT. In these methods, the selection of the slices inside bifurcation regions were manually performed based on the longitudinal view. Moreover, automated methods for plaque characterization were developed, but without any automated slice selection [9,10].Based on Diletti et al. [8] and Gonzalo et al. [7], the importance of the bifurcation region is established and consequently other related areas are emerging as computational methods to bifurcation identification. In fact, there are several papers relating to the development of computational methods in lumen segmentation [11], stent strut detection [12] and more recently tissue characterization [9] in IV-OCT. These methods are semi or fully automated, enabling a huge quantity of information to be dealt with, as hundreds of frames need to be analyzed per patient. Considering that manual tasks involved in the analysis of a large amount of data are very time-consuming and operator dependent, the classification of each frame as belonging to either a bifurcation or nonbifurcation group could benefit automated methods such as, stent analysis [13], plaque analysis [7,8] and co-registration between different modalities [14].Some studies have already developed automated methods for bifurcation identification: Alberti et al. [15] extracted a set of textural features from intravascular ultrasound (IVUS) image sequences and used supervised machine learning methods for bifurcation identification; For 3D vascular images, Zhao and Hamaneh [16] used a Random Forest (RF) classifier to identify bifurcations by geometrical features; And recently, Wang et al. [17] proposed an automated method to identify bifurcation slices for IV-OCT images using the distance between lumen center and lumen contour as a bifurcation indicator.We propose a fully automated method to distinguish frames as bifurcation or nonbifurcation for IV-OCT data sets using geometrical features and supervised machine learning methods. This method is based on: (i) automatic lumen contour detection, (ii) feature selection using the orthogonal least squares method, and (iii) supervised machine learning method. As benefits, the proposed method results in the lumen area quantification and geometrical characteristics for each cross-section lumen besides the labeled slices. On the other hand, a critical aspect of this work is dependence on the accuracy of lumen detection, which must be completed prior to classification. While it is possible to use automated lumen detectors already published [11,12,18,19], we propose a new automated lumen detector to assist the principal method. The results of our proposed lumen detector are comparable to other published methods and, additionally, we used data sets of very challenging conditions and characteristics, such as residual blood in the lumen, complex lesions and dissections.Once the features had been extracted from the images, we performed several tests to compare three discriminative state-of-the-art classifiers: AdaBoost (AB), Random Forest (RF), and Support Vector Machine (SVM). Furthermore, based on a preliminary study of our group [20], optimized feature selection methods were used to choose the most critical features with the aim of minimizing the number of feature dimensions used by the classifiers and reducing processing time: Forward Regression Orthogonalized Least Squares (FROLS) and Multiple FROLS (MFROLS) [21].A set of nine IV-OCT sequences of coronary arteries of in-vivo patients was tested, totaling 1460 frames, 178 of them being frames in a bifurcation region. Evaluations were performed in which: (i) automated method of lumen segmentation was compared with a manual segmentation by an expert; (ii) classification was evaluated with three different supervised methods plus one feature selection method.This paper is organized as follows: (a) Section 2 details the proposed method for lumen segmentation and the input data; b) feature extraction and the bifurcation detection are explained in Section 3; (c) the training phase and validation are detailed in Section 4; (d) results are shown in Section 5; (e) the discussion in Section 6; and (f) finally, our conclusions are shown in Section 7.The series of human IV-OCT images showing the cross section is acquired and submitted for the bifurcation detection method, which is divided into 3 parts as shown in Fig. 1. First, the lumen contour is determined using a mathematical morphology approach. Next, geometrical features are extracted and finally features are selected and a supervised classifier used to establish a label for each frame in the series of IV-OCT. Various tests are made to choose the best set of characteristics and type of classifier, including three state-of-the-art classifiers (AdaBoost, Random Forest and SVM).Images were acquired using a Fourier-Domain OCT (FD-OCT) system (C7-XR - OCT Intravascular Imaging System, St. Jude Medical, St. Paul, Minnesota) at the Heart Institute, University of Sao Paulo Medical School (INCOR-HC FMUSP). The study protocol was approved by the institutional review board (CAPPesq) under register n. 0243/08. The system was equipped with a Dragonfly catheter with a diameter of 0.90mm, a Guide Wire (GW) with a maximum outer diameter of 0.3556mm (ImagewireTM, LightLab Imaging), and working length of 135cm. Pullback speed was 20 mm/sec over a distance of 54.0mm, giving a total of 271 frames. We analyzed the frames from 9 pullbacks of 9 different patients immediately before stenting. In all data sets we had observed the presence of plaques and dissections. Table 1shows the characteristics of patients and the type of coronary arteries used to test the proposed method. The input images to the proposed method were in DICOM format with dimensions 1024×1024×271 pixels and spatial resolution of 10μm×10μm×200μm, in Cartesian coordinates.From these nine data sets, we discarded the corresponding frames of the trunk blood vessel and three different sets of frames were determined for the evaluation method. Set 1 has 1355 frames and is composed of frames absent of difficulties such as complex atherosclerotic lesions, presence of blood inside the lumen, and dissections. Set 2 has 1433 frames and is composed of all frames from Set 1 plus complex atherosclerotic lesions and dissections. Finally, Set 3 has 1460 frames and is composed of all frames from Set 2 plus frames with residual luminal blood. All the difficulties described above can cause inaccuracies in lumen detection and confuse the classifier with irregular geometries that have plaques and dissections. Table 2shows the number of frames and the characteristics in each frame set, dividing the frames in nonbifurcation region (NBR) and bifurcation region (BR).The lumen contour from each IV-OCT frame was obtained after pre-processing and lumen detection, as shown in Fig. 2. The pre-processing stage includes the removal of speckle noise, catheter and the guide-wire from the image. In the lumen contour detection, a set of operations including A-lines sweeping is used to find high gradients in the intima layer.For each IV-OCT frame, a pre-processing sequence was performed to remove speckle noise, catheter and guide wire.(a) Polar coordinates: The 2D input image is provided in Cartesian coordinates, showing the artery walls in a circular shape. However, the polar coordinates support the removal of radial structures and reduce the image to a determined width of 360 pixels (angle), which facilitates the standardization of the segmentation method. For these reasons, the proposed method considers the image representation in a polar coordinates system, where rows and columns in a single frame correspond to angle and radius. Let Ipbe the polar image and Icthe Cartesian image. Each pixel at Ipis then defined as:(1)Ip(θ,ρ)=Ic(cx0+ρcos(θ),cy0+ρsin(θ))where cx0 and cy0 are the center of the image Icand ρ is the radius and θ is the angle, coordinates of the polar image.(b) Removal of Catheter: Our catheter segmentation technique exploits the fact that the Dragonfly catheter diameter is ∼ 0.90 mm, and the spatial resolution of the image is known. Thus it is straightforward to remove the catheter sheath by setting pixels in the radial range of the catheter to zero.(c) Bilateral Filter: As the IV-OCT image has a intrinsic speckle noise, we performed a bilateral filtering [22] to smooth the image while preserving the edges.(d) Threshold: The Otsu method [23] was used to separate the region with high gradient magnitude, which consists mainly of the first vessel-wall layer.(e) Removal of guide wire: The guide wire (GW) is characterized by a bright reflection immediately followed by a shadow. According to the manufacturer (St. Jude Medical), the GW diameter is known to be 0.3556mm, which corresponds an area of 0.0992mm2. However, the bright region produced by the GW in a single frame corresponds to a projection of the real GW area. After analysis of this pattern in all data sets, we verified that the bright region corresponds to half (0.0496mm2) of the GW area. If a different catheter is used, this parameter can be changed. An area constraint (only nonsignificant size area can be removed) is performed applying the transformation from half GW area in square millimeters to pixels, according to the image resolution information.Based on Ughi et al. [19], a pipeline was built to detect the lumen. Considering the pre-processing output as a binary image, each A-line was scanned from the bottom to the top of the image, until a significant gradient was found. After this, the region below the intima layer has value zero and the intima layer plus lumen region had a value of one. To segment the lumen region, a subtraction between the image containing the intima layer plus the lumen region (A-line sweeping step) and the image containing only the intima layer (Removal of the guide wire step) was performed. This operation can result in the definition of irregular borders, as in the case of vessels with thrombosis or dissections. To eliminate holes, shadows of any struts or residual luminal blood, a sequence of five dilations followed by five erosions was applied with a structuring element [0 1 0;1 1 1;0 1 0]. The number of operations was determined by means of experimentation supervised by a specialist. Five steps are enough to group spurious points from residual luminal blood, without modifying the lumen area size.The guidewire forms a pattern shadow of 25 degrees on the Cartesian coordinates image. This guidewire shadow is established in polar coordinates image (radius × angle) as a rectangle with width of 25 degrees or pixels. Thus, the GW shadow identification is performed searching for a horizontal gap of 20-35 pixels of width. If a gap at the first line (on the top of the image) is identified, all corresponding A-lines are filled from top to the lumen border. For a different GW, this parameter can be adjusted in the proposed model. Finally, the lumen border points are detected using the morphological gradient (subtraction between the dilated image and the eroded image) edge detector with a 3×3 structuring element of 1s and, the resulting polar image (Ip) is transformed to an image with Cartesian coordinates (Ic) according to Eq. (2). Two examples of the resulting lumen border detection are shown in Fig. 3.(2)Ic(x,y)=Ip(x2+y2,arctanyx)where x and y are the Cartesian coordinates.Our hypothesis is that the vessel cross-section contains information which can indicate the detection and characterization of bifurcation points. This information can be extracted from texture in a vessel frame as in Alberti et at. [15] or from the lumen contour as in Wang et al. [17]. In the proposed method we use shape descriptors from the segmented lumen contour. According to Mehtre et al. [24], a 2D shape descriptor should be insensitive to: (i) translation, (ii) scale changes, and (iii) rotations.Some shape descriptors were selected to extract geometrical features from the lumen contour:•Distance centroidThe distance between the center of the main vessel and the centroid of the entire lumen contour. The center of the main vessel is acquired from the distance transform using the Euclidean metric, which represents the point which has the largest set of minimum distances from all contour points. In a bifurcation frame, this point lies at the center of the main vessel, and not between the two branches as the centroid point.CircularityA simple measure that estimates how close the shape is to a circle. It is defined as:(3)C=P2A,where C is the circularity, P is the perimeter and A is the internal area of the contour. A circle has circularity(2πr)2πr2=4π. Thus, circularity values different from 4π indicate an irregular shape.Bending energyThe bending energy expresses the required strength to bend an irregular curve into a circle. In this study, highest values of B were obtained from bifurcation frames. This measure is defined as:(4)B=1P∫K(t)2dt,where B is the bending energy, P is the perimeter of the contour and K is the curvature.Curvature (maximum, minimum, average)Let pc(t)=(x(t), y(t)) be the parametric representation of a contour. The curvature K(t) of parametric curve pc(t) is defined as:(5)K(t)=x˙(t)y¨(t)−x¨(t)y˙(t)x˙(t)2+y˙(t)21.5,where t is the t-th point in a parametric curve,x˙(t)andy˙(t)are the first derivative of x and y respectively, andx¨(t)andy¨(t)represent the second derivative of x and y, respectively. The maximum curvature (Kmax) is the highest value of K(t) in a contour of vessel cross-section. The minimum curvature (Kmin) is the smallest value of K(t) in a vessel cross-section contour and the average curvature (Kavg) is the average of all K(t) values in a contour of vessel cross-section.Radial varianceThis measure was developed in Macedo et al. [25] for characterizing bifurcation points. Assuming that S represents a set of parameterized n contour points, cl represents the main vessel centerline coordinate in the form (x, y) on a cross-section and D={dt1, dt2, dt3, ..., dtn} is the set of distances dti=||S(i)−cl||, the radial variance is defined as:(6)RV=1n−1∑i=1nDiD¯−∑j=1nDjD¯n2whereD¯is the average distance. The radial variance represents the variability of a contour profile as shown in Fig. 4.Axis ratioAn ellipse is fitted to a lumen contour and the ratio between the major axis and minor axis computed.Signature varianceThe variance of contour signature [26] was calculated considering the contour centroid.Signature standard deviationThe standard deviation of a contour signature [26] was calculated considering the contour centroid.Sector varianceFor every 30 degrees along the lumen contour, the variance of the signature metric [26] was computed considering the main vessel center. The final metric corresponds to the maximum variance for all sets of 30 degrees in the lumen contour.Area difference between framesThe difference between the total area of the previous frame and the total area of the current frame.Mean triangular areaFor each m points in a lumen contour, three points are established as vertices of a triangle: [i, (i+m)/2, (i+m)] and triangular area is computed. This metric is an average of all triangular areas built in a lumen contour.Other descriptors based on the above (n=13) descriptors were determined using derivatives and paired combination, totaling 104 different features, excluding square features. The set of j features of a frame i is defined as:(7)FEij=feit1≤t≤n,1≤j≤n,feit˙1≤t≤n,n+1≤j≤2nfeitfeik1 ≤ t≤ n, t< k ≤ n,2n+1≤j≤n2+3n2where feitare the initial features described above (1≤t≤13) for the ith frame andfeit˙are the derivatives of the initial features feit.A matrix of features P can be defined as(8)P=FE1,1FE1,2⋯FE1,n2+3n2FE2,1FE2,2⋯FE2,n2+3n2⋮⋮⋱⋮FEN,1FEN,2⋯FEN,n2+3n2where N is the total number of frames, FEijis the jth feature of the ith frame.Given the matrix of features P, it is possible to perform a classification to identify bifurcations frames. The variety and number of features present a difficulty in manually choosing the best features, so we used an optimization method to select the best features. The orthogonal least squares methods (FROLS and MFROLS) provide a set of the most relevant features and their respective weights [21]. The weak classifier BE that consists of a linear combination of selected features and their respective weights were used with the results of FROLS and MFROLS [20,25]. Moreover, three state-of-the-art classifiers (SVM, RF and AB) were used as bifurcation classifiers. A performance comparison was made among the results of the linear combinations and the above three state-of-the-art discriminative classifiers.The algorithm FROLS was created by Billings [21] and adapted in this study, where the matrix P has dimension N×M, N is the number of frames and M is the quantity of features as explained in Section 3.1. The vector y is a column vector of size N, which contain the answers determined by an expert (BR =1 or NBR=0) for each frame.Let pibe the ith column of matrix P. As explained above, each picorresponds to a candidate to the set of best features. The algorithm FROLS searches the best features to explain the bifurcations, i.e. which pivector is closest to the vector y. This measurement is made using the Error Reduction Ratio (ERR) defined as:(9)ERRi=yTpi(yTy)(piTpi)where yTandpiTare the transpose of y and pirespectively, and (yTy),(piTpi)and yTpiare inner products. The FROLS algorithm calculates the ERR for all features of the matrix P.The closest feature to vector y, in the feature space, has the greatest ERR and is chosen as one of the best features. Remaining features are orthogonalized with respect to the first feature already selected. However, to avoid numerical problems and facilitate a matrix inversion, this orthogonalization process is performed using the modified Gram-Schmidt algorithm for all features [27]. The orthogonalized feature with the highest ERR is chosen and this procedure is repeated until the value of the term ERR is smaller than ρ, in this study ρ=0.36, or the sum of ERR's is sufficiently close to 1.At the end, a least squares method is performed involving the selected features and the vector of the answers y, and defining the vector of weights.(10)y=Pewwhere Pe is a matrix composed by only the chosen features (FEe),wis the vector of weights and y is the result vector (bifurcation=1 or nonbifurcation=0).This variation of FROLS uses multiples images. A set of best features and their respective weights is established for each image, and these values are averaged to produce a single performance estimation. Generally, MFROLS provides a smaller number of best features than the FROLS method.The weak classifier, Bifurcation Estimator (BE) is determined by a linear combination of features. An improvement of this classifier can be achieved by determining the values of the weights and the best features as shown in Eq. (11)[20]. The optimization method Forward Regression Orthogonal Least Squares (FROLS) and the version using multiple images (MFROLS), described by Billings [21] is used to choose a set of best features and their respective weights.(11)BE(i)=∑j=1m(wjFEej(i))wherewjis the jth weight for each feature determined as FEejand i corresponds to the ith frame.This method does not have a training phase, but requires the selection method. The test phase has a performance of O(nm), where n is the size of sample and m is the number of features.In this study were used three supervised methods for bifurcation identification: (i) the support vector machine (SVM) [28] classifies data by finding the best hyperplane that separates two different classes. For nonlinear problems a kernel function can be used to separate the classes with a hyperplane in a high-dimensional feature space. Radial basis functions (RBF) were used as the kernel and a 10-fold cross-validation to tune the RBF parameters. The computational complexity at training phase is between O(n2) and O(n3), where n is the sample size. For our tests, SVM costs O(nm) where m is the number of features. As the cost of a SVM test is high with large set of features, we tested it with (a) all features, (b) a subset composed of selected features as chosen by FROLS and MFROLS, producing a reduction of almost 90% in the number of features; (ii) Another discriminative method used for bifurcation classification was the AdaBoost (AB), an approach based on the idea of combining numerous relatively weak and inaccurate rules to create a highly accurate prediction rule [29]. The computational complexity in the training phase is O(Tnm), where n is the sample size, m is the number of features and T is the number of iterations. For tests, AdaBoost costs O(T). The same combination with selected features from FROLS and MFROLS was performed; (iii) The last classifier is the Random Forest [30], which is an ensemble method that builds several decision trees such that each tree uses values of a random vector sampled independently and with the same distribution for all trees in the set (forest). The computational complexity at the training phase is O(TnM) and O(Tn) in test, where n is the sample size, T the number of trees, and M<n is the random subspace dimensionality [15]. A set of selected features defined from FROLS and MFROLS was also tested.The feature selection method FROLS was performed with a set of frames from four different patients and four different pullbacks. While MFROLS was performed with same quantity of frames, but separated by pullbacks. For each discriminative classifier and type of frame set, previously described in Table 2, a 10-fold cross-validation was applied to samples of all the entire frame set (nine patients, nine pullbacks). The samples were divided in 10 groups with each group being used exactly once as a test set, and its compliment as a training set. This was repeated ten times. Finally the ten results from the folds were averaged to produce single performance estimates.Three types of feature vector were tested for the SVM, AdaBoost, and Random Forest: (i) all 104 features, (ii) selected features from FROLS; and (iii) selected features from MFROLS.One independent expert observer, blinded to automated segmentation results, was involved in the manual contour tracing process. A gold-standard was established using ImageJ software (NIH software of public domain). Manual segmentation of the lumen was performed on 1282 frames of the nonbifurcation class. Only nonbifurcation frames were chosen in order to compare with other methods in the literature. An example of a manually segmented frame is shown in Fig. 5.A set of six metrics was used to measure the accuracy of the proposed automated method for lumen segmentation, using the manual lumen segmentation as reference. These metrics are described below:a) Volume overlap (VOE)(12)VOE=Vm∩VaVm∪Va·100%where Vmis the manually segmented volume and Vais the automatically segmented volume.b) Dice metric (DM)(13)DM=2·|A∩M||A+M|·100%where A and M are the lumen area from automated segmentation and manual segmentation in square millimeters respectively.c) Hausdorff distance (H)(14)H=max{maxa∈A{minm∈M{dist(a,m)}},maxm∈M{mina∈A{dist(a,m)}}}where m and a are points on the lumen contour obtained with the manual and automated methods respectively.d) RMS Symmetric surface distance (RMSSSD)(15)RMSSSD=∑a∈A[minm∈M{dist(a,m)}]2Na+Nm1/2+∑m∈M[mina∈A{dist(a,m)}]2Na+Nm1/2This metric is similar to H, but with the addition of Naand Nmas the number of contour points of automated and manual methods, respectively. RMSSSD stores the square distances between the two sets of border voxels, and after averaging the square values, the square root is taken which gives the symmetric RMS surface distance.e) Mean absolute difference of area (MADA)(16)MADA=∑i=1N|M−A|Nwhere N is the number of samples and, M and A are the areas obtained with the manual and automated method respectively.f) Accuracy (ACC)(17)ACC=(TP+TN)(TP+FP+TN+FN)where TP is true positive, TN as the true negative, FP as false positive and FN as false negative. It is considered the correlation between manual and automatic lumen pixels [31].The frames were visually classified by an expert as frames pertaining to BR or NBR. The classification evaluation was performed with the following metrics:True Positive Rate or sensitivity:(18)TPR=TPTP+FNFalse Positive Ratio:(19)FPR=FPTN+FPSpecificity:(20)SPE=TNTN+FPPrecision:(21)PRE=TPTP+FPFalse Alarm Ratio:(22)FA=FPTP+FNF-measure:(23)F=2·PRE·TPR(PRE+TPR)Area under the ROC curve:(24)AUC=∫01f(x)dxwhere TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative, f is the ROC curve and x is the FPR value.

@&#CONCLUSIONS@&#
