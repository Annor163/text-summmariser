@&#MAIN-TITLE@&#
A hybrid self-adaptive bees algorithm for examination timetabling problems

@&#HIGHLIGHTS@&#
Disruptive selection strategy to select the solution from the population to improve the diversity of the population.Self-adaptive strategy for directing the neighbourhood search to enhance the local intensification capability.Modified bees algorithm is combined with late acceptance hill climbing to quickly descend to the optimum solution.

@&#KEYPHRASES@&#
Bees algorithm,Examination timetabling problems,Late acceptance hill climbing algorithm,Selection strategy,Self-adaptive mechanism,Simulated annealing algorithm,

@&#ABSTRACT@&#
A hybrid self-adaptive bees algorithm is proposed for the examination timetabling problems. The bees algorithm (BA) is a population-based algorithm inspired by the way that honey bees forage for food. The algorithm presents a type of neighbourhood search that includes a random search that can be used for optimisation problems. In the BA, the bees search randomly for food sites and return back to the hive carrying the information about the food sites (fitness values); then, other bees will select the sites based on their information (more bees are recruited to the best sites) and will start a random search. We propose three techniques (i.e. disruptive, tournament and rank selection strategies) for selecting the sites, rather than using the fitness value, to improve the diversity of the population. Additionally, a self-adaptive strategy for directing the neighbourhood search is added to further enhance the local intensification capability. Finally, a modified bees algorithm is combined with a local search (i.e. simulated annealing, late acceptance hill climbing) to quickly descend to the optimum solution. Experimental results comparing our proposed modifications with each other and with the basic BA show that all of the modifications outperform the basic BA; an overall comparison has been made with the best known results on two examination timetabling benchmark datasets, which shows that our approach is competitive and works well across all of the problem instances.

@&#INTRODUCTION@&#
Examination timetabling problems (ETTPs) are combinatorial optimisation problems that consist of allocating a number of examinations into a predefined number of timeslots, while satisfying a set of hard constraints that cannot be violated and soft constraints that must be minimised as much as possible [1]. It is known that the ETTPs fall under the NP-hard problems [2,3]. Furthermore, it is a dynamic and perturbed problem. Many contributions related to the ETTPs have appeared for the last thirty years. This scenario could result from the fact that ETTPs are often dynamic problems, and the optimisation criteria are difficult to identify.Several meta-heuristic approaches have been developed for solving ETTPs which can be classified into two main types, i.e. single-based approaches (e.g. tabu search, simulated annealing, great deluge and variable neighbourhood search) and population-based approaches (e.g. genetic algorithms, ant colony optimisation and memetic algorithms) [4]. Single-based approaches have gained interest by many researchers due to the ability of these approaches to exploit the search space in a short time, but these approaches have some limitations such as a weak exploration and it is easy to get stuck in a local optima [4]. In addition, researchers have introduced population-based approaches to solve the examination timetabling problems. The main idea behind the population-based is that the algorithms iteratively improve a number of solutions [5]. However, these approaches have some limitations such as they are more concerned with exploration rather than exploitation, premature convergence and low convergence speed [5]. To overcome the limitations of the single-based and population-based approaches, the hybridisation between population-based approaches with a single-based approach has been addressed for timetabling problems. The aim of the hybridisation is to utilise the benefit of population-based approaches that has the ability of identifying promising areas in the search space and single-based approaches that are good in exploiting the promising area [6–9]. It is believed that the hybridisation approach is able to give a better performance in obtaining a preferred solution for a given problem [9].Population-based approaches can be categorised as either evolutionary algorithms or swarm intelligence based algorithms [10]. These two categories depend on the nature of the phenomenon simulated by the algorithm. Most common evolutionary algorithms introduced for timetabling problems can be found in [11–14]. Swarm intelligence relies on the cooperative behaviour of self-organised systems to develop meta-heuristics that mimic such a system's problem solving [15]. Local communication between individuals and with their environment contributes to the collective intelligence of the social colonies [10]. These swarm intelligence characteristics motivated a number of researchers to employ such behaviour in algorithms for timetabling problems (e.g. ant algorithms, fish swarm optimisation algorithm, honey-bee mating optimisation algorithm and artificial bee colony algorithm).Eley [16] proposes ant algorithms for the examination timetabling problem. The author investigated two approaches which were coded as Max–Min and ANTCOL. In both approaches the hybridisation between a simple ant system and hill climber was made. The initial solutions were constructed based on the inverse of saturation degree meta-heuristic. The author found that the simple ANTCOL outperformed the hybrid Max–Min Ant system with hill climber. The author also found that the parameters sitting in ant system much affects the performance of such approaches. This approach is good in discovering new solutions and able to avoid the premature convergence, the drawback are, it is reported as a slow algorithm, Involves a number of parameters and Not effective as an improvement algorithm. Turabieh and Abdullah [17] proposed the fish swarm optimisation algorithm for examination timetabling problems. In this work, the solutions in the population are classified into three groups based on the solution quality. In addition, two local search algorithms are used in order to enhance the solutions quality i.e. great deluge and steepest descent algorithms. In order to reduce the computational time of the original fish swarm algorithm, the authors modified the algorithm by selecting only one solution for exploitation based on a roulette wheel selection rather than exploit all the solutions in the population. This approach shows that it's good in exploration and diversification but not good in intensification. Sabar et al. [18] proposed honey-bee mating optimisation algorithm for solving examination timetabling problems. As a result of their approach has showed that it is able to explore and exploit the search space. The limitation of their approach is the number of parameters that should be set carefully. Alzaqebah and Abdullah [19] proposed a hybrid artificial bee colony with simulated annealing algorithm, in this work the authors have investigate the use of disruptive selection strategy and a self-adaptive mechanism for examination timetabling.The bees algorithm (BA) is based on the foraging behaviour of honeybees and was proposed in 2005 by Pham et al. [20]. Pham et al., in 2006, proved that BA outperforms other techniques in terms of the speed of the optimisation and the accuracy of the results [21]. With our research, we first seek to improve the local search efficiency of a BA by applying a local search algorithm in order to achieve the following: combine the advantages of BA, improve the ability to cooperatively explore the search space and local search algorithms, improve the ability to quickly find good solutions within a small region of the search space, and prevent deterioration. Second, we enhance the population diversity in the BA population, and third, we introduce a self-adaptive method for neighbourhood search to manage the neighbouring search. Experimental results show that the algorithm behaviour improves when we employ the three modifications that are stated above. Meanwhile, all of the modification comparisons are listed and analysed to show the effects that are produced by our modifications. The comparison with the best known results indicates that our results are comparable.The main contribution to the BA in this work is, first, maintaining a population of individuals that evolve according to the nature of a disruptive selection strategy. The second is to avoid the algorithm getting stuck (no available improving neighbours) at “local optima” by performing a self-adaptive mechanism that monitors the neighbourhood search. The third contribution is to support the BA neighbourhood search with a novel local search algorithm (late acceptance hill climbing algorithm).The details of the ETTP benchmarks are given in Section 2, which is followed by the details of the original BA (Section 3). Section 4 presents the proposed modifications to the original BA. Section 5 presents the proposed BA algorithm. Section 6 presents our experimental results analysis and comparisons. This section is followed by conclusions and comments in Section 7.In this paper, the BA is tested in two examination timetabling problems, as listed below:This problem is considered to be an uncapacitated examination timetabling problem, where a room capacity requirement is not taken into account. The Toronto benchmark was introduced by Carter et al. [22] in 1996. This problem has one hard constraint (clash-free), where conflicting exams cannot be assigned to the same timeslot. A timetable which meets all the hard constraints given is called a feasible timetable. The soft constraint spreads conflicting exams away from each other during the timetable as much as possible. The description of the problem is adapted from Burke and Newall [23]. In this benchmark, the examination timetabling problems consist of these inputs, as stated below:•N is the number of exams.Eiis an exam, i∈{1,…,N}.T is the given number of available timeslots.M is the number of students.C=(cij)NxNis the conflict matrix, where each element denoted by cij, i,j∈{1,…,N} is the number of students taking exams i and j.tk(1≤tk≤T) specifies the assigned timeslot for exam k (k∈{1,…,N}).The objective function has been formulated to space out students’ exams throughout the exam period (Eq. (1)), which can then be formulated as the minimisation of the following [24].(1)Min∑i=1N−1F1(i)2Mwhere(2)Fi(i)=∑j=i+1NCij⋅proximity(ti,tj)and(3)proximity(ti,tj)=25/2|ti−tj|if1≤|ti−tj|≤50otherwisesubject to:(4)∑i=1N−1∑j=i+1NCij⋅γ(ti,tj)=0whereγ(ti,tj)=1ifti=tj0otherwiseEq. (2) presents the cost for an exam I, which is given by the proximity value multiplied by the number of students in conflict. Eq. (3) represents a proximity value between two exams [22]. For example, if a student has two consecutive exams, then a proximity value of 16 (i.e. 25/21) is assigned. If a student has two exams with a free timeslot in between then a value of 8 (i.e. 25/22) is assigned. The value will be 4 if there are two timeslots in between and so on. These values are summed up and divided by 2M, to give an average penalty per student (Eq. (1)) since all clashes would otherwise be counted twice (e.g. c12 and c21).Eq. (4) represents a clash-free requirement so that no student is asked to sit in two exams at the same time. The clash-free requirement is considered to be a hard constraint. Table 1presents the characteristics of this dataset.ITC2007 introduces three tracks of problems, examination timetabling, curriculum-based course timetabling and post-enrolment course timetabling. In this paper, we concentrate on the first track, which represents the examination timetabling problems that include a number of real-world constraints [25]. Details of the benchmark instances can be found in [26]. Eight instances are available and four are hidden for testing purposes. Table 2shows the characteristics of these datasets.A feasible timetable is one in which all of the examinations have been assigned to a period and a room, and there is no violation of the hard constraints. The set of hard constraints are listed below:•There are no students sitting for more than one exam at the same time.The total number of students assigned to each room cannot exceed the room capacity.The length of the exams that are assigned to each timeslot should not violate the timeslot length.The exam sequences must be respected; for example, Exam_A must be scheduled after Exam_B.Room-related hard constraints must be satisfied; for example, Exam_A must be scheduled in Room2.In addition, the objective function is to minimise the violation of the soft constraints, as given in Eq. (5)[25]. Each dataset has its own weight (W) as shown in Table 3.(5)min∑s∈S(W2RCS2R+W2DCS2D+WpSCSpS)+(WNMDCS2NMD+WFLCFL+WpCp+WRCR)The soft constraints (C) are listed below [25]:•Two exams in a row (CS2R): minimise the number of consecutive exams in a row for a student.Two exams in a day (CS2D): student should not be assigned to sit more than two exams in one day. Of course, this constraint becomes important only when there are more than two examination periods in the same day.Periods spread (CSpS): all students should have a fair distribution of exams over their timetable.Mixed durations (CS2NMD): the numbers of exams with different durations that are scheduled in the same room must be minimised as much as possible.Larger exams appearing later in the timetable (CFL): minimise the number of examinations of large class sizes that appear later in the examination timetable (to facilitate the assessment process).Period penalty (CP): some periods have an associated penalty; minimise the number of exams that are scheduled in penalised periods.Room penalty (CR): some rooms have an associated penalty; minimise the number of exams that are scheduled in penalised rooms.In the natural life of the honeybee, bees can discover food sources using global and local search methods. The former consists of sending scout bees to search at random around the hive for food sources. Once the scout bees discover food sources, they determine the food source information, including the locations of the food, the food quality and the distance from the hive, and return back to their hive and start recruiting more bees to exploit those food sources [27]. Logically, more recruited bees will be sent to search around the better food sources, where they perform a search similar to a local search. To ensure that the search continues until good food sources are found, including the best, scout bees would continue on a global random search, while some bees are recruited to perform a local search. This intelligent optimisation process has motivated researchers to formulate such a process into an algorithmic form, as in the basic BA [20]. The applications of the BA algorithm are many and varied in the optimisation field [20,21,28–30].Fig. 1shows the main steps of the basic Bees Algorithm (BA), as stated in [21]. The algorithm starts with an Initial population (scout bees) that is generated randomly in the search space; then, the fitness of the population is evaluated, and the BA search process is started until the stopping criterion is met.In the first step, the bees are ranked from the highest to the lowest fitness; the highest bees are designated as “selected bees”, and the sites visited by the selected bees are chosen for a neighbourhood search (selected solutions). In the second step, more bees are assigned to search near the selected sites. Searching nearby to the best sites shows that, more promising solutions are made more detailed by recruiting more bees to search near the selected sites compared to other sites. Together with scouting, this scenario is a key operation of the bees algorithm [21,30]. However, in the third step, for each patch, only the bee with the highest fitness will be selected for the next population. This constraint is initiated here to maintain the same population size. In the fourth step, the remaining bees in the population are assigned randomly around the search space, scouting for new solutions. The new population after each iteration will have two parts; the first part is from each selected patch, and the second part is from conducting a random search.The selection strategies are used in many population based algorithms, over the year a number of research papers have studied different selection strategies in order to improve the algorithms’ performance, e.g. artificial bee colony (ABC) [31,19] algorithm and genetic algorithm (GA) [32]. Karaboga and Basturk [31] introduced ABC algorithm for solving constrained optimisation problems. In this work, authors have modified the ABC algorithm by changing from the greedy selection (the highest quality solution is selected) to a tournament selection strategy. As a result, the modified version of ABC is able to solve constraint optimisation problems. Also in [19], ABC algorithm is modified by applying three selection strategies (i.e. disruptive, rank and tournament) with an aim is to compare the performance of the ABC algorithm with different selection strategies. Experimental results have shown that the ABC with three selection strategies performs better than the original ABC, where the disruptive selection shows the best performance in comparison with the rank and the tournament selections.In GA, the selection strategy is used to select the parents for crossover operation. Jadaan et al. [33] introduce a comparison between roulette wheel and rank-based selection in comparing several mathematical fitness functions. Experimental results have shown that the rank-based selection strategy outperformed the roulette wheel selection strategy. The observation shows that the rank-based is steadier, faster, certainty and more robust. Zhong et al. [34] compared a roulette wheel with a tournament selection on seven test functions. The authors have found that the GA with the tournament selection is more efficient in convergence than the roulette wheel selection. Kuo and Hwang [35] introduced the use of disruptive selection in order to maintain the diversity in genetic algorithms.In this work, three selection strategies (tournament, rank and disruptive) are incorporated into the BA algorithm and are tested on the examination timetabling problem, as below:In tournament selection, a comparison is made depending on the fitness, to take the best individual among a number of individuals (Ntour) that are chosen randomly from the population. Parameter Ntouris called the tournament size. In tournament selection, the individuals with a high fitness are more preferable [36]. In this work, we conceder a binary tournament in which we select two individuals from the population and compare their fitness values, then assign one score (coded as a) to the better individual. This process is then repeated for all of the individuals in the population, as shown in Fig. 2, where fiis the fitness value of i=0,…n, and n is the population size adapted from [37]. Finally, the selection probability for each individual is calculated using Eq. (6).(6)Pi=ai∑j=0najIn rank selection, individuals are sorted in descending order based on the fitness value. The index k is given to each individual from the best to the worst, i.e. for the best fitness k=1, and for the worst fitness, k=n, where n is the population size, and N is the maximum number of iterations. Finally, the selection probability is calculated using the expression below [38]:(7)Pk=1n+a(t)n+1−2kn(n+1),k=(1,2,…,n)wherea(t)=0.2+3t4N,t=(1,2,…,N)Disruptive selection gives more chances for higher and lower individuals to be selected, by changing the definition of the fitness function, as in Eq. (8)[39]. Disruptive selection changes the fitness value for each individual (fiti) in the population to an absolute value of the difference between an individual's fitness (fi) and the average value for all individuals (f¯t) in the population.(8)fiti=|fi−f¯t|Pi=fiti∑i=0nfitiThere is a trend in the disruptive selection to keep the diversity longer because retaining the highest and lowest quality solutions is more preferable.Neighbourhood searches use a self-adaptive mechanism to guide the neighbouring search process. We employed the following neighbourhood structure to increase the searching algorithm performance [40].Nbs1: Select 2 exams randomly and swap timeslots.Nbs2: Select a single exam randomly and move it to a new random feasible timeslot.Nbs3: Select 4 exams randomly and feasibly swap timeslots among them.Nbs4: Select 2 exams randomly and move them to random feasible timeslots.The neighbourhood structures are selected based on the self-adaptive method, as discussed below [41]:1.This method fills a list (NL) randomly from four neighbourhood structure search methods, as above. In this step, the list (NL) is generated with a specified neighbour lengths.During the search process, the neighbourhood structure is selected from NL to generate a new solution. If it is better than the current solution, then the neighbourhood structure is inserted into a new list, called a winning neighbouring list (WNL). The same process is repeated until NL becomes empty.NL is refilled by 75% of the neighbourhood structures from the WNL list and 25% randomly from the four neighbourhood structure. Note that the idea of filling the NL list is adopted from [41] where we used the same number of neighbourhood structures. The percentages of 75% and 25% used here are based on our preliminary experiments; the WNL is also reset to repel any accumulation. If the WNL is empty, which may occur when a search is close to optimal with a negligible population variety, then the last NL is reused. Note that the same percentage of NL and WNL can be used in other applications since BA is not sensible to them.With a self-adaptive method, the suitable neighbouring search operation can be learned based on the current search process where the wining neighbourhood structure during the search is kept and reused. The chance of using the wining neighbourhood structures is higher than others due to the fact that the NL list is filled by 75% of neighbourhood structures taken from the WNL and 25% is randomly filled. In this paper, we performed a tuning on the length of NL and the final length is set to 200.We propose two local search algorithms, simulated annealing and late acceptance hill climbing, to improve the local search of the basic BA. The basic BA accepts the improved solution and eliminates the worst solution. These two local search algorithms are discussed and explained below:Kirkpatrick et al. [42] proposed simulated annealing for combinatorial optimisation problems. The SA algorithm works on a single solution and improves it by finding neighbouring solutions and slowly modifying a parameter called temperature (Temp) [43]. The acceptance criteria of the neighbouring SA solutions depend on a certain probability (P) between 0 and 1. If P is less than the value of e−δ/Temp, where δ=f(Sol*)−f(Sol) (the difference between the penalty cost of the new and current solutions), then the algorithm accepts the new solution, even if it is worse than the current solution; otherwise, the algorithm accepts the new solution only if it is better than the current solution. The process repeats until the Temp is less than the final temperature Tf, as in Fig. 3.The parameters used for the SA algorithm are set based on experimental results, as in Section 6.3.LAHC also applies to the basic BA algorithm to compare different local searches in the BA algorithm. The LAHC algorithm is a local search algorithm that was proposed by Burke and Bykov [44]. The LAHC algorithm works with a single solution and iteratively improves it. This algorithm keeps the fitness values after each single move in a memory (Ĉ=LAHC list) with size (L). Accepting the new solution in LAHC relies on a comparison between the new and previous solutions that were obtained in the Lth step. Fig. 4shows the late acceptance hill climbing pseudo-code.The general pseudo-code for our proposed algorithm is presented in Fig. 5. The general pseudo-code shows the employment of the three modifications mentioned in Section 4, where we linked each modification with the section number within the pseudo-code.As shown in Fig. 5, the algorithm starts with a feasible initial solution; then, an initial population is randomly generated, and the number of solutions in the population is equal to the number of scout bees. The scout bees evaluate the solution using the fitness function, which we explain in Section 2.Scout bees rank the solutions in the population according to the selection probability, as in Section 4.1 (for the basic BA, the solutions are ranked based on the fitness value), and the nb solutions of highest rank are selected for local exploration by other bees (foragers) that are directed to the neighbourhood of the selected sites by the scouts. For each selected solution, the number of foragers is allocated deterministically as follows. Each scout that returned from one of the nb best sites performs the ‘waggle dance’, which recruits nest mates for local exploration (or applies one local search, as in Section 4.3). The scout bees that visited the first ne elite solutions among the best nb sites recruit nre foragers for a random neighbourhood search (or using the self-adaptive method, as in Section 4.2). The scouts that visited the remaining (nb–ne) solutions recruit nrb<nre foragers for a random neighbourhood search (or using the self-adaptive method). The local search is thus more thorough in the neighbourhood of the elite sites, which are considered to be the most promising locations of the solution space.To choose suitable modifications for the basic BA algorithm, three experimental comparisons were made for the two examination timetabling problem datasets, as explained in Section 2. We first compared using three selection strategies; we then compared using two local search algorithms, which include some parameter tuning. We also considered the effect of using the self-adaptive method in neighbourhood searches. Finally, we compared our results to the best known results in the literature.In this paper, the parameters are experimentally chosen from a total of 5 runs to obtain the average results. Furthermore, we have performed good tuning on the parameters for the algorithm, and the final settings of the parameters are as follows:•Population size=50.Maximum number of iterations=500.Population size=50.ne: Number of elite sites=2.nre: Recruited bees for elite sites=30.nb: Number of best sites=4.nrb: Recruited bees for remaining best sites=10.stlim: Limit of stagnation cycles for site abandonment=10.LAHC list size (L)=5000.To show the performance of the basic BA algorithm with different selection strategies, three selection strategies were implemented within the BA algorithm. The three different modified BA algorithms are the BA algorithm based on disruptive selection (DBA), rank selection (RBA) and tournament selection (TBA). We ran the experiments 10 times for each dataset. Tables 4 and 5present comparisons for both problems, including the best and average results.Comparing the DBA, RBA, TBA, and BA algorithms indicates that the performance of the BA algorithm with three selection strategies is better than the basic BA algorithm on both datasets. As a comparison with different selection strategies in the BA algorithm, DBA works better compared to the RBA and TBA algorithms. From Table 4, the DBA algorithm produces good results for 9 datasets out of the 12 datasets that are presented in bold, as well as in Table 5, in which the DBA algorithm produces good results for 6 datasets out of the total of 8. This result arises from the behaviour of the selection strategy, where the tournament selection randomly selects a number of solutions (Ntour) and compares them based on a probability. The solution with the highest fitness value will be chosen. In a rank selection, the solutions are ranked based on the fitness values; thus, this function is biased to work in a solution with a higher rank (i.e. a higher fitness), while the disruptive selection concentrates on both bad and good fitness solutions and attempts to maintain the diversity of the population by improving the worst fitness solutions in synchrony with high fitness solutions.Fig. 6(a) and (b) represents the convergence of the sta83I and Exam_2 datasets, respectively, where the x-axis represents the number of solutions and the y-axis represents the penalty cost. These graphs show how the DBA, TBA and RBA spray the population at an initial stage (represented by the triangle symbol), and then, when the stop condition is met, the improved solutions are represented by the square symbol. From these figures, we can conclude that the DBA provides a chance for all of the solutions in the population to be improved and converge together. This result is evident in the fact that the plotted symbols are concentrated (not scattered) with each other, which represents the closeness of the solution qualities in the population. On the other hand, in TBA and RBA, the plotted symbols that represent the improved solution in the population are more scattered.The DBA algorithm employed a self-adaptive method for neighbourhood searches. To show the significance of using this method in the DBA algorithm search process, Tables 6 and 7show the self-adaptive DBA compared to the DBA algorithm.The comparison shows that the self-adaptive DBA outperforms the DBA algorithm. Employing a self-adaptive method in a neighbourhood search to penalise unperformed neighbourhood structures used later in the search algorithm helps the search algorithm to explore the search space differently. This scenario allows for a higher possibility of obtaining better solutions.From the previous section, we perform the BA disruptive selection strategy (coded as the DBA algorithm) because of its performance. In this section, we compare the two local search algorithms in the DBA algorithm.Table 8shows the experimental results when applying SA to a self-adaptive DBA algorithm, which is coded as the self-adaptive DBASA. We also used different values for the initial temperature (T0), which was set to 5000, 2000, 1000 and 500. The results obtained are based on the best results from 10 runs.Table 8 shows that the best value for T0 is 1000, so we used that value for ITC2007, as shown in Table 9.We performed the same comparison on the self-adaptive DBA algorithm with the late acceptance hill climbing algorithm, coded as self-adaptive DBALAHC. Note that the self-adaptive method is also used to monitor the LAHC neighbourhoods search.Comparing the self-adaptive DBA and the self-adaptive DBALAHC shows that the self-adaptive DBALAHC outperforms the self-adaptive DBA algorithm when it is applied to both problems, as shown in Tables 10 and 11. Applying the local search LAHC within a self-adaptive DBA produces better results because it accepts worse solutions during the LAHC search that later we believe lead to better solutions. A self-adaptive strategy can unstick a LAHC search from local optima.Tables 12 and 13show an experimental comparison between simulated annealing and late acceptance hill climbing. A t-test has been conducted to show a significant difference between the two methods with confidence level of 95%. The p-value in Table 12 indicates significant differences in 10 out of 12 datasets. The percentage difference in Toronto dataset is 83%. The p-value in Table 13 shows that there are significant differences in all datasets. From the presented results, we can conclude that the self-adaptive DBALAHC outperforms self-adaptive DBASA on both categories of problems.In this section, we first compare our best results with the best known results for the Toronto benchmark, as in Table 14. Using the results for the self-adaptive DBALAHC from the previous sections, we compare our results to three approaches that are able to produce best known results so far (taken from the survey by Qu et al. [4]).An overall comparison with the best known results shows that we are unable to exceed any of the best known results in the literature. We are still able to produce sufficiently good solutions. The comparison also shows that our results are very close to the best approaches in the literature.We also analyse our best results by conducting a statistical test to show the significant differences between our algorithms and the best approaches in the literature. As a statistical analysis, we first employ a Friedman test, followed by Holm and Hochberg tests as post hoc methods (if significant differences are detected), to obtain the adjusted p-values for each comparison between the control algorithm (the best-performing one) and the rest (Garcia et al. [47,48]). Table 15summarises the ranking obtained by Friedman's test.Table 15 shows that Burke and Bykov's 2008 [41] results rank first, followed by the self-adaptive DBALAHC and Yang and Petrovic's 2005 [25] results. The p-value computed by the Friedman test is 0.0017, which is below the critical level (α=0.05). This value shows that there is a significant difference among the observed results. We also performed post hoc methods (Holm's and Hochberg's test) for the self-adaptive DBALAHC algorithm. Table 16shows the adjusted p-value (Friedman).Holm's and Hockberg's procedures show significant differences, using Burke and Bykov as a control algorithm. The self-adaptive algorithm is better than Yang and Petrovic (2005) and is comparable to Burke and Bykov (2008) with α=0.05 and α=0.01 (1/3 algorithms).In addition, we have tested the performance of the self-adaptive DBALAHC algorithm on the International Timetabling Competition (ITC2007) datasets. Table 17shows the results and compares the proposed algorithm to five winners of the International Timetabling Competition 2007 that can be found at http://www.cs.qub.ac.uk/itc2007/, as listed below:1st place: Tomas Müller2nd place: Christos Gogos3rd place: Mitsunori Atsuta, Koji Nonobe, and Toshihide Ibaraki4th place: Geoffrey De Smet5th place: Nelishia PillayTable 17 indicates that the self-adaptive DBALAHC results are comparable with state-of-the-art approaches and that the self-adaptive DBALAHC is able to obtain solutions that are better than other proposed approaches on almost all of the tested datasets. Note that the experiment performed here is terminated when the time reaches 600s (as set in the ITC2007 computation rules).We applied a Friedman test to the ITC2007 dataset. The p-value computed by Friedman's was 9.4250E-6, which is below the significance level α=0.05. There are significant differences among the observed results.Table 18shows the average algorithm rankings found by the Friedman test. From this table, Muller ranks first, followed by the self-adaptive DBALAHC algorithm, Gogos, Atsuta and Pillay, in descending order.Table 19shows the adjusted p-value (Friedman). We conducted further post hoc methods (Holm's and Hochberg's tests).Figs. 7 and 8illustrate the box-and-whisker plot, which represents the distribution of solution qualities for the Toronto benchmark and International Timetabling Competition (ITC2007) datasets. It can easily be observed that the gap between the best, average and worse solution qualities are close, which indicates that the self-adaptive DBALAHC is robust. Each box has lines at the lower, median and upper quartile for the set of 10 runs. The figures show less solution point dispersion, particularly the upper and lower quartiles in Fig. 7 (car91, car92, sta83I, and uta92I datasets) and Fig. 8 (Exam_2, Exam_3 and Exam_7).

@&#CONCLUSIONS@&#
This paper describes three modifications on the BA, as follows: (i) the employment of a suitable selection strategy (i.e. a disruptive selection in this case) indicates the importance of choosing the individuals from the population for exploitation, to keep the population diversity longer, (ii) choosing a suitable adaptive method for adaptively choosing the neighbourhood structure for a neighbourhood search, and (iii) combining the advantage of the bee algorithm with late acceptance hill climbing as a local search to increase the ability to cooperatively explore the search space and to find good solutions within a small region of the search space and to prevent deterioration. The performance of our algorithm has been tested on the Toronto benchmark and the ITC2007 datasets. The experimental results show that the three modifications of BA outperform the BA alone. Our algorithm can produce good quality solutions on both categories of the tested datasets and are comparable with state-of-the-art approaches.