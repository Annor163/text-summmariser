@&#MAIN-TITLE@&#
Camera pose estimation under dynamic intrinsic parameter change for augmented reality

@&#HIGHLIGHTS@&#
We propose an intrinsic and extrinsic camera parameter estimation method.We extended a conventional marker-based method by adding two energy terms.Camera parameters are estimated accurately using new energy function.The effectiveness of our method is shown in simulated and real environments.

@&#KEYPHRASES@&#
Camera pose estimation,Augmented reality,Zoomable camera,Epipolar constraint,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Augmented reality (AR) is a technique that can integrate the real and virtual worlds. AR enables us to obtain additional information, such as navigation data, guidance, and virtual avatars. Recently, AR applications have been achieved by using a video see-through-based method. In this method, virtual information is overlaid onto a camera image, and the generated AR images are then shown to the user on a display device. In video see-through-based AR applications, geometric registration between the real and virtual worlds is generally required for overlaying the virtual information. Geometric registration for the video see-through-based AR can be achieved by estimating camera parameters.The methods that are used to estimate camera parameters can be divided into two groups: those for estimating intrinsic camera parameters, including focal length, image center, and lens distortion, and those for estimating extrinsic camera parameters, including camera positions and orientations. In most AR applications, intrinsic camera parameters are calibrated and fixed before the online extrinsic camera parameter estimation process. Many types of methods for estimating camera parameters have been proposed. In these methods, a square marker-based method for estimating extrinsic camera parameters [1] is widely used in various applications, because this method allows the easy construction of a robust AR environment.Changing the camera׳s field-of-view, termed “camera zooming,” cannot be used in conventional AR applications because intrinsic camera parameters change in the zooming process. Conventional AR applications assume the use of a head-mounted display (HMD) for overlaying virtual information [1,2]. Camera zooming has not been used for HMDs because zooming gives users an unnatural sensation. This sensation is caused by the difference between the actual head motion and the motion perceived in the displayed images. Thus, the limitation of fixed intrinsic camera parameters in camera parameter estimation is not relevant in conventional AR applications.In contrast, many types of mobile AR applications for overlaying virtual information that run on smartphones and tablet PCs have been developed recently [3,4]. In addition, AR technology is often used in the production of TV programs. Although camera zooming in these mobile AR applications or TV programs rarely gives the user an unnatural sensation, these technologies do not allow its use because of the difficulty involved in handling camera zooming in the camera parameter estimation process. Fig. 1(a) shows the results of overlaying a computer-generated (CG) object without camera zooming. Figs. 1(b) and (c) show the results of geometric registration during camera zooming. In the case shown in Fig. 1(b), the registration error increased because inconsistent intrinsic parameters were used to estimate the extrinsic camera parameters. However, in the case shown in Fig. 1(c), accurate geometric registration was achieved by using the proposed method to handle the intrinsic camera parameter change during camera zooming. Removing the limitation caused by fixed intrinsic camera parameters in camera parameter estimation opens possibilities in many AR applications.To realize simultaneous intrinsic and extrinsic camera parameter estimation during camera zooming, we propose a camera parameter estimation method that uses a pre-calibrated intrinsic camera parameter change and a novel energy function for online camera parameter estimation.11Part of this paper was presented at the International Symposium on Mixed and Augmented Reality, 2013 [5]. In the present paper, we address the auto balancing of each energy term, and we have added a quantitative and qualitative evaluation of the proposed method.In our method, two energy terms are added to the conventional marker-based method for estimating camera parameters: (1) the reprojection errors of tracked natural features and (2) the constraint of the continuity of zoom values. The tracked natural feature points implicitly give a 3D structure of the scene, and the continuity term gives the temporal constraint for the camera parameters. Using the new energy function, our method can accurately and stably estimate intrinsic and extrinsic camera parameters in the online estimation process. Our method requires a pre-calibration process. However, this process needs to be executed only once. Thus, this process does not reduce the usefulness of the proposed method. The remainder of this paper is organized as follows. In Section 2, we discuss related work on image-based camera parameter estimation. The proposed framework is described in Section 3, and a quantitative and qualitative evaluation of its effectiveness is presented in Section 4. Finally, in Section 5, we present the conclusion and future work.

@&#CONCLUSIONS@&#
