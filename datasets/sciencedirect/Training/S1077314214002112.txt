@&#MAIN-TITLE@&#
3-D object modeling from 2-D occluding contour correspondences by opti-acoustic stereo imaging

@&#HIGHLIGHTS@&#
3-D object modeling from occluding contours from multi-modal optical/sonar stereo.Imaging same contour by zero-baseline stereo, circumventing dense feature matching.Improve reconstruction accuracy from 3-D contour positions and orientations.Identifying degenerate configurations and simple misalignment rectification.Flexibility to use navigation data or a few feature tracks for 3-D trajectory estimation.

@&#KEYPHRASES@&#
Opti-acoustic imaging,Stereo imaging,3-D object reconstruction and modeling,Occluding contours,

@&#ABSTRACT@&#
Utilizing in situ measurements to build 3-D volumetric object models under variety of turbidity conditions is highly desirable for marine sciences. To address the ineffectiveness of feature-based structure from motion and stereo methods under poor visibility, we explore a multi-modal stereo imaging technique that utilizes coincident optical and forward-scan sonar cameras, a so-called opti-acoustic stereo imaging system. The challenges of establishing dense feature correspondences in either opti-acoustic or low-contrast optical stereo images are avoided, by employing 2-D occluding contour correspondences, namely, the images of 3-D object occluding rims. Collecting opti-acoustic stereo pairs while circling an object, matching 2-D apparent contours in optical and sonar views to construct the 3-D occluding rim, and computing the stereo rig trajectory by opti-acoustic bundle adjustment, we generate registered samples of 3-D surface in a reference coordinate system. A surface interpolation gives the 3-D object model.In addition to the key advantage of utilizing range measurements from sonar, the proposed paradigm requires no assumption about local surface curvature as traditionally made in 3-D shape reconstruction from occluding contours. The reconstruction accuracy is improved by computing both the 3-D positions and local surface normals of sampled contours. We also present (1) a simple calibration method to estimate and correct for small discrepancy from the desired relative stereo pose; (2) an analytical analysis of the degenerate configuration that enables special treatment in mapping (tall) elongated objects with dominantly vertical edges. We demonstrate the performance of our method based on the 3-D surface rendering of certain objects, imaged by an underwater opti-acoustic stereo system.

@&#INTRODUCTION@&#
Building 3-D volumetric models of underwater objects (e.g., natural reef objects, shipwrecks, and other sub-sea structures) under a variety of turbidity conditions by utilizing in situ measurements is a highly desirable capability for marine sciences. Among various “Shape from X” approaches in computer vision, feature-based structure from motion and stereo methods have been explored extensively for underwater mapping [1–7]. Unfortunately, these become less and less effective with rising turbidity level and (or) in the presence of other artifacts, e.g., sun flicker in shallow waters, non-uniformity of artificial lighting in deep waters, as well as weak texture. While the emergence of (X-box) Kinect [8] has addressed absence of texture and surface markings for feature matching in terrestrial domain, the technology is ineffective in underwater, due to the very high degree of IR attenuation.This motivates the exploration of alternative approaches that circumvent the need to establish dense correspondences. A suitable solution can be derived by exploiting the object boundaries and (or) occluding contours, namely the boundaries between object silhouettes and the background. Fig. 1(a,b) shows two low-resolution images of reef objects (downloaded from internet). These boundaries or contours can be readily determined (e.g., as the results in (c) based on LoG operator, without any adjustment to optimize detection and accuracy). However, dense features are hard to identify and much more difficult to match robustly in low-contrast underwater video and (or) stereo pairs, due to poor visibility and lighting, as well as other adverse conditions.The classic paper by Koenderink [9] unveils many novel findings and ideas about the relationship between the local shape properties of smooth surfaces and their apparent contours; e.g., convexities, concavities, and inflections of occluding contours for elliptic, hyperbolic, and parabolic surfaces, respectively, and that the sign of the apparent contour curvature follows that of the local intrinsic (Gaussian) curvature of the surface. His contributions paved the road for the development of methods to reconstruct smooth objects in 3-D, from the images of their apparent contours. The primary complexity arises from the fact that occluding contours of smooth surfaces vary with the viewer pose, and thus there is no correspondence among occluding contour points in multiple nearby views, in the sense of stereo vision. Generally, three consecutive images in a differential formulation are employed to characterize a local approximation of the surface up to order two, including the recovery of depth information. The surface is parametrized with respect to the occluding contours and the intersection of the surface with the epipolar plane. Here, an epipolar correspondence is defined between two points on two successive occluding contours, belonging to the epipolar plane defined by the two camera projection centers and one of the points.Giblin and Weiss [10] demonstrated the 3-D surface reconstruction for planar viewer motion under the assumption of orthographic projection. Some later works based on perspective projection for depth computation utilize the osculating circle, assuming that the camera motion is linear [11,12], or that the surface is locally cylindrical [13]. Here, each rim point is reconstructed by determining the osculating circle from the point and epipolar correspondents on the two neighboring rims. By projecting the viewing lines onto a plane, either an epipolar plane [11,12] or radial plane [13], the circle tangent to these three directions is computed. Szeliski and Weiss [14] tackle the numerical instability of differential formulations utilizing discrete observations and numerical approximation [15] – the main drawback of these earlier methods – with a Kalman filtering and smoothing formulation to compute the epipolar curves over the surface with an estimate of uncertainty. Boyer and Berger [15] utilize the discrete views of occluding contours under general viewer motion, a depth formulation based on the local approximation of surface up to order two, and taking advantage of an osculating quadratic (instead of the osculating circle) for surface interpolation between occluding contours.In contrast to these local approaches, other methods make use of a global surface reconstruction scheme. For example, Zhao [16] proposed a direct method based on regularized uniform bi-cubic B-spline surface patches. Here a set of overlapping B-spline patches constituting the object surface are reconstructed and fused to obtain a global 3-D shape. The approach requires a complete a priori parametrization of the surface, which is usually not available [15]. Kang et al. [17] employ the duality of points and tangent planes and algebraic surface representation by implicit polynomials of degree 2 or higher.In underwater, the deployment of a camera on a submersible platform undergoing motion with six degrees of freedom adds additional complexities to the common bottlenecks of these methods: e.g., (1) surface reconstruction requires three images from nearby known relative camera poses around a smooth object, to estimate the osculating circle, the local normal curvature of and the distance to a surface point; (2) numerical instability exists due to the differential analysis and estimation of second order derivatives to compute the depth of the contour generator. Referring to Fig. 1(d,d′), an attractive approach is offered by opti-acoustic stereo imaging, where we deploy optical and forward-scan (FS) sonar video cameras with overlapping views [18–21]. The utilization of different but complementary measurements, including range from sonar, offers key advantages. For example, traditional binocular stereo systems require a certain minimum baseline based on the target distance. With small baselines (e.g., imposed by the physical size and constrains of underwater platforms), the 3-D reconstruction by triangulation with two (nearly) parallel optical rays is highly ill-conditioned. In contrast, “opti-acoustic stereo triangulation” is well-posed by utilizing optical rays and range spheres (and azimuth planes) from sonar measurements [20].Unfortunately, the opti-acoustic correspondence still remains as an unsolved problem. While a geometric approach by exploiting the stereo and motion epipolar geometries in opti-acoustic video sequences has been proposed [22], building 3-D object models requires establishing dense feature correspondences over the sonar and (or) optical sequences. The dense feature matching problem can be circumvented by utilizing the 2-D apparent contours in the images acquired by the opti-acoustic stereo imaging system in a special configuration, where the projection centers of the two cameras coincide and their “viewing axes” align. That is, the sonar and optical cameras view the target from the same vantage point. While traditional binocular vision offers little/no advantage for 3-D object reconstruction by utilizing occluding contours, the proposed multi-modal approach enables devising a simple practical 3-D object reconstruction solution based on: (1) exploiting redundant and complementary visual cues in 2-D optical and sonar images at each position of the sensor platform, namely, opti-acoustic correspondences in the traditional stereo vision sense; (2) making use of images at each time instant, without the need to estimate second derivatives to compute depth from three (or more) nearby views; (3) overcoming the correspondence problem by making use of opti-acoustic epipolar geometry, with cameras at (roughly) the same position that image the same occluding contour; (4) enabling the recovery of both the 3-D position and the surface normal at each point on the occluding rim; (5) removing any restriction on the camera motion; (6) relaxing the surface smooth assumption that enables application to arbitrary shapes, excluding surfaces with concavities where no viewing ray/plane of the optical/sonar camera can be made tangent to the surface. It should be noted that the current method, as most previous techniques, makes no distinction between occluding contours and standard structural edges, where the surface normal is discontinuous. Most natural objects, as well as manmade structures deployed underwater have smooth surfaces,2Either originally or due to algea, coral and other marine growth.2giving rise to occluding contours. However, to identify the latter, one may estimate the surface normal from the gradient of computed 3-D positions of contour points, and compare with the given solution (that assumes the boundary to be an occluding contour). In practice, applying finite difference approximation to the noisy estimates of 3-D contour points is expected to yield inaccurate surface normal estimates. Further investigation, beyond the scope of this work, is warranted to quantify the impact on the 3-D reconstruction accuracy.Two other technical contributions of this work include the derivation of the degenerate target configuration and a simple calibration method. The former result is rather important in planing an effective data acquisition strategy based on the target shape, e.g., when mapping a (tall) elongated object with dominantly vertical edges/contours. Here, either the stereo pose can be adjusted or the data can be acquired over two or more paths. The new calibration method provides a simple solution for our special stereo setup, enabling adjustment to rectify discrepancy from the desired relative stereo pose.Finally, two other practical issues should not be overlooked. First, the visibility constraint from turbidity can be addressed by imaging objects at shorter distances. Next, the zero baseline requirement is a desirable feature for deployment on small submersible platforms, where the stereo rig dimension is no larger than the sonar size.In the balance, we give the relevant technical background in Section 2. In Section 3, we describe various components of the 3-D reconstruction process. These comprise of the detection of 2-D apparent contours and construction of 3-D occluding contours, local surface normal estimation, optimal trajectory estimation by opti-acoustic bundle adjustment, registration of 3-D occluding contours, and dense 3-D object modeling by surface interpolation. We present the results of experiments with real data in Section 4, and a summary of our contributions in Section 5. Finally, the appendix covers both the degenerate configuration of the opti-acoustic stereo system relative to the target, and a simple method to estimate and rectify the misalignment between the two cameras.

@&#CONCLUSIONS@&#
