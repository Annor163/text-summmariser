@&#MAIN-TITLE@&#
Directional wavelet based features for colonic polyp classification

@&#HIGHLIGHTS@&#
We test several wavelet based approaches for the classification of colon polyps.A total of 11 differernt endoscopic polyp databases is used for our experiments.The best results are achieved by extracting Weibull features from the subbands.We propose three wavelet based feature extraction approaches using Weibull features.Some of the methods improve the state of the art in classifying colonic polyps.

@&#KEYPHRASES@&#
Polyp classification,Wavelet,Curvelet,Contourlet,Shearlet,

@&#ABSTRACT@&#
In this work, various wavelet based methods like the discrete wavelet transform, the dual-tree complex wavelet transform, the Gabor wavelet transform, curvelets, contourlets and shearlets are applied for the automated classification of colonic polyps. The methods are tested on 8 HD-endoscopic image databases, where each database is acquired using different imaging modalities (Pentax’s i-Scan technology combined with or without staining the mucosa), 2 NBI high-magnification databases and one database with chromoscopy high-magnification images.To evaluate the suitability of the wavelet based methods with respect to the classification of colonic polyps, the classification performances of 3 wavelet transforms and the more recent curvelets, contourlets and shearlets are compared using a common framework. Wavelet transforms were already often and successfully applied to the classification of colonic polyps, whereas curvelets, contourlets and shearlets have not been used for this purpose so far.We apply different feature extraction techniques to extract the information of the subbands of the wavelet based methods. Most of the in total 25 approaches were already published in different texture classification contexts. Thus, the aim is also to assess and compare their classification performance using a common framework. Three of the 25 approaches are novel. These three approaches extract Weibull features from the subbands of curvelets, contourlets and shearlets. Additionally, 5 state-of-the-art non wavelet based methods are applied to our databases so that we can compare their results with those of the wavelet based methods.It turned out that extracting Weibull distribution parameters from the subband coefficients generally leads to high classification results, especially for the dual-tree complex wavelet transform, the Gabor wavelet transform and the Shearlet transform. These three wavelet based transforms in combination with Weibull features even outperform the state-of-the-art methods on most of the databases. We will also show that the Weibull distribution is better suited to model the subband coefficient distribution than other commonly used probability distributions like the Gaussian distribution and the generalized Gaussian distribution.So this work gives a reasonable summary of wavelet based methods for colonic polyp classification and the huge amount of endoscopic polyp databases used for our experiments assures a high significance of the achieved results.

@&#INTRODUCTION@&#
In this paper, wavelet based methods are applied for the automated classification of colonic polyps in endoscopic images. Wavelet transforms like the discrete wavelet transform (DWT), the dual-tree complex wavelet transform (DT-CWT) and the Gabor wavelet transformation have been widely used for the purpose of medical image analysis. In case of colonic polyp classification, especially the DT-CWT proved to be quite suitable for the distinction of different types of polyps as can be seen in numerous previous papers like e.g. Häfner et al. (2015a); 2009); 2010) Also Gabor wavelets have proved to be quite suitable for colonic polyp classification (Yuan and Meng, 2014; Häfner et al., 2009) and detection (Hwang and Celebi, 2010). The DT-CWT and the Gabor wavelets are both directional selective wavelet transforms, contrary to the classical DWT. It has been shown in Häfner et al. (2009), that these two directional selective wavelet transforms provide better results than the DWT. So enhanced directional selectivity may be an advantage classifying polyps.Based on the wavelet theory, new multiresolution analysis tools like the curvelet, contourlet and shearlet transform have been developed. These transforms (further denoted as Lets) are even more directional selective than the DT-CWT and Gabor transformation. To the best of our knowledge, until now solely the curvelet transform was applied for the automated detection or classification of polyps, however solely for small bowel tumors using capsule endoscopy (Barbosa et al., 2009; Martins et al., 2010).In this paper we use a common framework to compare the results of the wavelet transforms and Lets for the classification of colonic polyp in endoscopic images. To the best of our knowledge, there has not been a comparison of wavelet transforms and Lets with respect to the classification of images so far (the same applies for related issues like image retrieval or pattern and object recognition). So in spite of the similarity of wavelets and Lets, this is the first publication which systematically compares these transforms with respect to their suitability to classify texture images. In order to ensure a fair comparison of the wavelet based methods, we extract the same features (Gaussian, generalized Gaussian and Weibull distribution parameters) and use the same number of scale levels for each method. To ensure a high significance of the results, the wavelet based methods are applied to a total of 11 different endoscopic polyp databases. Feature extraction approaches using wavelet transforms already proved to be an appropriate choice in various publications. By means of our test we will see if the same applies to curvelets, contourlets and shearlets. Additionally we reimplemented some Let-based texture recognition approaches and applied them to the classification of our polyp databases to have a higher variability of extracted features and to find out which features extracted from Lets are most appropriate for our task. The results of the wavelet based approaches are compared with those of 5 non-wavelet based state-of-the-art approaches in colonic polyp classification.But first let us introduce and motivate the employed wavelet based transforms:Wavelet transforms use filterbanks to form a time-frequency representation for continuous-time signals. The main difference between the wavelet transform and the Fourier transform (FT) is that wavelets are localized in time and frequency whereas the standard Fourier transform is only localized in frequency. Because of the uncertainty principle, originally found and formulated by Heisenberg, the frequency and time information of a signal at some certain point in the time-frequency plane cannot be known. In other words: we cannot know what spectral component exists at any given time instant. The best we can do is to investigate what spectral components exist at any given interval. The wavelet transform deals with that problem by decomposing a signal in frequency bands (called subbands), where the higher frequency bands are better resolved in time (with less relative error) and the lower frequency bands are better resolved in frequency.Wavelets are widely used for data compression, signal analysis, signal reconstruction, denoising, etc. One of the most useful features of wavelets is their ability to efficiently approximate signals, that means to represent a signal as accurately as possible by means of a minimum of subband coefficients. Especially for signals with pointwise singularities, the DWT is much more efficient than the Fourier transform. This motivates why wavelet transforms are now being adopted for a vast number of applications, often replacing the conventional Fourier transform.However, the DWT does not perform as well with multidimensional data. Indeed, the DWT is very efficient in dealing with pointwise singularities only. In higher dimensions, other types of singularities (e.g. edges in images) are usually present or even dominant, and the DWT and other traditional wavelet methods are unable to handle them efficiently. In order to overcome this limitation of traditional wavelets, one has to increase their directional sensitivity. Two well known directional selective wavelet transforms are the Dual-tree complex wavelet transform (DT-CWT) (Kingsbury, 1998) and the Gabor wavelet transform (Lee, 1996).Based on the wavelet theory, new multiresolution analysis tools have been developed that are especially designed to efficiently representate edges and curves in 2-dimensional data. The idea behind this new schemes can be described by the following scenario (Easley et al., 2008). Imagine that there are two painters, one with a “wavelet”-style and the other using the new scheme, where both wish to paint a natural scene. Both painters apply a refinement technique to increase resolution from coarse to fine. Efficiency is measured by the number of brush strokes needed to faithfully recover the scene. We consider the situation that a smooth contour has to be painted like shown in Fig. 1.2-D wavelets are constructed from tensor products of 1-D wavelets, so the “wavelet”-style painter is limited to use square-shaped brush strokes along the contour, using sizes corresponding to the multiresolution structure of wavelets. As the resolution becomes finer, we clearly see the limitations of the painter, who needs to use many “dots” to capture the contour. The new style painter, on the other hand, is much more effective by making brush strokes with differently elongated shapes, where the directions of the shapes follows the contour. That means many wavelet coefficients are needed to account for edges or curves and it would be far more effective to have strongly anisotropic filters to represent edges of curves. This idea was implemented by a number of new wavelet-based approaches. The most established approaches using this new scheme are the curvelet transform (Candes and Donoho, 2002), the contourlet transform (Do and Vetterli, 2005) and the shearlet transform (Easley et al., 2008). We further denote these transforms as “Lets”.These Lets use non-separable filters which have elongated supports at various scales, directions and aspect ratios (the finer the scale, the higher is the aspect ration or in other words the more elongated are the supports). This allows an efficient approximation of smooth contours at multiple resolutions in much the same way as the new scheme shown in Fig. 1. Moreover, these Lets are able to use different numbers of directions at each scale (generally, the finer the scale, the more directions).The contributions of this manuscript are as follows:•We apply a total of 25 wavelet based methods for the automated classification of colonic polyps. 5 methods are based on the curvelet transform, 5 on the contourlet transform, 6 on the shearlet transform, 3 on the DWT, 3 on the DT-CWT and 3 on the Gabor transformation. By means of these experiments we are able to compare Lets and wavelet methods with respect to their classification performance. Most of the methods were already proposed in different texture classification contexts , but three of these methods are novel to the best of our knowledge. In these three methods, the subband coefficients of the curvelet, contourlet and shearlet transform are modeled by the 2 parameter Weibull distribution. We will show that modeling the subband coefficients by means of the Weibull distribution generally leads to the best results for classifying colonic polyps using wavelet based methods.We apply the Kolmogorov–Smirnov test as Goodness-of-Fit test and show that the Weibull distribution is well suited to model the subband coefficient distribution of the wavelet based transforms, which explains the superior results using Weibull features. It will turn out that the subbands are not actually Weibull distributed, but at least almost Weibull distributed.For our experiments we use a total of 11 different endoscopic databases. 8 databases are gathered using a HD-endoscope with 8 different imaging modalities (Pentax’s i-Scan in combination with staining the mucosa), 1 databases is gathered using high magnification endoscopy (or also called zoom-endoscopy) in combination with staining the mucosa and two databases are gathered using a zoom-endoscopy in combination with narrow band imaging (NBI). So we use a quite comprehensive collection of databases for the classification of colonic polyps. The results of the methods are compared and the differences between the methods as well as their impacts to the results are analyzed.5 (non wavelet based) state-of-the-art approaches for colonic polyp classification are applied to the classification of our databases to compare their results with the results of the wavelet based methods. In this way we are able to find out if there are wavelet-based methods that can compete with state-of-the-art approaches. We will see that some of the wavelet-based methods even outperform the state-of-the-art approaches, while others perform equally or inferior compared to the state-of-the-art approaches.This paper is organized as follows. In Section 2 we briefly introduce the concept of the computer-assisted diagnosis of polyps using mucosa texture patches and review the corresponding state-of-the-art. In Section 3, we describe and compare the wavelet based approaches. The experimental setup, the used databases and the results are presented in Section 4. Section 5 presents the discussion and Section 6 concludes our work.Colonic polyps are a rather frequent finding and are known to either develop into cancer or to be precursors of colon cancer. Hence, an early assessment of the malignant potential of such polyps is important as this can lower the mortality rate drastically. As a consequence, a regular colon examination is recommended, especially for people at an age of 50 years and older. The current gold standard for the examination of the colon is colonoscopy using a colonoscope. Modern endoscopy devices are able to take pictures or videos from inside the colon, allowing to obtain images (or videos) for a computer-assisted analysis with the goal of detecting and diagnosing abnormalities.Colonic polyps are usually divided into hyperplastic, adenomatous and malignant polyps. In order to determine a diagnosis based on the visual appearance of colonic polyps, the pit pattern classification scheme was proposed by Kudo et al. (1994). A pit pattern refers to the shape of a pit, the opening of a colorectal crypt. The various pit pattern types and exemplar (zoom-endoscopic) images of the classes are presented in Fig. 2. The pit pattern classification scheme differentiates between six types. Type I (normal mucosa) and II (hyperplastic polyps) are characteristics of non-neoplastic lesions, type III-S, III-L and IV are typical for adenomatous polyps and type V is strongly suggestive to malignant cancer.So this classification scheme allows to differentiate between normal mucosa and hyperplastic lesions, adenomas (a pre-malignant condition), and malignant cancer based on the visual pattern of the mucosal surface. The removal of hyperplastic polyps is unnecessary and the removal of malignant polyps maybe hazardous. In this work we use the 2-class classification scheme differentiating between non-neoplastic and neoplastic lesions. This classification scheme is quite relevant in clinical practice as indicated in a study by Kato et al. (2006).For an easier detection and diagnosis of the extent of mucosal lesions, two common mucosal enhancement technologies were developed:1.Conventional chromoendoscopy (CC) came into clinical use 40 years ago. By staining the mucosa using (indigocarmine) dye spray, it is easier to detect and differentiate colonic polyps. CC is often used in conjunction with high-resolution or magnification endoscopy.Digital chromoendoscopy is a technique to facilitate “chromoendoscopy without dyes” (Kiesslich, 2009). The strategies followed by major manufacturers differ in this area:•In Narrow band imaging (NBI, Olympus), narrow bandpass filters are placed in front of a conventional white-light source to enhance the detail of certain aspects of the surface of the mucosa.The i-Scan (Pentax) image processing technology (Kodashima and Fujishiro, 2010) is a digital contrast method which consists of combinations of surface enhancement, contrast enhancement and tone enhancement.The FICE system (Fujinon) decomposes images by wavelength and then directly reconstructs images with enhanced mucosal surface contrast.Both systems (i-Scan and FICE) apply post-processing to the reflected light and thus are called “computed virtual chromoendoscopy (CVC)”.Previous works for the computer assisted classification of colonic polyps using highly detailed images gathered from endoscopes in combination with different imaging modalities, can be divided in three categories:•High definition (HD) endoscope combined with or without staining the mucosa and the i-Scan technology:In Häfner et al. (2014a), shape and contrast features were extracted from blobs and in Häfner et al. (2015b); 2014c) fractal analysis based features were extracted.High-magnification chromoendoscopy:In Häfner et al. (2012c), the pit density was estimated using Delaunay triangulation, local binary patterns based features were used in Häfner et al. (2009) and Häfner et al. (2012a) and features from wavelet transforms were extracted in Häfner et al. (2008); 2009); 2010); 2015a).High-magnification endoscopy combined with NBI:Tamaki et al. (2013) extracted dense SIFT features and Gross et al. (2012) extracted features describing the vessel structure.In this work we use endoscopic image databases of all three categories.One of the aims of this work is to compare the classification results of the databases of all three categories.In addition to classical endoscopy, endomicroscopy, computed tomography (CT) and wireless capsule endoscopy can be used for the examination of the gastro-intestinal tract. Endomicroscopy (Jabbour et al., 2012) is a technique to obtain histology-like images and is also known as ‘optical biopsy’. For example Andrė et al. (2011); 2012) showed approaches based on semantics and visual concepts for the automated diagnosis of colonic polyps using endomicroscopy. CT colonography, also known as virtual colonoscopy, is a minimally invasive technique for the investigation of the colon. An example showing a detection and classification system based on Curvature Analysis using CT colonography can be seen in Chowdhury et al. (2008). Wireless capsule endoscopy (Iakovidis and Koulaouzidis (2015); Yuce and Dissanayake (2012)) is mainly used to examine parts of the gastrointestinal tract that cannot or only hardly be seen with other types of endoscopes (the small bowel). The capsule has the size and shape of a pill and contains a tiny camera. After a patient swallows the capsule, it takes images of the inside of the gastro-intestinal tract. An example for the automated detection and classification of colonic polyps using capsule endoscopy can be seen in Romain et al. (2013).In this work we use a total of 8 image databases gathered by HD endoscopy. HD-endoscopy has the advantage of an higher resolution compared to standard definition endoscopes. Each database is gathered by a different combination of the i-Scan technology and CC, respectively no CC.The three i-Scan modes are as follows:1.i-Scan 1 includes surface enhancement and contrast enhancement. Surface enhancement mode augments pit pattern and surface details, providing assistance to the detection of dysplastic areas. This mode enhances light-to-dark contrast by obtaining luminance intensity data for each pixel and adjusting it to accentuate mucosal surfaces.i-Scan 2 includes surface enhancement, contrast enhancement and tone enhancement. Expands on i-Scan 1 by adjusting the surface and contrast enhancement settings and adding tone enhancement attributes to the image. It assists by intensifying boundaries, margins, surface architecture and difficult-to-discern polyps.i-Scan 3 also includes surface enhancement, contrast enhancement and tone enhancement. Similar to i-Scan 2, with increased illumination and emphasis on the visualization of vascular features. This mode accentuates pattern and vascular architecture.In Fig. 3we see an image showing an adenomatous polyp without image enhancement technology (a), example images using CVC (b,c,d), an image using CC (e) and images combining CC and CVC by using the i-Scan technology to visually enhance the already stained mucosa (f,g,h).In Fig. 4we see exemplar images of the two classes (denoted as class “Non-neoplastic” and class “Neoplastic”) obtained by a HD endoscope using a combination of CC and i-Scan mode 2.In this work we will examine the effects of combinations of CVC and CC on the classification results.High magnification endoscopes are defined by the ability to perform optical zoom by using a moveable lens in the tip of the endoscope. In that way magnified images are obtained without losing display quality. High magnification endoscopy enables the visualization of mucosal details that cannot be seen with standard endoscopy. The CC-high-magnification database is gathered using zoom-endoscopy in combination with chromoendoscopy. Example images of the classes can be seen in Fig. 2.NBI (Gono et al., 2003) is a videoendoscopic system using RGB rotary filters placed in front of a white light source to narrow the bandwidth of the spectral transmittance. NBI enhances the visibility of microvessels and their fine structure on the colorectal surface. Also the pits are indirectly observable, since the microvessels between the pits are enhanced in black, while the pits are left in white.In this work we use two NBI-high-magnification databases.For one database, further denoted as the NBI-high-magnification database Aachen, image labels were provided according to their histological diagnosis (like for the previously presented databases). Exemplar images of the two classes of this database can be seen in Fig. 5.For the second database, further denoted as the NBI-high-magnification database Hiroshima, image labels were provided according to the optical appearance of the polyps. The images were labeled by at least two medical doctors and endoscopists who are experienced in colorectal cancer and NBI classification. Exemplar images of the two classes of this database can be seen in Fig. 6.In this section we will describe the wavelet based transforms and the employed feature extraction approaches.The discrete wavelet transform (DWT) (Mallat, 1989) generates frequency bands by applying low-pass (h) and high-pass (g) filters to the input signal followed by a subsampling of the filter outputs with factor 2. To increase the frequency resolution, the decomposition is repeated by decomposing the outputs of the low pass filtering. (see Fig. 7).This results in a binary tree with nodes representing a sub space with different time-frequency localization (see Fig. 7). This tree is known as filter bank. Starting with a mother wavelet ψ, the filters ψj, kare shifted and scaled versions of the mother wavelet:(1)ψj,k=12jψ(t−k2j2j),where j is the scale (or decomposition level) and k is the shift parameter and both are integers.Then the wavelet coefficient γj, kof a signal x(t) is computed as follows:(2)γj,k=∫−∞∞x(t)ψj,kdt.Given an image, the 1-D filter bank is first applied to the rows of the image and then applied to the columns as can be seen in Fig. 8.Like in Kwitt and Uhl (2010), we use the CDF 9/7 filters (Daubechies, 1992) for the DWT, which are biorthogonal wavelet filters. If not stated otherwise, the DWT and also the other employed wavelet based transforms are applied to RGB color images using 4 decomposition levels.Kingsbury’s dual-tree complex wavelet transform (Kingsbury, 1998) is designed to overcome two commonly known shortcomings of the 2-D DWT, the lack of shift-invariance and the poor directional selectivity. The key concept of the DT-CWT in 1-D is to use two separate DWT decompositions (see Fig. 9), where the low-pass filter of one tree is a half-sample delayed version of the low-pass filter of the other tree and the filters of one tree are the reverse of the filters of the other tree.The outputs of one tree can be interpreted as the real parts and the outputs of the other tree can be interpreted as the imaginary parts of complex wavelet coefficients. The redundancy of 2d(where d is the dimension of the signal being transformed) compared to the DWT provides extra information for analysis. The DT-CWT leads to a fixed number of 6 detail subbands per decomposition level in 2-D, capturing image details oriented at ≈ ±15°, ≈ ±45° and ≈ ±75°. In Fig. 10we see the frequency tiling of a DT-CWT with two scales.Gabor wavelets use complex functions constructed to serve as a basis for the Fourier transforms in information theory applications. The Gabor wavelet transform has multi-resolution as well as multi-orientation properties. Gabor wavelets minimize the product of its standard deviations in the time and frequency domain. In that way, the uncertainty in information (frequency resolution vs time resolution) carried by this wavelet is minimized. It has been found that the simple cells of the visual cortex of mammalian brains are best modeled as a family of self-similar 2D Gabor wavelets (Lee, 1996).A generic 2-D Gabor function (Manjunath and Ma, 1996) can be written as(3)g(x,y)=(12πσxσy)e(−12(x2σx2+y2σy2)+2πiWx),where σxand σyare the bandwidths of the filters and W is the central frequency. This function can be dilated and rotated to get a dictionary of filters.The Gabor wavelet transform (GWT) is parametrized by the number of orientations and scales and the lower (Ul) and upper (Uu) center frequency of interest, which influences the calculation of the scaling factor for the mother wavelet. Redundancy is minimized by choosing the scaling factor and the bandwidth of the filters so that the half-peak magnitudes of the filter responses touch each other. The frequency tiling for a GWT using 6 orientations and 3 scales can be seen in Fig. 11.Manjunath and Ma (1996) found that a choice of 4 scales and 6 orientations with center-frequency(Ul,Uu)=(0.05,0.4)(resulting in a scaling factor ofa=2) is optimal for their problem (texture analysis) and we chose the same parameter values.The continuous curvelet transform (CCT) is based on tilling the 2D Fourier space in polar “wedges”, with higher directional selectivity for higher frequency bands (see Fig. 12(a)).The CCT (Candes et al., 2006) can be defined by a pair of windows W(r) (the radial window) and V(t) (the angular window). Both are smooth, nonnegative and real-valued and are defined as scaled Meyer window functions (Daubechies, 1992):(4)W(r)={cos[π/2γ(3r−4)]4/3≤r≤5/315/6≤r≤4/3cos[π/2γ(5−6r)]2/3≤r≤5/60else(5)V(t)={cos[π/2γ(3|t|−1)]1/3≤|t|≤2/31|t|≤1/30elsewhere γ is a smooth function satisfying:(6)γ(x)={00≤x1x≥1,γ(x)+γ(1−x)=1x∈RThe frequency window Ujis defined in the Fourier domain by(7)Uj(r,ϕ)=2−3j/4W(2−jr)V(2⌊j/2⌋ϕ2π),where the support of Ujis a polar “wedge” defined by the support of W and V applied with scale dependent window width. The frequency window Ujcorresponds to the Fourier transform of a curvelet φj, which can be thought of as a “mother” curvelet in the sense that the 2⌊j/2⌋ curvelets at scale2−jare obtained by rotations and translations of φj.Contrary to the DT-CWT and the GWT, which only cover part of the frequency spectrum in the frequency domain, curvelets have a complete cover of the spectrum in the frequency domain.In Candes et al. (2006), two second generation discrete curvelet transforms (DCT’s) are proposed, the DCT via unequispaced FFTs (fast fourier transforms) and the DCT via wrapping. We chose the wrapping based algorithm because it is the more often used algorithm for feature extraction purposes. This algorithm is implemented in the tool CurveLab (available at http://www.curvelet.org/). The DCT via wrapping uses a spatial grid to translate curvelets at each scale and angle using 2-D FFT, with the assumption that “Cartesian” curvelets are defined in a regular rectangular grid (see Fig. 12(b)). Then for each scales=2−jand orientation n, the product of Uj(the curvelet in FT domain) and the image in FT domain is obtained. Finally the product is wrapped around the origin and the 2-D inverse FFT is applied to the wrapped product, resulting in the curvelet coefficients at scale s and orientation n. The frequency tiling of the DCT can be seen in Fig. 12(b).It should be noted that in case of the DCT there is a different denotation of the scale levels compared to the wavelet transforms. Scale level 1 of the DCT denotes the coarsest scale level and consists of only one undirectional subband that can be considered as the approximation subband or as the lowpass subband. Scale levels 2 till L include the directional subbands and can be considered as detail subbands. The higher the scale level, the finer the scale of the subbands (the higher the frequency content in the subbands), which is the exact opposite of the wavelet transforms. That means comparing a 5 level DCT and a 4-level wavelet transform (WT), the level 1 subband of the DCT can be considered as the approximation subband of the wavelet transform and the DCT subbands of the levels {2,3,4,5} can be considered as the level {4,3,2,1} subbands of the WT (with respect to the frequency partition).If not stated otherwise, we employ curvelets using the four DCT subband levels {2,3,4,5} with 16 level 2 subbands, 32 level 3 subbands, 32 level 4 subbands and 64 level 5 subbands.In an attempt to provide a better discrete implementation of the curvelets, the contourlet representation has been proposed by Do and Vetterli (2005). The contourlet transform is designed to achieve essentially the same frequency tiling as the curvelet transform, however contourlets allow a different (selectable) number of directions at each scale and are not a discretization of the curvelets.The multiscale decomposition of the contourlet transform (CT) is obtained using the Laplacian pyramid (LP) decomposition (Burt and Adelson, 1983). The LP decomposition at each level generates a downsampled low-pass version of the image and the difference between the image and the prediction, resulting in a bandpass image. In Fig. 13we depict the LP decomposition, where H is the lowpass filter, G the synthesis filter and M the sampling matrix.At each level, a directional filter bank (DFB) is applied to the bandpass image (b) that leads to a decomposition of 2l(l∈N) subbands with wedge-shaped frequency partitioning as shown in Fig. 14.The DFB (Do, 2001) is constructed from two building blocks. The first one is a two-channel quincunx filter bank (Vetterli, 1984) that divides a 2-D spectrum into 2 directions: horizontal and vertical. The second building block of the DFB is a shearing operator, which amounts to just reordering of image samples.We use the CT implementation described in Do and Vetterli (2005), which is public available (http://www.mathworks.com/matlabcentral/ fileexchange/8837-contourlet-toolbox). In all of our employed contourlet based approaches, the CDF 9/7 filters are used for the CT decomposition. If not stated otherwise, we employ the CT using four decomposition levels with 8 orientations per level.The continuous shearlet transform (Easley et al., 2008) is based on parabolic scaling matrices Aato change the resolution and on shear matrices Bsto change the orientation:(8)Aj=(a00a1/2),Bs=(1s01),with a > 0 ands∈R.The shearlets are given by(9)ψa,s,k(x)=a3/4ψ(BsAax−k),wherek∈R2is the translation. The continuous shearlet transform is defined as the mapping forf∈R:(10)SHΨf(a,s,k)=〈f,ψa,s,k〉.The discrete shearlet transform (Easley et al., 2008) can be viewed as a simplifying theoretical justification of the contourlet transform. The shearlet transform offers more flexibility than the contourlet and curvelet transform (the directions per scale and the local support of the shearing filters are selectable). The first step of the discrete shearlet transform (ST) is to accomplish a multiscale partition using the Laplacian pyramid decomposition similar to the contourlet transform. Then the 2-D FFT is applied to the resulting highpass images. The samples in the frequency domain are taken not on a Cartesian grid, but along lines across the origin at various slopes, known as pseudo-polar grid. In order to obtain the directional localization, a band-pass filtering is applied using a frequency window function W, which is localized on a pair of trapezoids and constructed from the shearing filters using Meyer wavelets and which is also transformed to the frequency domain and taken on the pseudo-polar grid (for a more detailed description see Easley et al. (2008)). The final step is to re-assemble the Cartesian sampled values and apply the inverse 2-D FFT. The ST-scheme is showed in Fig. 15.The ST offers large flexibility in the choice of the frequency window and allows to choose an arbitrary number of directional subbands per decomposition level to adapt the transform to specific applications. In case of the DCT, only the number of the directional subbands of the second coarsest level (the coarsest level is the low-pass subband) can be chosen, and even this number has to be a multiple of 4. All other decomposition levels of the DCT have a fixed number of directional subbands depending on the number of the directional subbands in the second coarsest level. In case of the CT, the number of subbands can be chosen free, but the numbers have to be dyadic.We use the 2D Shearlet Toolbox software (http://www.math.uh.edu/~dlabate/software.html), which is described in Easley et al. (2008). It should be noted that contrary to the ST scheme shown in Fig. 15, we use the nonsubsampled shearlet transform using the nonsubsampled Laplacian pyramid transform. Since already the normal ST is highly redundant because of the missing anisotropic subsampling, the nonsubsampled shearlet transform is even more redundant. The ST subbands are all of the same size as the input image (like for the GWT).If not stated otherwise, we employ the ST using four decomposition levels with 8 orientations per level and shearing filters with a support size of 32 × 32.In this work we apply three preprocessing steps before each of the wavelet based methods.The first preprocessing step removes specular reflections, which often occur in endoscopic images and have a major impact to the resulting subband coefficients in affected areas. Reflections are detected by thresholding the Saturation and grayscale values of an image. Similar to Stehle et al. (2009), a pixel is identified as part of a specular reflection if its gray value is greater as 235 and its Saturation is smaller than 0.09. As this kind of segmentation usually tends to a under-segmentation, a morphological dilation using a disc of radiusr=5as the structuring element is applied to enlarge the segmented area. The segmented area is set to the average RGB color values of the adjacent pixels of the segmented area. To avoid sharp transitions between the segmented area and the surrounding area, the pixels surrounding the segmented area with less than 4 pixels distance to the segmented area are Gaussian blurred usingσ=2and a 10 × 10 mask.The most important preprocessing step is contrast-limited adaptive histogram equalization (CLAHE) Zuiderveld (1994). CLAHE is used to enhance the contrast and remove noise and intensity inhomogeneities. CLAHE is applied using 8 × 8 tiles and an uniform distribution for constructing the contrast transfer function. CLAHE operates on small regions in the image, called tiles, rather than the entire image. Each tile’s contrast is enhanced, so that the histogram of the output image is approximately flat. CLAHE distinctly enhances the results of the wavelet based methods.In the final preprocessing step, the images are (slightly) Gaussian blurred usingσ=0.5and a 3 × 3 mask. This step is done to slightly smooth the images and to remove noise.If not stated otherwise, the employed wavelet based methods are preprocessed using the previously described three steps, even if the methods are originally proposed using different or no preprocessing methods. For each method, the achieved classification rates increase using our preprocessing approach compared to the originally proposed preprocessing approaches or no preprocessing at all.For each of the wavelet based transforms (DWT, DT-CWT, Gabor wavelets, curvelet, contourlet and shearlet transform), the distribution of the subband coefficients is once modeled by means of the Gaussian distribution, the GGD and the Weibull distribution (Evans and Peacock, 2000; Kwitt and Uhl, 2007). The Gaussian distribution and the Weibull distribution are used to model the subband coefficient magnitudes, whereas the GGD is used to model the original subband coefficients in case of the employed wavelet transforms producing real valued coefficients (DWT, contourlets and shearlets) and the subband coefficient magnitudes in case of the employed wavelet transforms producing complex valued subband coefficients (DT-CWT, Gabor wavelets and curvelets).We chose the Gaussian distribution because extracting mean and standard deviation (the two parameters of the Gaussian distribution) of subband coefficients is probably the most known and most used approach to extract features of wavelet based transforms. The GGD is also a widely used feature to extract information from subbands of wavelet based transforms and it is able to model the subband coefficient distributions more accurate than the Gaussian distribution. In fact, the subbands of various types of wavelet transforms (with real valued subband coefficients) are well modeled using the GGD (Do and Vetterli, 2002). The Weibull distribution has been chosen because it already has been successfully used for the classification of polyps in combination with the DT-CWT and because it is able to accurately model the subband coefficient distribution of all employed wavelet based transforms, contrary to the Gaussian distribution and the GGD (see Section 5.1).The probability distribution of the GGD (Do and Vetterli, 2002) is defined as(11)p(x;μ,α,β)=β2αΓ(1/β)e−(|x−μ|/α)β,where Γ(.) denotes the gamma function, μ is the mean, α the scale parameter and β the shape parameter. Only the parameters α and β are extracted as features from the subbands for further classification. Distances between GGD feature vectors are measured using the Kullback–Leibler distance (Do and Vetterli, 2002), which is in case of the GGD defined as(12)D(p(.;α1,β1),∥p(.;α2,β2))=log(β1α2Γ(1/β2)β2α1Γ(1/β1))−1β1+α1α2β2Γ((β2+1)/β1)γ(1/β1).The probability density function of a Weibull distribution with shape parameter c and scale parameter b is given by(13)p(x;c,b)={cb(xb)c−1e−(xb)cforx≥0,0forx<0,where b > 0 and c > 0. The two parameters of the Weibull distribution are estimated using the method of moments (Niola et al., 2006).In case of the Gaussian and Weibull distribution, the resulting feature vectors are L2-normalized and distances between the feature vectors are measured using the Euclidean distance. The L2-normalization is important to balance the different ranges of coefficient values per decomposition level. All our employed wavelet based transforms have in common that the coefficients in the subbands representing the coarser image details are much higher than the coefficients in the subbands representing the finer image details. Given our d-dimensional samplesv1,⋯,vn,the normalization formula for the mth feature of the jth feature vector is defined by(14)v˜j(m)=vj(m)−v¯(m)s¯(m),wherev¯(m)ands¯(m)denote the sample mean and the sample variance of the mth features of the n feature vectors. In this way we obtain re-scaled features with zero-mean and unit standard deviation. Now each feature contributes equally to the calculation of the distance metric.The wavelet based transforms are applied using four decomposition levels (scales) for the extraction of Weibull, GGD and Gaussian features from the subbands. If not stated otherwise, all employed wavelet and wavelet based approaches are applied to RGB color images and the final feature vector consists of the concatenation of the features of the three color channels. So the length of a feature vector l(fv) resulting from extracting Gaussian, GGD or Weibull parameters from the subbands of a wavelet based transform is given by(15)l(fv)=3*2*NrSB,where 3 is the number of color channels, 2 is the number of parameters extracted by the probability distributions and NrSB is the number of subbands of the used wavelet based transform.Since we primarily focus on Lets in this work, we additionally reimplemented 2 texture analysis approaches based on curvelets (Gomez and Romero, 2011; Barbosa et al., 2009), 2 based on contourlets (Long and Younan, 2006; Dong and Ma, 2013) and 3 based on shearlets (Schwartz et al., 2011; He et al., 2013; Dong et al., 2015), which extract features that are different to the three previously described statistical features (Gaussian distribution, GGD and Weibull distribution). These approaches were published in well known journals or conferences.In this approach (Gomez and Romero, 2011), the same features are extracted as in the approach extracting GGD features using the DCT (DCT-GGD). Also the same distance metric is used. To achieve rotation invariance, the features of each scale level are circular shifted, using the dominant orientation as reference. The dominant orientation is defined as the orientation whose associated directional (second level) subband has the highest sum of absolute valued coefficients (the highest energy). Contrary to the original approach, we apply the same DCT decomposition as for the DCT-GGD approach. This has the advantage of a better comparability to the DCT-GGD approach, which is basically the same approach as the considered one but without cyclic shifted features to achieve rotation invariance. We further denote this approach as DCT-DO.This approach (Barbosa et al., 2009) firstly extracts the means and standard deviations (std) of the DCT subbands. Then the color covariance of these features can be calculated as follows:(16)CC(a,b,s,m)=∑α(Fm(a,s,α)−E{Fm(a,s,α)})×(Fm(b,s,α)−E{Fm(b,s,α)},where a and b represent two different color channels, Fmthe statistical texture descriptor (m=1: mean,m=2: std), α is the considered angle of the DCT subband, s the considered DCT level and E{Fm(a, s, α)} the average of the statistical texture descriptor Fmover the different directions in the color channel a.It should be noted that in this approach the HSV color space is used instead of the RGB color space like for all other approaches and that we did not apply CLAHE as preprocessing step (CLAHE cannot be applied to all HSV color channels). The DCT decomposition results in a lowpass subband and two levels of directional subbands with 8 and 16 orientations (we only use the directional subbands) resulting in a feature vector of an image of length 24 (6 combinations of color channels × 2 scale levels × 2 parameters). We further denote this approach as DCT color covariance feature (DCT-CCF).In this approach (Long and Younan, 2006), the CT subband coefficients are modeled using histograms with 10 bins. Distances between two feature vectors are measured using the χ2 distance metric:(17)χ2(x,y)=∑i(xi−yi)2xi+yi.The CT is applied using 3 decomposition levels with 8 directional subbands per level resulting in 24 directional subbands and the low-pass subband. The final feature vector of an image has length 750 (3 color channels × 25 subbands × 10 bins per histogram). We further denote this approach as CT-Histogram.In this approach (Dong and Ma, 2013) the k-means clustering algorithm is used to find 3 cluster centers of the CT subband coefficients, which are used as features for further classification. First, the CT decomposes an image intoL=4levels with 8 directional subbands per level and the low-pass subband. With increasing decomposition level i (from fine (i=1) to coarse (i=4)), the average amplitude of the CT coefficients increases almost exponentially. The by far highest coefficient values are in the low-pass subband. To balance the different ranges of coefficient values per decomposition level, the low-pass subband coefficients are multiplied by the factor of 1/4Land the detail subband coefficients of decomposition level i (i∈{1,2,…,L}) are multiplied by the factor of1/4i−1(in the publication describing the approach (Dong and Ma, 2013) the authors wrote 1/4i, but we think this is a typo since this factor would not consider the far higher coefficient values in the low-pass subband). Additionally, the variance and norm-2 energy of each subband is extracted, resulting in a feature vector’s length of 990 (3 color levels × 33 subbands × 5 parameters (3 clusters, variance and energy)). We further denote this approach as CT-Cluster.In this approach (Schwartz et al., 2011), the energy of the subband coefficients is used as feature:(18)E(s)=∑|s(x)|,where s denotes a subband. The energy feature is computed from the subbands of a 4 level ST decomposition with 8 directional subbands per level. The resulting feature vectors are L2-normalized and have length 81 (3 color channels × 4 levels × 8 orientations per level × 1 parameter). This approach will be further denoted as the ST-Energy approach.In this approach (He et al., 2013), a feature based on local binary patterns (LBP) (Ojala et al., 2002) is extracted from the subband coefficients of the ST decomposition. First, two local features are computed as follows:(19)ei,jl,d=19∑p=−11∑q=−11|si+p,j+ql,d|(20)gi,jl,d=−1log(9)∑p=−11∑q=−11|si+p,j+ql,d|normi,jl,dlog(|si+p,j+ql,d|normi,jl,d)where si, jis the shearlet coefficient at (i, j) in the d’th directional subband within the l’th decomposition level and(21)normi,jl,d=∑p=−11∑q=−11|si+p,j+ql,d|.Then these features are normalized and by means of thresholdstnl(n ∈ {0, 1, 2}) witht1l<t2l<t2l,an integer value m between 0 and 3 is assigned to each local featureei,jl,d(gi,jl,danalogous with different threshold values) in each decomposition level l:(22)mi,jl,d=={0forei,jl,d<t0l1fort0l<ei,jl,d<t1l2fort1l<ei,jl,d<t2l3forei,jl,d>t2lThe local shearlet-based energy pattern (LSEP) is defined as(23)LSEPi,jl∑d=1Dmi,jl,d3d−1.To achieve orientation invariancemi,jl,dis sorted before the LSEP computation, so that the values of a given level l and position (i, j) are ascending in the orientation dimension (D=4directions are used and so e.g.mi,jl=2,1,2,0becomesmi,jl=0,1,2,2).The support size of the shearlet filters is 16 × 16. The final step is to build histograms of the LSEP’s and to concatenate these histograms into a feature vector. The final feature vector of an image consists of 270 elements (3 color channels × 3 scales × 2 local features × 15 bins per histogram). Distances between feature vectors are measured using the χ2 distance metric. We further denote this approach as ST-LSEP.In this approach (Dong et al., 2015), regression is used as a tool to investigate the dependences between shearlet subbands at different scale levels.By applying theL=3level shearlet transform using shearlet filters with support size 30 × 30, we obtain one low-pass subband andD=10directional subbands at each scale. From each subband the norm-1 (mean) and norm-2 energy is computed. Such a subband feature at scale i and direction d from an image n (n∈{1,…,N}) of class c is further denoted asqc,ni,d. Then the samples{(qc,ni−1,d,qc,ni,d)}n=1N(further denoted as{(xn,yn)}n=1N) can be seen as the N observations of (X, Y). The following linear regression models the dependences between the shearlet subband features at neighboring scale levels:(24)E(Y|X=x)=β0+β1xUsing the training images, the estimatesβ^0c,i,dandβ^1c,i,dare computed for each class c, where d denotes the direction and i the scale level.Given a test image and a pair of extracted features (qi−1,d,qi,d), the residual dci, d is computed as follows:(25)dci,d=|qi,d−q^i,d|where(26)q^i,d=E(Y|X=qi−1,d)=β^0c,i,d+β^1c,i,dqi−1,dThe distance from the test image I to the cth class Tcis defined as the weighted summation of residuals (WSR):(27)DWSR(I,Tc)=∑d=1D∑i=1L2idc,norm1i,d+∑d=1D∑i=1L2idc,norm2i,d,where dc, norm1 (dc, norm2) is the residual using norm-1 (norm-2) energy as subband feature. The test image I is assigned to the class corresponding to the minimum of{DWSR(I,Tc)}c=1C.So contrary to the other methods, there is no feature vector as output of a image. The output of an evaluation set image is the predicted class. This approach will be further denoted as the ST-Reg approach.In this sections we will describe a variety of state of the art methods for colonic polyp classification which are not based on wavelets or Lets. By means of these methods we are able to compare the results of the wavelet based approaches with the results of state-of-the-art methods.This feature extraction method (Häfner et al., 2014c) is derived from the local fractal dimension (LFD) (Varma and Garg, 2007; Xu et al., 2009). For a given pixel locationx=(x1,x2),the local fractal dimension LFD(x) analyzes the changes of the intensity distribution of differently sized circle shaped regions of the image centered at the point x. This is usually done by filtering the image I with circle shaped binary filters withr=1,2,3,…,8and the LFD is computed for each pixel location by estimating the slope of the filter responses with increasing radii.Contrary to the original LFD approach, the considered approach (Häfner et al., 2014c) enhances the viewpoint invariance using elliptic shaped binary and Gaussian filters, whose shape, size and orientation is adapted to the local texture structure. The final feature vector consists of the histograms of the LFD’s.This approach (Häfner et al., 2014a) consists of two steps. The first step is a segmentation algorithm, that applies local region growing to the maxima and minima of the image in a similar way as the watershed segmentation by immersion (Roerdink and Meijster, 2000). The resulting blobs represent the local texture structures of an image.In the second step, 3 shape features and a contrast feature are extracted from the blobs. The final feature vector consists of the histograms of these 4 features.This approach (Tamaki et al., 2013) combines densely computed SIFT features with the bag-of-visual-words (BoW) approach. The SIFT descriptors are sampled at points on a regular grid. From these SIFT descriptors, cluster centers (visual words) are learned by means of k-means clustering. Given an image, its corresponding model is generated by labeling its SIFT descriptors with the texton that lies closest to it. We use the same parameters that led to the best results in Tamaki et al. (2013) (grid spacing = 5, SIFT scale 5 and 7), but with a lower number of visual words (only 600 instead of up to over 10000 visual words in (Tamaki et al., 2013)). In our experiments, the lower number of visual words led to better results and less (but still huge) computational cost. In Tamaki et al. (2013), this approach is used for the colonic polyp classification in NBI endoscopy, however, there is no reason why this approach should not also be suited for other imaging modalities like the i-Scan technology or chromoendoscopy. The computation of the SIFT descriptors and the following k-means clustering is done using the Matlab software provided by the VLFeat open source library (Vedaldi and Fulkerson, 2008).This approach (Gross et al., 2012) segments the blood vessel structure on polyps by means of the phase symmetry (Kovesi, 1999). Vessel segmentation starts with the phase symmetry filter, whose output represents the vessel structure of polyps. By thresholding the output, a binary image is generated, and from this image 8 features are computed that represent the shape, size, contrast and the underlying color of the connected components (the segmented vessels). This method is especially designed to analyze the vessel structures of polyps in NBI images and is probably not suited for imaging modalities that are not designed to highlighting the blood vessel structure. Hence, this method is most probably not suited for any other image processing task than endoscopic polyp classification using NBI.We use the implementation of the phase symmetry filter (Kovesi, 2000) for the vascularization feature approach.Based on a grayscale image, the LBP operator generates a binary sequence for each pixel by thresholding the neighbors of the pixel by the center pixel value. The binary sequences are then treated as numbers (i.e. the LBP numbers). Once all LBP numbers for an image are computed, a histogram based on these numbers is generated and used as feature vector. There are several variations of the LBP operator and they are used for a variety of image processing tasks including endoscopic polyp detection and classification (e.g. Häfner et al. (2012b)). Because of its superior results compared to the standard LBP operator LBP(8, 1) (with block size = 3), we use a multiscale block binary patterns (MB-LBP) operator (Liao et al., 2007) with three different block sizes (3,9,15). The uniform LBP histograms of the 3 scales (block sizes) are concatenated resulting in a feature vector with3×59=177features per image.For each type of the employed wavelet-based transforms we employ three approaches extracting three different types of statistical features (Gaussian GGD and Weibull features), which describe the subband coefficient distributions. The remaining methods are listed and characterized in Table 1.

@&#CONCLUSIONS@&#
