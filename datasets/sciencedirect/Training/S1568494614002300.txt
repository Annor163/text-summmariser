@&#MAIN-TITLE@&#
Multi-objective optimization and bio-inspired methods applied to machinability of stainless steel

@&#HIGHLIGHTS@&#
Simultaneous optimization with various responses is configured as a necessary strategy in real process.Machinability of stainless steel has been considered a difficult task and any movement toward optimization of this process are really worthy.Traditionally, the treatment of this problem is done through the application of the desirability function.The present work proposes a methodology to solve the problem by using the BOM.The proposed algorithm is applied to the machinability of stainless steel ABNT420.

@&#KEYPHRASES@&#
Multi-objective optimization,Bio-inspired optimization methods,Multi-response,Machinability of stainless steel,

@&#ABSTRACT@&#
Nowadays, due to the growing needs of market, the simultaneous optimization of various responses is configured as a necessary strategy in real process. Machinability of stainless steel has always been considered a difficult task and any movement toward optimization of this process are really worthy. Traditionally, the treatment of this problem is done through the application of the desirability function that consists in transforming the original multi-response problem in a similar with one objective. In spite of various applications involving this methodology, the quality of the solution obtained is dependent on the choice of the inferior and superior limits and on goals for each one of the responses. To overcome this disadvantage, the present work proposes a methodology to solve the original multi-objective problem by using the Bio-inspired Optimization Methods (BiOM). The strategy proposed consists in the extension of the BiOM to problems with multiple objectives, through the incorporation of two operators into the original algorithm: (i) the rank ordering, and (ii) the crowding distance. The proposed algorithm is applied to the machinability of stainless steel AISI (ABNT) 420 using a model that considers the tool life and cutting forces responses in terms of cutting speed, feed per tooth and axial depth of cut, in end milling process. The effects of these variables in the responses were investigated crossing information contained in response surfaces of material removal rate and cutting forces. The results obtained showed that the methodology used represents an interesting approach to the treatment of the optimization problem formulated.

@&#INTRODUCTION@&#
Naturally, real-world problems involve the simultaneous optimization of two or more (often conflicting) objectives, called multi-objective optimization problem (MOOP). The solution of such problems is different from that of a single-objective optimization problem.The main difference is that multi-objective optimization problems normally have not one but a set of solutions, which may all be equally good [1].Traditionally, the treatment of such problems is done transforming the original MOOP into one-objective problem. However, the development of specific methodologies allows the formulation of the optimization problem in a way that various objectives can be taken into account simultaneously. In addition, as a number of points that constitutes the optimal solution is found, it is possible to explore these solutions according to the practical application studied [1]. In the literature, several methods for solving MOOP can be found [1]. These methods follow a preference-based approach, in which a relative preference vector is used to scalarize multiple objectives. Since classical searching and optimization methods use a point-by-point approach, at which the solution is successively modified, the outcome of this classical optimization method is a single optimized solution. However, evolutionary algorithms (EA) can find multiple optimal solutions in one single simulation run due to their population-based search approach. Thus, EA are ideally suited for multi-objective optimization problems. A detailed account of multi-objective optimization using EA and some of the applications using genetic algorithms can be widely found in literatures [1,2].In many engineering applications, it is necessary to find the conditions under which a certain process attains the optimal results. That is, they want to determine the levels of the design parameters at which the response reaches its optimum. The optimum could be either a maximum or a minimum of a function of the design parameters. One of the methodologies for obtaining the optimum is response surface technique (RS). This approach is a collection of statistical and mathematical methods that are useful for the modeling and analyzing engineering problems. The main objective is to optimize the response surface that is influenced by various process parameters.Response surface also quantifies the relationship between the controllable input parameters and the obtained response surfaces. The design procedure of response surface methodology is as follows [3]: (i) designing of a series of experiments for adequate and reliable measurement of the response of interest; (ii) developing a mathematical model of the second order response surface with the best fittings; (iii) finding the optimal set of experimental parameters that produce a maximum or minimum value of response.In this context, Pettersson et al. [4] proposed a genetic algorithm based multi-objective optimization technique for the training process of a feed forward neural network, using noisy data from an industrial iron blast furnace. Recently, Giri et al. [5] proposed a new bi-objective genetic programming (BioGP) for meta-modeling and applied in a chromatographic separation process using a simulated moving bed (SMB) process. The BioGP technique initially minimizes training error through a single objective optimization procedure and then a trade-off between complexity and accuracy is worked out through a genetic algorithm based bi-objective optimization strategy.Associate with the MOOP, the multi-response surface technique is configured as good strategy to treatment of real-world problems. In this sense, the desirability function approach, originally developed by Harrington [6] and later modified by Derringer and Suich [7], to multi-response optimization is a useful technique for the analysis of experiments in which several responses have to be optimized simultaneously. The basic idea of the desirability function approach is to transform a multi-response problem into a single response problem by means of mathematical transformations.One very important manufacturing process is machining, which possesses a large number of variables. When measuring the way a material behaves under cutting one is determining its machinability. Therefore, machinability must be understood as a system of properties which depends on complex interactions among workpiece, tool material, cutting fluid and cut conditions. Trent [8] suggests that machinability is not only a property, but the “way” material behaves during machining. Therefore, machinability is much more than a test function, and it's improvement is characterized by, at least, one of the following factors: increase of tool life, higher rate of material removal, improvement of surface finishing, better chip control, reduction of cutting forces and power consumption, decrease of the cutting temperature, etc. According to its duration, the tests of machinability are classified in to short and long term duration. And the best example of long lasting test is the tool life test and their results, generally presented using Taylor's equation.Stainless steel is one of the main materials employed in critical parts for installation of power plants and modern chemical industries due to combination of appropriate mechanical properties and high corrosion resistance. However, the composition required allowing such properties results in poor machinability of this steel, right below to that for the carbon steel. High rate of strain hardening, high toughness and low thermal conductivity are the main factors that cooperate for this. As a consequence, the machinability of stainless steel tends to present short tool life, especially in intermittent cut operations like milling, where thermal and mechanical shocks are observed [9]. Non-traditional machining has also many variables and process optimization is also challenging. Zhang et al. [10] analyzed the workpiece surface quality and the material removal rate on process parameters during machining a cold work die steel SKD11 (AISI D2) by medium-speed wire electrical discharge machining (MS-WEDM). The experimental data were utilized to material removal rate model and workpiece surface quality under optimal parameter condition by a backpropagation neural network combined with genetic algorithm (BPNN-GA) method. Another example of optimization within the area of machining was provided by Klancnik et al. [11] that proposed a system for the automatic programming of a CNC milling machine by particle swarm optimization (PSO). In the algorithm proposed, each individual swarm particle presents a possible numerical control (NC) program.In this work, the machinability of AISI (ABNT) 420 stainless steel in end milling operation is analyzed using a model that foresees the responses of tool life and cutting forces in terms of cutting speed, feed per tooth and axial depth of cut. The effects of these variables in the responses were investigated crossing information contained in the bound surfaces of material removal rate and cutting force.In this context, the main contribution of this paper is to introduce a systematic methodology for the solution of multi-objective optimization problems by using the bio-inspired optimization methods. These methodologies are based on strategies that seek to mimic the behavior observed in species found in the nature to update a population of candidates to solve optimization problems [12,13]. These systems have the capacity to notice and modify their environment in order to seek for diversity and convergence. In addition, this capacity makes possible the communication among the agents (individuals of population) that capture the changes in the environment generated by local interactions [14]. Among the most recent bio-inspired strategies stand the Bees Colony Algorithm – BCA [15], the Firefly Colony Algorithm – FCA [16], and the Fish Swarm Algorithm – FSA [17]. The BCA is based on the behavior of bees colonies in their search of raw materials for honey production. According to Lucic and Teodorovic [18], in each hive groups of bees (called scouts) are recruited to explore new areas in search for pollen and nectar. These bees, returning to the hive, share the acquired information so that new bees are indicated to explore the best regions visited in an amount proportional to the previously passed assessment. Thus, the most promising regions are best explored and eventually the least end up being discarded. Every iteration in this cycle repeats itself with new areas being visited by scouts. The FCA mimics the patterns of short and rhythmic flashes emitted by fireflies in order to attract other individuals to their vicinities. The corresponding optimization algorithm is formulated by assuming that all fireflies are unisex, so that one firefly will be attracted to all other fireflies. Attractiveness is proportional to their brightness, and for any two fireflies, the less bright will attract (and thus move to) the brighter one. However, the brightness can decrease as their distance increases and if there are no fireflies brighter than a given firefly it will move randomly. The brightness is associated with the objective function for optimization purposes [16]. Finally, the FSA is a random search algorithm based on the behavior of fish swarm observed in nature. This behaviors may be summarized as follows [17]: random behavior – in general, fish looks at random for food and other companion; searching behavior – when the fish discovers a region with more food, it will go directly and quickly to that region; swarming behavior – when swimming, fish will swarm naturally in order to avoid danger; chasing behavior – when a fish in the swarm discovers food, the others will find the food dangling after it; and leaping behavior – when fish stagnates in a region, a leap is required to look for food in other regions.This work is organized as follows. Section 2 presents the desirability function concept. The mathematical formulation of multi-objective optimization is presented in Section 3. A review of the BiOM and its extension for multi-objective context are presented in Sections 4 and 5. Section 6 presents the methodology proposed in this work. The results and discussion are described in Section 7. Finally, the conclusions conclude the paper.The desirability function approach is one of the most widely used methods in industry for the optimization of multiple response processes. It is based on the idea that the “quality” of a product or process that has multiple quality characteristics, with one of them outside of some “desired” limits, is completely unacceptable. The method finds the operating conditions x that provide the “most desirable” response values.For each response Yi(x), an individual desirability function di(Yi) assigns numbers between 0 and 1 to the possible values of Yi(x), with di(Yi)=0 representing a completely undesirable value of Yi(x) and di(Yi)=1 representing a completely desirable or ideal response value. The individual desirabilities are then combined using the geometric mean, which gives the overall desirability D:(1)D=(d1(Y1)×d2(Y2)×⋯×dk(Yk))1/kwith k denoting the number of responses.Depending on whether a particular response Yi(x) is to be maximized, minimized, or assigned a target value, different desirability functions di(Yi) can be used. For example, if a response is of the “target is best” kind, then its individual desirability function is(2)di(Yi)=0ifYi(x)<LiYi(x)−LiTi−LisifLi≤Yi(x)<TiYi(x)−UiTi−UitifTi≤Yi(x)<Ui0ifYi(x)>UiIf a response should be maximized, the individual desirability function is defined as(3)di(Yi)=0ifYi(x)<LiYi(x)−LiTi−LisifLi≤Yi(x)<Ti1ifYi(x)>TiIf a response should be minimized, the individual desirability function is defined as(4)di(Yi)=1ifYi(x)<TiYi(x)−UiTi−UisifTi≤Yi(x)<Ui0ifYi(x)>Uiwhere Li, Uiand Tibe the lower, upper, and target values, respectively, that are desired for response Yi(x), with Li≤Ti≤Ui. The exponents s and t determine how important it is to hit the target value. For s=t=1, the desirability function increases linearly toward Ti; for s<1, t<1, the function is convex, and for s>1, t>1, the function is concave.It should be considered that, in spite of quite spread, this approach present some difficulties [7]: (i) dependence of choice of individual desirability functions; (ii) the increase of the non-linearity of D and of number of responses can lead to location of optimal; (iii) the quality of solution obtained is affected drastically by definition of Li, Tiand Ui.When dealing with MOOP, the notion of optimality needs to be extended. The most common one in the current literature is that originally proposed by Edgeworth [19] and later generalized by Pareto [20]. This notion is called Edgeworth–Pareto optimality, or simply Pareto optimality, and refers to finding good tradeoffs among all the objectives. This definition leads us to find a set of solutions that is called the Pareto optimal set, whose corresponding elements are called non-dominated or non-inferior. The concept of optimality in single objective is not directly applicable in MOOPs. For this reason a classification of the solutions is introduced in terms of Pareto optimality, according to the following definitions [1]:Definition 1The multi-objective optimization problem (MOOP) can be defined as(5)f(x)=(f(x)1,f2(x),…,fm(x)),m=1,…,Msubject to(6)h(x)=(h1(x),h2(x),…,hi(x)),i=1,…,H(7)g(x)=(g1(x),g2(x),…,gj(x)),j=1,…,J(8)x=(x1,x2,…,xn),n=1,…,N,x∈Xwhere x is the vector of design (or decision) variables, f is the vector of objective functions and X is denoted as the design (or decision) space. The constraints h and g (≥0) determine the feasible region.Pareto optimality: When the set P is the entire search space, or P=S, the resulting non-dominated set P′ is called the Pareto-optimal set. Like global and local optimal solutions in the case of single-objective optimization, there could be global and local Pareto-optimal sets in multi-objective optimization.Non-dominated set: Among a set of solutions P, the non-dominated set of solutions P′ are those that are not dominated by any member of the set P.In the multi-objective context, various multiple-objective evolutionary algorithms (MOEAs) can be found. This group of algorithms conjugates the basic concepts of dominance described in the later section with the general characteristics of evolutionary algorithms. MOEAS are able to deal with non-continuous, non-convex and/or non-linear spaces, as well as problems whose objective functions are not explicitly known [1]. Basically, the main features of these MOEAs are:•Mechanism of adaptation assignment in terms of dominance. Between one non-dominated solution and another dominated, the algorithm will favor the non-dominated one. Moreover, when both solutions are equivalent in dominance, the one located in a less crowded area will be favored. Finally, the extreme points, (e.g., the solutions that have the best value in one particular objective) of the non-dominated population are preserved and their adaptation is better than any other non-dominated point, to allow maximum front expansion.Incorporation of elitism. The elitism is commonly implemented using a secondary population of non-dominated solutions previously stored. When performing recombination (selection-crossover-mutation), parents are taken from this archive in order to produce the offspring.This optimization algorithm is based on the behavior of a colony of honey bees. The colony can extend itself over long distances and in multiple directions simultaneously to exploit a large number of food sources. In addition, the colony of honey bees presents as characteristic the capacity of memorization, learning and transmission of information, thus forming the so-called swarm intelligence [21].In a colony the foraging process begins by scout bees being sent to search randomly for promising flower patches. When they return to the hive, those scout bees that found a patch which is rated above a certain quality threshold (measured as a combination of some constituents, such as sugar content) deposit their nectar or pollen and go to the waggle dance. This dance is responsible for the transmission (colony communication) of information regarding a particular flower patch: the direction in which it will be found, its distance from the hive and its quality rating (or fitness) [21]. The waggle dance enables the colony to evaluate the relative merit of different paths according to both the quality of the food they provide and the amount of energy needed to harvest it [22]. After waggle dancing, the dancer (scout bee) goes back to the flower patch with follower bees that were waiting inside the hive. More follower bees are sent to more promising patches. This allows the colony to gather food quickly and efficiently. While harvesting from a patch, the bees monitor its food level. This is necessary to decide upon the next waggle dance when they return to the hive [22]. If the patch is still good enough as a food source, then it will be advertised in the waggle dance and more bees will be recruited to that source. In this context, Pham and co-workers [15] proposed an optimization algorithm inspired by the natural foraging behavior of honey bees (Bees Colony Algorithm – BCA) as presented in Table 1.The BCA requires a number of parameters to be set, namely, the number of scout bees (n), number of sites selected for neighborhood search (out of n visited sites) (m), number of top-rated (elite) sites among m selected sites (e), number of bees recruited for the best e sites (nep), number of bees recruited for the other (m−e) selected sites, neighborhood search (ngh), and the stopping criterion.The BCA starts with the n scout bees being placed randomly in the search space. The fitnesses of the sites visited by the scout bees are evaluated in step 2.In step 4, bees that have the highest fitnesses are chosen as selected bees and sites visited by them are chosen for neighborhood search. Then, in steps 5 and 6, the algorithm conducts searches in the neighborhood of the selected sites, assigning more bees to search near to the best e sites. The bees can be chosen directly according to the fitnesses associated with the sites they are visiting.Alternatively, the fitness values are used to determine the probability of the bees being selected. Searches in the neighborhood of the best e sites, which represent more promising solutions, are made more detailed by recruiting more bees to follow them than the other selected bees. Together with scouting, this differential recruitment is a key operation of the BCA.However, in step 6, for each patch only the bee with the highest fitness will be selected to form the next bee population. In nature, there is no such restriction. This restriction is introduced here to reduce the number of points to be explored. In step 7, the remaining bees in the population are assigned randomly around the search space scouting for new potential solutions.In the literature, various applications using this bio-inspired approach can be found, such as modeling combinatorial optimization transportation engineering problems [18], optimal control problems [23], engineering system design [12,24], mathematical function optimization [15], transport problems [25], dynamic optimization [26], parameter estimation in control problems [13,27], among other applications (http://www.bees-algorithm.com/).The FCA is based on the characteristic of the bioluminescence of fireflies, insects notorious for their light emission. According to Yang [16], biology does not have a complete knowledge to determine all the utilities that firefly luminescence can bring to, but at least three functions have been identified: (i) as a communication tool and appeal to potential partners in reproduction, (ii) as a bait to lure potential prey for the firefly, (iii) as a warning mechanism for potential predators reminding them that fireflies have a bitter taste.In this way, the bioluminescent signals are known to serve as elements of courtship rituals (in most cases, the females are attracted by the light emitted by the males), methods of prey attraction, social orientation or as a warning signal to predators [28].Some of the flashing characteristics of fireflies were idealized so as to develop firefly-inspired algorithms. For simplicity the following three idealized rules are used [29]:•all fireflies are unisex so that one firefly will be attracted to other fireflies regardless of their sex;attractiveness is proportional to their brightness; thus, for any two flashing fireflies, the less brighter will move toward the brighter one. The attractiveness is proportional to the brightness and they both decrease as their distance increases. If there is no brighter one than a particular firefly, it will move randomly;the brightness of a firefly is affected or determined by the landscape of the objective function. For a maximization problem, the brightness can simply be proportional to the value of the objective function.According to Yang [16], in the firefly algorithm there are two important issues: the variation of light intensity and the formulation of the attractiveness. For simplicity, it is always assumed that the attractiveness of a firefly is determined by its brightness, which in turn is associated with the encoded objective function.This swarm intelligence optimization technique is based on the assumption that the solution of an optimization problem can be perceived as agent (firefly) which glows proportionally to its quality in a considered problem setting. Consequently, each brighter firefly attracts its partners (regardless of their sex), which makes the search space being explored more efficiently. The algorithm makes use of a synergic local search. Each member of the swarm explores the problem space taking into account results obtained by others, still applying its own randomized moves as well. The influence of other solutions is controlled by the attractiveness value [28].According to Lukasik and Zak [28], the FCA can be presented as follows. Consider a continuous constrained optimization problem where the task is to minimize the cost function f(x).(9)f(x*)=minx∈Sf(x)Assume that there exists a swarm of maagents (fireflies) solving the above-mentioned problem iteratively and xirepresents a solution for a firefly i in algorithm's iteration k, whereas f(xi) denotes its cost. Initially, all fireflies are dislocated in S (randomly or employing some deterministic strategy). Each firefly has its distinctive attractiveness λ which implies how strong it attracts other members of the swarm. As the firefly attractiveness, one should select any monotonically decreasing function of the distance rj=d(xi,xj) to the chosen firefly j, e.g., the exponential function:(10)λ=λ0exp(−γrj)where λ0 and γ are predetermined algorithm parameters: maximum attractiveness value and absorption coefficient, respectively. Furthermore every member of the swarm is characterized by its light intensity Iiwhich can be directly expressed as a inverse of a cost function f(xi). To effectively explore considered search space S it is assumed that each firefly i is changing its position iteratively taking into account two factors: attractiveness of other swarm members with higher light intensity, e.g., Ij>Ii, for all j=1,…,ma, j≠i which is varying across distance and a fixed random step vector ui. It should be noted as well that if no brighter firefly can be found only such randomized step is being used.Thus, moving at a given time step t of a firefly i toward a better firefly j is defined as(11)xit=xit−1+λ(xjt−1−xit−1)+α(rand−0.5)where the second term on the right side of the equation inserts the factor of attractiveness λ while the third term, governed by α parameter, governs the insertion of certain randomness in the path followed by the firefly, rand is a random number between 0 and 1.In the literature, few works using the FCA can be found. In this context, is emphasized application in continuous constrained optimization task [28], multimodal optimization [30], solution of singular optimal control problems [31], economic emissions load dispatch problem [32], and parameter estimation in control problems [13].In the development of the FSA, based on fish swarm and observed in nature, the following characteristics are considered [17,33]: (i) each fish represents a candidate solution of optimization problem; (ii) food density is related to an objective function to be optimized (in an optimization problem, the amount of food in a region is inversely proportional to value of objective function); and (iii) the aquarium is the design space where the fish can be found.As noted earlier, the fish weight at the swarm represents the accumulation of food (e.g., the objective function) received during the evolutionary process. In this case, the weight is an indicator of success [17,33]. Basically, the FSA presents four operators classified into two classes: “food search” and “movement”. Details on each of these operators are shown as follows.This operator contributes for the movement individual and collective of fishes in the swarm. Each fish updates its new position using Eq. (12):(12)xit+1=xit+rand×sindwhere xiis the final position of fish i at current generation, rand is a random generator and sindis a weighted parameter.The weight of each fish is a metaphor used to measure the success of food search. The higher the weight of a fish, the more likely this fish is in a potentially interesting region in the designed space.According to Madeiro [33], the amount of food that a fish eats depends on the improvement in its objective function in the current generation and the greatest value considering the swarm. The weight is updated according to Eq. (13):(13)Wit+1=Wit+Δfimax(Δf)where Witis the fish weight i at generation t and Δfiis the difference of objective function between the current position and the new position of fish i. It is important to emphasize that Δfi=0 for the fishes in same position.This operator is important for the individual movement of fishes when Δfi≠0. Thus, only the fishes whose individual execution of the movement resulted in improvement of their fitness will influence the direction of motion of the school, resulting in instinctive collective movement. In this case, the resulting direction (Id), calculated using the contribution of the directions taken by the fish, and the new position of the ith fish are given by(14)I→t=∑i=1NΔx→iΔfi∑i=1NΔfi(15)x→it+1=x→it+I→tIt is important to emphasize that in the application of this operator, the direction chosen by a fish that located the largest portion of food exerts the greatest influence on the swarm. Therefore, the instinctive collective movement operator tends to guide the swarm in the direction of motion chosen by fish who found the largest portion of food in it individual movement.As noted earlier, the fish weight is a good indication of search success for food. In this way, the swarm weight is increasing, this means that the search process is successful. So, the “radius” of the swarm must decrease for that other regions can be explored. Otherwise, if the swarm weight remains constant, the radius should increase to allow the exploration of new regions.For the swarm contraction, the centroid concept is used. This is obtained by means of an average position of all fish weighted with the respective fish weights, according to Eq. (16):(16)B→t=∑i=1Nx→iWit∑i=1NWitIf the swarm weight remains constant in the current iteration, all fish must update their positions using Eq. (17):(17)x→t+1=x→t−svol×rand×x→t−B→td(x→t,B→t)where d is a function that calculates the Euclidean distance between the centroid and the current position of fish, and svolis the step size used to control fish displacements.In the literature, few works using the FSA can be found. In this context the following can be cited: parameter estimation in engineering systems [34], feed forward neural networks [35], combinatorial optimization problem [36], Augmented Lagrangian fish swarm based method for global optimization [37], forecasting stock indices using radial basis function neural networks optimized [38], hybridization of the FSA with the particle swarm algorithm to solve engineering systems [39], and parameter estimation in control problems [13].Due to success obtained by BiOM in different applications in science and engineering, several attempts to extend the BiOM to solve multi-objective problems can be found in the literature. In this work, the MOBC (multi-objective optimization bee colony), MOFC (multi-objective optimization firefly colony) and MOFS (multi-objective optimization fish swarm) algorithms are used. Each approach proposed is based on BCA, FCA and FSA algorithms and has the following structure: an initial population of size N is randomly generated. All dominated solutions are removed from the population through the operator fast non-dominated sorting. In this way, the population is sorted into non-dominated fronts Fj (sets of vectors that are non-dominated with respect to each other). This procedure is repeated until each vector is member of a front. A child is generated from the three parents (this process continues until N children are generated).The new population is then classified according to the dominance criterion. If the number of individuals of this population is larger than a number defined by the user, it is truncated according to the criterion named the crowding distance [1]. The crowding distance describes the density of solutions surrounding a vector. To compute the crowding distance for a set of population members the vectors are sorted according to their objective function value for each objective function. To the vectors with the smallest or largest values an infinite crowding distance (or an arbitrarily large number for practical purposes) is assigned. For all other vectors the crowding distance is calculated according to(18)distxi=∑j=0m−1fj,i+1−fj,i−1|fj,max−fj,min|where fjcorresponds to the jth objective function and m equals the number of objective functions.

@&#CONCLUSIONS@&#
In this work it was studied the treatment of multi-response surface using the desirability function approach and multi-objective optimization associated with the bee colony algorithm, firefly colony algorithm and fish swarm algorithm considering the same number of objective function evaluations in all cases to better comparison among the algorithms.The proposed algorithms was applied to machinability of AISI (ABNT) 420 stainless steel using a model that foresees the responses of tool life and cutting forces in terms of cutting speed, feed per tooth and axial depth of cut. The effects of these variables in the responses were investigated crossing information contained in the bound surfaces of material removal rate and cutting force.The results obtained show that the methodology used represents an interesting approach to the treatment of the optimization problem formulated.Finally, it is important to observe that the methodology proposed in this work eliminate the necessity transformation of original multi-response problem in a similar with one objective, e.g., solve the original multi-objective problem.