@&#MAIN-TITLE@&#
Detection of the optic disc in fundus images by combining probability models

@&#HIGHLIGHTS@&#
We propose an ensemble framework of detectors for OD localization.We use probability maps for the detection.We investigate some combination approach.Our method outperforms several state-of-the-art approaches.

@&#KEYPHRASES@&#
Optic disc,Object detection,Ensemble-based system,Naïve Bayes,Information fusion,

@&#ABSTRACT@&#
In this paper, we propose a combination method for the automatic detection of the optic disc (OD) in fundus images based on ensembles of individual algorithms. We have studied and adapted some of the state-of-the-art OD detectors and finally organized them into a complex framework in order to maximize the accuracy of the localization of the OD. The detection of the OD can be considered as a single-object detection problem. This object can be localized with high accuracy by several algorithms extracting single candidates for the center of the OD and the final location can be defined using a single majority voting rule. To include more information to support the final decision, we can use member algorithms providing more candidates which can be ranked based on the confidence ordered by the algorithms. In this case, a spatial weighted graph is defined where the candidates are considered as its nodes, and the final OD position is determined in terms of finding a maximum-weighted clique. Now, we examine how to apply in our ensemble-based framework all the accessible information supplied by the member algorithms by making them return confidence values for each image pixel. These confidence values inform us about the probability that a given pixel is the center point of the object. We apply axiomatic and Bayesian approaches, as in the case of aggregation of judgments of experts in decision and risk analysis, to combine these confidence values. According to our experimental study, the accuracy of the localization of OD increases further. Besides single localization, this approach can be adapted for the precise detection of the boundary of the OD. Comparative experimental results are also given for several publicly available datasets.

@&#INTRODUCTION@&#
More than 360 million people were suffering from diabetes in 2012 worldwide. The number of the diagnosed cases has been growing rapidly in the last few years and this tendency is estimated to continue [1]. Long-term diabetes also affects the eye, resulting in a disease called diabetic retinopathy (DR). If DR remains undiagnosed or is treated inappropriately, it can lead to the loss of vision. In addition, DR is the most common cause of blindness in the world. However, there are suitable ways of treatment to slow down the deterioration of the eye-sight. An automatic screening system for DR would be of great importance mainly in the developing countries, where nearly 40% of the cases remain undiagnosed. Such a system is useful if it is capable of detecting the first signs of the disease. The blood vessels that provide nourishment to the retina, in case of a person with diabetes, may weaken and leak, forming small, dot-like hemorrhages known as microaneurysms and hemorrhages. Exudates come into when fluid exudes from tissue because of its injured capillaries. The masking out the OD region in the image is highly recommended by [2–4] before the detection of exudates and cotton-wool spots, as these lesions appear in the retinal images as bright patches which are similar to the OD concerning their color and shape characteristics. Moreover, if the position and the radius of the OD are detected correctly, they can be used as references for approximating other anatomical parts e.g. the macula and the fovea, as it is proposed in [5] or to analyze pathologies e.g. glaucoma or neovascularization on the disc.In the corresponding literature, several OD detection algorithms are published [6–15]. Most of these try to perform the extraction of the OD based on color, size, shape, direction of vessels, etc. For example, Mendels et al. [10] used morphological filtering and active contours to find the boundary of the OD, while Sekhar et al. [7] applied morphological operations and Hough-transformation to localize it. Here, the proposed method consists of two steps: in the first step, a circular region of interest is found by isolating the brightest area in the image by means of morphological processing, and in the second step, the Hough-transformation is used to detect the main circular feature (corresponding to the OD) in the positive horizontal gradient image within this region of interest. Abramoff et al. [8] proposed a kNN regression approach to find relationship between the dependent variable d which represents the distance from the OD center, and a feature vector extracted around a circular template. Shijian [9] used circular transformation which is capable of detecting both the OD center and its boundary from images of pathological retinas, as well. Lalonde et al. [10] proposed an algorithm (ODdecomp) which generates a pyramid with a simple Haar-based discrete wavelet transformation. The input image has low resolution after its decomposition is repeated four or five times and the pixel of this low-resolution image with highest intensity value is considered as the center of the OD. Another approach (ODedge) in [10] uses edge detection applying the Rayleigh-based CFAR threshold. This solution guarantees the strong edges which are associated with the border of anatomical structures. In the next step, the Hausdorff distance is calculated between the set of edge points and a circular template like the average OD. The lowest distance value corresponds to the center of the OD. Sopharak et al. [11] proposed a method (ODentropy) which applies a median and a CLAHE filter on the green intensity channel. The entropy of the intensity values in the local region around each pixel is calculated and the location of the highest entropy values is considered to belong to the OD. Niemeijer et al. [12] proposed feature extraction and classification steps (ODclassify) to determine the area of the OD. They suggest the following features: number, width, orientation and density of vessel segments. In the next step, a kNN classifier made a decision about each pixel whether they belong to the OD, or not. Hoover et al. [13] thinned the vessel system and each line-shape segment is modeled by a fuzzy segment. This model (ODfuzzy) creates a voting map and the pixel obtaining the most votes is considered to be the center of the OD. Ravishankar et al. [14] proposed an algorithm (ODhough) which uses Hough-transformation on the thinned vessel system. Lines which have slope less than 45° are eliminated. The intersection points of the rest of the lines give a voting map. Number of votes is weighted with the original intensity values of the intersection points in the image, and the highest corresponding value indicates the center of the OD. Finally, Zhu et al. [15] locate the border of the OD in terms of a circle with a given diameter using the circular Hough-transformation (ODcHough). For this aim, edge detection is applied and the circle containing the most edge points is selected.There is, in fact, no reason to assume that any single algorithm would be optimal for the detection of various anatomical parts of the retina. It is difficult to determine which the best approach is, because good results were reported for healthy retinas but weaker ones for more challenging datasets containing diseased retinas with variable appearance of ODs in term of intensity, color, contour definition and so on. To overcome the imperfectness of the individual algorithms, we study and adapt some of the state-of-the-art OD detectors and finally organize them into an ensemble framework in order to combine their strengths and maximize the accuracy of the localization of the OD. First in [16], we suggested an ensemble of them and tested a majority voting scheme with a circular template to detect the correct position of the OD center, where the individual algorithms had just a single candidate. As a further improvement of this model, in [17], we extracted more than one candidate for each algorithm to increase the chance of getting the OD location among them. We assigned weight to each candidate to replace simple majority voting by a weighted one and treated them as weighted nodes of a complete graph. For the location of the OD center, we selected that subgraph of the candidates which met the OD geometry constraint and had a maximal total weight. For this selection, we borrowed a graph theoretical approach supplying the optimal solution in terms of a maximal weighted clique.Besides increasing the accuracy of the detection of the OD center, our aim is also the segmentation of the OD region so that it can be entirely eliminated before the detection of bright lesions. In this paper, we propose a method to maximize the accuracy of the localization of the OD and to determine its region. As we have mentioned earlier, in our former ensemble-based approaches we considered only one, then up to five possible OD center points as the output of each individual algorithm. Now, to utilize all available information corresponding to the possible location of the OD provided by the algorithms, we let them assign probability (confidence) values to each pixel of the input image. In this way, probability maps are composed of the member algorithms and a suitable combination of these maps can be considered to locate the correct OD region. Taking advantage of more information is supposed to lead to improvement, which is a natural expectation validated by our experiment studies. Namely, in our tests, the proposed method outperformed both the simpler ensemble-based systems and the state-of-the-art individual member algorithms on publicly available datasets.The rest of the paper is organized as follows. In Section 2, we give a brief overview about our former ensemble-based systems used for OD detection. In Section 3, we introduce our methodology for the detection of the center and region of the OD based on the combination of probability maps provided by the individual algorithms. In Section 4, we describe the considered datasets for experimental evaluation. Section 5 is dedicated to our experimental results also in comparison with some other state-of-the-art OD detection methods. Finally, further technical details are discussed in Section 6, and some conclusions are drawn in Section 7.In this section, we introduce our fusion strategies which are based on the majority voting scheme, finding maximal-weighted clique and combining probability maps, respectively. Besides giving detailed description of these frameworks, we show the positive effect of exploiting more and more information for the localization of a single object.In [16], we have proposed an ensemble-based single object detection system based on simple majority voting which outperforms the member detectors [10–15]. Here, the single outputs for the object center of the member algorithms are merged and the majority voting scheme is applied using a template of the shape of the object to detect its correct position. More precisely, to overcome the imperfectness of the member algorithms, a templateDis fit on each pixelpx,yof the input imageIand the outputs of the algorithms that fall withinDare summed. The center of theDcovering the maximum number of detector outputs is considered to be a hot spot for the object. There can be more hot spots, hence they together define a hot spot region. To find the final center of the single object(xres,yres), the centroids of the outputs within the hot spot region are computed.For an impression, seeFig. 1 for the output of the OD detectors ODdecomp, ODedge, ODentropy, ODclassify, ODfuzzy, ODhough, ODcHoughtogether with the manually selected center (ground-truth) ODmanualof the OD. As for the specific example in Fig. 1, with ignoring the candidates of ODedgeand ODfuzzy, the true OD location has been found based on the ensemble of the result of ODdecomp, ODentropy, ODclassify, ODhoughand ODcHough.To use the simple majority voting scheme for OD detection, a circular templateDRof radiusR>0is fit on each pixel and the outputs of the detectors withinDRare counted. Based on some preliminary experiments on the manually segmented OD regions (ODR), the value of R is set to 6.5% of the width of the region of interest (ROI) of the fundus image. InFig. 2(a) and (b), we can observe the hot spot region composed of the hot spots containing the maximum number of outputs. If there are more hot spot regions, we apply a complementary post processing step. Namely, a Gaussian filter is applied on the green channel of the image with a large variance parameter (σ=300). The smoothed image is subtracted from the original one to make the OD appear as a brighter patch compared with the background. The average intensities around the output of the detectors are computed in the hot spot regions and the region with the highest average intensity is selected as the final OD hot spot region. However, as it can be seen in Fig. 2(b), majority voting may fail to detect the correct OD center, especially, in case of a diseased retina. Therefore, we proposed a more sophisticated method to avoid these shortcomings, explained in the following section.In [17], we examined how to improve the performance of the ensemble-based system, when the candidates of the member algorithms do not fall within the true single object region. We found that if we let the members suggest more candidates, one of them falls inside the true region of the object with higher probability. However, if we consider the outputs of only a single algorithm as candidates we should select one of them as a final output. For this selection, we have to choose an appropriate post processing step which means something like new algorithms. In this case, the single object detection is performed by only one algorithm which may have any imperfectness. Instead of considering the candidates of one member, we took all candidates of each involved member algorithm into account and we assigned weights to each candidate based on their priority suggested by the members. Then, these weighted candidates were considered as vertices of a graph, where we were looking for a subgraph with a maximal sum of weights constrained also by the geometry of the single object.In this ensemble-based approach it is a key issue to determine, how many candidates for a member we should consider. Letci,j∈Cidenote the jth candidate of the ith member algorithmAi(i=1,2,…,N), (j=1,2,…,|Ci|), whereNdenotes the number of member algorithms,Cithe set of candidates ofAiand|.|the cardinality of a set. Letci⁎mean that the candidate ofAiwhich falls inside the true object region. Then, on the one hand we have to increase|Ci|tillci⁎∈Ci. On the other hand we have to keep|Ci|relatively small to avoid too many false positive which would confuse the final combination. To solve this problem, for each algorithm, we used a training dataset and checked the ratio of the images withci⁎∈Ciand selected the smallest|Ci|as the number of candidates above which the increase ofP(ci⁎∈Ci)slows down. Namely, we try to determine the maximum curvature of the line which connects the accuracies ofAiconsidering its jth candidate (j=1,2,…,|Ci|). A similar approach for selecting the number of classes is known as the elbow-criterion in statistics.After determining|Ci|forAi(i=1,2,…,N), we compose a weighted graph from the candidates with lettingAi(i=1,2,…,N) assign a confidence levelConf(ci,j)ϵℛ+(j=1,2,…,|Ci|) to each of its candidates. Using these confidence levels, we can sort the candidates ofAiin a priority order so thatConf(ci,k)≥Conf(ci,l)for any 1≤k<l≤|Ci|. Then, we assign weights to the candidates, as:(1)ωi,j=Conf(ci,j)Conf(ci,1)for i=1,2,…,N, j=1,2,…,|Ci|. Note that, this normalization will giveωi,1=1(weight 1 for every first candidate) for i=1,2,…,N.Finally, we connect those vertices of the graph with edges which fall inside a possible region of the object, that is, their distance is smaller than the average diameter of the region of the single object. In this graph, we look for the clique with maximal sum of weights of nodes. We note that, the number of candidates of the member algorithms should be kept relatively low to avoid very large graphs, where the weighted clique search algorithm would become inefficient. Moreover, if we let the|Ci|(i=1,2,…,N) increase beyond a meaningful limit, too many false positive vertices can meet within a false region even accidently which has a negative effect for the detection of the final location of the OD. Furthermore, the moderate slopes of the lines after the maximal curvature in Fig. 4 means that the jth candidate(j>|Ci|)ofAifalls inside the true region of the object only in few times. To validate our selection approach also in an objective way, we have tested the performance of the maximal weighted clique-based ensemble when each member algorithm provides one more and one less candidate than the values corresponding to the elbow. Since the description of the test databases are given in the forthcoming sections, the corresponding quantitative results will be enclosed in Section 6.The corresponding (NP-hard) graph theoretical problem in this representation is known as the maximum-weighted clique finding problem. For the solution of this task, we borrow an algorithm from [18] which is based on heuristic vertex-coloring and backtrack search. This algorithm provides the maximum-weighted cliques and works quickly also on dense graphs. The final object center(xres,yres)is determined as the centroid of the maximum-weighted clique.To see the performance of the framework considering more candidates of the members regarding the problem of OD detection, we have included the same member algorithmsA1=ODdecomp,A2=ODedge,A3=ODentropy,A4=ODclassify,A5=ODfuzzy,A6=ODhough,A7=ODcHoughto make the results comparable with the simple majority voting scheme. Though we should preserve the basic principles of the member algorithms, in this case we have to extract more than one candidate for each of them. For this purpose, for eachAi(i=1,2,…,7) we mask out its first candidate by the disc templateD2R, after which the algorithm should locate the next candidate within the remaining image region and so an (seeFig. 3). In this way, we can assure that a possible OD region is suggested by at most one candidate of each member.The number of candidates|Ci|forAi(i=1,2,…,7) were selected as the values after whichP(ci⁎∈Ci)slows down and where the curvature of these lines is the maximum as shown also inFig. 4.Conf(ci,j)are calculated using the original principles ofAifor all of its candidates. The weights for each candidate were defined using (1), and the nodes falling inside a sameDRare connected by edges. For such a graph and the final results of the maximal weighted clique-based combination of the members seeFig. 5(a) and (b). Note that, the input fundus images are the same in Figs. 2(b) and 5(a) for the better comparability of the ensemble-based systems.As it can be seen in Fig. 5(b), in some cases the maximum-weighted clique-based ensemble of the member algorithms still could not find the correct location. Moreover, these extracted candidates cannot be used for the detection of the precise region of the object. These are the reasons for which we examine further possibilities to take advantage of all the information provided by the member algorithms about the location of the single object. Namely, we let them assign confidence values to each pixel of the input image. In this way, probability maps are composed by the member algorithms and a suitable combination of these maps can be considered to locate the correct OD region.The basic idea of the proposed method is to utilize as much information as possible about the location of a single object. Namely, we expect the member algorithms to assign a valueConf(px,y)to eachpx,y∈Iindicating their confidence thatpx,yis the center of the object. The most of the algorithms basically assign such a value to each pixel but they apply a threshold to select only one location corresponding to the highest value. Thus, we can easily modify them with omitting their final thresholding step and can consider each pixel as a candidate equipped with confidence values by each member algorithm. These confidence values define probability maps (PM) for the input image. Now, we introduce some possible approaches to fuse these maps in order to increase the accuracy of single object detection.The fields of decision making and risk analysis, where information derived from several experts and aggregated by a decision maker, have a well-established literature [19–21]. In general, the aggregation of information increases the precision of the forecast. In our scenario, we can consider the assigned confidence values to eachpx,y∈Ias the opinion of the member algorithms on how probable the given pixel is the center point of the object. Based on the fact of the positive effect of the ensemble, if we consider the algorithms as experts with voting their confidence value and apply aggregation accordingly, the accuracy of the single object detection should improve.As a short summary concerning the combination of information derived from experts, basically two approaches are known in the corresponding literature. One of them is based on clearly established mathematical rules, whereas the other one is entrusted to the interaction of experts, also known as a behavior-based method. In a behavior-based model, the experts contact the decision maker directly or indirectly to make him/her take their arguments and statements into consideration to reach consensus. In this approach, the quality of the individual experts and the dependencies among them are considered implicitly rather than explicitly. So, we examine only the applicability of strict theoretical approaches which are widely available in the literature from the simple axiomatic methods to the processes requiring different information aggregation models. In the case of single object detection, axiomatic approaches can be applied easily to eachpx,y∈Ito aggregate the probability values assigned byAi(i=1,2,…,N) topx,y. Considering the more complex approaches, we should apply a training set to determine all the necessary parameters to set up the model for the ensemble.To start the proper formalization of the proposed ensemble-based framework, let the true (ground-truth) center of the single object be denoted by(xman,yman). LetL1denote the event whenpx,y=(xman,yman), whileL0the one, whenpx,y≠(xman,yman). Since most of the object detection algorithms use various features ofpx,yand its neighborhood for localization, letHi(x,y)(i=1,2,…,N) be the set of these features based on whichAiassign a probability value topx,y. To show the confidence ofAithatpx,yis the center of the object, a probability mapPMi(i=1,2,…,N) can be defined as:(2)PMi(x,y)=P(L1|Hi(x,y)).Here, we omit any details on the feature setsHi, as they are completely algorithm dependent, and focus on the aggregation of thePMs.The mapsPMi(i=1,2,…,N) can also be considered as probability density function, if the following conditions hold:(3)PMi(x,y)>0,forallpx,y∈I,(4)∑x∑yPMi(x,y)=1.Condition (3) can be fulfilled with assigning a very small probability valueε>0to each position, which originally has zero confidence:(5)PMεi(x,y)=max(PMi(x,y),ε).Finally, to meet condition (4), we perform the following normalization step:(6)PDFi(x,y)=PMεi(x,y)∑x∑yPMεi(x,y).In this way, the probability mapsPMi(i=1,2,…,N) are transformed to the probability density function PDFi. After we have these PDFs, we can fuse them by applying standard axiomatic approaches or more complex aggregation models.The product, sum, minimum, maximum of the probability density functions are the simplest approaches of the aggregation in the corresponding literature [19], [20]. These techniques are realized by simple arithmetic operations performed between two or more PDFs given by the experts. One of the most commonly used axiomatic approaches is the linear opinion pool published by Stone in [22]. This method calculates the weighted sum of the probability density functionsPDFirendered by the experts:(7)PDFLINOP=∑i=1NwiPDFi,wherePDFLINOPrepresents the combined probability density and withe weights assigned to the experts provided that we have information on their reliability. As a natural condition,∑iwi=1must hold. Ifwi=1/N, we have a simple linear combination, otherwise a weighted linear one.Multiplicative averaging (also known as logarithmic opinion pool) is another commonly used fusion approach [19]. In this case, probability density functions are combined as:(8)PDFLOGOP=k∏i=1NPDFiwi,where k is a normalizing constant andwirepresents the same weights as above. Ifwi=1/N, (8) returns the geometric mean of the individual distributions. These axiomatic approaches combine the PDFs in a simple way with ignoring the quality of the members and the dependencies among them. Now, we start discussing the Bayesian models of the information aggregation process, which require input regarding bias and dependencies of the experts.In [23,24], Morris formally laid the foundation of the Bayesian paradigm to aggregate the information collected from different experts. The Bayesian models operate on the individual probability density functions to aggregate them. In the case of single object detection, according to these models the pixels can be considered as the center point(L1)or not(L0). Thus, using the Bayes’ theorem we assign the ensemble-based probability to each pixelpx,y∈Ion whether it is the object center through the following way based on the probability mapsPDFi(i=1,2,…,N):(9)px,y=(xman,yman),ifP(L1|PDF1(x,y),…,PDFN(x,y))>P(L0|PDF1(x,y),…,PDFN(x,y)).As only two cases are possible, we haveP(L0)=1−P(L1)for each pixel. Thus, in our case it is sufficient to determine the probability ofL1for the pixels with the help of the Bayes’ theorem. To eachpx,y∈Iwe calculate the posterior probability in (9) by the help of the Bayes’ rule in the following way:(10)P(ℒ|PDF1,…,PDFN)=P(PDF1,…,PDFN|ℒ)P(ℒ)P(PDF1,…,PDFN),ℒ∈{L0,L1}.Note that,ℒdoes not appear in the denominatorP(PDF1,…,PDFN), so this term is applied only for normalization. Thus, it can be omitted by following the general recommendations [21].The a priori probabilityP(ℒ)in the numerator of (10) can be easily estimated from the training database (see Section 4). The calculation of the joint probability density functionP(PDF1,…,PDFN|ℒ)depends on whether the model takes the dependencies of the member algorithms into account or not. In this respect, there are two basic approaches in the relevant literature as discussed next.In the first Bayesian approach, let us suppose that the experts do not influence each other, there is no connection between them so they give their opinion or forecast completely independently. That is, according to this naive hypothesis, the decision maker manages the information collected from the experts independently. This type of aggregation is known as the Naïve Bayes model and the joint density function in(10)can be separated according to the conditionally independent assumption based on the following formula:(11)P(PDF1,…,PDFN|ℒ)=∏i=1NP(PDFi|ℒ).Consequently, the aggregation of the probability density functionsPDFi(i=1,2,…,N) can be derived based on as:(12)PDFNB(x,y)=P(L1)∏i=1NP(PDFi(x,y)|L1),whereP(PDFi(x,y)|L1)(i=1,2,…,N) are estimated on the basis of the probability values assigned by the algorithms to the pixels within the manually segmented object in the images of the training set. Since all the terms of (12) can be estimated from the training examples, the Naïve Bayes model can be easily constructed and adopted, as well. However, this model ignores the dependencies among the members although, the assumption on the conditional independence of the experts is fulfilled very rarely in practice.To measure up the dependencies of the member algorithmsAiandAj(i, j=1,2,…,N), we can calculate the Pearson’s correlation coefficientρi,j[25].ρi,jis calculated pairwise for the member algorithms through comparing all the pairs(PDFi(x,y),PDFj(x,y)),(i,j=1,2,…,N)as:(13)ρi,j=E[(PDFi−μ(PDFi))(PDFj−μ(PDFj))]σ(PDFi)σ(PDFj),whereμ(PDFi)stands for the mean, whileσ(PDFi)for the standard deviation of the probability mapPDFi, respectively. The coefficientsρi,jdescribe the dependencies betweenAiandAj. Non-zero coefficients show dependencies suggesting that the model can be improved further as presented in the next section.In the corresponding literature [26] the problem is well-known that experts do not provide their opinions or forecasts entirely independently from each other. So, combining their input in a way that the decision maker considers the experts independent have a negative effect on the result. In this case, a Bayesian model is required, which is able to take all the dependencies between the experts into account. To address this issue, the optimal Augmented Naïve Bayes (ANB) model has been suggested [27], where during the learning phase the dependencies of the members are also incorporated. However, creating such an ANB model is an NP-hard problem [28], so it is recommended to choose an alternative approach which takes the dependencies into consideration, however, does not try to disclose them entirely. One of these models is the Tree Augmented Naïve Bayes (TAN) [27] one, which has the disadvantage that only the most dependent pairs are kept and the effect of the less dependent experts are omitted. As a trade-off, the complexity of the creation of the TAN model is significantly reduced. Contrarily, the Hidden Naïve Bayes (HNB) model developed by Zhang et al. [29] is capable of taking all the dependent experts into account collectively. Thus, the HNB model approximates the precision of the optimal ANB model better, while its time complexity for training is only polynomial.The basic idea of the HNB model is that a hidden expert (HE) is created for each expert which can affect it. Thus, the ith expert depends only on the ith HE (HEi), where HEicontains all the dependency relations between the ith and the other experts. That is, the joint probability in the numerator of(10)can be calculated by the HNB model considering the dependencies among the experts as:(14)P(PDF1,…,PDFN|ℒ)=∏i=1NP(PDFi|HEi,ℒ),where(15)P(PDFi|HEi,ℒ)=∑j=1,j≠iNWijP(PDFi|PDFj,ℒ)with∑j=1,j≠iNWij=1. As it can be seen,HEiis the hidden expert ofPDFi(i=1,2,…,N) and is basically a mixture of the weighted dependencies with other experts. The weightsWij(i, j=1,2,…,N, i≠j) are determined using the training set based on the conditional mutual information (CMI) ofPDFiandPDFj:(16)Wij=CMI(PDFi;PDFj|ℒ)∑j=1,j≠iNCMI(PDFi;PDFj|ℒ),where CMI is generally calculated as:(17)CMI(Α;Β|Γ)=∑α,β,γP(α,β,γ)logP(α,β|γ)P(α|γ)(β|γ).Using the weightsWij(i, j=1,2,…,N, i≠j), the hidden expertsHEi(i=1,2,…,N) can be determined. Thus, the HNB model incorporates all the dependencies among experts similarly to the optimal ANB one. However, the time complexity of the training phase of HNB isO(tN2+kN2v2), where t is the number of training pixels of the training images, N is the number of algorithms, k is the number of classes and v is the average number of values for an attribute.After defining the weightsWij(i, j=1,2,…,N, i≠j), the aggregation of the probability mapsPDFi(i=1,2,…,N) can be executed via the HNB model on the basis of the following formula:(18)PDFHNB(x,y)=P(L1)∏i=1NP(PDFi(x,y)|HEi(x,y),L1).Till this point of this section, we have proposed a general ensemble-based framework for single object detection, when we have more than one member algorithms which can generate probability maps to locate the object. Now we show how to apply these approaches for OD detection and observe their performance considering the accuracy of detection. For visual and precise comparison of the proposed ensemble-based approaches, we use the same input image as in Fig. 5(b) with considering the same detectors (ODdecomp, ODedge, ODentropy, ODclassify, ODfuzzy, ODhough, ODcHough), as well.The OD detector algorithms are slightly modified since they are not allowed to threshold the confidence valuesConf(px,y)to extract a single pixel having the highest value as the final center candidate. Instead, all the image pixelspx,y∈Iare equipped by a confidence value for each member. These confidence values together compose probability maps for I corresponding to each OD detector (seeFig. 6 for these PMs).As we have discussed in Section 3, the proposed ensemble approaches can be applied if the PMs fulfill conditions . For this aim, the PMs are transformed to probability density functions (PDFs) by formulas . InFig. 7, we can see a visual representation of the PDFs derived from the PMs of Fig. 6.After constructing the PDFs, they can be fused by applying the standard axiomatic or Bayesian model-based approaches. For axiomatic ensemble of PDFs the weightswi(see (7) and (8)) are calculated from the individual accuracies as follows:(19)wi=Acci∑i=1NAcci,whereAccidenotes the accuracy ofAion the training set. The proper details of the databases used for training and testing is given in Section 4. After making tests on a training set, we adjust the following weights: wdecomp=0.16, wedge=0.18, wentropy=0.17, wclassify=0.16, wfuzzy=0.04, whough=0.16, wcHough=0.13. The result of the combination ofPDFi(i=1,2,…,N) by weighted linear opinion pool and weighted logarithmic opinion pool can be seen inFig. 8(a) and (b), respectively.Now we turn to the Naïve Bayes model for OD detection. During the training stage, we determine the probability of OD center pixels among all the pixels of the training images. However, there is only one OD center point in the image, and considering the number of all the image pixels,P(L1)is a very small value. SinceL1would be very under-represented in this way in a training dataset, we interpretL1in a wider sense. Namely, we letL1represent not only the case whenpx,y=(xman,yman), but also whenpx,yfalls inside the OD region(px,y∈ODR). In other words, we do not restrict our attention to the center, but we accept any OD pixels. Note that, in this wayP(L1)becomes sufficiently large, and from now we work in this extended context. Besides the a priori probabilityP(L1), the conditional probabilitiesP(PDFi(x,y)|L1)(i=1,2,…,N) are also calculated inside and outside the region of the OD. A sample result for the combination based on the Naïve Bayes model can be seen in Fig. 8(c).As we have mentioned in Section 3.2.1, the assumption on the conditional independence of the experts is fulfilled very rarely in practice. This assumption does not keep for the involved OD detectors either. To confirm this hypothesis, we calculate the Pearson’s correlation coefficientsρi,jfor all the possible pairs of member algorithms with enclosing them inTable 1.A smaller (close to 0) correlation value corresponds to smaller dependency of the given algorithms. For instance, ODdecompand the ODclassifyseem to be the most diverse algorithms compared to each other regarding this measure. There are no zeros in Table 1 showing the trivial fact that the members cannot be completely independent. Thus, we can apply the HNB model which takes the dependencies among the detectors also into consideration. The sample result of the HNB combination can be seen in Fig. 8(d).In all the images of Fig. 8, very high probability values can be observed for the region of the OD, so its location can be found with a simple extra step. Namely, the center of the average OD size disc templateDRis matched on each pixel of the resulted ensemble PDF image and that pixel is selected as the final OD center(xres,yres), where we find the maximum sum of PDF values for the pixels within the matchedDR.If we compare the results of the axiomatic models (Fig. 8(a) and (b)) with the Bayesian ones (Fig. 8(c) and (d)), we can see significant difference between the areas, where the OD is detected with lower probability. There are high peaks at the possible OD locations, but the rest of Fig. 8(c) and (d) are flat because of the more complex aggregation methods which take the dependencies among the members also into account. Furthermore, as we considerL1in a wider sense with letting it represent the eventpx,y∈ODR, the resulted PDFs of the Bayesian models show high probability also at the pixels falling inside the OD region not just at the center of it. Thus, we can determine the final OD region if we consider the area corresponding to the peak found by the templateDRmatching process. IfDRexpands this region, their union is considered as the segmentation of the OD region, as it can be seen also inFig. 9.We have evaluated our proposed combination approaches to localize the OD on publically available image sets. Namely, the sets DIARETDB0 [30], DIARETDB1 [31], DRIVE [32] and MESSIDOR [33] have been considered for performance analysis. DIARETDB0 includes 130 color fundus images. 20 of these are healthy and 110 of these contain signs of DR (exudates, microaneurysms, hemorrhages and neovascularization). The dataset DIARETDB1 includes 89 fundus images. 84 of these contain microaneurysms or more serious signs of DR, while 5 are considered as healthy with containing no signs of DR according to clinical experts. In both sets, the images were taken with a 50° field-of-view, at a resolution of 1500×1152pixel and the average diameter of the regions-of-interest (ROI) is 1410pixel. DRIVE images were acquired using a Canon CR5 non-mydriatic 3CCD camera with a 45° field-of-view. Each image is 24-bit RGB of resolution 768×584pixel. The ROI of the images is circular with an average diameter 540pixel. The image set MESSIDOR includes 1200 fundus images which were acquired by 3 ophthalmologic departments using a color video 3CCD camera on a Topcon TRC NW6 non-mydriatic retinograph with a 45° field-of-view. The images were captured using 24-bit RGB at the resolution of 1440×960, 2240×1488 or 2304×1536pixel.The proposed Bayesian approaches for combining the member algorithms require training images to construct the Bayesian models. So the NB and HNB models should be trained on the training set without the influence of the test set. Therefore, a set of images from our private dataset is used during the training phase. The images from our dataset were captured with a 50° field-of-view at a resolution of 3072×2048 and 1360×1024pixel with the average diameter of the ROI is 2287 and 1340pixel, respectively. This set includes 327 images, for which manually drawn regions of the OD are also available.Table 2 contains the summary of datasets used for training and the evaluation of the proposed combinations of individual algorithms for OD localization.To collect the training dataset for Bayesian models, we have calculatedPDFi(i=1,2,…,7) for all the 327 images. Then, we have 400,000pixel randomly selected from these images together with their correspondingPDFi(i=1,2,…,7) values. In this way, 4% of the pixels belonged to OD regions in the training set.Fig. 10 shows the distribution of the probability values outside and inside the region of the OD for these selected pixels.

@&#CONCLUSIONS@&#
