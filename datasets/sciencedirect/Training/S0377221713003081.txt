@&#MAIN-TITLE@&#
Advanced greedy algorithms and surrogate constraint methods for linear and quadratic knapsack and covering problems

@&#HIGHLIGHTS@&#
New refined greedy algorithms for linear and quadratic knapsack/covering problems.Extensions for multiple multi-constraint knapsack and covering problems.Advance-look combination strategies that provide enhanced solution capabilities.Effective multi-start and strategic oscillation approaches exploiting these methods.New surrogate constraints dominating the constraints guiding current best methods.

@&#KEYPHRASES@&#
Metaheuristics,Greedy algorithms,Knapsack/covering problems,Surrogate constraints,Multi-start/strategic oscillation,Tabu search,

@&#ABSTRACT@&#
New variants of greedy algorithms, called advanced greedy algorithms, are identified for knapsack and covering problems with linear and quadratic objective functions. Beginning with single-constraint problems, we provide extensions for multiple knapsack and covering problems, in which objects must be allocated to different knapsacks and covers, and also for multi-constraint (multi-dimensional) knapsack and covering problems, in which the constraints are exploited by means of surrogate constraint strategies. In addition, we provide a new graduated-probe strategy for improving the selection of variables to be assigned values. Going beyond the greedy and advanced greedy frameworks, we describe ways to utilize these algorithms with multi-start and strategic oscillation metaheuristics. Finally, we identify how surrogate constraints can be utilized to produce inequalities that dominate those previously proposed and tested utilizing linear programming methods for solving multi-constraint knapsack problems, which are responsible for the current best methods for these problems. While we focus on 0–1 problems, our approaches can readily be adapted to handle variables with general upper bounds.

@&#INTRODUCTION@&#
Greedy algorithms have long been a mainstay of methods for single-constraint and multi-constraint knapsack and covering problems. These algorithms are often embedded within constructive processes used in multi-start metaheuristics and also within linked constructive and destructive processes in strategic oscillation metaheuristics. We introduce new variants of these algorithms, called advanced greedy algorithms, which can be implemented for problems with linear and quadratic objective functions.In the quadratic case, we observe that previous formulations of greedy algorithms have conspicuous deficiencies and show how a new graduated-probe strategy can be used to overcome them both for greedy and advanced greedy methods. Though most strongly motivated in the quadratic setting, this new strategy can also be used to enhance variable-selection for problems with linear objectives. Starting with single-constraint problems, we then introduce extensions for more general multiple knapsack and multi-constraint (multi-dimensional) problems. Processes for employing these methods in strategic oscillation and multi-start approaches are also described.In the domain of multi-constraint knapsack problems, we show how surrogate constraints can be used to provide inequalities that dominate inequalities used by previous methods incorporating linear programming strategies, which have produced the best existing methods for these problems. Our primary focus deals with 0–1 problems, though our methods can also be adapted for problems with more general integer variables.Our paper is organized as follows. Section 2 begins by examining the simple case of single-constraint 0–1 knapsack and covering problems, including consideration of both linear and quadratic objectives. Section 3 describes classical greedy methods for these problems utilizing a framework that provides a foundation for later extensions. The new advanced greedy algorithms are introduced in Section 4, disclosing how these methods have the ability to eliminate certain deficiencies of the classical methods (and other previous methods). This section also identifies a way to produce fast updates for one of the main components of these methods.Section 5 introduces the graduated-probe strategy and discloses the manner in which it overcomes limitations of methods proposed for quadratic problems. More general multiple knapsack problems, which have recently become the focus of a number of investigations, are addressed in Section 6. This section also describes how to reinforce such strategies in multi-start and strategic oscillation approaches. Finally, Section 7 discusses multi-constraint knapsack problems, together with the surrogate constraint strategies that generate inequalities to guide the solution process.Single-constraint 0–1 knapsack and covering problems with linear and quadratic objectives may be formulated as follows.Linear single-constraint knapsack (LK)(LK0)Maximizexo=∑(pjxj;j∈N)(K1)subjectto∑(ajxj;j∈N)⩽ao(K2)xj∈{0,1},j∈Nwhere ao>0, and the profit coefficients pjand the constraint coefficients ajare likewise positive constants for all j∈N={1,…,n}. (Cases where some pjor ajcoefficients are non-positive can easily be converted to the positive coefficient form by complementing variables or by observing that particular variables can be automatically assigned 0 or 1 values in an optimal solution.) We assume∑(aj:j∈N)>ao, since∑(aj:j∈N)⩽aoimplies (LK) has the trivial solution xj=1, all j∈N.Linear single-constraint cover (LC)(LC0)Minimizeyo=∑(cjyj;j∈N)(C1)subjectto∑(djyj;j∈N)⩾do(C2)yj∈{0,1},j∈N(LK) and (LC) are equivalent problems, as can be seen by replacing xjby 1−yjin the former or replacing yjby 1−xjin the latter and simplifying the resulting representation. (This produces constant terms in the objective functions for the two problems, but these do not affect the optimal solutions. The assumption ao>0 in (LK) corresponds to stipulating∑(dj;j∈N)>doin (LC), and the assumption do>0 in (LC) corresponds to stipulating∑(aj;j∈N)>aoin (LK).) In spite of this equivalence, however, the classical greedy algorithms for these problems do not yield equivalent solutions, and we treat them separately by indicating specific rules for each.The quadratic versions of these problems arise by replacing the objective functions of the linear versions as follows:Quadratic single-constraint knapsack (QK)(QK0)Maximizexo=∑(pjxj;j∈N)+∑(pjhxjxh:j,h∈N)subjectto(K1)and(K2)Quadratic single-constraint cover (QC)(QC0)Minimizeyo=∑(cjyj;j∈N)+∑(cjhyjyh:j,h∈N)subjectto(C1)and(C2)In these formulations we assume for convenience that pjjand cjjare 0. This can be accomplished by setting pj≔pj+pjjand cj≔cj+cjj, which is justified by the observation that a 0–1 variable z satisfies z2=z. We also assume pjhand cjhare 0 for j>h, in this case accomplished by setting pjh≔pjh+phjand cjh≔cjh+chjfor j<h (justified by the fact that xjxh=xhxjand yjyh=yhyj). This latter assumption gives a means to save memory in storing data for the quadratic problems.It is also customary to assume the profit coefficients pjand pjhand the cost coefficients cjand cjhare non-negative. However, this is not necessary for our development, though we retain the assumption that the ajand djcoefficients of (K1) and (K2) are positive. (The quadratic problems (QK) and (QC) are not equivalent under the assumption of non-negative pjhand cjhcoefficients. In fact, equivalence between the two formulations requires cjh=−pjh.)We begin by discussing the classical greedy algorithms as a prelude to introducing the advanced greedy algorithms.The classical greedy algorithms for (LK) and (LC) use the so-called bang-for-buck ratios RKj=pj/ajand RCj=cj/djwhose relevance for one-pass constructive methods was first noted in Dantzig (1957). Effectively, the algorithms go through the RKjratios in descending order and the RCjratios in ascending order, respectively, to assign xj=1 and yj=1 until no more assignments are possible that preserve feasibility for (LK) and until feasibility is achieved for (LC). We describe these algorithms in a form that is convenient for introducing later extensions, without consideration of details relating to efficient implementation (although we later describe fast updating methods for elements that change).Greedy (LK)Initialize:xj=0 for all j∈NN1=∅ (N1 is the index set for variables xjcurrently set to 1)RHS=ao(RHS is the current “right hand side”)No={j∈N: aj⩽RHS} (Nois the index set for variables xjthat can feasiblybe set to 1 at a given iteration of the following loop)While RHS>0 and No≠∅j∗=argmax(RKj: j∈No)xj∗=1N1=N1∪{j∗}RHS=RHS-aj∗No=No−{j∗}No={j∈No: aj⩽RHS}Endwhile(Upon concluding, xj=1 for j∈N1 and xj=0 otherwise.)We remark that the set Nodoes not have to be explicitly identified and updated in the context of the simple (LK) problem, since it suffices to identify j∗ by writingj∗=argmax(RKj:j∈N-N1:aj⩽RHS)However, explicit reference to Nois useful for the context where knapsacks are generated by surrogate constraints in solving multidimensional knapsack problems, as discussed in Section 7.Greedy (LC)Initialize:yj=0 for all j∈NN1=∅ (N1 is the index set for variables yjcurrently set to 1)RHS=do(RHS is the current “right hand side”)While RHS>0 and N1≠Nj∗=argmin(RCj: j∈N−N1)yj∗=1N1=N1∪{j∗}RHS=RHS-dj∗EndwhileIf N1=N and RHS>0, problem (LC) has no feasible solution.(Otherwise, the algorithm yields yj=1 for j∈N1 and yj=0 for j∈N−N1.)As previously indicated, Greedy (LK) and Greedy (LC) do not necessarily yield equivalent solutions. To make the methods more nearly comparable, a post-greedy process can be applied in conjunction with Greedy (LC) as follows.Post-Greedy (LC)For j∈N1Examine indexes j in the reverse order in which they were added toN1 (or alternatively in descending order of the djor cjcoefficients)If RHS+dj⩽0yj=0RHS=RHS+djN1=N1−{j}EndifEndforComment. A different type of greedy algorithm can be specified for (LC) that is in fact equivalent to Greedy (LK). This algorithm modifies Greedy (LK) to start by setting yj=1 for all j∈N andRHS=∑(dj:j∈N)-do, and then replacing “aj” by “dj”, “RKj” by “RCj” and “xj=1” by “yj=0” (including in the case where j=j∗). Traditionally, however, greedy algorithms for the covering problem are formulated by reference to starting with all variables equal to 0.It is also possible to improve the greedy solution of (LK) by post-processing. We do not bother to state such a post-processing approach in this case, because the advanced greedy methods together with the associated strategies described in the knapsack context in succeeding sections render such an approach significantly less relevant.We now observe that these methods can be extended in a straightforward way to handle quadratic problems. However, for reasons to be elaborated later, we call these naïve greedy methods.Relative to the set N1={j∈N: xj=1} for the knapsack problem, and the set N1={j∈N: yj=1} for the covering problem, define the quadratic profit QPj for j∈N−N1 in the knapsack case, and the quadratic cost QCj for j∈N−N1 in the covering case, as follows:QPj=pj+∑(phj:h∈N1)QCj=cj+∑(chj:h∈N1)We employ the convention that a summation over the empty set is 0, hence QPj=pjand QCj=cjif N1=∅.The greedy single constraint quadratic objective algorithms that directly correspond to the algorithms for linear objective problems can then be expressed as:Naïve Greedy (QK)Replace the ratio RKj=pj/ajin Greedy (LK) by the ratio RQKj=QPj/ajforj∈NoThen Naïve Greedy (QK) has the same statement as Greedy (LK)Naïve Greedy (QC)Replace the ratio RCj=cj/djin Greedy (CK) by the ratio RQCj=QCj/djforj∈N-N1Then Naïve Greedy (QC) has the same statement as Greedy (LC).The use of the ratio RQKjwas proposed by Hiley and Julstrom (2006). In the following sections, we first introduce the advanced greedy algorithms for the linear and quadratic problems. Then we consider how the naïve greedy approaches can be improved by means of a graduated-probe strategy, which also can be used to enhance the solution process for linear objectives.The advanced greedy algorithms can be stated in a direct manner by reference to the format used to state the preceding methods.The advanced greedy algorithms replace the bang-for-buck ratios RKj=pj/ajand RCj=cj/djof the Greedy (LK) and Greedy (LC) algorithms with quantities (products) PKjand PCjdefined as follows. To identify these products we take advantage of quantities njand n0, and mjand m0, exploited in connection with surrogate constraint knapsack and covering problems in Glover (1965). The njquantities were also employed in Akcay et al. (2007) in the context of multi-constraint knapsack problems.Determination of PKj:Relative to the valueRHS=ao-∑(aj:j∈N1)computed and updated as in the Greedy (LK) algorithm letnj=⌊RHS/aj⌋where⌊⌋istheintegerfloorfunctionAssume N is indexed so that the ajcoefficients appear in ascending order, and moreover, we have extracted the subset of these indexes for the current set No, which we denote by {1,…,q} to give a1⩽⋯⩽aqfor q=∣No∣. (The original indexing and the extraction can easily be handled by a doubly linked list allowing an element j to be removed from the sequence by linking the predecessor of j to its successor.) Let n0 be the largest index ⩽q in Nosuch that a1+⋯+an0⩽RHS. (Thus, n0 maximizes∑(xj;j∈No)subject to the knapsack constraint.)Finally, letnj′=Min(nj,n0). Then we definePKj=pjnj′Then the Advanced Greedy (LK) algorithm can be expressed as follows.Advanced Greedy (LK)Replace the ratio RKj=pj/ajin Greedy(LK) by the productPKj=pjnj′forj∈NoThen the Advanced Greedy (LK) has the same statement as Greedy (LK).The analogous product PCjand the associated advanced greedy algorithm for the covering problem are given as follows.Relative to the valueRHS=do-∑(dj:j∈N1)computed and updated as in the Greedy (LC) algorithm, letmj=⌈RHS/dj⌉where⌈rceilistheintegerceilingfunctionAssume the indexes in N−N1 are ordered so the djcoefficients by this indexing yield d1⩾⋯⩾dp, where p=∣N−N1∣. Let m0 be the smallest index in N−N1 such that d1+⋯+dm0⩾RHS. (Thus, m0 minimizes∑(xj;j∈N-N1).) If m0 is undefined (i.e., d1+⋯+dp<RHS), then (LC) has no feasible solution. Finally, letmj′=Max(mj,m0). Then we definePCj=cjmj′Advanced Greedy (LC)Replace the ratio RCj=cj/djin Greedy(LC) by the productPCj=cjmj′forj∈N-N1Then the Advanced Greedy (LC) has the same statement as Greedy (LC)The linked lists used to identify the ordering of the ajand djcoefficients can be accompanied by a fast update procedure that allows values of n0 and m0 to be identified highly efficiently on each iteration.Initialization.For descriptive purposes, let the auxiliary indexing j(h) identify the orderingaj(1)⩽aj(2)⩽⋯⩽aj(n)We identify this ordering by a linked list where j=FirstIndex identifies j(1), then j=After(j) identifies all remaining j(h). Let Before(j) be the reverse linked list, and set Before(FirstIndex)=n+1 and After(n)=n+2.Using the linked list:Identify n0 so that aj(1)+⋯+aj(no)⩽aoand=aj(1)+⋯+aj(no+1)>aoRecord KeyIndex=j(n0) and KeySum=aj(1)+⋯+aj(no).For j=j(h), let KeySet(j)=true for h⩽n0 and KeySet(j)=false for h>n0Update when j∗is selected andRHS=RHS-aj∗jBefore=Before(j∗) and jAfter=After(j∗)After(jBefore)=jAfter and Before(jAfter)=jBeforeIf KeySet(j∗)=truen0=n0−1KeySum=KeySum-aj∗If j∗=KeyIndex then KeyIndex=jBeforeElsej=KeyIndexWhile KeySum>RHSKeySet(j)=falsen0=n0−1KeySum=KeySum−ajj=Before(j)EndwhileEndifWe observe that when KeySet(j∗)=true, so that j∗=j(h) for h⩽n0, the implication is that droppingaj∗both from RHS and from KeySum means that we continue to satisfy KeySum⩽RHS and KeySum+aj(n0+1)>RHS, where n0 refers to the “old n0” before updating. Thus KeySet(j)=true accurately identifies the indexes that define KeySum, noting that j∗ has been removed (so it is not necessary to set KeySet(j∗)=false) and hence n0 must decrease by 1. On the other hand, when KeySet(j∗)=false,aj∗has not been removed from KeySum, and we iteratively check whether KeySum>RHS to determine if the “last j” in the sequence defining KeySum needs to be dropped.A corresponding fast update identifies the new m0 value for the covering problem, making use of the same doubly linked list but tracing it backward from larger to smaller ajvalues.We give an interpretation of the product term PKjused in Advanced Greedy (LK) to motivate its use. (An analogous interpretation applies to the term PCjused in Advanced Greedy (LC).)First, note that the ratio RKj=pj/ajused in the classical greedy algorithm can be scaled by RHS so that it can be replaced by the product pj(RHS/aj) without changing the choice of j∗. Moreover, RHS/ajcan be interpreted as the value xjwould receive in the relaxation of the current instance of (LK) where the 0–1 restriction is replaced by requiring the variables simply to be non-negative. However, if we add the condition that xjis an integer variable, the value RHS/ajcan be replaced by nj=⌊RHS/aj⌋ as in the bounding process of Glover (1965). Thus njrepresents the “number of times” the 0–1 variable xjcould be used to form an approximate solution to the current instance of (LK) if an ideal number of copies of xjexisted. But an additional implication of the 0–1 condition is that the largest legitimate number of such copies cannot exceed n0. In short, the ideal number of copies of xjequalsnj′=Min(nj,n0). Finally, the ideal contribution of xj(and its potential copies) to the objective function will bepjnj′, which is precisely the product PKj.The use of PKjautomatically overcomes a deficiency of the classical greedy algorithm, which can be illustrated by the simple problemMaximize10x1+1000x25x1+501x2⩽505The classical greedy algorithm gives the solution x1=1 and x2=0, whereas the solution x1=0 and x2=1 is much better. The example can easily be changed to make the difference between the greedy solution and the optimal solution arbitrarily large, and the typical proposed “fix” is to select j∗ by reference to the max pjvalue on the last assignment step of the algorithm, instead of by reference to the max ratio pj/aj. The Advanced Greedy (LK) not only avoids this problem but removes a variety of other potential deficiencies as well. (It should be observed that the use of njby itself does not avoid this difficulty, but that we also require reference to n0 in definingnj′.)The determination of j∗ in the advanced greedy algorithm requires somewhat more work than in the classical greedy algorithm. This is not due to the work of identifying n0 (when the fast update described above is used) but rather due to the fact that the njandnj′values are not constant from iteration to iteration. This means they do not necessarily fall in the same descending sequence order as the ratios RKj(an order which, once determined, does not change).On the other hand, the issue of determining j∗ quickly for the advanced method becomes irrelevant in the context of solving quadratic knapsack problems, since as previously noted the profit pjof the linear problem is replaced by the quantity QPjthat changes from iteration to iteration, and hence there is no fixed descending order sequence for these quantities. The same is true for multi-constraint knapsack problems, where the generation of surrogate constraints causes the ajcoefficients and RHS values defining both the RKj ratios and the PKj products to change for each new surrogate constraint.The Naïve Greedy (QK) and (QC) algorithms for quadratic problems can be advanced in the same manner as the Greedy (LK) and (LC) algorithms, by replacing ratio terms with corresponding product terms employing the valuesnj′andmj′. However, this replacement is not enough to remove the naïve character of the classical methods in the quadratic case, which effectively renders them too myopic to generate solutions of reasonably high quality.To overcome this limitation requires increasing the computational effort to respond to the additional complexity introduced by the quadratic structure, which grows roughly by the square of the number of variables. (The increase in complexity is actually somewhat greater, since this squared growth becomes magnified by the exponential behavior typical of NP hard problems.) We consider a specialized approach that increases the computational effort by a constant factor, which (according to a choice among options) multiplies the work of selecting j∗ in the naïve approach by examining from 5 to 7 additional candidates for j∗ at each iteration, which in turn translates into examining approximately 10–50 related cross product terms xjxh. Again we restrict attention to the knapsack problem, since the corresponding considerations for the covering problem can be established by direct analogy.First we examine the nature of the limitation encountered by the Naïve Greedy (QK) method to motivate our alternative approach. Essentially the profit valueQPj=pj+∑(phj:h∈N1)embodied in the ratio RQKj=QPj/ajcontains insufficient information to make an intelligent choice when the set N1={j∈N: xj=1} is small. Since the composition of N1 depends on past choices of j∗ (added to N1 at each iteration), the value QPj does not reflect the interactions of the current choice ofxj∗=1with potential future choices of other variables to set to 1. Instead QPj only gives “retrospective guidance” relative to interactions between current candidates forxj∗and past choices of other variables that previously have taken the role ofxj∗.This retrospective weakness is especially pronounced in early iterations of the algorithm, where N1 is small and few variables have been set to 1. On the first iteration, when N1 is empty, the choice of j∗ depends solely on the value of pj/aj, so that no potential interactions with other variables are considered at all. In short, the choice of j∗ on this first step is very nearly “blind”, and the choices that immediately follow have scarcely more information to rely on. Moreover, since these early choices strongly influence the choices subsequently made, a process that makes poor initial choices can degrade the entire collection of choices.To make a more informed choice, we modify the Greedy (QK) algorithm to incorporate an evaluation that anticipates the impact of potential future choices. This is accomplished by making use of a simple candidate list idea.We extend the process of identifying a “best” variablexj∗by identifying b best xjcandidate variables to become xjby using either the greedy evaluation or the advanced greedy evaluation, and denote their indexes by j1,j2,…,jb. (Hence j1 corresponds to j∗.) Taking advantage of these candidates, we create a “best anticipated evaluation” for each of these b choices by first evaluating 2-element or 3-element combinations of these choices and then considering the contribution of each candidate to the resulting combinations. (If b=5, for example, then the possible 2-element combinations can be represented by (j(p), j(q)) for p=1–4, and q=p+1–5, and the possible 3-element combinations can be represented by (j(p), j(q), j(r)) for p=1–3, q=p+1–4, and r=q+1–5.)The Graduated-Probe Strategy consists of two parts, a Combination Evaluation Method and a Choice Rule for Selecting j∗ that makes use of the combination evaluations.We first describe the method for evaluating combinations by reference to bang-for-buck ratios of the type used in the classical methods, and then by reference to product terms of the type used in the advanced greedy methods.For simplicity, first consider the evaluation of 2-element combinations, where we represent the indexes for the combination currently examined by j=1 and j=2 for j∈N−N1 (i.e., xjis among the “unassigned” variables currently set=0). Denote the profit of this 2-element combination by QProfit(1,2), which is analogous to the profit contribution of a single variable xjwhich we have represented byQPj(=pj+∑(phj:h∈N1). In view of the meaning of QPjwe infer that setting x1=x2=1 will yield a profit ofQProfit(1,2)=QP1+QP2+p12The act of setting x1=x2=1 also results in consuming resources from the knapsack equal to a1+a2, and hence the appropriate bang-for-buck ratio QRatio(1,2) is given byQRatio(1,2)=QProfit(1,2)/(a1+a2)Similarly, to evaluate a 3-element combination, whose indexes j∈N−N1 are denoted by 1, 2 and 3, we obtain a profit contribution ofQProfit(1,2,3)=QP1+QP2+QP3+p12+p13+p23and a bang-for-buck ratio ofQRatio(1,2,3)=QProfit(1,2,3)/(a1+a2+a3)It may be noted that the QProfit contribution in the numerator of QRatio grows more rapidly than the knapsack resource utilization in the denominator. This growth difference is still more pronounced for 4-element combinations, where the profit contribution becomesQProfit(1,2,3,4)=QP1+QP2+QP3+QP4+p12+p13+p14+p23+p24+p34while the resource utilization is just a1+a2+a3+a4.Letting QProfit(1)=QP1, and letting [a, b] denote the closed interval of integers from a to b, then for any r⩾2 we haveQProfit(1,…,r)=∑(QPj:j∈[1,r])+DeltarwhereDeltar=∑(phj:h∈[1,r-1],j∈[h+1,r])(Deltar=0if r=1). Here we assume the indexes j∈[1, r] belong to N−N1 (={j∈N: xj=0}). To compute QProfit with slightly less effort, and using the convention QProfitk(1)=Q1k, the foregoing can also be written for r>1 asQProfit(1,…,r)=QProfit(1,…,r-1)+QPr+PostDeltarwherePostDeltar=∑(phr:h∈[1,r-1]).As noted in Garcı́a-Martı́nez (submitted for publication-a), the single-element profit terms QPjcan be updated very efficiently, which permits the foregoing evaluations to be made efficiently as well.We observe that the foregoing discussion is general by understanding j=1,…,r to be shorthand for j=j(1),…,j(r).The corresponding evaluation for the Advanced Greedy version of the quadratic problem replaces the values njandnj′of the linear problem with values n(1,2) and n′(1,2) for 2-element combinations and with values n(1,2,3) and n′(1,2,3) for 3-element combinations, which in turn yield product terms QProduct(1,2) and QProduct(1,2,3) to replace the preceding ratio terms QRatio(1,2) and QRatio(1,2,3), as follows.2-element combination evaluations:Define n(1,2)=⌊RHS/(a1+a2)⌋ and n′(1,2)=Min(n(1,2), ⌊n0/2⌋). ThenQProduct(1,2)=QProfit(1,2)n′(1,2)3-element combination evaluations:Define n(1,2,3)=⌊RHS/(a1+a2+a3)⌋ and n′(1,2,3)=Min(n(1,2,3), ⌊n0/3⌋). ThenQProduct(1,2,3)=QProfit(1,2,3)n′(1,2,3)Again, the general form of these expressions is apparent. The same is true of the following remarks.The value of n0 in these instances is unchanged from its earlier definition. If ⌊n0/2⌋=0 (hence n0<2), then clearly no 2-element combinations exist, and if ⌊n0/3⌋=0 (hence n0<3), then similarly no 3-element combinations exist.When considering these evaluations both for the greedy and advanced greedy cases, it is evidently necessary to restrict attention in the 2-element case to pairs such that a1+a2⩽RHS, and in the 3-element case to triples such that a1+a2+a3⩽RHS. As a special instance, when examining r-element combinations we require r⩽n0.Because it is generally more important to use more extensive evaluations in early iterations, it would be reasonable to use 4-element evaluations for some initial number of iterations and then eventually switch to 3-element and ultimately to 2-element evaluations. When n0 reaches 1, the method uses a “1-element” evaluation, which is just the evaluation involving QProfit(1)=QP1 (and a1).The choice of b, the number of best candidates for j∗, can be varied in a similar manner. For example, b can start at 7 in early iterations and then drop eventually to 6 and then ultimately to 5 or even smaller (noting that we require b⩽∣No∣).We exploit the preceding Combination Evaluation Method by using it to select a single element j∗ for settingxj∗=1. For concreteness, consider the 3-element case (The 2-element and 4-element cases follow the same design.) Denote the combination that yields the best (maximum) evaluation by (jp, jq, jr). We propose the following two rules for selecting one of the three indexes jp, jq and jr to be j∗.Rule 1. Assign a weight to each combination, with the largest weight going to the best combination (jp, jq, jr), the next largest weight going to the next best combination, and so forth. Compute the sum of these weighted values for each j index (according to the combinations that contain j) and choose j∗ to be the index that receives the largest tally. Ties in the choice of j∗ can be broken by choosing the one that yields the largest QPj/ajorQPjnj′value.Rule 2. Select one of the j indexes from the winning combination (jp, jq, jr) by selecting the maximum profit coefficient pjh from the paired combinations (j, h)=(jp, jq), (jp, jr) (jq, jr). The selected combination that yields the largest profit pjhreduces the choice of j∗ to be either j∗=j or j∗=h. We make this final choice to be the one that yields the maximum bang-for-buck valuepj∗+pj∗j0/aj∗or the maximum productpj∗+pj∗j0/nj∗′(where j0=h if j∗=j and j0=j if j∗=h).Weights can be selected in Rule 1, for example, by giving a weight to each combination equal to the evaluation of that combination. Alternatively, if there are a total of c combinations generated, the weights could be c, c−1,…,1, or (weighting on the 5 best) 5,4,…,1,0,…,0. One reason for having a tie-breaking rule is that not all combinations may exist, in view of Remark 2. (For instance, selecting 3 out of 5 elements would normally generate 10 combinations, but for some of these the sum a1+a2+a3 may exceed RHS.)Generally speaking, Rule 1 is anticipated to be better than Rule 2, but both are offered as a means to indicate alternative components that may be relevant to a rule for selecting j∗.The quadratic multiple knapsack and multiple covering problems consist of assigning variables to different single-constraint knapsacks or covers. We continue to focus on the knapsack case in recognition that the covering case can be handled analogously. (Moreover, linear multiple knapsack problems can be handled by direct specialization of the quadratic case examined here.) A good deal of attention has recently been given to the quadratic multiple knapsack problem (QMK) in Saraç and Sipahioglu (2007), Singh and Baghel (2007), Sundar and Singh (2010), Garcı́a-Martı́nez (submitted for publication-a, submitted for publication-b), the latter two approaches making significant gains over their predecessors.The (QMK) problem involves a collection of single-constraint knapsacks indexed by k∈K. Zero-one variables xjkare introduced with the interpretation that xjk=1 if and only if object j is assigned to knapsack k. Hence we have∑(xjk:k∈K)⩽1,j∈NThe knapsack constraints associated with these inequalities are given by∑(ajxjk:j∈N)⩽aok,k∈KThe quadratic objective function for (QMK) is thenMaximize∑(pjxjk:j∈N,k∈K)+∑(pjhxjkxhk:j,h∈N:j<h,k∈K)The cross product terms xjkxhkfor the quadratic multiple problem correspond directly to the cross product terms xjxhfor the quadratic single-constraint problem. Note in particular the profit coefficients pjand pjh, and the constraint coefficients aj, are the same regardless of the knapsack k that variable xjis assigned to, and are just the profit and constraint coefficients used in the single-constraint problem.Thus, the additional complexity introduced by the quadratic multiple knapsack problem consists of allocating the xjvariables to different knapsacks (which have different capacities aok). This allocation may be viewed as subdividing N1={j∈N: xj=1} into sets Jk, k∈K, where setting xjk=1 corresponds to assigning j to Jk(i.e., Jk={j∈N1: xjk=1}).Just as the multiple knapsack problem has different aocoefficients denoted by aok, the updated form of these coefficients produces different RHS values denoted by RHSk.To apply the previous Combination Evaluation Method and the associated Choice Rule for Selecting j∗ given in Sections 5.2.1 and 5.2.2, respectively, we must differentiate the evaluation QPjaccording to the knapsack k to which the evaluation refers, thus replacingQPj=pj+∑(phj:h∈N1)by the term QPjkdefined byQPjk=pj+∑(phj:h∈Jk)Then the previous terms QProfit, QRatio and QProduct all similarly are differentiated to refer to a specific knapsack k, to yield corresponding terms QProfitk, QRatiokand QProductk. Hence, for example, in the 3-element case we haveQProfitk(1,2,3)=QP1k+QP2k+QP3k+p12+p13+p23QRatiok(1,2,3)=QProfitk(1,2,3)/(a1+a2+a3)QProductk(1,2,3)=QProfitk(1,2,3)nk′(1,2,3)where nk(1,2,3)=⌊RHSk/(a1+a2+a3)⌋ andnk′(1,2,3)=Min(nk(1,2,3),⌊n0k/3⌋). Here, following Remark 2, we require a1+a2+a3⩽RHSk. The general profit representation is given byQProfitk(1,…,r)=∑(QPjk:j∈[1,r])+DeltarwhereDeltar=∑(phj:h∈[1,r-1],j∈[h+1,r])(Deltar=0if r=1) where again we assume [1, r]⊆N−N1 (={j∈N1: xj=0}).By means of these observations, our previous method for the quadratic single-constraint knapsack problem generalizes to the quadratic multiple knapsack problem as follows. We refer to this generalized method as a “Constructive Greedy” method to differentiate it from a related “Destructive Greedy” method we introduce later. The Constructive Greedy method includes both a classical ratio-based choice rule and an advanced product-based choice rule, according to the version of the Combination Evaluation Method that is embedded in the algorithm.Constructive Greedy (QMK)Initialize:xj=0 for all j∈NN1=∅ (N1, as before, is the index set for variables xjcurrently set to 1)RHSk=aokand Jk=∅ for all k∈K (Jkis the index set for j∈N1 such that j isassigned to knapsack k, hence for which xjk=1)ActiveK=K (ActiveK is the index set for those knapsacks k such that Nk≠∅,where Nk(analogous to No) is identified next)For each k∈ActiveKNk={j∈N: aj⩽RHSk}If Nk=∅ then ActiveK=ActiveK−{k}EndforWhile ActiveK ≠∅Apply Knapsack Choice Rule for Selecting k∗ (identified below)Apply Combination Evaluation Method to the knapsack k∗Apply Choice Rule for Selectingj∗ to the knapsack k∗xj∗=1xj∗k∗=1N1=N1∪{j∗}Jk∗=Jk∗∪{j∗}RHSk∗=RHSk∗-aj∗For all k∈ActiveKNk=Nk−{j∗}Nk={j∈Nk: aj⩽RHSk}If Nk=∅ then ActiveK=ActiveK−{k}EndforEndwhile(Upon concluding, xj=1 for j∈N1 and xj=0 otherwise. In terms of double subscripted variables, for each k∈K, xjk=1 for each j∈Jk,)The key issue remaining is to identify the Knapsack Choice Rule to choose k∗. We examine six options for this rule in order to show the relevant considerations, and then indicate the option that is anticipated to be best.Option 1. Choose k∗=argmin (RHSk: k∈ActiveK), hence knapsack k∗ is the one with the least current capacity.Option 2. Choose k∗=argmax (RHSk: k∈ActiveK), hence knapsack k∗ is the one with the greatest current capacity.Option 3. Choose k∗ to be the knapsack k that yields the maximum QRatiok(or QProductk) by the Combination Evaluation Method.Option 4. Let QRatio1k(QProduct1k) denote the largest QRatiok(QProductk) for knapsack k and let QRatio2k(QProduct2k) denote the second largest QRatiok(QProductk) for knapsack k. Then we choose k∗=argmax (QRatio1k−QRatio2k) or k∗=argmax (QProduct1k−QProduct2k).Option 5. Apply Option 3 or Option 4 subject to the following additional stipulation: the choice of the first k∗, denoted by k0, launches a cycle in which all other k∈ActiveK must be selected exactly once as k∗ before starting the next cycle by choosing as k∗=k0 again. (Thus there is no restriction on the order of choosing the knapsacks k∈ActiveK within the cycle.) If the original k0 drops out of ActiveK, then apply Option 3 or 4 to select a new k0 at the end of the cycle.Option 6. Apply Option 3 or 4 subject to the following restriction. When a knapsack k0 is selected as k∗, let MaxVal(k0)=Max (RHSk: k∈ActiveK) and MeanVal(k0)=Mean (RHSk: k∈ActiveK). Then k0 is eligible to be re-selected as k∗ by Option 3 or 4 as long as RHSk0⩾MeanVal(k0) and Max(RHSk: k∈ActiveK)<MaxVal(k0). Initialization sets MeanVal(k0) as above and MaxVal(k)=Large for all k∈ActiveK.First observe that Option 1 shares part of the same failing that the Naïve Greedy (QP) algorithm exhibited. Effectively, Option 1 implies that the same knapsack k∗ will be chosen on every iteration until it is filled – i.e., untilNk∗=∅. Then another knapsack will be chosen and it will likewise be chosen on every succeeding iteration until it is filled. The potential contribution of the Combination Evaluation Method is therefore partly negated.Option 2 does not suffer the limitation of Option 1, because it allows the Combination Evaluation Method to rotate its application among different knapsacks as their residual capacities RHSkbecome more nearly the same. However this option still does not give the Combination Evaluation Method a direct role in choosing k∗, hence again a part of the potential contribution of this evaluation method fails to be realized.Option 3 evokes the Combination Evaluation Method in choosing k∗, but the method will be biased to repeat the same choice of k∗ until the knapsack is full, much as in the case of Option 1 (due to the fact that the QPjvalues make an increasingly large contribution to the combination evaluations as Jkgrows, and hence this growth will tend to favor repeated choice of the same knapsack k∗ on successive iterations.Option 4, which is a form of “Min Regret” rule, engages the Combination Evaluation Rule more fully in the choice of k∗ and in this way appears more promising than the previous options. Nevertheless, there is still a possibility that the contribution from the QPjvalues to the combination evaluations will pass a tipping point that causes this option to shift toward selecting the same k∗ repeatedly until the knapsack k∗ is full.Options 5 and 6 offer a way to combat the limitations of Options 3 and 4. On the surface, Option 6 appears to be slightly more flexible than Option 5, but both options may be worth exploring. Conjecturally, the best option is Option 6 in the version that incorporates Option 4.A highly effective approach for the multiple knapsack problem has been developed in Garcı́a-Martı́nez (submitted for publication-a) using the strategic oscillation method. We briefly remark on how the Constructive Greedy (QMK) method can be used within such a strategic oscillation framework.The approaches of nearly all the methods for the (QMK) previously indicated use the naïve greedy algorithm for an initial construction, choosing the current knapsack k that receives the highest evaluation. Consequently, these methods all exhibit the weaknesses previously indicated for the naïve greedy approaches, and also have the “sequential fill” weakness discussed for Option 1 above. Thus, not surprisingly, the initial construction rarely produces a solution of high quality. We suggest a way to improve this situation even with a simple version of the Constructive Greedy (QMK) method, including one that uses only “1-element combinations,” hence which reduces to the naïve greedy method when bang-for-buck evaluations are used (as opposed to the product-based evaluations of the advanced methods).The idea is this. As observed in Glover (1995), it can sometimes be valuable to hover at various levels of constructive and destructive approaches, especially in a strategic oscillation setting, and improve the solution at such levels in addition to applying a method to improve the solution at the critical (boundary) level. In the present case, such a Hover-Oscillation process can serve to remedy a situation where early choices are myopic, and thus interfere with the possibility of making good later choices because of their reliance on the early choices for their evaluations. The following method, which is described for strategic oscillation, can also be adapted to the case of multi-start strategies (which may be viewed as one-sided oscillations that drop all the way back to the 0 solution).1.Select hover-levels by dividing the constructive or destructive process into intervals based on allocating resources available at the critical boundary. We illustrate this by considering 6 hover-levels H(L), L=1–6, represented by H(1)=.25, H(2)=.50, H(3)=.75, H(4)=1.00, H(5)=1.15 and H(6)=1.30. In the resource-based allocation, this generates the resource levelsaok(L)=H(L)aokL=1–6,k∈K(Note that the hover-point 4, for H(4)=1.00, corresponds to the critical level of a complete construction since aok(4)=aokfor each k.)Treat each hover-level as defining a complete problem, and instigate an improvement process to create a better solution relative to this level. (For example, for L=1 the problem is conceived to be the one with resource limits given by .25 of their total values. Once the construction process is complete for this set of limits, an improvement process is initiated to improve the solution at this level.)Spend additional effort at the critical hover-level which defines the complete construction (i.e., for H(L)=1.00), corresponding to the greater importance of obtaining good solutions at this level. The effort at other levels is graduated to be greater as the levels become closer to the critical level, particularly upon approaching the critical level from either side.Spend less effort at a hover-level during the process of retreating from the critical level than at the same level during the process of approaching the critical level. (As an extreme instance of this approach, the improvement at a given hover-level may be bypassed when retreating from the critical level.)The foregoing approach clearly gives rise to a number of possible variants, according to the choice of the number of hover-levels and the spacing between them, which may vary depending on which side of the critical level a particular hover-level lies. In addition, the hover-levels and the turn-around points, where the strategic oscillation ends its progression away from the critical level and begins approaching the boundary again, can change over time, as by the use of a changing span parameter (see. e.g., Glover and Kochenberger (1996) and the related rule of Garcı́a-Martı́nez (submitted for publication-a)).Implicit in the foregoing method is the need for a Destructive Greedy method that is the counterpart of the Constructive method, but which is executed during destructive phases of the method. Special considerations apply to the formulation of such a method and to coordinating it with a Constructive method. We describe such considerations and observe how they can give rise to variants of the Hover-Oscillation strategy for a variety of problems other than the quadratic multiple knapsack (QMK) problem. For example, such a variant is particularly well suited for being applied to the multi-constraint problems discussed next.The multi-constraint (or multi-dimensional) knapsack and covering problems generalize the single-constraint knapsack and covering problems as follows.Multi-constraint knapsack (MK)(MK0)Maximizexo=∑(pjxj;j∈N)+po(MK1)subjectto∑(aijxj;j∈N)⩽aioi∈M(MK2)xj∈{0,1},j∈Nwhere aio>0 for all i∈M={1,…,m}, pj>0 for all j∈N={1,…,n} and aij⩾0 for all i∈M and j∈N.Multi-constraint cover (MC)(MC0)Minimizeyo=∑(cjyj:j∈N)+co(MC1)subjectto∑(dijyj:j∈N)⩾dioi∈M(MC2)yj∈{0,1},j∈NSimilarly dio>0 for all i∈M, cj>0 for all j∈N and dij⩾0 for all i∈M and j∈N.Thus, (MK) and (MC) have the same formulations as (LK) and (LC), respectively, except that (MK1) and (MC1) involve multiple constraints whose coefficients are permitted to be non-negative instead of restricting the constraint coefficients to be positive. Problem (MC) is often called the generalized covering problem because classical covering problems additionally assume dij=0 or 1 for all coefficients defining (MC1). As before, we focus on the knapsack version of these problems since our observations extend naturally to the covering version.A variety of methods have been developed for the (MK) problem, including more recently a very effective method by Khemakhem et al. (in press). Most of the best-known solutions for the set of MKP instances available in the OR-Library (Beasley, 1990) were obtained by Vasquez and Hao (2001) and Vasquez and Vimont (2005). A comprehensive annotated bibliography of exact and approximate algorithms for (MK) appears in Fréville and Hanafi (2005).Surrogate constraint approaches for the (MK) problem apply weights wi⩾0, i∈M, to the constraints (MK1) to yieldaj=∑(wiaij:i∈M)forj=0andj∈NThe resulting surrogate constraints thus acquire the form∑(ajxj:j∈N)⩽aowhich are the same as the constraint (K1) of the single-constraint knapsack problems. In consequence, surrogate constraint strategies often use the approach of generating approximate solutions to single-constraint knapsack (and covering) problems as part of their operation (see, e.g., Glover, 1965, 1975, 2003; Gavish et al., 1991; Osorio et al., 2002; Hanafi and Glover, 2007; Ablanedo-Rosas and Rego, 2010).The extension of the Greedy and Advanced Greedy (LK) methods to apply to surrogate constraints for the (MK) problem is straightforward, noting that the set Nomust be explicitly determined relative to all constraints, by stipulatingNo={j∈N:aij⩽RHSifor all i∈M}. For any given i∈M, as soon as aij=0 for all j∈Nothis index i can be removed from M. (The current reduced constraint∑(aijxj:j∈No)⩽RHSicorresponds to 0⩽RHSiand hence is redundant.)Surrogate constraints can be generated and updated on successive iterations by using weights that result from normalizing the problems constraints, though the most effective rules generally include the use of linear programming to generate the weights, as by employing the weights that result from the optimal solution to the dual when (MK) is solved by a linear program.A recent extension of these approaches employs searches that employ constraints also generated by linear programming that bound sums of variables, as instances of earlier proposals for generating guiding constraints composed of sums and nested sums of variables (see, e.g., Glover, 1971; Osorio et al., 2002; Hanafi and Glover, 2007). These linear programming based methods have provided the best solutions for multi-constraint problems, notably in the work of Fleszar and Hindi (2009), Hanafi and Wilbaut (2011) and Khemakhem et al. (in press).We now disclose the somewhat surprising fact that the inequalities used by these best methods in the literature are dominated by inequalities generated by surrogate constraints, which raises the possibility that these latter constraints may provide guidance that is still more effective. Building on this observation, we will also propose new strategies for generating and exploiting such guiding inequalities. As a basis for doing this, we first briefly sketch the nature of inequalities previously used.Consider the relaxation of the constraints of (MK2) given by(MK2′)0⩽xj⩽1,j∈NThen the methods that use linear programming to generate guiding inequalities generally employ the following design.1.Use linear programming to Maximizezo=∑(xj:j∈N)subject to (MK1) and (MK2′), and denote the optimum zovalue byzo∗.Conduct a series of searches that enforce a succession of equations or inequalities of the formzo=U(orzo⩽U)whereU=zo∗,zo∗-1,zo∗-2,…,Uminfor a chosen integer value of Umin.As a variant (Fleszar and Hindi, 2009), randomly partition N into subsets N1 and N2 (restricting the number of elements in each) and use LP post-optimization to Maximizezo=∑(xj:j∈N1)-∑(xj:j∈N2)subject to (MK1) and (MK2′). Then similarly enforce a succession of equations or inequalities as in step 2.Additional strategies are employed for carrying out the indicated searches, as by tabu search in the case of Hanafi and Wilbaut (2011) and by the filter-and-fan method in the case of Khemakhem et al. (in press).We indicate the relationship of the guiding constraints used in these approaches to corresponding surrogate constraints as follows.Consider a more general class of linear programs for creating guiding constraints defined by(P)Maximizezo=∑(bjxj:j∈N)subjectto(MK1)and(MK2′)where the coefficients bjcan take any integer values, positive or negative. Ifzo∗is an optimum value for the linear program (P), then we have a guiding inequality(G)zo=∑(bjxj:j∈N)⩽zo∗Relative to this general problem (P), we identify the surrogate constraint(SC)∑(ajxj;j∈N)⩽aowhere, as beforeaj=∑(wiaij:i∈M)forj=0andj∈NWe note that the (LK) problem, which becomes a surrogate constraint problem when (SC) replaces (K1), explicitly includes the constraints xj∈{0,1}, j∈N. This observation is important for identifying the relative strength of different surrogate constraints.The integer coefficient version of (SC) is(SCI)∑(⌊aj⌋xj;j∈N)⩽⌊ao⌋By the original formulation of Glover (1965), surrogate constraints are defined to include cutting planes obtained from other surrogate constraints, and we note that (SCI) is a simple instance of a constraint that falls in this category.We identify the dual of (P) to be the problem(D1)(D)Minimizewo=∑(wiaio:i∈M)+∑(uj:j∈N)subjectto∑(wiaij:i∈M)+uj⩾bjj∈N(D2)wi⩾0,i∈Manduj⩾0,j∈NHere wiis the dual variable associated with constraint∑(aijxj;j∈N)⩽aioof (MK1) and ujis the dual variable associated with the inequality xj⩽1 of (MK2′). Note that the wiweights can be used to generate (SC) and (SCI).Defineai′=ai+ujfor j∈N andao′=ao+∑(uj:j∈N). Then the surrogate constraint generated from using all dual variables of (D) is given by(SCD)∑(aj′xj;j∈N)⩽ao′and the integer version of this constraint is given by(SCID)∑aj′xj;j∈N⩽aoThe following result shows that the solution of (P) to obtain the guiding constraint (G) also generates a surrogate inequality that dominates (G), since the optimal dual values for (D) are automatically obtained as a result of solving (P). (In particular, these dual values correspond to the optimal reduced costs for the slack variables of the constraints of (P).)PropositionAssume the weights wi, i∈M and uj, j∈N are obtained from optimal dual values for (D). Then the surrogate constraint(SCID)dominates the guiding inequality(G). Moreover, the surrogate constraint(SC)dominates the surrogate constraint(SCD), and the surrogate constraint(SCI)typically dominates both(SCID)and(G). Finally,(SCID)strictly dominates(G)if any coefficient bjof(G)is negative.Denote optimal dual weights for (D) bywi∗,i∈Manduj∗,j∈N, and letwo∗denote the associated optimum value of wo. By duality,wo∗=zo∗. Under the assumption of the Proposition and the definition ofao′we also haveao′=wo∗. Henceao′=zo∗and we may write (SCID) and (SCID) in this instance as(SCD):∑(aj′xj;j∈N)⩽zo∗and(SCID):∑aj′xj;j∈N⩽zo∗From (D1) we haveaj′⩾bjand hence (SCD) dominates the inequality∑(bjxj;j∈N)⩽zo∗where the latter is the same as the guiding inequality (G) except that (G) replaceszo∗byzo∗. In addition,aj′⩾bjand together withao′=zo∗we conclude that (SCID) in turn dominates (G). This proves the first claim of the Proposition.Next we show that by using the surrogate constraint (SCI) in place of (SCID) we can typically do still better. First consider the outcome of replacing (SCD) with the surrogate constraint (SC), which is given by∑(ajxj;j∈N)⩽aowhereaj=ai′-uj∗for j∈N andao=zo∗-∑uj∗:j∈N. From this we observe that the inequality (SCD) results from (SC) by multiplying each inequality xj⩽1 by the non-negative valueuj∗and adding it to (SC). Since the surrogate constraint problem includes the inequalities xj⩽1 for j∈N (as part of the stronger constraint xj∈{0,1}), the inequality (SCD) is dominated by (SC) when these constraints are considered as part of the full surrogate constraint problem. This dominance of (SCD) by (SC) indicates that upon considering the integer coefficient versions these constraints, the constraint (SCID) will often be dominated by (SCI).Finally, the fact that (SCID) strictly dominates the guiding constraint (G) when some coefficient bjof (G) is negative follows simply from the observation that all coefficients aijof the constraints (MK1) are non-negative, and hence both aj⩾0 andaj′⩾0, henceaj′>bj.□Another way of expressing the last statement of the preceding proof is to note that the surrogate constraints (SCI) and (SC) will be unchanged if any negative bjcoefficient is replaced by 0. Since this replacement significantly strengthens (G), and since one or both of the indicated surrogate constraints dominate this stronger form of (G), they correspondingly dominate the original form of (G).We observe that the equations corresponding to the surrogate constraint inequalities of the foregoing Proposition are likewise more restrictive than the equation that enforces (G) as an equality. Thus, equations as well as inequalities derived from surrogate constraints afford an opportunity to produce stronger methods based on incorporating guiding constraints to solve (MK) problems.The foregoing Proposition raises the thought that the surrogate constraint (SC) may be advantageous in place of using one of the integer coefficient surrogate constraints (SCI) or (SCID). The only reason for using these latter constraints is to be able to conduct a search that systematically decreases the right hand side value ⌊ao⌋ orzo∗by integer amounts. But all other search operations using such a surrogate constraint are unaffected by whether its coefficients are integer or not. These include, in particular, the operation of shrinking the set of active variables by reference to the set No, and the exploitation of the upper bound n0 on the sum of the variables in No.Consequently, the fact that (SC) dominates the surrogate constraint (SCD) which is the source of (SCID) makes (SC) an appealing candidate for consideration. A search based on systematically decreasing the right hand side of (SC) is still possible, and in fact integer decrements are reasonable by noting that the resulting right hand side values will still be as large or larger than those obtained by decrementing ⌊ao⌋. Moreover, since aj⩾⌊aj⌋ for left hand side coefficients, the “scale” of an integer decrement in the right hand side is less for (SC) than it is for (SCI). If this loses perfect assurance that no integer solution is bypassed, the implicit tolerance for deviating from an optimum objective function value will be small.If a search process that uncovers a succession of feasible solutions and keeps track of the best, whose objective function value we denote bypo∗, it is natural and customary to include the following objective function constraint among the other problem constraints∑(pjxj;j∈N)⩾po∗+1(The valuepo∗+1is based on assuming the pjcoefficients are integers.) To include this constraint among those of (P) to generate a surrogate constraint, we may re-write it as(OB)∑((-pj)xj;j∈N)⩽-po∗+1where OB is shorthand for “objective.” When surrogate constraints are generated from the resulting modified form of (P) and (D), there is an option of including or excluding the weight attached to (OB). In either case, the modified (P) and (D) can be valuable for strategies such as those discussed in Section 7.3 below.Assuming all coefficients of (P) are integers the range of surrogate constraints considered can be enlarged by a special use of the classical Gomory fractional cuts (FC). For our present purpose, we write these cuts in the following form(FC)s=∑(fjxj;j∈NB1)+∑(fisi;i∈NB2)+∑(fjvj;j∈NB3)-foHere “NB” refers to the set of non-basic variables in the optimal LP basic solution, and we have divided this set into NB1={j∈N; xjis non-basic}, NB2={i∈M; siis non-basic} and NB3={j∈N; vjis non-basic}, where the variables si, i∈M are the slack variables for the constraints of (MK1) and the variables vj, j∈N are the slack variables for the constraints of (MK2′). The “fractional” coefficients fo, fiand fjare non-negative values less than 1 (with fo>0) and s is the integer-valued slack variable for (FC). A Gomory all-integer cut can be obtained for the original representation of (P) (as opposed to the optimal basis representation that gives rise to (FC)) by noting that the coefficients fjfor j∈NB1 can be viewed as weights for the inequalities xj⩾0, written in the form −xj⩽0 to include among the other “⩽constraints” of (P). Then, multiplying each inequality of (P) by its corresponding non-negative weight from (FC) we obtain a valid inequality, and since s also has a representation as an integer linear combination of the current non-basic variables, we know the coefficients of the inequality for (P) are integers. However the right hand side is fractional, equal to an integer +fo, and hence upon rounding this value down (equivalent to subtracting fo) we obtain a Gomory all-integer cut for (P) that corresponds to the fractional cut (FC).For the goal of generating a surrogate constraint, however, we are only interested in the weights wi=fifor i∈NB2⊆M, since the inequalities xj⩾0 and xj⩽1 are explicitly included within the surrogate constraint system as part of xj∈{0,1}, and thus including the weights fjfor j∈NB1 and for j∈NB3 only weakens the resulting constraint. (This is conspicuously true for j∈NB1, since including the weight fjadds fj(−xj) to the resulting constraint, thus reducing the coefficient of xj.) Consequently, by defining wi=fifor i∈NB2 and wi=0 for i∈M−NB2 we obtain a surrogate constraint of the form (SC) that may be denoted.Different Gomory fractional cuts give rise to different surrogate constraints (SC)–(FC), and these provide an opportunity for using additional guiding constraints for solving (MK). When an objective function constraint is incorporated, as above, then it may optionally be considered as included among the constraints defining (MK1). As previously noted, we do not necessarily require the coefficients of the resulting surrogate constraints to be integers.We now examine a new class of strategies for exploiting surrogate constraints obtained by reference to (P).The Proposition of Section 7.2 and its associated discussion suggest how we can improve upon the customary approaches that use guiding inequalities for (MK). In these approaches the objective function Maximizezo=∑(bjxj:j∈N)for (P) either has all coefficients bj=1, or has some bj=1 and some bj=−1. However, we are motivated to go farther by considering other possibilities for selecting the coefficients of (P) to create guiding surrogate constraints, and to use the outcome of solving (P) as a basis for additional information to aid the search for a solution to (MK).We start from the premise that that it can be valuable to obtain surrogate constraints (and hence their associated surrogate constraint problems) which are likely to yield values of variables that match the values we anticipate most likely to correspond to values in an (MK) solution. Variables we estimate should receive 0 values will be called weak variables and variables we estimate should instead receive values of 1 will be called strong variables. We begin with the supposition that a good portion of the variables that should receive values of 0 and 1 will respectively be among those that have values close to 0 and close to 1 in an LP solution to (MK), and hence we use this as an initial criterion for identifying weak and strong variables.Evidently, surrogate constraints that yield larger coefficients ajandaj′for the weak variables compared to the coefficients for the strong variables will be more likely to drive the weak xjvariables to 0 in a knapsack solution. (This likelihood is reinforced by the definition of Noas the index set for variables that have coefficients not exceeding the current right-hand-side.) But since the dual problem (D) bounds eachaj′from below by bj, we may expect to influence the surrogate constraint to have the desired form by selecting positive bjcoefficients for the weak variables and zero bjcoefficients for the strong variables.More formally, letxjMKdenote the value of xjin an optimal LP solution to (MK). Then we select a fractional threshold T and define the weak and strong index sets byWeak={j∈N:xjMK⩽T}andStrong={j∈N:xjMK>T}From this, we choose bj>0 for j∈Weak and bj=0 for j∈Strong. By allowing T to vary, we can generate different collections of Weak and Strong variables, and thus induce the resulting surrogate constraints to influence the solution of (MK) in different ways in the role of guiding constraints.Among the possibilities for selecting the values of the positive bjcoefficients, two apparent candidates are to set (i) bj=1 for j∈Weak and (ii) bj=pjfor j∈Weak. By these choices, the instances of problem (P) that result for various values of the threshold T can readily be solved by post-optimization starting from the LP solution to (MK), and proceeding from smaller values of T to larger ones. By this means, the first post-optimization will occur for the instance that is closest in form to (MK) (especially when choosing bj=pjas opposed to bj=1) and each successive instance will be relatively close to the one preceding.Moreover, we can use solutions to these problems to refine the choices of Strong and Weak variables and to aid in the determination of 0–1 trial solutions for (MK). We describe how this can be done in very general terms, to provide latitude for multiple strategies.LetxjPdenote the value of xjin an LP solution to (P). If a variable xjin the Strong set (i.e., for which j∈Strong) yields a valuexjPthat is not appreciably closer to 0 thanxjMK, then in view of the fact that bj=0 provides less inducement for xjto be positive than the pjcoefficient in (MK), we may take this as evidence that xjshould indeed belong in the strong category. Consequently we are motivated to employ a trial solution strategy that sets xj=1 for such variables. On the other hand, if the relative decrease inxjPcompared toxjMKis greater than that the decrease for most other variables in the Strong set, then we may surmise that xjis not as strong as originally anticipated. This latter condition therefore motivates a transfer of j to the Weak set.Similarly, if a variable xjin the Weak set yields a valuexjPwhich is not appreciably closer to 1 thanxjMK, then in view of the fact that bj>0 provides greater inducement for xjto be positive than the coefficients bj=0 for variables in the Strong set, and in view of the effect of inequalities of (MK1) which causes a competition among variables to receive positive values, we may interpret the lack of increase inxjPoverxjMKas evidence that xjindeed belongs in the weak category. Consequently, this supports a trial solution strategy that sets xj=0 for such variables. On the other hand, if the relative increase inxjPcompared toxjMKis greater than that the increase for most other variables in the Weak set, then we may conclude that xjis not as weak as originally anticipated. This latter condition therefore motivates a transfer of j to the Strong set.When applying the preceding principles, variables that jump back and forth between the Strong and Weak categories are the ones that deserve special attention. Ultimately, when variables that belong more consistently to the Strong and Weak categories are set to their presumed appropriate values, the step of re-solving (P) for the reduced problem should cause these “vacillating variables” to become more stable (and land more decisively within either the Weak or Strong set), thus identifying good trial values for these variables as well.Greater variety in the foregoing process can be induced by using probabilities for assigning indexes to the Weak and Strong sets, where the magnitude of such probabilities is based on the proximity ofxjMKto T. However, this probabilistic approach weakens the basis for concluding whether a variable should be considered as a stable member of one set or another.The strategic oscillation approach sketched in Section 6 describes a form of this method in which the critical region is given in terms of the boundary that demarks feasibility from infeasibility. Other definitions of the critical region are appropriate to other forms of strategic oscillation and additional observations are warranted in order to identify how the Hover-Oscillation Method of Section 6.3 can be adapted to these cases. We first introduce key considerations relevant to the Hover-Oscillation Method in the context of the multiple knapsack problem, as treated in Section 6, identifying its components more rigorously and providing details of how the coordination of constructive and destructive phases occurs. Following this we discuss broader issues for carrying these ideas into other problem settings.We begin by giving a more compact but more technical description of the Hover-Oscillation Method of Section 6.3. We employ the following conventions.The hover-levels are indexed by L=0 to CrestLevel, the upper turn-around level, where a Destructive Phase is launched. A Destructive Phase then decreases L, proceeding from CrestLevel to TroughLevel, the lower turn-around level, where a new Constructive Phase in launched in turn. Thereafter, the method oscillates by repeating the Constructive and Destructive Phases. The number of levels between the lower and upper turn-around points (CrestLevel+1−TroughLevel) can be changed by reselecting CrestLevel each time L=TroughLevel or L=CrestLevel is reached.The hover-level multiples H(L) that give current resource capacities by the formula aok(L)=H(L)aok, k∈K can also change. We represent these capacities more directly by bok=H(L)aok, k∈K The application of either a constructive method in a Constructive Phase or a destructive method in a Destructive Phase, followed by an execution an Improvement Method, defines a pass of the method. That is, a Constructive Pass occurs when L increases by 1, and a new increased resource levelbok∗=H(L+1)aokresults, while a Destructive Pass occurs when L decreases by 1, and a new decreased resource levelbok∗=H(L-1)aokresults.Both the values of CrestLevel and TroughLevel, and the values H (L) can change from one oscillation to another. However, we retain the relationshipsH(L+1)>H(L)H(L)=1forsomeLsuchthatTroughLevel<L<CrestLevelwhere H(L)=1 identifies the critical level where bok=aok. By convention H(0)=0, but normally L=0 is only relevant for launching the initial constructive pass. (We could assume that TroughLevel is always represented by L=1 after this initial pass, but we refer to TroughLevel as a counterpart to CrestLevel to keep the description of the method symmetric.)The resulting Hover-Oscillation Method is described next to give an overall view of its structure, though we have not yet described the Destructive Greedy (QMK) Method employed during its Destructive Phase. This latter method requires the introduction of several additional observations, and is described subsequently.Initialization: xj=0, j∈N, and Jk=∅, RHSk=0, k∈K.Set the initial boundary level by bok=0, k∈K, corresponding to H(L)=0 for L=0.Establish a Termination Condition represented by Termination=true or falseWhile Termination=false(Constructive Phase of Oscillation)While L<CrestLevelL=L+1 (Begin Constructive Pass)bok∗=H(L)aok,k∈K.RHSk=RHSk+bok∗-bok,k∈K(RHSkincreases)bok=bok∗Execute Constructive Greedy (QMK) MethodExecute Improvement MethodEndWhile(Destructive Phase of Oscillation)While L>TroughLevelL=L−1 (Begin Destructive Pass)bok∗=H(L)aok,k∈K.RHSk=RHSk+bok∗-bok,k∈K(RHSkdecreases)bok=bok∗Execute Destructive Greedy (QMK) MethodExecute Improvement MethodEndWhile(Return to launch next Constructive Phase)EndwhileThere are several things to observe.1.The Termination Condition can be established in various ways, as in customary metaheuristic methods. For example, when the Improvement Method is applied at the critical level, a check can be maintained of the number of iterations since the last new best solution was obtained, and the method may terminate when this number exceeds a desired cutoff. Alternatively, the method may terminate after a specified overall iteration limit or time limit is exceeded, and so forth.In the Constructive Phase,bok∗>bok, and hence the value RHSkincreases, while in the Destructive Phase,bok∗<bok, and hence the value RHSkdecreases. If the problem data are integers, as often is the case, each newbok∗can be rounded to its nearest integer value so that the successive RHSkvalues will also be integers.The format of settingbok∗=H(L)aok,k∈Kis primarily for representational convenience and to give an intuitive glimpse of possibilities for setting resource levels. Because of the flexibility for revising the H(L) values, we could as easily stipulate that thebok∗values are generated by performing a current evaluation process each time L changes. As the process continues, the depth of the oscillation (distance between the turn-around points) can become relatively shallow.At the conclusion of both the Constructive and Destructive Greedy methods, the value of RHSkwill be given byRHSk=bok-∑ajk:j∈Jk)⩾0,k∈K. Hence the Improvement Method inherits the condition∑ajkxjk:j∈Jk)⩽bok(since Jk={j∈N: xjk=1}).As already intimated, the Improvement Method is applied more intensively during a process of approaching the critical level than during a process of retreating from the critical level, and as the current bokvalues become closer to the aokvalues (devoting the greatest effort to the case bok=aok, which identifies the critical level). Upon drawing close to the critical level, it is natural to allow the Improvement Method to have some flexibility to make moves that slightly violate the feasibility conditions. (If this is done at the critical level itself, the approach must of course complement such moves with others that restore feasibility.)The Hover-Oscillation Method could also begin by launching a Destructive Phase first, setting all xj=1 initially and arbitrarily (or heuristically) assigning the indexes j to the sets Jk, to determineRHSk=aok-∑(ajk:j∈Jk).We remark that it is also possible to select the critical level to be a turn-around level, in which case the method gives a one-sided oscillation. In such an approach, all oscillation occurs within exactly one of the feasible and infeasible regions, except that the final step within the infeasible region crosses into the feasible region in order to attain the the critical level that defines a complete (and feasible) solution.Now we turn to describing the Destructive Method that is incorporated within the foregoing approach.We require some additional conventions and definitions. As in the Constructive Greedy (QMK) Method, we make use of the term QPjkdefined byQPjk=pj+∑(phj:h∈Jk)However, since we are choosing an index j∗ to remove from Jkinstead of one to add to Jk(i.e., changingxj∗from 1 to 0 instead of from 0 to 1) we are only interested in quantities QPjksuch that j∈Jk. (Note it is not necessary in this case to stipulate h≠j in defining QPjkabove since pjj=0.)Analogous to the profit term QProfitkused in the Constructive Method, we introduce a lost profit termQProfitkofor the Destructive Method which we define byQProfitko(1,…,r)=∑(QPj:j∈[1,r])-DeltarWhere, as before,Deltar=∑(phj:h∈[1,r-1],j∈[h+1,r])(Deltar=0if r=1). Here we assume [1, r]⊆Jk.There are two ways in whichQProfitkoof the Destructive Method contrasts with QProfitkof the Constructive Method. First, as seen earlier, QProfitkis defined for the Constructive Method byQProfitk(1,…,r)=∑(QPjk:j∈[1,r])+Deltarhence attaching a different sign to Deltar. Second, although the definition of Deltarappears to be identical in the Constructive and Destructive Methods, in the Constructive case the indexes j∈[1, r] are elements of N−N1 (={j∈N: xj=0}), while in the Destructive case the indexes j∈[1, r] are elements of N1 (={j∈N: xj=1}) and in addition are assigned to a specific knapsack k; i.e., they are elements of Jk.Employing the conventionQProfitko(1)=Q1k, we may similarly write (in the case r>1)QProfitko(1,…,r)=QProfitko(1,…,r-1)+QPrk-PostDeltarwherePostDeltar=∑(phr:h∈[1,r-1]).Thus, in particular, the 2-element and 3-element cases yieldProfitk(1,2)o=QP1k+QP2k-p12andProfitko(1.2.3)=QP1k+QP2k+Q3k-p12-p13-p23Moreover, becauseProfitkois a lost profit (i.e., it represents the amount by which profit decreases when variables change from 1 to 0), we want to minimize rather than maximize this quantity. More precisely, we want to minimize an associated quantityQRatiokoorQProductkoanalogous to QRatiokand QProductkin the Constructive Method. However,QRatiokoandQProductkoare defined somewhat differently than QRatiokand QProductk, drawing on the following stipulations.Just as nj, n0 andnj′in the knapsack (LK) case are replaced by mj, m0 andmj′in the covering (LC) case, we replace the values nk(1,…,r), n0kandnk′(1,…,r)for the Constructive Method with values mk(1,…,r), m0kandmk′(1,…,r)for the Destructive Method. The quantity m0kis entirely analogous to m0, representing the least number of variables xjthat can be set to 0 in order to satisfy the resource level bokof knapsack k. A fast method for determining m0, corresponding to the fast level for determining n0 in Section 4.1, can be applied to each knapsack k to yield m0k.LetRHSko=-RHSk. In reference to 2-element combinations we definemk(1,2)=RHSko/(a1+a2)andmk′(1,2)=Max(mk(1,2),⌊m0k/2⌋)Similarly, in reference to 3-element combinations we definemk(1,2,3)=RHSko/(a1+a2+a3)andmk′(1,2,3)=Max(mk(1,2,3),⌈m0k/3⌉)From this, the general form for mk(1,…,r) andmk′(1,…,r)is apparent. Note that themk′(•)values select the max of two terms instead of the min of two terms as done in defining thenk′(•)values.This minimization goal of the Destructive Phase implies that theQProductkoandQRatiokovalues should be sequenced from smallest to largest to obtain a “best to worst” ordering, exactly the opposite from the QProductkand QRatiokvalues. Accounting for this difference, the Graduated-Probe Strategy has the same description for the destructive case as for the constructive case. Thus similarly we will refer to the Combination Evaluation Method and the Choice Rule for Selecting j∗ as if they are unchanged, understanding that we are referring toQProductkoandQRatiokovalues in place of QProductkand QRatiokvalues, and prefer smaller values to larger ones.There is one final important difference to note concerning the organization of a Destructive Method. Each knapsack k is evaluated independently of the others during a Destructive Phase, and the sequence in which the knapsacks are considered is immaterial. Thus, for example, the decisions made will not change if each knapsack k is examined in succession (in any order) and the method focuses just on this knapsack to set selected variablesxj∗=0for j∗∈Jkuntil satisfying RHSk⩾0, before examining the next knapsack. However, the interjection of improving moves at any point may modify this outcome.The Destructive Greedy method thus operates as follows, where we note that N1 and the sets Jk, k∈K are inherited from the current phase of search, along with the implicit assignments xj=1 for all j∈N1 and xik=1 for all j∈Jk, k∈K. The values RHSkare likewise inherited, and as stipulated we understandRHSko=-RHSk.Destructive Greedy (QMK)Initialize:ActiveK=k:RHSko>0While ActiveK≠∅Select any knapsack k∗ in ActiveKApply Combination Evaluation Method to the knapsack k∗Apply Choice Rule for Selectingj∗ to the knapsack k∗xj∗=0xj∗k=0N1=N1−{j∗}Jk∗=Jk∗-{j∗}RHSk∗=RHSk∗+aj∗(henceRHSk∗o=RHSk∗o-aj∗)IfRHSk∗⩾0then ActiveK=ActiveK−{k∗}Endwhile(Upon concluding, xj=1 for j∈N1 and xj=0 otherwise. In terms of double subscripted variables, for each k∈K, xjk=1 for each j∈Jk,)As previously indicated, strategic oscillation has been applied by reference to defining critical levels based on a variety of criteria in addition to feasibility and infeasibility. Commonly, the critical level itself is manipulated in an oscillating fashion. For example, critical levels have been defined by reference to numbers of employees in employing scheduling (Glover and McMillan, 1986), numbers of platforms in telecommunications network design (Glover et al., 1992), objective function values in arc crossing minimization (Valls et al., 1996), values of p for in p-median problem (Voss, 1996a), numbers of markets in the traveling purchaser problem (Voss, 1996b), and numbers of partitioned nodes in graph partitioning (Rolland et al., 1997).Problems where the Hover-Oscillation approach appears most relevant are those where it is natural to oscillate over an allocation of resources, as in multiple knapsack and multi-constraint knapsack problems. In the multi-constraint problems, unlike the multiple knapsack problems, the destructive phases are more nearly symmetrical to the constructive phases. However, here too a minimization perspective related to a covering approach is appropriate in the destructive phase. In general, if the original problem is formulated with a maximization objective, then destructive phases are most easily formulated in terms of a minimization objective (as opposed to the equivalent, but less intuitive, formulation in terms of maximizing the negative of the original objective).The application of the basic ideas of the Hover-Oscillation Method in other settings opens up an interesting area for research. In particular, for problems where oscillation strategies effectively involve oscillating over a sum of variables, as in the first two oscillation methods mentioned above (oscillating over numbers of employees and over numbers of platforms), other resource considerations are likely to be present where a Hover-Oscillation approach may constitute a reinforcing form of oscillation.In addition, the uses of surrogate constraints described in Section 7 invite a strategy where a collection of such constraints is considered as a select set of resource limitations to which a Hover-Oscillation Method can be applied. The Improvement Method in such cases will normally include reference to constraints in addition to those treated by the Hover-Oscillation approach.

@&#CONCLUSIONS@&#
