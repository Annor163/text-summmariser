@&#MAIN-TITLE@&#
A hybrid noise suppression filter for accuracy enhancement of commercial speech recognizers in varying noisy conditions

@&#HIGHLIGHTS@&#
Commercial speech recognizers open speech control applications.They are likely to be produced error when background noise surrounds.Potential dangers are created if recognition errors exist.We proposed a noise suppression filter to enhance the recognition accuracy.It intends to decrease the recognition errors under noisy environment.

@&#KEYPHRASES@&#
Fuzzy neural networks,Noise suppression filter,ANFIS,Speech recognition,Commercial speech recognizer,Sigmoid filter,Speech enhancement,

@&#ABSTRACT@&#
Commercial speech recognizers have made possible many speech control applications such as wheelchair, tone-phone, multifunctional robotic arms and remote controls, for the disabled and paraplegic. However, they have a limitation in common in that recognition errors are likely to be produced when background noise surrounds the spoken command, thereby creating potential dangers for the disabled if recognition errors exist in the control systems. In this paper, a hybrid noise suppression filter is proposed to interface with the commercial speech recognizers in order to enhance the recognition accuracy under variant noisy conditions. It intends to decrease the recognition errors when the commercial speech recognizers are working under a noisy environment. It is based on a sigmoid function which can effectively enhance noisy speech using simple computational operations, while a robust estimator based on an adaptive-network-based fuzzy inference system is used to determine the appropriate operational parameters for the sigmoid function in order to produce effective speech enhancement under variant noisy conditions. The proposed hybrid noise suppression filter has the following advantages for commercial speech recognizers: (i) it is not possible to tune the inbuilt parameters on the commercial speech recognizers in order to obtain better accuracy; (ii) existing noise suppression filters are too complicated to be implemented for real-time speech recognition; and (iii) existing sigmoid function based filters can operate only in a single-noisy condition, but not under varying noisy conditions. The performance of the hybrid noise suppression filter was evaluated by interfacing it with a commercial speech recognizer, commonly used in electronic products. Experimental results show that improvement in terms of recognition accuracy and computational time can be achieved by the hybrid noise suppression filter when the commercial recognizer is working under various noisy environments in factories.

@&#INTRODUCTION@&#
Well-established speech recognition technologies benefit many rehabilitation and biomedical engineering industries in the development of health or assistance devices for paraplegics and the disabled, where speech recognition is used as a patient-machine interface which transfers control commands from patient to the machine and provides feedback from the machine to the patient. Although advanced sensors for human movements such as eyes and tongue switches have been included in health or assistance devices, such sensing approaches have many limitations which make these devices less efficient for the user. In fact, speech control is simpler in interfacing between the patients and the assistance devices, and it has been implemented for the control of server-assistance devices for the disabled [44,45]. In the commercial and industrial sectors, speech controls [2,27] are used in factory automation [32], warehouse automation [1], and industrial robotic control [26]. Disabled people can give verbal commands or input data to control the manufacturing system without the necessity for physical contact since speech is the only thing required to control the manufacturing systems [24].During the development of the commercial recognizer mechanism, much research regarding speech recognition was conducted on enhancing speech recognition accuracy by developing effective recognition algorithms [14,23], identification mechanisms for capturing significant speech features for recognition [20,30], recognition algorithms for distorted and contaminated speech [42], etc. However, these approaches have a common limitation in that the development of speech recognizers has been based only on a database which consists of a limited number of speech signals contaminated by certain types of acoustic noise. It is impractical for industrial sectors to manufacture a commercial speech recognizer which can work ideally in every noisy environment, due to the limitations of cost and time. Hence, conventional commercial recognizers can work accurately only under the trained noisy conditions, but might not work under untrained noisy conditions in which inaccurate recognitions are likely to occur. Recognition errors in a control system would create potential risks and dangers for the disabled user. Therefore, it is necessary to decrease the recognition errors for commercial speech recognizers that are working in noisy environments.Although multi-channel beamformers [9,15,41] can be used to enhance noisy speech which is contaminated by near-end noise, such approaches have the commonly limitation that the signal source needs to be tracked, based on the difference between the signal spectrums collected from multiple channels. Also, their mechanisms are computationally complex and their inbuilt parameters need to be calibrated with respect to the location of noise sources and speech sources.A practical way to improve recognition accuracy is to interface the commercial speech recognizer with a noise suppression filter which works effectively under multi-noise conditions for varying noisy environments. Noise suppression filters first identify both active and inactive periods of noisy speech, and then estimate the noise spectrum based on the inactive periods. Hence, an enhanced speech spectrum can be produced by removing the noise spectrum from the original speech spectrum [4]. However, several acoustic criteria need to be addressed in order to enhance the accuracy of commercial speech recognition, as annoying residual noise or musical noise can be perceivable when the noise spectrum is under-estimated, and original speech can be distorted leading to a loss of speech quality and intelligibility when the noise spectrum is over-estimated [29]. It is difficult to optimize those acoustic criteria even under a single condition with respect to a single user and a single noisy environment, as nonlinearities exist in those acoustic criteria; moreover, multi-objective optimization for satisfying those acoustic criteria needs to be handled. It is much more difficult to satisfy multi-noise conditions which involve multi-users and varying noisy environments.Although much progress has been made in the development of noise suppression filters using different cost functions engaged with different acoustic criteria which are perceptual, intelligibility and quality [3,6], these approaches are often computationally complex and difficult to implement in real-case scenarios. Even though a powerful processor can be used to implement such complex filters, speech quality can only be improved with respect to the specified but limited acoustic criteria which may not be related to accuracy of speech recognition. Hence, they still result in poor speech recognition performance.Hu et al. [16] show that sigmoid filters with low complexity can be implemented for real-time speech recognitions. These simple sigmoid filters overcome the limitation of the noise suppression filters which are too computationally complex for real-time implementation. To further increase the flexibility of speech enhancement for varying noise conditions, Yong et al. [39] have recently developed an advanced sigmoid gain function, which combines a logistic function with a hyperbolic tangent function. The advanced sigmoid gain function provides several filter parameters that can be adjusted to flexibly model exponential distributions, in order to achieve a balanced trade-off between many acoustic criteria such as noise reduction, speech distortion and musical noise [41]. With this trade-off, the accuracy of the commercial recognizer can be enhanced under a single-noisy condition. However, a particular set of filter parameters can be optimized only with respect to a single condition with a particular noise power level. Hence, it is necessary to adjust the filter parameters to maintain the trade-off under varying noisy conditions.In this paper, a hybrid noise suppression filter, namely ANFIS-SF, is proposed based on the mechanisms of the ANFIS and the sigmoid filter, in order to improve the accuracy of the commercial recognizer operating in varying noisy conditions. To develop ANFIS-SF, a speech recognition problem is formulated in order to optimize the accuracy of the commercial recognizer with respect to a single-noisy condition. A global optimization method, namely particle swarm optimization (PSO), is used to initialize a set of optimal filter parameters, each of which is optimized with respect to the speech recognition problem, as PSO can effective in solving optimization problems with similar landscapes which are discontinuous, vastly multimodal and non-differentiable [25,36,37,43]. Based on these optimal filter parameters for single-noise conditions, a robust estimator [18], ANFIS, is used to perform a mapping relationship between filter parameters and various noisy conditions, as this mapping relationship is highly nonlinear and ANFIS is an effective method for nonlinear mapping [10,13,22,31,48]. As the ANFIS provides appropriate filter parameters for the sigmoid filter with respect to varying noisy conditions, the resulting ANFIS-SF is likely to work effectively under such conditions.The effectiveness of the ANFIS-SF is demonstrated by interfacing it with a commercial speech recognizer which is used in electronic products [28]. When compared with other existing noise suppression filters, ANFIS-SF produces better results in terms of recognition accuracy and computational time in factory environments.A commercial recognizer,ℜ(⋅),is designed to identify n inbuilt speech commands,{u1,u2,…,un}of which those speech commands can be single words such as numerical digits, ‘yes’ or ‘no’ decisions, ‘left’ or ‘right’ directions, etc., or those speech commands can also be phrases, such as operational commands for manufacturing processes, speech controls for toys or audio players, etc.Let the tth sample of the noisy speech,xji(t),received byℜ(⋅)be denoted as,(1)xji(t)=sji(t)+v(t),i=1,2,…,nwheresji(t),is the ith speech command voiced out by the jth regular user, with j=1,2.,N of which N is the number of regular users;v(t),is the background noise;t=1,2,…,m;and m is the number of samples. Letiˆbe the recognized command fromℜ(⋅)for the noisy speech,xji(t),which is given by,(2)iˆ=ℜ(xji),wherexji=[xji(1),xji(2),…,xji(m)].Ifiˆ=i,a correct recognition is obtained with respect toxji.Otherwise, an incorrect recognition occurs, ifiˆ≠i.When the power of v(t) is large, recognition errors are likely to be produced byℜ(⋅).A sigmoid filter, namelyGSIG(ω,ℓ,κ¯(σ))with three filter parameters,κ¯(σ)=[κ1(σ),κ2(σ),κ3(σ)],can be used to enhance the accuracy ofℜ(⋅),where ω is a real angular center frequency given byω∈[ω0,ω1,…,ωK−1];ℓis the time frame index given byℓ∈[0,1,…,L−1];K is the number of bands; L is the number of frames; and σ is the estimated degrees of signal to noise ratio (SNR).UsingGSIG(ω,ℓ,κ¯(σ)),the estimate of clean speech spectrum,Sˆji(ω,ℓ),with respect tosji(t)can be obtained by:(3)Sˆji(ω,ℓ)=GSIG(ω,ℓ,κ¯(σ))⋅Xji(ω,ℓ)whereXji(ω,ℓ)is the M-point short time Fourier transformation ofxji(t);andGSIG(ω,ℓ,κ¯(σ))is formulated as:(4)GSIG(ω,ℓ,κ¯(σ))=GSIG(ω,ℓ,κ1(σ),κ2(σ),κ3(σ))=11+e−κ1(σ)⋅(ξˆ(ω,ℓ)−κ2(σ))⋅1−e−κ3(σ)⋅ξˆ(ω,ℓ)1+e−κ3(σ)⋅ξˆ(ω,ℓ);ξˆ(ω,ℓ)is the estimate of a priori SNR, which is determined based on the modified decision directed approach [39] and is given byξˆ(ω,ℓ)=β|GSIG(ω,ℓ−1,κ¯(σ))⋅X(ω,ℓ)|2λˆv(ω,ℓ)+(1−β)P(γ(ω,ℓ)−1)whereλˆv(ω,ℓ)andGSIG(ω,ℓ−1,κ¯(σ))denote, respectively, the estimated noise PSD from [38] and the gain value from the preceding frame. The parameter β denotes the smoothing factor,P(⋅)denotes the half-wave rectification andγ(ω,ℓ)denotes the a posteriori SNR. Withξˆ(ω,ℓ),σ can be determined asσ=E(ξˆ(ω,ℓ)).InGSIG(ω,ℓ,κ¯(σ)),κ¯(σ)needs to be optimized with respect to σ. In the first term ofGSIG(ω,ℓ,κ¯(σ))illustrated in (4), the sigmoid slope of the logistic function can be adjusted in order to maximize sensitive toward speech and minimize sensitive toward variation of noise, by tuningκ1(σ)andκ2(σ)with respect to σ. To further enhance the effectiveness of noise reduction at low SNR,κ3(σ)can be used to makeGSIG(ω,ℓ,κ¯(σ))trending to be zero under a very low σ. Therefore, the behavior ofGSIG(ω,ℓ,κ¯(σ))can be made similar to different conventional noise filters by optimizingκ¯(σ)=[κ1(σ),κ2(σ),κ3(σ)]with respect to σ[39].When working under a single condition, the filter parameters,κ¯(σ),need to be optimized only with respect to a single σ, by solving the following optimization problem in order to maximize the accuracy ofℜ(⋅):(5)Js(κ¯(σ))=maxκ¯(σ)∑j=1N∑i=1nθji,subject toθji=0ifℜ(sˆji)≠i,which is incorrect recognition1ifℜ(sˆji)=i,which is correct recognition,wheresˆjiis the time domain ofSˆji(ω,ℓ)in (3) which is obtained by the inverse M-point short-time Fourier transformation ofSˆji(ω,ℓ).However, it is impractical to develop a filter which can only work effectively with respect to a single condition, as the power of noise and the power of user speeches cannot be a constant in an operational environment for the commercial recognizer. Hence, multi-conditions need to be addressed to generate a filter which can enhance accuracy of the commercial recognizer under multiple SNR. For multi-conditions, the following optimization problem is solved, in order to maximize accuracy ofℜ(⋅)under varying σ:(6)JM(K¯)=∑k=1pJs(κ¯(σk)),where all σkare within the specified minimum and maximum of SNRs with respect to the operational environments for the commercial recognizer; andK¯opt=[κ¯opt(σ1),κ¯opt(σ2),…,κ¯opt(σp)]is the filter parameter set for multi-conditions of whichκ¯opt(σk)is optimal with respect to the SNR of σk; and p is the number of multi-conditions with multiple SNR. Since the optimization problem formulated in (6) involved the step function which represents the correct recognitions, it is non-differentiable. Hence, local search methods, which require gradient information to trace optimum, are not appropriate for solving this optimization problem. Since the particle swarm optimization performs effectively on solving similar optimization problems which are discontinuous, vastly multimodal and non-differentiable [25,36,37,43], the particle swarm optimization (discussed in Section 3.1) is used to solve this optimization problem.In this paper, a hybrid filter namely, ANFIS-SF, is proposed based on the mechanisms of the ANFIS and the sigmoid filter, in order to enhance the accuracy of the commercial recognizer for multi-conditions formulated in (6). To develop ANFIS-SF, PSO is first used to initialize a set of optimal filter parameters, each of which is optimized with respect to a single condition formulated in (5). Then an ANFIS is developed based on these optimal filter parameters, in order to create a map between the filter parameters and the SNR.Fig. 1illustrates the mechanism of the ANFIS-SF. The filter parameters are first determined by the ANFIS based on the degree of estimate of SNR, which is within the operational environments for multi-conditions. Then, the sigmoid filter enhances the noisy speech based on the determined filter parameters. Correct recognitions are more likely to be produced by the commercial recognizer based on the enhanced speeches. Hence, the multi-conditions formulated in (6) can be addressed. Detailed descriptions of the PSO and the ANFIS are discussed in the following two subsections.The PSO consists of Nsparticles, where the position of the jth particle at the gth generation is represented by:(7)Pjg(σi)=(κj,1g(σi),κj,2g(σi),κj,3g(σi)),which are the filter parameters used in the sigmoid filter,GSIG(ω,ℓ,Pjg(σi)),against a single condition for a particular SNR,σi. At the 1-st generation with g=1, allκj,kg(σi),with k=1, 2, 3, are generated randomly within their operational ranges, given asκj,1g(σi),κj,2g(σi)∈[0,…,1]andκj,3g(σi)∈0,…,15,which can be referred to [39]. When g>1, eachκj,kg(σi)are updated based on its velocity,velj,kg(σi),by the following formulation (8):(8)κj,kg(σi)=κj,kg−1(σi)+velj,kg(σi)where(9)velj,kg(σi)=C(vj,kg−1(σi)+φ1⋅γ⋅(pbestj,k(σi)−κj,kg−1(σi))+φ2⋅γ⋅(gbestk(σi)−κj,kg−1(σi))pbestj(σi)=[pbestj,1(σi),pbestj,2(σi),pbestj,3(σi)],andgbest(σi)=[gbest1(σi),gbest2(σi),gbest3(σi)];pbestj(σi) denotes the best previous position of a particle recorded from the previous generation; gbest(σi) denotes the position of the best particle among all particles; γ denotes a random number in the range of [0,1]; w is an inertia weight factor; ϕ1 and ϕ2 are the acceleration constants [11]; and C denotes the constriction factor, that ensures the PSO converges [5], which is given by:(10)C=2|2−ϕ−ϕ2−4ϕ|,withϕ=ϕ1+ϕ2andϕ>4.The PSO utilizes pbestj(σi) and gbest(σi) to modify the current location of allκj,kg(σi)in order to prevent them from moving in the same direction, but to converge gradually toward pbestiand gbest[12]. To further refine the dynamic ofκj,kg(σi),velj,kg(σi)is limited by a value which was set as 10–20% of its range. This limit is employed to avoidκj,kg(σi)from flying past good solutions or exploring insufficient local solutions. The searching process of the PSO stops when it converges to a satisfactory filter parameter with respect to (5), where the satisfactory filter parameters are denoted asκ¯opt(σi)=[κj,1opt(σi),κj,2opt(σi),κj,3opt(σi)],which can address the enhancement of speech recognition with respect to a single condition formulated in (5).To address the multi-conditions formulated in (6), the PSO can be run for p times where each run targets a particular SNR condition, σiwith i=1, 2, …, p. However, it is impractical to find large sets of filter parameters in which each set of filter parameters is optimal with respect to only a single SNR. Hence, the satisfactory filter parameter set,K¯=[κ¯opt(σ1),κ¯opt(σ2),…,κ¯opt(σp)],determined by the PSO is used to develop an ANFIS in order to construct an input-output mapping between σ andκ¯′(σ).A description of the development of an ANFIS is given in the following subsection.Although simple neural networks are capable of modeling nonlinear systems, the models generated are implicit. It is difficult to analyze the relationship between filter parameters and SNR within the simple neural network. Therefore, ANFIS is proposed, whereby a non-linear and explicit model can be generated in order to represent the relationship between filter parameters and SNR. In ANFIS, the architecture of Takagi-Sugeno fuzzy model [34] with one input and three outputs is used, where the input represents the SNR, σ, and the outputs represents the estimates of the three filter parameters which are denoted by,(11)κˆ(σ)=[κˆ1(σ),κˆ2(σ),κˆ3(σ)].Using the mechanism of ANFIS,κˆ(σ)can be estimated with respect to any σ, where the ANFIS consists of nrule fuzzy rules, and the gth fuzzy rule is given by:(12)Rg:IFσisAg(σ)THENzgj=w0,g+σ⋅w1,gjwithj=1,2,3g=1,2,…,nrule;w0,gjandw1,gjare the consequent coefficients with respect to the polynomial of the gth rule and the estimate of the jth filter parameter,κˆj(σ);zgjis the consequence of the polynomial with respect to the gth rule andκˆj(σ);Ag(σ)denotes the membership function of the gth fuzzy rule, which is given by:(13)Ag(σ)=exp−(σ−μg)2ρg;and μgand ρgare the mean and the variance of Ag(σ) respectively. When the SNR is σ, the estimate of the jth filter parameter,κˆj(σ),is given by:(14)κˆj(σ)=∑g=1nrule(Ag(σ)⋅(w0,gj+σ⋅w1,gj))∑g=1nrule(Ag(σ)).Here, a widely used approach with fast convergence, namely Jang's algorithm [18], is used to determine the ANFIS parameters,w0,gj,w1,gj,μg,and ρg. The filter parameters,κ¯opt(σi)=[κj,1opt(σi),κj,2opt(σi),κj,3opt(σi)],with i=1, 2,…, p, which are determined based on the PSO, are used to train the ANFIS, where that set of filter parameters is divided into two sets, namely training set,T¯,and validation set,Ω¯,such thatκ¯opt(σi)∈T¯andκ¯opt(σj)∈Ω¯,withalli,j∈[1,2,…,p]but alli≠j.The training error,eT¯,and the validation error,eΩ¯,with respect toT¯andΩ¯are given by:(15)eT¯=∑∀κ¯opt(σi)∈T¯eARE(κ¯opt(σi))and(16)eΩ¯=∑∀κ¯opt(σi)∈Ω¯eARE(κ¯opt(σi)),respectively,whereeARE(κ¯opt(σi))is the absolute difference between the real parameter,κ¯opt(σi),and the estimated parameter,κˆ(σi),andeARE(κ¯opt(σi))is determined by:(17)eARE(κ¯opt(σi))=eARE([κ1opt(σi),κ2opt(σi),κ3opt(σi)])=∑j=13κjopt(σi)−κˆj(σi)κjopt(σi)In the early training stage for the ANFIS, both training errors and validation errors decrease gradually, as the characteristics of both training and test sets are usually similar. After both errors decrease to a certain level, the ANFIS becomes over-trained by the training set and the validation error increases with the decreased training error. During this time, the training of the ANFIS is terminated when the validation error starts to increase. Hereby, over-fitting can be avoided and the determined filter parameters,κ¯(σ),can be used as the filter parameters of the sigmoid filter. Hence, the multi-conditions formulated in (6) with varying σ can be addressed.In this research, a commercial recognizer, namely the RSC3X synthesis microcontroller [28], is used to evaluate the effectiveness of the proposed ANFIS-SF since the commercial recognizer has been applied widely to various electronic products with speech control functions.The commercial recognizer is a finite state machine, which can be in either a standby state or trigger state. When there is conversational interchange between the commercial recognizer and the user, the commercial recognizer is in the trigger state. Otherwise, the commercial recognizer is in the standby state where it is assumed that no conversational interchange is being conducted. During the trigger state, the trigger phrase voiced out by the user is passed to its inbuilt hidden Markov model which generates a set of likelihoods for the trigger phrase with respect to the speech commands. The speech command with the highest likelihood is the outcome of the commercial recognizer which is the recognized command. More than 99% accuracy can be produced when the commercial recognizer works under high SNRs [28], but wrong recognitions are likely to be produced under low SNRs.The commercial recognizer was configured as in Fig. 4, which simulates the environment of a noisy factory. Here the commercial recognizer was placed in front of a warehouse operator and a noise source was produced by a factory machine located beside the warehouse operator. The proposed ANFIS-SF was interfaced with the commercial recognizer in order to enhance the noisy speech before performing speech recognition. The commercial recognizer was implemented for the assigned machine, which can assign the five Christmas carol products including ‘Jingle Bells’, ‘Santa Claus is Coming to Town’, ‘Sleigh Ride’, ‘Let It Snow’, and ‘Winter Wonderland’, where the five carol names are the speech commands embedded in the commercial recognizer. These are typical commands comprising phrases which can be used as the statements for commanding the assigned machine to deliver different song products. The assigned machine can deliver the correct song product if the speech command voiced by the factory operator is recognized correctly. If a wrong command is recognized, the assigned machine either deliver correct song product or generates no action (Fig. 2).When the SNR is high, correct commands are likely to be recognized. However, noise always exists in a factory, and inaccurate recognitions are likely to occur. Therefore, ANFIS-SF is used to interface with the commercial recognizer in order to upgrade recognition accuracy. In a factory environment, the SNRs of the noisy speeches received by the commercial recognizer depend on three factors: (1) the volume of the noise produced by the factory machine; (2) the volume of the speech voiced out by the users; and (3) the distance between the user and the commercial recognizer.The company supporting this research specially developed a Matlab interface for the commercial recognizer whereby the recognized commands can be returned by the Matlab. The noisy environments in a factory were considered, and noise sequences were collected from the Noisex-92 database [33]. If the commercial recognizer is working accurately, factory operators can simply voice out speech commands to control the assigned machine in order to remain focused on the main tasks without requiring both hands to control the machine. Interruptions to their main task can be minimized. Here, the sampling time used for the commercial recognizer is 18kHz. All the algorithms and computations involved in this study were implemented using Matlab 2008 in a PC which has a CPU of Intel(R) Core(TM)2 Duo 2.66GHz and a memory of 7.99GB.Five speech commands voiced by ten people, eight males and two females, were recorded in a recording studio which is assumed to be noise free. Then, the recordings were contaminated artificially with two types of factory noise, namely machinery noise and engine noise, in order to simulate the noisy environment of factories. The machinery noise was recorded near plate-cutting and electrical welding equipment, and the engine noise was recorded in the engine room while the engine was running. The recorded speech commands were contaminated at different SNRs, so as to simulate the real environment in which the people voice the commands with different volumes and at different distances from the commercial recognizer.To develop the ANFIS-SF, the number of fuzzy rule, nrule, used in ANFIS-SF is 3. The following parameters, which can be found in reference [47], were implemented in the PSO: the number of particles in the swarm was 100; the number of elements in the particle was 30; both the acceleration constants φ1 and φ2 were set at 2.05; the maximum velocity vmax was 0.2; the pre-defined number of generations was 100. Based on the results in [47], these parameters can produce satisfactory results when solving both parameterized and combinatorial problems. Therefore, these parameters are used in this research.Cross-validations were used to evaluate the effectiveness of the ANFIS-SF, where the cross-validations were repeated five times. The training set was generated by the seven male speech commands and the one female speech command, which were contaminated with various SNRs. The test set was generated by the remaining one male and one female speech commands contaminated with various SNRs. Hence, the performance of the ANFIS-SF can be evaluated in terms of the recognition accuracy under multi-conditions with various SNRs and multi-users. Also, it simulates a practical situation whereby the ANFIS-SF is trained by a group of regular users and is used by new users. It can therefore evaluate whether the trained ANFIS-SF can work accurately with respect to those new users.After testing the performance of the commercial recognizer by gradually decreasing the SNRs, it was found that the commercial recognizer performs poorly under machinery noise and engine noise with similar SNRs. Therefore, both training sets and test sets were contaminated with similar SNRs for both types of noise. The training set was contaminated with the SNRs of −5dB, −4dB, −3dB, −2dB, −1dB, 0dB, 1dB, 2dB, 3dB, 4dB and 5dB, while the test set was contaminated with the SNRs of −5.5dB, −4.5dB, −3.5dB, −2.5dB, −1.5dB, −0.5dB, 0.5dB, 1.5dB, 2.5dB, 3.5dB, 4.5dB. Therefore, 11 SNR cases were considered for both training and test sets. The SNRs of the test set was smaller than those of the training set with 0.5dB in order to evaluate the recognition accuracy under different SNRs.In the five cross-validations, there were 5 commands and 8 persons involved in training, so 120 training sequences were involved in each SNR case. While there were 11 SNR cases for training, there were a total of 1320 training sequences involved in training. For testing, there were 5 commands and 2 persons involved, so each SNR case had 50 test sequences. For testing, 11 SNR cases were involved with a total of 550 test sequences.

@&#CONCLUSIONS@&#
