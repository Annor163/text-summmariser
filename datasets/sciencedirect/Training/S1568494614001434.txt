@&#MAIN-TITLE@&#
Automatic system to detect the type of voice pathology

@&#HIGHLIGHTS@&#
Existing voice pathology detection techniques are classifying the given signal as normal voice and pathological voice. But no technique is to detect the type of pathology (analyzed the techniques published during last five years).This is a new work in the direction to detect the specific type of pathology.A two level system has been proposed for detecting the type of voice pathology. In the first level, the system identifies whether the given voice is normal or not. If it is recognized as pathological voice, in the second level which aims at identifying the particular type of pathology.

@&#KEYPHRASES@&#
Voice pathology,Mel-frequency cepstral coefficients,Linear prediction cepstral coefficients,Gaussian mixture model and hidden Markov model,

@&#ABSTRACT@&#
Acoustic analysis is a noninvasive technique based on the digital processing of the speech signal. Acoustic analysis based techniques are an effective tool to support vocal and voice disease screening and especially in their early detection and diagnosis. Modern lifestyle has increased the risk of pathological voice problems. This work focuses on a robust, rapid and accurate system for automatic detection of normal and pathological speech and also to detect the type of pathology. This system employs non-invasive, inexpensive and fully automated measures of vocal tract characteristics and excitation information. Mel-frequency cepstral coefficients and linear prediction cepstral coefficients are used as acoustic features. The system uses Gaussian mixture model and hidden Markov model classifiers. Cerebral palsy, dysarthria, hearing impairments, laryngectomy, mental retardation, left side paralysis, quadriparesis, stammering, stroke, tumour in vocal tract are the types of pathologies considered in our experiments. From the experimental results, it is observed that to classify normal and pathological voice hidden Markov model with mel frequency cepstral coefficients with delta and acceleration coefficients is giving 94.44% efficiency. Likewise to identify the type of pathology Gaussian mixture model with mel frequency cepstral coefficients with delta and acceleration coefficients is giving 95.74% efficiency.

@&#INTRODUCTION@&#
The voice represents enormous information concerning the speaker through changes of vocal tone in a variety of social contents. Listeners draw inferences from the voice regarding gender, age, intelligence, regional and socio economic origin, education and occupation. Every voice is unique to the speaker and has a distractive quality. Voice is a multidimensional phenomenon comprised of a number of elements that contribute to overall voice quality and voice effectiveness.As long as particular voice does not deviate substantially from the internal gauge in terms of parameters such as pitch, loudness, quality and duration, it will be considered within the normal range. When a voice is perceived as deviating from the normal range, it may be characterized as being dysphonic. The term dysphonia literally means abnormal/difficult/impaired voice/pathological voice.Nowadays voice disorders are increasing dramatically due to the modern way of life. Most of the voice disorders cause changes in the voice signal. The main methods used by the medical community to evaluate the speech production system and diagnose pathologies are either direct ones which requires direct inspection of vocal folds and cause discomfort to the patient, or subjective ones in which voice quality is evaluated by a trained expert doctor's direct audition [1]. With the rapid development of signal processing techniques vocal signal can be used for the detection of voice disorders.In previous studies, several methods for assessing speech pathologies have been introduced. In [2,3], the detection of voice impairments using long term parameters is demonstrated. For the last few years, new approaches using short term speech have been proposed [4–7]. A wide range of acoustic features has been proposed for pathology detection namely pitch, jitter, shimmer, the harmonics to noise ratio (HNR), the normalized noise energy (NNE) [6] and the cepstrum based features [8]. In the area of automatic detection of voice pathology various classifiers have been proposed such as multi layer perceptron [4,5,8,9], Gaussian mixture model [10,7], hidden Markov model [11], probabilistic neural network [6], learning vector quantization, linear discriminant analysis [12], k-nearest neighborhood classifier [13,14].Most of the existing methods are detecting whether the voice is normal or pathological, but they are not detecting the specific type of pathology. This paper focuses on a robust, rapid and accurate system for automatic detection of normal and pathological speech. Also it focuses on to identity the type of pathology. This system employs non-invasive, inexpensive and fully automated measures of vocal tract characteristics and excitation information. The rest of the paper is organized as follows: the feature extraction methods to extract the features used in this work are described in Section 2. A brief description about the modeling techniques is given in Section 3. The proposed system and the performance measures are given in Sections 4 and 5. In Section 6, the experimental results and the performance of the proposed system are presented. Finally in Section 7 the conclusions of this study are reported.Classically two short-term dominant acoustic estimation techniques of the speech are in use. The first one is the parametric modeling approach developed to match closely the resonant structure of the human vocal tract. It is mainly derived from linear predictive analysis (LPC) and LPC based cepstrum (LPCC). Section 2.2 describes the extraction of LPC features from speech samples.In the second technique the windows of speech signal are parameterized by means of Mel-frequency cepstral coefficients (MFCC). A family of parameters that can be estimated using a nonparametric (fast Fourier transform (FFT) based) approach that allows to model the effects of pathology in both the excitation (vocal folds) and the system (vocal tract). Another reason for using these parameters is because they are also based on a perceptual representation of the frequency corresponding to the human auditory system response. This matches well, with the facts that an experienced speech therapist can often detect the presence of a disorder just by listening to it. Section 2.3 describes the computation of MFCC features from speech samples.To extract the features from the speech signal, the signal must be preprocessed and divided into successive windows or analysis frames [15]. So the following steps are performed before extracting the features.•Preemphasis: The digitized speech signal at time n, s(n), is put through a low order digital system to spectrally flatten the signal and to make it less susceptible to finite precision effects later in the signal processing. The output of the preemphasis network,sˆ(n)is related to the input s(n) by the difference equation(1)sˆ(n)=s(n)−αs(n−1)The most common value for the preemphasis coefficient α is around 0.95.Frame blocking: Speech analysis usually assumes that the signal properties change relatively slowly with time. This allows examination of a short time window of speech to extract parameters presumed to remain fixed for the duration of the window. Thus to model dynamic parameters, we must divide the signal into successive windows or analysis frames, so that the parameters can be calculated often enough to follow the relevant changes. In this step the preemphasized speech signal,sˆ(n)is blocked into frames of N samples, with adjacent frames being separated by M samples. If we denote the lth frame speech by xl(n), and there are L frames within the entire speech signal, then(2)xl(n)=sˆ(Ml+n),n=0,1,…,N−1,l=0,1,…,L−1Windowing: The next step in the processing is to window each individual frame so as to minimize the signal discontinuities at the beginning and end of the frame. The window must be selected to taper the signal to zero at the beginning and end of each frame. If we define the window asw(n), 0≤n≤N−1, then the result of windowing the signal is(3)x˜l(n)=xl(n)w(n),0≤n≤N−1The Hamming window is used in this work, which has the form(4)w(n)=0.54−0.46cos2πnN−1,0≤n≤N−1A given speech sample at time n, s(n), can be approximated as a linear combination of the past p speech samples, such that(5)s(n)≈a1s(n−1)+a2s(n−2)+a3s(n−3)+⋯+aps(n−p)where the coefficients a1, a2, …, apare assumed constants over the analysis frame. The steps for computing LPC is illustrated in Fig. 1. After obtaining the autocorrelation of a windowed frame, the linear prediction coefficients are obtained using Levinson–Durbin recursive algorithm. This is known as LPC analysis. The cepstral coefficients are the coefficients of the Fourier transform representation of the logarithmic magnitude spectrum. Cepstral coefficients of a sequence x are the coefficients of the inverse discrete Fourier transform (IDFT) of the log magnitude short-time spectrum(6)IDFT(log(|DFT(x)|))If x is LPC, the cepstral coefficients are known as linear prediction cepstral coefficients (LPCC). The LPC parameter conversion block in Fig. 1 converts LPC to LPCC.The procedure of MFCC computation is shown in Fig. 2and described as follows:After preprocessing, the spectral coefficients of the windowed frames are computed using fast Fourier transform. The results of the FFT will be information about the amount of energy at each frequency band. Human hearing is not equally sensitive at all frequency bands. It is less sensitive at higher frequencies roughly above 1000Hz. MFCC is extracted using this principle. The mapping of frequency in mel scale is linear below 1000Hz and logarithmic above 1000Hz. So the band edges and center frequencies of the filters are linear for low frequency and logarithmically increase with increasing frequency as shown in Fig. 3. We call these filters as mel-scale filters and collectively a mel-scale filter bank. As can be seen, the filters used are triangular and they are equally spaced along the mel-scale which is defined by(7)Mel(f)=2595log101+f700Each short term Fourier transform (STFT) magnitude coefficient is multiplied by the corresponding filter gain and the results are accumulated. Then DCT is applied to the log of the mel spectral coefficients to obtain the mel frequency cepstral coefficients.The hidden Markov model (HMM) consists of two stage stochastic processes: one is an unobservable Markov chain with a finite number of states, an initial state probability distribution and a state transition probability matrix, and the other is a set of probability density functions associated with each state. The probability density function can be either discrete (discrete HMM) or continuous (continuous HMM). The continuous HMM is characterized by the following [16]:•Nx, the number of states in the model. The individual states are denoted ass={s1,s2,…,sNx}, and the state at time t as qt.The state-transition probability distribution A={aij}, whereaij=P[qt+1=sj|qt=si],1≤i,j≤Nxdefines the probability of transition from state sito sjat time t with the constraint∑j=1Nxaij=1,1≤i≤NxThe observation probability density function in state i, B={bi(O)}, wherebi(O)=∑k=1MCikp(O,μik,Σik),1≤i≤Nxwhere Cikis the mixture coefficient for kth mixture component in statei.Mis the number of components in a Gaussian mixture model, and p(O, μik, Σik) is a Gaussian probability density function with mean (μik) and covariance (Σik).The initial state distribution π={πi}, whereπi=P[q1=si],1≤i≤NxGiven appropriate values ofNx,M,A,B, and π, the HMM can be used as both a generator of observations, and as a model of how a given observation sequence O=(o1o2…oT) was generated by an appropriate HMM, where T is the length of the observation sequence. The compact notation λ=(A, B, π) is used to indicate the complete parameter set of the model. A 5 state (Nx=3) left-right HMM with two mixtures (M=2) in each state has been used for modeling each language feature vectors. In the ergodic HMM any state can be reached from any other state in a single step, i.e., aij>0 for all i, j.The basis for using Gaussian mixture model (GMM) is that the distribution of feature vectors extracted from an individual's speech data can be modeled by a mixture of Gaussian densities. For a Nfdimensional feature vector x, the mixture density function for class s is defined asp(x/λs)=∑i=1Mαisfis(x)The mixture density function is a weighted linear combination ofMcomponent unimodal Gaussian densitiesfis(·). Each Gaussian density functionfis(·)is parameterized by the mean vectorμisand the covariance matrixΣisusingfis(x)=1(2π)Nf∣Σis∣exp(−12(x−μis)T(Σis)−1(x−μis))where(Σis)−1and|Σis|denote the inverse and determinant of the covariance matrixΣis, respectively. The mixture weights (α1s,2s,...,αMs)satisfy the constraint∑i=1Mαis=1. Collectively, the parameters of the class s model λsare denoted asλs={αis,μis,Σis},i=1,2,…,M. The number of mixture components is chosen empirically for a given data set. The parameters of GMM are estimated using the iterative expectation-maximization (EM) algorithm [17].In this work, a two level system has been proposed for detecting the type of voice pathology. In the first level, the system identifies whether the given voice is normal or not. For normal voice no further classification is necessary. If it is not normal, it is recognized as pathological voice and then it is fed to the second level which aims at identifying the particular type of pathology. Fig. 4illustrates the steps involved in the proposed system. The acoustic features like MFCC and LPC are extracted from the given speech signals as described in Section 2. Two models corresponding to normal and pathological voices are created from the training samples. These models are used to identify whether the given voice is normal or not. Likewise ten models corresponding to each type of pathology (cerebral palsy, dysarthria, hearing impairments, laryngectomy, mental retardation, left side paralysis, quadriparesis, stammering, stroke, tumour in vocal tract) are created. These models are used to identify the type of pathology if the given voice is classified as pathological voice in the first level. GMM and HMM are the modeling techniques used in this work as described in Section 3.In order to test the performance of the voice pathology detector, and to allow comparisons, several measures are considered [4,6]. Sensitivity, specificity and efficiency are the measures used in this work.

@&#CONCLUSIONS@&#
