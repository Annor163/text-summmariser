@&#MAIN-TITLE@&#
State assignment for area minimization of sequential circuits based on cuckoo search optimization

@&#HIGHLIGHTS@&#
A major optimization problem in synthesis of sequential circuits is State Assignment (SA).Cuckoo search optimization (CSO) algorithm is employed for solving the SA problem.CSO targets area minimization of synthesized sequential circuits.CSO results outperform deterministic and non-deterministic heuristic optimization methods.

@&#KEYPHRASES@&#
Cuckoo search,State Assignment,Heuristics,Sequential circuit,Area minimization,Finite state machines,

@&#ABSTRACT@&#
A major optimization problem in the synthesis of sequential circuits is State Assignment or State Encoding in Finite State Machines (FSMs). The state assignment of an FSM determines the complexity of its combinational circuit and thus area, delay, testability and power dissipation. Since optimal state assignment is an NP-hard problem and existing deterministic algorithms produce solutions far from best known solutions, we resort to the use of non-deterministic iterative optimization heuristics. This paper proposes the use of cuckoo search optimization (CSO) algorithm for solving the state assignment problem (SAP) of FSMs with the aim of minimizing area of the resulting sequential circuit. Results obtained from the CSO algorithm are compared with those obtained from binary particle swarm optimization (BPSO) algorithm, genetic algorithm (GA), and the well-known deterministic methods of NOVA and JEDI. The results indicate that CSO outperforms deterministic methods as well as other non-deterministic heuristic optimization methods.

@&#INTRODUCTION@&#
As the density and size of integrated circuits (ICs) keep increasing rapidly, area and power dissipation have become and are still a significant concern in Very Large Scale Integration (VLSI) designs. VLSI systems by nature are mostly sequential circuits and are modeled as finite state machines (FSMs). In FSMs, the behavior of sequential circuits is characterized by using symbolic names to represent states. State assignment is the mapping of the state names of an FSM to a set of binary codes. This mapping has a significant impact on the circuit area and power dissipation [1]. An example of an FSM is given in Table 1, which has 4 states, one input and one output. To understand the example in Table 1, consider the case when Present State=S0. If input X=0, then Next State=S0 and Output=1, but if X=1, then Next State=S2 and Output=0.Since there are 4 states in the FSM, a 2-bit code is sufficient for encoding each state. Table 2shows two typical state assignments for the FSM labeled as “Ass. 1” and “Ass. 2”. The number of literals of the Boolean equations that implement the FSM as a multi-level circuit with “Ass. 1” is 6 literals while that with “Ass. 2” is 14 literals. The number of literals is a cost measure that correlates with the number of transistors in the circuit and hence its area.The multi-level circuits resulting from synthesizing the FSM example using “Ass. 1” and “Ass. 2” are shown in Fig. 1. This example demonstrates the significant impact of state assignment on the area of a synthesized sequential circuit.Formally, the state-assignment problem of an FSM is one that maps state symbols to binary codes using the mapping functionf:S→Bn, where n is the code length,n⩾⌈log2|S|⌉,Bnis an n-dimensional Boolean hypercube and|S|is the number of states. To encode S states, using k bits, the number of possible state-assignment combinations is given in Eq. (1).(1)(2k)!(2k-|S|)!As an illustration, if we have an FSM with 10 states, then each state will require 4 bits for distinctive encoding. As a result, the number of possible state assignments for these 10 states as obtained from Eq. (1) is 29,059,430,400. Hence, exhausting all the possible combinations in order to find the state assignment that optimizes a certain objective will require a very huge amount of time. Clearly, SAP is computationally hard [2].Among the best-known methods that were employed for state assignments is that of partitions and decomposition [3]. However, not all state machines have useful closed partitions and can be minimized using these techniques. Implicant merging, code covering and disjunctive coding [4,5] are previous deterministic methods employed for area minimization of two-level combinational circuit implementations of FSMs. These techniques work well for certain FSMs and produce good results but for others they may not apply effectively. This is because these techniques rely mainly on symbolic minimization of state tables and not all FSMs can be minimized symbolically to lead to the best state assignment solutions.The objective of state assignment targeting multi-level circuit implementation is that of finding state assignments that result in common expressions and maximum literal savings. Devadas et al. suggested two algorithms [6]. One of these algorithms is fan-in oriented and looks for state pairs with higher numbers of incoming transitions from the same states. Subsequently, higher weights are assigned to those pairs of states to be given close codes in terms of Hamming distance. The Hamming distance between the codes of two states is the number of positions of non-identical bits between the codes of the two states. The aim is to maximize the frequency of common cubes in the encoded next-state functions. The second algorithm is fan-out oriented and assigns close codes to state pairs that have similar next-state transitions. A similar deterministic method is JEDI [7], which calculates the encoding affinity cost as a function of how often a pair of states is represented in the next-state and output functions. Wang et al. [8] attempted to solve the problem of state assignment in order to minimize both area and power dissipation for FSMs. They suggested a novel matching-based state assignment algorithm that takes into account area and state transitions simultaneously. The experimental results they obtained show that they outperform NOVA [4] in both area and power.Due to limitations of existing deterministic algorithms and the intractable nature of the state-assignment problem [9], a lot of work has been done in the area of employing non-deterministic optimization heuristic methods. Some of these methods have been used to solve many combinatorial optimization problems successfully. Examples of these heuristics include simulated annealing, tabu search, particle swarm optimization, cuckoo search and genetic algorithms [2]. Several non-deterministic optimization heuristic methods have been applied to solve SAP. Chaudhury et al. [10] used a genetic algorithm (GA) based state encoding to solve SAP targeting area and power optimization. A unified approach is used targeting static and dynamic power along with area trade-off. Other efforts in the use the GAs to solve SAP include the work by Almaini et al. [11,12], El-Maleh et al. [13], and others [14,15]. Other heuristic optimization techniques for solving SAP include the use of simulated annealing (SA) [16], simulated evolution (SE) [17] and binary particle swarm optimization (BPSO) [18].This paper proposes the application of a recent heuristic algorithm, the cuckoo search optimization (CSO) algorithm [19,20] integrated with Lévy walk [21], which enables the algorithm to make random walks in the design space for the state-assignment problem (SAP) targeting area minimization. The CSO algorithm has been applied successfully to many computationally difficult problems [22,23]. The main advantage of the CSO algorithm is its simplicity when it comes to implementation as it involves the tuning of few parameters [19].The rest of the paper is organized as follows. In Section 2 the proposed algorithm is presented. In Section 3 we provide an illustrative example of running the CSO algorithm on a typical benchmark circuit. Subsequently, in Section 4 the experimental results are presented. Finally, Section 5 concludes the paper.Yang et al. [19] developed a new meta-heuristic optimization algorithm called cuckoo search (CS). Cuckoos are fascinating birds due to their reproduction strategy. Cuckoos lay their eggs in communal nests and may remove others’ eggs to increase the hatching probability of their own eggs. They are often very specialized in laying eggs that mimic the color and pattern of that of their hosts. This reduces the probability that their eggs will be identified by the host and thus get discarded. As a result, this increases their reproductivity. They often choose a nest where the host bird has just laid its own eggs. In general, the cuckoo’s eggs hatch slightly earlier than their hosts’ eggs. Once the first cuckoo chick is hatched, it blindly propels other eggs out of the nest in order to increase the share of food it gets from the host bird.This section briefly discuses the modified cuckoo search optimization (CSO) algorithm [20] for solving the state-assignment problem (SAP) of sequential circuits.1The terms egg and nest are used interchangeably because each of the nests contains a single solution termed egg.1The modification of the cuckoo search algorithm in [20] resulted from the inadequacy of the original cuckoo search algorithm developed by Yang et al. [19] to have a faster convergence rate. This modified version presented two improvements in order to make the cuckoo search have a wider application but at the same time not losing the attractive features of the original method.Algorithm 1CSO algorithm1:Pa←0.75,ψ←1.62,MAXiter←3502 : Initialize the Population3 : Rank the entire population according to cost4 : forG=1toMAXiterdo5 : partition the population into top and bottom nests6:for allXiin bottom nests do7 : use Lévy flight to create a new nestXkfromXi8: replaceXiwithXk9:end for10 : Rank the entire population again according to cost11 :for allXisuch thatXiis in top nests do12 : Select another random top nestXj13:if (Xi=Xj)then14 :perform Lévy flight fromXito create a new nestXk15 :Select a random nestXl16:if (Cost(Xk)<Cost(Xl)) then17 :replaceXlwithXk18:end if19:else20 :Move a distancedx=|Xi-Xj|/ψfromXito create a new nestXk21 :validateXk22 :Select a random nestXl23:if (Cost(Xk)<Cost(Xl)) then24 :replaceXlwithXk25:end if26:end if27:end for28 : Rank the nests according to their costs29: end for30 : Save the best achieved state assignment and its costFor solving the SA problem, the CSO algorithm, shown in Algorithm 1, starts by setting some essential variables such as the size of the population, percentage of nests to be abandonedPa, Maximum iteration MAXiter, golden ratio (ψ) (a constant number approximately=1.62 [24]). The population is then initialized with random state assignment solutions. The entire generated population is then ranked according to the cost of each nest. The cost used is the literal count which is obtained by the sequential interactive synthesis (SIS) tool [25]. Low literal count implies low cost and thus less area for the resulting sequential circuit. After the population is ranked, a procedure is repeated for a number of times up to the MAXiter value.This procedure commences by partitioning the population into top and bottom nests. Then for each of the bottom nests (nests to be abandoned), we generate a Lévy flight from the particular nest and generate a new nest to replace the existing nest. The value of the Lévy flight function determines the number of code-pair swaps to be made. A code-pair swap picks randomly two of the available codes and swaps their positions. For example, if code 000 is assigned to state S1 and code 111 is assigned to state S2, and the two codes 000 and 111 are picked to swap, then the code for S1 becomes 111 and the code of S2 becomes 000. Similarly, if code 000 is assigned to state S1 and code 111 is unassigned and the two codes are swapped, the code for S1 becomes 111 and the code 000 becomes unassigned. In essence, all the existing bottom nests are replaced by fresh nests by performing Lévy flight from each of the bottom nests.In contrast, for each of the top nests,Xi, we select another random nest,Xj, from the top nests. If the second randomly chosen nestXjis the same as the present top nest, then Lévy flight is conducted fromXito generate a new nestXk. Furthermore, another nest,Xl, is then selected randomly from the entire population. If the cost ofXkis less than that ofXl, then the nestXlis replaced withXk.On the other hand, if the second nest selected from the top nests,Xj, is not the same as the first selected nest,Xi, then we determinedx(dxis found by taking the Hamming distance betweenXiandXjand dividing the result by the golden ratio which is approximately=1.62 [24]). Then, a new nestXkis generated fromXiby replacingdxbits fromXiwith their corresponding bits fromXj. The bits replaced inXiare the firstdxnon-identical bits betweenXiandXj. The new generated solution,Xk, needs to be validated to avoid the assignment of the same code to two or more states. If any duplicate code is found then it is replaced with one of the unassigned codes. Minimum Hamming distance criterion is used to pick a code from a set of unassigned codes to replace a duplicate code. Subsequently, we select a random nest,Xl, from the entire population and compare the cost ofXlwithXk. IfXkhas a lower cost thanXl, then it replaces it.Finally, the nests are ranked according to their cost. The algorithm then repeats the larger loop until the maximum iteration number is reached. Since the entire bottom nests are replaced at the beginning of each iteration via Lévy flights, the average cost is bound to rise and fall rather than improve steadily. This is similar to hill climbing in elitist algorithms where the best solution is always retained while non-determinism (via Lèvy flights) guides the introduction of other solutions.The CSO algorithm has the advantage that it has few parameters to tune, namely the percentage of nests to be abandoned (Pa), the golden ratio (ψ) and the function used to compute the Lévy flight. Suggestions for empirical values for the golden ratio (ψ) and the function used to compute the Lévy flight are available in the literature [19,20]. In essence, CSO has onlyPato tune. This is in contrast to other evolutionary algorithms that involve more parameters to tune such as the genetic algorithm which has at least four parameters to tune [2].Numerous findings have revealed that characteristics of Lévy flight are being demonstrated by the flight behavior of many insects and animals. Contemporary research by Reynolds and Frye have confirmed that fruit flies explore their landscape using a series of straight flight paths disrupted by a sudden 90° turn, thus leading to a Lévy-flight-style irregular scale free search pattern. Recent application of such behavior in optimization and optimal search have produced good results [26,27]. The random walk around the design space is essentially provided by the Lévy flight with the random step length drawn from a Lévy distribution. Fig. 2shows a typical plot of the Lévy flight. In our work, the Lévy flight is performed by swapping a number of code pairs according to the random step length generated.The number of code pairs to swap, k, called, the Lévy flight step length, is computed by the following equation [28]:(2)k=(1-u)-1/αwhere u is a uniform random variable in the range [0,1] andα=i1/5, where i is the iteration number.In this section, the CSO algorithm is demonstrated with an illustrative example. The example chosen is the dk14 circuit, which is one of the MCNC/LGSynth [29] benchmark circuits. The dk14 circuit has 7 states, 3 inputs and 5 outputs. We optimize this circuit using the proposed CSO algorithm and show how the cost (literal count) converges to the near optimal with iterations. Since the circuit has 7 sates, we need a minimum of 3 bits to encode each of the states uniquely.In this illustrative example, we set the population size to 10, which is generated initially randomly, and the percentage of nests to abandon as 70%. The population is then ranked according to cost with the nest with minimum cost at the top, as shown in Fig. 3.Iteration 1: We begin the first iteration by dividing the population into top and bottom nests as shown by the shaded and unshaded rows in Fig. 3, respectively. Then, perturbations are performed on the bottom part of the population by using Lévy flights. These newly generated nests are made to replace the old ones. For example, for the first bottom nest,N4, the Lévy flight step length generated is 1. SoN4changes from {011,110,100,111,010, 101,000} to {011,100,110,111,010,101,000}, which has a cost of 151. It can be seen that the codes of S2 and S3 have swapped positions. Similarly, Lévy flight step length is generated for each of the other nests in the bottom nests, and perturbations are carried out accordingly. Consequently, all of the bottom nests are replaced with the newly generated ones. The resulting new generated bottom nests are as shown in Fig. 4.Next, the newly generated bottom nests are merged with the top nests, and the entire population is ranked again as shown in Fig. 5. Then we proceed to top nests perturbation. For the first top nest N1: {101,001,111,100,011,000,010}, we pick another random top nest. In this case the second random top nest selected is N2: {111,010,101,000,011,001,110}. Since the second nest picked is not the same as the first top nest, we compute the Hamming distance between the two nests (equal to 7) divided by the golden ratio (1.62) [24] to generate the perturbation number 4. Then, we create a new nest,Xk, by replacing 4 bits from N1 with their corresponding 4 bits from N2. The replaced bits in N1 are the first non-identical 4 bits between N1 and N2. The resulting nestXkis {111,010,101,100,011,000,110} with a cost of 127. Next we select a random nest from the entire populationXlwhich is N7: {001,011,110,000,111,101,010} whose cost is 143. Since the cost ofXkis lower than that ofXl,Xlis replaced withXk.A similar procedure is carried out for the second and third top nests. Finally, the population is ranked and the best nest and its resulting cost are reported. The best nest in this case is {101,001,111,100,011,000,010}, and its cost is 114. The ranked population after iteration 1 is shown in Fig. 6.Iteration 2: A similar procedure is repeated in iteration 2 and the final population is as shown in Fig. 7with the best nest being {101,001,111,100,011,000, 010} with a cost of 114.Iteration 20: The same procedure is repeated and at the end of iteration 20 the final ranked population obtained is as shown in Fig. 8. In this case the best nest seen so far after the 20th iteration is {010,011,110,111,001,000,100} with a resulting cost of 101. It can be seen that the algorithm has begun to converge.

@&#CONCLUSIONS@&#
