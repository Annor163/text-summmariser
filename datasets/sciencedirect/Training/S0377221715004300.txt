@&#MAIN-TITLE@&#
A simulation model to enable the optimization of ambulance fleet allocation and base station location for increased patient survival

@&#HIGHLIGHTS@&#
We simulate and optimize within a multi-tiered Emergency Medical Service model.We apply the model using real call data from the London Ambulance Service.Increases in cardiac arrest patient survival are seen without additional resources.An optimized new base station location and resourcing improves patient survival.Optimizing the removal of a base station has low impact on survival probability.

@&#KEYPHRASES@&#
Simulation,Optimization,Emergency medical service,

@&#ABSTRACT@&#
An effective emergency medical service (EMS) is a critical part of any health care system. This paper presents the optimization of EMS vehicle fleet allocation and base station location through the use of a genetic algorithm (GA) with an integrated EMS simulation model. Two tiers to the EMS model realized the different demands on two vehicle classes; ambulances and rapid response cars. Multiple patient classes were modelled and survival functions used to differentiate the required levels of service. The objective was maximization of the overall expected survival probability across patient classes. Applications of the model were undertaken using real call data from the London Ambulance Service. The simulation model was shown to effectively emulate real-life performance. Optimization of the existing resource plan resulted in significant improvements in survival probability. Optimizing a selection of 1 hour periods in the plan, without introducing additional resources, resulted in a notable increase in the number of cardiac arrest patients surviving per year. The introduction of an additional base station further improved survival when its location and resourcing were optimized for key periods of service. Also, the removal of a base station from the system was found to have minimal impact on survival probability when the selected station and resourcing were optimized simultaneously.

@&#INTRODUCTION@&#
An effective emergency medical service (EMS) is a critical part of any health care system. One key factor in the performance of an EMS is the speed at which emergency vehicles can respond to incidents. It is vital that at all times emergency vehicles are located so as to ensure adequate coverage and rapid response times (Brotcorne, Laporte, & Semet, 2003). The optimum distribution of emergency vehicles depends on the distribution of demand.There is a significant body of literature on the effective positioning of EMS facilities and a wide variety of models have been developed to solve the problem (Brotcorne et al., 2003; Goldberg, 2004; Li, Zhao, Zhu, & Wyatt, 2011; Marianov & ReVelle, 1995; ReVelle, 1989). Although different models are used, the overarching goal of any such model is to determine the distribution of emergency facilities and resources that best serves a given demand.Much of the literature on EMS facility location uses models derived from the principle of set covering (Farahani, Asgari, Heidari, Hosseininia, & Goh, 2012; Gendreau, Laporte, & Semet, 2006; Li et al., 2011; ReVelle & Eiselt, 2005). Such models aim to locate EMS resources so as to cover a set of demand nodes. At its simplest, a node is covered if an EMS resource is within a predetermined distance or response time. Early covering models ignored the stochastic nature of EMS systems and dealt with the static and deterministic location problem (Gendreau, Laporte, & Semet, 1997; Toregas, Swain, ReVelle, & Bergman, 1971). Probabilistic models have been developed that use queuing theory to account for the fact that ambulances act as servers in a queuing system and are sometimes unavailable (Bianchi & Church, 1988; Galvao & Morabito, 2008; Marianov & ReVelle, 1996).Increases in computing power and the advent of metaheuristics have facilitated the development of more complex models to solve the EMS facility location problem. For example, Aytug and Saydam (2002) solved the large-scale, maximum expected coverage location problem (MEXCLP) using two forms of genetic algorithm, one being coupled with a local search algorithm, which were seen to outperform an integer programming approach and Daskin’s heuristic (Daskin, 1983) in terms of locating an optimal or near-optimal solution in a reasonable amount of time. Also, Saydam and Aytug (2003) solved the MEXCLP by combining a genetic algorithm with Jarvis’ and Larson’s hypercube model (Jarvis, 1985; Larson, 1975), the latter of which had previously only been used as a comparison tool (Chiyoshi, Galvao, & Morabito, 2003; Saydam, Repede, & Burwell, 1994). Similarly, a number of other approaches have combined a hypercube queuing model with a genetic algorithm (Geroliminis, Kepaptsoglou, & Karlaftis, 2011; Iannoni, Morabito, & Saydam, 2008; 2009; Toro-Diaz, Mayorga, Chanta, & McLay, 2013), simulated annealing (Galvao, Chiyoshi, & Morabito, 2005) and Tabu search (Gendreau, Laporte, & Semet, 2001; Rajagopalan, Saydam, & Xiao, 2008; Toro-Diaz, Mayorga, McLay, Rajagopalan, & Saydam, 2014) in order to optimize the location and allocation planning of EMS systems. Also, some metaheuristics have been used alone such as a genetic algorithm to optimize the location of ambulances in order to contribute to higher survival rates from life-threatening medical events (Sasaki, Comber, Suzuki, & Brunsdon, 2010) and simulated annealing to solve the large scale, dynamic maximal covering location problem (MCLP) (Zarandi, Davari, & Sisakht, 2013). Some research has focused on the stochastic and uncertain nature of the location problem of EMS vehicles. For example, Repede and Bernardo (1994) introduced TIMEXCLP, the first covering model with time variation to account for the stochastic nature of variables such as travel and service times when evaluating alternative ambulance locations. On a similar theme, Ingolfsson, Budge, and Erkut (2008) included uncertainty in relation to delays and travel times when aiming to maximize expected coverage by minimizing the allocation of the number of ambulances to stations in order to provide a specified level of service.Recent developments in the field of EMS system research include a number of areas such as the use of approximate dynamic programming (Maxwell, Restrepo, Henderson, & Topaloglu, 2010; Schmid, 2012) and stochastic programming (Beraldi & Bruni, 2009; Naoum-Sawaya & Elhedhli, 2013) to solve the ambulance redeployment and/or location problem. Another important development has been the use of patient survivability as a performance metric instead of the concept of ‘cover’. Erkut, Ingolfsson, and Erdogan (2008) recognized the need for a new performance measure and introduced the concept of survival functions; non-linear functions that model the relationship between response time and survival rate. They incorporated a survival function, derived from medical research into cardiac arrests, within a number of existing covering models. It was found that the existing covering models produced sub-optimal EMS facility distributions when evaluated using the more realistic performance measure. Indeed, in recognizing the importance of performance measures being more closely related to patient outcomes, McLay and Mayorga (2010); 2011) investigated the influence of maximizing coverage for different response time thresholds on patient survival rates. Acknowledging that the findings were specific to the rural/urban geographic region considered, locating ambulances to maximize minimum response time thresholds was found to simultaneously maximize patient survival. Also, Bandara, Mayorga, and McLay (2012) focused on patient survivability and its maximization via optimizing the dispatch of paramedic units to emergency calls depending on their severity. It was found that consideration of call severity, or urgency, would lead to an increase in patients’ mean survival probability.One limitation of the work presented by Erkut et al. (2008) is the modelling of only one incident type. Knight, Harper, and Smith (2012) addressed this limitation by incorporating a cardiac arrest survival function with step functions representing response time targets for other incident types. The heterogeneous objective function was a sum of the individual survival functions weighted by their relative priorities; effectively a multi-objective optimization. This objective function was incorporated into a simple covering model.Although covering models are popular, it is accepted in the literature that EMS simulations are more accurate (Fitzsimmons & Srikar, 1982; Goldberg et al., 1990). In fact, simulation is almost universally used in the literature to validate the selections of optimization models (Henderson & Mason, 2004). As well as increased realism, simulation produces a wealth of performance data, such as response time distributions and ambulance utilization statistics, which cannot be acquired using a covering model.Despite recent advances in the field there are areas for further development. This paper presents work to amalgamate the recent developments in performance metrics with an accurate, simulation based model of a complex EMS system. The aim of this work is to provide useful recommendations on vehicle resourcing and ambulance base station siting from a planning perspective. The novel areas of this work are:•The integration of heterogeneous survival functions with an EMS simulation capable of utilizing real call data.A method for the modelling of time-variant travel times in a complex network. The incorporation of vehicle routing avoids the unsound, but common assumption that vehicles respond from their base stations.A multi-tiered EMS model recognizing the different demands on two vehicle classes; ambulances and rapid response cars.Calibration and validation of the simulation model as applied to the London EMS system.An application case study incorporating one million calls across the entire London EMS region (2400 kilometre2), demonstrating the significant improvements in patient survival achievable with optimized resource plans.Simultaneous optimization of base station location and the number and type of EMS vehicles located at each station (vehicle allocation). Further, the impact of introducing a new station to the London system is investigated; recommendations are made on the optimum location for the new station and how it should be resourced.The remainder of this paper is structured as follows. In Section 2, details are given of an EMS simulation model. Next, Section 3 presents the optimization heuristic and objective function used in conjunction with the simulation model. In Section 4, the results of a number of cases considered based on real incident call data from the London Ambulance Service are presented and discussed. Finally, concluding remarks and possible areas for further work are given in Section 5.An EMS simulation model was required in order to evaluate proposed vehicle allocations, i.e. the number and type of EMS vehicles located at each base station. Simulation was chosen over other modelling techniques due to the increased realism and accuracy it affords (Henderson & Mason, 2004; Yue, Marla, & Krishnan, 2012). Simulation gains a further advantage through the ability to directly utilize real call data (trace-driven), avoiding the simplifications required to model demand. Collating such data used to be an issue, however the majority of modern EMS providers utilize computer-aided dispatch (CAD) systems that can provide data for use in data-driven simulations. The use of real data also captures the complex, time-dependent variation in demand and resourcing, something omitted by the majority of studies.For the purpose of the study reported in this paper, the London Ambulance Service (LAS) provided data covering all emergency calls between 1st November 2011 and 31st October 2012; almost one million calls, see Fig. 1for the geographic distribution of these calls. For each call the data contained call arrival time, incident type (initial diagnosis), location, dispatch time, number of resources dispatched, time spent at the scene, destination of patient transport (if any), time travelling to hospital, and time spent handing over the patient to hospital staff. The originating location of dispatched EMS vehicles was not included in this data. Wherever possible this data was used directly in the simulation instead of modelling, helping to minimize assumptions. Modelling was employed in cases where the required data was not available or decisions and processes depended on vehicle allocation. Fig. 2shows the EMS vehicle dispatch and service process.The simulation model was written using C++ rather than bespoke simulation software as it afforded a superior level of control for modelling such unique processes. Further, execution speed was also a primary concern. Code was designed to be as generic as possible, with minor alterations the simulation model could be applied to any large EMS system.The simulator accepts the following inputs:•An allocation of ambulances (A) and rapid response cars (R) to base stations.A period of interest (⊤). Calls that arrive within the time period ⊤ are loaded from a data file.The trace-driven simulator processes emergency calls in accordance with a first-come first-served order. Waiting calls are stored in a global system queue and only assigned to a specific station and vehicle at the point of dispatch; the logic is described in Algorithm 1. Four types of simulation event are processed:•New call arrival (lines 8–15). The new call (c) is assigned the required number of vehicles according to the dispatch policy. If not all of the required vehicles are available then as many as possible are dispatched and further vehicles are sent once they become available. In this study a simple myopic dispatch policy is employed, where the nearest available vehicles (shortest estimated travel times) are assigned. The nearest available vehicles may include one or more vehicles in the process of returning to base following completion of a job, these vehicles would then be re-dispatched from their current simulated location. Discussions with the LAS indicated that this is a reasonable approximation of the real dispatch policy, although an operator may decide to wait for alternative vehicles if the nearest currently available is beyond a threshold distance.The array V(c) contains the vehicles assigned to the call, the number and type of which is specified in the LAS data. If vehicles are assigned (|V(c)| > 0) then they are flagged as busy and a scene departure event is created. The scene departure time is dependent on the call time (t), dispatch delay (td), time taken for the nearest vehicle to reach the scene (tr), and time spent at the scene (tsc). These variables are unique to each call and all but the travel time is extracted from the LAS call data. Travel times are estimated using the travel time model presented in Section 2.1.If no resources are available then the call is added to a first-in first-out queue (Q). Although this is a simple approximation to what is a complex decision for an EMS operator, it was considered a reasonable approximation by LAS personnel. This queue of waiting calls is considered whenever a vehicle finishes servicing another call.Scene departure (lines 16–23). The vehicles assigned to a call are leaving the scene of the incident, tsc seconds after arrival of the first vehicle. If transport is required, as specified in the LAS data, one ambulance departs for hospital and a job completion event is created. At least one ambulance is sent to every call requiring transport and the first ambulance on-scene is assigned transport duties. The job completion time is dependent on the travel time to hospital (th), and the time spent handing over the patient to hospital staff (tho). Both of these variables are extracted directly from the LAS call data. All other vehicles are flagged as available and depart for their respective base stations.Job completion (lines 24–27). Service of call c is complete. Any vehicles still assigned to the call are flagged as available and depart for their respective base stations.Vehicle location update (lines 28–31). The locations of travelling vehicles are periodically updated in line with the routing and travel time model presented in Section 2.1. The “real-time” locations of vehicles are used when deciding which vehicles should respond to calls. This is a significant departure from the existing academic literature in which it is assumed that vehicles always respond from their base stations; an assumption even made in relatively complex simulation models (Goldberg et al., 1990; Yue et al., 2012). Discussions with the LAS revealed that such an assumption is flawed for a busy EMS. In London it is not uncommon for vehicles to be away from their bases for several hours at a time.One of the principal components of the simulation model is a method for estimating travel times and routes within the London transport network. Ideally this travel time model would be capable of estimating the distance between any two precise locations, however the size and complexity of the London network make this impractical. In order to simplify the model the simulation space was discretized into a grid; a common approach to demand aggregation (Aytug & Saydam, 2002). It was found that over 99.9 per cent of LAS calls in the one year period considered were bounded by a 53 kilometre by 45 kilometre area approximately centred on the city centre. This area was divided into a 26 by 22 grid to form a discretized simulation space; see Fig. 3. The grid resolution used was a compromise between accuracy and computational efficiency. The locations of all calls, base stations, and hospitals were snapped to the centre of the cell in which they resided. The 0.1 per cent of calls outside these bounds were excluded from the model.In order to effectively model travel times within London it was important to capture the time-dependent nature of the system; something rarely considered in similar studies. The most practical approach was to assume that the routes travelled by vehicles were independent of time but the speed at which vehicles travelled was not. Having time-independent routes allowed distances between nodes to be precomputed, reducing the run-time and complexity of the model. One approach to modelling distances is to use the Euclidean distance between two nodes (Hausner, 1975); this however, does not capture the varying complexity of a road network. One way to capture this complexity is to use geographic information systems (GIS). A tool was developed utilizing the Google Maps Javascript API, which could return the travel distance, along the quickest road route, between any two nodes.The size of the area to be modelled posed a number of challenges. For example, a limit existed on the volume of geocoded data that could be requested from Google; a maximum of 2500 requests per day under a free license. To produce a look-up table of distances for each node pairing in the 572 node grid would require almost 330,000 data requests, which was deemed impractical. Consequently, a number of possible solutions were considered:•A smaller region could be modelled using a sub-set of the LAS call data. This would require a number of assumptions about which calls were answered from within the sub-region.The resolution of the simulation grid could be reduced. A 12 by 12 grid could have been achieved however such a coarse resolution would likely invalidate the model.An assumption could be made about travel routes in order to reduce the volume of GIS data required. Given that the simulation space is discretized into a grid, it could be assumed that a route between two nodes in neighbouring cells is well approximated by a straight path between the two nodes. Thus, the overall travel route could be constructed from the straight paths between neighbouring nodes; see Fig. 4.From these three possible solutions, the route approximation was preferred as it avoided making potentially invalid assumptions about the LAS system. Further, the straight path assumption is not unreasonable when journeys are of a similar length to the distance between grid spaces; confirmed through analysis of the LAS data. This assumption reduced the volume of distance data required by a factor of 72; for each node, only the distance to each of its eight neighbours is required, reducing the number of data requests to 4292. The possible solutions of modelling a smaller region and reducing the resolution of the simulation grid were not considered any further.The accuracy of the route approximation was evaluated in order to quantify potential errors. Almost 2400 typical journeys, of varying length, were extracted from the LAS data and their precise start and end locations were used with Google Maps to determine an accurate travel distance. These precise distances were compared to those approximated by the distance model. As anticipated, the model overestimated travel distances on average and errors increased with length of journey. A correction was built into the model to remove this average overestimation. The factor by which each distance is corrected is dependent on journey length; see Table 1.The time-dependent aspect of the travel time model is the speed at which vehicles travel. For any given time of week it is assumed that all vehicles travel at a constant speed. A higher degree of accuracy could be achieved by considering the variable nature of travel times and the effect of different road types, however this level of detail was considered outside the scope of this study. If derived from real data, the benefit of using an average speed is that the effects and frequency of random perturbations, such as delays due to unusual traffic or road accidents, are incorporated into the model. Durations of journeys with known start and end locations were extracted from timestamps in the LAS data; these journeys corresponded to urgent transport from the scene to hospital. With these travel times, and approximated distances from the calibrated distance model, it was possible to derive vehicle speeds. For each day in the week these speeds were then aggregated and averaged based on time of day; see Fig. 5. When derived from real data, the benefit of using an average speed is that the effects and frequency of random perturbations are incorporated into the model. Whilst using these average speeds does not explicitly model events such as breakdowns and heavy traffic, it does implicitly encompass the impact of these random events on travel times, and their relative probabilities.At the start of simulation all EMS vehicles are idle at their respective base stations, leading to unrealistically short response times until a steady operating state is reached. In order to prevent this affecting the evaluation of vehicle allocations, a steady operating state is created by processing a buffer of calls prior to the period of interest; no statistics are recorded for the calls in this buffer. By gradually incrementing the buffer period, it was found that processing a buffer of 90 minutes of calls or over, prior to the period of interest, produced simulation results that were independent of buffer duration. A buffer of 90 minutes was therefore used for all simulations.Verification and validation of the simulation were vital for model acceptance and confidence in results. The validation approach described in Goldberg et al. (1990) was employed. By working closely with the LAS during model development it was ensured that the model had “face validity” (reasonable to the practitioner), “structural validity” (operated like the system), and “technical validity” (assumptions on the data were not far from reality). “Replicative validity” (predicting the past performance of the system) was achieved through model calibration. The model was used to simulate the existing distribution of EMS vehicles and the resulting survival efficiency compared to that calculated using the LAS data. The average speeds at which vehicles travelled were tuned so as to minimize the disparity between real and simulated response times, effectively replicating the current system. Fig. 6compares actual survival efficiency to results from the calibrated simulation model. Following calibration, the root-mean-square (RMS) error between simulated and actual survival efficiency was 0.61 per cent. The speeds derived from the LAS data were modified by 12 per cent on average.An optimization heuristic was required for the optimization of EMS vehicle fleet allocation and base station location. The use of a GA was selected as they have been shown to robustly find good solutions for this type of facility location-allocation problem (Aytug & Saydam, 2002; Houck, Joines, & Kay, 1996; Saydam & Aytug, 2003). GAs employ a “survival of the fittest” strategy to iteratively improve the performance of a population of solutions (Holland, 1975).A key aspect of any GA is the effective representation of a solution as an encoded string. Careful design of this representation guarantees feasible solutions, removing the need for continuous feasibility checks. In the optimization heuristic implemented in this study, the representation used was:|{g1,g2,…,g2n−1,g2n}{g2n+1}{g2n+2,…,g2n+1+m}|where each gene (g) is a real number between 0 and 1. The first 2n genes encode the coordinates of n base stations with unfixed locations; n can be varied between 0 and N, where N is the total number of base stations. The next gene,g2n+1,defines the ratio of ambulances to rapid response cars; this can be included in the optimization or fixed to represent existing resource levels. The final m genes encode the allocation of m vehicles to base stations; each gene is decoded to give an index between 1 and N.An illustrative example of the chromosome representation now follows. Consider a simple problem with three emergency medical vehicles and two base stations; Station 0 has an unfixed location and Station 1 is fixed. The solution space has been divided into a 12 by 10 grid and the ratio of ambulances to rapid response cars is unfixed. One chromosome in the population is as follows:|0.74,0.80,0.70,0.25,0.10,0.74|The first two genes encode a grid coordinate for Station 0 of (8,7):Round(0.74×(12−1))=8Round(0.80×(10−1))=7The third gene specifies that of the three vehicles, two are ambulances:Round(0.70×3)=2Finally, the fourth, fifth, and sixth genes specify that Vehicles 0, 1, and 2 are assigned to Stations 0, 0, and 1 respectively:Round(0.25×(2−1))=0Round(0.1×(2−1))=0Round(0.74×(2−1))=1Algorithm 2 describes the GA procedure used in this study; adapted from that presented in Goldberg (1989). The procedure begins with initialization of the population (P) using the complementary initialization method described in Haupt and Haupt (2004). The first half of the population is randomly generated, the second half is then the “mirror image” of the first; i.e. each mirrored gene (gmirrored) is one minus the original gene (1−goriginal). This method goes some way to ensuring reasonable diversity in the initial population. For example, if one of the chromosomes in the first half of the population was randomly generated as:|0.47,0.08,0.72,0.51,0.10,0.67|Then the “mirror” of this in the second half of the population would be:|1−0.47,1−0.08,1−0.72,1−0.51,1−0.10,1−0.67||0.53,0.92,0.28,0.49,0.90,0.33|At each generation, the fitness of every individual is evaluated using the simulation model and the objective function detailed in Section 3.2. Evaluations are independent and can therefore be executed in parallel. The ComputeFitness function utilizes multiple threads, taking advantage of the multiple cores in modern computers. The studies presented in this paper were conducted on a quad-core computer using eight threads.Once the fitness of each individual is known, the next generation can be populated. Individuals are selected and either copied to the next generation or crossed with another individual to produce offspring; the probability of which is set by the crossover rate (rx). A number of different selection procedures were trialled, including cost and rank weighted roulette-wheel selection. The procedure which produced high performing individuals in the shortest time, without premature convergence, was the tournament selection procedure described in Haupt and Haupt (2004); a small subset of the population is randomly picked and the fittest individual within this subset selected. Although likely, it is not guaranteed that the best individuals contribute to the next generation. Ensuring the preservation of a number of elite individuals leads to improved performance (Man, Tang, & Kwong, 1999). The single best individual was preserved in this implementation.Crossover operations combine the genetic information of parents with the aim of producing fitter offspring. The crossover operator used is an adaptation of the heuristic crossover method detailed in Haupt and Haupt (2004), where two parents produce two offspring. There are two stages to the procedure:1.Genes are copied from parent to child and then randomly swapped between offspring. This is known as uniform crossover.Half of the genes in the two children (gchild) are randomly selected and replaced with a blend of the two parent genes (gparent):(1)gchild1=gparent1+β(gparent2−gparent1)(2)gchild2=gparent2+β(gparent1−gparent2)where β is a randomly generated number in the range 0 to 1.1 (inclusive). This crossover operation is effectively a linear interpolation between parent genes, where the point of interpolation is randomly selected by β. By allowing values of β greater than one we allow slight extrapolation of genetic information, helping to maintain genetic diversity. However, this extrapolation can produce infeasible genes, child gene values are therefore fixed between 0 and 1.For example, consider two parent chromosomes copied to two offspring:gchild1=gparent1=|0.13,0.67,0.84,0.33,0.82,0.91|gchild2=gparent2=|0.76,0.97,0.52,0.01,0.18,0.39|Genes 0, 3, and 4 are randomly selected and swapped between offspring (uniform crossover):gchild1=|0.76,0.67,0.84,0.01,0.18,0.91|gchild2=|0.13,0.97,0.52,0.33,0.82,0.39|A β value is randomly generated, genes 2, 3, and 5 randomly selected, and Eqs. (1) and (2) applied:β=1.05gchild1=|0.76,0.67,0.50,0.00,0.18,0.15|gchild2=|0.13,0.97,0.86,0.35,0.82,0.94|Following crossover operations the population is subject to mutation. From the entire population, a number of randomly selected genes are replaced with randomly generated real numbers between 0 and 1. The number of mutated genes is determined by the mutation rate (rm). The fittest chromosome is immune to mutation.It is technically possible that following crossover and mutation operations, multiple chromosomes could translate to the same solution. Given that each problem addressed in this paper typically has in the order of 4 × 1040 possible solutions, the probability of chromosome redundancy was considered negligible.Each iteration the GA is checked for convergence. A number of GA stopping conditions were implemented but the most effective way to ensure convergence was to run the GA for a predetermined number of generations whilst monitoring progress using real-time graphs. Each experiment was replicated 15 times with the genetic algorithm running for an average of 180 generations. Solutions remained static for a minimum of 40 generations before termination of the genetic algorithm; see Fig. 7which shows typical GA convergence.Although a GA is a generally applicable meta-heuristic, the crossover rate, mutation rate, and population size parameters need to be tuned to suit each application. Preliminary experiments were undertaken to determine the optimum settings of these parameters. It was found that a crossover rate of 0.85 and mutation rate of 0.04 quickly produced high performing individuals, without premature convergence. The crossover rate is slightly higher than the norm but not unusually so (Man et al., 1999). The high mutation rate was expected, it encourages adequate exploration of what is an exponentially large and flat solution space (Fitzsimmons & Srikar, 1982); a mutation rate of 0.03 was used for a similar problem in Aytug and Saydam (2002). A population size of 25 was selected as a compromise between performance and computation time.The optimization presented in this study aims to maximize the number of EMS patients that survive cardiac arrests and other life-threatening incidents. Patient survival was first used as a performance metric by Erkut et al. (2008). They used a survival function derived from a medical study that modelled the health of patients after suffering cardiac arrests (Valenzuela, Roe, Cretin, Spaite, & Larsen, 1997). Cardiac arrest incidents were used because response time is crucial to survival and the relationship has been studied extensively. Knight et al. incorporated a similar cardiac arrest survival function with step functions representing response time targets for other incident types (Knight et al., 2012). The heterogeneous survival function was a sum of the individual survival functions weighted by their relative priorities; effectively a multi-objective optimization.The heterogeneous survival function used in this study is one of a number of functions that have been shown to approximate survival probability as a function of time for cardiac patients (Erkut et al., 2008; Knight et al., 2012). This particular survival function was derived using cardiac survival data from the US and logistic regression. The survival probability (s) of two patient classes is modelled; cardiac arrests (sc):(3)sc=11+exp(−0.26+0.139×Tr)and all other life-threatening (category A) calls (sa):(4)sa={1,forTr≤80,forTr>8,where Tris the response time. The objective is maximization of the heterogeneous survival efficiency (ηs):(5)ηs=2∑i=1γsci+∑j=1δsaj2γ+δ,where γ is the number of cardiac arrest calls and δ the number of category A calls. Cardiac arrests are weighted as twice as important as other category A calls. Non-urgent calls (category C) are excluded from the objective function as they are non life-threatening and not included in LAS performance targets.The ambulance fleet allocation and base station location problem is defined as follows. We are given a set of base stationsB={Bn},1≤n≤Nto be populated with a set of EMS vehiclesV={Vm},1≤m≤M. During simulation, vehicles respond to a set of emergency callsC={Ck},1≤k≤K. Each call must be processed by a subset of vehicles Vk⊆V, with each call having an independent time, location, duration, and vehicle requirement. Vehicles can process at most one call at a time.The objective of the problem is to maximize patient survival by finding the optimal allocation of EMS vehicles to base stations and base station locations. Stations can be located at any point within the geographic limits of the model. A derivative of this problem, also addressed by this paper, fixes the location of base stations to emulate the existing EMS system.The LAS follows a resource plan that, for each hour of the week, defines the number of ambulances and rapid response cars allocated to each of their seventy base stations. It was seen as logical to approach optimization in the same way and optimize the planned vehicle allocations for a number of these hour-long periods. Fig. 8shows the volume of calls received by the LAS over a 1 year period, aggregated by time of week. Probable cardiac arrest calls have been separated from other category A calls for the purposes of modelling patient health. Fig. 9outlines the current performance of the LAS as measured by response time targets and survival efficiency.Due to the exponential size of the problem, the resource plan has only been optimized for the eight stations highlighted in red in Fig. 3, selected due to their proximity to an area of high call volume. This is still far from a trivial problem since during periods of high call volume there are up to 45 vehicles allocated to these eight stations, giving 4.36 × 1040 possible combinations. Evaluating each allocation takes 15 seconds, thus a full enumeration would take 2.07 × 1034 years. The approach detailed in this paper is capable of optimizing the entire LAS system, the only limit on problem size is that of solution time.Although only eight stations are being optimized, the entire LAS system was simulated. This meant that vehicles stationed at the central eight stations were free to respond to calls anywhere in the city, and vehicles at stations not being optimized were able to respond to calls within the central zone. This approach captured the cooperative aspects between optimized stations and the remaining stations in the model.The results of key studies investigating the resourcing of these eight base stations are presented and discussed in the remainder of this section.

@&#CONCLUSIONS@&#
This paper presents the optimization of EMS vehicle fleet allocation and base station location through the use of a GA with an integrated EMS simulation model. Novel simulation features and modelling approaches have enabled a level of realism not seen in other EMS models. In a departure from existing academic literature, this model has been applied to a complex, real-life system through the use of LAS call data and geocoded locations. The aim has been to demonstrate how such a model can be used to make useful recommendations to practitioners.A number of studies have demonstrated that significant improvements in patient survival can be achieved with optimized resource plans. In the periods examined, the lives of nine additional cardiac arrest patients could be saved per year without introducing additional resources. Indeed, the LAS indicated real value in the direct link between potential resource plans and patient survival estimates.The LAS weekday resourcing strategy was challenged and the benefits of moving towards a customized plan assessed. Feedback from the LAS identified that the main reasons for non-optimal cover are shift-pattern and rostering requirements. Knowledge of the optimum cover is still useful however and is used to decide when and where to allocate unplanned resources. The impact of introducing a new station to the LAS system was also investigated and recommendations made on the optimum location. The LAS noted that the same techniques would be useful in identifying and evaluating potential standby points.Future LAS strategy could see small base stations consolidated into larger ’super stations’. An investigation was made into the impact of removing a station from the system and a recommendation made on the optimum station to remove. An investigative tool such as this could help inform decisions on future strategy.Further work could consider rostering and shift-pattern requirements and investigate the effects of time dependent vehicle routing and stochastic variation in travel times. The effects of different dispatch methods could also be investigated. One aspect of the LAS system not considered here is how the optimum resource plan might change throughout the year. Accounting for seasonal change in demand may reveal more about how best to achieve optimum performance.