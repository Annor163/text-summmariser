@&#MAIN-TITLE@&#
Fuzzy C-means++: Fuzzy C-means with effective seeding initialization

@&#HIGHLIGHTS@&#
Paper proposes the Fuzzy C-means++ method for improving the effectiveness and speed of the Fuzzy C-means algorithm.This method works by spreading the initial cluster representatives in the data space at initialization.The proposed algorithm achieves superior results on both artificially generated and real world data sets.

@&#KEYPHRASES@&#
Cluster analysis,Fuzzy C-means clustering,Initialization,

@&#ABSTRACT@&#
Fuzzy C-means has been utilized successfully in a wide range of applications, extending the clustering capability of the K-means to datasets that are uncertain, vague and otherwise hard to cluster. This paper introduces the Fuzzy C-means++ algorithm which, by utilizing the seeding mechanism of the K-means++ algorithm, improves the effectiveness and speed of Fuzzy C-means. By careful seeding that disperses the initial cluster centers through the data space, the resulting Fuzzy C-means++ approach samples starting cluster representatives during the initialization phase. The cluster representatives are well spread in the input space, resulting in both faster convergence times and higher quality solutions. Implementations in R of standard Fuzzy C-means and Fuzzy C-means++ are evaluated on various data sets. We investigate the cluster quality and iteration count as we vary the spreading factor on a series of synthetic data sets. We run the algorithm on real world data sets and to account for the non-determinism inherent in these algorithms we record multiple runs while choosing different k parameter values. The results show that the proposed method gives significant improvement in convergence times (the number of iterations) of up to 40 (2.1 on average) times the standard on synthetic datasets and, in general, an associated lower cost function value and Xie–Beni value. A proof sketch of the logarithmically bounded expected cost function value is given.

@&#INTRODUCTION@&#
Partitional cluster analysis is defined as the problem of partitioning a group of objects into clusters that share similar characteristics. The most well-known and widely used partitional clustering algorithms are K-means and Fuzzy C-means (Peizhuang, 1983). When compared across clusters, members of a cluster will be different from members of all other clusters. In order to quantify the similarity/dissimilarity relationship between objects, metric functions, defined on both numeric (Euclidean, Manhattan, Cosine, etc.) or non-numeric (Hamming, Jaro-Winkler, Levenshtein, etc.) data have been used.K-means is one of the oldest clustering algorithms (MacQueen, 1967) and refers both to the clustering task and a specific algorithm to solve it. Given a setXof input data and a parameterk, the task is to choosekrepresentatives ofXsuch that the distances between any points inXand their representative is minimized. The set of representatives discovered after running the K-means algorithm is enough to define a clustering of the points in the data space (theith cluster being the set of all points inXthat are closer torithan any other representative).In contrast to the of K-means where each point belongs to one cluster, in Fuzzy C-means each pointxiin the space belongs torj,∀j∈Rwithμij∈[0,1]defined in the membership matrix (of sizen×kwherenis the number of points in the data space andkis the number of representatives). The use of a membership matrix increases the expressiveness of the clustering analysis, arguably presenting a more comprehensive view of relationships present in the data. Further, the hard assignment of the data points by K-means is inadequate when the points are equally distanced between representatives, in which case they will be randomly assigned to one cluster or another (Doring, Lesot, & Kruse, 2006). Fuzzy C-means mitigates this problem by assigning equal degrees of belonging through the use of the membership matrix. This method computes membership degrees at each iteration, a costly operation that gives a membership degree to a point proportional to its proximity to the cluster representatives. Moreover, the size of this matrix grows as a product of the number of points and clusters, making the algorithm computationally expensive for high values. To reduce the computational burden of the algorithm and at the same time increase its accuracy, an integration of the K-means careful seeding algorithm (Arthur, Arthur, Vassilvitskii, & Vassilvitskii, 2007) into the standard version of Fuzzy C-means is proposed, analyzed and verified in this paper.The reminder of the paper is structured as follows: Section 2 presents work improving the performance of Fuzzy C-means; both the standard and the proposed algorithm are introduced in Section 3, together with a proof that shows the theoretical bounds of the expected cost function; Section 4 presents the datasets and the evaluation procedure used, and compares the proposed scheme with the standard algorithm; Section 5 summarizes findings and considers future work.

@&#CONCLUSIONS@&#
