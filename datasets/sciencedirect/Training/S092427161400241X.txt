@&#MAIN-TITLE@&#
Evaluating the performance of a new classifier – the GP-OAD: A comparison with existing methods for classifying rock type and mineralogy from hyperspectral imagery

@&#HIGHLIGHTS@&#
Gaussian Processes incorporating SAM at core for hyperspectral data classification.Systematic comparison of machine-learning methods under various conditions.Data acquired from different materials, sensors and different illumination.Classification using such independent training and test data sets.The presented method provides a Bayesian framework as basis for data fusion.

@&#KEYPHRASES@&#
Hyperspectral,Absorption feature,Iron minerals,Vertical geology,Illumination conditions,Machine learning,Classification,Remote sensing,

@&#ABSTRACT@&#
In this study, we compare three commonly used methods for hyperspectral image classification, namely Support Vector Machines (SVMs), Gaussian Processes (GPs) and the Spectral Angle Mapper (SAM). We assess their performance in combination with different kernels (i.e. which use distance-based and angle-based metrics). The assessment is done in two experiments, under ideal conditions in the laboratory and, separately, in the field (an operational open pit mine) using natural light. For both experiments independent training and test sets are used. Results show that GPs generally outperform the SVMs, irrespective of the kernel used. Furthermore, angle-based methods, including the Spectral Angle Mapper, outperform GPs and SVMs when using distance-based (i.e. stationary) kernels in the field experiment. A new GP method using an angle-based (i.e. a non-stationary) kernel – the Observation Angle Dependent (OAD) covariance function – outperforms SAM and SVMs in both experiments using only a small number of training spectra. These findings show that distance-based kernels are more affected by changes in illumination between the training and test set than are angular-based methods/kernels. Taken together, this study shows that independent training data can be used for classification of hyperspectral data in the field such as in open pit mines, by using Bayesian machine-learning methods and non-stationary kernels such as GPs and the OAD kernel. This provides a necessary component for automated classifications, such as autonomous mining where many images have to be classified without user interaction.

@&#INTRODUCTION@&#
To characterise rock type or mineralogy, hyperspectral data have been acquired in the laboratory (e.g. Cudahy et al., 2009; Doublier et al., 2010; Huntington et al., 2004), from satellite and airborne platforms (Brown, 2006; Swayze et al., 2009; Goetz, 2009) and from field-based platforms (Kruse et al., 2011; Kurz et al., 2008, 2011; Murphy et al., 2012). Such data are of sufficient spectral resolution to resolve broad crystal field absorptions in the visible and near-infrared (VNIR) as well as narrower absorption features caused by vibrational processes in the short-wave infrared (SWIR, Hunt and Salisbury, 1970; Rencz, 1999). Traditionally, methods to identify materials, including minerals, from hyperspectral data characterise specific absorption features within the spectral curve. Methods operating on the level of individual absorption features – “feature-based methods” – rely on extraction of attributes from these features, e.g. their wavelength position, depth and width (Clark et al., 1990, 2003; Murphy et al., 2014a, b, c; Zaini et al., 2014). Extraction of these attributes may, however, be problematic in cases where absorption features are masked by noise or by other, more dominant, features (e.g. Swayze et al., 2003; Rodger et al., 2012).In recent years, machine-learning methods (often supervised methods) for classification of hyperspectral data (e.g. Support Vector Machines) have received increasing attention (e.g. Bazi and Melgani, 2006; Alajlan et al., 2012; Foody and Mathur, 2004; Plaza et al., 2009 and references therein). Kernel machines such as SVMs have opened up the possibility of using flexible models which are practical to work with (Mountrakis et al., 2011). Machine-learning methods often use all the spectral bands in the dataset, however, methods are also used to reduce the volume of data (e.g. Demarchi et al., 2014). Processing of these large amounts of information is possible by applying convenient mathematical formulations to the data such as the “kernel trick” (Smola and Schölkopf, 2004). Other machine learning methods, e.g. Gaussian Processes (GPs; Rasmussen and Williams, 2006), have been successfully applied to classification of multi- and hyperspectral data and in the selection of spectral bands and retrieval of biophysical properties (e.g. Bazi and Melgani, 2008; Pasolli et al., 2010; Verrelst et al., 2012). Recent studies report a competitive classification performance of GPs compared to SVMs (e.g. Bazi and Melgani, 2010).Many studies using supervised machine-learning methods lack, however, a thorough assessment of the performance of these methods in general terms because they are often limited to (i) simulated data, (ii) using cross-validation to validate the performance of the algorithm and/or (iii) using non-independent training and test sets where the training and test data are often selected from the same population of data. These approaches do not provide a general test of the performance of methods, leading to an overoptimistic assessment of the performance of these methods for data acquired from different scenes or under different environmental conditions. This is because training and test data are often: (i) acquired at the same time of the same target, (ii) under the same physical conditions, (iii) with the same sensor and (iv) using the same sensor parameters (e.g. Jiang et al., 2007; Monteiro et al., 2009; Li et al., 2011). Therefore, applications of methods using such data tend to remove any extraneous factors which are contained within a particular image. This approach works but generally requires specifying training data manually, which may be a difficult and laborious process and which is incompatible with automated tasks of classification. For example, it constrains the use of supervised methods in autonomous operational mining where many images of different surfaces need to be classified using data acquired from airborne and field-based platforms. The use of an independent spectral library or training set is therefore necessary to enable methods to be applied consistently and automatically across imagery acquired from different targets. Given these requirements, there is a need to compare methods for classification of hyperspectral data when training data and test data come from different (i.e. independent) populations of data. Only then can we make statements about the general performance of methods.Few studies have evaluated the performance of supervised machine-learning methods using independent training and test sets (but see Nidamanuri and Zbell, 2011a, b). Because SVMs and GPs are increasingly being used in remote sensing applications and research, a comparison of these methods under more rigorous experimental conditions is timely. This study differs from previous studies by providing a rigorous test of methods by using independent training and test data, without the use of cross-validation. Independent in the context means that training and test data are not derived from the same data set or image and are not acquired by the same sensor. Training and test data are acquired using different sources of illumination (artificial vs natural) and different types of sensors (non-imaging and imaging spectrometers). In this study, a new method of classification of hyperspectral data – the GP-OAD (Schneider et al., 2010) – is compared against the Radial Basis Function (RBF) kernel, SVMs and the Spectral Angle Mapper (SAM, Kruse et al., 1993). Previous studies have indicated that the performance of the GP-OAD is superior to other methods (e.g. Chlingaryan et al., 2013; Schneider et al., 2011) but this has not yet been formally tested.A two-stage validation strategy was developed which compared the aforementioned methods first using data acquired in the laboratory under stable artificial illumination and then using imagery of a mine face in an open pit mine, acquired under natural illumination. This two-staged approach was necessary because findings from laboratory studies cannot be assumed to have relevance when methods are applied to data acquired in the field under natural light. This is because imagery acquired in the field is affected by spatial variability in illumination, including shade and effects of the intervening atmosphere. Absorption by water vapour across certain wavelength regions (e.g. those centred on 720nm, 762nm, 822nm, 945nm 1135nm) can reduce amounts of incident light causing a lower signal-to-noise ratio (SNR) close to these wavelengths. Other environmental and measurement effects can also have a significant impact on the quality of imagery acquired in the field (reviewed by Kurz et al., 2013). It is, therefore, of fundamental importance to understand any differences in the results obtained from laboratory and field data. Only then can we make general statements about the suitability of methods for classification of hyperspectral data acquired from satellite, airborne and field based platforms.The study area from which exploration drill cores and field imagery were obtained, was an operational open pit mine in the Pilbara, Western Australia. The area is characterised by extensive areas of banded iron formation (BIF) comprised of alternating layers of silica (often chert; CHT) with hematite or magnetite. Some areas have become mineralised through the influence of weathering and ground-water leaching. In this process, silica, a major component of CHT and BIF, is leached from the rock matrix, concentrating deposits of iron in the form of goethite and martite (hematite). Other major rock types in this area are different types of shales, including thin volcanic shale bands (SHL2), extensive deposits of West Angeles Shale (SHL1) and another type of shale (SHL3), containing variable amounts of kaolinite and/or halloysite, with bands of pyrolusite. Mineralised areas contain iron-rich materials dominated by goethite–limonite (GOL) which has a high abundance of goethite and a mixture of martite–goethite (MAR) which is abundant in both minerals but generally has a higher content of martite. The particular mine face used in this study exhibits all of these rock types. Mining is conducted via conventional drill and blast open-pit operations. The training set/spectral library was acquired from exploration drill-core samples from this area. The test data were acquired from the same drill cores (Experiment 1), however, spatially independent from the training set and from bulk rocks on a mine face (Experiment 2).Hyperspectral data were acquired using two different sensors. A field spectrometer (Analytical Spectral Devices, Boulder, Colorado; ASD) was used to acquire reflectance spectra (350–2500nm) for the spectral library. This spectrometer has a spectral sampling interval of 1.4 and 2nm Full Width at Half Maximum (FWHM) for the VNIR and 3 and 10nm, respectively, for the two SWIR sensors. Data were digitised at 16 bits and the fibre-optic of the device was fitted with an 8° fore-optic. Two imaging spectrometers (Specim, Finland) were used to acquire data from exploration drill cores in the laboratory and of a mine face in the field. The VNIR (400–1027nm) and SWIR (971–2516nm) imagers had a FWHM spectral resolution of 4.6 and 6.4nm, respectively digitised at 12 and 14 bits.This spectral library is the ‘reference’ or ‘training’ library used for the different classification methods in all experiments (Fig. 1). It is comprised of 90 spectra unevenly distributed across 6 classes of rock (Table 1). The spectral library was constructed from drill cores (10cm wide) using artificial illumination and a consistent target-sensor-illumination geometry (Schneider et al., 2009). A reference spectrum was acquired using a calibration panel (99% Spectralon) prior to each target measurement. Each reflectance spectrum was comprised of an average of 25 individual spectral measurements. Spectra were converted to absolute reflectance by dividing the target spectrum by the calibration spectrum and multiplying this quotient by the factors of the calibration panel. For consistency across all experiments, ASD spectra were converted to the band-passes of the imaging sensor using Gaussian convolution. In addition, spectral bands around the major water absorption bands centred at about 1400 and 1900nm were removed. Each library spectrum processed in this way comprised 283 spectral bands.The drill cores exhibited mainly smooth and dust free surfaces and were stored in plastic trays. Trays were comprised of four cores (each approximately 1m in length), each core being separated from a neighbouring core by a plastic divider. The imaging sensors were mounted on a scanning frame, nadir to the target. The distance from the target to the sensors was ∼860mm. To minimise shading effects, core trays were illuminated using two arrays of seven halogen lamps each, illuminating the tray at an angle of ±45° from each side. The halogen lamps were approximately 40cm away from the cores. A calibration panel (99% Spectralon), covering the entire spatial dimension of the sensor array, was placed into the field of view of the sensors at the beginning of each tray.A correction was applied to the image spectrum at each pixel in the VNIR images to remove an artefact (an increase in reflectance towards shorter wavelengths), caused by frame-smear. Dark current was then subtracted from each VNIR and SWIR images on a line-by-line basis. The calibration panel was used to calibrate the images to reflectance on a line-by-line basis. To maximise the SNR in the image spectra, separate calibration and target images, were acquired using integration times that allowed the full dynamic range of each sensor to be used. The difference in integration time of the two images was taken into account during the reflectance calibration using Eq. (1):(1)ρ(λ)tray=DN(λ)tray·ρ′(λ)WRDN(λ)WR·ttraytWR,where ρ(λ)trayis the reflectance of a tray image at band λ, DN(λ)trayis the digital number of an individual pixel in the tray image, DN(λ)WRis the line average of forty image frames of the white reference and ρ′(λ)WRis the reflectance factor of the calibration panel at the wavelength λ. Integration times for the calibration image and the tray image are indicated by tWRand ttray, respectively.Image spectra showed large increases in noise due to reduced sensor sensitivity towards the shorter (400–439nm) and longer (>970nm) end of the VNIR sensor. Noise also affected the shorter end of the SWIR sensor (971–1027nm) and wavelengths longer than 2335nm. Thus, these bands (and the small spectral overlap between the VNIR and SWIR sensors) were removed from the image cubes. The same was done for the training set to have the same number of bands in both data sets (283 bands). The VNIR and SWIR images were spatially registered using interpolation.Sixteen trays of drill cores were acquired and processed in this way. A meta-data set was then constructed for this study by extracting six rock types across all images (Table 1). Several rock samples of each of the six rock types were combined into a single hyperspectral image (Fig. 2).Because it is difficult to determine the identity of what mineral or composite suite of minerals which make up rock samples simply by colour/appearance alone, samples for X-ray diffraction analysis (XRD) were acquired from the rock samples after acquisition of spectral data (Ramanaidou et al., 2008). To provide a more definitive labelling of areas of the core we used XRD results in combination with visual inspection and contextual placement of each area within the core relative to other areas. This enabled us to determine if the assigned labels on the core were consistent with the measured and expected mineralogy.Hyperspectral imagery was acquired from the mine face using the VNIR and SWIR sensors mounted adjacently on a rotating stage (Fig. 3). A calibration panel (60% Spectralon; 30cm by 30cm), was placed next to the mine face during image acquisition. Integration times of the sensors were adjusted so that the brightest object of interest within the scene did not saturate. The VNIR and SWIR imagery were spatially registered and corrected for dark current in the same way as the laboratory imagery. Reflectance calibration was done on a band-by-band basis by dividing each pixel by the average value of pixels over the calibration panel and multiplying by the reflectance factors of the panel. The final image cube had a spatial resolution of 1882 by 291 pixels with 283 bands. The spatial resolution per pixel was 4.8cm.A Gaussian Process (GP) in a supervised learning problem uses a given training set D=(X,y) consisting of a matrix of training data X=[x1,x2,…,xN]T, where T indicates a transposed vector or matrix and y=[y1,y2,…,yN]T, consisting of N input points (i.e. training samples). To each vectorxi∈RB, with i=1, 2, …, N, a target yi∊{−1, 1} is associated. The vector xiin this context is a reflectance spectrum within the training data X (i.e. the spectral library) with B number of spectral bands. The predictive distribution f(x∗) at a new test point x∗ (i.e. a reflectance spectrum of an unknown class) can then be computed. A GP model uses a multivariate Gaussian distribution over the space of function variables f(x) mapping input to output spaces. A GP is fully specified by its mean function m(x) and covariance function k(x, x′), sof(x)∼GPm(x),kx,x′. UsingX,f,y={xi},{fi},{yi}i=1Nfor the training set (i.e. a spectral library consisting of reflectance data) andX∗,f∗,y∗={x∗i},{f∗i},{y∗i}i=1Nfor a test point (i.e. a pixel in a reflectance image), the joint Gaussian distribution with m(x)=0 becomes:(2)yf∗∼N0,K(X,X)+σ2K(X,X∗)K(X,X∗)K(X∗,X∗).N(μ,Σ)is a multivariate Gaussian distribution with mean μ and covariance Σ and K is the covariance matrix computed between all points in the data set. By conditioning on the observed training points, the predictive distribution for new points (i.e. spectra constituting pixels in a reflectance image) can be obtained bypfi|X∗,X,y=N(μ∗,Σ∗)whereμ∗ and Σ∗ are the new mean and covariance for the test data.Learning (or training) a GP model is equivalent to learning the hyper-parameters of the covariance function (kernel) from a data set. In a Bayesian framework this can be performed by maximizing the log of the marginal likelihood with respect to the hyper-parameters which control data-fitting and regularisation of the model. The trade-off between regularisation and data-fit in the GP model is automatic, i.e. no manual parameter tuning is necessary. In this study, the hyper-parameters were initialized with random values and a gradient descent method was used to search for their optimal values (i.e. a global minimum). To avoid converging to a local minimum, the search step was repeated several times with different random starting points in the hyper-parameter space (Williams and Rasmussen, 1996). After this step, the best parameter set was selected by comparing the magnitude of the log marginal likelihood for each starting point and selecting the one with the largest value.Prediction of class probabilities for a test sample x∗(i.e. an image pixel) is obtained from the joint Gaussian distribution of the training samples and the test samples by conditioning on the observed targets in the training set. Generally, the predictive distribution is Gaussian with a mean and a covariance function. Using Bayesian inference, the most likely label for a sample x∗with some uncertainty around it can be obtained. These two parameters are equivalent to the mean (μ) and the standard deviation (σ) of a Gaussian distribution and can thus be used to calculate the probability of a pixel belonging to either the ‘One’ or the ‘All’ class using the Gaussian cumulative distribution function. The result is the probability that a single observation from a normal distribution with parameters μ and σ will fall in the interval (−∞,0] because labels in our implementation of the ‘One versus All’ (OvA) classification were set to ‘−1’ (‘One’ class) and ‘1’ (‘All’ class).Our implementation of SVMs, outlined here, is derived from the work of Vapnik (2000) and similar to Murphy et al. (2012). To perform classification, the standard procedure is to apply a hard decision function to the final SVM. Because results obtained using hard decision boundaries were poor, we adopted an alternative approach that makes use of probabilistic estimates of class membership. Probabilistic predictions are particularly useful for problems having more than two classes, as is the case here. The decision is made based on a winner-takes-all strategy, i.e., the winning class is the one with the highest probability. To obtain probabilistic estimates, we transformed the SVM output to represent the likelihood of class membership, as in Platt (1999). The probabilities were obtained by fitting a parametric model to the output of the SVM; the parameters were calculated by the numerical optimization method proposed in Lin et al. (2007). They used essentially the same algorithm as Platt (1999), however, they improved their method in terms of numerical robustness using Newton’s method and back-tracking (Nocedal and Wright, 2006). In order to provide a fair test of methods, in which no manual parameter tuning was performed, the SVM regularisation parameter C was set to 1.Covariance functions or kernels can be used within several kernel machines (e.g. SVMs and GPs) without adapting the kernel to a given method or framework if they conform to the Mercer’s theorem (Schoelkopf et al., 1999). The following two kernels used in this study conform to the Mercer’s theorem (Table 2).The GP framework requires computing the covariance between all input pairs x and x′ (i.e. between spectra) or alternatively a covariance function which correlates the data in order to learn hyper-parameters and perform inference. A kernel can be combined with the GP framework by replacing the square brackets in Eq. (2) with any kernel, so that it becomesyf∗̃N(0,kOAD)andyf∗̃N(0,kSE), respectively for the two kernels presented in this study.The OAD kernel (Melkumyan and Nettleton, 2009) computes the covariance between spectra using an angular metric and depends, not on the difference x–x′, but on the spatial location of the points x and x′, thus the OAD kernel is non-stationary. The OAD is defined as:(3)kOAD(x,x′)=σ021-1-sinφπα(x,x′),where σ0 and φ are scalar hyper-parameters of the kernel and α(x,x′) represents the spectral angle between two spectra. The parameter φ controls the weight of the spectral angle and adjusts the influence of α on the overall correlation between x and x′; σ0 is a scaling factor. Empirical tests showed that small changes on the values of the hyper-parameters have negligible effects on the classification outcome, this was however, not tested quantitatively. Both hyper-parameters were learned automatically from the training data by maximising the log of the marginal likelihood (Section 2.3.1). No manual tuning of any parameter was done, neither for the SVMs nor for GPs.The squared exponential (SE) covariance function also known as Radial Basis Function (RBF) is defined as(4)kSE(x,x′)=σ02exp-(x-x′)22l2Unlike the OAD kernel, the SE kernel is stationary which means that it is invariant against translation which can be seen from the nominator in Eq. (4). The signal variance σ0 is one of the hyper-parameters of this kernel and is learned from the data, representing a scaling factor. The second hyper-parameter is the characteristic length-scale l which determines how quickly the sample function varies and in turn controls the amount of correlation between x and x′. If x is a vector, l becomes a vector with the same dimensionality as x to account for the variation in each dimension. Both kernel parameters were automatically learned from the training data for the SVM and GP framework using the methods described in Sections 2.3 and 2.4, respectively.The following strategy was used for classifications using GPs and SVMs. For the classification of each rock type, all spectra within the training set which were of the rock type being classified, were labelled as ‘−1’, other spectra from all other rock types (classes) were labelled ‘1’. The aim was to identify all samples of classes ‘−1’ and ‘1’ in the unknown test set correctly. This is a binary approach of classification and is known as ‘One versus All’ or ‘One versus Rest.’ The classification algorithm is applied n times for n different classes in a data set (Rifkin and Klautau, 2004). For example, in the case of the training set used in this study comprising six classes, the algorithm had to be applied six times (Fig. 4).SAM was selected for comparison with the machine-learning methods because it is commonly used to classify hyperspectral data; SAM is also embedded at the core of the OAD kernel. It therefore enables direct comparison of machine-learning methods with a method which does not operate within a probabilistic framework. SAM calculates the similarity of two spectra in a high dimensional space using the spectral angle α, Eq. (5). The brightness of a spectrum does not influence the spectral angle, i.e. the norm of a vector does not cause a change in the angle between two vectors. The spectral angle α is calculated using(5)α=cos-1x·x′‖x‖·‖x′‖,where x and x′ are a target and a reference spectrum, respectively. The norm of either vector is denoted by ||x|| and ||x′||.SAM is often implemented by applying a user-specified angular threshold (e.g. Shrestha et al., 2005; Dehaan et al., 2007). Other implementations can be used to improve scene classification, for example, a ‘minimum angle’ criterion can be applied, whereby a target vector is compared to all reference spectra in a spectral library (e.g. Clark et al., 2005; Hecker et al., 2008). A class label is then assigned by comparing the angles of all target-reference combinations and selecting the class of the reference spectrum which has the smallest angle with the unknown (target) spectrum. The ‘minimum angle’ implementation of SAM was used in this paper because it has been shown to perform better than a fixed threshold implementation under certain circumstances (Murphy et al., 2012).A standard set of statistics was used to evaluate the classification performance of methods applied to laboratory data. For each classification, the number of true-positive, false-positive, true-negative and false-negative classifications for each rock type was determined. Statistical measures to assess classifier performance were derived from these data, including accuracy, precision, and recall. Recall measures the quantity of positive results predicted by the method. It is the number of positive results predicted divided by the total number of results that should have been returned. Precision is a measure of the quality of the results predicted and is the number of positive results predicted divided by the total number of results returned (Olson and Delen, 2008; van Rijsbergen, 1979). The F-score is defined as the harmonic mean between recall and precision, i.e. F=(2×precision×recall)/(precision+recall). The kappa coefficient of agreement (Kappa, Congalton et al., 1983; Hudson and Ramm, 1987) was also determined. A Student’s T-test was done to determine if the differences between the classification performances of the different methods were statistically significant.

@&#CONCLUSIONS@&#
Results show that GPs can compete with the state-of-the art SVM classification approaches. In general, GPs:(i)Provide class posterior probabilities.Yield a variance estimate that can be exploited as a measure of confidence.Operate in a Bayesian framework allowing the ability to:a.Integrate prior information in the classification process.Fuse data from several sensors or data of the same target acquired at different times.Select or weight features using automatic relevance determination kernels.The main drawback of GPs is their high computational costs during inference. In this study no attempts were made to improve upon the computational speed, however, there are several methods to do this (e.g. Melkumyan and Ramos, 2009).The experimental results obtained using the mine face imagery show that a non-stationary kernel (e.g. OAD kernel) or a kernel which is not based on the distance between two spectra is better suited for classification of hyperspectral data, particularly, when the training and test set were acquired independently and under different conditions of illumination. Although, the GP-OAD has been applied to data acquired from a field-based platform, it may be applied to any hyperspectral image acquired from satellite or aircraft. Our choice of data acquired from a field-based platform allowed a more rigorous approach of validation. The results presented in this paper are therefore of direct relevance to all hyperspectral imagery, independent of the platform from which they were acquired.