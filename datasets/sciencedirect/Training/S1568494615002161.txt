@&#MAIN-TITLE@&#
A modified particle swarm optimization with multiple subpopulations for multimodal function optimization problems

@&#HIGHLIGHTS@&#
This paper shows a modified particle swarm optimization (PSO) algorithm with multiple subpopulations for solving multimodal function optimization problems.The best particle within each subpopulation is recorded and then applied into the velocity updating formula to update all particles in each subpopulation.To show the efficiency of the proposed method, two kinds of function optimizations including a single modal function optimization and a complex multimodal function optimization are provided.Simulation results will demonstrate the convergence behavior of particles by the number of iterations, and the global and local system solutions are solved by these best particles of subpopulations.

@&#KEYPHRASES@&#
Particle swarm optimization (PSO),Multiple subpopulations,Multimodal optimization problem,

@&#ABSTRACT@&#
In this paper, a modified particle swarm optimization (PSO) algorithm is developed for solving multimodal function optimization problems. The difference between the proposed method and the general PSO is to split up the original single population into several subpopulations according to the order of particles. The best particle within each subpopulation is recorded and then applied into the velocity updating formula to replace the original global best particle in the whole population. To update all particles in each subpopulation, the modified velocity formula is utilized. Based on the idea of multiple subpopulations, for the multimodal function optimization the several optima including the global and local solutions may probably be found by these best particles separately. To show the efficiency of the proposed method, two kinds of function optimizations are provided, including a single modal function optimization and a complex multimodal function optimization. Simulation results will demonstrate the convergence behavior of particles by the number of iterations, and the global and local system solutions are solved by these best particles of subpopulations.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO) algorithm is a rather popular and useful tool for solving any kind of engineering optimizations over the few years [1–13]. It was firstly proposed by Kennedy and Eberhart in 1995 and has been proven to be a simple but powerful optimal algorithm among a lot of evolutionary algorithms (EAs) [1]. The main features consist of the simplicity of updating formulas, easy for implementation on computer programs, real number manipulations, quicker convergence, etc. Due to these excellent advantages, a variety of engineering applications based on the PSO have successively been explored and developed such as job-shop scheduling problems [2,3], digital filter designs [4–6], controller designs [7–9], power system designs [10,11], antenna array design [12] etc. This paper will focus on the issue of solving the multimodal function optimization problem using the modified PSO algorithm. It is well known that most of function optimization problems with several designed variables are of multimodal, i.e., including multiple global or/and local optimal solutions, not a single optimum, over the search space. To solve this kind of optimization problems, various methods based on evolutionary algorithms have been employed and developed in recent years [14–19]. For example, a novel evolutionary algorithm which combines Niche technique with the gravitational search algorithm (NGSA) was presented for solving multimodal function optimizations [14]. Three strategies consisting of a K-nearest neighbors strategy, an elitism strategy, and modification of active gravitational mass formulation are considered. In [15], for multimodal optimizations they developed a new variant of differential evolution (DE) algorithm in which new individuals close to an isolated individual in a current population are generated. This mechanism will allocate search resources for each optimum of the function. Another new algorithm named as the glowworm swarm optimization (GSO) was presented for simultaneous computation of multiple optima of multimodal functions [18]. This algorithm is to share some features with known swarm intelligence algorithm like the ant colony optimization and particle swarm optimization. In [19], they proposed a memetic algorithm which hybridizes particle swarm optimization with a local search technique for locating multiple global and local optimal solutions. A triggered re-initialization scheme is introduced into the proposed algorithm to enhance the search performance.In the evolutionary algorithms, the concept of subpopulation (or named as subswarm) is often discussed and utilized especially for solving multiobjective optimization problems and multimodal function optimization problems [14,17,20–24]. It is always to split up the original population into several small subpopulations with a few particles for PSO, chromosomes for GA, or parameter vectors for DE algorithm for some special purposes. Then, certain evolving mechanisms and operations are executed to achieve the system design. In [20], a sub-population genetic algorithm (SPGA) was utilized and combined with a mining gene structure technique for multiobjective flowshop scheduling problems. In the SPGA, the original is divided into numerous subpopulations which are assigned with different weights to search for optimal solutions in different directions. They claimed that this approach can consider both the expanding and converging natures of the system solutions [20]. In [21], the author presented a two-layer particle swarm optimization (TLPSO) consisting of the top layer and the bottom layer to increase the search diversity of the particles so that the drawback of trapping in some local optimum can be avoided. In the developed structure, it contains M swarms of particles in the bottom layer and one swarm of particles in the top layer. Each global best position in each swarm of the bottom layer is set to be the position of the particle in the swarm of the top layer. A mutation mechanism is then introduced into the particles of each swarm in the bottom layer so that the particles leap the local minimum to search for the global one [21]. Furthermore, a competitive and cooperative co-evolutionary approach to multiobjective PSO algorithm design was presented, which the subswarms are employed to produce the reasonable problem decompositions by exploiting any correlation and interdependency between components of the problem [23]. It was validated by some comparisons with existing state-of-the-art algorithms.This paper will propose a simple modified version of PSO algorithm with multiple subpopulations for the multimodal function optimization. In the beginning, the population needs to be split up into several subpopulations and in each subpopulation the best particle is necessarily recorded, that is, each subpopulation has a best particle. With the information of the best particle instead of the global best particle, all of particles contained in this subpopulation are updated. In this manner, simultaneous finding multiple optima is probably achieved for the multimodal function optimization. The remainder of this paper is organized as follows. In Section 2, the difference between the general PSO algorithm and the proposed one is introduced in detail. A modified version of the velocity updating formula is described. In Section 3, a single modal function optimization problem is first simulated by the proposed method and it will reveal that all simulation results converge to the single optimum. In Section 4, the proposed method is applied to solving the complex multimodal function optimization problem which consists of several global and local minimum points. Simulation results reveal that the proposed method can seek for most of optima. Finally, Section 5 gives a simple conclusion and future research work.It is well known that the PSO algorithm has been shown to be a powerful search means to solving various engineering optimization problems. It is an iterative and population-based algorithm which is motivated by the social behavior of a flock of birds and a school of fishes. In recent years, the PSO algorithm has received much attention of many researches and also been applied to a variety of engineering fields as addressed in the previous section because of its good features. In the general PSO algorithm, it begins with generating a random initial population that consists of a number of individuals (or called particles). For an optimization problem, every particle represents a candidate solution of the optimized system. It is necessary to enroll some information including both the individual best for every particle and the global best for the whole population. The individual best, pbest, denotes the best position of each particle which it has found so far, and the global best which is denoted by gbest is the best particle in the population. Every particle contained in the population is updated according to these two main information pbest and gbest, i.e., they guide the search direction of all particles over the search space. How to evaluate the pbest for each particle and the gbest for the whole population is determined by the corresponding cost function value. Generally, it is a better particle whose cost function value is smaller.In the general PSO, let the vector X=[x1, x2, …, xn] be a particle, where xifor i=1, 2, …, n is the decision variable or the designed variable of the optimized problem. The following two updating formulas are utilized to guide the moving of each particle, the velocity updating formula of Eq. (1) and the position updating formula of Eq. (2):(1)vij(t+1)=w∗vij(t)+c1⋅r1⋅(pbestij(t)−xij(t))+c2⋅r2⋅(gbestj(t)−xij(t)),(2)xij(t+1)=xij(t)+vij(t),where xij, pbestij, and gbestjrepresent the jth position components of the ith particle, the ith individual best particle, and the global best particle, respectively,vijis the jth velocity component of the ith particle, w is the inertia weight for balancing the global and local search, c1 and c2 are two positive constants assigned by the designer, r1 and r2 are two uniformly random numbers chosen from the interval [0,1]. It is worthy of notice that only one global best particle of the population, gbest, is enrolled in the general PSO algorithm. In this manner, only one corresponding system solution can be caught by the gbest for the optimized problem. For solving the multimodal function optimization, it is rather improper and not applicable because the multimodal function consists of several system optima including global optimal solutions and local optimal solutions.To tackle this problem, a modified version of the PSO algorithm is developed, which the concept of subpopulations is utilized for solving multimodal functions. In the proposed algorithm, the original single population is firstly requested to be divided into M subpopulations just according to the order of particles. For instance, assume that there are 40 particles in the original population, and it will be split up into four subpopulations. In the case, the first subpopulation is composed of particles from number one to number ten, the second subpopulation consists of particles from number eleven to number twenty, and so forth. The best particle in each subpopulation is necessary to be recorded to guide the moving of all particles in the same subpopulation by a modified velocity formula. Following this idea the gbest used in Eq. (1) is referred to as the best particle of each subpopulation, not as the global best particle in the whole population. Moreover, in the proposed method there are totally M best particles because of having M subpopulations. It means that these M best particles are separately able to catch different optima, at most M optima, for the multimodal function optimization because some of them probably search for the same system optimum. Fig. 1clearly explains the proposed concept of subpopulations, where N is the number of particles, i.e., population size, in the original single population, M is the number of subpopulations and, therefore, there contains N/M particles in each subpopulation. Notice again that it is necessary to record the best particle of each subpopulation and the information will be utilized in the velocity formula to update all of particle positions in the same subpopulation. Besides, the design flow chart for the proposed PSO method with multiple subpopulations is clearly listed in Table 1for the multimodal function optimization problem. The following describes the complete design steps of the modified PSO algorithm.I.Create a population consisting of N particles which are generated from some search interval [xmin, xmax] randomly.Divide the population into M subpopulations simply according to the order of particles. Each subpopulation includes N/M particles.If the number of iterations is achieved, then the algorithm stops.Calculate the optimized function value for each particle and enroll the individual best particle pbest and the best particle gbest in each subpopulation, respectively.Execute the velocity updating formula of Eq. (1) in which the global best is replaced by the best particle of each subpopulation and the position updating formula of Eq. (2), respectively, for all particles of each subpopulation.Check the position of each particle by(3)xi=xminifxi<xminxiifxmin≤xi≤xmaxxmaxifxi>xmaxfori=1,2,…,n.Go back to Step III.In this section, a single modal function optimization problem is firstly illustrated to explain the concept of the proposed PSO algorithm with multiple subpopulations. The optimized function is given by(4)f(x,y)=(x−1)2+(y−2)2,where the search space is defined by −6≤x≤6 and −6≤y≤6, respectively. Fig. 2shows the 3-D surface of the optimized function and its corresponding contour is then displayed in Fig. 3. It can easily be seen from Eq. (4) or these figures that it has only one global minimum occurred at (x, y)=(1, 2). In the following simulations, the software of Borland C++ 5.02 under the environment of Intel(R) Core(TM) i7-3770 CPU@3.40GHZ is utilized to program the above design steps of the proposed PSO algorithm with multiple subpopulations. Furthermore, the common parameters used in the PSO are given by the population size N=20, inertia weightw=0.5, positive constants c1=c2=0.5 in Eq. (1), and the search interval [xmin, xmax]=[−6, 6] in Eq. (3), respectively.Three different examinations are considered including Case 1: only one population, Case 2: two subpopulations, and Case 3: four subpopulations for solving such a single modal function optimization. Convergence dynamics of all particles will be displayed, respectively, when iteration=0, iteration=5, iteration=10, and iteration=20. Fig. 4shows the convergence behavior of particles converging to the global optimum (1, 2) for Case 1, where the red point represents the global minimum of the single modal function, the green point means the best particle in this single population, and the black point then represents the common particle. In the case, all particles quickly and fully converge to the global minimum point of the optimized function after about 20 iterations. Fig. 5displays the simulation results for Case 2 with two subpopulations. It contains two best particles (two green points) corresponding to two subpopulations. After a few iterations, the other common black points as well as both two green points quickly converge to the same point, red point (1, 2). In Case 3, the population size is changed to N=40 in order to meet the situation of using four subpopulations. In Fig. 6, there are totally 40 points consisting of 36 black points and 4 green points due to four subpopulations. Also, these four green points are successively converging to the minimum point (1, 2) after some iterations. It is clearly seen from these figures that all best particles contained in the subpopulations fully converge to the only one optimal solution of the optimized function. It can be concluded that all numerical results derived by using single population and multiple subpopulations are the same for solving the single modal function optimization.Consider the following multimodal function minimization problem [25](5)f(x,y)=(x2+y−11)2+(x+y2−7)+0.1[(x−3)2+(y−2)2].This function is called the modified Himmelblau function which is often used as a benchmark minimization problem. Fig. 7displays the 3-D surface of this multimodal function with the defined space −6≤x≤6 and −6≤y≤6, and its corresponding contour is then shown in Fig. 8Fig. 8. It can easily be found from Figs. 7 and 8 that this optimized function has four minimum points including one global minimum occurred at f(3, 2)=0 and another three local minimum points at f (−3.7634, −3.2660)≈7.3673, f (3.5814, −1.8208)≈1.5043, and f (−2.7870, 3.1282)≈3.4871, respectively. In addition, the parameter settings employed in the algorithm are the same with those of the above example.For solving such a multimodal function optimization problem, a large number of different testing cases are provided to demonstrate the efficiency of the proposed method, including single population, two subpopulations, and four subpopulations. In Case 1, Fig. 9shows the convergence behavior of particles when iteration=0, 5, 10, and 20, respectively, where the four red points represent the four minimization points and the green point denotes the global best in this single population. In the case, the only one global best (green point) also quickly converges to the global minimum (x, y)=(3, 2), one of these four minimization points. However, the global best particle probably converges to one of other local minimum points, for examples, converging to (x, y)=(−3.7634, −3.2660) in Fig. 10or to (x, y)=(3.5814, −1.8208) in Fig. 11, respectively, if the algorithm's initial conditions are given by different values. As can be seen from Figs. 9–11, the PSO algorithm with a single population is insufficient and not applicable to solving the complex multimodal function problem. The solution derived may be a local minimum, not a global minimum of the optimized function due to the effect of algorithm's initial conditions.In the following, the population is further divided into a few subpopulations so that the best particle in each subpopulation can separately search for other minimum points. To explain this, Cases 4–6 are simulated for two subpopulations under different initial conditions. Fig. 12displays the two best particles converging to two minimum points, one is the global minimum (3, 2), the other is the local minimum (−2.7870, 3.1282), respectively. Certainly, it maybe converges to only one minimum point (−3.7634, −3.2660) as shown in Fig. 13or to another two minimum points (3.5814, −1.8208) and (3, 2) in Fig. 14. From these simulation results, it can be concluded that the PSO algorithm with two subpopulations is better than a single population for solving the multimodal function optimization. As for the algorithm with four subpopulations, Cases 7–9 are executed when number of particles is changed as N=40. All simulation results are displayed in Figs. 15–17, respectively. In Fig. 15, two minimum points including the global minimum (3, 2) and a local minimum (−2.7870, 3.1282) of the optimized function are separately caught by these four best particles (green points). In Fig. 16, on the other hand, the four best particles then finally converge to points (3, 2), (−3.7634, −3.2660), and (3.5814, −1.8208), respectively. In the case, three minimum points of the multimodal function are solved by using four subpopulations method. Fig. 17shows another simulation result which another three minimum points (3, 2), (−2.7870, 3.1282), and (3.5814, −1.8208) are found. It is clearly shown from all simulations that the PSO algorithm with multiple subpopulations is rather effective and applicable in solving the multimodal function optimization problem than the general PSO algorithm with a single population.Finally, in order to clearly show all of the particle distributions in different subpopulations over the search space and to clarity the effect of different population sizes on the convergence behavior, the case of two subpopulations are reconsidered. First, the population size is assumed to be N=20 and it is divided into two subpopulations as well. Fig. 18displays the simulation results, where particles belonging to the first subpopulation are denoted by black points and the blue particles then belong to the second subpopulation. At the beginning, all particles are distributed over the search space uniformly, and after a few iterations all particles in each subpopulation are separately converging to two different optimum points (the black particles converging to (−2.7870, 3.1282) and the blue particles converging to another point (3, 2), respectively). This figure sufficiently reveals the convergence dynamics of all particles in each subpopulation. Furthermore, the optimum points derived by two best particles may not be the same when the population size is given by N=30 and N=40, as shown in Figs. 19 and 20, respectively. These show that the distribution of particles on the search space will significantly affect the solutions obtained.

@&#CONCLUSIONS@&#
This paper has successfully developed a modified PSO algorithm with multiple subpopulations for solving the multimodal function optimization problem. It begins with splitting up a single population of the algorithm into several subpopulations by the order of particles. In each subpopulation, the best particle with the best cost function needs to be recorded, and this information is utilized in the modified velocity formula to replace the original global best in the single population. All particles within the same subpopulation are updated according to the modified formula. These best particles can separately converge to various function optima including the global and local solutions of the multimodal function. Simulation results sufficiently reveal the applicability of the proposed method. In the future work, the modified PSO algorithm with multiple subpopulations may be applied to solving the multi-objective optimization problem and the MIMO control system designs.