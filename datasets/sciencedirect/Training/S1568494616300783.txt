@&#MAIN-TITLE@&#
Binary artificial algae algorithm for multidimensional knapsack problems

@&#HIGHLIGHTS@&#
A novel binary artificial algae algorithm is proposed for solving MKPs.The method is composed of discrete process, repair operators and elite local search.The results show the proposed method outperforms many existing algorithms.

@&#KEYPHRASES@&#
Artificial algae algorithm,Multidimensional knapsack problem,Pseudo-utility ratio,Elite local search,

@&#ABSTRACT@&#
The multidimensional knapsack problem (MKP) is a well-known NP-hard optimization problem. Various meta-heuristic methods are dedicated to solve this problem in literature. Recently a new meta-heuristic algorithm, called artificial algae algorithm (AAA), was presented, which has been successfully applied to solve various continuous optimization problems. However, due to its continuous nature, AAA cannot settle the discrete problem straightforwardly such as MKP. In view of this, this paper proposes a binary artificial algae algorithm (BAAA) to efficiently solve MKP. This algorithm is composed of discrete process, repair operators and elite local search. In discrete process, two logistic functions with different coefficients of curve are studied to achieve good discrete process results. Repair operators are performed to make the solution feasible and increase the efficiency. Finally, elite local search is introduced to improve the quality of solutions. To demonstrate the efficiency of our proposed algorithm, simulations and evaluations are carried out with total of 94 benchmark problems and compared with other bio-inspired state-of-the-art algorithms in the recent years including MBPSO, BPSOTVAC, CBPSOTVAC, GADS, bAFSA, and IbAFSA. The results show the superiority of BAAA to many compared existing algorithms.

@&#INTRODUCTION@&#
Knapsack problems are found in many science and engineering applications such as finite word length filter design problems [1]. The decision vectors are discrete valued. One common approach to address this issue is to approximate the problems by the optimization problems with continuous valued decision vectors and some advanced techniques [2–5] are applied to find the solution of these problems. To address the original optimization with the discrete valued decision vectors, the 0–1 multidimensional knapsack problem (MKP) is a well-known NP-hard optimization problem [6]. Given a set of items with non-negative weights and values (profits), MKP is to select some of the items to put into knapsack with specified capacity constraints such that the profit is maximized without violating the constraints. A standard MKP is given as follows [7]:(1)maxf(x)=∑i=1dpixi,i=1,2,…,d,s.t.∑i=1dcijxi≤bj,i=1,2,…,d,j=1,2,…,m,xi∈{0,1},i=1,2,…,d,where d is the number of items and m is the number of knapsack constraints; piis the profit of ith item if it is put into knapsack; xiis either 1 or 0, where 1 denotes the ith item being stored into the knapsack and 0 denotes ith item being discarded, respectively; cijis the consumption of jth resource while putting the ith item into knapsack and bjis the total capacity of jth resource. Without loss of generality, it is assumed that pi>0, 0≤cij<bjand∑i=1dcij>bj.In nature, MKP is a typical integer programming problem with d variables and m constraints. In the past decades, MKP has been investigated and applied in cutting stock, loading problem, project selection and resource allocation [8]. Plenty of methods were introduced to solve MKP in recent years including deterministic and approximate algorithms [9]. Some exact algorithms like dynamic programming [7,10], branch and bound algorithm [11] and hybrid algorithms [12,13] can solve small-scaled and medium-scaled problems within endurable time. As the number of items and constraints increase, the performance of exact algorithm declines rapidly and becomes intolerable. With the development of intelligent computing, many new approximate methods emerge such as heuristic and meta-heuristic algorithms. This type of algorithms can find optimal, sub-optimal or at least satisfactory solutions in most cases, although the optimum is not guaranteed. Such algorithms include genetic algorithm [14–16], tabu search [17], simulated annealing [18], particle swarm optimization [19,20], firefly algorithm [21], harmony search [22,23] and artificial fish swarm algorithm [24,25], etc. Evolutionary computation and bio-inspired algorithms are the fastest developing type of algorithms. The basic idea of them is that from an initial population of individuals, solution vectors, individuals evolve by some way to produce new better individuals and keep better ones in the next generation (iteration), whereas the worse individuals are discarded in the next generation. A satisfactory solution will be obtained after updating some generations. More details can be found in [26,27].In [14], genetic algorithm was utilized to solve MKP. This method has been further improved by Djannaty in [15] where initial population created by Dantzig algorithm and penalty function to increase the rate of convergence of MKP were introduced. In [28], a binary version of PSO is introduced by Kennedy to solve discrete optimization problems. In [20], a modified binary particle swarm optimization (MBPSO) algorithm is proposed for 0–1 knapsack problem and multidimensional knapsack problem. MBPSO introduced a new probability function to improve the diversity and made it more effective than simple binary version of PSO. In [29], binary PSO with time-varying acceleration coefficients (BPSOTVAC) and chaotic binary PSO with time-varying acceleration coefficients (CBPSOTVAC) were proposed. Through introducing the time-varying inertia weight and time-varying learning factors, the performance of the solution had been improved significantly. In [30], a particle swarm optimization with self-adaptive check and repair operator (SACRO) was presented to improve the efficiency of PSO, where SACRO will change the alternative pseudo-utility ratio dynamically. In [25], a binary version of the artificial fish swarm algorithm was proposed where a decoding scheme was introduced to transform infeasible solutions to be feasible for multidimensional knapsack problem. In [23], an effective hybrid algorithm based on harmony search (HHS) was presented to solve multidimensional knapsack problems. HHS developed a novel harmony improvisation mechanism with modified memory consideration rule and global-best pitch adjustment scheme. In addition, the fruit fly optimization (FFO) scheme was integrated as a local search strategy. Compared with an improved adaptive binary harmony search algorithm (ABHS) [31] and a novel global harmony search algorithm (NGHS) [32], HHS demonstrated the effectiveness and robustness.In the recent years, a new meta-heuristic algorithm, artificial algae algorithm (AAA), was presented [33]. Similar to other bio-inspired algorithms, AAA was inspired by the lifestyles of algae. AAA has been successfully applied in the optimization of benchmark functions with various dimensions in CEC’05 [34] and implemented on the pressure vessel problem. However, due to its continuous nature, AAA cannot settle the discrete problem straightforwardly such as MKP. In view of this problem, this paper proposes a binary artificial algae algorithm (BAAA) to solve MKP. Compared with many bio-inspired binary version algorithms in well-known benchmarks for MKP, BAAA achieves better performance in terms of robustness as well as the best solution obtained.In the recent years, a new artificial algorithm, named as artificial algae algorithm (AAA), is proposed to solve continuous optimization problems [33]. AAA simulates real algae to survive by finding and moving to the appropriate environment, and reproduce next generation. In this section, we will review AAA briefly. More details on AAA can be found in [33].Denote the algae population which comprises of a number of algal colonies as below:(2)Population of algal colony=x11x12⋯x1dx21x22⋯x2d⋮⋮⋯⋮xn1xn2⋯xndSet xi=(xi1, xi2, …, xid), i=1, 2, …, n, where each xirepresents a feasible solution in solution space. Each algal colony contains a group of algal cells which are regarded as the elements of a solution. All the algal cells in an algal colony are considered as a whole to move together towards a suitable place with abundant resources. As the colony reaches a ideal position, optimum solution is obtained.In the artificial algae algorithm, there are three key parts which are helical movement, evolutionary process and adaptation. The algal colony tries to move to a optimal position through moving, evolving and adapting itself. It is worth to mention that a crucial concept in AAA is the size of algal colony of ith algal colony denoted as Si, i=1, 2, …, n. Similar to the real algae, under perfect living condition, the algal colony will reproduce and grow to a bigger size. Living in a bad environment will lead to death of algal cells and shrink of algal colony. Siis set as 1 at the initial stage, and altered with the change of the fitness value of the ith algal colony, i.e. the value of objective function. The better the objective function f(xi) is, the bigger Siis. Siis updated according to the biological growth process given as follows:(3)Si=size(xi)(4)μi=Si+4f(xi)Si+2f(xi)(5)Sit+1=μiSit,i=1,2,…,nwhere f(xi) is the objective function, μiis the update coefficient of Si, t represents the current generation.Algae make instinctive movement to the water areas which have adequate light and other nutrients. In AAA, each algal colony moves towards the best algal colony which has the biggest size or optimal objective function value. Similar to the movement in three dimensions of the object in real world, algal colony moves in three dimensions as well. However, this movement is simulated by selecting three distinct algal cells randomly and changing their positions. Eq. (6) represents the movement in the first dimension and can be used for one-dimensional problems. Eqs. (7) and (8) indicate movement in other two dimensions.(6)ximt+1=ximt+(xjmt−ximt)(sf−ωi)p(7)xikt+1=xikt+(xjkt−xikt)(sf−ωi)cosα(8)xilt+1=xilt+(xjlt−xilt)(sf−ωi)sinβwhere m, k and l are random integers uniformly generated between 1 and d, xim, xikand xilsimulate x, y and z coordinates of the ith algal colony, j indicates the index of a neighbor algal colony and is obtained by tournament selection, p is an independent random real-valued number between −1 and 1, α and β are random degrees of arc between 0 and 2π, sf is shear force which exists as viscous drag, ωiis the friction surface area of ith algal colony which is proportional to the size of algal colony. Due to the spherical shape of algal colony, friction surface is deduced as the surface area of the hemisphere which can wrap up the algal colony. ωiis calculated as follows:(9)ωi=2πri2(10)ri=3Si4π3where rirepresents the radius of the hemisphere of the ith algal colony, and Siis its size.In natural environment, algal colony with adequate nutrient source grows rapidly and that with scarce nutrient source will wither to die. Similarly, in AAA, algal colony xibecomes bigger if it moves to an ideal position and obtains more feasible solution. While a iteration terminates, the smallest algal colony withers and an algal cell of the smallest algal colony is substituted by an algal cell of the biggest algal colony. This process is simulated as the following equations:(11)biggest=argmax{size(xi)},i=1,2,…,n(12)smallest=argmin{size(xi)},i=1,2,…,n(13)smallestj=biggestj,j=1,2,…,d.where biggest and smallest represent the biggest and smallest algal colony, respectively, j is the index of a randomly selected algal cell.In the growing process, algal colony suffers from starvation under insufficient light and nutrient. Adaptation is the process in which starved algal colony tries to move towards the biggest colony and adapts itself to the environment. Starvation value is set to zero from beginning, and increases with the helical movement. The movement makes the fitness of algal colony either better or worse. Thus, the objective function value becomes superior or inferior to the value after movement. If the objective function gets better value, the corresponding algal colony remains its starvation level unchanged. Otherwise, the starvation value increases by one. After movement of algal colony ends in an iteration, the algal colony that has the highest starvation value (Eq. (14)) adapts itself to the biggest algal colony with a probability Ap. In the adaptation phase of original AAA [33], the adaptation of the algal colony was implemented by adapting every single algal cell. For the sake of clarity, we introduce Eq. (15) to illustrate this process:(14)xs=argmax{starvation(xi)},i=1,2,…,n(15)xsjt+1=xsjt+(biggestj−xsjt)×rand1,ifrand2<Ap;j=1,2,…,dxsjt,otherwise.where s is the index of algal colony which has the highest starvation value, and starvation(xi) measures the starvation level of algal colony xi, j is the index of algal cell, rand1 and rand2 generate stochastic real-valued numbers between 0 and 1, Apis the adaptation probability which decides whether adaptation occurs or not, Apis a constant usually being set between 0.3 and 0.7.AAA was initially proposed to solve continuous nonlinear optimization problems. Therefore, all computation in AAA, such as helical movement, evolutionary process and adaptation are continuous. However, MKP is a typical discrete optimization problem. AAA cannot be applied directly. Here we will introduce a binary version of AAA, namely BAAA, to solve MKP. At the initialization stage, algal colony xiis initialized as a binary string of length d with 0 or 1. Each algal cell xijis generated according to the following equation:(16)xij=0,ifrand<0.5;1,otherwise.Then, the population of algal colony is encoded as n binary strings and each string is a candidate solution for MKP. An encoding example is illustrated in Fig. 1which demonstrates the changing process of population in one iteration. In Fig. 1,denotes each algal colony is transformed into a new binary string through helical movement.indicates algal colony moves until its energy runs out.represents the evolutionary process which leads to the inversion of one bit in a specified binary string.means each binary string adapts itself according to the adaptation probability.Due to its continuous nature of AAA, the intermediate results tend to be real-valued number and cannot be applied to MKP straightforwardly. Discrete method should be introduced to transfer real number into binary number 0 or 1. Sigmoid function is a type of mathematical function which is defined for all real input values with bound outputs ranging from 0 to 1. Logistic function is the special case of sigmoid function (see Eq. (17)) and its figure is shown in Fig. 2.(17)g(x)=1e−x+1(18)xij=0,ifg(x)<rand;1,otherwise.In real applications, two variants of logistic function, called Tanh(x) and Sig(x), are often used. Here Tanh(x) and Sig(x) are defined as:(19)g(x)=Tanh(x)=eτ|x|−1eτ|x|+1(20)g(x)=Sig(x)=1e−τx+1where τ is a controlling parameter which determines the changing trend of the curve. Combined with Eq. (18), a discrete value 0 or 1 is produced through comparing g(x) with a random distributed value between 0 and 1. Fig. 3illustrates the figure of Tanh(x) and Sig(x) with different τ. As seen in Fig. 3, the smaller τ is, the less steepness of the curves have. When τ is very small, the curve tends to be a horizontal line. Taking Sig(x) as an example, when τ=0.1, the values of function are close to 0.5 which makes the discrete procedure like a random selection. As a result, the algorithm is led to poor exploitation and easy to fall into local optimum. On the other hand, when τ is large, the curve becomes much steep which leads to low diversity and poor exploration. For example, if x>5 and τ=3.5, then g(x) is very close to 1. For this case, Eq. (18) has little chance to produce 0. This clearly shows that proper τ is crucial for the discrete procedure. An experiment is carried out in the next section for the selection of τ.In the initialization and discrete process, the solution vectors with 0 or 1 are produced without considering their feasibility. However, they are likely to be infeasible solutions in spite of their high fitness values, and they may mislead the search into hopeless situation. As is known to all, as the solution of MKP, the binary string should satisfy all the constraints. Therefore, each candidate solution must be checked and modified to meet every constraint. Moreover, total fitness value is to be enhanced as high as possible. This idea can be realized by two stages. The first stage is to adjust the infeasible solution to feasible one by discarding some items from the knapsack and setting the responding item value from 1 to 0. The second stage is to utilize the remainder space of the knapsack completely by putting some items into the knapsack and setting the responding item value from 0 to 1. In order to choose appropriate items for previous operation, a selection mechanism must be determined. Several techniques were proposed in the literatures. [35] first introduced the pseudo-utility in the surrogate duality approach. The pseudo-utility of each variable was given below:(21)δi=pi∑j=1mwjcij,i=1,2,…,dwherewjis surrogate multiplier between 0 and 1 which can be viewed as shadow prices of the jth constraint in the linear programming (LP) relaxation of the original MKP. Obviously,wjis a key value to determine the selection of items. An optimal set of surrogate multipliers can effectively measure the consumption level of resources for each item, and improve the final repair effect. However, it is hard to find the optimal set ofwj, especially when m+n is very large. To overcome this drawback, [36] presented a new metric called relative mean resource occupation defined as:(22)δi=∑j=1mcijm·bjpi,i=1,2,…,dIn addition, another two common used pseudo-utilities [30], i.e. profit/weight utility and relative profit density, are:(23)δi¯=minpicij,i=1,2,…,d,j=1,2,…,m(24)δi˜=minpi·bjcij,i=1,2,…,d,j=1,2,…,mEq. (23) calculates the ratio of profit and weight. The greater the ratio is, the more possible the item being selected into knapsack. Considering cij, j=1, 2, …, m have m values for itemδi¯, only the smallest value of the ratios is adopted to measure the pseudo-utility. Compared with Eq. (23) and (24) not only takes profit/weight into account but also introduces the capacities in each dimension, i.e. profit density. Three different measures of pseudo-utility ratios produce different ranking of ratios and lead to various packing sequence. An experimental comparison among them will be implemented in Section 4.After pseudo-utility ratios are calculated, the pseudo-utilities are ranked to ascending order. Then, two repair operators are performed for making the solution feasible and improving the quality of solution, respectively. The first is DROP operator in which some items will be removed from the knapsack if the solution is infeasible. The DROP operator selects the item from the knapsack with smallest value of pseudo-utility and changes the responding bit from 1 to 0 until the solution is feasible. The second is ADD operator in which some items will be added into the knapsack as much as possible. The ADD operator examines each item in the descending order of pseudo-utility, and tries to pack the item in the knapsack one by one without violating the constraints. This greedy-like procedure makes sure that the profit can be acquired as much as possible based on the pseudo-utility ratio. The DROP and ADD operators are implemented in Algorithm 1. The function feasible(x) judges whether solution vector x satisfies all the constraints. It returns true if x is feasible, otherwise, it returns false. This repair method not only makes the solution feasible without violating any constraints but also packs items into knapsack with profits as much as possible.Algorithm 1DROP and ADD procedure.Input:a candidate solution xOutput:a repaired solution x1:compute δi, i=1,2,…,d2:initialize s(i)=i, i=1, 2, …, d3:sort s(i) rendering δs(i) be in ascending order//DROP phase4:if(not feasible(x))5:for i=1 to d do6:if(xs(i)=1)7:xs(i)=08:if(feasible(x))break9:end if10:end for11:end if//ADD phase12:for i=d to 1 do13:if(xs(i)=0)14:xs(i)=115:if(not feasible(x))xs(i)=016:end if17:end for18:returnx.In BAAA, the best algal colony is obtained in each iteration which represents current optimal solution xb. In order to further improve the quality of the solution xb, an greedy local search method is adopted to exploit the neighborhood of the current best solution called EliteLocalSearch. The main idea of EliteLocalSearch is to remove an item from the knapsack and put another outside item into the knapsack for every possible pairwise items. As far as xbis concerned, each pairwise element which contains distinct value 0 or 1 is interchanged for a higher profit. Providing that new achieved vector is a feasible solution and has better fitness value than the previous one through swap operation, then new vector will substitute for old one. This swap operation continues until all pairwise positions are examined. The algorithm is outlined as Algorithm 2 and an experiment is implemented to verify the effectiveness of this method in Section 4.Algorithm 2EliteLocalSearch procedure.Input:a current best solution xbOutput:an improved solution xb1:for i=1 to d do2:for j=1 to d do3:if (i!=j andxib!=xjb)4:x=swap(xb, i, j) //exchange the ith and jth elements of the solution vector5:if (fitness(x)>fitness(xb))xb=x6:end if7:end for8:end for9:returnxb.The flowchart of BAAA is illustrated in Fig. 4. As can be seen in the flowchart, each algal colony has certain energy. How far the algal colony moves or how many times it moves in one generation (iteration) is determined by its energy. Along with the iteration, energy of each algal colony is updated in proportion to the size of algal colony Siand transformed into a value between 0 and 1. The purpose of transformation is to make the energy values comparable and easy to handle in a controlled scope. Each movement of algal colony consumes some energy. Under the drive of energy, algal colony moves several times to a new position and achieves a new size until the energy is exhausted. After all algal colonies use up their energy, the helical movement ends and is followed by the evolutionary process and adaptation. This process is described in Algorithm 3 with details. In Algorithm 3, there are three loops. The outer loop controls the times of iteration, while the middle loop deals with each algal colony of population and the inner loop is the energy loop which controls the movement of algal colony until its energy is used up. Each movement consumes eloss or eloss/2 energy which depends on whether this movement achieves better result.Algorithm 3Binary artificial algae algorithm.Input:c, p, bOutput:the maximized profit of knapsack1:define n, sf, eloss, Ap2:initialize population of algal colony xiand repair xi,i=1, 2, …, n3:starvationi=0,i=1, 2, …, n4:while (t<Tmax)5:calculate energy Eiand friction surface ωiaccording to size of xi,i=1, 2, …, n6:for i=1 to n do7:isstarve=true8:while (Ei>0 and t<Tmax)9:calculate j through tournament selection method10:choose distinct k, l, m randomly between 1 and d11:produce α, β, p randomly where α and β are in the range [0,2π], p is between −1 and 112:xim=xim+(xjm−xim)(sf−ωi))p13:xik=xik+(xjk−xik)(sf−ωi))cosα14:xil=xil+(xjl−xil)(sf−ωi))sinβ15:discretize and repair xi16:Ei=Ei−eloss/217:if (new fitness value of xiis better than old one)18:accept xiand update corresponding fitness value19:isstarve=false20:else21:Ei=Ei−eloss/222:end if23:t=t+124:end while25:if (isstarve) starvationi=starvationi+126:end for27:the rthdimension of smallest algal colony is replaced by that of biggest one, where r is selected randomly between 1 to d28:if (Ap>rand)29:select the most starving algal colony xs, and xs=xs+(biggest−xs)*rand30:discretize and repair xs31:end if32:best=findBest(x)33:ebest=eliteLocalSearch(best)34:end while35:return ebestIn order to verify the effectiveness and robustness of the proposed BAAA algorithm for optimization problems, BAAA is evaluated on the well-known MKP benchmarks which come from the OR-Library.11OR-Library (Download on 2015-7-6): http://www.brunel.ac.uk/~mastjjb/jeb/orlib/mknapinfo.html.The benchmark datasets are divided into two groups: low-dimensional knapsack problems and high-dimensional knapsack problems. The first group totally has 54 instances including “Sento”, “Hp”, “Pb”, “Pet”, “Weing” and “Weish”, in which the number of decision variables (d) ranges from 10 to 105 and the number of constraints (m) ranges from 2 to 30. The second group covers 10 medium-scaled problems and 30 large-scaled problems with 500 items and 5 constraints. Among the latter 30 instances, three tightness ratios exist which are 0.25, 0.50 and 0.75, respectively. For the sake of clarity, the instances are named as cb.m.d-s_n, where m is the number of constraints, d is the number of items, s is the tightness ratio and n is the index of instances. The control parameters in BAAA are predefined for all runs. The shear force sf is set as 2, energy loss eloss is 0.3, and the adaptation probability Apis 0.5. The size of population is experience-based which is set as 100. In fact, too small size decreases the diversity of population, while too big size increases the computation complexity and leads to memory overflow. As can been seen in Algorithm 3, the parameter Tmaxcontrols the maximum number of iterations. Based on our extensive numerical experience, Tmaxis set to be 35,000. However, it does not mean that the algorithm iterates so many times. The algorithm terminates in many other situations. Firstly, in the inner loop t increases itself as algal colony moves until its energy is used up or iteration variable t reaches Tmax. Secondly, since the optimal solutions Opt are available, the algorithm terminates once the Opt has been obtained.The proposed algorithm is implemented in C++ within Microsoft Visual Studio 2010 using a PC with Intel Core (TM) 2 Duad CPU Q9300 @2.5GHz, 4GB RAM and 64-bit Windows 7 operating system. The point-estimator of digits is studied in [37]. Here we will use standard truncation method to report numerical results. If the error between the true optimal and that of obtained by our algorithm is less than 10−8, we say that our algorithm has successfully found the solution.As mentioned above, the selection of τ is a key step for the balance of search ability between exploitation and exploration. To clarify the influence of τ on BAAA, a comparison test is implemented using different τ on the instance Sento1 which has 60 items and 30 constraints. The comparison results are depicted in Figs. 5–7. In the experiment, ten different τ between 0.1 and 3.5 are used in the algorithm for 30 independent runs. BAAA with Tanh(x) and Sig(x) are named as BAAA-Tanh and BAAA-Sig, respectively. The comparison is performed based on three performance measures: average iteration number (AIT), average fitness value (AVG), and success rate (SR). AIT reflects the speed of finding optimal solution. It is worth to mention that AIT only indicates the number of running the outer loop in BAAA. SR indicates the ratio of the number of finding the optimal solution and the total running times (30). From Figs. 5–7, we can observe that based on the function Tanh(x), BAAA obtains best result when τ is 1.5 in terms of AIT, AVG and SR. As far as function Sig(x) is concerned, best results are obtained when τ is 2. The comparison results confirm that too small or too large values of τ can downgrade the performance of algorithm. Figs. 5–7 depict the variations of AIT, AVG and SR in terms of τ, respectively. Based on these observations, we set τ as 1.5 and 2 for BAAA-Tanh and BAAA-Sig, respectively, in the following experiments.Moreover, it is clear that BAAA-Tanh performs much better than BAAA-Sig in all respects. The success rate of BAAA-Tanh almost reaches 100%, except for the two smallest values of τ, whereas BAAA-Sig cannot achieve 100% success rate no matter what τ is. For further analysis, more comprehensive and complex comparisons between BAAA-Tanh and BAAA-Sig are implemented on more datasets which include 24 instances. The results are illustrated in Table 1. Through running 30 times of two algorithms on each instance, and we can observe that BAAA-Tanh outperforms BAAA-Sig. BAAA-Tanh obtains optimal solutions in 18 instances out of 24 instances with 100% success rate, whereas BAAA-Sig fails to achieve 100% success rate in 9 instances. In addition, SR of BAAA-Tanh is much higher than that of BAAA-Sig even if it can not reach 100%, and BAAA-Sig can not succeed in finding optimal solution at all in “Pet6” instance. The responding AVG prefers BAAA-Tanh in the same way, since BAAA-Tanh obtains higher average fitness values than BAAA-Sig. According to the comparison results, Tanh(x) is applied in BAAA for further tests.In BAAA, repair operators play a significant role in improving the maximal profit of the knapsack. The DROP and ADD operators utilize the ranked pseudo-utility ratios to discard and receive items. Eqs. ((22)–(24)) present three pseudo-utility ratios:δi¯,δi˜and δi, i.e. profit/weight utility, relative profit density and relative mean resource occupation. In order to verify the effects of the three pseudo-utility ratios on the algorithm, an experiment is conducted and the results are depicted in Figs. 8–11. Standard deviation (SD) and SR are considered to measure the performance of algorithm with different pseudo-utility ratios. The tests are based on 54 instances and each instance is solved by 30 times. The instances from weish1 to weish17 are left out in Fig. 11 where all runs are able to find optimal solutions at 100% success rate. From these figures, it is difficult to confirm which one is more appropriate than others. In terms of SR,δi¯fails to find optimal solutions at 100% success rate for 11 instances, whileδi˜and δiare 8 and 6, respectively. It seems that δiperforms better, but its success rates are 0 for “Pet6” and “Pet7” and the success rates are very low only about 0.1 for “Hp2”, “Pb2” and “Weing7”. As far as SD is concerned,δi˜obtains less SD thanδi¯and δifor “Hp1”, “Pet6”and “Pet7”. However, in other cases it is not true. In general,δi˜and δioutperformδi¯, and each has its own strong point. We adopt relative profit density in BAAA to compare with other swarm-based algorithms.Elite local search is a greedy local search method which can improve the solution quality significantly. However, it may take more computational cost for its greedy character to search better neighbors. In order to gain insight into its effect on the algorithm, a comparison experiment is implemented on 10 hard problems which have 100 items and 10 constraints. Considering elite local search is a built-in feature of BAAA, BAAA without elite local search is named as BAAA-noelite. The Comparative results based on 100 independent runs are shown in Table 2. SR denotes the ratio of the running times reaching the best-known value of 100 runs. AT is the average computational time (in seconds). It is quite clear that BAAA obtains better AVG and higher SR than BAAA-noelite. However, AT denotes BAAA costs more computational time than BAAA-noelite, because extra computation is needed to complete elite local search.In order to verify the superiority of the algorithm, BAAA is further compared with other population-based algorithms, including the modified binary particle swarm optimization algorithm (MBPSO [20]), particle swarm optimization with time-varying acceleration coefficients (BPSOTVAC and CBPSOTVAC [29]), genetic algorithms with double strings (GADS [16]), binary artificial fish swarm algorithm (bAFSA [25]) and improved binary artificial fish swarm algorithm (IbAFSA [24]). Table 3summarizes the comparison among MBPSO, BPSOTVAC, CBPSOTVAC and BAAA based on four different performance criteria, namely, SR, average error (AE), mean absolute deviation (MAD) and SD. AE is calculated as the average of the difference between the values and corresponding optimum solutions. Whereas MAD is the average of the absolute difference between the values and their mean. The data of MBPSO, BPSOTVAC and CBPSOTVAC are collected from original literatures. For the sake of consistency, 100 independent runs of BAAA are carried out for 48 instances. The experimental results show that BAAA performs much better than other three algorithms in terms of SR except for “Hp2”, “Weish23” and “Weish24”. It is worth mentioning that BAAA finds optimal solutions for all the instances and succeeds at 100% success rate for 42 instances. AE, MAD and SD are the measures to evaluate the stability of the algorithms from different angles. Based on the observation from Table 3, most values of AE, MAD and SD obtained by BAAA are less than corresponding values obtained by other three algorithms. In general, BAAA is superior to MBPSO, BPSOTVAC and CBPSOTVAC in terms of effectiveness and robustness.The comparison with other bio-inspired algorithms are further carried out. Table 4indicates the experimental results of GADS, IbAFSA and BAAA in terms of AIT, AIT*, Nopt, AT and ASR. AIT is the average iteration number, and AIT* is the average iteration number only considering successful runs. Nopt is the number of instances which optimal solutions are found at least one time from 30 runs. AT is the average computational time (in seconds). ASR is the average of the success rate (in %) of all instances in one set. For a fair comparison, we run BAAA 30 times independently like other two algorithms. As far as AIT and AIT* are concerned, the iteration times of our proposed BAAA are smaller than those of GADS and IbAFSA. However, BAAA is not always superior to other algorithms in AT because of the different computational complexity of each iteration in different algorithms. Considering Nopt, except for GADS, they are able to solve all instances to optimality at least one time out of 30 runs. Meanwhile, the ASR of BAAA is greater than or equal to those of other algorithms in “Pb”, “Pet”, “Sento” and “Weing”.In order to verify the stability of our algorithm, BAAA is compared with HHS [23], ABHS [31] and NGHS [32] in terms of AVG, Min.Dev, Ave.Dev and Var.Dev. Min.Dev is the minimum percentage deviations from best-known values. Ave.Dev denotes the average percentage deviations from best-known values. Var.Dev represents the variance of the deviations. The experiment is based on a medium-scaled instances which have 100 items and 10 constraints. For consistency with other algorithms, the algorithm is run 20 times independently for each instance. The comparative results are shown in Table 5. From Table 5, we can confirm BAAA is stable in obtaining acceptable solutions because BAAA can achieve minimal Min.Dev, Ave.Dev and Var.Dev, although AVG of BAAA is sometimes inferior to that of HHS.To further reveal the performance of BAAA, we test BAAA on large-scaled problems which have 500 items and 5 constraints with different tightness ratios. The simulation results are compared with those of state-of-the-art algorithms: SACRO-BPSO-TVAC and SACRO-CBPSO-TVAC [30]. This is because [30] is published in the recent and the method in [30] shows its superior to many existing algorithms. Table 6summarizes the comparative results based on 30 independent runs. We can observe from the results that BAAA performs better than SACRO-BPSO-TVAC and SACRO-CBPSO-TVAC in terms of best obtained value (BEST) in 23 out of 30 instances. BAAA performs worse than SACRO-BPSO-TVAC or SACRO-CBPSO-TVAC in 6 instances in terms of BEST, and the results of instance ‘cb.5.500-0.50_5’ are not available in the reference [30] which are denoted as ‘-’. With respect to AVG and SD, BAAA outperforms SACRO-BPSO-TVAC and SACRO-CBPSO-TVAC clearly. In summary, in contrast to other algorithms, BAAA is more robust and competitive in low-dimensional problems as well as high-dimensional problems.Furthermore, a non-parametric test, Wilcoxon signed-rank test (W-test) is carried out to determine whether the results from BAAA and those from other algorithms have significant difference or not. Table 7shows the Wilcoxon signed-rank test results on AVG of BAAA against other algorithms, including ABHS, NGHS, HHS, SACRO-BPSO-TVAC and SACRO-CBPSO-TVAC. R− or R+ is the sum of ranks based on the absolute value of the difference between sample data from two algorithms. R− indicates the sum of the ranks corresponding to the negative difference and R+ indicates the sum of the ranks corresponding to positive difference, respectively. pValue is significant difference between the AVG values of two algorithms, which is calculated by the software SPSS statistics 22. A null hypothesis is assumed that there is no significant difference between the two samples and an alternative hypothesis is assumed that there is a significant difference between the two samples, at 0.05 significance level. According to the relationship between pValue and 0.05 significance level, we obtain the result which is represented by three signs: “+”, “−” or “≈”. “+” or “−” denotes the first algorithm is significantly better or worse than the second one, i.e. there is a significant difference. And “≈” denotes there is no significant difference between the two algorithms. It can be seen from Table 7 that BAAA is superior to ABHS, NGHS, SACRO-BPSO-TVAC and SACRO-CBPSO-TVACGA, and nearly equivalent to HHS.

@&#CONCLUSIONS@&#
In this paper, a binary artificial algae algorithm is proposed for solving MKPs. Two logistic functions with different coefficients of curve are studied in discrete process. Three types of pseudo-utility ratios are presented and compared as well for repair operation so as to increase the efficiency of BAAA. In addition, an elite local search is introduced into our algorithm to improve the quality of solutions. Comparing with the existing algorithms, our algorithm is more robust and achieves better numerical performance. The comparisons of BAAA with other bio-inspired state-of-the-art algorithms available in the literatures are carried out with total of 94 benchmark problems. The numerical experiments demonstrate that BAAA is efficient and competitive comparing with the binary versions of the HS, PSO, GA and AFSA. Further research will focus on improving the model structure of AAA to decrease the computational efforts. Moreover, to extend the proposed algorithm for general purposes, BAAA must be applied in other binary test problems, especially in real applications, such as project scheduling and resource allocation.