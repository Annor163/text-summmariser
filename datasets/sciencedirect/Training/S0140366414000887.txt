@&#MAIN-TITLE@&#
Reciprocity, fairness and learning in medium access control games

@&#HIGHLIGHTS@&#
A new notion of reciprocity in a medium access game is introduced and the corresponding Nash equilibrium is derived.It has been shown that this type of reciprocity can remove unfair/inefficient equilibrium solutions.The best response learning method for the reciprocity game framework is studied and simulated.The game converges to the unique Nash equilibrium if the nodes have low collision costs or high psychological sensitivity.For symmetric games the converged Nash equilibrium turns out to be the fair strategy.

@&#KEYPHRASES@&#
Medium access games,Nash equilibrium,Fairness,Learning,

@&#ABSTRACT@&#
In wireless communication systems users compete for communication opportunities through a medium access control protocol. Previous research has shown that selfish behavior in medium access games could lead to inefficient and unfair resource allocation. We introduce a new notion of reciprocity in a medium access game and derive the corresponding Nash equilibrium. Further, using mechanism design we show that this type of reciprocity can remove unfair/inefficient equilibrium solutions.The best response learning method for the reciprocity game framework is studied. It demonstrates that the game converges to the unique and stable Nash equilibrium if the nodes have low collision costs or high psychological sensitivity. For symmetric games the converged Nash equilibrium turns out to be the fair strategy.

@&#INTRODUCTION@&#
Using game theory to investigate the performance of medium access control (MAC) protocols have resulted in interesting insights. Game theory allows us to incorporate a variety of behaviors of the wireless nodes into the MAC design. One of these is the notion of reciprocity. The notion of reciprocity implies that users are neither selfish nor altruistic all the time. Rather, “they are nice to those who are nice to them, but mean to people who harm them”. A corresponding property is fairness that is also dealt with in our analysis. One of the main results we derive is that reciprocity changes the best response dynamics of the game and renders bad Nash equilibria to become unstable.A homo reciprocan model for medium access control is investigated in [1] where one notion of fairness is considered. In [2,10], the effect of compassion is studied. Game theory has been used to analyze opportunistic radio networks in [3]. Packet collisions when multiple user transmit simultaneously usually provides an incentive for selfish behavior [6]. User can selfishly cheat in a MAC game, for example, an user may not respect the random exponential backoff in CSMA/CA by adjusting the contention window arbitrarily to its minimum size. In this paper, we introduce the notion of Rabin’s fairness Nash equilibrium [4] to analyze a medium access control game model with reciprocity. In our model, users have an incentive to punish selfish behaviors that allows them to avoid unfair equilibrium under certain conditions.In [7], analysis of the fundamental equilibrium properties of the one shot random access game model is provided. It is observed that all centrally controlled optimal solutions are subsets of this game solution. This is extended in [8] to characterize the existence of uniqueness of Nash equilibria.The transient network behavior and iterative game strategies are the focus of the studies in [9–12]. Effect of reciprocity on transient network behavior is studied in [9] using the notion of conjectural equilibrium. The operating points of the throughput region are shown to be conjecture equilibria. Dynamic altruistic behavior in Aloha random access game and its effect on altruistic behavioral stability is studied in [10].We note that the idea of reciprocity is a “moral” correlation device that can help the medium access protocol to avoid bad equilibrium solutions. We also discuss methods to achieve good equilibrium solutions with respect to collision cost and psychological sensitivity of users. We show that an intervening mechanism designer [5] can remove the undesirable network equilibrium of MAC games by affecting the channel collision probability. The contributions of this paper are different from some of the previous works. For example, we address reciprocity in normal form MAC games while [9] addresses dynamic reciprocity. Moreover, the notion of reciprocity in [9] is different in that their addressed equilibrium is a conjectural equilibrium while we study the Nash equilibrium. One shot random access games studied in [7,8] do not consider fairness. Also unlike [8], our proposed learning mechanism converges to the unique stable Nash. Also in the symmetric game the converged Nash of our best response learning is the fair strategy while the best response in [8] does not guarantee to achieve the fair Nash.The paper is organized as follows. In Section 2 we discuss the standard medium access game model. Reciprocity and fairness in these games are presented in Section 3. In Section 4 a best response learning method has been presented. Simulations and numerical results are presented in Section 5. Concluding remarks are given in Section 6.Let’s consider a set of wireless nodes denoted byI={1,2,…,N}contending for spectrum opportunities. If user i transmits successfully it obtains an utilityus, if the transmission fails the utility isufand waiting for a spectrum opportunity leads to an utility equal toubs.t.us>ub>uf. Let the random spectrum access utility vector for user i be denoted by the vector notation (usi,ubi,ufi). Then the random access gameGis defined by the tupleG=〈I,{pi}i∈I,{ui}i∈I〉, wherepi∈[0,1]is the node transmission probability or the mixed strategy of the ith node in the game. Let us denote the channel access probability vector of the users byp=(p1,…,pN). Then the gameGis said to be in the standard form if the utility vectors are in the form ofui=(1,0,-θi), whereθi>0is the cost of packet failure for user i.Definition 2.1A channel access probabilityp∗is said to be a Nash equilibrium if no node can improve its payoff by unilateral deviation, i.e.ui(pi∗,p-i∗)⩾ui(pi,p-i∗),∀pi.Two games are equivalent to each other if they have the same Nash equilibria. It can be shown that any random access game is equivalent to a standard random access game by selectingθi=ub-ufus-ub[8]. Therefore, we have considered the standard random access games for simplicity.Assume wireless nodes or players 1 and 2 are contending for the available spectrum. Then for the chosen strategies of transmit (T) or buffer (B) they receive payoffs according to the matrix M in Table 1. It can be easily shown that this game has two pure Nash equilibria, namely,(T,B),(B,T)and one mixed strategy equilibrium11+θ,11+θ. The pure equilibria are not desirable here since in this case one user is transmitting and the other is buffering all the time. Fairness property of the mixed strategies [13] suggests the mixed strategyσis the focal equilibrium of the random access game.Since the probability that at least one user other than user i also transmits is given by(1)qi(p-i)=1-∏j≠i(1-pj).the expected utility of user i playing the random access game with strategypis(2)ui(pi,p-i)=pi[-θiqi(p-i)+(1-qi(p-i))]which can be written as(3)ui(pi,p-i)=pi(1+θi)∏j≠i(1-pj)-θi1+θip∗is a Nash equilibrium, if and only if for alli∈I, the followings hold true [8]:(i)pi∗=1if∏j≠i(1-pj∗)>θi1+θipi∗∈(0,1)if∏j≠i(1-pj∗)=θi1+θipi∗=0if∏j≠i(1-pj∗)<θi1+θiConsider a two-player game in normal form(S1,S2,π1,π2)where, fori=1,2,Si={T,B}is the set of actions for player i andπi(s1,s2)is the payoff for player i according to the payoff matrix M wheresi∈Siand another player j, selectssj∈Sj. LetΔ(Si)denote the set of mixed strategies of player i. For each mixed strategy vectorσi=(σi(T),σi(B))∈Δ(Si),∑si∈{T,B}σi(si)=1whereσi(si)denotes the probability that player i will select the actionsi∈Si. Then(4)πi(σi,σj)=∑si∈{T,B}∑sj∈{T,B}πi(si,sj)σi(si)σj(sj)is the expected payoff for player i.Fairness Nash formulation [4] suggests that users engage in a type of reciprocal fairness, i.e. users are neither selfish nor altruistic all the time. Rather, “they are nice to those who are nice to them, but mean to people who harm them”. Therefore modelling the reciprocity of nodes in a medium access game can be done using the following model. For each(σj∈Δ(Sj), let(5)Π(σj)≡{πi(σi,σj),πj(σj,σi)}Π(σj)is the set of pair of payoffs by both players. Let valuesπjh(σj)andπjl(σj)denote the highest and lowest values that are Pareto efficient inΠ(σj), and the equitable payoff is(6)πje(σj)=πjh(σj)+πjl(σj)2Letπjmin(σj)be the worst possible payoff for player j in the setΠ(σj). The first step to incorporate fairness into the analysis is to define a sort of “kindness” function f which measures how kind players are being to each other. From previous payoff regions, the kindness function can be defined as the following.Definition 3.1Suppose player i selects actionsi∈Siand believes that player j selects the mixed strategyσj∈Δ(Sj). Then, player i’s kindness to player j is(7)fi(si,σj)=πj(σj,si)-πje(σj)πjh(σj)-πjmin(σj)πjh(σj)≠πjmin(σj)0OtherwisePlayer i’s belief about how kind player j is to him given it’s belief that player j is playing the mixed strategyσj∈Δ(Sj)is given by(8)fj̃(σj,σi)=πi(σi,σj)-πie(σi)πih(σi)-πimin(σi)πih(σi)≠πimin(σi)0OtherwiseIn order to incorporate fairness into the payoffs, each user maximizes a convex combination of his material and psychological payoff as shown in (9). Suppose player i believes that player j is playing the mixed strategyσj∈Δ(Sj)and furthermore i believes that j believes that i is playing the mixed strategyσi∈Δ(Si)then i’s expected payoff from playing the pure strategysiis given by:(9)Ui(si,σj,σi)=(1-α)πi(si,σj)+αfj̃(σj,σi)[1+fi(si,σj)]whereα∈(0,1)represents the psychological sensitivity.Definition 3.3(σ1F,σ2F) is a fairness equilibrium if fori=1,2,j≠i,(10)σiF(si)>0⇒Ui(si,σjF,σiF)⩾Ui(si′,σjF,σiF)∀si′∈SiTheorem 3.1There exits a collision costθso that the pure Nash equilibria of the reciprocity random access game shifts to(B,B)and(T,T).The proof follows by using the following definitions and Lemma 3.1.□A strategy pair(s1,s2)∈(S1,S2)is a mutual-max outcome if, fori=1,2,j≠i,si∈argmaxs∈Siπj(s,sj)A strategy pair(s1,s2)∈(S1,S2)is a mutual-min outcome if, fori=1,2,j≠i,si∈argmins∈Siπj(s,sj).An strategy pair(s1,s2)∈(S1,S2)is strictly positive (negative) if, fori=1,2fi>0(fi<0)Note that(B,B)and(T,T)are respectively the strict mutual-max and mutual-min of the random access game with payoff matrix M. Then the rest of the proof is the direct result the following Lemma.For any strategy pair(s1,s2)that is either a strictly positive mutual-max outcome or a strictly negative mutual-min outcome there exits a suitable selection of payoff matrix such that(s1,s2)is a fairness equilibrium.As the result of this we observe that a designer can adjust the price of collision to shift the pure Nash equilibria of random access game to(B,B)and(T,T).This means that mechanism designer can easily trigger a punishment phase by setting an appropriate pricing policy. However our focus in this work is on mixed strategies.The kindness functions (7) and (8) use the Pareto efficient points to provide a reference point to measure how kind players are to each other. Notice that in our random access game model the stationary steady state strategies have been addressed and in fact the payoff matrix M is used to arrive at the suitable region for a mechanism designer. Therefore it is enough to consider the Pareto efficient region of a random access model where each user payoff is derived asσi(T)∏j≠i(1-σj(T))without considering the payoff matrix M.Lemma 3.2The Pareto boundary of a random access throughput region(r1,…,rn)whereri(σ)=σi(T)∏j≠i(1-σj(T))can be achieved by probability vectorσ=(σ1,…,σn)when(11)∑iσi(T)=1In Table 2the kindness parameters are set up for random access games. The vector notation forσiandσjhas been replaced by easier scalar notation ofσi(T)=pandσj(T)=qto make the formulas more tractable. Using Lemma 3.2 we can see that for a two player gamep=1-qis in the Pareto region. By substituting this in the parameters defined previously:(12)fi(T,q)=πj(q,T)-πje(q)πjh(q)-πjmin(q)=-1/2-θ2(1+θ)qq>θ1+θ0q=θ1+θ-1/2-(1+θ)q2θq<θ1+θ(13)fi(B,q)=πj(q,B)-πje(q)πjh(q)-πjmin(q)=-12+1+θ/2(1+θ)qq>θ1+θ0q=θ1+θ12+1-(1+θ)q/2θq<θ1+θ(14)fj̃(q,p)=πi(p,q)-πie(p)πih(p)-πimin(p)=-12-qp+1+θ/2p(1+θ)p>θ1+θ0p=θ1+θ+12+1θ-(p/2+q)(1+1/θ)p<θ1+θFor(p,q)to be an equilibrium the following equations need to be satisfied:(15)Ui(T,q,p)-Ui(B,q,p)=0(16)Uj(T,p,q)-Uj(B,q,p)=0The expected utility that user i achieves is then:(17)Ui(p,q)=pi(Ui(T,qi(p-i),pi)+(1-pi)Ui(B,qi(p-i),pi)This can be written as the following using (9):(18)Ui(p,q)=pi[(1-α)(πi(T,qi(p-i)-πi(B,qi(p-i))+αf-ĩ(qi(p-i,pi)(fi(T,qi(p-i)-fi(B,qi(p-i))]+(1-α)(πi(B,qi(p-i))+αf-ĩ(qi(p-i,pi)(1+fi(B,qi(p-i)))To address selfish behavior we use the following definition for unfairness in random access games.Definition 3.7A mixed Nash strategyp∗=(p1,…,pn)is unfair when the following is satisfied:(19)∃is.tpi<θ1+θ,qi(p-i)>θ1+θIn other words player i considers itself as kind and others as unkind. We call the set of unfair mixed strategies the unfair region. In the unfair region:(20)Ui(p,qi(p-i)=pi(1-α)(1-(θ+1)qi(p-i))+α(12+1θ-p2+qi(p-i)1+1θ-1-1qi(p-i)-αθ+12θ12+1+θ/2(1+θ)qi(p-i)It is easy to notice thatpi=0andq(p-i)=1is a specific case of unfairness. In fact this is the most unfair equilibrium. In the next theorem we show that there exists a suitable adjustment over the collision cost and psychological sensitivity (θ,α), that allows the most unfair mixed strategy to be made unstable.Theorem 3.2The most unfair equilibrium does not belong to the set of Nash equilibria in a reciprocity random access game ifθ1+θ⩽α.To analyze the behavior of a user in an unfair region we use (20). Since(21)∂2Ui(pi|qi(p-i))∂pi2=1+1qi(p-i)1+1θ>0Uiis strictly convex. Therefore a local minimum exists, it is unique and it should belong to[0,θ1+θ). To prove the theorem it is enough to show that∂Ui(pi|qi(p-i)=1)∂pi|pi=0⩾0. This condition can be done by solving the following for(θ,α):(22)∂Ui(pi|qi(p-i)=1)∂pi|pi=0⩾0⇒α⩾θ1+θ□In fact the previous equilibrium shows how reciprocity removes the most unfair equilibrium in random access games. Moreover this selection of parameters(θ,α)yields(23)∂2Ui(pi|qi(p-i))∂qi(p-i)∂pi|pi=0>0It means that the best response of user i in the unfair region is to increase the probability of transmission (or decrease the contention window size) with the increase in the number of collisions. This result can be utilized by a mechanism designer (base station) to change the network equilibrium by modifying the collisionqi(p-i)=1-∏j≠i(1-pj)(1-p0)through probability of dummy transmissionsp0. By dummy transmissions we mean that the BS transmissions are used to control the perceived channel collision probability of users and not for any communication. In the next theorem the removal ofpi=1,q(p-i)=1as the most inefficient Nash equilibrium is proved.Theorem 3.3The most inefficient equilibrium does not belong to the set of Nash equilibria in a reciprocity random access game ifθ1+θ⩾α.The proof is similar to the previous proof. By consideringpi>θ1+θandqi(p-i)>θ1+θwe get:(24)∂Ui(pi|qi(p-i)=1)∂pi|pi=1≤0⇒α⩽θ1+θThis removespi=1,qi(p-i)=1as the reciprocity Nash equilibrium. □Observation 3.1: From Theorems 3.2 and 3.3 we observe that to remove the most inefficient and most unfair Nash equilibrium it is required thatα=θ1+θ. This means to have a suitable design that removes both highly inefficient and highly unfair equilibrium at the same time the designer should hit the numberθexactly at a single point which is practically impossible. However this reciprocity model enables the mechanism designer to shift the network solution toward efficient and fair regions depend on the network situation. It provides users with incentive to punish the selfish behaviors, a characteristics the classic random access game is deprived of.In the previous game theoretic analysis we addressed the single shot reciprocity medium access games. It was shown how reciprocity can empower the MAC games to remove the unfair/inefficient Nash equilibria. However it is not clear whether any Nash equilibrium exits for the game or not. If there exist any Nash equilibria, is it unique and does any simple learning mechanism exist that can converge to it? In this work we study the best response mechanism as the simplest strategy update mechanism. It is known that there are no general convergence results for classical random access games using these dynamics. We study how the introduced reciprocity element affects the learning dynamics.In a practical multi player scenario users do not have the knowledge of each other collision costsθ. Therefore let’s relax the assumption on the psychological utility of each useri,fj̃(σj,σi)[1+fi(si,σj)]by removing the collision costs of other nodesθ-ifrom the utility formulation. Also in order to ease the formulation let’s replace the reciprocity (psychological) utility term by polynomial expression ofpi(αiqi-12pi). In this way ifαiqi<pithen psychological utility of user i get increased by reducing the transmission probability stating the “Be nice to those who are nice to you” rule of reciprocity. Ifαiqi>pithen the psychological utility of user i get increased by increasing the transmission probability stating the “Be mean to people who harm you” rule of reciprocity. Therefore we end up with the utility formulation of the following for each user i,(25)ui(pi,qi)=pi[1-(1+θi)qi]+piαiqi-12pi,∀iwhere the first term in the RHS of (25) is the materialistic utility (2) and the second term is the psychological utility.Considering the fact that the only information available for any wireless node i at the stage t is the previous channel collision probabilityqit-1the best response strategy update of the user i at the stage t will be as the following:(26)pit=argmaxpiui(pit,qit-1)=[1-(1+θi-αi)qit-1,1]01where the operator[x]01=max(min(x,1),0)Then the distributed best response learning mechanism follows the steps in Algorithm 1.Algorithm 1. Distributed best response learning algorithm for reciprocity random access1: Initialization:t=0, the transmission probability vectorpt∈[0,1]n, the collision cost vectorθand the psychological sensitivity vectorα,i∈{1,…,n}.2: procedure3: Locally at each node i, iterate though t4: Sett←t+1.5:For alli∈{1,…,n}do6: Estimate the previous stage channel collision probability,qit-1=1-∏j≠i(1-pjt-1)7: Update the mixed transmission strategypit=[1-(1+θi-αi)qit-1]018:end for.9: Node i decides to transmit with a probabilitypitat stage t.9: end procedure.Theorem 4.1Regardless of any initial transmission vectorp0Algorithm 1 converges to a unique Nash if∀i∈{1,…,n},∑j≠i(θj-αj)<2-nwhere n is the number of wireless nodes.To show this we need to construct the Jacobian matrixJn×n≔(Ji,j)of the best response dynamic of (26) as:(27)Ji,j=∂pit∂pjt-1=0,ifi=j(1+θi-αi)∏k≠i,j(1-pkt-1),otherwise.That is,Jis the matrix of slopes of the best response functions of each player with respect to the strategies of other players.If‖J‖∞<1for the best response dynamic the game converges to a unique Nash.Lemma 4.1 implies if the sum of the absolute values of the off-diagonal elements in theJbe less than 1 in each row or in each column then Algorithm 1 achieves a unique Nash. Then Using (27) and Lemma 4.1 it yields that if∀i∈{1,…,n},∑j≠i(1+θj-αj)<1. In another way,∀i∈{1,…,n},∑j≠i(θj-αj)<2-nthe best response dynamic converges to the unique Nash equilibrium.Theorem 4.1 has two interesting results in terms of the stability and the fairness of MAC games:First introducing reciprocity in MAC framework can help the random access games to achieve a unique Nash and therefore a stable equilibrium if the nodes acquire either small collision costs or high psychological sensitivity.Second in a symmetric game where all nodes have the same collision costθand psychological sensitivityα, the game can reach a unique fair mixed equilibrium via the simple best response mechanism.In the next chapter section we illustrate our assertions by conducting several simulations.In Fig. 1a, we see that the best response dynamic of a symmetric two player reciprocity random access game changes with the observed collision probabilityqi(p-i). Beyond the fairness threshold, the best strategy is to increase the transmission probability with the increase in the perceived channel collision probabilityqi(p-i). Moreover a mechanism designer can change the network equilibrium by affectingqi(p-i). Fig. 1b shows the effect of suitable adjustment(θ,α)on the instability of Nash equilibria. Fig. 2a and b demonstrate the removal of bad equilibrium with the previously mentioned adjustmentα=θ1+θ. These simulations validate the results of Theorems 3.2 and 3.3. Figs. 3 and 4are simulated for networks of 5 and 10 nodes respectively. For simplicity it is assumed thatαi=1,∀i. The best response learning of Algorithm 1 is used. It is known that if the best response dynamics reach a steady state, then this state is a Nash equilibrium. As can be seen in Fig. 3a the best response of the nodes converges to a unique Nash equilibrium. Theorem 4.1 indicates the existence of the unique Nash equilibrium if∀i,∑j≠iθj<1. Fig. 3 a shows that the game converges to a unique Nash equilibrium even for a wider range ofθ, independent of the initialization. This is because Theorem 4.1 provides the sufficient condition for convergence to a unique Nash equilibrium but not the necessary condition. However, for increasing magnitude ofθthe game does not converge. In Fig. 3b we observe oscillation between pure strategies. This is because given a psychological sensitivity, with the increase in the collision cost users have less incentive to punish the unfair strategies and the unfair equilibria will not be eliminated. It is interesting to note that in the symmetric case of Fig. 3a, all nodes converge to the fair transmission strategy independent of the initial conditionsp0.The simulations with the heterogeneous case ofθare shown in Fig. 4a and b. The results are the same as the symmetric case except that users with low collision cost end up with the higher transmission probability equilibrium. Fig. 4a is simulated for a larger network of 10 nodes with collision cost vector ofθ=(0.4,0.4,0.6,0.6,0.8,0.8,0.9,0.9,1,1). As it can be seen those who have the same collision costs end up with the same transmission probability. Also similar to the homogeneous case observations, for larger collision cost values the best response learning does not converge as it can be seen in Fig. 4b.

@&#CONCLUSIONS@&#
