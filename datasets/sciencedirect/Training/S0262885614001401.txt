@&#MAIN-TITLE@&#
The effects of temperature variation on videometric measurement and a compensation method

@&#HIGHLIGHTS@&#
This paper proposed a compensation method for eliminating the effects of temperature variation in the long duration application of image vision.A model of the relationship between the camera parameters and temperature variations is established with the system identification method.Experiments are carried on. The analyses and experiments demonstrate the feasibility and efficiency of the proposed method.

@&#KEYPHRASES@&#
Vision,Measurement,Temperature,Video,Experiment,

@&#ABSTRACT@&#
When a videometric system operates over a long period, temperature variations in the camera and its environment will affect the measurement results, which cannot be ignored. How to eliminate or compensate for the effects of such variations in temperature is an emergent problem. Starting with the image drift phenomenon, this paper presents an image-drift model that analyzes the relationship between variations in the camera parameters and drift in the coordinates of the image. A simplified model is then introduced by analyzing the coupling relationships among the variations in the camera parameters. Furthermore, a model of the relationship between the camera parameters and temperature variations is established with the system identification method. Finally, several compensation experiments on image drift are carried out, using the parameter–temperature relationship model calibrated with one arbitrary data set to compensate the others. The analyses and experiments demonstrate the feasibility and efficiency of the proposed method.

@&#INTRODUCTION@&#
Computer vision technology has developed rapidly in recent years and is now in widespread use. Combined with traditional photogrammetry and optical measurement, the discipline named videometrics, or vision measurement, has been established. Where photogrammetry mainly processes static pictures, videometrics focuses on sequence images. Therefore, videometrics can be used to obtain both 3D static information on an object and 3D dynamic information in time and space.Establishing and calibrating the camera imaging model [1,2] is a fundamental task. Apart from research on self-calibration technology [3–5] and zoom lens camera systems [6,7], most work is based on a static camera model, which means that once the camera is calibrated, the camera model parameters remain constant. However, this is not the case when the working temperature varies over a wide range, especially for long-term movement and deformation measurement. On the one hand, the volume or length of different parts of the system (including the sensors, lens and supportive installation structures) will increase due to thermal expansion effects as the temperature rises, and vice versa. On the other hand, the refractive index of the optical material in the lens will change with the variation in the temperature [8–10], which leads to changes in the focal distance and optical axis.Errors caused by environmental variations are generally unacceptable when videometrics is used for high-accuracy measurements. For example, measuring the deformation of large architectures such as ships, subways, tunnels, bridges and dams [11,12] using videometrics requires high-accuracy measurements over a long time duration, which inevitably involves changes in the environmental temperature. Therefore, research is urgently needed on the influence of temperature variations and how to eliminate their effects.Research in this field is scarce and there is no mature and applicable method. Some studies [13–15] have reported that the image drifts by as much as a tenth of a pixel during the camera's warm-up period. P. Podbreznik and B. Potočnik [16,17] have proposed a simple model for eliminating the measurement errors caused by changes in temperature in specific conditions. However, the model is based on the assumption that when the temperature changes, only the translations of the camera need to be considered, whereas the intrinsic parameters and the pose of the camera remain unchanged. Hence, its application and accuracy are limited. Handel investigated the influence of camera warm-up on the imaging process and the corresponding compensation methods [18,19]. In his model, the center of projection should be fixed or the intrinsic parameters of the cameras should remain constant. In fact, changes in the temperature cause thermal expansion of all components in the camera system and the optical properties of the lens, especially the refractive index. Therefore, the assumptions of the model are inaccurate.To resolve the problems caused by temperature variations over long periods, this paper deduces an image drift model and a simplified model that analyzes the relationship between the variations in the camera parameters and the drift of the coordinates. Then, a model of the relationship between the camera parameters and temperature variations is established with the system identification method. Finally, several compensation experiments on image drift are carried out, which demonstrate the feasibility and efficiency of the proposed method. The method does not need any specific assumptions, and hence is more all-purpose.In Section 2, a central projection model and the image drift phenomenon are introduced. An image drift model is deduced in Section 3, which refers to the mathematical relations between drifts in the measured image coordinates and variations in all of the camera parameters. Then, by analyzing the coupling relationships between these variations, a simplified image drift model is deduced in Section 4. In Section 5, the relationship between variations in the camera parameters and temperature variations is established, which is used to compensate for the image drift in the experiments. Finally, some conclusions are summarized.To analyze the effects of temperature variation on videometrics and establish the image drift model, we first introduce the camera imaging model — a central projection imaging model — adopted in this paper, and then design an experimental setup to validate the relationship between temperature variation and the image drift model.This paper adopts a central projection camera model (also called as pin-hole model). For an arbitrary 3D point P, there is a relationship between the coordinates PC(XC, YC, ZC) in the camera coordinate system and coordinates PW(XW, YW, ZW) in the global coordinate system, shown as(1)PC=RPW+t,where R and T, respectively, are the rotation matrix and translation vector transformed from the world coordinate system to the camera coordinate system. R is a 3×3 orthogonal matrix with three independent variables, which can be expressed in several ways. In this paper, an Euler angle expression is adopted. Suppose that Ax, Ayand Azare the Euler angles rotating around the X, Y, Z axis in sequence, then R(Ax, Ay, Az) can be expressed as(2)⁢cos⁡Ay⁢cos⁡Az⁢sin⁡Ax⁢sin⁡Ay⁢cos⁡Az−cos⁡Ax⁢sin⁡Az⁢cos⁡Ax⁢sin⁡Ay⁢cos⁡Az+sin⁡Ax⁢sin⁡Az⁢cos⁡Ay⁢sin⁡Az⁢sin⁡Ax⁢sin⁡Ay⁢sin⁡Az+cos⁡Ax⁢cos⁡Az⁢cos⁡Ax⁢sin⁡Ay⁢sin⁡Az−sin⁡Ax⁢cos⁡Az−sin⁡Ay⁢sin⁡Ax⁢cos⁡Ay⁢cos⁡Ax⁢cos⁡Ay.The 3D point PC(XC, YC, ZC), in the camera coordinate system and its corresponding homogeneous image coordinates p(u, v, 1) have the relationship(3)ZCp=KPC,where K is the camera's intrinsic parameter matrix, shown as(4)K=fu0u00fvv0001,where fu=f/dx and fv=f/dy, f are the focal lengths, and dx and dy are the pixel's physical width and height, respectively. Therefore, fuand fvdefine the effective focal lengths of the camera along the two axes, and (u0, v0) are the coordinates of the principal point, which are referred to as intrinsic parameters. The following equation can then be obtained from Eqs. (1) and (3):(5)ZCp=KRPW+Kt.The experimental setup shown in Fig. 1is adopted to analyze the effects of temperature variations on the image coordinates. The optical axis of the camera and the plane grid plate are fixed almost vertically, which is the case in most practical applications. In Fig. 1, C represents a camera with a resolution of 2448×2048pixels; the target G is an aluminum plate with 7×7 uniformly spaced grid points and 100mm×100mm grid space, as shown in Fig. 2. The camera is calibrated using Zhang's method [2]. Two temperature sensors — TCam and TGrid — are fastened on the camera body and the plate target, respectively, with temperature measurement precision of 0.1°C. The distance between the camera and the plate target is about 5m, and the field of view of the camera is about 1000mm×840mm with a 50mm focal length lens.With the experimental setup shown in Fig. 1, the camera continuously takes images of the target plane grid plate, and a sub-pixel extraction algorithm is adopted to obtain the feature point coordinates accurately. Temperature variations also bring thermal noise of CCD sensor, which often behaves as the gray level change of the pixel. In this experiment, each cross marker consists of many pixels, so that the position of the cross marker can be detected using sub-pixel location method which eliminates the thermal noise of CCD sensor to a great extent. The sub-pixel location method can reach a high accuracy prior to 0.1pixels. The ambient temperature is changed by turning on and off the air-conditioner. A drift in the measured image coordinates, which is very similar to lens distortion, will occur. Fig. 3shows the image drift when the ambient temperature increases by 6°C. The circles () in the figure refer to the original feature point coordinates, and the crosses () refer to the feature point coordinates after the temperature change. Because the drifts are so slight that the vectors constructed by the original coordinates and their corresponding coordinates hardly change, the plots are magnified 500 times when we plot them in the figure. The following figures containing circles () and crosses () are all processed using this magnification. The black rectangle refers to the size of the camera image. The original image drift is shown in Fig. 3(a), which can be represented by the average image drift and the relative image drift, as shown in Fig. 3(b) and (c) respectively.The image drift shown above could be caused either by variations in the camera parameters or change of the feature-point coordinates on the grid plate target. The plane grid plate target has a thermal expansion effect when the temperature changes, which can be measured by the linear thermal expansion coefficient, defined as(6)αL=1LdLdT.The linear expansion coefficient of aluminum is about 23×10−6/°C at room temperature. Variations in the size L and changes in the temperature ΔT can be estimated as(7)ΔL=αL⋅ΔT⋅L.We construct the global coordinate system on the center of the plane grid plate target, and the XY plane of the coordinate system is on the grid plate, as shown in Fig. 1. For an arbitrary 3D point P located on the grid plate target, the global coordinates can be denoted by PW(XW, YW, 0). The relation between the coordinates of a homogeneous image p(u, v, 1) and its corresponding 3D point can be expressed in Eq. (5).A temperature change will cause small variations in the intrinsic and exterior parameters of the camera and the feature points on the plate target. If we denote the changed intrinsic parameter matrix, rotation matrix, and translation vector asK˜,R˜, andt˜respectively, the changed global coordinates of the feature point areP˜WX˜WY˜W0, the corresponding coordinates in the camera coordinates system areP˜CX˜CY˜CZ˜C, and its varied homogeneous image coordinates arep˜u˜v˜1, then the following equation can be obtained:(8)Z˜Cp˜=K˜R˜P˜W+K˜t˜.Suppose that the variation in the Euler angle vector can be expressed as δA(δAx,δAy,δAz), the variation in the translation vector as δt(δtx,δty,δtz), the variation in the intrinsic parameter matrix as δK, the variation in ZCas δZC, and the variation in the image point coordinates u and v as δu and δv, respectively, then:(9)K˜=K+δK(10)R˜=R⋅δR(11)t˜=t+δt(12)Z˜C=ZC+δZC(13)u˜=u+δuv˜=v+δv,where(14)δK=δfu0δu00δfvδv0000.Variations in the feature point PWon the plate grid target can be denoted as δPW(δXW,δYW,0)(15)P˜W=PW+δPW.Assume that the linear expansion coefficient of the grid is αLand a change in the environmental temperature is ΔT, following Eq. (7), we obtain(16)δXW=αL⋅ΔT⋅XWδYW=αL⋅ΔT⋅YW.Substituting Eqs. (9)–(15) into Eq. (8), the following equation can be obtained:(17)ZC+δZCuv1+δuδv0=K+δKR⋅δR⋅PW+δPW+K+δKt+δt.Subtracting Eq. (5) from Eq. (17), and omitting the high-order infinite decimals give(18)ZCδuδv0+δZCuv1=KRδR−IPW+δK⋅PC+K⋅δt+KR⋅δPW,where I is the identity matrix and PC is the coordinate vector of the feature point in the camera coordinate system, which can be obtained by PW from Eq. (1).Assuming that δAiis small, sin(δAi)≈δAi, and cos(δAi)≈1 (i=x,y,z), by substituting them into the rotation matrix expression (2) and omitting the high-order infinite decimals, we can obtain δR as the following matrix:(19)δR=1−δAzδAyδAz1−δAx−δAyδAx1.Clearly, the anti-symmetric matrix δR−I=⌊δA⌋× is the cross-product matrix corresponding to the Euler angle vectorδA=δAxδAyδAzT, and the following can be obtained under the characteristics of the cross-product matrix:(20)δR−IPW=δA×PW=δA×PW.Substituting Eq. (20) into Eq. (18),(21)ZCδuδv0+δZCuv1=fur1T+u0r3T⋅δA→×PWfvr2T+v0r3T⋅δA→×PWr3T⋅δA→×PW+δfuXC+δu0ZCδfvYC+δv0ZC0+fuδtx+u0δtzfvδty+v0δtzδtz+fur1T+u0r3T⋅δPWfvr2T+v0r3T⋅δPWr3T⋅δPW.Then, we obtain(22)δZC=r3T⋅δA→×PW+r3T⋅δPW+δtz,(23)ZCδu=fur1T−Δur3TδA→×PW+δPW+δfuXC+δu0ZC+δtxfu−δtzΔuZCδv=fvr2T−Δvr3TδA→×PW+δPW+δfvYC+δv0ZC+δtyfv−δtzΔv,where Δu=u−u0 and Δv=v−v0 are the image coordinates under the centered image coordinate system, which use the principal point (u0, v0) as the origin. Eq. (23) shows the relationship between the image drifts δu and δv and the variations in the camera's intrinsic and exterior parameters. The intrinsic parameters u0, v0, fu, and fvcan be obtained by camera calibration; the rotation matrix R and translation vector (tx, ty, tz) can be obtained by the pose estimation algorithm; and the variations δPWin the feature point can be obtained from Eq. (16).As Eq. (23) is still complicated, according to the triple scalar product,a⋅b×c=b⋅c×a=c⋅a×b=axayazbxbybzcxcycz,some terms in Eq. (23) can be further be simplified as follows:(24)riT⋅δA→×PW=δAxδAyδAzXWYW0ri1ri2ri3,i=1,2,3(25)riT⋅δPW=ri1δXW+ri2δYW,i=1,2,3.Furthermore, we can see that R≈I when the camera is facing straight toward the grid plate target in our experiment; in other words, the nine factors in the rotation matrix R have the following properties:(26)rij≈1,i=j0,i≠j.Substituting Eqs. (24)–(26) into Eq. (23) will result in the simplified equation(27)δu−δXWfuZC=δu0+δfuXCZC−δAxYWZCΔu+δAyXWZCΔu−δAzYWZCfu+δtxfuZC−δtzΔuZCδv−δYWfvZC=δv0+δfvYCZC−δAxYWZCΔv+δAyXWZCΔv+δAzXWZCfv+δtyfvZC−δtzΔvZC.For all n(n≥5) points on the grid, the following linear equations can be obtained:(28)10XiCZiC0−YiWZiCΔuiXiWZiCΔui−YiWZiCfufuZiC0−ΔuiZiC010YiCZiC−YiWZiCΔviXiWZiCΔviXiWZiCfv0fvZiC−ΔviZiCX=δui−δXiWfuZiCδvi−δYiWfvZiCwhereX=δu0,δu0,δfu,δfv,δAx,δAy,δAz,δtx,δty,δtzT.The variations in the intrinsic and exterior parameters can be obtained from the variations in the image coordinates by solving the above equations.Note that the model expressed in Eq. (28) contains 10 variations in the camera parameters; however, below we show that these variations are not independent, as some of them are coupled with each other [20,21]. To avoid the model being over-parameterized, it is necessary to simplify the model and eliminate the coupling.The simulations adopt the ideal parameters of the experimental devices shown in Section 2.2. Suppose that the principal point (u0, v0) is located in the center of the image, and the focal length is 50mm. The global coordinate system is established on the XY plane of the plate target, and the origin is on the central point of the plate target. The imaging point of the origin of the global coordinate system is set at the principal point by adjusting the camera holder. The distance between the camera and the plate target is about 5m.First, the original image coordinates pi(u, v) of the feature points can be obtained by substituting the parameters into Eq. (5), and the drifted image coordinatesp˜iuvcan then be obtained by slightly changing the parameters. They are plotted in the same figure, in which the circles and crosses refer to the original and drifted image coordinates, respectively.The simulated image drifts caused by increasing the intrinsic parameters of the camera are shown in Fig. 4(a)–(c), where one can see that variations in the effective focal lengths fuand fvlead to a zooming effect on the image, whereas variations in the principal point (u0, v0) lead to a displacement effect in the horizontal and vertical directions, respectively.Next, in Fig. 4(d)–(f) we show the simulated image drift caused by increasing or decreasing the translation vector of the camera.Comparing Fig. 4(b)–(e), it can be seen that the image drift caused by a change in tx(ty) is similar to that caused by a change in u0(v0), as both lead to horizontal (vertical) global displacement in the image. Comparing Fig. 4(a) with (f), it can be seen that the image drift caused by changing tzis similar to that caused by changing fuand fv, as both lead to zooming in the image. Therefore, variations in the translation vector and in the intrinsic parameters are coupled. If the translation vector and the intrinsic parameters vary slightly by an appropriate proportion at the same time, then the resulting image drifts will cancel each other out, as shown in Fig. 4(g) and (h).From the above simulations, we can see that of the 10 parameters (four intrinsic parameter variations, and six exterior parameters variations), δtx, δty, and δtzare coupled with δu0, δv0, δfu, and δfv. In fact, the same conclusion can be obtained by analyzing Eq. (27). Taking the coupling between δtxand δu0 as an example, their coefficient is fu/Zc and 1 separately. The focal length is 50mm and the dimension of a sensor cell is 3.45um, which means fu is about 14,500pixels, and fu/Zc is about 2.9. In Fig. 4(b), u0 increases by 1/3000, so δu0 is about 1024/3000=0.34; in Fig. 4(d), tx increases by 0.1mm, so δtxfu/Zc is 0.29. Their contributions to δu are similar in direction and magnitude, which indicates that their effects are coupled. The same analysis can be used to explain the coupling between other parameter variations. Therefore, only the first seven parameters in Eq. (27) are considered and the simplified image drift model is obtained as follows:(29)δu−δXWfuZC=δu0+δfuXCZC−δAxYWZCΔu+δAyXWZCΔu−δAzYWZCfuδv−δYWfvZC=δv0+δfvYCZC−δAxYWZCΔv+δAyXWZCΔv+δAzXWZCfv.If the relationship between the temperature variations and parameter variations in the image drift model can be calibrated, the parameter variations can be calculated from the temperature variations and the image drifts can be compensated. Next, we introduce the parameter–temperature relationship model established by the system identification algorithm [22].To validate the image drift model and model the dependency between variations in the camera parameters and temperature, we conduct experiments shown in Fig. 1. The setup is fixed in a laboratory equipped with an air-conditioning unit. Two thermal sensors are used to measure the temperature. The experiments can be divided into two stages: the warm-up stage after the camera start-up and the air-conditioning stage after the camera temperature being stabilized.Step1:Start up the camera and track the image coordinates of the feature points. It takes about 0.5–1h for the temperature of the camera body to become stable.Turn up the heat on the air-conditioner. Turn off the heating after 3h.Fig. 5shows the temperature changes in the camera body and the grid plate during the warm-up stage and during the air-conditioning stage. The variations in the camera's intrinsic and exterior parameters, calculated from Eq. (29), are shown as a solid line in Figs. 6 and 7.The relationship between variations in the camera parameters and variations in temperature can be quite complicated as it may be influenced by several factors, including the absolute temperature, temperature variations, the velocity of the temperature variations, and so on. How to choose one or more main factors and calculate the relationship between the camera parameters and the selected factors represents a complicated system engineering problem. This paper adopts the system identification algorithm [22] to solve this problem.The basic idea behind system identification is to select one mathematical model equivalent to the system from a set of mathematical models according to the “system equivalence rule” and the data produced by running or testing the system. Variations in the camera parameters depend not only on the current temperature variations but also on the data on historical temperature variations. Due to the limitations of the experimental conditions, calibration data with a wide frequency spectrum of temperature variations are not yet available. System identification follows the “parsimony principle”, thus the model with the fewest parameters and the simplest results should be chosen for any given condition. Figs. 6 and 7 show that there are notable correlations between variations in the camera parameters and variations in the temperature. Therefore, a black-box model can be considered for each variation in the camera parameters with the variation in temperature as input, and the model parameters can be estimated by the system identification algorithm.Based on the “parsimony principle”, a simple zero-pole-gain linear time invariant model with one zero and one pole [20] is chosen, with the transfer function(30)His=Ki1+bis1+ais,where Kirefers to the gain of the model, aiand biare the model parameters, and i=1,2, … 7 refer to the parameter–temperature relationship models corresponding to the seven parameters of δfu, δfv, δu0, δv0, δAx, δAy, and δAzrespectively.The unit pulse response to the transfer function shown in Eq. (30) is(31)ht=Kibiaiδt+Kibiai1bi−1aie−1ait.For the input signal ΔT(t), the system output can be obtained by convolution:(32)yt=ΔTt∗ht=∫−∞∞ΔTτht−τdτ.Simulated variations in the camera parameters using the estimated models and temperature data are plotted as dotted lines in Figs. 6 and 7.As shown in Figs. 6 and 7, variations in δfu, δfv, δu0, δv0 and δAzare simulated quite well during both the warm-up and the air-conditioning stages; however, there are some high-frequency characteristics for δAxand δAy. This is probably because the coefficients of δAxand δAyare relatively small, which indicates that they are sensitive to noise.Once the parameter–temperature relationship model is calibrated with the system identification algorithm, the variations in the camera parameters can be calculated from the variations in the temperature. The drift of the image point can then be calculated from the variations in the camera parameters, so that the image drift can be compensated. More than ten sets of experiments are carried out. All the experiments last about half a month. The air-conditioning stages are different with each other. Using a model calibrated by one arbitrary set of data to compensate the image drift in the other sets of data produces very similar results. Only one group of typical experimental results is reported below.The image coordinates of one feature point during the warm-up stage and the air-conditioning stage are plotted in Fig. 8. The dark crosses depict the original image drifts and the light spots depict the compensated image drifts, based on the simplified image drift model proposed in Section 4.2.Fig. 8 shows that the image drifts has been reduced from about 0.4pixel to 0.02pixel duration during the warm-up stage, and from about 1.6pixel to 0.6pixel during the air-conditioning stage. In fact, the major drifts are caused by variations in the principal points δu0 and δv0, which are less well modeled in the air-conditioning stage as shown in Fig. 7(c) and (d), so that the compensation effect is not as good during the air-conditioning stage as during the camera warm-up stage. Of course, the variations in the camera parameters during the air-conditioning stage are also stronger and more complicated than during the camera warm-up stage.Temperature variations affect videometric measurements taken over long time periods, which cannot be ignored. How to eliminate or compensate the effects of temperature variation is an emergent problem, especially in the long duration surveillance fields.Starting with the image drift model, this paper presents a model of the relationship between camera parameters and temperature variations using the system identification method. In the compensation experiments on image drift, the parameter–temperature relationship model calibrated with one arbitrary data set is used to compensate the other sets of data. During the air-conditioning stage, the image drifts can be reduced from about 1.6pixel to 0.6pixel after the compensation. The experimental results demonstrate the feasibility and efficiency of the proposed method, which proves a probable solution of the temperature effects during the long duration and high precious measurements.The findings thus provide an important foundation for applying videometrics in high-accuracy deformation measurements over a long period, although the method is still primary and will need to be improved with further experiments and analyses in the future.

@&#CONCLUSIONS@&#
