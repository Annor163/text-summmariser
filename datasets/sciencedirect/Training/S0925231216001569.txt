@&#MAIN-TITLE@&#
Assessing the effects of voluntary and involuntary eyeblinks in independent components of electroencephalogram

@&#HIGHLIGHTS@&#
Voluntary and involuntary eyeblink features obtained from all channels present significant differences in the delta band.Distorting effects have continued influence for 3.0–4.0s (in the occipital region, 2.0s).Eyeblink effects cease to exist after the zero-crossing four (in the occipital region, two) times, regardless of type.

@&#KEYPHRASES@&#
Eyeblinks,Electroencephalographic signals,Artifacts,Independent component analysis,Wavelet transform,

@&#ABSTRACT@&#
The effect of voluntary and involuntary eyeblinks in independent components (ICs) contributing to electroencephalographic (EEG) signals was assessed to create templates for eyeblink artifact rejection from EEG signals with small number of electrodes. Fourteen EEG and one vertical electrooculographic signals were recorded for twenty subjects during experiments that prompted subjects to blink voluntarily and involuntarily. Wavelet-enhanced independent component analysis with two markers was employed as a feature extraction scheme to investigate the effects of eyeblinks in ICs of EEG signals. Extracted features were separated into epochs and analyzed. This paper presents following characteristics: (i) voluntary and involuntary eyeblink features obtained from all channels present significant differences in the delta band; (ii) distorting effects have continued influence for 3.0–4.0s (in the occipital region, 2.0s); and (iii) eyeblink effects cease to exist after the zero-crossing four (in the occipital region, two) times, regardless of the type. Several characteristics are different between voluntary and involuntary eyeblinks in EEG signals. Therefore, any templates need both types of data for eyeblink artifact rejection if the EEG signals were obtained from small number of electrodes.

@&#INTRODUCTION@&#
Kaleidoscopic functional states of the cerebral cortex affected by neuronal activities (nerve firings) can be measured using an electrical non-invasive index, in the form of an electroencephalographic (EEG) signal. The EEG signal is the useful clinical tool for the diagnosis of psychiatric disorders such as schizophrenia and epilepsy, and for studying the functional states of the brain [1,2]. In addition, EEG signals have been widely used in brain-computer interface (BCI) systems that provide communication channels to people with severe motor disabilities [3,4]. Over the past three decades, the spatio-temporal event-related neural dynamics revealed from various experimentally manipulated events and interpretation of EEG signals have been developed to integrate dynamics with practical applications.The good conductivity of the scalp leads to contamination of recorded EEG signals with potentials generated from movement of the eyelid and/or the eyeball, which may affect on delta (0.5–4.0Hz), theta (4.0–8.0Hz), and alpha (8.0–13.0Hz) bands [5,6]. Eyeblink artifacts are extremely burdensome when investigating neuronal activities using EEG signals because the EEG spectrum is superimposed with the artifacts [7]. Furthermore, the amount of oscillating neuronal discharge (EEG potential) is generally lower than the artifact potential at each electrode [8]. The effects of eyeblinks on EEG signals depend on the orientation of the eyeball, the trajectory of the eyelid, the location of the electrode on the scalp, and the propagation path of the electric field across the head [9,10]. Although researchers are able to avoid the issue by giving an instruction that asks subjects to keep their eyes closed during the EEG measurement, any constructed system based on the research would be impractical in the real world because of the necessity of having users close their eyes while the system operates. In addition, the inhibition of eye movements or eyeblinks significantly distorts the neuronal activity [11]. Therefore, EEG signals should be recorded with the eyes open and without any constraints to allow investigation into intrinsic endogenous brain activities, even if the eyeblink artifactual contamination of the EEG signal cannot be avoided because of the structure of human body.Regression-based approaches include the well-known ocular artifact removal method for investigating plausible neuronal activities with the eyes open [12]. In this approach, propagation factors are calculated using linear least-square regression to estimate the relationship between the recorded electrooculographic (EOG) signals and the recorded EEG signals of each channel [13]. By subtracting the eyeblink artifact coordinated by the propagation factors, regression procedures remove eyeblink artifacts from each channel at a low computational cost. However, eyeblinks vary their amplitudes and durations according to the movement of the eyelid [14] and whether the blink occurs under voluntary or involuntary control [8,15]. For this property, the approximation performance of linear regression depends on the distribution of eyeblink amplitude and duration in the data set [16]. Furthermore, bidirectional contamination between EEG and EOG signals has been revealed; therefore, relevant cerebral information interfered with the EOG signal would also be canceled in the EEG signal corrected using a regression-based approach [17].Eyeblink artifacts observed in EEG signals have the following properties: (i) the influence of the artifact is attenuated with increasing distance from the eyes [18]; and (ii) the activity of the artifacts appears to propagate along the anterior–posterior axis in a symmetrical fashion [5,8]. On the basis of these properties, theoretically multivariate statistical analysis approaches such as principal component analysis and independent component analysis (ICA), which separate EEG signals into spatially and temporally distinguishable components, are useful for extracting EEG components from the scalp recordings [19,20]. In particular, ICA is a powerful tool for separating the recorded EEG signals into maximally independent activity patterns derived from cerebral or non-cerebral (artifactual) sources [21]. ICA-based approaches have shown an extraordinary ability to solve blind source separation problems using the assumption of independence among signal sources in each subject׳s data. These approaches have been used in a wide range of EEG signal processing procedures for the removal of eyeblink artifact components from recorded EEG signals [22] and the extraction of signals of interest to improve the overall performance [23], regardless of the distribution of blink amplitude and duration. In comparison with the regression-based approach, the ICA-based approach accurately eliminates eyeblink artifacts from EEG signals with less loss of cerebral information [24].A smaller number of electrodes (i.e., the single-electrode case would be an extreme case) should result in better practical applications in daily life. Single-channel ICA, which is an adaptation of ICA to single-channel signals, has been proposed [25]; however, the scheme does not always satisfy its assumptions in real-world applications. Therefore, proposing an eyeblink artifact removal scheme for a single-channel EEG signal is now a major challenge within EEG signal processing [26,27]. To avoid an inconsistency in separating components of a single-channel EEG signal that has overlapping frequency components, reference data helps experimental data to converge to the values of estimated sources in the aforementioned schemes. In addition, the presence of involuntary eyeblink artifacts in the target signal leads to a distorted signal after applying the reference-based scheme, because the reference is usually based only on voluntary eyeblink data. Although several research has analyzed the pattern of eyeblink artifacts to develop eyeblink artifact removal methods for multichannel EEG signals, the effect of involuntary eyeblinks on scalp EEG signals is still missing [22,28]. This study investigates the plausible effects of voluntary and involuntary eyeblinks on scalp EEG signals using multichannel ICA. Since recent studies have suggested wavelet-enhanced ICA algorithm is suitable for separating EEG signals into cerebral and non-cerebral sources [29], this study employed this method. Investigation of eyeblink artifacts under voluntary and involuntary control lead to development of more robust and more common references or training datasets based on the representative attributes for small number of channels in EEG analysis. Therefore, the objective of this paper is to characterize the effects of voluntary and involuntary eyeblinks on independent components (ICs) contributing to EEG signals by wavelet-enhanced ICA to create templates for eyeblink artifact rejection from a recorded EEG signal with a single-electrode.In this paper, EEG signals were recorded at 14 positions (Fp1, Fp2, F3, F4, T3, C3, Cz, C4, T4, P3, Pz, P4, O1, and O2) according to the 10–20 system. Active electrodes for EEG data were made of sintered Ag/Ag–Cl material (g.tec Medical Engineering GmbH, Austria) and their metallic tips were attached to the scalp. A vertical EOG signal was recorded from two surface Ag/Ag–Cl electrodes (Blue Sensor P, Ambu Corp., Denmark) placed at the superior and inferior orbital rims of the left eye. Reference and ground electrodes were placed at the left mastoid and Fz, respectively. The EEG and EOG data were band-pass filtered from 0.5Hz to 60Hz with a Butterworth filter and digitized at a sampling rate of 256Hz using g.USBamp. The first 5s of recorded data is discarded. All electrodes were pasted with an electrolyte, g.GAMMAgel, to reduce skin resistance.Twenty subjects (14 males and 6 females, mean age: 22.75±1.45 years, 14 right and 6 left eye dominants) participated in the experiments. No subjects had a history of sensorimotor, ophthalmologic, or auditory abnormalities. All subjects were asked to read and sign an informed consent approved by the Research Ethics Committee of Keio University prior to participating the study. None of the subjects were permitted to wear eyeglasses and all used canal-type earphones during the experiments.Each subject was seated in a dim room (mean illuminance: 188.95±24.50lx) in front of a laptop PC. The distance between subject and display was roughly 60cm and the third highest lightness-contrast was selected, while displaying a cross-fixation on the display. During the experiments, the subject׳s face was video recorded using a tablet PC fixed to the frame of the monitor. The experimental procedure was written in Matlab using the Psychophysics Toolbox extensions [30], as follows.An audio file (Windows Background.wav, 55.0dB), which is used as an alert sound (a beep) in the Windows 8.1 operating system was used to obtain voluntary eyeblink data. The task is simply to focus on a black cross-fixation in the center of the display and to blink with both eyes within 1s after the sound stimulus (seeFig. 1(A)). The simple auditory stimulus was repeated for this experiment to avoid interference with other eye-related potentials: (i) the occipital positive potential (the lambda wave) that is an evoked potential based on the changed visual stimulus, which typically occurs roughly 300ms after the onset of a blink [31]; (ii) the cerebral potential caused by the efference copy, which represents a process for anticipation of the change in the visual stimulus from the eye-movement [32]. In each of the experiments, the subject was instructed to blink naturally, in addition to the prescribed blinks, and not to blink stiffly or strongly, but instead, to simply react quickly. The datasets for each subject consist of 3 sessions. Each session includes 20 trials; the next session is started after a 60-s resting period to maintain ocular moisture. Whereas normal adults blink every 3.0s, a sound was presented every 5.0 or 6.0s in a randomized order. In short, subjects had to blink in a slightly unusual way. However, the presentation interval was deliberately decided (as mentioned above) because we experimentally found that the effects of eyeblink on EEG signals have continued their influence for 3.0–4.0s.Three sounds called “A” (440.0Hz, 55.0dB), “S” (554.0Hz, 55.0dB), and “D” (659.0Hz, 55.0dB) were prepared to obtain involuntary eyeblink data. One of the three sounds (in a randomized order) is presented for 1s after 10–14s. During the experiments, subjects put their left fingertips (the ring finger, the middle finger, and the index finger) on the “A”, “S”, and “D” keys of the keyboard (see Fig. 1(B)). The subject presses the key corresponding to the associated sound after the sound stimulus. Then, a feedback sound is presented to the subject in accordance with the answer. After 20 trials, the rate of correct answers is shown on the display. In each of the experiments, the subject was instructed to attempt to answer 90% of the total trials correctly and to fix their eyes at the central black cross-fixation. There were no other restrictions, meaning the subject could blink naturally (involuntarily). The datasets of each subject consist of 3 sessions.In this paper, the information maximization (infomax) ICA algorithm [19] is employed as the signal separation scheme to obtain ICs and relative projection strengths. Furthermore, double thresholds based on indexes of modified multiscale sample entropy (mMSE) and kurtosis are employed to automatically classify the ICs as either neuronal or artifactual. Then, the identified artifactual ICs are carefully purified using biorthogonal wavelets to extract eyeblink features from the recorded signals. Finally, the extracted features are used to assess the effects of voluntary and involuntary eyeblink on ICs contributing to EEG signals.ICA is the most popular scheme for separating multi-channel observed signalsx(n)=[x1(n),x2(n),⋯,xp(n)]Tinto statistically independent source signalss(n)=[s1(n),s2(n),⋯,sq(n)]T[20,21]. The observed signals are assumed to consist of signals that are linear combinations of unknown, and statistically-q-independent source signals. In addition, we assume that the number of independent sources is equal to or lower than the number,p, of observation signals. The ICA algorithm determines the mixing matrixMthat defines the weights with which each estimated source is present in the recorded EEG data.(1)x(n)=Ms(n),where the unknown mixing matrixMis a squarep×pmatrix. In this paper, the number of electrodes for EEG recording is 14; therefore,p=14. The matrix gives the relative projection strengths of the respective ICs to each of the scalp electrodes [17]. There are several kinds of ICA algorithm for accuracy improvement for source separation. In this paper, we apply the logistic infomax ICA algorithm that has been implemented using the runica function in the EEGLAB Matlab toolbox [33] with its default settings. This scheme separates the original signals into the same number of ICs (p=q=14).After ICA-based signal separation, each IC is suspended as an artifactual component and identified as an artifactual or neuronal IC using specific steps (visual inspection, thresholding, and so on). Then, intrinsic (non-artifact) EEG signals and artifacts are spuriously separated using the inverse ICA linear demixing process.ICA gives us the ability to investigate the plausible effects of eyeblink on recorded EEG signals based on the two assumptions described above and an assumption that propagation delays through the mixing medium (i.e., brain, scalp, and body) are negligible. Visual inspection of scalp topographies and correlation analysis of the IC that has the highest correlation with the recorded vertical EOG signal have been conducted for identifying the ocular artifacts in ICs from recorded EEG signals [34,35]. However, eyeblink artifacts are allocated to one or more ICs, meaning that the identification steps are sometimes not able to accurately select the correct components. This year, the issue was solved by combining ICA with a wavelet transform (WT) [36]. The new scheme automatically identifies artifactual components using double thresholds based on the indeces of mMSE and kurtosis.The index of mMSE is based on the concept of sample entropy, which is an index quantifying the regularity and complexity of data. Given the p-th estimated IC{s^p(n):1≤n≤Ns}by logistic infomax ICA that hasNsdata points, the following vector sequence is formed:(2)S^im={s^p(i),s^p(i+1),…,s^p(i+m−1)}−s^p0(i)(i=1,…,Ns−m+1),(3)s^p0(i)=1m∑j=0m−1sp(i+j),wheres^p0(i)and m are a baseline for generalization of the vector sequence and the maximum length of epochs for matching templates, respectively. The minimum length is set to 2 (i.e.,m=2). Despite the fact that the actual number of data points isN(25,600 to 31,920 in the Exp.1 and 51,200 to 71,680 in the Exp. 2), the first 10s of data (i.e.,Ns=2560) is used in this step.Then, the distance between two vectors is defined as(4)dijm=d[S^im,S^jm]=maxh∈(0,m−1)|s^p(i+h)−s^p0(i)−(s^p(j+h)−s^p0(j))|(i,j=1,…,Ns−m,j≠i),and the degree of similarity between vectors is defined using Eq. (2).(5)Dijm=f(dijm,r)=11+exp[(dijm−0.5)/r],where r is the tolerance or the slope of the Sigmoid function. In this paper, we set the value at0.2σs^p(r=0.2×σs^p). The input pattern assesses its belongingness to a given class using the continuous boundary, instead of the Heaviside function [37]. Furthermore, functions B and A, which are used to count m and (m+1) template matches within the tolerance, are defined as(6)Brm(i)=1Ns−m−1∑j=1,j≠iNs−mDijm,(7)Brm=1Ns−m∑i=1Ns−mBrm(i),(8)Arm(i)=1Ns−m−1∑j=1,j≠iNs−mDijm+1,(9)Arm=1Ns−m∑i=1Ns−mArm(i).Finally, index of mMSE is defined by using negative natural logarithm of deviation ofBrmfromArm,(10)mMSE(m,r)=limNs→∞(lnBrm−lnArm),(11)mMSE(m,r,Ns)=−ln(Arm/Brm).The index of mMSE with a 95% confidence interval (CI) of the mean in the Student׳s t-distribution is used for the threshold for detecting eyeblink artifactual ICs using the following equation:(12)Threshold1=mmMSE−σmMSENs×tNf,wheremmMSE,σmMSE, andtNfare the mean of mMSE, the standard deviation of mMSE, and the index in the t-distribution with 13 degrees of freedom (Nf=p−1). An artifactual IC is expected to have a value of mMSE that is less than that of a neuronal IC.One index of kurtosis is the fourth-order cumulant, which is used to characterize the location and variability of data and is a measure of whether the variables are peaked or flat relative to a Gaussian distribution.(13)kurtosisp=mp4−3mp22,(14)mpc=E{(s^p−mp1)c},wherempc,mp1and E are the c-th order central moment of the variable, its mean, and the expectation function of the p-th IC. In this paper, we calculated the kurtosis using the kurtosis function of Matlab for each IC. Eyeblink activities can be effectively detected by combining this index with mMSE because kurtosis is positive for peaked spasmodic activities [38]. Therefore, the index of kurtosis with a 95% CI for the mean is used for the threshold to detect eyeblink artifactual ICs based on the following equation:(15)Threshold2=mkurtosis+σkurtosisNs×tNf,wheremkurtosisandσkurtosisare the mean and the standard deviation of kurtosis.All of the ICs with mMSE and kurtosis values that are outside the double thresholds are identified as eyeblink artifactual ICs.There may be cases in which a contradiction occurs between the ICA assumption and the neural patterns of activation because neural networks are often overlapping (not independent). ICs presenting artifactual activities obtained from the stimulus-presenting analysis, especially in the event-related potential analysis, might have distinctive interfering neuronal activities in the components. Discarding all components will lead to loss of neuronal data in the ICA procedure. The wavelet-enhanced ICA algorithm uses wavelet thresholding of ICs as an intermediate step. This step allows recovery of substantial parts of the neural signal with artifacts and extraction of eyeblink artifactual components from identified artifactual ICs, all of which is done automatically [29]. All identified artifactual ICs are passed to the following thresholding procedure.1)The identified artifactual ICss^pare transformed into components of disjointed spectra (a matrix) instead of signals (vectors) via the discrete wavelet transform (DWT).2)If the wavelet coefficient W(a, b) of each levellis lower than the wavelet threshold, the coefficient will be set toW′(l,k)=0. The threshold value is defined asEnhanced eyeblink artifactual ICss^p′are reconstructed from the thresholded wavelet coefficientsW′(l,k)via inverse DWT.Fourteen-channel eyeblink artifacts in recorded EEG signals are reconstructed using the inverse ICA linear demixing process.Figs. 2(A) and 3(A) show an 8-s EEG signals that includes voluntary and involuntary eyeblinks from subject data measured at 14 scalp positions. 2 or 3 eyeblink artifacts appear on all channels; frontal positions (e.g., Fp1, Fp2, F3, and F4) show large eyeblink effects in the data. The ICA algorithm separated the contributions of neuronal and artifactual components into 14 ICs [Figs. 2(B) and 3(B)]. In this paper, each IC was classified as either artifactual or neuronal on the basis of double thresholds and indices of mMSE and kurtosis [Figs. 2(C) and 3(C)] and blink-origin components were extracted from the identified artifactual ICs via a wavelet threshold. The extracted eyeblink features [Figs. 2(D) and 3(D)] are used to assess the effects of voluntary and involuntary eyeblink on ICs contributing to EEG signals.As shown in the previous section, we obtained consecutive 14-channel eyeblink features for 20 subjects.Here, we also have consecutive vertical EOG signals. All channel features are separated into 4-s epochs to obtain time-locked data. The method for separating the epoch is determined from the vertical EOG signal. First, each recorded EOG signal passes through a Butterworth low pass filter whose cutoff frequency is 8.0Hz, so as to reduce the cerebral activities in the EOG signal [18]. Second, the first positive peaks of blinks in the filtered EOG signal are detected using a hard threshold. The threshold value was set to 50μV (common to all EOG signals). A value exceeding the threshold is compared to the adjacent 50 sampling points (roughly ±0.20s). In this paper, if the detected value is the highest in the range, the value is further classified as to whether it is an actual peak or not by visual inspection; then, it is identified as the first positive peak of the blink. Third, 14-channel eyeblink features and a vertical EOG signal are separated into 4-s epochs based on the point of maximum amplitude in the EOG data. The point is located at the 64th sampling point (i.e., 0.25s). An epoch, as defined above, is shown inFig. 4.In the Exp. 2, there is no restriction on the times and duration of blinks. Selecting an exemplary signal that has only a blink effect in its own epoch is needed to compare the voluntary eyeblink characteristics. However, it is difficult to control conscious eyelid motion, although each subject was instructed to blink only after cue presentation in the Exp. 1. Subject׳s eyelids sometimes quivered convulsively during motion execution; there were also instances in which two (or more) blinks were reflexively induced. Therefore, the identified epochs were carefully selected as a dataset to avoid contaminating other motions, e.g., eye movement and body motion based on video recordings and visual inspections [see Fig. 4(A)]. The number of voluntary and involuntary eyeblink epochs obtained from each subject and the total number of the epochs are presented inTable 1. The amounts of data are uneven, however, the numerical range of differences between voluntary and involuntary for each subject lies within ±10, except for three subjects (Sub. 01, Sub. 09, and Sub. 20).The eyeblink artifacts contributing to EEG signals are characterized with their respective epochs in the frequency-domain, time–frequency-domain, and time-domain. In this paper, we assessed the following three phenomena: (i) propagation effects across the head (in a symmetrical fashion); (ii) power distributions; and (iii) overlapping durations.In frequency-domain analysis, Welch׳s overlapped segment averaging estimator [39], implemented using the pwelch function in Matlab with a Hamming window, is performed to estimate the one-sided power spectral density (PSD). The window size, overlapping samples between adjoining sections, and number of discrete Fourier transform (DFT) points were set to 512, 256, and 512 (frequency resolution: 0.50Hz). The values of estimated PSD are averaged over the delta (0.5–4.0Hz), theta (4.0–8.0Hz), alpha (8.0–13.0Hz), and beta (13.0–30.0Hz) bands. Moreover, the relative power in each frequency band for 14-channel voluntary eyeblink features for 20subjects is separately compared with the relative power for involuntary eyeblink features.In time–frequency-domain analysis, grand means of eyeblink features are used to compute spectrograms, implemented using the spectrogram function. The window size, overlapping samples, and number of DFT points were set at 32, 16, and 256. The log-transformed power distribution and overlapping duration are investigated from the spectrograms.Finally, the duration of eyeblink effect in the ICs (overlapping duration of eyeblink artifacts in EEG signal), and peak amplitude value of 14-channel eyeblink features are separately computed to assess the effects of voluntary and involuntary eyeblinks on ICs contributing to EEG signals in time-domain analysis. The electrical potential caused by eyeblink will reduce its effects on EEG signals by reiteration of the positive–negative inversion, although the overall amount of discharge with eyeblink depends on the subject and the manner of eyelid/eyeball movement [14,40]. We experimentally found that the effects continue their influence for 3.0–4.0s. In other words, each electric potential caused by an eyeblink crosses the zero points several times after passing the first positive peak; then, the potential ceases to exist. Therefore, several zero-crossing points and potential peaks are analyzed for the characterization of eyeblinks. The number will be determined in the time–frequency-domain analysis.

@&#CONCLUSIONS@&#
In this paper, the effect of voluntary and involuntary eyeblinks on ICs contributing to EEG signals was characterized for creating templates of eyeblink artifact rejection from recorded EEG signals with small number of electrodes. Fourteen EEG signals and one vertical EOG signal were recorded for twenty healthy subjects during two different experiments, which prompted subjects to blink voluntarily and involuntarily. Wavelet-enhanced ICA with two markers (mMSE and kurtosis) was employed as a source-separation and feature-extraction scheme. The extracted eyeblink features were separated into epochs and analyzed in the frequency, time–frequency, and time domains.The extracted eyeblink features confirmed three characteristics reported in the literature: (i) the distorting effects of eyeblink artifacts on the EEG are within the delta and theta bands; (ii) electric potentials (dipole projections) caused by eyeblinks decrease with increasing distance between measurement points and eyes; and (iii) the propagation effects across the scalp present in a bilaterally symmetrical fashion. Furthermore, additional characteristics were found: (i) eyeblink features obtained from all channels presented significant differences between voluntary and involuntary; (ii) eyeblink effects continue to have an influence on EEG signals for 3.0–4.0s (in the occipital region, 2.0s); and (iii) these effects cease to exist after the zero-crossing point four (in the occipital region: two) times, for both eyeblink types.Eyeblink artifactual contamination, which inevitably occurs with EEG applications, should be rejected from recorded EEG signals to allow precise diagnosis and system construction. The differences among the effects of voluntary and involuntary eyeblink in EEG signals were shown in this paper. The datasets used in this study is freely available (http://u4ag2kanosr1.blogspot.jp/). These results and dataset are helpful for making templates of eyeblink artifact rejection from recorded EEG signals with small number of electrodes. Finally, we hope the heuristic development of more robust and more common references and training data based on the representative attributes for small number of channels in EEG analysis and encourage the practical use of EEG applications in daily life.Conceived and designed the experiments: SK. Performed the experiments: SK. Analyzed the data: SK. Wrote the paper: SK, MN, and YM.