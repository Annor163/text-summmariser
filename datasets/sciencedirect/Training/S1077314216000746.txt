@&#MAIN-TITLE@&#
Model effectiveness prediction and system adaptation for photometric stereo in murky water

@&#HIGHLIGHTS@&#
Different models for Photometric Stereo in murky water are evaluated considering realistic imaging conditions.A system with dynamic lighting is proposed that predicts the validity of a photometric model without prior knowledge of the scene geometry.The optimal light position is adapted according to the scenario.

@&#KEYPHRASES@&#
Underwater vision,Photometric stereo,Illumination,

@&#ABSTRACT@&#
In murky water, the light interaction with the medium particles results in a complex image formation model that is hard to use effectively with a shape estimation framework like Photometric Stereo. All previous approaches have resorted to necessary model simplifications that were though used arbitrarily, without describing how their validity can be estimated in an unknown underwater situation. In this work, we evaluate the effectiveness of such simplified models and we show that this varies strongly with the imaging conditions. For this reason, we propose a novel framework that can predict the effectiveness of a photometric model when the scene is unknown. To achieve this we use a dynamic lighting framework where a robotic platform is able to probe the scene with varying light positions, and the respective change in estimated surface normals serves as a faithful proxy of the true reconstruction error. This creates important benefits over traditional Photometric Stereo frameworks, as our system can adapt some critical factors to an underwater scenario, such as the camera-scene distance and the light position or the photometric model, in order to minimize the reconstruction error. Our work is evaluated through both numerical simulations and real experiments for different distances, underwater visibilities and light source baselines.

@&#INTRODUCTION@&#
Consider a robotic platform operating in a murky sub-sea environment, equipped with light sources and a camera to illuminate and image the scene in front. Imaging and scene understanding in this scenario is challenging for two reasons: (a) light from the sources is backscattered toward the camera reducing image contrast severely, and (b) light reaching the scene and reflected back to the camera is weak and results in dark (and noisy) scene appearance.Feature-based methods such as Structure-from-Motion are effective in mapping large areas in clear water [14]. However, they fail to perform reliably in murky maritime environments due to the strong image degradation that de-features the captured images and dictates special post-processing [28].Photometric approaches on the other hand attempt to model the cause of image degradation and develop algorithms for scene reconstruction. However, the image formation model in murky water is complex and non-linear, making it hard to use effectively with a shape estimation approach such as Photometric Stereo (PS). For this reason all photometric approaches [15,21,23,38,39] have resorted to approximations to keep the problem tractable. For example, often the scene is assumed to be distant enough that inverse-square law can be ignored and that backscatter does not vary with distance, or the scene is assumed to be close enough that backscattering can be ignored.The above photometric model simplifications are very effective when applied in the appropriate scenarios. But it is hard for a robotic platform exploring an unknown environment to know a priori which assumptions are valid. Blindly applying a model simplification is very likely to result in poor scene reconstruction. Fig. 1shows the Photometric Stereo images of a barrel using an ROV in real murky port water, and the reconstruction results using the method of [38] as the vehicle was navigating toward the target. Being too far decreased the SNR severely as the backscatter dominated the dynamic range of the sensor and the reconstruction was poor. Being too close also yielded errors, since the photometric model neglected the strong non-uniform illumination on the scene. Since the scene was unknown, it was hard to predict which distance was more effective, or if another photometric model or light source position could have been more successful.In this work, we propose an effective approach for reasoning about the validity of such photometric models when the scene is unknown. To achieve this, we use a dynamic lighting framework where a robotic platform is able to probe the scene with varying light positions. This approach is based on a simple idea: if the photometric model is wrong for a particular scenario, the estimated surface normals will be erroneous and, more importantly, the error will vary significantly as the light source positions are varied with respect to the camera. On the other hand, if the photometric model is correct, the estimated surface normals will not vary as the source positions are varied.In short, we obtain a faithful proxy for the true reconstruction error by estimating the change in surface normals under different light source positions. For example, when the source is close to the camera, backscatter is strong and any algorithm that ignores this produces worse shape estimates. But, as the source is moved away (even a short distance), the backscatter reduces [10] and the same algorithm produces better normal estimates. Our proposed dynamic lighting framework offers significant potentials to Photometric Stereo in murky water. The ability to approximate the reconstruction error can be used to adjust automatically: (a) the camera-scene distance, (b) the light position, and (c) the photometric model, in order to maximize the reconstruction quality.We perform extensive numerical simulations where we mimic realistic scenarios underwater with different medium, distance, and system characteristics. Then, we present a real robotic platform in murky water navigating toward the scene of interest which can move the lighting fixtures along a mechanical arm. We demonstrate our system in the controlled environment of a big water tank, where the platform explores an unknown object for different distances, light positions and scattering levels, and we compare our results with the reconstruction from a depth sensor [24].

@&#CONCLUSIONS@&#
In this work, we evaluated the effectiveness of different photometric models in murky water considering several factors that are critical in realistic imaging conditions (model validity, camera SNR, light source baseline, distance, scattering etc.). We showed that the reconstruction error depends strongly on the imaging conditions and for this reason we presented a simple way for predicting the effectiveness of a photometric model when the scene and the environment are unknown. The effectiveness of our method lies on the observation that the change in estimated surface normals under different light source positions reflects the true error due to an invalid photometric model or noise due to low SNR.Our methodology still assumed that some information is a-priori known or calibrated, such as the incident illumination vector on the object centroid. This can be easily estimated using a sonar or laser beam sensor [23], or using uncalibrated methods that have been suggested for pure air [2,9,34]. The goal of our work was to focus on the photometric model validity in murky water, rather than on its final optimization. In future work, our framework can be used to evaluate totally uncalibrated methods.Approximating the model’s effectiveness using our dynamic lighting system offers significant potentials to Photometric Stereo in murky water. Specifically, some critical parameters that were chosen arbitrarily in previous works, such as the scene depth, the light baseline and the photometric model, can be adapted automatically to an unknown imaging scenario. Additional photometric models could be evaluated through our framework, such as forward or multiple scattering [10,11,20,23], or models which assume different illumination profiles for the light sources such as [21] which neglects shadow volumes in the medium or [26] which models non-isotropic sources.Supplementary material associated with this article can be found, in the online version, at 10.1016/j.cviu.2016.03.002.Supplementary Data S1Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/