@&#MAIN-TITLE@&#
Analyzing respiratory effort amplitude for automated sleep stage classification

@&#HIGHLIGHTS@&#
We propose 12 novel features to capture properties of respiratory depth and volume for respiratory effort-based sleep stage classification.We evaluate the discriminative power of each feature for multiple-stage classification and single sleep stage detections.Calibrating the respiratory effort signal with quantified body movements can increase the feature discriminative power.The new features can help significantly improve sleep stage classification performance.The classification results outperform some previous studies and they are comparable to those with additional cardiac activity.

@&#KEYPHRASES@&#
Respiratory effort amplitude,Signal calibration,Feature extraction,Sleep stage classification,

@&#ABSTRACT@&#
Respiratory effort has been widely used for objective analysis of human sleep during bedtime. Several features extracted from respiratory effort signal have succeeded in automated sleep stage classification throughout the night such as variability of respiratory frequency, spectral powers in different frequency bands, respiratory regularity and self-similarity. In regard to the respiratory amplitude, it has been found that the respiratory depth is more irregular and the tidal volume is smaller during rapid-eye-movement (REM) sleep than during non-REM (NREM) sleep. However, these physiological properties have not been explicitly elaborated for sleep stage classification. By analyzing the respiratory effort amplitude, we propose a set of 12 novel features that should reflect respiratory depth and volume, respectively. They are expected to help classify sleep stages. Experiments were conducted with a data set of 48 sleepers using a linear discriminant (LD) classifier and classification performance was evaluated by overall accuracy and Cohen's Kappa coefficient of agreement. Cross validations (10-fold) show that adding the new features into the existing feature set achieved significantly improved results in classifying wake, REM sleep, light sleep and deep sleep (Kappa of 0.38 and accuracy of 63.8%) and in classifying wake, REM sleep and NREM sleep (Kappa of 0.45 and accuracy of 76.2%). In particular, the incorporation of these new features can help improve deep sleep detection to more extent (with a Kappa coefficient increasing from 0.33 to 0.43). We also revealed that calibrating the respiratory effort signals by means of body movements and performing subject-specific feature normalization can ultimately yield enhanced classification performance.

@&#INTRODUCTION@&#
According to the rules presented by Rechtschaffen and Kales (the R&K rules) [1], human sleep is comprised of wake, rapid-eye-movement (REM) sleep and four non-REM (NREM) sleep stages S1–S4. S1 and S2 are usually grouped as “light sleep” and S3 and S4 correspond to slow-wave sleep (SWS) or “deep sleep” [2]. The gold standard for nocturnal sleep assessment is overnight polysomnography (PSG) which is typically collected in a sleep laboratory. With PSG, sleep stage is manually scored on each 30-s epoch throughout the night by trained sleep experts, forming a sleep hypnogram [1]. PSG recordings usually contain multiple bio-signals such as electroencephalography (EEG), electrocardiography (ECG), electrooculography (EOG), electromyography (EMG), respiratory effort, and blood oxygen saturation.Respiratory information has been widely used for objectively assessing human nocturnal sleep [3–5]. Detecting sleep stages overnight is beneficial to the interpretation of sleep architecture or monitoring of sleep-related disorders [6,7]. Cardiorespiratory-based automated sleep stage classification has been increasingly studied in recent years [8–12]. Some of those studies only made use of respiratory activity because, when comparing with it cardiac activity is relatively more difficult to be captured reliably in an unobtrusive manner [10,11]. For respiratory activity, in comparison with the breathing ventilation acquired with traditional devices such as nasal prongs or face mask [13], respiratory effort can be obtained in an easier and more noninvasive or unobtrusive way, e.g., using a respiratory inductance plethysmography (RIP) sensor [14], an infrared (IR) camera [15], or a pressure sensitive bed-sheet [16].Several parameters have been derived from respiratory effort signals for sleep analysis including respiratory frequency, powers of different respiratory spectral bands [8], respiratory self-similarity [11], regularity [17] etc. These parameters are usually called “features” in the tasks of epoch-by-epoch sleep stage classification. In addition, it has been reported that the respiratory amplitude (e.g., depth and volume) differs between sleep stages [4]. For instance, the “respiratory depth” is more regular and the tidal volume, minute ventilation, and inspiratory flow rate are significantly lower during REM sleep than during NREM sleep (particularly during deep sleep) [18,19]. To the authors’ knowledge, these characteristics that express different physiological properties across sleep stages have not been explicitly elaborated and quantified for applications of sleep stage classification. We therefore exploit these characteristics by analyzing respiratory effort signal envelope and area. Features quantifying these characteristics are motivated to be designed which are expected to in turn help separate different sleep stages.It is assumed that the information about respiratory depth or volume is obtainable from the respiratory effort signal. For instance, the signal (upper and lower) envelopes and area should correspond to respiratory depth and volume, respectively. In fact, respiratory effort has often been used as a surrogate of tidal volume since it is obtained by measuring motions of rib cage or abdominal with, e.g., RIP [14]. However, Whyte et al. [20] argued that this assumption does not always hold, particularly when a sleeper changes his/her posture along with body movements during sleep. This is because the respiratory effort amplitude might be affected by body movements as the sensor position may shift and/or the sensor may be stretched. This will cause an uneven comparison of the signal amplitude before and after body movements, yielding errors when computing the feature values. In order to provide a more accurate estimate of respiratory depth and volume from respiratory effort signal, we must calibrate the signal by means of body movements. They can be quantified by analyzing the artifacts of respiratory effort signal (often inline with body movements) using a dynamic time warping (DTW)-based method [11]. DTW is a signal-matching algorithm that quantifies an optimal non-linear alignment between two time series allowing scaling and offset [21]. Our previous work [11] has proposed a DTW measure to effectively capture body motion artifacts by measuring self-similarity of respiratory effort. This measure has been successfully used as a feature for classifying sleep and wake states in that work. Therefore, we simply adopted this measure to detect motion artifacts modulated by body movements in respiratory effort signals. Using the DTW-based method enables the exclusion of an additional sensor modality (e.g., actigraphy) specifically used for detecting body movements.The address of this paper is exclusively on investigating a set of novel features that can characterize respiratory amplitude in different aspects with the ultimate goal of improving sleep stage classification performance. Previous studies have shown that linear discriminant (LD) is an appropriate algorithm in sleep stage classification [6,8,22]. Likewise, we simply adopted an LD classifier. Preliminary results of this work in classifying REM and NREM sleep have been previously published [23].Data of 48 healthy subjects (21 males and 27 females) in the SIESTA project (supported by European Commission) [24] were included in our data set. The subjects had a Pittsburgh Sleep Quality Index (PSQI) of no more than 5 and met several criteria (no shift work, no depressive symptoms, usual bedtime before midnight, etc.). All the subjects signed an informed consent form prior to the study, documented their sleep habits over 14 nights, and underwent overnight PSG study for two consecutive nights (on day 7 and day 8) in sleep laboratories. The PSG recordings collected on day 7 were used for analyses, from which the respiratory effort signals (sampling rate of 10Hz) were recorded with thoracic inductance plethysmography.Sleep stages were manually scored on 30-s epochs as wake, REM sleep, or one of the NREM sleep stages by sleep clinicians based on the R&K rules. For sleep stage classification epochs were labeled as four classes W (wake), R (REM sleep), L (light sleep), and D (deep sleep), or three classes W, R, and N (NREM sleep).From the data used in this study the subject demographics and some sleep statistics [mean±standard deviation (SD) and range] are summarized in Table 1.The raw respiratory effort signals of all subjects were preprocessed before feature extraction. They were filtered with a 10th order Butterworth low-pass filter with a cut-off frequency of 0.6Hz for the purpose of eliminating high frequency noise. Afterwards the baseline was removed by subtracting the median peak-to-trough amplitude. To locate the peaks and troughs, we identified the turning points simply based on sign change of signal slope and then corrected the falsely detected ‘dubious’ peaks and troughs (1) with too short intervals between peak and trough pairs where the sum of two successive intervals is less than the median of all intervals over the entire recording and (2) with two small amplitudes where the peak-to-trough difference is smaller than 15% of the median of the entire respiratory effort signal. These methods were validated by comparing automatically detected results with manually annotated peaks and troughs and an accuracy of ∼98% was achieved.A pool of 14 existing features extracted from the respiratory effort signal has been used in previous studies for sleep stage classification. In the time domain, the mean and SD of breath lengths (Lm and Lsd) and the mean and SD of breath-by-breath correlations (Cm and Csd) were calculated [6]. In the frequency domain, we extracted features based on the respiratory effort spectrum for each epoch where the spectrum was estimated using a short time Fourier transform (STFT) with a Hanning window. From the spectrum the dominant frequency (Fr) in the range of 0.05–0.5Hz (estimated as the respiratory frequency) and the logarithm of its power (Fp) were obtained [6]. We also took the logarithm of the spectral power in the very low frequency band between 0.01 and 0.05Hz (VLF), low frequency band between 0.05 and 0.15Hz (LF), and high frequency band from 0.15 to 0.5Hz (HF) and the ratio between LF and HF spectral powers (LF/HF) [6,8]. Furthermore the standard deviation of respiratory frequency over 5 epochs (Fsd) was computed [8]. Non-linear features consist of self-similarity measured between each epoch of interest and the other epochs by means of dynamic time and frequency warping (Sdtw and Sdfw) [11] and signal regularity estimated by sample entropy (Rse) [17]. The latter was implemented with the PhysioNet toolkit sampen[25].Fig. 1illustrates four short segments of a respiratory effort signal during different sleep stages. It is observed that the envelopes formed by the peak and trough sequences of the signal during wake and REM sleep, when compared with that during light and deep sleep: (1) are more ‘irregular’; (2) have generally lower absolute mean or median; and (3) have larger variance. In addition, as illustrated in Fig. 2, we also considered the respiratory effort ‘area’ comprised between the respiratory effort amplitude and its mean value (zero in the example). As explained, this area should correlate with respiratory volume to a certain extent, which differs across sleep stages. Relying on these observations, several new respiratory amplitude features were explored in two aspects, namely respiratory depth-based and volume-based features.A total of five depth-based features were extracted from the peak and trough sequences (i.e., upper and lower envelopes) of the respiratory effort signal. The amplitudes of these peaks and troughs should include the information in regard to respiratory depth. Let us consider p=p1, p2, …, pnand t=t1, t2, …, tnthe peak and trough sequences from a window of 25 epochs or 12.5min centered at the epoch under consideration, containing n peaks and troughs, respectively. We thus computed the standardized median of the peaks (and troughs) by dividing the median by their interquartile range (IQR, the difference between the 3rd and the 1st quartile), such that(1)Psdm=median(p1,p2,…,pn)IQR(p1,p2,…,pn),(2)Tsdm=median(t1,t2,…,tn)IQR(t1,t2,…,tn).These two features consider the mean respiratory depth and its variability at the same time in terms of inhalation (for peaks) and exhalation (for troughs). Note that the period length of 25 epochs was chosen to maximize the average discriminative power (see Section 2.7.2) of all respiratory amplitude features in separating wake, REM sleep, light sleep, and deep sleep.In order to examine how regular the envelopes are, we used the non-linear sample entropy measure, which has been broadly used in quantifying regularity of biomedical time series [17]. Now considering a time series with n data points u=u1, u2, …, un, let v(i)=ui, ui+1, …, ui+m−1 (1≤i≤n−m+1) be a subsequence of u, where the window length m is an positive integer and m<n. Then for each i, we have Bi,m(r)=(n−m+1)−1η(r), in which η(r) is the number of j such that dm[v(i), v(j)]≤r (1≤j≤n−m, j≠i) where the distance metric dm between two subsequences v(i) and v(j) is given by dm[v(i), v(j)]=max |ui+l−uj+l| for all l=0, 1, …, m−1. For a higher dimension m+1, we have Ai,m(r). Then the sample entropy of the time series u is defined by(3)SE=−lnAm(r)Bm(r),where(4)Am(r)=1n−m∑i=1n−mAi,m(r),(5)Bm(r)=1n−m∑i=1n−mBi,m(r).Similarly, the sample entropy measures of the peak and trough sequences are(6)Pse=−lnApeakm(r)Bpeakm(r),(7)Tse=−lnAtroughm(r)Btroughm(r),in which r is the tolerance that usually takes the value of 0.1–0.25 SD of the peak or the trough sequence and m takes a value of 1 or 2 for the sequence of length n larger than 100 data points [17,26]. In our study, r of 0.20 SD of the sequence and m of 2 were experimentally chosen to maximize the discriminative power of the two features.Additionally, the median of peak-to-trough differences expresses the range of inhale and exhale depths. It was computed as(8)PTdiff=median[(p1−t1),(p2−t2),…,(pn−tn)].A total of seven volume-based features were extracted from the respiratory effort signal. They should reflect certain properties of respiratory volume. The respiratory effort signal (sampled at 10Hz) over a window of 25 epochs or 12.5min centered at the epoch of interest is expressed as s={s1, s2, …, sx, …, sM} (x=1, 2, …, M), where M is the number of sample points in this period. Suppose thatΩkbris the kth breathing cycle in the epoch where there are in total K consecutive breathing cycles (k=1, 2, …, K). Then the corresponding kth inhalation and exhalation periods areΩkinandΩkex, respectively. As illustrated in Fig. 2, a breathing cycle is the period between two consecutive troughs and thereby the inhalation and exhalation periods in this breathing cycle are separated by the peak in between these two troughs. We first computed the median respiratory volume (expressed by respiratory effort area) measured during breathing cycles (Vbr), inhalation periods (Vin), and exhalation periods(Vex) for each epoch, such that(9)Vbr=median∑sx∈Ω1brsx,∑sx∈Ω2brsx,…,∑sx∈ΩKbrsx,(10)Vin=median∑sx∈Ω1insx,∑sx∈Ω2insx,...,∑sx∈ΩKinsx,(11)Vex=median∑sx∈Ω1exsx,∑sx∈Ω2exsx,...,∑sx∈ΩKexsx.In addition, we computed the median respiratory “flow rate” (expressed by the respiratory effort area over time) during breathing cycles (FRbr), inhalation periods (FRin), and exhalation periods (FRex), such that(12)FRbr=median1τ1br∑sx∈Ω1brsx,1τ2br∑sx∈Ω2brsx,…,1τKbr∑sx∈ΩKbrsx,(13)FRin=median1τ1in∑sx∈Ω1insx,1τ2in∑sx∈Ω2insx,…,1τKin∑sx∈ΩKinsx,(14)FRex=median1τ1ex∑sx∈Ω1exsx,1τ2ex∑sx∈Ω2exsx,…,1τKex∑sx∈ΩKexsx,in whichτkinandτkexare the kth inhalation and exhalation time (unit: 100ms)(15)τkin=maxsx∈Ωkin(x)−minsx∈Ωkin(x),(16)τkex=maxsx∈Ωkex(x)−minsx∈Ωkex(x),and accordingly the time of the kth breathing cycle is given by(17)τkbr=τkin+τkex.The ratio of the inhalation and the exhalation flow rate FRin and FRex was finally computed as(18)RTfr=FRinFRex.As mentioned, the respiratory amplitude features are sensitive to body motion artifacts. We thus should calibrate the respiratory effort signal before computing these features. This was done by calibrating each signal segment to have zero mean and unit variance between any two epochs detected as with body movements. As mentioned in Section 1, a DTW-based method measuring the respiratory similarity between each epoch and its adjacent epochs using DTW distance [21] was applied to estimate the body movements. For the details of computing the DTW measure we refer to our previous work [11]. Here the epochs were identified as with body movements if their DTW measures (expressing body motion artifacts) are larger than a threshold. A threshold of 0.01 was experimentally found to be adequate for this purpose. Fig. 3compares an overnight preprocessed respiratory effort signal with the corresponding epoch-based DTW measure from a subject where the peaks (reflecting body movements) are well aligned in time axis.Following the feature extraction procedure as described above, we performed a subject-specific Z-score normalization for each feature. It was done per subject/recording by subtracting the mean of feature values and dividing by their standard deviation. This allows for reducing physiological and equipment-related variations from subject to subject, thereafter enhancing the discrimination between sleep stages.An LD classifier was used for sleep stage classification in this study. With LD, the prior probabilities of different classes (i.e., sleep stages) have been observed to change over time. To exploit this change, we calculated a time-varying prior probability for each epoch by counting the relative frequency that specific epoch index was labeled as each class [6,8,22].A 10-fold cross validation (10-fold CV) was conducted in our experiments. The subjects were first randomly divided into 10 subsets, yielding 8 subsets with 5 subjects each and 2 subsets with 4 subjects each. During each iteration of the 10-fold CV procedure, data from 9 subsets were used to train the classifier and the remaining one was used for testing. After CV, classification results obtained for each subject in each iteration's testing set were collected and performance metrics (averaged or pooled over all subjects) were computed to evaluate the classifier.We first compared the values of the new respiratory amplitude features in different sleep stages to see whether they are statistically different between sleep stages. This serves to understand their feasibility to detect sleep stage at first glance. For each of them, an unpaired Mann–Whitney test (two-sided) was applied to examine the significance of difference.To assess the discriminative power or class separability of each single feature in separating different classes, the information gain (IG) [27] metric was employed. IG describes the change in information entropy caused by knowing the informative feature values. A higher discriminative power of a feature is reflected by a larger IG value, vice versa. In this study the discriminative power of the new features (in separating wake, REM sleep, light sleep, and deep sleep) with and without calibrating the respiratory effort signal and with and without performing subject-specific normalization were compared. To examine which sleep stage they are able to detect best, we compared their IG values (after signal calibration and feature normalization) in discriminating between each stage and all the other stages as a whole. The new features in combination with the existing features were ranked by IG which serves to select features.During each 10-fold CV iteration, features were first ranked by means of the discriminative power (measured by IG) in a descending order based on the associated training set. Afterwards, a certain number of top-ranked features were selected. With this approach, we would get 10 feature subsets for all the 10 iterations. To compare the classification performance using different number of features, we plot the performance metric versus the number of selected features and then report the best results. Note that the feature ranking and thus the selected features may change during each iteration of the cross validation. We allowed for this during our experiments since we found that the feature rankings in different iterations were similar for the relatively large-sized training data sets (with 43 or 44 overnight recordings) used in this study.We evaluated the performance of several sleep stage classification tasks. They are (1) two multiple-stage classification tasks: WRLD (classification of W, R, L, and D) and WRN (classification of W, R, and N); and (2) four detection tasks: W, R, D, and N (binary classification between each of them versus all the other stages).To evaluate the performance of classifiers, conventional metric of overall accuracy was considered. However, the high class imbalance makes this metric less appropriate. For instance, the wake epochs account for an average of only 12.9% of all the epochs throughout the night while the light sleep constitutes 53.6% of the night. The Cohen's Kappa coefficient of agreement [28] which has often been used in the area of sleep stage classification is considered to be a better criterion for this problem. By factoring out chance agreement, it is not sensitive to class imbalance. By these means, it offers a better understanding of the general performance of the classifier in correctly identifying different classes. For the binary classification tasks, we chose the classifier decision-making threshold leading to the maximum pooled Kappa and therefore with this threshold the mean and SD of the overall accuracy and Kappa over all subjects were computed.For each classification task, the 10-fold CV using the LD classifier was conducted with the feature sets comprising the existing pool of 14 respiratory features (set “exist”) and the combination of the existing features and the new respiratory amplitude features (set “all”). In addition, we also compared the classification results obtained using features with and without performing subject-specific (Z-score) normalization. A paired Wilcoxon signed-rank test (two-sided) was applied to test the significance of difference between classification performances.

@&#CONCLUSIONS@&#
Respiratory effort amplitude (depth and volume) was analyzed and quantified during nighttime sleep, which has been found to differ across sleep stages. Based on this, 12 novel features that characterize different aspects of respiratory effort amplitude were extracted for automated sleep stage classification. To eliminate the effect of body movements during sleep, respiratory effort signals were calibrated by using a DTW measure which has been shown to correlate with body motion artifacts. By calibrating the signals and normalizing the features for each subject, the discriminative power of the features can be increased. When using only respiratory effort signals, combining the new features proposed in this paper with the existing respiratory features (known in literature) can help significantly improve the performance in classifying and identifying different sleep stages with an exception of wake state detection.