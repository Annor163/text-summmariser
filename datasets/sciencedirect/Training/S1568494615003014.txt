@&#MAIN-TITLE@&#
Context-based ensemble method for human energy expenditure estimation

@&#HIGHLIGHTS@&#
Multiple Contexts Ensemble (MCE) method to estimate the human energy expenditure (EE).MCE outperforms conventional regression approaches, ensembles and BodyMedia EE device.MCE provides better accuracy than using only the activity of the user as the context.MCE is independent of the machine learning algorithm, thus any algorithm can be used.

@&#KEYPHRASES@&#
Human energy expenditure estimation,Machine learning,Regression,Ensembles,Context,Wearable sensors,

@&#ABSTRACT@&#
Monitoring human energy expenditure (EE) is important in many health and sports applications, since the energy expenditure directly reflects the intensity of physical activity. The actual energy expenditure is unpractical to measure; therefore, it is often estimated from the physical activity measured with accelerometers and other sensors. Previous studies have demonstrated that using a person's activity as the context in which the EE is estimated, and using multiple sensors, improves the estimation. In this study, we go a step further by proposing a context-based reasoning method that uses multiple contexts provided by multiple sensors. The proposed Multiple Contexts Ensemble (MCE) approach first extracts multiple features from the sensor data. Each feature is used as a context for which multiple regression models are built using the remaining features as training data: for each value of the context feature, a regression model is trained on a subset of the dataset with that value. When evaluating a data sample, the models corresponding to the context (feature) values in the evaluated sample are assembled into an ensemble of regression models that estimates the EE of the user. Experiments showed that the MCE method outperforms (in terms of lower root means squared error and lower mean absolute error): (i) five single-regression approaches (linear and non-linear); (ii) two ensemble approaches: Bagging and Random subspace; (iii) an approach that uses artificial neural networks trained on accelerometer-data only; and (iv) BodyMedia (a state-of-the-art commercial EE-estimation device).

@&#INTRODUCTION@&#
Human energy expenditure (EE) directly reflects the intensity of physical activity, which makes it important for sports training, weight control, management of metabolic disorders (e.g., diabetes), and other health goals. There are various approaches that can reliably estimate the EE. Direct calorimetry measures the total heat output of a person in an accurate way, but is only usable in laboratory conditions. The slightly less accurate indirect calorimetry analyzes the respiratory gases and requires wearing a breathing mask, making it impractical for everyday use. Doubly labeled water is both accurate and convenient, but can measure only long-term EE. Finally, self-reporting is highly unreliable. Therefore, if both accuracy and convenience are required, a different approach is needed.With the increasing accessibility and miniaturization of sensors and microprocessors, ubiquitous monitoring systems are becoming a practical solution for measuring the EE. Such systems primarily measure the physical activity with accelerometers, but can include additional sensors that indirectly measure the metabolic activity, such as a heart rate monitor or thermometer. The main challenge is how to estimate the EE from wearable sensor outputs accurately, irrespectively of the participant's activity, ambient conditions and other circumstances, i.e., contexts.Recent studies in the EE-estimation field showed that machine learning (ML) techniques applied on sensor data can accurately estimate the EE [1–3]. In these studies, the EE estimation is defined as a process of transforming the sensor data into METs (Metabolic Equivalent of a Task), where one MET is defined as the energy expended at rest. MET values usually range from 0.9 (sleeping) to over 20 (extreme exertion). Researchers usually use an indirect calorimeter to estimate the actual EE in METs with a high accuracy, which is later used as the ground truth during the ML phase.In this study, we propose a novel, Multiple Contexts Ensemble (MCE) approach, which is applied to the task of EE estimation. The MCE approach uses multiple contexts extracted from sensor data and performs context-based reasoning in order to estimate the EE. In general, context is any information that characterizes the circumstances in which an event/situation occurs [4]. In our application, the context information is represented by the eight features extracted from the sensor data: activity, heart rate (HR), breath rate (BR), acceleration counts, chest skin temperature, galvanic skin response (GSR), arm skin temperature and near-body ambient temperature. Each of these features is used as a context in which ML models are built using the remaining features as training data. More precisely, for each value of each context feature, a regression model is trained using the subset of the dataset that corresponds to that particular context (feature) value. For example, for the activity of the user, a regression model is trained for each activity (sitting, walking, running, etc.) using the rest of the features as training data (HR, BR, body temperature, etc.). When evaluating a data sample, a custom ensemble of regression models is assembled from the previously constructed set of models, i.e., the models that correspond to the context (feature) values in the evaluated sample. The final estimation is provided by aggregating the outputs of the assembled models. This way, context-based reasoning is performed, which provides the benefit of combining multiple “viewpoints” when estimating the EE, resulting improved accuracy compared to previous approaches.The remainder of this paper is organized as follows: Section 2 presents the background of the study and reviews the related relevant methods; Section 3 describes the proposed MCE approach; Section 4 presents the experimental setup, including the description of the activity scenario, the sensor equipment, the evaluation technique, and the description of the competing approaches; Section 5 presents the experimental results and a discussion; and lastly, Section 6 offers concluding remarks.The first automatic methods for EE estimation included supervised ML, i.e., regression learning techniques. In particular, linear regression was used to map a single accelerometer output to EE [5–8]. The accelerometer output was often expressed in “counts”, an aggregate acceleration measure reported by devices such as ActiGraph. To estimate the EE, investigators used these “counts” to develop linear regression models. Although numerous studies showed reasonably good correlation between the counts and the EE [5,9], the estimation accuracy of accelerometer count-based linear regression was shown to contain systematic errors and vary with the type of activities, resulting in overestimations for the walking activity and underestimations during the moderate intensity lifestyle activities [10]. This limitation is probably due to the insufficient information provided by the counts and the simplicity of the linear model. Efforts were made to improve the estimation accuracy by using a richer representation of the accelerometer output consisting of multiple features [11,12], as well as non-linear regression methods such as artificial neural networks (ANNs) [1,13,14] or support vector machine for regression (SVR) [15,16]. These approaches were experimentally shown to substantially improve the accuracy compared to earlier work [17].Researchers soon realized that single-regression approaches cannot accurately estimate the intensity of physical activity across a range of activities, and that different activities require different EE equations [18,19]. Crouter et al. [20] used the acceleration counts in order to divide the activities into three categories and assigned the following EE estimations: 1 MET to inactivity and two regression equations for light and intense activity, thus achieving a better estimate than previous single-regression methods. The advances in the accelerometer-based recognition of activity type allowed finer-grained activities as the context for EE estimation [2,21,22]. Lester et al. [23] used a Naive Bayes classification model to first recognize three activities (rest, walking and running) from the accelerometer's data, and then to apply the appropriate regression equations in order to estimate the EE. They also considered GPS and barometer information to estimate the slope of walking/running, and showed that additional sensor information improves the EE estimation. However, even with these three types of sensors (accelerometer, GPS, and barometer) they still encountered two problems: (i) EE underestimation of activities that are not characterized by acceleration, but are still energy demanding, e.g., carrying a box and (ii) EE underestimation of activities that follow an intense activity, i.e., the “cool-down” effect (sitting after intense running). Both problems can be solved by sensing other physiological parameters such as the HR and BR [24,25]. In our previous work [26], we showed that by using data from multiple sensors one can more accurately estimate the EE. This may seem as an additional burden to the user, because it requires additional sensors attached to him/her. However, today's commercial wearable devices already provide multiple sensors packed in a single enclosure, e.g., BodyMedia, Basis, Empatica wristband, etc.The BodyMedia armband sensor uses both multiple sensors and multiple regression models. Vyas et al. [3], the research team of the BodyMedia, proposed a method that uses an activity recognition model that recognizes dozens of activities which are used as the context, and then it combines multiple regression models according to the probabilities for the recognized activities. They showed that by using multiple sensors: an accelerometer, two thermometers, GSR and heat-flux sensors, the estimation of the EE significantly improves. Additionally, a recent review showed that it is the most accurate EE estimation consumer device [27].The aforementioned studies showed that: (i) using multiple regression models for different user's activities (i.e., context) outperforms single-regression approaches, and (ii) using multiple features extracted from multiple sensor data provides more accurate EE estimation than using only acceleration data (even when multiple acceleration features are extracted). In this work we improve upon these findings and propose a method that uses multiple features extracted from multiple sensor data, and uses not only the activity as the context, but multiple contexts, so that each measurement can be placed in multiple contexts simultaneously (e.g., activity=running, HR=high, BR=moderate, etc.).The proposed MCE is a general approach which can be applied to various reasoning tasks about the user's health and condition. The only requirement is that the data to reason about can be represented by multiple context features. This is usually the case when the reasoning task includes multiple sources of information, for example data streams provided by multiple sensors.The application of the MCE approach to the task of EE estimation is shown in Fig. 1. It consists of three phases: context extraction, context modeling and context evaluation. In the first phase the data provided from multiple sensors is used in order to extract eight features. In the second phase, each of these eight features is individually exploited as the user's context, and the other seven features are used to model the EE in the context of the first feature. That is, for each value of each feature a regression model is trained on the subset of the dataset that corresponds to that particular value using a regression learning method. In the evaluation phase a custom ensemble of regression models is assembled from the previously constructed set of models, i.e., the models that correspond to the context (feature) values in the evaluated data sample. The final EE estimation is provided by aggregating the outputs of the ensemble models by using an aggregation technique such as averaging, median or stacking. Each of the phases is described in the following three subsections.In the context extraction phase, raw sensor data are acquired and the multiple contexts are extracted. This phase is similar to the feature-extraction phase commonly used in ML tasks. We refer to features as contexts, because in our approach each feature is individually used as a context in order to train multiple regression models. In this study, each feature represents unique information about the user: activity, acceleration peak counts (similar to a pedometer), HR, BR, chest body temperature, arm body temperature, GSR, and near-body temperature. More details about the sensor equipment and the raw sensor data are provided in Section 4.2.Similar to feature values in ML, each context has values (context values), e.g., “sitting” for the activity context (see Fig. 1). In our case most of the extracted features were in numerical format, i.e. numbers that represent the user's heart-rate, temperature, etc. In order to train a reasonable number of models for different context values, a discretization procedure was performed. The discretization process allows us to group data samples with similar context values, e.g., data samples with “very low” HR value.Each numerical feature was discretized using the split criterion proposed by Yong et al. [28]. It is the most commonly used supervised discretization technique in the ML community, which finds such splits for a given feature that the standard deviation of the class (EE) value in each interval of the feature is minimized. The standard deviation reduction (SDR) achieved by a given split is calculated by the formula:(1)SDR=sd(T)−|T1||T|×sd(T1)+|T2||T|×sd(T2)where T is the set of data samples before the split, T1 and T2 are the sets that result from the binary split, |T| is the number of data samples in the set T, and sd(T) is the standard deviation of the class value. The discretization procedure tests all the possible splits and selects the one with the highest SDR. In order to maintain a reasonable number of training data samples in each subset, we included a parameter which was empirically adjusted to 10%. This way, at least 10% of the data samples remain in each interval. This resulted in 46 discrete context values – around 6 per context on average. A more thorough analysis of choosing the minimum number of training samples is considered for future work.In the second phase, the context modeling is performed by first partitioning the data into multiple subsets using each feature as a context, and then learning a regression model using the subsets.In order to explain the context modeling phase, consider the dataset shown in Fig. 2. It consists of three features (activity, HR and BR) and a target feature (EE in MET). A conventional ML approach would apply a single ML algorithm to learn a single regression model. More advanced approaches may use an ensemble-based approach and learn multiple models on multiple subsets of the dataset. These subsets are usually created by using techniques such as bootstrapping (sampling with replacement) [29], and modifying the dataset in the feature space (e.g., Random Subspace method, which randomly chooses a subset of features multiple times) [30]. Even though these techniques have proven to be successful in numerous ML applications [31], they do not take the nature of the domain into account. In EE estimation and other tasks dealing with a human in an environment, the context is known to be very important [23] and is also close to how humans reason about such situations. Because of that, MCE uses each of the features as a context, and the reasoning is performed using multiple contextual views of the data.An example of such context-based data partitioning is shown in Fig. 2, where the BR feature is used as the context. Therefore, the dataset is partitioned according to each feature value (low, medium and high), resulting in three subsets. This way, each subset contains data samples with similar values for the chosen context value. In the next step, for each of the subsets a regression model is trained. The same procedure is performed for the other two features, i.e., activity and HR, resulting in nine regression models (a model for each feature value). When evaluating a data sample, only the models that correspond to the particular feature values are invoked in order to evaluate it. This way each data sample is evaluated by an ensemble constructed of three models that correspond to the three contexts.Fig. 2 also shows the advantage of using intervals (discrete values) instead of numerical values for partitioning the dataset. In particular, if the numerical values were used to create the subsets, MCE would have created a subset for each numeric value, resulting in too many subsets with one or few instances, which is too less to train a regression model. On the other hand, when constructing the models one may use the original numerical values (as shown in the example in Fig. 2). We believe that it is better to use the original numeric values because with the discretization process some information is lost (e.g., breath rate 10 and 12 is considered as the same value – Low). In general though, the method can also work with the discrete values or even combination of both.For the application of MCE to EE estimation, 46 regression models were constructed (for each discrete value of each context). The MCE method does not restrict the choice of the regression learning algorithm; therefore we used and later compared the results achieved by five linear and non-linear regression learning methods as implemented in the WEKA ML toolkit [32]. More details about these methods are provided in Section 4.4.By constructing multiple models corresponding to different contexts of the user, the MCE considers multiple views on the reasoning problem. This way, the MCE not only exploits the complementarity of multiple models like most other ensemble approaches, but also contains models that tend to be more accurate for a particular context than those trained on the whole training set. The reason for that is that each model is trained on a subset of the training set that is more homogeneous than the whole set, and used in the context of this subset, i.e., to reason about data samples similar to the ones in the subset. In other words, in our approach we try to semantically split the domain (dataset) into meaningful viewpoints and not on some statistics about the data (as most of the ensemble-based approaches).When evaluating a data sample, a custom ensemble is constructed from the models that correspond to the context (feature) values of that sample. In the context evaluation phase, the estimations from each of the context models are combined in order to provide the final estimation of the EE. For example, consider the scenario shown in Fig. 1 using three contexts: a user is sitting with the HR of 50min−1 and BR of 10min−1. Suppose that the HR value falls in the second HR interval (low), and the BR value into the first BR interval (very low). The data sample will thus be evaluated by the models mA=sitting, mHR=low and mBR=verylow, whose outputs will be aggregated by an aggregation method in order to estimate the final EE. The related literature suggests various aggregation methods, including averaging, median, aggregating with learning – stacking, and similar. In this study, we tested the first two (averaging and median), which are the simplest for implementation but still enabled the MCE approach to achieve significantly better performance than other ensemble methods that use the same aggregation technique (i.e., MCE with averaging outperformed Bagging and Random subspaces, which also use averaging). We plan to experiment with more advanced techniques in future work.A total of ten healthy participants (age 27.2 years (SD=3.1); BMI 24.1kgm−2 (SD=2.3); weight 78.2kg (SD=10.9)) completed a two-week study (each participant was recorded during one day for approximately 8h). Before testing, height and weight (one layer of clothes, no shoes) were measured via the InBody-720 body-composition analyzer. Prior to participation, informed consent was obtained from the participants. Each participant was observed by a medical supervisor during the execution of a comprehensive pre-defined activity scenario. The activity scenario included 15 different atomic activities, which were categorized into seven activity types according to the intensity and the type, as presented in Table 1.An example of a person wearing the sensor equipment and walking on a treadmill is shown in Fig. 3. The equipment consists of the following wearable sensors: two 3-axis accelerometers, a Zephyr sensor, and a BodyMedia sensor. Each of the sensors used in this study provided different information about the user's EE. Because the BodyMedia sensor is the state of the art EE estimation sensor, its MET output was used for comparison. Additionally, a Cosmed indirect calorimeter was used to provide the ground truth for the EE estimation.Indirect calorimeter – Oxygen uptake (VO2) during each activity was measured breath-by-breath and averaged every 10s using the Cosmed K4b2, a light-weight portable indirect calorimeter. Prior to each test, the Cosmed unit was calibrated according to the manufacturer's guidelines. This sensor data were used as the ground truth for the regression learning algorithms and for the evaluation of the performance of the tested EE-estimation methods.Accelerometers – The Shimmer sensor platform was used to measure the accelerations of the user. The chosen platform contains a 3-axis accelerometer and uses Bluetooth communication for sending data in real-time. To record the participants’ acceleration, 50Hz data-sampling frequency was used. Each participant wore two accelerometers while performing the activities. They were attached to the participants’ chest and thigh using elastic Velcro straps. The placement was chosen as a trade-off between the physical intrusiveness and the performance achieved for the activity recognition in prior studies of activity recognition [34,35]. The results achieved in those studies [34,35] showed that from the 6 placements analyzed (chest, waist, right and left thigh, right and left ankles), the combination of the chest and the thigh is the most suitable (tradeoff between the number of sensors and the accuracy) for the activity recognition task, achieving the accuracy of 93%.Zephyr – The Zephyr BioHarness sensor is a commercial sports strap worn on the chest with direct contact to the skin. It measured the participants’ HR, BR, and chest skin temperature, which were used as contexts.BodyMedia – The BodyMedia sensor is a state-of-the-art commercial sensor for EE estimation, which was worn on the left upper arm as suggested by the manufacturer. It served as a benchmark for EE estimation, and additionally provided the data for GSR, ambient temperature and arm skin temperature used as features for EE estimation. The ambient temperature is an estimation of the ambient temperature near the arm.A custom PC application was created to record, preprocess and synchronize the multiple sensor data. During the recordings, the accelerometers’ data were acquired on a laptop using Bluetooth and were manually labeled with the corresponding activity, which was later used for the training of the activity-recognition classification model. The data provided from the other sensors was labeled with the appropriate timestamp and stored locally in the sensor's internal memory. Afterwards, they were transferred into a database for offline analysis together with the accelerometer data and the activity labels. Once the multiple sensor data were saved into the database, they were synchronized using the unique timestamp for each data sample. In the next step, they were segmented using a sliding window of 10s. In each data window, eight context features were extracted from the sensor data, as shown in Table 2. The dataset that contains the extracted features is available in our repository of Ambient Intelligence (AmI) datasets [33] (http://dis.ijs.si/ami-repository/index.php?d=16).Except for the activity and the acceleration peak counts, all other features are provided directly by the sensors (Zephyr, BodyMedia or Cosmed) and are computed by averaging the raw sensor data in the 10-s intervals. The physiological signals provided by the Zephyr and BodyMedia (HR, BR, etc.) differ from participant to participant and were additionally normalized. After empirical analysis of the data, we used the 15-min lying activity data recorded at the beginning of the activity trials in order to calculate the average resting value for each sensor, which was subtracted from each subsequent sensor value.To extract the acceleration peak counts and the activity of the user from the acceleration data, they were first filtered using a band-pass filter [36]. The acceleration peak counts is the number of times the length of the acceleration vector stops increasing and starts decreasing or vice versa in the 10-s interval. For the activity recognition we used a previously developed classification method based on ML [34,37]. The method uses the data from the two accelerometers (chest and thigh), extracts 128 features and applies a Random forest classification model to recognize the atomic activities of the user: lying, sitting, standing, walking, running, cycling, bending, on all fours and kneeling. It achieved 93% accuracy on a 1-s recognition interval. For the EE, the majority activity value was chosen for each 10-s window interval. A similar implementation of our activity recognition method achieved the best recognition performance at the international competition in activity recognition – EvAAL-2013 [38,39].The evaluation of the method was performed using the leave-one-person-out cross-validation technique [40]: models were trained on the data of nine people and tested on the remaining person. This procedure was repeated ten times, once for each person. The same procedure was performed for the activity recognition classifier, whose output was used as a feature in the EE estimation. This evaluation technique is the most commonly used in the ML community if the model is intended to be used on a user different from the ones used for training, which is the case in the EE estimation [14]. This method yields an estimate of how well the model would do if it were applied to a population on which it was not trained. As for the evaluation metrics, root mean squared error (RMSE) and mean absolute error (MAE) were used, since they are the most commonly used metric in the EE estimation domain. They are defined as follows:(2)RMSE=1q∑1q(EEestimated−EEtrue)2(3)MAE=1q∑1q|EEestimated−EEtrue|where q is the number of data samples, EEestimated is the estimated EE and EEtrue is the ground-truth EE measured by the Cosmed device.For each comparison, tests to confirm the statistical significance of the MAE and RMSE results were performed using paired Student's T-test with a significance level of 5%. The normal distribution was confirmed using normal probability plots, also known as Q–Q plots (Q as quantiles).This subsection briefly presents the methods to which we compared the MCE approach. In particular, two types of comparisons were made: relative and absolute. The relative comparison compares the MCE to conventional ML approaches: single regression and ensembles. That is, the same dataset with the eight extracted features was used to evaluate both the MCE and the conventional ML methods. This comparison was proposed in order to confirm the hypothesis that context-based partitioning of the data improves the accuracy compared to conventional ML methods. On the other hand, the absolute comparison illustrates the accuracy of the MCE on an absolute scale, i.e., compared to estimations provided by the BodyMedia state-of-the-art commercial device and to an algorithm that is established as state-of-the-art accelerometer-based EE estimation commonly used in medical applications.First, we compared the MCE to single-regression learning methods. This means that we trained single models on all the eight features. We tested five regression learning methods that are also commonly used in the EE literature: multiple linear regression (MLR) [41], support vector machine for regression (SVR) [42], Gaussian processes for regression (GPR) [43], model trees (M5P) [28], and multilayer perceptron feedforward artificial neural network (ANN) [44]. MLR is the simplest approach: it finds a linear function using all of the features in that matches the target variable, i.e., the EE [41]. The next method, SVR, is an extension of the classical SVM (commonly used for classification) adapted to regression, i.e., numeric output. The main characteristic of SVR is that the kernel function used for building the model ignores the training data samples close to the model hyperplane (within a pre-defined threshold) [42]. Similar to SVR, GPR is another non-linear, kernel-based method; however the theory behind the GPR is different compared to the SVR and is based on the Bayesian probability theory and assuming that the target variable follows a multivariate Gaussian distribution [43]. The next method, M5P is a model tree. The difference compared to standard decision/regression tree is that each leaf contains a linear function instead of a single value [28]. The last method is the ANN which is a popular non-linear regression learning method [44]. ANNs are composed of interconnecting artificial neurons, which are arranged in layers where each unit receives inputs from its immediately preceding layers. Each neuron computes a summation of its inputs weighted by a weight vector, and then applies an activation function, which can be a logistic or linear function. In our case we used an ANN with one hidden layer and logistic learning function. Each of the five algorithms was used as implemented in the WEKA ML toolkit [32]. In addition to using these algorithms to build single-regression models as a baseline for comparison, we also used them to train base learners in the ensemble schemes constructed by our MCE algorithm.Next, because MCE is an ensemble of regression models, we also compared it to two commonly used ensemble learning methods: Bagging [29] and Random subspaces [30]. Bagging is an approach that is based on bootstrapping, i.e., training multiple models on different subsets of the whole training dataset, constructed by sampling the whole dataset with replacement, and then aggregating the outputs from each model by averaging (regression) or voting (classification). Random subspace is an ensemble method proposed by Ho [6], which also modifies the training data; however, this modification is performed in the feature space. That is, a pre-defined number of features are selected randomly from the whole feature set. This procedure is repeated multiple times, creating a different training set for each selection. Then, for each training set, a regression model is built. Similar to Bagging, the final output is provided by aggregating the outputs from each model by averaging (regression) or voting (classification). Please note that for both ensemble techniques, the same five base machine learning algorithms were compared as in the single-regression learning.Because the final goal of the approach is to be used in real-life applications, we also compared it to a commercial device for EE estimation. A recent review showed that BodyMedia commercial sensor is the most accurate EE estimation consumer device [27]. Therefore, we compared the MCE's estimated MET to the MET output of the BodyMedia commercial sensor (it should be noted that the BodyMedia sensor averaged the MET estimation over 1-min interval, while our methods over 10-s interval). This comparison illustrates the accuracy of our method on an absolute scale (compared to a device which is already used in real life).Finally, we re-implemented and compared the results to an approach that is widely accepted in the medical and sports research community [1,14]. It is an approach that uses an ANN trained with 6 features extracted from the chest accelerometer data only: 10th, 25th, 50th, 75th and 90th percentiles of the acceleration peak counts, and the lag one autocorrelation. The approach was first introduced by Staudenmayer et al. [14] and further improved by Trost et al. [1], and is a state-of-the-art approach if a single accelerometer data is used to estimate the EE. From this point on, we refer to this method as ANN-Acc (ANN trained only on accelerometer data).Table 3compares four approaches in terms of RMSE and MAE: single regression, Random subspace, Bagging and our MCE. The five base learners explained in Section 4.5 were tested for each of the approaches. The best performing base learner is marked with bold. Additionally, the best performing approach for each base learner is marked with a gray background.The results achieved by the single-regression methods show that in general the methods that use simple learning functions, e.g., linear or polynomial (SVR, GPR and MLR) are better compared to the more complex ones such as ANN an M5P. This is in a way expected since ANNs and M5P are more susceptible to overfitting, and this problem is particularly likely to harm the performance when the testing data are from a person that is not used in the training data. When these same methods are used as base learners in the two ensemble schemes, i.e., Random spaces and Bagging, the results are similar to the single regression, except for the ANN and M5P, for which a slight improvement is achieved. However, when our ensemble method (MCE) uses the same base learners, the achieved RMSE and MAE are significantly better (lower) compared to the other three approaches. The difference ranges from 0.08 METs to 0.24 MET for the RMSE, and from 0.05 to 0.21 MET for the MAE.The improvements of our MCE compared to the single-regression approach confirms the general rule in ensemble learning, i.e., ensembles tend to train multiple weak learners, and by combining the learner's outputs they create a stronger and more robust model [45]. The further comparison to the two standard ensemble approaches (Random subspace and Bagging) shows the advantage of using the nature of the domain (context) to resample the training data instead of using bootstrapping (Bagging) or randomly selecting features (Random subspaces).The MCE approach is general and can use different techniques for aggregating the outputs of each model into a final one. In the tests shown in Table 3 we used the simplest aggregation technique, i.e., averaging. This technique was also used by the other two ensemble approaches: Bagging and Random subspaces, making the results more comparable. We additionally tested the performance achieved by the median technique.Table 4shows the comparison of the RMSE and MAE achieved by averaging compared to the median technique. The results show that the RMSE and MAE achieved by the median are almost always better (lower), except for the RMSE achieved by the M5P. The rationale why the median should work better is that by choosing the median value the models that are not accurate for some situations are not taken in consideration, which is not the case if the average is chosen. Because SVR by using the median achieved the best overall results (0.825 RMSE and 0.601 MAE), it is used in all further analysis.Since the MCE consists of eight contexts, we additionally show the results if only a single context is used. In Fig. 4, one can see that the MCE's EE estimation is better than the estimations provided by each of the base learners individually using RMSE metrics. This shows the advantage of using an aggregation function, i.e., by combining the individual models outputs using a median, the ensemble outperformed the individual models. This result is in accordance with the hypothesis presented by Dietterich [45], who studied the process of combining (aggregation) of the decisions provided by multiple models. He showed that it is better to find a good aggregation function instead of choosing the best single model, which also leads to stronger generalization.Of particular interest is the comparison with the first regression model, which uses the activity as the only context: it only uses different regression models for different activities, like in several pieces of related work [3,20,23]. The results show that by combining multiple contexts one should expect better performance than by only using the activity as the context, i.e., a decrease of the RMSE by 23%.Fig. 5shows a scatter plot comparing the ground-truth and estimated MET values for different activities. Three approaches are compared: our MCE approach, the EE output of the BodyMedia sensor, and the ANN trained on chest-accelerometer data only (ANN-Acc). The results show that in general, the estimations of the MCE better match the true Cosmed values (the diagonal line in Fig. 5) for almost all of the activities. The BodyMedia sensor has comparably good performance for the sedentary activities and for the more dynamic, exercise activities (walking, cycling, running), which is probably because the device is intended for physically active users. On the other side, for everyday light and moderate household activities the performance is significantly worse than the MCE's estimations. In addition, the results in Fig. 5 show that the ANN-Acc approach largely underestimates the METs for the dynamic activities, especially for the cycling activity. This was in a way expected, because this method uses only the torso acceleration, while the cycling activity is an activity that does not include a lot of torso movement, but has a relatively high MET value.The results achieved by the ANN-Acc approach show that acceleration information alone is not sufficient for accurate EE estimation. This is especially notable during the running activity and activities that are not characterized by high accelerations, but are still EE demanding, e.g., cycling (light and intense) and moderate-to-vigorous intensity household activities (digging, scrubbing the floor, etc.). These results are in accordance with the findings of Trost et al. [1], who also showed the highest RMSE values during these activities, except for the cycling activity which was completely omitted in their scenario. Staudenmayer et al. [14] also investigated and showed that worse results should be expected during the cycling activity when only torso-placed accelerometer is used to estimate the EE.The comparison in Fig. 5 has a drawback because it averages the estimated EE over one type of activity, and thus allows the errors of the methods (underestimations and overestimations) to cancel each other. For this reason we further analyzed the performance using the MAE and RMSE.Table 5presents the results for the MCE, BodyMedia and ANN-Acc EE estimations for all the activities and for different activity types individually. When calculated for all the activities, the MCE has significantly lower MAE and RMSE compared to the BodyMedia and ANN-Acc. Per-activity analysis shows that the MCE also has significantly lower RMSE and MAE for all activity types compared to the BodyMedia and ANN-Acc approach: on average 0.45 (RMSE)/0.25 (MAE) lower than the BodyMedia, and 0.94 (RMSE)/0.67 (MAE) lower than the ANN-Acc. The averaging issue (canceling the errors), which is present in Fig. 5, is confirmed with the running activity in Table 5. That is, according to Fig. 5 BodyMedia better match the EE estimation, however the RMSE and MAE statistics in Table 5 showed that MCE achieves significantly lower errors: 1.27 difference in RMSE and 0.79 difference in MAE.The difference in performance of the ANN-Acc compared to the other two (MCE and BodyMedia) additionally confirms that acceleration information is not sufficient for accurate EE estimation. These results are in accordance with the findings of Lester et al. [23], Liu et al. [17], and Vyas et al. [3], who showed that by using multiple sensors one can overcome this problem.

@&#CONCLUSIONS@&#
This study presented a novel context-based ensemble method called MCE. The method was applied to the task of human EE estimation using multiple sensors. It builds upon the work of Crouter et al. [20], Lester et al. [23], and Vyas et al. [3], who showed that single-regression models cannot accurately estimate the EE over a range of activities, and that using multiple models based on the context (in their case the activity) significantly improves the EE estimation. It goes a step further in that it uses not only the activity as a context, but multiple contexts (HR, BR, GSR, etc.), resulting in an ensemble of models invoked for the contexts in which the participant is at a particular moment.The presented MCE approach has a number of strengths. First, the novel reasoning with the use of multiple contexts enables more accurate and more context-specific EE estimation compared to conventional single-regression approaches (linear models, non-linear regression models, ANN-Acc), conventional ensemble approaches (Bagging and Random subspace), and the state-of-the-art BodyMedia device. Second, we showed that using multiple contexts can provide better accuracy than using only the activity of the user as the context. Third, our methodology is independent of the ML algorithm used for training; therefore, any algorithm that performs well on a given problem can be used. This may be beneficial if limited processing power or memory is available, since simple algorithms such as linear regression can be used. It also means that the MCE approach can be applied to classification problems. In our previous studies we already showed that the context-based reasoning significantly improves the accuracy in activity recognition domain [46] (by using classification models) and in the fall detection domain (by using expert rules) [35].To summarize, the results show that the difference in the errors – if they do not cancel each other out – can amount to several hundred calories per day. This is probably most valuable for people who are particularly interested in precisely matching the caloric intake and output (because of engaging in certain sports or calorie restriction lifestyle, suffering from diabetes etc.).Some may argue that the absolute improvement in the EE-estimation accuracy is not worth the trouble of introducing such a complex methodology. However, once the context structure is defined and the models trained, the use is simple and requires relatively low computational power. In fact, the processing power is mainly needed in the training phase while learning the models. Once the models are learned, the method estimates the EE as any ensemble-based machine learning model (every 10s: to compute the 8 features, to provide 8 estimation using each feature as a context, and to aggregate the decisions). Even more, recent studies show that the computational cost of constructing an ensemble is not much larger than creating a single regression model [31].There are also a few limitations that warrant consideration. First, since it is not easy to obtain valid, multi-sensor measurements useful for EE estimation, our method was developed using data from a limited number of people in controlled activity trials. Since ML and pattern recognition algorithms perform best when applied to population groups and/or activities that are identical or similar to those used to train the model, it remains an open question whether the models developed in the present study perform acceptably in independent samples of people performing similar or different activities remains. This issue is also relevant when comparing the MCE to the EE output of the BodyMedia sensor, whose EE estimation model was trained on a scenario different from ours (but not in the case of the ANN-Acc approach, where the model was trained and tested the same way as the MCE). Second, even though the practical usability of the system is an important issue, it was not appropriately addressed and exploited in the paper. We plan to address this issue in our next study by analyzing and comparing different feature sets and this way to find trade-off (optimal configuration) between the number of sensors and the burden to the user. It should also be noted that having multiple sensors does not necessarily means multiple devices on the body. Today's commercial wearable devices already provide multiple sensors packed in a single enclosure, e.g., Basis watch, Empatica wristband, Microsoft band, iWatch, etc.In the future we plan to implement and release the MCE approach as readily usable software package or a plug-in for the WEKA ML toolkit [32]. First, this will make it accessible to researchers and practitioners from various areas and remove its complexity as a barrier to use. And second, it will make it easy to test it on various ML problems. While the approach was developed specifically for ambient-intelligence and healthcare problems, where humans are measured with sensors, it can in principle be used on any ML problem. It may no longer be possible to interpret (some of) the features as contexts, and contexts there may not be as important as in ambient intelligence and healthcare, but the MCE approach may still perform well.