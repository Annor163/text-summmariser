@&#MAIN-TITLE@&#
Weighted Superposition Attraction (WSA): A swarm intelligence algorithm for optimization problems – Part 1: Unconstrained optimization

@&#HIGHLIGHTS@&#
A novel swarm intelligence based algorithm inspired by superposition principle and field attraction for global optimization.High converging capability.Extensive computational study is presented for solving many test problems with success.

@&#KEYPHRASES@&#
Meta-heuristics,Swarm intelligence,Global optimization,

@&#ABSTRACT@&#
This paper is the first one of the two papers entitled “Weighted Superposition Attraction (WSA)”, which is based on two basic mechanisms, “superposition” and “attracted movement of agents”, that are observable in many systems. Dividing this paper into two parts raised as a necessity because of their individually comprehensive contents. If we wanted to write these papers as a single paper we had to write more compact as distinct from its current versions because of the space requirements. So, writing them as a single paper would not be as effective as we desired.In many natural phenomena it is possible to compute superposition or weighted superposition of active fields like light sources, electric fields, sound sources, heat sources, etc.; the same may also be possible for social systems as well. An agent (particle, human, electron, etc.) may be supposed to move towards superposition if it is attractive to it. As systems status changes the superposition also changes; so it needs to be recomputed. This is the main idea behind the WSA algorithm, which mainly attempts to realize this superposition principle in combination with the attracted movement of agents as a search procedure for solving optimization problems in an effective manner. In this current part, the performance of the proposed WSA algorithm is tested on the well-known unconstrained continuous optimization functions, through a set of computational study. The comparison with some other search algorithms is performed in terms of solution quality and computational time. The experimental results clearly indicate the effectiveness of the WSA algorithm.iteration number (stopping condition)current iteration numbernumber of artificial agentsnumber of dimensions of the problemuser defined parameteruser defined parameteruser defined parameterupper limit for the dimensionslower limit for the dimensionsfitness of the current point of agent ifitness of the target pointweight of the current point of an agentcurrent position vector of an agentposition vector of the target pointvector combines an agent to target pointmove direction vector of an agentsignum functionstep length

@&#INTRODUCTION@&#
Algorithmic design is an exploratory research field, since numerous real world problems need to be solved optimality or near-optimality. Numerous researchers attempted to develop effective algorithms within the purpose of optimization, which is the name of the process of systematically making a system or design as efficient as possible [1]. In this respect, effectiveness arises as a key feature for the efforts to design algorithms for optimization purposes.From the optimization point of view, the concept of effectiveness of a solution approach covers robustness, ability to find optimal or near optimal solutions in a reasonable time limit and having the potential to be used widely. According to these important characteristics, solution approaches may be classified as mathematical programming, heuristics and meta-heuristics methods. Mathematical programming methods are generally developed for formally describing the problem on hand. They guarantee the optimal solution of a problem; however, they require large amount of time for providing the optimal solution as the size of the problem gets larger and mathematically complex (non-convex, ill-defined, etc.). Hence, the mathematical programming approaches have not the desired level of effectiveness for many cases. Heuristic methods may provide optimal or near-optimal solutions for a problem in shorter times. Nevertheless, they are generally developed on a problem dependent basis and this situation prevents widespread implementations, thus decreases the effectiveness level of them. On the other hand, meta-heuristic algorithms which are one of the pillars of soft computing have the ability to provide satisfactory results for different type of optimization problems in reasonable time limits. Thus, it would not be wrong to claim that meta-heuristic algorithms are usually more effective than mathematical programming and heuristic methods for many complex problem settings.Meta-heuristic algorithms are generally based on a specific philosophy inspired by a source. Probably, natural processes of evaluation and swarm intelligence are the most popular and widely used sources of inspiration while designing meta-heuristic approaches. Thus, nature inspired meta-heuristics have been mainly grouped as evolutionary algorithms (genetic algorithm (GA) [2] and differential evolution (DE) [3]) and swarm intelligence algorithms (ant colony optimization (ACO) [4], particle swarm optimization (PSO) [5], bee colony optimization (BCO) [6], and bees algorithm (BA) [7]). On the other hand, non-nature inspired meta-heuristic algorithms (Tabu search (TS) [8,9], and simulated annealing (SA) [10]) were also designed and provided satisfactory performances on several optimization problems. In this current study, we propose a new swarm intelligence algorithm and test the effectiveness of this algorithm on a set of standard unconstrained continuous optimization problems.A great number of real world problems are included in the field of continuous optimization, a branch of applied mathematics. This kind of optimization is different from the combinatorial optimization in the type of decision variables. The optimization problems belonging to this class of optimization may have one or more real continuous decision variables each one may have an infinite number of values from a particular interval. Thus, the search spaces of continuous optimization problems are infinite. For that reason, effectively exploring the search spaces of this type of problems is a challenging research field. Within this context, various meta-heuristic solution approaches (harmony search algorithm (HSA) [11], electromagnetic algorithm (EA) [12], seeker optimization algorithm (SOA) [13], firefly algorithm (FA) [14], gravitational search algorithm (GSA) [15], bat-inspired algorithm (BIA) [16], cuckoo optimization algorithm (COA) [17], exchange market algorithm (EMA) [18], forest optimization algorithm (FOA) [19], bird mating optimizer (BMO) [20], krill herd algorithm (KHA) [21], social spider optimization (SSO) [22], differential search algorithm (DSA) [23], teaching–learning-based optimization (TLBO) [24]) were developed by numerous researchers.In this paper, we introduce a new swarm based optimization algorithm, which is based on two basic mechanisms, superposition and attracted movement of agents, that are observable in many systems. It should be mentioned here that in most of the swarm based algorithms including PSO it is assumed that an agent can identify the best agent in the population and adjust its direction towards to it. In realty however, it is not easy if not impossible to accurately identify the best source due to many interferences, on the other hand agents may identify the superposition (as it is usually performed to determine the overall effect of more than one source in physics and other related scientific fields under several assumptions “http://en.wikipedia.org/wiki/Superposition_principle”) and may decide to direct towards to this position. This basic mechanism is successfully implemented as an optimization algorithm in the present study. Within this framework, WSA algorithm determines a target point within the search space via the superposition principle and directs the agents of the swarm towards this point. That is to say, the target point is the superposition of the currently discovered points of the search space by the agents of the swarm. Once the target point is determined, agents explore the search space whether moving towards target point or a randomly selected direction.This paper is the first one of a two-part paper which main aim is to introduce a new swarm based solution approach for complex optimization problems. The aim of this current part is to introduce the WSA algorithm and to provide a comprehensive performance evaluation test of WSA on the unconstrained continuous optimization problems. For a new algorithm, its effectiveness must be proved on both unconstrained and constrained optimization problems to our point of view. Within this context, the second part [25] is about the performance evaluation test of WSA on constrained optimization problems and it also has a comprehensive content. Since both parts of the paper have individually comprehensive contents and these contents required to effectively introduce the new algorithm, writing them as separate parts makes the paper much more effective. Additionally, writing them as a single paper would be resulted to shorten their comprehensive contents due to space requirements and to reduce the effectiveness of the paper.Decision making is a hard process for living beings, especially for human beings. Through this process a decision-maker takes into account some criteria rather than a single criterion and each criterion's features have impacts over the judgement of the decision-maker. These impacts may be thought as the attractiveness of the related criterion. From this point of view, it is possible to say that a decision is a result of the attractiveness of some criteria. In other words, a decision is generally given in accordance with some criteria thus it arises as a superposition of some criteria related to their individual attractiveness. To our point of view, this decision making procedure is also valid and applicable for the optimization purposes and this procedure constitutes the rationale of the newly developed WSA algorithm. In WSA, decision makers are artificial agents and they have to give decisions about their search directions in order to effectively discovering the solution space of an optimization problem. Each artificial agent has its own point over the search space and this point has an attractant effect over the other artificial agents. This attractiveness of an artificial agent is a measure in proportional to its current positions quality, which is actually the objective function value at this point. As mentioned above, an agent determines its search direction while considering all the other agents’ attractiveness not a single one's and this process is more realistic from the optimization point of. As a result, WSA tries to simulate this decision making process, a combination of attractant movement and superposition principle, as a new swarm based solution approach.The remainder of this paper is organized as follows. Some related works are discussed in Section 2. The newly developed swarm based algorithm is defined in Section 3. Comparative computational study is given in Section 4, and the discussions and conclusions are presented in Section 5.

@&#CONCLUSIONS@&#
In this paper, we have introduced a new swarm based search algorithm named as Weighted Superposition Attraction (WSA), which was based on two basic mechanisms, “superposition” and “attracted movement of agents”, that are observable in many systems. In many natural phenomena it is possible to compute superposition or weighted superposition of active fields as it is also applicable for social systems as well. An agent usually moves towards to this superposition due to the attractiveness of this superposition. As systems have dynamic structures their status changes over time, hence the superposition is also dynamic and changes over time; so it is required to be recomputed over time. This phenomenon was the main inspiration source while developing the WSA algorithm, which mainly simulates the dynamically changing superposition due to the dynamic nature of the system in combination with the attracted movement of agents as a search procedure for solving the optimization problems in an innovative manner.In order to evaluate the capability of WSA in tackling the complex optimization problems, a set of computational experiments was carried out. The computational experiments was done in two parts: the first part evaluated the performance of WSA on a benchmark set contains 50 standard global optimization functions with different dimensions and the second part evaluated the performance of WSA on a benchmark set contains 13 standard global optimization functions with bigger sizes dimensions in comparison to different version of PSO published between the years of 1998 and 2015. The obtained results reveal the effectiveness of WSA in solving global optimization problems in terms of solution quality and execution time.Future research directions will focus on adapting WSA so as to have the ability of effectively solving different combinatorial and multiple objective optimization problems and constrained optimization problems along with some other real life optimization applications.The reader can refer tohttp://web.deu.edu.tr/baykasoglu/wsa.htmlfor the Matlab code of WSA for Schaffer1 (SF1) function.In this appendix we present a numerical example on the two dimensional Bohachevsky 1 Problem (BF1) (Eq. (A.1)) for two iterations and 10 function evaluations per iteration. The BF1 function is a minimization problem and has an unknown number of local minima, but the global minimum of this function is located at x*=(0, 0) with f*(x1, x2)=0.(A.1)minxf(x)=x122x22−0.3cos(3πx1)−0.4cos(4πx2)+0.7WSA starts its search from the initial points with the fitness values and weights given in Table A.1. The weights values are assigned to each point according to their ranks among all points.The target point is determined by using the initial points and their ranks as 7.7998 and 6.2517 for x1 and x2 respectively. Additionally, the fitness value of the target point is obtained as 140.1973. Now it is required to determine the search directions of each point with regard to target point's fitness value and each point's fitness value. Table A.2presents the determined move directions for all solutions’ dimensions and how each solution to select its move direction.After determining the search directions, each solution required to update its current position by using Eq. (1) (Section 3.2.2) according to the initial step length of 0.035. By the way the solutions move to newly determined positions given in Table A.3after the first iteration. Additionally, the fitness values for the newly determined points are calculated and they ranked again according to their fitness values and weights are assigned to each solution with regard to its rank. Table A.3 also contains the fitness values and weights for the points determined after the first iteration.The target point for the second iteration is determined as 7.5340 and 6.0329 for x1 and x2 respectively with the fitness value of 129.9826. Similar to first iteration move directions are determined for all points’ directions as given in Table A.4. Additionally, points after the second iteration with their fitness values are also given in Table A.4.