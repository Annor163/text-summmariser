@&#MAIN-TITLE@&#
A Tabu Search hyper-heuristic strategy for t-way test suite generation

@&#HIGHLIGHTS@&#
HHH is the first strategy that adopts the hyper-heuristic approach for t-way test suite generationHHH introduces new approach for the heuristic selection and move acceptance mechanism based on three operators (i.e. improvement operator, diversify operator, and intensify operator) that are integrated into the Tabu search HLH.HHH outperforms existing strategies as far as optimality of test suite is concerned in many benchmarks.

@&#KEYPHRASES@&#
Software testing,t-way Testing,Hyper-heuristic,Particle Swarm Optimization,Cuckoo Search Algorithm,Teaching Learning based Optimization,Global Neighborhood Algorithm,

@&#ABSTRACT@&#
This paper proposes a novel hybrid t-way test generation strategy (where t indicates interaction strength), called High Level Hyper-Heuristic (HHH). HHH adopts Tabu Search as its high level meta-heuristic and leverages on the strength of four low level meta-heuristics, comprising of Teaching Learning based Optimization, Global Neighborhood Algorithm, Particle Swarm Optimization, and Cuckoo Search Algorithm. HHH is able to capitalize on the strengths and limit the deficiencies of each individual algorithm in a collective and synergistic manner. Unlike existing hyper-heuristics, HHH relies on three defined operators, based on improvement, intensification and diversification, to adaptively select the most suitable meta-heuristic at any particular time. Our results are promising as HHH manages to outperform existing t-way strategies on many of the benchmarks.

@&#INTRODUCTION@&#
Interaction (t-way) testing is a methodology to generate a test suite for detecting interaction faults. The generation of a t-way test suite is an NP hard problem [1]. Many t-way strategies have been presented in the scientific literature. Some early algebraic t-way strategies exploit exact mathematical properties of orthogonal arrays. These t-way strategies are often fast and produce optimal solutions, yet they impose restrictions on the supported configurations and interaction strength. Computational t-way strategies remove such restrictions, allowing for the support of arbitrary configurations at the expense of producing (potentially) non-optimal solution.By formulating interaction testing as an optimization problem, recent efforts have focused on the adoption of meta-heuristic algorithms as the basis for t-way strategies. Search Based Software Engineering (SBSE) [2–4], is a relatively new field that has proposed meta-heuristic based t-way strategies (e.g. Genetic Algorithms (GA) [5], Particle Swarm Optimization (PSO) [6,7], Harmony Search Algorithm (HS) [8], Ant Colony Algorithm (ACO) [5], Simulated Annealing (SA) [9,10] and Cuckoo Search (CS) [11]). The adoption of these meta-heuristic based strategies appears to be effective for obtaining good quality solutions, as reported in benchmarking experiments related to t-way testing [7,8]. Nevertheless, as suggested by the No Free Lunch theorem[12], no single meta-heuristic can outperform all others even over different instances of the same problem. For this reason, hybridization of meta-heuristics can be the key to further enhance the performance of t-way strategies. Since each meta-heuristic has its own advantages, meta-heuristic hybridization is beneficial for compensating the limitation of one with the strengths of another. In fact, the best results of many optimization problems are often obtained by hybridization [13].In this paper we explore the hybridization of meta-heuristics based on a hyper-heuristic approach. We present a new t-way testing strategy. Specifically, our contributions can be summarized as follows:•A novel hyper-heuristic based strategy, which we have termed High Level Hyper-Heuristic (HHH), for general combinatorial t-way test suite generation. HHH employs Tabu Search (TS) as its high level meta-heuristic (HLH) and leverages on the strength of four low level meta-heuristics (LLH), comprising Teaching Learning based Optimization (TLBO) [14], Global Neighborhood Algorithm (GNA) [15], Particle Swarm Optimization (PSO) [16], and Cuckoo Search Algorithm (CS) [17]. To the best of our knowledge, HHH is the first hyper-heuristic based strategy that addresses the problem of t-way test suite generation.A new hyper-heuristic approach for the meta-heuristic selection and acceptance mechanism based on three operators (i.e. improvement, diversification and intensification) that are integrated into the Tabu Search HLH. As the name suggests, the improvement operator checks for improvements in the objective function. The diversification operator measures how diverse the current and the previously generated solution are against the population of potential candidate solutions. Finally, the intensification operator evaluates how close the current and the previously generated solution are against the population of solutions.The rest of the paper is organized as follows. Section 2 presents an overview of hyper-heuristics and the mathematical and theoretical foundation for t-way testing. Section 3 reviews the state-of-the-art for t-way test case generation strategies. Section 4 presents the design and implementation of HHH. Section 5 describes the calibration of HHH. Section 6 evaluates HHH against existing strategies and Section 7 debates the usefulness of HHH. Section 8 elaborates on threats to validity. Finally, Section 9 presents our conclusion.To put hyper-heuristics into perspective, consider the different possible options for utilizing and combining meta-heuristic algorithms (see Fig. 1). The first option, shown for completeness, is a standard meta-heuristic algorithm and can be ignored from our discussion as we want to focus on hybridization methodologies. These are shown in remaining figures, that is a hybrid meta-heuristic and a hyper-heuristic.Hybrid meta-heuristics can be low-level or high level hybridizations [13]. Low-level hybridization combines two or more algorithms. High-level hybridization retains the original meta-heuristic, which can run independently (e.g. either in sequence or parallel) without any connection amongst the meta-heuristics involved (i.e. it operates as a black box).Hyper-heuristics could be seen as a hybrid meta-heuristic owing to the integration of more than one meta-heuristic algorithm (refer to Fig. 1). However, unlike a typical hybrid meta-heuristic, hyper-heuristics (or (meta)-heuristic to choose (meta)-heuristics[18–20]) adopts a high level meta-heuristic (HLH) to adaptively select from a set of low level meta-heuristics (LLHs), which are applied to the problem at hand. The LLHs communicate with the HLH through a domain barrier to relay the feedback of the quality of the current solution. Only the LLHs have domain knowledge, meaning that the HLH is a general algorithm that can be utilized for different problems without any algorithmic changes. It is only required to supply a different set of LLHs. In fact, the LLHs can also be formed from (low-level or high-level) hybrid meta-heuristics themselves.Recent developments have introduced hyper-heuristics that are able to automatically generate the LLHs, whereby the end user does not have to implement a set of LLHs for each problem domain. Moreover, the HLH is also able to evolve its own selection and acceptance criteria [21,22].Consider a hypothetical example of a mobile phone product configuration. The product configuration has four features (or parameters): Call Options, Message Types, Media, and Screen. Each parameter takes three possible values (e.g. Call Options={Voice Calls, Video Calls, Both Voice and Video Calls}, Message Types={Text, Video, Image}, Media={Camera, Radio, Video Player}, and Screen={Basic Colors, High Resolution, Black and White}). The pairwise (2-way) test generation for the Mobile Product Configuration can be seen in Fig. 2with nine test cases. The mapping of the corresponding tests can be achieved (row-wise) from the 2-way representation based on the defined parameter values (column-wise) as depicted in Table 1. It should be noted that all the 2-way interaction tuples between parameters are covered at-least once.Mathematically, the t-way test generation problem can be expressed by Eq. (1).(1)f(Z)=|{Iin VIL:ZcoversI}|Subject to Z=Z1, Z2, ..., Zi, in P1, P2, ... ..., Pi; i=1, 2, ..., Nwhere, f(Z) is an objective functions (or the fitness evaluation), Z (i.e., the test case candidate) is the set of decision variables Zi, VIL is the set of non-covered interaction tuples (I), the vertical bars | · | represent the cardinality of the set and the objective value is the number of non-covered interaction tuples covered by Z, Piis the set of possible range of values for each decision variable, that is, Pi=discrete decision variables (Zi(1)<Zi(2)<……<Zi(K)); N is the number of decision variables (i.e. parameters); and K is the number of possible values for the discrete variables.In general, t-way testing has strong associations with the mathematical concept of covering arrays (CA). For this reason, t-way testing often adopts CA notation for representing t-way tests [23]. The notation CAλ(N; t, k, v) represents an array of size N with v values, such that every N×t sub-array contains all ordered subsets from the v values of size t at least λ times [24,25], and k is the number of components. To cover all t-interactions of the components, it is normally sufficient for each component to occur once in the CA. Therefore, with λ=1, the notation becomes CA (N; t, k, v). When the CA contains a minimum number of rows (N), it can be considered an optimal CA according to the definition in Eq. (2)[26].(2)CAN (t, k, v)=min {N: ∃ CAλ(N; t, k, v)}To improve readability, it is customary to represent the covering array as CA (N; t, k, v) or simply CA (N; t, vk). Using our earlier example of the mobile phone product configuration in Fig. 2, the test suite can be represented as CA (9; 2, 34). In the case when the number of component values varies, this can be handled by Mixed Covering Array (MCA) (N; t, k, (v1, v2,…vk)) [27]. Similar to covering array, the notation can also be represented by MCA (N; t, k, vk). For example, MCA (9; 2, 32 22) represents a test suite of size nine for a system with four components (two components having three values and two components having two values) covering two-way interactions. Fig. 3illustrates the two aforementioned CA and MCA arrangements respectively.Having described the theoretical framework, the following section surveys the existing studies on t-way strategies in order to reflect the current progress and achievements in the scientific literature.Generally, t-way strategies can be classified as algebraic or computational approaches [28,29]. Algebraic approaches are often based on the extensions of the mathematical methods for constructing Orthogonal Arrays (OAs) [30,31]. Examples of strategies that originate from the extension of OA include Combinatorial Test Services and TConfig. The main limitation of the OA solutions is the fact that not all solutions can be found for t>2, thus, limiting its applicability for small scale system configuration. Empirical evidence [32] suggest the need to support up to at least t=6 in order to sufficiently cater for interaction faults.Much existing work has placed emphasis on the computational-based approaches that provide support for very large configurations. Specifically, there are two competing approaches for constructing t-way test suites, that is, the one-test-at-a-time (OTAT) approach and the one-parameter-at-a-time (OPAT) approach. In the first case, the strategy iteratively traverses the required interaction and generates a complete test case per iteration. During each iteration, the strategy greedily checks whether or not the generated test case is the best fit value (i.e. covering the most uncovered interactions) to be selected in the final test suite. In the second case, the strategy constructs the test case incrementally by horizontal extension until completion. This is followed by vertical extension, if necessary, to cover the remaining uncovered interactions.One-test-at-a-time based strategies were pioneered by AETG [33]. AETG first constructs all the required interactions then generates one final test case for every cycle, for each iteration. For each cycle, AETG generates a number of test case candidates, and from these candidates, one is greedily selected as the final test case (i.e., covering the most uncovered interactions). Over the years, a number of variations of AETG have emerged including mAETG [27] and mAETG_SAT [34]. Similar to AETG, GTWay [35,36] also adopts the one-test-at-a-time approach to generate the final test suite. Unlike AETG, GTWay permits the use of actual parameter values as a symbolic string and supports automated execution of test cases.Claiming to be an AETG variant, the test vector generator (TVG) [37] generates test suites based on three algorithms: T-reduced, Plus-one, and Random sets. Due to limited literature, the details’ concerning the implementation for each algorithm remains unclear. However, based on our experience with TVG implementation, T-reduced often produces the greater number of optimal results compared with other algorithms.Jenkins [38] adopts the one-test-at-a-time approach by first generating a test suite that covers the 1-way interaction. Later, the test suite was extended to cover 2-way interactions and the process was repeated until all t-way interactions (where t is specified by the user) are covered. At around the same time, Hartman developed the Intelligent Test Case Handler (ITCH) [39] as an Eclipse Java plug-in tool. ITCH relies on exhaustive search to construct the test suites for t-way testing. Owing to its exhaustive search algorithm, ITCH’s execution time typically takes a long time and results are often not optimal.PICT [40,41] generates all specified interactions, and randomly selects their corresponding interaction combinations to form the test cases as part of the complete test suite. Due to its random behavior, PICT tends to give poor test sizes as compared to other strategies.Classification-Tree Editor eXtended Logics (CTE-XL) [42,43] is a t-way strategy based on the Classification-Tree Method (CTM). The idea is that CTM abstracts and separates the test object’s input domain into different subsets according to features that the test engineer considers relevant to the test. Then, test cases are produced by combining subsets from different classifications as one-test-at-a-time.Complementing the one-test-at-a-time approach, the in-parameter-order (IPO) strategy [44] is a strategy that adopts the one-parameter-at-a-time approach. IPO generates a pairwise test set for the first two parameters, and then extends the test set by generating the pair for the first three parameters and so on, until all the system parameters are covered. This is followed by a vertical extension to cover the uncovered interactions, if necessary. The IPO strategy was later generalized into a number of variants; IPOG [45], IPOG-D [46] and IPOF [47]. Owing to its simplicity, IPO has been adopted by other researchers, notably in the development of MIPOG [48–50]. Unlike IPO and its family, MIPOG removes inherent dependencies between horizontal and vertical extensions in order to permit parallel t-way test suite generation on multiple-core machines.Recently, efforts have been focused on the use of meta-heuristic algorithms as part of the computational approach for t-way test generation. Strategies adopting meta-heuristic algorithms as the basis of t-way strategies appear to be superior to other computational approaches. Its popularity has increased due to the interest in Search based Software Engineering [4].Generally, meta-heuristic algorithms start with a random set of solutions. These solutions undergo a series of transformations in an attempt to improve them. One best candidate is selected at each iteration until all the required interactions are covered. Concerning t-way test generation, a number of meta-heuristic algorithms have been explored as the basis for t-way strategies including Genetic Algorithms (GA), Ant Colony Optimization (ACO), Simulated Annealing (SA), Particle Swarm Optimization (PSO) and Cuckoo Search (CS).GA, ACO, and SA represent early attempts to utilize meta-heuristic algorithms for constructing t-way strategies. A GA [5] mimics the natural selection processes. It begins with randomly created test cases, referred to as chromosomes. These chromosomes undergo crossover and mutation until a termination criteria is met. In each cycle, the best chromosomes are (probabilistically) selected and added to the final test suite. Unlike GAs, ACO [5] mimic the behavior of ants in their search for food. SA [51] relies on a large random search space and probability-based transformation equations for generating a t-way test suite.Although useful for addressing small values of uniform interaction strength t (i.e. t≤3), strategies based on GA, ACO, and SA are not without their limitations. GA and ACO have been criticized for their complex algorithm structure as well as potentially requiring large computational resources. SA, being a single solution meta-heuristic, can be sensitive to its initial starting point in the search space, hence, prone to suffer from early convergence. For these reasons, these algorithms have been limited to small interaction strengths (i.e. t≤3). Addressing earlier limitations of SA, an improved variant of SA, called CASA [52], has been developed to address the t-way test generation for software product lines testing.PSTG [53–56] is a meta-heuristic t-way strategy based on Particle Swarm Optimization, which mimics the swarm behavior of birds. Internally, PSTG iteratively performs local and global searches to find the candidate solution to be added to the final suite until all the interaction tuples are covered. Unlike other AI-based strategies, that address small values of t (i.e. 2≤t≤3), the most notable feature of PSTG is the fact that it can support up to t=6.Complementary to PSTG, HSS [8] is a meta-heuristic strategy based on the Harmony Search Algorithm (HSS). HSS mimics musicians trying to compose good music from improvisations to create the best tune from their memory or from random sampling. In doing so, HSS iteratively exploits the Harmony memory to store the best found solution through a number of defined improvisations within its local and global search process. In each improvisation, one test case will be selected to be the final test suite until all the required interactions are covered. Unlike PSTG, HSS addresses the support for forbidden combinations (or constraints).Cuckoo Search (CS) [11] is a recent strategy for t-way test generation. At the start, the algorithm generates random initial nests. Each egg in a nest represents a vector solution (i.e. a test case). At each generation, two operations are performed. Firstly, a new nest is generated (typically through Levy Flight path) and evaluated against the existing nests. The new nest will replace the current nest, if it has a better objective function. Secondly, CS has probabilistic elitism in order to maintain elite solutions for the next generation.Existing meta-heuristic based strategies have been successful as the basis of t-way strategies. Extending and complementing existing works, this paper proposes combining more than one meta-heuristic as part of a t-way strategy. Instead of taking one meta-heuristic algorithm, our approach takes four algorithms to form the basis of our strategy, called High Level Hyper-Heuristic (HHH). We utilize four recently developed meta-heuristic algorithms, these being Teaching Learning based Optimization (TLBO), Global Neighborhood Algorithm (GNA), Particle Swarm Optimization (PSO) and Cuckoo Search Algorithm (CS).The proposed HHH strategy utilizes Tabu Search as the high level meta-heuristic (HLH), incorporating a selection and acceptance mechanism based on three defined operators (i.e. improvement, diversification and intensification operator). The HHH strategy is illustrated in Fig. 4. The algorithmic details are provided in the next sections.The pseudo code for the Tabu Search HLH is shown in Fig. 5.Line 1 initializes the population of the t-way interaction tuples, I={I1, I2… IM}. The value of M depends on the given input interaction strength (t), parameter (k) and its corresponding value (v). Specifically, M captures the number of required interactions that needs to be covered in the final test suite. M can be obtained as the sum of products of each individual’s t-way interaction. For example, for CA (9; 2, 34), M takes the value of 3×3+3×3+3×3+3×3+3×3+3×3=54. If MCA (9; 2, 32 22) is considered, then M takes the value of 3×3+3×2+3×2+3×2+3×2+2×2=37. Line 2 defines the maximum iteration ϴmax and population size, N. Line 3 randomly initializes the initial population of solutions Z={Z1, Z2… ZN}. Line 4 selects the initial LLH from the four available meta-heuristics. The selected hyper-heuristic algorithm (LLH), Hiwill then be performed repeatedly until all the interactions in I has been covered and the maximum fitness function limit, Fmax, has been reached, as shown in lines 5–22. The selected LLH Hiwill update the population Z for ϴmax iterations, as shown in line 7. In line 8, Zbest (the individual with the best quality) is added to the final test suite (TS). To decide whether to select a new LLH or not, the three operators, comprising the improvement, diversification and intensification operator (lines 9–11) will be used. More precisely, the three operators work as follows.The improvement operator compares the current Zbest against the previous Zbest from the final test suite TS. F1 evaluates to true only if Zbest≥previous Zbest.The diversification operator exploits the hamming distance measure to evaluate the diversification of each Zbest solution (i.e. in terms of how far Zbest is from the population of candidate solutions). The hamming distance measure between two rows of Z, d(Zi, Zj) is defined as the number of values in which they differ. Referring to Fig. 6and assuming Zbest=Z3, the hamming distance between Z1 and Zbest is d(Z1, Zbest)=4 (since all the values differ) and the hamming distance between Z2 and Z3 is d(Z2, Zbest)=3 (with three values being different). In this case, the diversification value dvcan be defined as the cumulative sum of the hamming distance measure of each individual Z population with Zbest. Here, the value of dv=7 (i.e. as the sum of d(Z1, Zbest) and d(Z2, Zbest)).As far as the diversification operator is concerned, the current value of dvwill be compared to the previous value of dv(i.e. from the previous iteration). F2 evaluates to true only if the current dv≥the previous dv.Like the diversify operator, the intensification operator also exploits the hamming distance to evaluate the intensification of each Zbest solution. Unlike the diversification operator, the intensification operator measures the intensification value, Iv, of Zbest against the final test suite TS population (i.e. how close is Zbest to the final test suite). To be more specific, the intensification value can be defined as the cumulative sum of the hamming distance of each individual TS population with Zbest. Here, the current value of Ivwill be compared to the previous value of Iv(i.e. from the previous iteration). F3 evaluates to true only if the current Iv<=the previous Iv.In line 12 (Fig. 5), the meta-heuristic selection and acceptance mechanism, ψ(Hi, F1, F2, F3) evaluates to true, if and only if, F1=true and F2=true and F3=true. If ψ(H, F1, F2, F3) evaluates to false, the new Hiwill be selected (and the current Hiwill be put in the Tabu List). Visually, the internal working of the meta-heuristic selection and acceptance mechanism, ψ, is shown in Fig. 7.Referring to lines 17–20, the current Hiis penalized and will miss at least one turn from being selected in the next iteration. Apart from one’s own performance in terms of objective value improvement, diversification, and intensification, a particular LLH can be chosen more frequently than others owing to the random selection of meta-heuristics within the Tabu Search (line 18).Finally, it is worth mentioning here that the adopted LLHs are designed for continuous problems. As such, to deal with discrete parameters and values, each individual Zjneeds to capture the parameters as a valid range of integer numbers (i.e. based on the user inputs). When the HHH iterates, each Zjwill be updated accordingly depending on the chosen LLH (i.e. based on the specific LLH transformation equation). Here, the LLH update may result into the need to do rounding off floating point values. Apart from rounding off floating point values, there is also the need to deal with out-of-range values. Within HHH, we establish the boundary condition (i.e. as clamping rule) to restrict parameter values to both lower and higher bounds. In this way, when Zjmoves out-of-range, the boundary condition brings it back to the search space. We configure our boundary condition in such a way that when the Zjvalue reaches a certain dimensional bound, we reset its position to the other endpoint. For example, if we have a parameter with a range of values from 1 to 3, when the position is greater than 3, the position is reset to 1.The Teaching Learning based Optimization (TLBO) [14] is a population based meta-heuristic that draws on the analogy of the teaching and learning process between teachers and students. In TLBO, teachers attempt to impart knowledge in a way that will enhance the knowledge of their students. With knowledge gained from a particular teacher, the knowledge of the students would be enhanced. As teachers have different competency levels, there could be potential improvements if students learn from other teachers. Students can also learn from other students, yielding similar improvements.The TLBO algorithm is shown in Fig. 8.During the teacher phase (lines 7–10), each student learns from the best teacher Zbest teacher, that is, the best individual in the population. The student will move toward the Zbestteacher teacher by taking into account the current mean value of the learners, Zmean, that represents the qualities of all the students in the population (line 8). The movement of the learner is also affected by the teaching factor, TiF(line 7).For the learner phase (lines 11–18), each student attempts to improve its knowledge through interaction with its peers. Specifically, the student Ziwill select a peer learner Zj(where i≠j). If Zihas better fitness than Zj, the latter is moved toward the former (line 15) and vice versa (line 16).Concerning its implementation, unlike most meta-heuristic algorithms, TLBO has twice more fitness function evaluations due to the two phases (teacher and learner). For this reason, direct comparative experiments with TLBO and other meta-heuristic algorithms can be misleading. Additionally, despite its parameter free claims, TLBO still requires tuning of its population size and iteration. Recently, the original author for TLBO [14] has been criticized for not reporting the duplicate elimination step in the implementation resulting into inaccurate and unfair comparative results [57]. For our implementation, we consider the TLBO implementation without the duplicate elimination step (similar to that of Yarpiz [58]).Like TLBO, the Global Neighborhood Algorithm (GNA) [15], is a population based meta-heuristic. GNA has only two control parameters; population size and the maximum number of iterations. The GNA algorithm is shown in Fig. 9.In GNA, the population is divided into two phases. In the first phase, GNA performs a local search through perturbation of Zi(line 5). If the pertubated Zihas a better fitness value, then the incumbent is replaced (lines 4–5).In the second phase, GNA performs a random search. If Zrandom has better fitness value than the current Zi, Ziwill be replaced with Zrandom (lines 10–11).Particle Swarm Optimization (PSO) [16] is a population based meta-heuristic that simulates the swarm behavior of flocks of birds or schools of fish. PSO comprises a group of particles with negligible mass and volume and which move through hyperspace. Each particle attempts to find a better position (solution) by recording and updating essential information about its movement. This information is related to the ith particle of interest, which includes the current position (Zi), the velocity (Vi), local best (Zlbest) and global best (Zgbest). The PSO algorithm is shown in Fig. 10.During the search, each Zith particle of the population stochastically adapts its trajectory through velocity its local best (Zlbest) and global best value (Zglobal best) through velocity (Vi) as indicated in lines 7–8. In turn, the velocity (Vi) exploits three coefficients c1, c2, and ω respectively. Here, c1 and c2 are the acceleration coefficients that control the personal and global best to the updated velocity; and ω is the inertia weight that is used to balance the global/local searches of the particle. In lines 9–10, if the updated Zihas better fitness than current Zi, the incumbent is updated. Finally, Zbest will be assigned to Ziif the latter has better fitness (lines 11–12).The Cuckoo Search Algorithm (CS) [17] is a population based meta-heuristic algorithm that is based on the parasitic behavior and aggressive reproduction strategy of Cuckoos. The female Cuckoos lay their eggs (potential solutions in the algorithm) in the nest of other birds and have the ability to imitate the colors and pattern of the host eggs. Cuckoos also have the ability to remove existing (the host birds, or other cuckoos) from the nest. In the algorithm, this is akin to replacing a poorer solution with a better one. The CS algorithm is shown in Fig. 11.The CS algorithm provides two search capabilities: global search, which allows the algorithm to jump out of local optimum, and local search by intensifying search around the current best solution, via Lévy Flight motion. The Lévy Flight motion is a random walk that takes a sequence of jumps, which are selected from a heavy tailed probability function. For our Lévy Flight implementation, we adopt the well-known Mantegna’s algorithm [17]. Within this algorithm, a step length can be defined as:(3)Step=u[v]1βwhere u and v are approximated from the normal Gausian distribution in which:(4)u≈N(0,σu2)×σuv≈N(0,σv2)×σvFor v value estimation, we useσv=1. For u value estimation, we evaluate the Gamma function (Γ) with the value ofβ=1.5[59], and obtainσuusing:(5)σu=|Γ(1+β)×sin(πβ2)Γ((1+β)2)×β×2(β−12)|1βIn our case, the Gamma function (Γ) implementation is adopted from Press et al. [60].During the search, Ziwill be continuously updated from its previous value with the appropriate step size (α), entry-wise multiplication (⊕) and Lévy Flight motion as indicated in line 3. If the updated Zihas better fitness than the current Zi, the former is updated (lines 4–5). CS also maintains an elite population of solutions (lines 7–13). CS will replace a fraction pa×S of the poorly generated Zworst solutions (where pa is the elitism factor ranging from 0.0<pa<1.0) with a random solution Zrandom, iteratively if the corresponding fitness improves.It is worth mentioning here that the number of fitness function evaluation for CS cannot be determined statistically owing to the probability pa. However, a counter can be put during run-time to determine the exact number of fitness evaluation (so as to have the same fitness evaluation as other LLHs).As far as calibration is concerned, there are generally two types of parameters of concern; specific algorithm parameters and common algorithm parameters. The former relates to the algorithm settings of the four LLHs, whilst the latter accounts for the common parameters between LLHs and HLH.Table 2summarizes the parameters that are to be calibrated.In the design of HHH, the specific algorithm parameters are the Tabumax of the Tabu Lists for TS HLH, c1, c2(i.e. acceleration coefficients) and ω (inertial weight) for PSO LLH as well as pa (elitism factor) for CS LLH. As for TLBO LLH and GNA LLH, their parameters are ϴmax and S (which are also shared by PSO LLH, Cuckoo LLH and Tabu HLH as well). As far as the calibration of specific algorithm parameters is concerned, the value of Tabumax=4 can be easily deduced as the number of adopted meta-heuristics as LLH. Any particular meta-heuristic can either be available for selection or penalized in the Tabu List depending on its prior performance. Meanwhile, the value of c1=1.375, c2=1.375, ω=0.3 and pa=0.25 are adopted from existing work reported in the context of adopting PSO [7] and CS [11] as t-way ‘test generation strategy respectively.Unlike the specific parameters, the calibration of common parameters ϴmax iteration and population size, S, can be subtle owing to the way each individual LLH operates. As highlighted earlier, TLBO requires twice as much fitness function evaluation as GNA and PSO. Furthermore, Cuckoo also has non-deterministic number of fitness evaluation owing to the elitism probability pa. This large diversification makes it hard to select the appropriate value for both ϴmax and S to ensure fair comparison with other meta-heuristic based strategies particularly when it comes to the fitness function evaluation. For this reason, we decide to establish the limit on the maximum fitness function evaluation, called Fmax, as seen in Table 2. Specifically, we define Fmax=400,000 as it was empirically verified to be large enough to allow HHH’s solution to converge even for the largest configurations. Internally, we have implemented a global static counter (as part of fitness function evaluation) that ensures the Fmax limit is adhered to.Having established the Fmax=400,000 as the stopping criterion, the selection of ϴmax and S follow accordingly. In this case, any values of ϴmax and S can be selected as long as the value of Fmax is observed. For example, if the selected values of ϴmax=20 and S=40, the minimum fitness evaluation per iteration is at least 20×40=800 and the maximum possible iteration for convergence is 400,000/800=500. In similar manner, if the selected values of ϴmax=20 and S=100, the minimum fitness evaluation per iteration is at least 20×100=2000 and the maximum possible iteration for convergence is 400,000/2000=200. For our case, considering the recommendation from the scientific papers in Refs. [59,61], we opt to adopt the former case with ϴmax=20 and S=40.

@&#CONCLUSIONS@&#
