@&#MAIN-TITLE@&#
A modified ABC algorithm for the stage shop scheduling problem

@&#HIGHLIGHTS@&#
A modified artificial bee colony algorithm is proposed for the stage shop scheduling problem.The stage shop is a new extension for the mixed shop problem and as a result, for job shop and open shop problems.In employed bee phase of ABC, a potent neighborhood of the stage shop is used and a tabu search manner is substituted for greedy selection.In onlooker bee phase of ABC, particle swarm optimization idea is applied instead of completely random search.The proposed algorithm obtained new optimal solutions and upper bounds for benchmark problems.

@&#KEYPHRASES@&#
Scheduling,Stage shop,Artificial bee colony,CMA-ES,Particle swarm optimization,

@&#ABSTRACT@&#
Stage shop problem is an extension of the mixed shop as well as job shop and open shop. The problem is also a special case of the general shop. In a stage shop, each job has a number of stages; each of which includes one or more operations. As a subset of operations of a job, the operations of a stage can be done without any precedence consideration of each other, whereas the stages themselves should be processed according to a preset sequence. Due to the NP-hardness of the problem, a modified artificial bee colony (ABC) algorithm is suggested. In order to improve the exploitation feature of ABC, an effective neighborhood of the stage shop problem and PSO are used in employed and onlooker bee phases, respectively. In addition, the idea of tabu search is substituted for the greedy selection property of the artificial bee colony algorithm. The proposed algorithm is compared with the traditional ABC and the state-of-the-art CMA-ES. The computational results show that the modified ABC outperforms CMA-ES and completely dominates the traditional ABC. In addition, the proposed algorithm found high quality solutions within short times. For instance, two new optimal solutions and many new upper bounds are discovered for the unsolved benchmarks.

@&#INTRODUCTION@&#
Scheduling can be defined as the allocation of resources to perform a collection of tasks over a period of time [1]. Job shop and open shop as notoriously intractable scheduling problems are focused by many researchers. However, the real world situations do not exactly coincide with one of these two problems, and therefore extensions are presented. In mixed shop, as a famous extension of job shop and open shop, the set of jobs is divided into two disjoint subsets: one subset of the open shop category and the other one of the job shop category. The mixed shop problem is NP-hard in its general form [2]. Furthermore, a generalization of the job shop scheduling problem is presented by Kis [3] wherein the job routings are directed acyclic graphs. These graphs include sets of alternative subgraphs comprising several operations each and can model partial orders of operations. Nasiri and Kianfar [4] proposed a new extension of the mixed shop problem called stage shop and solved it by means of a combination of genetic algorithm and tabu search.Artificial bee colony (ABC) as a population-based meta-heuristic shows outstanding performance when it is applied to the combinatorial optimization problems. Karaboga et al. [5] presented a survey of the applications of ABC algorithm. In addition, several works tried to evaluate the performance of ABC in comparison with other algorithms [6–8]. Moreover, the scheduling literature is full of papers using ABC to find a near optimal solution for NP-hard problems.There are frequent implementations of artificial bee colony algorithms for the flow shop scheduling. Liu and Liu [9] developed a hybrid discrete artificial bee colony to minimize the makespan in permutation flow shop scheduling problems. Li and Yin [10] presented a kind of discrete artificial bee colony with composite mutation strategies for the permutation flow shop scheduling problem. Lin et al. [11] developed a hybrid artificial bee colony algorithm with bi-directional planning to minimize makespan for the problem of scheduling multistage hybrid flow shops with multiprocessor tasks. Tasgetiren et al. [12] introduced a discrete artificial bee colony algorithm hybridized with a variant of iterated greedy algorithms to find the permutation that gives the smallest total flow time in flow shop. Pan et al. [13] presented a discrete artificial bee colony algorithm for solving the lot-streaming flow shop scheduling problem with the criterion of total weighted earliness and tardiness penalties under both the idling and no-idling cases. Tasgetiren et al. [14] presented a discrete artificial bee colony algorithm to solve the no-idle permutation flow shop scheduling problem with the total tardiness criterion.ABC is applied to the job shop scheduling problem as well. Wang et al. [15] applied ABC algorithm to the flexible job-shop scheduling problem with the makespan criterion. Zhang et al. [16] proposed a novel artificial bee for minimizing the total weighted tardiness in job shop scheduling problem. Banharnsakun et al. [17] proposed an effective scheduling method based on Best-so-far Artificial Bee Colony (Best-so-far ABC) for solving the JSSP. In this method, authors biased the solution direction toward the Best-so-far solution rather a neighboring solution as proposed in the original ABC method. Interval job shop scheduling problem with non-resumable jobs and flexible maintenance is considered by Lei [18] and a multi-objective artificial bee colony is proposed to minimize interval makespan and a newly defined objective called total interval tardiness. Zhou et al. [19] used ABC to solve the multi-objective flexible job-shop scheduling problem with the criteria to minimize the maximum completion time, the total workload of machines and the workload of the critical machine simultaneously. Li et al. [20] presented a hybrid Pareto-based discrete artificial bee colony algorithm for solving the multi-objective flexible job shop scheduling problem. In the hybrid algorithm, each solution corresponds to a food source, which composed of two components, i.e., the routing component and the scheduling component.The tabu search and particle swarm optimization ideas are both very successful in solving the combinatorial optimization problems; however, they are not utilized together in ABC so far. In this work, ABC algorithm is modified using TS and PSO concepts and applied to the stage shop problem with makespan criterion. In order to evaluate the performance of the proposed algorithm, two other algorithms, i.e. traditional ABC and CMA-ES, are also implemented. To the best of our knowledge, this research is the first application of ABC to the stage shop problem and the first implementation of CMA-ES to a scheduling problem. An innovative idea used in this paper is switching the encoding of the solutions in transition from the employed bee to the onlooker bee phase and vice versa, which results in better exploration of the search space.The remainder of the paper is organized as follows. In the next section, the stage shop problem, its formulation and notations are introduced. Section 3 describes the three stochastic algorithms: the traditional ABC, the proposed ABC and the CMA-ES. In Section 4, the computational results are presented. Finally, some concluding remarks are given in the last Section.According to Nasiri and Kianfar [4], stage shop is defined as a generalization of the mixed shop and a special case of the general shop problem. A stage shop comprises several jobs, each of which includes several stages of operations. No precedence constraint exists between the operations of a job which are in the same stage. That is, they could be processed in any relative sequence without violating the feasibility of the solution. If all operations of a job are involved in one stage, the job resembles an open shop job of the mixed shop problem. A predetermined order exists for processing the stages of a job, similar to the operations of a job in a job shop. Thus, when each stage of a particular job has exactly one operation, the job resembles a job shop job of the mixed shop problem. Consequently, the mixed shop is a special case of the stage shop. It is worthwhile to note that in the stage shop problem the operations of two distinct jobs cannot have a predetermined precedence relation. So, the stage shop is a special case of the general shop problem. An efficient tool for explaining the scheduling problems is disjunctive graph (for more information, see [1]). The disjunctive graph for an instance of the stage shop scheduling problem is depicted in Fig. 1. In this instance, we have three jobs, the first two of which have three stages and the last one has only two stages. The solid (conjunctive) arcs indicate the precedence constraints between the stages, e.g. in job 1 the operation of stage 2 cannot be started before the completion of all three operations of stage 1. On the other hand, an arc should be selected from each pair of the broken (disjunctive) arcs that go in reverse directions to determine the sequence of the operations.Consider a set of jobsJ={1,2,…,n},a set of machinesM={1,2,…,m}and a set of operationsO={*,1,2,…,o,o+1},where two operations * (source) ando+1(sink) are dummy start and finish operations, respectively. Job j includes sjstages which should be done sequentially according to the stage numbers:1,2,…,sj.In other words, the processing of the operations of the stagek+1can be started only when the processing of all operations of the stage k is finished. Each operation l should be processed without preemption for pltime units on a predetermined machine. Each stage k of job j has|Hjk|operations, between which no precedence relations exist. In other words, the operations within the same stage can be performed in any arbitrary order. The other suppositions are as follows:•All jobs and all machines are available from time zero on.Each job visits each machine once at most, in other words, recirculation is not permitted.Operations of different jobs are not allowed to have precedence relations.No transportation time is considered between machines.The buffer capacity between machines is infinite.No machine can process more than one job (operation) at a time.In this paper, makespan (Cmax) is considered as criterion for the stage shop problem.Swarm Intelligence is a meta-heuristic method in the field of artificial intelligence that is used to solve optimization problems. It is based on the collective behavior of flocks of birds, schools of fish, colonies of ants, swarms of bees, and termites. These animals can solve complex tasks without centralized control. The Artificial Bee Colony (ABC) algorithm is inspired by the behavior of honey bees [21].The colony of artificial bees includes three groups of bees: employed bees, onlookers and scouts. In the basic form of the algorithm, the colony is equally partitioned into scout bees and onlooker bees at the initiation. Each solution is represented by a food source and there is a food source corresponding to each employed bee. The nectar quantity of a food source corresponds to the quality of the associated solution which is called its “fitness value”. Initially, scout bees try to find food source positions. Once a scout bee discovers a food source, it becomes employed. In the basic form, each employed bee is corresponding to one and only one food source. Afterwards, employed bees extract the nectar of food sources and share information with the onlooker bees, which are watching the dances of the employed bees within the hive. The onlooker bees will then select a food source with probability proportional to the quality of that food source. Thereafter, if a food source has been exhausted the employed bee associated with it will abandon the position, and becomes a scout bee again to search randomly for a new food source. By this mechanism, employed bees and onlookers perform exploitation whereas exploration is handled by scout bees. The basic form of the artificial bee colony algorithm is demonstrated in Fig. 2.The detailed description of the algorithm is as follows.In order to calculate the makespan for a solution with random key representation it should be decoded to permutation representation. To that end, smallest position value (SPV) rule is applied. Consider the following example for illustration of the rule for the stage shop. Fig. 3shows an instance of the stage shop problem (dummy operations are not shown and the stages are demonstrated by thick lines). The cells containing bold text are associated with the problem data and the other cells are related to the solution data.For example, in the first stage of job 1 operation 2 is preferred to operation 1 because its random key (0.38) is greater than that of operation 1 (0.25). Moreover, the operation 10 is processed first on machine 2 because its random key (0.47) is greater than that of operation 1 (0.25). As illustrated in Fig. 3, the random key representation is more compact than the permutation representation. In addition, both of the illustrated representations contain all the information needed for calculating the fitness value (makespan).SN D-dimensional real vectors are randomly produced as the initial solutions. Letxi=(xi,1,xi,2,…,xi,D)represent the i-th food source, which is obtained by(3.1)xi,j=xjmin+rand(0,1)(xjmax−xjmin),j=1,…,Dwherexjminandxjmaxare the lower and upper bounds for dimension j, respectively.In this stage, each employed bee is associated with exactly one food source position. Therefore, the number of employed bees is equal to the number of food source positions. An employed bee applies a random modification on the solution (original food source) to produce a new solution (new food source). In fact, the mechanism of finding the new solutionviis a neighborhood search which is defined by:(3.2)vi,j=xi,j+rand(−1,1)(xi,j−xk,j)where j is randomly chosen from{1,…,D}and k is randomly chosen from{1,…,SN}such thatk≠i.After generating the new food source, its fitness is calculated and a greedy selection is applied between the new and existing food sources. That is, if the fitness ofviis superior to that ofxi(i.e., the nectar amount of the new food source is higher than that of the old one), the employed bee will forget the old solution and memorize the new one. Else, she will keep working onxi.Once all employed bees have completed their local search, they share the nectar information of their food source with the onlooker bees on the dance area. This information helps onlooker bees in choosing their food source probabilistically. This random selection depends on the fitness values of the solutions in the population. To that end, a fitness based selection method can be implemented, like roulette wheel, ranking based, stochastic universal sampling, tournament selection or another selection scheme. In the basic form of the algorithm, the roulette wheel is considered. Hence, the probabilityPriof choosing food sourcexiby an onlooker is as follows:(3.3)Pri=fi∑i=1SNfiwhere fiis the fitness value ofxi. After the selection of the food source by the onlooker, she will search the neighborhood ofxiusing Eq. (3.2). Then, as in the case of employed bees, a greedy selection is used between two sources. That is, if the new solution has a superior fitness,xiwill be replaced by it. This process is terminated when all onlookers are scattered onto food source positions.In any cycle, when all employed bees and onlookers finish their quests, ABC tries to find exhausted sources that should be abandoned. For this purpose, for each source a numerator is introduced that counts the number of times that the quality of a solution (food source nectar) cannot be improved. If the value of the numerator is greater than a predetermined number of trials, called “limit” then the employed bee abandons the source and becomes a scout. Subsequently, the scouts generate new random solutions according to Eq. (3.1).The proposed algorithm is not a blind application of ABC, but it is adapted to the properties of the stage shop problem. The modifications of the original ABC are as follows.The neighborhood search is not identical for employed bees and onlookers:•An employed bee does not discover the neighbor food source by a random mechanism, but by a systematic way. For this purpose, an established neighborhood is implemented and the food source with maximum nectar is chosen. Instead of a commonly used greedy selection, it is allowed to the fitness to be worsened consecutively in a tabu search manner for at most Improveiter times.Using the basic idea of particle swarm optimization, personal best (the best food source the onlooker bee has ever visited) and global best (the best food source have been ever visited) guide onlookers to find a neighbor food source and greedily select between new and current sources.Discretization of the artificial bee colony is necessary in order to use it for solving a combinatorial optimization problem. To that end, using the random keys for encoding the solutions and redesigning the operators to be appropriate for the permutation representation are two main tactics. So, another important attribute of the proposed algorithm is that the two popular approaches are both used for the encoding. This issue is addressed in the next subsection.As mentioned earlier, a classic neighborhood is used for the employed bee phase. The permutation representation is required for this neighborhood and as a result for exploiting the food sources by the employed bees. On the other hand, it is more straightforward to use the random key representation for the modified onlooker bee phase. In addition, one solution can be represented by random keys in different ways and when these different representations are combined with personal best and global best, different solutions may be generated. Therefore, using random key representation can improve the exploration ability of the algorithm. Consequently, we need a technique in order to switch between the two representations smoothly. For this purpose, the initial food sources are generated using random keys, i.e. random real numbers. Subsequently, the random keys should be decoded to the permutation representation in the employed bee phase. After finding the neighbor solution, the permutation should be encoded again to the random key representation to be used in the onlooker bee phase. Switching between the two representations is repeated until the termination criterion is met. The encoding structure of the MABC is as used in Section 3.1.1.A particular food source can be modified to a neighbor by applying a move. The neighborhood used in this phase is produced by means of a kind of insert type move which originally devised for the job shop scheduling problem (N6 neighborhood according to [22] notations). In order to describe the N6 neighborhood, it is necessary to introduce some definitions. A critical path is the longest path from operation * to operation o+1. Here in the stage shop, we define a critical block as a maximal subsequence of operations of a critical path if all the operations of this subsequence either belong to the same stage of a job or should be processed on the same machine. Moreover, in stage shop a critical pair is defined as a pair of operations such that all the operations between them belong to the same critical path and also belong to the same machine or are associated with the same stage of a job. Fig. 4shows the N6 neighborhood.The neighborhood is extended by [23] in order to facilitate changing the sequence of the operations which are included in the same stage. This kind of move is specific to the stage shop scheduling problem. After determining the set of potential moves, the tabu moves (the last tabulength moves) are removed. As an exception (aspiration condition), if a tabu move results in a solution with a better fitness value than the best solution found so far, the move will be chosen. On the other hand, if there is not such a situation, the non-tabu move with the best fitness value is selected. The new solution could be worse than the previous one and this deterioration could be repeated at most Improveiter times successively. Then, the onlooker bee return to the food source with the highest nectar amount visited so far.In order to make the neighborhood more efficient, we applied the guideposts introduced by [24]. After the implementation of a worsening move (a move with decrease in fitness value), the guideposts try to prevent the repetition of deterioration of the makespan. In such a case, the fragment of the critical path considered in making the move should be restricted according to the guideposts.As mentioned earlier, the ideas of the personal best and global best are also used in the onlooker bee phase besides the traditional random modification. Therefore, the personal best of each onlooker bee should be maintained in memory. The current solutionxican be converted to the new solutionvias follows:(3.4)vi,d=xi,d+c1(xi,d−xk,d)+c2(xi,d−pbj,d)+c3(xi,d−gbd)where operation number d is randomly selected from{1,…,o},k is randomly selected from{1,…,SN}such thatk≠i,pbjis the personal best of onlooker j, gb is the global best and acceleration coefficientscz,z∈{1,2,3}is a random variable with uniform distributionU(−1,1).After acquiringvi, its fitness value will be calculated. If the fitness ofviis higher than that ofxi, the old solution will be replaced with the new one.Evolution strategies, as a type of evolutionary algorithms, apply a multi-variate normal distribution to find an optimal or a near optimal solution [25]. Firstly developed by Hansen and Ostermeier [26], the covariance matrix adaptation evolution strategy is an evolutionary algorithm for black-box optimization in continuous domain. In order to improve the effectiveness of the CMA-ES, the method is extended by [27] with the so-called rank-μ update and then by [28] with the weighted rank-μ update of the covariance matrix. For solving the stage shop scheduling problem, we applied the (μ/μW, λ)-CMA-ES which is briefly clarified here as described in [29].In CMA-ES, an objective function f is to be minimized:(3.5)f:X⊂ℝn→ℝx↦f(x),where X is considered to be convex. Assuming that the algorithm is in iteration t,λ=4+3lnnrandom individualsxi∈ℝnare produced using multi-variate normal distribution as follows:(3.6)xi=Mt+σtNi(0,Ct)i=1,…,λwheremtdenotes the mean of distribution of all individuals, the positive σtis the step size, andNi(0,Ct)is a sample of a normal distribution with mean 0 and covariance matrixCt(an×nmatrix). The algorithm continues with the calculation of fitness functions. When fitness function f for each individual is calculated, the individuals are ranked in a non-increasing order of their fitness values. Next, the parametersmt,σt, andCtshould be renewed for iteration t+1. The recombination weights wifor sorted individuals are defined aswi=(ln(μ+1)−lni)/(∑j=1μ(ln(μ+1)−lnj))whereμ=[λ/2].Now,mt+1can be calculated using(3.7)mt+1=∑i=1μwixif,where ifis the index of ith individual in the ranked set. For calculation of σt + 1 andCt+1,it is required first to obtainpσt+1andpct+1,respectively. These so-called evolution paths can be calculated as follows:(3.8)pσt+1=(1−cσ)pσt+cσ(2−cσ)μw1σt(Ct)−12(mt+1−mt)(3.9)pCt+1=(1−cC)pCt+hσcC(2−cC)μw1σt(mt+1−mt),where(Ct)−12is symmetric, positive and defined such that(Ct)−12(Ct)−12=(Ct)−1,μw−1=∑i=1μwi2,the accumulation factors are calculated ascσ=(μw+2)/(n+μw+3),cC=4/(n+4)and if||pσt+1||is large, hσtakes the value zero; otherwise, it usually becomes one as given in [29].In order to update the step size and the covariance matrix, the evolution paths are utilized:(3.10)σt+1=σt×expcσdσpσt+1EN(0,I)−1(3.11)Ct+1=(1−c1−cμ)Ct+c1pCt+1pCt+1T+cμ∑i=1μwixif−mtσt⋅(xif−mt)Tσt,wheredσ=1+cσ+2max(0,(μw−1/n+1)−1),and the learning rates for the covariance matrix are as follows:(3.12)c1=1μw1−1μwmin1,2μw−1n+22+μw+1μw2(n+2)2(3.13)cμ=(μw−1)c1.All relations are from [29].The population size λ is the only parameter that needs to be adjusted. As in [30], in this paper the restart version of CMA-ES is applied. At first, the population is in its default value and then within each restart the population is multiplied by a factor (here, two).The implementation of CMA-ES to solve the stage shop scheduling problem is quite straightforward. Here, the random key representation, introduced in Section 3.1.1, is used. In this representation, the components ofxare not limited, subject to any constraint, and therefore the search space X is just equal toℝn.The proposed algorithm for the stage shop scheduling problem was implemented in visual C++ 2010 on an E530 Thinkpad laptop with Core i5-3210M CPU (2.5GHz).In order to compare the performance of the modified ABC with the other mentioned algorithms, we applied the algorithms to the problem instances of [4], which are originated from the most difficult well-known job shop benchmarks:•Eighty instances due to [31] called as TA01-80, which their corresponding stage shop instances are denoted as ATA01-80, hereafter.Forty instances due to [32] called as DMU01-40, which their corresponding stage shop instances are denoted as ADMU01-40, hereafter.The adapted stage shop problems are exactly based on job shop benchmarks and all processing times and corresponding machines are the same (Taillard's instances are available at his website11http://mistic.heig-vd.ch/taillard.). The only data generated by [4] are the structure of stages. For more information about the construction method of the structure, the reader is referred to [4].Obtaining the success rates necessitate the application of the algorithms to a problem set which can be solved to optimality by the under comparison algorithms. Therefore, in addition to the mentioned instances, a stage structure for five small instances (LA01-5 with n=10, m=5 from [33]) is created using the method of [4] (the associated stage shop problems are called ALA01-5). All stage structures are available in supplementary files.Due to the fact that the different values for parameters affect the quality of the solutions, Taguchi method for design of experiments is utilized for adjusting the parameters. Based on some tests, three levels are selected for each parameter in our experiments. After determination of the number of parameters and the number of levels for each parameter, the related array could be selected according to the Taguchi method. Subsequently, the number of trials and the combination of parameter levels in each trial can be specified. In each trial, five small problems (ALA01-5) are solved. Each experiment is executed for three replications, each of which is terminated when 105 function evaluations is reached. In order to enable the comparison between the objective functions of five different problems, each result is converted to RE using “Relative Error” formulaRE=100*(fsolution−fopt)/fopt. Because MRE, i.e. the mean of REs, is to be minimized and therefore it is of “the smaller the better” category, S/N ratios are obtained using equation (4.1):(4.1)S/Nratio:ηi=−10log1N∑i=1Nyi2For TABC, the parameters to be adjusted are: SN and limit. The three levels chosen for each parameter are shown in Table 1.The orthogonal array L9 is selected for parameter setting of TABC because we want to adjust two parameters, each of which has three levels. Table 2shows the mean value of the S/N ratios and means in every level of the parameters. In this table, the parameters are ranked according toΔ=Max(.)−Min(.).It can be seen that the effect of SN on MRE is larger than the effect of limit.Main effects plots for S/N ratios and means are depicted in Fig. 5. The level with maximum mean of S/N ratios is selected for each parameter, i.e., SN=70 and limit=40. Alternatively, the level with minimum mean of means can also be chosen, which leads to the same results in this case.To enhance the performance of MABC, seven parameters are to be adjusted to one of their three levels as demonstrated in Table 3.Regarding the case of MABC, L27 is the appropriate array. According to the signal to noise ratios, the level with maximum S/N value should be chosen and then we will have SN=60, limit=30, c1=0.5, c2=0.3, c3=0.7, tabulength=5, Improveiter=2000 (Fig. 6a) and the most significant factors are SN and tabulength (Table 4); whereas considering the means, the level with minimum value of mean should be selected and therefore, we have SN=40, limit=40, c1=0.7, c2=0.3, c3=0.5, tabulength=7, Improveiter=1000 (Fig. 6b) and tabulength and Improveiter have the most significant impact (Table 5). Finally, we conclude that in order to maintain the robustness of the algorithm, the adjustment corresponding to signal to noise ratios should be selected.According to Section 3.3, the values of parameters are specified and further adjustment is not required.To compare the success rates of the algorithms, each of which applied 100 times to a set of easier stage shop problems, i.e. ALA01-5, with known optimal objective function. A run is considered to be successful when the optimal makespan is obtained before exceeding 105 function evaluations. The best NFE (number of function evaluations) is defined corresponding to the run with minimum NFE among 100 replications. The mean and standard deviation of the objective function evaluation numbers is calculated with respect to only the successful runs (Table 6).Table 6 deserves the following comments. The problems ALA01, 3 and 5 are quite easy and solved by all the three algorithms with 100% success rate. As far as ALA02 is concerned, MABC and CMA-ES have perfect success while only 17 out of 100 runs of TABC are successful. Regarding the most difficult problem ALA04, TABC does not succeed at all, whereas MABC outperforms CMA-ES with the difference of 0.14. However, in terms of the average of function evaluation numbers CMA-ES is the fastest, followed by MABC and TABC, respectively.Due to the fact that the problems ATA51-80, like their job shop counterparts, are really easy and could be solved in about 1s, they are omitted from the results. Table 7displays the average results achieved by GATS, TABC, MABC and CMA-ES from 10 independent runs. In the case of GATS, we present the original running times on the original computer reported by [4]. The termination criterion for all the algorithms is achieving 106 function evaluations. Columns entitled “MRE” show the mean relative error of the algorithm which is computed using the “relative deviation” formulaRE=100*(UBsolution−LB1)/LB1,where LB1 is a lower bound for the objective function of the problem instance and UBsolutionis the objective function of the best solution obtained by the algorithm. Columns with the title “CPUav(s)” demonstrate the average CPU time for solving a problem over 10 repetitions in seconds. Columns with the title “# of opt” display the number of the optimal solutions found by the algorithm.MABC achieves MRE=8.24, whereas GATS, TABC and CMA-ES obtain 9.77, 25.69 and 14.68, respectively. It can be seen from Table 7 that MABC outperforms the other algorithms in solution quality. Besides, comparing the CPU times in Table 7 reveals that the average running time for MABC is shorter than the others. This can be attributed to the use of the topological order of N6 neighborhood (proposed by [23]) which can significantly reduce the time required for computing the makespan of a neighbor solution.Moreover, MABC found the optimal solution of two new problems and 28 new upper bounds for the unsolved problems. As the performance is concerned, the next algorithms are GATS, CMA-ES and TABC, respectively. The detailed results for ATA01-50 are available in supplementary files.The chart in Fig. 7shows the convergence behavior of the three algorithms for problem ATA01. It can be observed that TABC has a premature convergence while MABC have normal convergence behavior and CMA-ES has log-linear convergence.Table 8compares the performance of GATS, TABC, MABC and CMA-ES. The algorithm MABC provides MRE=1.41%, while GATS, TABC and CMA-ES offer 1.80%, 29.97% and 7.47%, respectively. MABC evidently outperforms GATS, TABC and CMA-ES in solution quality. Furthermore, MABC requires relatively shorter CPU time to obtain these results on the experiments’ computer.Similar to ATA instances, MABC found new bounds for ADMU benchmarks. In fact, the optimal solutions of two new problems and five new upper bounds for the unsolved problems are found. The algorithms are ranked based on their performance as GATS, CMA-ES and TABC, respectively. The detailed results for ADMU01-40 are available in supplementary files.

@&#CONCLUSIONS@&#
