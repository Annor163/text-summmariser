@&#MAIN-TITLE@&#
Multi-scale texture-based level-set segmentation of breast B-mode images

@&#HIGHLIGHTS@&#
Multi-scale texture-based level-set segmentation of breast B-mode images.Computation of a fine and delicate as well as a coarse lesion contour.Evaluation by manually delineated and a corrected lesion contour.Improvements in contour-based and region-based error metrics w.r.t state-of-the-art.Potential contribution to lesion classification via fine and coarse area difference.

@&#KEYPHRASES@&#
B-mode scan,Breast ultrasound imaging,Level-set framework,Multi-scale,Segmentation,

@&#ABSTRACT@&#
Automatic segmentation of ultrasonographic breast lesions is very challenging, due to the lesions′ spiculated nature and the variance in shape and texture of the B-mode ultrasound images. Many studies have tried to answer this challenge by applying a variety of computational methods including: Markov random field, artificial neural networks, and active contours and level-set techniques. These studies focused on creating an automatic contour, with maximal resemblance to a manual contour, delineated by a trained radiologist. In this study, we have developed an algorithm, designed to capture the spiculated boundary of the lesion by using the properties from the corresponding ultrasonic image. This is primarily achieved through a unique multi-scale texture identifier (inspired by visual system models) integrated in a level-set framework. The algorithm׳s performance has been evaluated quantitatively via contour-based and region-based error metrics. We compared the algorithm–generated contour to a manual contour delineated by an expert radiologist. In addition, we suggest here a new method for performance evaluation where corrections made by the radiologist replace the algorithm-generated (original) result in the correction zones. The resulting corrected contour is then compared to the original version. The evaluation showed: (1) Mean absolute error of 0.5 pixels between the original and the corrected contour; (2) Overlapping area of 99.2% between the lesion regions, obtained by the algorithm and the corrected contour. These results are significantly better than those previously reported. In addition, we have examined the potential of our segmentation results to contribute to the discrimination between malignant and benign lesions.

@&#INTRODUCTION@&#
Breast cancer is the second leading cause of death in women all over the world and about 12% of women will suffer from this disease during their lifetime [1]. B-mode ultrasound (US) is widely used for breast imaging [2] as an adjunct imaging modality to mammography, especially in young (less than 30 years), pregnant and lactating women, and women with dense breasts. In addition, US is a relatively low-cost, noninvasive and non-radiating imaging modality.The quality of most B-mode images, however, is problematic. The images typically have low contrast, blurry boundaries and a speckle-like appearance. Moreover, there may be a number of artifacts resulting from the imaging technique, such as: enhancement, shadowing, side lobes, and multiple reflection echoes [3].The interpretation of breast US images by radiologists is based on the Breast Imaging Reporting and Data System (BI-RADS lexicon) [4]. The radiologist usually supplies a coarse contour and a measurement of the diameter of the lesion, in order to mark its size and location in the image. Computer aided diagnosis (CAD) systems can assist the radiologist in identifying abnormalities with objective measures [5], but because of the low quality of US images, this requires an objective and accurate segmentation of the lesion. In addition to assisting in diagnosis, an exact automatic segmentation supplies a tool for the delineation of the cancer borders. This is useful in order to ensure that none of the cancerous mass is missed and to protect the welfare of women by avoiding unnecessary biopsies of benign lesions.A considerable amount of research has been done in the area of US image segmentation, in order to cope with this challenge. A number of algorithms, which include different computational methods, have been proposed [5]: Histogram thresholding [6–8], Markov random field [9–11], artificial neural networks (ANN) [12–14], active contours and level-set [15–20].The histogram thresholding algorithms [6,8], for example, determines the potential lesion margins through gray-value thresholding of a processed version of the US image and maximization of a utility function. Markov random field algorithms alternatively approximate the maximization of the posterior (MPM) estimation of the class labels of image pixels, and estimate the class parameters. One of the studies which utilized Besag׳s iterative conditional mode [10], considered texture by using discrete wavelet transform.ANN algorithms employ different lesion properties, such as wavelet analysis [13] and auto-covariance [14] as measures for texture, in order to distinguish the lesion from the background. A recent study obtained improved clinical results, relative to those previously reported by using a single-scale texture property, an intensity property [17], and the phase from two dimensional Fourier transform [12]. However, it seems that the algorithm′s results are still not clinically satisfactory.Different intensity, spatial and texture properties have been incorporated in both active contour and level-set frameworks [21]. The intensity property was applied through the use of distribution functions, such as Rayleigh distribution [16,19,22] or the intensities distribution of the image itself [17,23,24]. The texture was also represented by statistical models, such as Gaussian distribution functions with different means and variances [25–27]. Additional measures for texture such as the difference of the intensity of each pixel in the image with the mean of its nearest neighbors and feature vector of directional derivatives have also been suggested [17,23]. The spatial properties have been applied through convolution of the image with different spatial functions, such as Gabor functions, and the computation of a distance map [15].Even though many studies and computational methods have been applied to US image segmentation, it seems that a solution for accurate lesion segmentation that defines the lesion precisely and satisfies clinical requirements has not been reached yet. Our study proposes a solution to this challenge.The organization of the paper is as follows. The suggested algorithm and its parameters are presented in Sections 2 and 3, respectively; Results are shown in Section 4; Section 5 concludes the study.A database of biopsy-proven 78 sonograms (43 benign and 35 malignant) has been used to test our algorithm. The database was collected between the years 2010 and 2013 and includes a large repertoire of lesion manifestations. The images were acquired by Siemens Acuson S2000 ultrasound system with 6–18MHz linear probe, and stored in bit-map (BMP) format.We propose a segmentation algorithm inspired by computational models for visual system [28,29], which include adaptation and induction effects, that increase and enhance the differences between adjacent regions. This enables the algorithm to detect non homogeneous textures and un-sharp edges, such as those typically seen in the noisy B-mode ultrasound images.The algorithm can be divided into four main sections: (1) Region of interest (ROI) generation; (2) Computation of multi-scale response map; (3) Level-set segmentation of an ultrasonic lesion and (4) Post-processing (Fig. 1).The first part is related to an ROI, containing a suspected breast abnormality. The ROI, denoted as IROI, is marked by an expert radiologist and cropped from the input US image I. The radiologist defines the ROI such that it includes the entire lesion and the surrounding breast tissue with different echogenicity [4].In the second part (Section 2.3), a multi-scale response map, denoted as M, is computed for the ROI. This response map emphasizes the texture properties of the object to be segmented. The multi-scale response map is based on a texture measure building block in the computational model for adaptation mechanism of the visual system [28].In the third part (Section 2.4), we use a region-based level-set segmentation [30], which is based on the response map [28,29] from the previous stage. This is done in order to obtain an optimal and fine contour for the breast lesion. The optimality is with respect to minimization of an energy cost functional, defined for the ROI.In the last part (Section 2.5), due to clinical considerations, the segmentation result from the previous part is post-processed. We create a simple curve for the segmented object and perform a morphological opening process. The resulting contour is the suggested lesion boundary CLS. In addition to this contour, we compute a convex-hull contour (Section 2.6), denoted as CCH. The latter contour is computed in order to evaluate the potential of the algorithm׳s segmentation results to distinguish between malignant and benign lesions (Section 5). This information may be used for further processing, regarding classification of B-mode ultrasound lesions. Classification of malignant and benign lesions is outside the scope of this work and we plan to report this in a future manuscript.In order to capture the un-sharp edge of a lesion in the B-mode US modality, we have chosen to identify the lesion through a unique multi-scale texture measure [28]. An un-sharp edge is usually not identified by a single resolution, thus, a multi-scale measure is required. For this purpose, we applied a variation of such a measure from a proposed model of visual system adaptation mechanism [28].Following this rationale, a Multi-Scale Response Map (Fig. 1), termed MSRM, is computed by using achromatic opponent receptive fields (RFs). An opponent RF is composed of two sub-regions, center and surround. It is often modeled by a difference of Gaussians (DOG) spatial mask [31].The center and surround signals are defined as a convolution between the ROI image, IROI, and Gaussian decaying spatial weight functions, fckand fsk, where k denotes the spatial resolution. The decay coefficients of fckand fskare denoted as ρkcand ρks, respectively.The functions fckand fskare defined over the center and surround regions, respectively. The diameter of the center region is ρkcpixels and its support is (ρkc)2 pixels. The surround region has an annular shape, with an inner diameter of ρkcpixels and an outer diameter of ρkspixels. At each resolution, the outer diameter is two times larger than the inner diameter, i.e. ρks=2ρkc. Thus, the support of fskis three times larger than the support of fckand equals 3(ρkc)2 pixels.The response at each resolution is calculated as the subtraction of the center and the surround responses of the appropriate resolution [28]:(1)Lk(x,y)=Lck(x,y)−Lsk(x,y)The MSRM (Fig. 1) is computed as the average power of the response of all resolutions (Section 3.1), where the sign of each response is taken into account. The MSRM takes the form:(2)M(x,y)=sign(1N∑k=1Nsign(Lk(x,y))⋅(|Lk(x,y)|)λ)⋅(|1N∑k=1Nsign(Lk(x,y))⋅(|Lk(x,y)|)λ|)1λwhere N is the number of resolutions and λ>1 is a predefined constant.The MSRM aims to identify different texture zones in the B-mode image, which are usually not specified by a single specific resolution. This is done through the use of DOG spatial masks with different resolutions, which model opponent RFs. In addition, the blurred edges of the ultrasonic lesion can appear in different sets of resolutions. Thus, in order to enhance the dominant responses from the relevant RF resolutions adaptively, we apply the power coefficient (Eq. (2)). This enables the automatic enhancement of the dominant responses, regardless of their specific resolutions. Since the dominant resolutions are not known in advance, the responses from all resolutions are averaged, after applying the power coefficient. The inverse power coefficient is applied to the averaged response in order to obtain the MSRM in the same order of magnitude as the responses of the RFs.The polarity of the lesion is taken into account by considering the sign of the RF responses and the sign of the averaged response in the computation of the MSRM (Eq. (2)). The lesion usually appears with darker texture, relative to its surroundings, so that the MSRM in the lesion region has mainly negative responses, while adjacent healthy tissue has mainly positive responses (Fig. 2). Note that the automatic relevant resolutions with the most influence on the sign calculations will be the coarse resolutions. The MSRM, which incorporates both the texture and polarity properties of the lesion, can therefore emphasize the lesion over the background.Level-set framework [32] (Fig. 1) is employed, in order to obtain an optimal and fine lesion border. The resulting contour obtained from the level-set framework is optimal in the sense that it minimizes an energy cost functional, which is defined in the B-mode ROI (Section 2.1).In order to differentiate the lesion from its background, we incorporate the lesion texture property, expressed by the MSRM, in the level-set framework. For the sake of clarity, a brief overview of the level-set framework, based on [32], will be given.Let I be a real function, defined on a two dimensional domain Ω, such that I:Ω→ℜ. Segmentation of the image I is obtained by partitioning the image domain Ω into two disjointed regions, object and background, denoted as Ωoand Ωb, respectively. The contour defined by the segmentation is C=∂Ωo=∂Ωb.Let ϕ:Ω→ℜbe an auxiliary real function, termed level-set function [32]. ϕ is defined such that it is negative at Ωoand positive at Ωb. Thus, C is defined implicitly by the zero level set of ϕ.In order to determine an optimal segmentation of the object, an energy functional of ϕ, denoted as E(ϕ), is defined and minimization with respect to ϕ is performed. In our algorithm, we use a region-based level-set approach [30]. With this approach, the partition of the object and background is according to the different properties of these regions.Ultrasonic lesions usually appear with a different texture, relative to their surrounding tissue. Due to the large amount of speckle noise and poorly defined edges, the region-based level-set method, incorporating the MSRM, is applied.An energy term is formulated using the MSRM and the Chan-Vese “fitting” term [30]:(3)E(ϕ)=ERB(ϕ,co,cb)=∫Ω|M(x,y)−co|2(1−H(ϕ))dxdy+∫Ω|M(x,y)−cb|2H(ϕ)dxdywhere M(x,y) is defined in Eq. (2); coand cbare constants; H(ϕ) is the Heaviside step function. Minimization of this energy term is done with respect to ϕ, coand cb.Regularization terms, based on the contour length or the area inside it [30], have not been applied here as part of the energy functional. The reason is that these terms can impair the accuracy of the resulting contour, which has a lacy nature in cancerous tissue. Since we do not use regularization terms, which play a role in preventing over segmentation, we have to deal with this issue with a different way, by the implementation of a post-processing procedure for the result of the level-set algorithm (Section 2.5).We use the gradient descent method for minimizing the energy functional E(ϕ), using the following Euler-Lagrange equation [32]:(4)∂ϕ∂t=−∂E∂ϕwhere ∂E/∂ϕ is the Gateaux derivative (or first variation) [33] of the functional E. ϕ=ϕ(x,y,t) and is evolved as a time dependent function22The notation ϕtwill be also used to describe the time derivative of ϕ., for an artificial time variable t≥0.The evolution equation of ϕ in time is:(5){∂ϕ∂t=ϕtRB,in[0,∞)xΩϕ(x,y,0)=ϕ0(x,y),inΩδ(ϕ)|∇ϕ|⋅∂ϕ∂n→=0,on∂Ωwhere ϕ°(x,y) is the initial level set function at time t=0; δ(ϕ) is the Dirac delta function, defined by δ(x)=H′(x). The last equation in Eq. (5) is the Neumann boundary condition [30].

@&#CONCLUSIONS@&#
