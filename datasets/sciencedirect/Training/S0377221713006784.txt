@&#MAIN-TITLE@&#
The single machine serial batch scheduling problem with rejection to minimize total completion time and total rejection cost

@&#HIGHLIGHTS@&#
We study a single machine serial batch scheduling problem with rejection.The objectives are to minimize total completion time and total rejection cost.We study four different variants of the problem.We prove that one variant is efficiently solvable while all other areNP-hard.We provide an ε-approximation algorithm for one of theNP-hard variants.

@&#KEYPHRASES@&#
Batch scheduling,Bicriteria scheduling,Rejection,Total completion time,

@&#ABSTRACT@&#
We study a scheduling problem with rejection on a single serial batching machine, where the objectives are to minimize the total completion time and the total rejection cost. We consider four different problem variations. The first is to minimize the sum of the two objectives. The second and the third are to minimize one objective, given an upper bound on the value of the other objective and the last is to find a Pareto-optimal solution for each Pareto-optimal point. We provide a polynomial time procedure to solve the first variation and show that the three other variations areNP-hard. For solving the threeNP-hard problems, we construct a pseudo-polynomial time algorithm. Finally, for one of theNP-hard variants of the problem we propose an FPTAS, provided some conditions hold.Batch scheduling problems have been traditionally studied under the assumption that all jobs have to be processed within the shop (see Potts and Van Wassenhove, 1991; Webster and Baker, 1995; Potts and Kovalyov, 2000 for survey papers on this field). However, in many cases, especially in highly loaded manufacturing systems, the scheduler may not be able to process all jobs in the shop while maintaining acceptable quality of service or reasonable (economic) inventory level. In such cases, the scheduler may have to make a higher level decision as to which job to process in the shop and which to reject. Each rejected job may either be outsourced or not produced at all which will result in a rejection cost. In order to arrive at the best decision, the scheduler has to carefully coordinate the higher level decisions about the sourcing strategy for each job with the lower level decisions of how to schedule the set of accepted jobs. In this paper we study the problem of coordinating these two critical decisions for the case when the scheduling is done on a single serial batching machine and the scheduling criterion is the total completion time. The importance of the total completion time criterion is well recognized in the literature. According to Pinedo (1995), this criterion is usually used as a surrogate criterion for minimizing the Work-In-Process (WIP) inventory. WIP ties up capital and a large amount of it can clog up operation and increases handling cost.Our batch scheduling problem with rejection can be formally stated as follows. We are given a set of n jobs, J={J1, J2, …, Jn}, that is available for processing at time zero. For j=1,…,n, the scheduler can either reject to process job Jjin the shop, at a cost of ej, or can accept and process it non-preemptively during pjunits of time on a single batching machine. The accepted jobs are to be processed in batches and a setup time s is required before the production of each batch. We use the batch availability assumption according to which all jobs in a batch are considered to have been completed together at the completion time of the last job in their batch, i.e., a batch of jobs is removed from the system at this common completion time. We assume that the number of jobs to be included in each batch is not restricted. However, our solution method can be easily modified to deal also with the restricted version of the problem. We consider the case of a serial batching machine for which the batch processing time equals the total processing time of the jobs assigned to the batch. A solution S to our problem is defined by1.Partitioning set J into two subsets, A andA¯, each of which correspond to the set of accepted and rejected jobs;Determining the sequence π(A)={J[1], J[2], …, J[∣A∣]} in which the jobs in set A are to be processed on a single batching machine, where [j] represents the index of the jth job to be processed on the batching machine (J[j]∈A for j=1, …, ∣A∣); andPartitioning π(A) into m batches (where m is a decision variable), B=(B1, B2, …, Bm) whereB1={J[l0+1],…,J[l1]},B2={J[l1+1],…,J[l2]},…,Bm={J[lm-1+1],…,J[lm]}, and licounts the number of jobs in the first i batches for i=1, 2, …, m, with l0=0 and lm=∣A∣.For a given solution S, let Cjbe the completion time of job Jj∈A. We evaluate the quality of a solution by two different criteria. The first,F1(S)=∑Jj∈ACj, is the total completion time (scheduling) criterion, and the second,F2(S)=∑Jj∈A¯ej, is the total rejection cost. Due to the batch availability assumption the total completion time can be given by(1)F1(S)=∑i=1m(lm-li-1)×s+∑j=li-1+1lip[j].Since we are dealing with a bicriteria problem, several different problem variations can be defined (see, e.g., T’kindt and Billaut, 2006, pp. 121–122). We focus on the following four different variations of the problem (see Shabtay et al., 2013 for a more detailed description of these variations).•The first, P1, is to minimize the total integrated cost, i.e., to find a solution S which minimizes F1(S)+F2(S).The second, P2, is to find a solution S that minimizes F1(S) subject toF2(S)⩽E¯, whereE¯is a given upper bound on the total rejection cost.The third, P3, is to find a solution S that minimizes F2(S) subject toF1(S)⩽K¯, whereK¯is a given upper bound on the value of the scheduling criterion.The fourth, P4, is to identify a Pareto-optimal solution for each Pareto-optimal point, where a solution S is called Pareto-optimal (or efficient) if there does not exist another solution S′ with F1(S′)⩽F1(S) and F2(S′)⩽F2(S), with at least one of these inequalities being strict. The point (K, E), where K=F1(S) and E=F2(S), is Pareto-optimal point corresponding to this Pareto-optimal solution.Following the classification of bicriteria problems introduced in T’kindt and Billaut (2006), our problem can be referred to by 1∣rej, s−batch∣X, where rej implies that rejection is allowed and s−batch implies that the set of accepted jobs are to be processed on a serial batching machine. Moreover, X is replaced by (F1, F2) for the general problem and with F1+F2, ∊(F1/F2), ∊(F2/F1) and #(F1, F2) for variants P1, P2, P3 and P4, respectively. We note that problems P2 and P3 are also known as the ∊-constraint problems with respect to the total rejection cost (F2) and the total completion time (F1), respectively. We also remark here that solving problem P4, also solves problems P1–P3 as a by-product, and that the decision versions of P2 and P3 are identical as they both ask if, given an instance of the 1∣rej, s−batch∣(F1, F2) problem and parameters K and E, is there a solution S with F1(S)⩽K and F2(S)⩽E? The fact that both P2 and P3 share the same decision version implies that either both or none of them isNP-hard.It is easy to observe that when s=0 each Pareto-optimal solution is such that each accepted job is included in a different batch (there is no motivation to include several jobs in a batch as the total completion time will obviously increase). Thus, when s=0 the number of batches equals to the number of accepted jobs (m=∣E∣) and we have that li=i for i=1, …, ∣E∣. The total completion time in (1) is thus simply reduces toF1(S)=∑i=1|E|(|E|-(i-1))p[i]=∑i=1|E|(|E|-i+1)p[i]. This last term simply identical to the total completion time of any set E in a 1∣rej∣(F1, F2) problem withF1=∑Jj∈ACj. This implies that the 1∣rej∣(F1, F2) problem withF1=∑Jj∈ACjreduces to the 1∣rej, s−batch∣(F1, F2) problem. The fact that the decision versions of P2 and P3 are bothNP-complete is now directly follows from the fact that Shabtay et al. (2012) proved that the decision version of problems 1∣rej∣ ∊(F1/F2) and 1∣rej∣ ∊(F2/F1) withF1=∑Jj∈ACjisNP-complete. Accordingly, our main objectives in the paper is to find out whether the P1 problem is solvable in polynomial time, and whether problems P2–P4 are ordinary or stronglyNP-hard.There are dozens of papers on scheduling with rejection (see a recent survey by Shabtay et al., 2013) with some of them focusing on batch scheduling on parallel batch machines (see, e.g., Lu et al., 2008; Cao and Yang, 2009; Miao et al., 2010; Li and Feng, 2010). However, although scheduling problems on serial batching machines have been extensively studied in the literature (see, e.g., Coffman et al., 1990; Albers and Brucker, 1993; Cheng et al., 2001; Ng et al., 2003; Yuan et al., 2004; Mosheiov et al., 2005; Shabtay and Steiner, 2007; Mosheiov and Oron, 2008), to the best of our knowledge this subject has not been approached in the context where rejection is allowed. Thus, our main aim is to shift the focus of the research area to the case where the set of accepted jobs are scheduled on a serial (rather than parallel) batching machine.Our paper proceeds as follows. In Section 2 we develop a polynomial time procedure for solving the P1 problem variation in O(n5) time. In Section 3, we provide a pseudo-polynomial time algorithm to solve the P2 problem, which can be modified to solve problems P3–P4 in pseudo-polynomial time as well. Moreover, we show how we can construct an ε-approximation algorithm that, given the existence of a Pareto-optimal solution with a total rejection cost of at most R and a total completion time of at most K, finds in O(n6/ε2) time a solution with a total rejection cost of at most (1+ε)R and a total completion time value of at most (1+ε)K. A summary section concludes our paper.Coffman et al. (1990) study the1|s-batch|∑Jj∈JCjproblem and prove the following lemma.Lemma 1There exists an optimal schedule for which the jobs are scheduled in a non-decreasing order of processing times, i.e., according to the SPT rule.It is easy to observe that Lemma 1 holds for the set of accepted jobs (set A) in our1|rej,s-batch|∑Jj∈ACj+∑Jj∈A¯ejproblem, i.e., there exists an optimal solution where π(A) follows the SPT rule. Thus, for ease of presentation, hereafter we assume that the jobs are indexed according to the SPT rule such that p1⩽p2⩽⋯⩽pn.Next, we show how we can solve the1|rej,s-batch|∑Jj∈ACj+∑Jj∈A¯ejproblem by using a dynamic programming-based optimization procedure. To do this, we let Fj(l) be the minimal total cost for a partial schedule that includes jobs Jj, …, Jn, where the number of accepted jobs is l (thus there are n−j−l+1 rejected jobs among jobs Jj, …, Jn), and subject to the conditions that job Jjis accepted and that it starts the first batch in the partial schedule. Then, if the next batch starts with job Jk(j<k⩽n+1), the minimal cost for jobs Jj, …, Jncan be given byminrmin(j,k,l)⩽r⩽rmax(j,k,l){f(j,k,l,r)+Fk(l-r)},where r represents the number of accepted jobs among jobs Jj, …, Jk−1 and f(j, k, l, r) is the minimum additional cost that results from selecting a set A(j, k, l, r) of r jobs out of jobs Jj, …, Jk−1 to be included in set A and to be processed in the first batch. Note that if k=n+1, all accepted jobs among jobs Jj, …, Jnare scheduled in a single batch that starts with job Jj.Since Jj∈A(j, k, l, r), we have that r⩾1. In addition, due to the fact that there are at most n−k+1 accepted jobs among jobs Jk, …, Jn, in order to have l accepted jobs among jobs Jj, …, Jn, there has to be at least l−(n−k+1) accepted jobs among jobs Jj, …, Jk−1. Thus, we have that(2)rmin(j,k,l)=max{1,l-(n-k+1)}.Since there are only k−j jobs between job Jjand Jk(including job Jjand excluding job Jk), we have the restriction that r⩽k−j. Furthermore, since r is the total number of accepted jobs among jobs Jj, …, Jk−1 and Jk∈A, we have that r⩽l−1 if k⩽n and that r=l if k=n+1. Thus, we have that(3)rmax(j,k,l)=min{l-1,k-j}ifk⩽nlifk=n+1.As the second batch can start with any job Jk(j<k⩽n+1), the following recursion holds:(4)Fj(l)=minj<k⩽n+1minrmin(j,k,l)⩽r⩽rmax(j,k,l){f(j,k,l,r)+Fk(l-r)}for j=1, …, n and l=1, …, n−j+1. Note that similar to the recursion in Coffman et al. (1990) for the less general1|s-batch|∑Jj∈ACjproblem, the fact that the second batch starts with job k does not necessary imply that there are at most two batches in an optimal schedule, as the second batch does not necessarily ends up with the last accepted job. This can be viewed from the recursion in (4) and from the fact that the Fj(l) value corresponds to the total cost result in from a schedule that schedule r accepted jobs among jobs Jj, …, Jk−1 in the first batch (for some j<k⩽n+1) and from scheduling additional l−r among jobs Jk, …, Jnin a set of consecutive batches (this set may include up to l−r batches as the number of accepted jobs among jobs Jk, …, Jn).In order to track back the optimal solution at the end of the program, we let k(j, l) and r(j, l) be the k and r indices that yield the Fj(l) value as given by (4), that is(k(j,l),r(j,l))=argminj<k⩽n+1minrmin(j,k,l)⩽r⩽rmax(j,k,l){f(j,k,l,r)+Fk(l-r)}.By applying the recursion in (4) with the initial condition that Fn+1(0)=0, we can compute all possible Fj(l) values. Then, since the first batch can start with any job, Jj∈{J1, …, Jn+1}, and it may include no more than n−j+1 accepted jobs among jobs Jj, …, Jn, we have that the optimal solution value is given byF∗=minmin1⩽j⩽nmin1⩽l⩽n-j+1∑i=1j-1ej+Fj(l),∑i=1nei.To conclude the above analysis, we provide the following Pseudo-code to solve our P1 problem. We note that every part that is presented in the code within curly brackets is just a comment which explains the purpose of the corresponding step and is not an actual part of the code itself. Moreover, we follow the convention that indentation shows mutual relations between particular parts of the algorithm.Algorithm 1Algorithm for solving the1|rej,s-batch|∑Jj∈ACj+∑Jj∈A¯ejproblem{Input}: e=(e1, …, en), p=(p1, …, pn), s.Step 1: {Initialization}: Fn+1(0)=0, F∗=∞, j∗=n+1 and A=∅Step 2: Renumber the jobs according to the SPT rule.Step 3: {Obtaining all f(j, k, l, r) values and the corresponding A(j, k, l, r) sets}:Call procedure f(j, k, l, r) to obtain all f(j, k, l, r) values and the corresponding A(j, k, l, r) sets.Step 4: {Obtaining all Fj(l) values and the corresponding k(j, l) and r(j, l) indices}:For j=n downto 1 doFor l=1 to n−j+1 doFj(l)=∞For k=j+1 to n+1 doFor r=rmin(j, k, l) to r=rmax(j, k, l) doIf Fj(l)>Fk(l−r)+f(j, k, l, r) thenFj(l)=Fk(l−r)+f(j, k, l, r), k(j, l)=k, r(j, l)=rStep 5: {Obtaining the optimal solution value (F∗), the index of the job that begins the first batch (j∗) and the number of accepted jobs (l∗)}:For j=1 to n doFor l=1 to n−j+1 doIf∑i=1j-1ej+Fj(l)<F∗thenj∗=j, l∗=l andF∗=∑i=1j-1ej+Fj(l)If∑i=1nei<F∗then j∗=n+1, l∗=0 andF∗=∑i=1neiStep 6: {Tracking the optimal partition of set J intoA∪A¯and determining the optimal partition of the jobs in A into batches}j=j∗, l=l∗ and i=0While j<n+1 doi=i+1Bi=A(j, k(j, l), l, r(j, l)), A=A∪Bi, j=k(j, l) and l=l−r(j, l)m=iStep 7: {Output}:A,A¯=J⧹Aand B1, …, Bm.In order to implement Algorithm 1, we still have to provide a procedure to obtains all f(j, k, l, r) values and the corresponding A(j, k, l, r) sets. According to the definition of f(j, k, l, r), we select a set A(j, k, l, r) of r jobs among jobs Jj, …, Jk−1 to be included in set A and to be scheduled at the first batch (that begins with job Jj) in a partial schedule that includes jobs Jj, …, Jnwith l accepted jobs. Since job Jjstarts the first batch we have that Jj∈A(j, k, l, r) and that job Jjdelays the completion time of each of the l accepted jobs in s+pjunits of time (see Eq. (1)). Thus, job Jjadds l(s+pj) units to the objective value (i.e., the cost addition is l(s+pj)). In addition to selecting job Jj, we need to select additional r−1 jobs to be included in A(j, k, l, r). This should be done such that the cost addition to the partial schedule that includes jobs Jj, …, Jnis minimum. If we reject job Ji∈{Jj+1, …, Jk−1} then the cost addition is ei, but if we accept job Ji∈{Jj+1, …, Jk−1}, it is included in the first batch (which starts with job Jj). Since the number of accepted jobs is l, accepting job Jiimplies that we delay the completion of l jobs by piunits of time; thus the cost addition is lpi. Now, let Δil=lpi−eirepresent the penalty caused from a decision to include job Ji∈{Jj+1, …, Jk−1} in A (and not inA¯), given that the number of accepted jobs among jobs Jj, …, Jnis l. For a given l value, we reorder jobs J1, …, Jnin a non-decreasing order of Δilto produce an ordered list of jobsL(l)={J[1,l],J[2,l],…,J[n,l]}such that Δ[i, l]l⩽Δ[i+1, l]lfor i=1, …, n−1 and [i, l] represents the index of the ith job in listL(l). Then, in addition to selecting job Jjto be included in A(j, k, l, r), it is optimal to include in A(j, k, l, r) the first r−1 jobs inL(l)(among jobs {Jj+1, …, Jk−1}) while the jobs inA¯(j,k,l,r)={Jj+1,…,Jk-1}⧹A(j,k,l,r)are rejected. To conclude the above analysis we present the following procedure to obtain all f(j, k, l, r) values and the corresponding A(j, k, l, r) sets.Algorithm 2Procedure f(j, k, l, r)Step 1: {Obtaining all Δilvalues for l, i=1, …, n}:For l=1 to n doFor i=1 to n doΔil=lpi−eiStep 2: {Obtaining the set of n ordered lists}:For l=1 to n doReorder jobs J1, …, Jnin a non-decreasing order of Δilto produce an ordered list of jobs,L(l)={J[1,l],J[2,l],…,J[n,l]}, such that Δ[i, l]l⩽Δ[i+1, l]lfor i=1, …, n−1.Step 3: {Obtaining all f(j, k, l, r) values and the corresponding A(j, k, l, r) sets}:For j=1 to n doFor k=j+1 to n+1 doFor l=1 to n−j+1 doCalculate rmin(j, k, l) and rmax(j, k, l).For r=rmin(j, k, l) to r=rmax(j, k, l) dof(j, k, l, r)=l(s+pj), A(j, k, l, r)={Jj}, and x=1For q=1 to n doIf J[q, l]∈{Jj+1, …, Jk−1} thenIf x<r thenf(j, k, l, r)=f(j, k, l, r)+lp[q, l]A(j, k, l, r)=A(j, k, l, r)∪{J[q, l]}x=x+1Elsef(j, k, l, r)=f(j, k, l, r)+e[q, l]Step 4: {Output}:f(j, k, l, r) and A(j, k, l, r) for j=1, …, n, k=j+1, …, n+1, l=1, …, n−j+1 and r=rmin(j, k, l), …, rmax(j, k, l)Step 1 of Procedure f(j, k, l, r) requires O(n2) time; Step 2 requires O(n2logn) time; and Step 3 requires O(n5) time. Thus, Procedure f(j, k, l, r) takes O(n5) time. Furthermore, the fact that Step 1 of Algorithm 1 requires O(1) time; Step 2 requires O(nlogn) time; Step 3 requires the implementation of procedure f(j, k, l, r) which requires O(n5) time; Step 4 requires O(n4) time; Step 5 requires O(n2) time; and Step 6 requires O(n) time implies that the following theorem holds:Theorem 1Algorithm 1solves the1|rej,s-batch|∑Jj∈ACj+∑Jj∈A¯ejproblem in O(n5) time.We point out that Algorithm 1 can be easily modified to solve the bounded version of the problem, where the number of jobs to be processed in a batch is bounded by B. The only changes required are to redefine rmax(j, k, l) such thatrmax(j,k,l)=min{l-1,k-j,B}ifk⩽nlifk=n+1.and to restrict the l value to be not greater than B if k=n+1. Thus, the1|rej,s-batch,B⩽n|∑Jj∈ACj+∑Jj∈A¯ejproblem is solvable in O(n5) time as well. A numerical example that illustrates the implementation of Algorithm 1 is included in an Appendix.In this section we provide a pseudo-polynomial time algorithm to solve the P2 problem. We note that the algorithm can be easily modified to solve problems P3–P4 in pseudo-polynomial time as well. The algorithm is constructed only for cases whenE¯<∑Jj∈Jej. Otherwise, ifE¯⩾∑Jj∈Jejthen the optimal solution is simply to reject all jobs. SinceE¯<∑Jj∈Jej, at least a single job has to be accepted.To describe the algorithm, we define F(j, l, D, E) as the minimal total completion time value for a partial solution that includes jobs Jj, …, Jn, where l is the number of accepted jobs, D is the total processing time of the jobs included in the first batch, and E is the total rejection cost. In order to justify our optimization algorithm, we present the following elimination property. Let S1 and S2 be two partial solutions that include jobs Jj, …, Jnboth with the same number of accepted jobs (l), the same total processing time of the jobs included in the first batch (D) and the same total rejection cost (E). Moreover, let F1(j, l, D, E) and F2(j, l, D, E) represent the total completion time for partial solutions S1 and S2, respectively. Then, we have the following easy-to-prove elimination property:Lemma 2Partial solution S1dominates partial solution S2if F1(j, l, D, E)⩽F2(j, l, D, E).Our algorithm uses Lemma 2 to solve the P2 problem variation in pseudo-polynomial time, by finding the entire set of non-dominated partial solutions. When considering to include job Jjwithin a partial schedule that includes jobs Jj+1, …, Jnthere are only three possible decisions.•Decision 1: To reject job Jj;Decision 2: To accept job Jjand include it in the current batch; andDecision 3: To accept job Jjand include it as a single job in a new batch.The algorithm dynamically constructs a set (list)Ljof sextuplets (F(j, l, D, E), l, D, E, d(j, l, D, E), Δ(j, l, D, E)) for j=1, …, n that corresponds to the entire set of non-dominated partial solutions that includes jobs Jj, …, Jn, where d(j, l, D, E)=i(i∈{1, 2, 3}) implies that decision i is made about job Jjand Δ(j, l, D, E) implies that this sextuplet is obtained from a sextuplet inLj+1for which the total processing time of the jobs included in the first batch was Δ(j, l, D, E). The d(j, l, D, E) and Δ(j, l, D, E) values will help us to track back the optimal solution at the end of the list construction procedure.We initialize the algorithm by settingLn+1={(F(n+1,0,0,0),0,0,0,0,0)}={(0,0,0,0,0,0)}. Then, we use a backward method for constructingLjfromLj+1for j=1, …, n. Out of each sextuplet (F(j+1, l, D, E), l, D, E, d(j+1, l, D, E), Δ(j+1, l, D, E)) inLj+1, we construct at most three different sextuplets inLjcorresponding to each of the three possible decisions to schedule job Jj(see Decisions 1–3 above). More specifically, for any sextuplet(F(j+1,l,D,E),l,D,E,d(j+1,l,D,E),Δ(j+1,l,D,E))∈Lj+1we do the following:•{Decision 1 is made}: IfE+ej⩽E¯we construct inLjthe sextuplet (G(j, l, D, E+ej), l, D, E+ej, d(j, l, D, E+ej), Δ(j, l, D, E+ej)) where G(j, l, D, E+ej)=F(j+1, l, D, E), d(j, l, D, E+ej)=1 and Δ(j, l, D, E+ej)=D.{Decision 2 is made}: We accept job Jjand include it in the current batch. According to (1) the completion time of each of the l previously accepted (and scheduled) jobs will increase by pjunits of time. Moreover, job Jjwill be completed at time s+D+pj. Thus, the resulting sextuplet to be included inLjis (G(j, l+1, D+pj, E), l+1, D+pj, E, d(j, l+1, D+pj, E), Δ(j, l+1, D+pj, E)), where G(j, l+1, D+pj, E)=F(j+1, l, D, E)+s+D+(l+1)pj, d(j, l+1, D+pj, E)=2 and Δ (j, l+1, D+pj, E)=D.{Decision 3 is made}: We accept job Jjand include it as a single job in a new batch. This implies that job Jjwill be completed at time s+pj, which will increase the completion time of the l previously accepted (and scheduled) jobs by s+pjunits of time. Thus, the resulting sextuplet to be included inLjis (G(j, l+1, pj, E), l+1, pj, E, d(j, l+1, pj, E), Δ(j, l+1, pj, E)) where G(j, l+1, pj, E)=F(j+1, l, D, E)+(l+1)(s+pj), d(j, l+1, pj, E)=3 and Δ(j, l+1, pj, E)=D.Naturally, the construction of listLjmay generate more than a single sextuplet with the same l, D and E values. According to Lemma 2, among all sextuplets with the same l, D and E values, we can keep inLjonly the one with the minimum F(j, l, D, E) value. That is, if there are q(j, l, D, E) sextuplets, (G1(j, l, D, E), l, D, E, d1(j, l, D, E), Δ1(j, l, D, E)), (G2 (j, l, D, E), l, D, E, d2(j, l, D, E), Δ2(j, l, D, E)), …, (Gq(j, l, D, E) (j, l, D, E), l, D, E, dq(j, l, D, E)(j, l, D, E), Δq(j, l, D, E)(j, l, D, E)) inLjwith the same l, D and E values, we keep inLjonly the sextuplet(F(j,l,D,E),l,D,E,dr∗(j,l,D,E),Δr∗(j,l,D,E))where r∗=arg{minr=1, …, q(j, l, D, E){Gr(j, l, D, E)}} andF(j,l,D,E)=Gr∗(j,l,D,E).At the end list construction procedure, the optimal solution is given by the F(1, l, D, E) value that corresponds to sextuplet (F(1, l, D, E), l, D, E, d(1, l, D, E), Δ(1, l, D, E)) with the minimum F(1, l, D, E) value among all the sextuplets inL1. To summarize the above analysis, we present the following optimization algorithm to solve the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejproblem, followed by a proof that the algorithm runs in pseudo-polynomial time.Algorithm 3Algorithm for solving the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejproblem{Input}: e=(e1, …, en), p=(p1, …, pn), s andE¯.Step 1: {Preprocessing}: Renumber the jobs according to the SPT rule.Step 2: {Initialization}: SetLn+1={(F(n+1,0,0,0),0,0,0,0,0)}={(0,0,0,0,0,0)}.Step 3: {The construction of listLj}:For j=1 to n doOut of each(F(j+1,l,D,E),l,D,E,d(j+1,l,D,E),Δ(j+1,l,D,E))∈Lj+1do:IfE+ej⩽E¯Construct inLjthe sextuplet (G(j, l, D, E+ej), l, D, E+ej, d(j, l, D, E+ej), Δ(j, l, D, E+ej)) where G(j, l, D, E+ej)=F(j+1, l, D, E), d(j, l, D, E+ej)=1 and Δ(j, l, D, E+ej)=D.Construct inLjthe sextuplet (G(j, l+1, D+pj, E), l+1, D+pj, E, d(j, l+1, D+pj, E), Δ(j, l+1, D+pj, E)), where G(j, l+1, D+pj, E)=F(j+1, l, D, E)+s+D+(l+1)pj, d(j, l+1, D+pj, E)=2 and Δ(j, l+1, D+pj, E)=D.Construct inLjthe sextuplet (G(j, l+1, pj, E), l+1, pj, E, d(j, l+1, pj, E), Δ(j, l+1, pj, E)) where G(j, l+1, pj, E)=F(j+1, l, D, E)+(l+1)(s+pj), d(j, l+1, pj, E)=3 and Δ(j, l+1, pj, E)=D.Among the q(j, l, D, E) sextuplets, (G1(j, l, D, E), l, D, E, d1(j, l, D, E), Δ1(j, l, D, E)), (G2(j, l, D, E), l, D, E, d2(j, l, D, E), Δ2(j, l, D, E)), …, (Gq(j, l, D, E)(j, l, D, E), l, D, E, dq(j, l, D, E)(j, l, D, E), Δq(j, l, D, E)(j, l, D, E)) inLjwith the same l, D and E values, keep inLjonly the sextuplet(F(j,l,D,E),l,D,E,dr∗(j,l,D,E),Δr∗(j,l,D,E))where r∗=arg{minr=1, …, q(j, l, D, E){Gr(j, l, D, E)}} andF(j,l,D,E)=Gr∗(j,l,D,E).Step 4: {Determining the optimal solution value}: Find the sextuplet (F(1, l, D, E), l, D, E, d(1, l, D, E), Δ(1, l, D, E)) with the minimal F(1, l, D, E) value among all sextuplets inL1. Set F∗=F(1, l, D, E), l∗=l, D∗=D and E∗=E.Step 5: {The construction of the optimal solution}:Seti=1,l=l∗,D=D∗,E=E∗,A=A¯=∅and B1, …, Bn=∅.For j=1 to n doIf d(j, l, D, E)=1SetA¯=A¯∪{Jj}and E=E−ej.If d(j, l, D, E)=2Set A=A∪{Jj}, l=l−1, D=Δ(j, l, D, E) and Bi=Bi∪{Jj}.If d(j, l, D, E)=3Set A=A∪{Jj}, l=l−1, D=Δ(j, l, D, E), Bi=Bi∪{Jj} and i=i+1.m=i.Step 6: {Output}:A,A¯=J⧹Aand B1, …, Bm.Step 1 requires a sorting operation which takes O(nlogn) time. Steps 2 requires O(1) time and Step 5 requires a linear time. In Step 3, out of each sextuplet (F(j+1, l, D, E), l, D, E, d(j+1, l, D, E), Δ(j+1, l, D, E)) inLj+1, we construct at most three sextuplets inLj. Since we haveOnE¯∑j=1npjsextuplets in each list, the construction of listLjrequiresOnE¯∑j=1npjtime, which is also the time required to obtain the optimal solution value in Step 4. The fact that in Step 3 we constructLjfor j=1, …, n implies that the following theorem holds:Theorem 2Algorithm 3solves the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejproblem inOn2E¯∑j=1npjtime.In order to solve the P4 problem variation we can simply modify Algorithm 3 as follows:(i) We remove the condition thatE+ej⩽E¯from Step 3.(ii) In order to find the entire set of Pareto-optimal points we replace Step 4 with:SetF(E¯=-1)=∞.ForE¯=0up toE¯=∑Jj∈A¯ejdoAmong all sextuplets inL1with a total rejection cost ofE¯find the sextuplets(F(1,l,D,E¯),l,D,E¯,d(1,l,D,E¯),Δ(1,l,D,E¯))with the minimalF(1,l,D,E¯)value.IfF(1,l,D,E¯)⩽F(E¯-1)Include(F(E¯),E¯)in the set of Pareto-optimal points.SetF(E¯)=F(1,l,D,E¯),l(E¯)=landD(E¯)=D.ElseSetF(E¯)=F(E¯-1).(iii) In order to find an efficient solution corresponding to each Pareto-optimal points we replaceStep 5 with:For each Pareto optimal point(F(E¯),E¯)do:Seti=1,l=l(E¯),D=D(E¯),E=E¯,A(E¯)=A¯(E¯)=∅andB1(E¯),…,Bn(E¯)=∅.For j=1 to n doIf d(j, l, D, E)=1SetA¯(E¯)=A¯(E¯)∪{Jj}and E=E−ej.If d(j, l, D, E)=2SetA(E¯)=A(E¯)∪{Jj},l=l-1,D=Δ(j,l,D,E),Bi(E¯)=Bi(E¯)∪{Jj}.If d(j, l, D, E)=3SetA(E¯)=A(E¯)∪{Jj},l=l-1,D=Δ(j,l,D,E),Bi(E¯)=Bi(E¯)∪{Jj}and i=i+1.m(E¯)=i.(iv) The output will include a Pareto optimal solution for each Pareto optimal point and thus we replace Step 6 by:For each Pareto optimal point(F(E¯),E¯)do:Output a Pareto-optimal solution:A(E¯),A¯(E¯)=J⧹AandB1(E¯),…,Bm(E¯).In the modified algorithm we will haveOn∑j=1nej∑j=1npjsextuplets in each list. Thus, the construction of listLjwill requireOn∑j=1nej∑j=1npjtime, which is also the time required for the elimination procedure in this step. If we make sure during the list construction procedure that the sextuplets inL1are maintained in a sorted list with respect to their E value, we can actually determine the Pareto optimal solution associated with a specificE¯value, given the Pareto optimal solution associated withE¯-1inOn∑j=1npjtime. Thus, the modified Step 4 can be implemented inOn∑j=1nej∑j=1npjtime. Since there are at mostO∑j=1nejPareto optimal solutions, we can implement the modified Step 5 inOn∑j=1nejtime. Thus, the modified algorithm can solve problem P4 isOn2∑j=1nej∑j=1npj. In a similar way it is easy to show that Algorithm 3 can be modified to solve the P3 problem variation inOn2K¯∑j=1nejtime. Thus, we have the following corollary:Corollary 1Problems P2–P4 are all ordinaryNP-hard.In this subsection we provide an ε-approximation algorithm that, given the existence of a Pareto-optimal solution with a total rejection cost of at most R and a total completion time of at most K, finds in O(n6/ε2) time a solution with a total rejection cost of at most (1+ε)R and a total completion time value of at most (1+ε)K. This is done by defining a series of h-auxiliary P2-type problems (denoted by1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejfor 1⩽h⩽n withE¯=(1+ε)R) where job Jhis accepted and has the largest pjvalue in set A, i.e.,ph=maxJj∈A{pj}, and also by providing an ε-approximation algorithm to each of these n auxiliary problems. Then, we show that by selecting the approximate solution with the minimum total completion time value out of the n approximate solutions of the n auxiliary problems, we can obtain an ε-approximation solution with a total rejection cost of at most (1+ε)R and a total completion time value of at most (1+ε)K.To optimally solve the above auxiliary problem in pseudo-polynomial time, the following modifications are incorporated into Algorithm 3 (we refer to this modified algorithm as Algorithm 3M and the corresponding lists constructed by the algorithm asLj(h)for j=1, …, n+1):•To make sure that job Jhis indeed accepted we add the condition j≠h to the condition thatE+ej⩽E¯=(1+ε)Rin Step 3.1.To make sure that the feasibility condition thatph=maxJj∈A{pj}is satisfied, the two sextuplets in Steps 3.2 and 3.3 are constructed only if pj⩽ph.The following corollary is straightforward from Theorem 2 as well as from the above analysis.Corollary 2Algorithm 3M solves the1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejauxiliary problem inOn2E¯∑j=1npjtime.Next, we show how we can obtain an ε-approximation algorithm for finding an approximate optimal solution for the1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejauxiliary problem by using the interval partitioning technique originally proposed by Sahni (1976). In order to construct this algorithm we first need to provide a lower bound (LBh) and an upper bound (UBh) for the minimal total completion time value,zh∗, of the1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejauxiliary problem. Since (i) job Jhis the job with the largest pjvalue in set Ah, that is,ph=maxJj∈Ah{pj}, and (ii) any feasible solution of the h-auxiliary problem includes at least a single batch, implies thatLBh=s+ph⩽zh∗. Moreover, the fact that (i) no more than n jobs are accepted, and that (ii) a feasible solution is to schedule all accepted jobs in a single batch, implies thatzh∗⩽UBh=n(s+nph). Therefore, we have that UBh/LBh⩽n2.Now, letI1=[0,UBh=n(s+nph)],I2=[0,E¯=R(1+ε)]and I=I1×I2 be a two-dimensional interval that is the Cartesian product of the two intervals (I1 and I2). We partition intervals I1 and I2 into ⌈n/δ1⌉ and ⌈ n/δ2⌉ equal-size subintervals (closed from the left and open from the right, except for the last one which is closed at both ends and is possibly smaller), respectively, where δ1, δ2>0. This results in the partition of I into a set of ⌈n/δ1⌉⌈n/δ2⌉ two-dimensional subintervals. Then, we apply Algorithm 3M with the provision that, within each list, among all the sextuplets with the same l value and with F and E values falling within the same two-dimensional subinterval, we keep only the sextuplet with the smallest D value. Note that UBhδ1/n and E(1+ε)δ2/n denote the maximum length of any subinterval in the partition with respect to the total completion time value and the total rejection cost, respectively. The resulting algorithm can be formally stated as follows:Algorithm 4An ε-approximation algorithm for the1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejauxiliary problem{Input}: e=(e1, …, en), p=(p1, …, pn), h, s, ε and R.Step 1: {Preprocessing}: Renumber the jobs according to the SPT rule.Step 2: {Initialization}: SetLn+1ε(h)={(G(n+1,0,0,0),0,0,0,0,0)}={(0,0,0,0,0,0)}.Step 3: {Interval Partition}: Partition the interval I1=[0, UBh=n(s+nph)] into ⌈n/δ1⌉ equal-size subintervals as follows:0,δ1UBhn;δ1UBhn,2δ1UBhn,…,nδ1-1δ1UBhn,UBhPartition the intervalI2=[0,E¯=R(1+ε)]into ⌈n/δ2⌉ equal-size subintervals as follows:0,δ2E¯n;δ2E¯n,2δ2E¯n,…,nδ2-1δ2E¯n,E¯. This results in the partition of I=I1×I2 into a set of ⌈n/δ1⌉⌈n/δ2⌉ two-dimensional subintervals.Step 4:TheconstructionoflistLjε(h):For j=n down to 1 do:Out of each(G(j+1,l,D,E),l,D,E,d(j+1,l,D,E),Δ(j+1,l,D,E))∈Lj+1ε(h)do:IfE+ej⩽E¯and j≠hConstruct inLjε(h)the sextuplet (G(j, l, D, E+ej), l, D, E+ej, d(j, l, D, E+ej), Δ(j, l, D, E+ej)), where G(j, l, D, E+ej)=G(j+1, l, D, E), d(j, l, D, E+ej)=1 and Δ(j, l, D, E+ej)=D.If pj⩽phConstruct inLjε(h)the sextuplet (G(j, l+1, D+pj, E), l+1, D+pj, E, d(j, l+1, D+pj, E), Δ(j, l+1, D+pj, E)), where G(j, l+1, D+pj, E)=G(j+1, l, D, E)+s+D+(l+1)pj, d(j, l+1, D+pj, E)=2 and Δ(j, l+1, D+pj, E)=D.Construct inLjε(h)the sextuplet (G(j, l+1, pj, E), l+1, pj, E, d(j, l+1, pj, E), Δ(j, l+1, pj, E)) where G(j, l+1, pj, E)=G(j+1, l, D, E)+(l+1)(s+pj), d(j, l+1, pj, E)=3 and Δ(j, l+1, pj, E)=D.Among all sextuplets with the same l value that falls within the same two-dimensional subinterval inLjε(h), keep only the sextuplet with the smallest D value (if there is morethan a single sextuplet within the same subinterval with the smallest D value, keep the one with the smallestG(j, l, D, E) value).Step 5: {Determining the approximate solution value}: Find the sextuplet (G(1, l, D, E), l, D, E, d(1, l, D, E), Δ(1, l, D, E)) with the minimal G(1, l, D, E) value among all sextuplets inL1ε(h). Setzh′=G(1,l,D,E),lh′=l,Dh′=DandEh′=E.Step 6: {The construction of the approximate solution}:Seti=1,l=lh′,D=Dh′,E=Eh′,Ah′=A¯h′=∅andB1′(h),…,Bn′(h)=∅.For j=1 to n doIf d(j, l, D, E)=1 thensetA¯h′=A¯h′∪{Jj}and E=E−ej.If d(j, l, D, E)=2 thensetAh′=Ah′∪{Jj},l=l-1,D=Δ(j,l,D,E)andBi′(h)=Bi′(h)∪{Jj}.If d(j, l, D, E)=3 thenset i=i+1,Ah′=Ah′∪{Jj},l=l-1,D=Δ(j,l,D,E)andBi′(h)=Bi′(h)∪{Jj}m=i.Step 7: {Output}:Ah′,A¯h′andB1′(h),…,Bm′(h).For any eliminated sextuplet(F(j,l,Dj,Ej),l,Dj,Ej,d(j,l,Dj,Ej),Δ(j,l,Dj,Ej))∈Lj, there exists a sextuplet(G(j,l,D^j,E^j),l,D^j,E^j,d(j,l,D^j,E^j),Δ(j,l,D^j,E^j))∈Ljε(h)which satisfies thatD^j⩽Dj,G(j,l,D^j,E^j)-F(j,l,Dj,Ej)⩽(n-j+1)Δ1andE^j-Ej⩽(n-j+1)Δ2where Δ1=UBhδ1/n and Δ2=E(1+ε)δ2/n.We prove the Lemma by induction on j. We start by showing that the Lemma holds for j=n. According to the elimination procedure of Algorithm 4, for every eliminated sextuplet (F(n, l, Dn, En), l, Dn, En, d(n, l, Dn, En), Δ(n, l, Dn, En)) in any two-dimensional subinterval, we keep an alternative sextuplet(G(n,l,D^n,E^n),l,D^n,E^n,d(n,l,D^n,E^n),Δ(n,l,D^n,E^n))within the same two-dimensional subinterval withD^n⩽Dn,G(n,l,D^n,E^n)-F(n,l,Dn,En)⩽Δ1=UBhδ1/nand withE^n-En⩽Δ2=R(1+ε)δ2/n, where Δ1 and Δ2 denote the maximum length of any two-dimensional subinterval with respect to the total completion time value and the total rejection cost, respectively. Therefore the Lemma holds for j=n.Let us now assume that the Lemma holds for j+1 (the induction assumption); that is, for any eliminated sextuplet(F(j+1,l,Dj+1,Ej+1),l,Dj+1,Ej+1,d(j+1,l,Dj+1,Ej+1),Δ(j+1,l,Dj+1,Ej+1))∈Lj+1(h)there exists a sextuplet(G(j+1,l,D^j+1,E^j+1),l,D^j+1,E^j+1,d(j+1,l,D^j+1,E^j+1),Δ(j+1,l,D^j+1,E^j+1))∈Lj+1ε(h)which satisfies thatD^j+1⩽Dj+1,G(j+1,l,D^j+1,E^j+1)-F(j+1,l,Dj+1,Ej+1)⩽(n-j)Δ1andE^j+1-Ej+1⩽(n-j)Δ2. We need to show that the Lemma also holds for j; that is, for any eliminated sextuplet(F(j,l,Dj,Ej),l,Dj,Ej,d(j,l,Dj,Ej),Δ(j,l,Dj,Ej))∈Lj(h), there exists a sextuplet(G(j,l,D^j,E^j),l,D^j,E^j,d(j,l,D^j,E^j),Δ(j,l,D^j,E^j))∈Ljε(h)which satisfies thatD^j⩽Dj,G(j,l,D^j,E^j)-F(j,l,D1,E1)⩽(n-j+1)Δ1andE^j-Ej⩽(n-j+1)Δ2. We show below that the Lemma holds for all three different cases that can arise.Let us first consider case 1, where(F(j,l,Dj,Ej),l,Dj,Ej,1,Δ(j,l,Dj,Ej))∈Lj(h)is constructed from the sextupletFj+1,l,Dj+1′,Ej+1′,l,Dj+1′,Ej+1′,dj+1,l,Dj+1′,Ej+1′,Δj+1,l′,Dj+1′,Ej+1′∈Lj+1(h), whereF(j,l,Dj,Ej)=Fj+1,l,Dj+1′,Ej+1′,Dj=Dj+1′andEj=Ej+1′+ej. This implies thatEj+1′+ej⩽E¯=R(1+ε). According to the induction assumption, there exists a sextuplet(G(j+1,l,D^j+1,E^j+1),l,D^j+1,E^j+1,d(j+1,l,D^j+1,E^j+1),Δ(j+1,l,D^j+1,E^j+1))∈Lj+1ε(h)(which might also be the sextupletFj+1,l,Dj+1′,Ej+1′,l,Dj+1′,Ej+1′,dj,l,Dj+1′,Ej+1′,Δj,l,Dj+1′,Ej+1′withD^j+1⩽Dj+1′,G(j+1,l,D^j+1,E^j+1)-Fj+1,l,Dj+1′,Ej+1′⩽(n-j)Δ1andE^j+1-Ej+1′⩽(n-j)Δ2. The existence of this sextuplet implies that just before the elimination procedure forLjε(h)we have that(G(j,l,D∼j,E∼j),D∼j,E∼j,d(j,l,D∼j,E∼j),Δ(j,l,D∼j,E∼j))∈Ljε(h)withG(j,l,D∼j,E∼j)=G(j+1,l,D^j+1,E^j+1),D∼j=D^j+1,E∼j=E^j+1+ej,d(j,l,D∼j,E∼j)=1andΔ(j,l,D∼j,E∼j)=D^j+1. Furthermore, it directly follows from the elimination procedure forLjε(h)that after the elimination there exists a sextuplet(G(j,l,D^j,E^j),l,D^j,E^j,d(j,l,D^j,E^j),Δ(j,l,D^j,E^j))∈Ljε(h)withD^j⩽D∼j=D^j+1,G(j,l,D^j,E^j)-G(j,l,D∼j,E∼j)⩽Δ1andE^j-E∼j⩽Δ2. Thus, we have thatD^j⩽D∼j=D^j+1⩽Dj+1′=Dj. The fact thatG(j,l,D^j,E^j)⩽G(j,l,D∼j,E∼j)+Δ1=G(j+1,l,D^j+1,E^j+1)+Δ1⩽Fj+1,l,Dj+1′,Ej+1′+(n-j)Δ1+Δ1=Fj+1,l,Dj+1′,Ej+1′+(n-j+1)Δ1=F(j,l,Dj,Ej)+(n-j+1)Δ1and thatE^j⩽E∼j+Δ2=E^j+1+ej+Δ2=Ej+1′+(n-j+1)Δ2+ej=Ej+(n-j+1)Δ2completes our proof for case 1.Let us now consider case 2, where(F(j,l,Dj,Ej),l,Dj,Ej,2,Δ(j,l,Dj,Ej))∈Lj(h)is constructed from the sextupletFj+1,l″,Dj+1″,Ej+1″,l″,Dj+1″,Ej+1″,dj+1,l″,Dj+1″,Ej+1″,Δj+1,l″,Dj+1″,Ej+1″∈Lj+1(h), whereF(j,l,Dj,Ej)=Fj+1,l″,Dj+1″,Ej+1″+s+Dj+1″+lpj,l=l″+1,Dj=Dj+1″+pjandEj=Ej+1″. This implies that pj⩽ph. According to the induction assumption, there exists a sextupletGj+1,l″,D^j+1,E^j+1,l″,D^j+1,E^j+1,dj+1,l″,D^j+1,E^j+1,Δ(j+1,l″,D^j+1,E^j+1)∈Lj+1ε(h)(which might also be the sextupletFj+1,l″,Dj+1″,Ej+1″,l″,Dj+1″,Ej+1″,dj+1,l″,Dj+1″,Ej+1″,Δj+1,l″,Dj+1″,Ej+1″withD^j+1⩽Dj+1″,Gj+1,l″,D^j+1,E^j+1-Fj+1,l″,Dj+1″,Ej+1″⩽(n-j)Δ1andE^j+1-Ej+1″⩽(n-j)Δ2. The existence of this sextuplet implies that just before the elimination procedure forLjε(h)we have thatGj,l″+1,D∼j,E∼j,D∼j,E∼j,dj,l″+1,D∼j,E∼j,Δj,l″+1,D∼j,E∼j∈Ljε(h)withGj,l″+1,D∼j,E∼j=Gj+1,l″,D^j+1,E^j+1+s+D^j+1+lpj,D∼j=D^j+1+pj,E∼j=E^j+1,d(j,l″+1,D∼j,E∼j)=2andΔ(j,l″+1,D∼j,E∼j)=D^j+1. Furthermore, it directly follows from the elimination procedure forLjε(h), that after the elimination there exists a sextuplet(G(j,l″+1,D^j,E^j),l″+1,D^j,E^j,d(j,l″+1,D^j,E^j),Δ(j,l″+1,D^j,E^j))∈Ljε(h)withD^j⩽D∼j,G(j,l″+1,D^j,E^j)-G(j,l″+1,D∼j,E∼j)⩽Δ1andE^j-E∼j⩽Δ2. Thus, we have thatD^j⩽D∼j=D^j+1+pj⩽Dj+1″+pj=Dj. The fact thatG(j,l″+1,D^j,E^j)⩽G(j,l″+1,D∼j,E∼j)+Δ1=G(j+1,l″,D^j+1,E^j+1)+s+D^j+1+lpj+Δ1⩽Fj+1,l″,Dj+1″,Ej+1″+(n-j)Δ1+s+Dj+1″+lpj+Δ1=F(j,l,Dj,Ej)+(n-j+1)Δ1and thatE^j⩽E∼j+Δ2=E^j+1+Δ2⩽Ej+1″+(n-j+1)Δ2=Ej+(n-j+1)Δ2completes our proof for case 2.Last we consider case 3, where(F(j,l,Dj,Ej),l,Dj,Ej,3,Δ(j,l,Dj,Ej))∈Lj(h)is constructed from the sextupletF(j+1,l‴,Dj+1‴,Ej+1‴),l‴,Dj+1‴,Ej+1‴,dj,l‴,Dj+1‴,Ej+1‴,Δj,l‴,Dj+1‴,Ej+1‴∈Lj+1(h), whereF(j,l,Dj,Ej)=Fj+1,l‴,Dj+1‴,Ej+1‴+l(s+pj),l=l‴+1,Dj=pjandEj=Ej+1‴. This implies that pj⩽ph. According to the induction assumption,there exists a sextuplet(G(j+1,l‴,D^j+1,E^j+1),l‴,D^j+1,E^j+1,d(j+1,l‴,D^j+1,E^j+1),Δ(j+1,l‴,D^j+1,E^j+1))∈Lj+1ε(h)(which might also be the sextupletFj+1,l‴,Dj+1‴,Ej+1‴,l‴,Dj+1′″,Ej+1‴,dj+1,l‴,Dj+1‴,Ej+1‴,Δj+1,l‴,Dj+1‴,Ej+1‴) withD^j+1⩽Dj+1‴,G(j+1,l‴,D^j+1,E^j+1)-Fj+1,l‴,Dj+1‴,Ej+1‴⩽(n-j)Δ1andE^j+1-Ej+1‴⩽(n-j)Δ2. The existence of this sextuplet implies that just before the elimination procedure forLjε(h)we have that(G(j,l‴+1,D∼j,E∼j),D∼j,E∼j,d(j,l‴+1,D∼j,E∼j),Δ(j,l‴+1,D∼j,E∼j))∈Ljε(h)withG(j,l‴+1,D∼j,E∼j)=G(j+1,l‴,D^j+1,E^j+1)+(l‴+1)(s+pj),D∼j=pj,E∼j=E^j+1,d(j,l‴+1,D∼j,E∼j)=3andΔ(j,l‴+1,D∼j,E∼j)=D^j+1. Furthermore, it directly follows from the elimination procedure forLjε(h), that after the elimination there exists a sextuplet(G(j,l‴+1,D^j,E^j),l‴+1,D^j,E^j,d(j,l‴+1,D^j,E^j),Δ(j,l‴+1,D^j,E^j))∈Ljε(h)withD^j⩽D∼j,G(j,l‴+1,D^j,E^j)-G(j,l‴+1,D∼j,E∼j)⩽Δ1andE^j-E∼j⩽Δ2. Thus, we have thatD^j⩽D∼j=pj=Dj. The fact thatG(j,l‴+1,D^j,E^j)⩽G(j,l‴+1,D∼j,E∼j)+Δ1=G(j+1,l‴,D^j+1,E^j+1)+(l‴+1)(s+pj)+Δ1⩽F(j+1,l‴,Dj+1‴,Ej+1‴)+(n-j+1)Δ1+l(s+pj)=F(j,l,Dj,Ej)+(n-j+1)Δ1and thatE^j⩽E∼j+Δ2=E^j+1+Δ2⩽Ej+1‴+(n-j+1)Δ2=Ej+(n-j+1)Δ2completes our proof for case 3.□Algorithm 4finds in O(n5/ε2) time a solution for problem1|rej,h,s-batch|∑Jj∈ACj,∑Jj∈A¯ejwith a total rejection cost of at most (1+ε)R and a total completion time of at most(1+ε)zh∗.Let δ1=εLBh/UBhand δ2=ε/(1+ε). From Lemma 3, we can conclude that if the sextuplet(F(1,l,D1,E1),l,D1,E1,d(1,l,D1,E1),Δ(1,l,D1,E1))∈L1(h)withF(1,l,D1,E1)=zh∗has been eliminated during the implementation of Algorithm 4, then there exists a non-eliminated sextuplet(G(1,l,D^1,E^1),l,D^1,E^1,d(1,l,D^1,E^1),Δ(1,l,D^1,E^1))∈L1ε(h)withG(1,l,D^1,E^1)⩽zh∗+nΔ1=zh∗+UBhδ1=zh∗+εLBh⩽zh∗+εzh∗=(1+ε)zh∗. The fact thatE^1⩽E¯=(1+ε)Rfollows from the condition in Step 4 of Algorithm 4 that we can construct a sextuplet by rejecting a job only if the total rejection cost does not exceedE¯.Next, we analyze the time complexity of Algorithm 4. Step 1 requires a sorting procedure which takes O(nlogn) time, Steps 2 takes O(1) time and Step 3 takesOn2δ1δ2=O(n4/ε2)time. Since we have O(n4/ε2) two-dimensional subintervals, there are O(n4/ε2) sextuplets inLj+1ε(h). Furthermore, since we construct at most three sextuplets inLjε(h)out of every sextuplet inLj+1ε(h), the construction of listLjε(h)in Step 4 needs at most O(n4/ε2) time, which is also the time required for the elimination process in this step. In Step 5 we need to find the approximate sextupletzh′=G(1,l,D,E),l,D,E,d(1,l,D,E),Δ(1,l,D,E)with the minimal G(1, l, D, E) value among all sextuplets inL1ε(h). Since there are at most O(n4/ε2) sextuplets in each list, this can be done in O(n4/ε2) time. Then, tracing the approximate solution in Step 6 can be done in linear time. Since Steps 4 is repeated O(n) times, the overall complexity of Algorithm 4 is indeed O(n5/ε2).□Let z∗(R) be the optimal total completion time value for the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejproblem withE¯=R. Given that there exists a schedule with a total rejection cost of at most R and a total completion time value of at most K we have that z∗(R)⩽K. Sincezh∗is the optimal total completion time value for the1|rej,h,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejauxiliary problem withE¯=R(1+ε)we have thatz∗(E¯)=min1⩽h⩽nzh∗⩽z∗(R)⩽K.Now, let us define an approximation algorithm (denoted as Algorithm 5) which runs Algorithm 4 for 1⩽h⩽n and select the solution that yields the minimumzh′value as the approximate solution for the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ejproblem. According to Theorem 3, the running time of Algorithm 5 is O(n6/ε2). Leth∗=argmin1⩽h⩽nzh′and letzh∗′=G(1,l′,D′,E′),l′,D′,E′,d(1,l′,D′,E′),Δ(1,l′,D′,E′)∈L1ε(h∗)be the sextuplet that corresponds to the approximate solution for the1|rej,s-batch|∊∑Jj∈ACj/∑Jj∈A¯ej. Then by Theorem 3 we have thatzh∗′=min1⩽h⩽nzh′⩽min1⩽h⩽n(1+ε)zh∗=(1+ε)z∗(E¯)⩽(1+ε)z∗(R)⩽(1+ε)K.The fact thatE′⩽E¯=(1+ε)Rfollows from the condition in Step 4 of Algorithm 4 that we construct a sextuplet by rejecting a job only if the total rejection cost does not exceedE¯. Thus, the following theorem holds.Theorem 4Given that there exists a solution with a total rejection cost of at most R and a total completion time of at most K, Algorithm 5 finds in O(n6/ε2) time a solution with a total rejection cost of at most (1+ε)R and a total completion time value of at most (1+ε)K.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
