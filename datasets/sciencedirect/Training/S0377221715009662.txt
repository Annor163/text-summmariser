@&#MAIN-TITLE@&#
Optimal policies of M(t)/M/c/c queues with two different levels of servers

@&#HIGHLIGHTS@&#
We obtain the optimal control points of special periodic M(t)/M/c/c queues.We modify the fourth-order Runge–Kutta to calculate the transient solutions.The periodic variation of arrival rates makes the control policies periodic.We study how fast the policies converge to a periodic pattern.We obtain a criterion for independence of policies in two sequential cycles.

@&#KEYPHRASES@&#
Periodic MDP,Time-dependent queues,Health care,Two-level for number of servers,Hysteretic policy,

@&#ABSTRACT@&#
This paper deals with optimal control points of M(t)/M/c/c queues with periodic arrival rates and two levels of the number of servers. We use the results of this model to build a Markov decision process (MDP). The problem arose from a case study in the Kelowna General Hospital (KGH). The KGH uses surge beds when the emergency room is overcrowded which results in having two levels for the number of the beds. The objective is to minimize a cost function. The findings of this work are not limited to the healthcare; They may be used in any stochastic system with fluctuation in arrival rates and/or two levels of the number of servers, i.e., call centers, transportation, and internet services. We model the situation and define a cost function which needs to be minimized. In order to find the cost function we need transient solutions of the M(t)/M/c/c queue. We modify the fourth-order Runge–Kutta to calculate the transient solutions and we obtain better solutions than the existing Runge–Kutta method. We show that the periodic variation of arrival rates makes the control policies time-dependent and periodic. We also study how fast the policies converge to a periodic pattern and obtain a criterion for independence of policies in two sequential cycles.

@&#INTRODUCTION@&#
In this paper, we discuss the determination of the optimal time-dependent control policy of the M(t)/M/c/c queue. The (m, N) policy, gives two contours for deciding the level of service based on the length of the queue or number of the customers in the system. If the number of the customers reaches N from below, we use the higher level of service, and if it drops down below m, we switch back to the lower level of service. These types of policies are also called bi-level or hysteretic policies. We will show that for a periodic arrival rate, the decisions will be independent of each other after a mixing time. We will also discuss that the policies are periodic with the same period as arrival rates. Arrivals are Poisson with a periodic time-dependent arrival rate and service times are distributed exponentially. There are two possible levels of the number of servers. The maximum capacity of the system is equal to the number of servers at each level. In literature, different levels of service rates have been considered for queues. However, according to our knowledge, changes in number of servers have not been studied.The problem discussed in this paper arises out of a case study in the Emergency Department (ED) of the Kelowna General Hospital (KGH) in British Columbia, Canada. The KGH is using surge beds in its ED. Surge beds (or generally surge resources) can either be temporary beds or a section which is only used when there is a “crisis situation”. A crisis situation arises when the waiting time for patients exceeds an acceptable threshold (Gorunescu, McClean, & Millard, 2002; Palvannan & Teow, 2012). This model can be represented by a queue with the number of servers at two different levels, where it is at a higher level of service when the surge beds are in use. The arrival rate is periodic (e.g. annually) and therefore it is time-dependent. The main questions are (1) when to decide to use the surge resources and (2) for how long to keep them open.There are three types of beds in KGH, the main beds, stretchers or hall-way beds and surge beds. Surge beds can only be used after it has been decided to open the surge section. There are two costs related to the surge section; Opening a surge section (applied each time it opens) and running the surge section (the daily cost). There is another cost related to the number of the patients on stretchers. The quality of service has an inverse relation to the number of patients on stretchers. The lower the number of patients on stretchers, the better the quality of service. The goal is to obtain an optimal policy which is a trade-off between the quality of service and the cost of the surge section. The problem addressed here is how one can manage the surge resources such that one has the maximum quality of service with minimum costs according to the start up and running cost of the surge section of the ED.Hysteretic policies have been studied for different possible queueing systems including determining the arrival rate (Lee & Li, 1993), the service rate (Artalejo & Economou, 2005; Lee & Srinivasan, 1989; Lin & Kumar, 1984; Neuts & Rao, 1992), the bulk size of the service or the arrival (Dudin, 2002), the system capacity (Perry, Stadje, & Zacks, 2007), the vacation mode of the server (Dshalalow, Kim, & Tadj, 2006), etc. However, most of these studies are focused on one server with multiple levels of service. Heyman (1968) considered an M/G/1 queue with a server that can be turned off. The start-up, shut-down, running cost for the server, and holding cost for customers was considered. Based on the similarity of this model and inventory models, Heyman suspected that the optimal policy is of the (S, s) form. He used dynamic programming for modeling the problem and obtaining the optimal control policy. Bell (1971) provided the proof and improved the computational algorithm for Heyman’s problem. Sobel (1969) examined the (m, N)-policy for the GI/G/1 queue defining a two dimensional state space with queue length and whether the server is operational and arguing with the random walk approach. Tadj and Choudhury (2005) provided a review on control policies papers until 2005. In more recent works, hysteretic policies has been used for variety of problems (Chang & Pearn, 2011; Jain, Shekhar, & Shukla, 2012; Wei, Yu, Tang, & Gu, 2013; Yu & Alfa, 2015; Zhang, 2009; Zhang, Tadj, & Bounkhel, 2011). However, after an extensive investigation involving Google Scholar and checking the indices of many relevant journals, including EJOR, from 2008 to now, no article on time-dependence hysteretic policies was found. We therefore believe that our approach is new.Time dependence is important because the seasonality or periodic behavior of a stochastic process can be observed in many real world service systems, i.e., walk-in clinics, hospital emergency departments, road traffic systems, public transportation, call centers and internet services. In order to have a better understanding of these systems, one can study the effects of time variation on decisions to run a system optimally. Since there is a time-dependence in the arrival rate in our work, obtaining a constant (m, N)-policy will not give an optimal solution. The novelty of this paper is to consider the effect of time-dependence on this category of control policies. That is, the m and N values can be varied depending on the location of decision making in the cycle of the arrival rate function.The theory we develop will work whenever the arrival rate varies in a periodic fashion. However, for the purpose of this paper, we considerλt=β+αsin(ω0t−π2ω0)as the time-dependent arrival rate where α, β and ω0 are constant and real. We chose the sine wave for our study since it has been considered before in Green and Kolesar (1991) and Green, Kolesar, and Svoronos (1991) and it seems to be a reasonable assumption for the arrival rate in the health care systems. The service rate of one bed in ED is denoted by μ. Let m1, m2 and m3 be the number of the main beds, stretchers, and surge beds, respectively. There are two levels for the number of beds for the ED, excluding and including the beds in the surge section,c1=m1+m2andc2=m1+m2+m3,respectively. The objective is to find an optimal policy for opening and closing the surge section such that the utility (cost) function becomes minimum.In this paper we will model and solve this problem with a Markov decision process (MDP) and use the results to obtain optimal control policies. For the objective function of the MDP model the transition probabilities and the time averages for an M(t)/M/c/c queue with one service level must be calculated. To do this, we need transient solutions of the M(t)/M/c/c queue. In Section 2 we will adapt the 4th order Runge–Kutta method for this queue. Section 3 will describe the problem in details and provide an MDP model for obtaining the optimal decisions to minimize the cost function. In Section 4 we will show empirically that the policies are periodic for a finite horizon MDP and consequently we can extend the results for the infinite planning horizon. Then we will give a numerical example of the (mt, Nt)-policy based on the results of MDP model and explore the existence of a phase difference of the results and the pattern of λt, and observe that for our case policies reach their periodic pattern quickly. Conclusions will be in Section 5.In this section, we obtain the transient solutions for the M(t)/M/c/c queue using numerical methods. For the cost function, we also need the accumulated cost over time which requires integrals of the probabilities over time. We use the transient solutions to estimate the integrals in the cost function. Consider the state of the queue given by the number of the patients in the system,j=0,1,2,…,cand let pj(t) be the probability of being in state j at time t. We want to calculate pj(t) within the interval (0, T). Let P(t) be the row vector of pj(t), that isP(t)=[p0(t),p1(t),p2(t),…,pc(t)]. We define the initial conditionsP(0)=QwhereQ=[q0,q1,q2,…,qc]is given. LetA(t)=[aij(t)]be the transition matrix of the M(t)/M/c/c queue. A(t) is a square matrix of sizec+1depending on t because of the arrival rates. Also we putaii(t)=−∑j=1caij(t). Therefore A(t) can be written as(1)A(t)=[−λtλt0⋯⋯0μ−(μ+λt)λt0⋯002μ−(2μ+λt)λt⋯⋮⋮0⋱⋱⋱0⋮⋱0(c−1)μ−[(c−1)μ+λt]λt0⋯⋯⋯cμ−cμ].We can compute pj(t) from the following differential equations with initial conditions mentioned above(2)pi′(t)=∑j=1c+1pj(t)aji(t)i=1,2,…,c+1,or(3)P′(t)=P(t)A(t).For solving Eq. (3), one can use the Runge–Kutta method. The most common Runge–Kutta method is fourth order Runge–Kutta (RK4). Consider differential equation such asy′=f(t,y),y(tn)=yn. Given ynand the step size Δt, the RK4 computes four quantities, κ1, κ2, κ3 and κ4, to findyn+1as follows (Davis, 1992)(4)κ1=f(tn,yn)Δt,(5)κ2=f(tn+Δt2,yn+κ12)Δt,(6)κ3=f(tn+Δt2,yn+κ22)Δt,(7)κ4=f(tn+Δt,yn+κ3)Δt,(8)yn+1=yn+16(κ1+κ2+κ3+κ4).One can consider A(t)P(t) as f(P, t) and simply apply RK4 directly on the function f(P, t). To reduce the round-off errors in the RK4 method, we letB(t)=A(t)f+I,where I is the identity matrix of the same size as A(t) and f is an arbitrary number such that f ≥ |aii(t)| for alli=1,2,…,Nand t ≥ 0. We can simply setf=maxi,t{−aii(t)}=λmax+cμwhereλmax=maxtλt. In this way all the elements of B(t) will be positive. Substituting A(t) by(B(t)−I)fin the RK4 formulas leads to(9)κ1=fP(tn)[B(tn)−I]Δt,(10)κ2=f[P(tn)+κ12][B(tn+Δt2)−I]Δt,(11)κ3=f[P(tn)+κ22][B(tn+Δt2)−I]Δt,(12)κ4=f[P(tn)+κ3)][B(tn+Δt)−I]Δt,(13)P(tn+1)=P(tn)+16(κ1+κ2+κ3+κ4).We did the comparison between the modified RK4 and other available methods and it has been found that the modified RK4 is more accurate with the same amount of running time. For comparing the RK4 and the modified RK4, we use the numerical results in Knessl and Yang paper (Knessl & Yang, 2006). Consider an M(t)/M/c/c queue with a periodic time-dependent arrival rate as follows:(14)λ(t)=c(α+asin(ω0t+ϕ)),wherec=100is the number of servers. They chooseα=1.2,a=0.5,ω0=0.1andϕ=−2.0. The initial state probabilities att=0isP(0)=(1,0,0,…,0)and the rate of service for each server isμ=1.The blocking probability, b(t), is the probability that a customer shows up at time t and he leaves the system without getting service. In M/M/c/c queues, b(t) equals to the probability of being in the state c at the time t, pc(t). For times in the range [2, 16], b(t) has been provided in Table 1 with different methods. The first column is time in seconds. The second column is the best solution claimed in Knessl and Yang’s paper. They did not mention the method for obtaining the values of this column; however, we believe they used Runge–Kutta method with a very small step size since there is no exact and closed form solution for b(t). The third column is the result of the fluid approximation that they provide in their paper. The fifth and seventh column are the results of the RK4 and the modified RK4 with the same step sizeh=.005,respectively. The absolute error for the RK4 and the modified RK4 are significantly smaller than Knessl and Yang’s approximation. Moreover, the modified RK4 gives the more accurate results in comparison with the RK4. The order of the error for modified RK4 is significantly smaller than RK4. We can see the same results for longer run. Table 2shows the blocking probabilities for times in the range 14.8 ≤ t ≤ 53. Therefore, we use the modified RK4 for our analysis since it showed the better performance rather than RK4.In the cost function we need to calculate the integral∫tntn+1pi,j(t)dtwhere pij(t) is the probability of going from state i to j during time t. For this purpose we need the transient solutions from the modified RK4. We approximate the integrals with Simpson’s rule, since they can not be computed analytically. Let h be the step size of the modified RK4. It means that to calculatepijnthe modified RK4 method computespij(tn−1+lh)for alll=0,1,2,…,L=Δth,whereΔt=tn−tn−1. We tune the step size in the way that L is always an even integer. By Simpson’s rule, we have∫tntn+1pij(t)dt≃h3∑l=0L2−1[pij(tn+2lh)+4pij(tn+(2l+1)h)+pij(tn+(2l+2)h)].It is obvious that the smaller the step size, h, the better approximation of the integrals.In this section we first explain the problem and its objective and then we provide a Markov decision model for solving it. The condition for using the model for the infinite horizon will then be discussed.Consider an emergency department with three types of beds, main, stretchers and surge beds. The service time for each bed, independent of its type, is exponentially distributed with a service rate μ. The surge beds are in an extra section with an additional cost when in use. There is a start-up and running cost for the surge section. On the other hand, having a patient on a stretcher bed imposes another cost to the system because of the lower quality service. When the surge section is closed, upon a new arrival, the priority is to allocate main beds first and then stretchers. When the surge section is open the order of assignments are the main, surge, and stretcher beds. The arrivals follow a Poisson process with time-dependent arrival rates. We assume the seasonality of arrival rate is a sine function. The objective is to find the optimal policy for opening and closing the surge section such that the cost of the system related to surge and patients on stretchers is minimized.The model considered is a discrete-time Markov decision process (Puterman, 1994). The elements of MDP will be explained in this section in detail and the backward induction algorithm for solving the model will be provided in Section 3.1.Assume we would like to obtain the optimal policy for a time interval (0, TH] where THis planning horizon. LetTH=nyTwhere T is the length of the cycle of function λt, that isT=2πω0and nyis the number of cycles in the planning horizon. Decision points are assumed to be discrete and equidistant. This is a reasonable assumption since decision making in our problem might be done daily, weekly as in KGH, biweekly, monthly,…,etc. We break down T intoN˜intervals. tnis the decision epoch att=nTN˜wheren∈{0,1,…,N˜−1}andtn−tn−1=Δt,∀n∈{1,…,N˜−1}.Let b be the number of patients in the system, and k1, k2 and k3 be the number of the patients on main, stretcher and surge beds, respectively. Let m1, m2 and m3 be the total number of beds in each section: main, stretcher, and surge. We assume that moving the patients between sections at each decision epoch are allowed with the following priority of the sections•when the surge section is closed,0≤b≤m1+m2,–if b ≤ m1 thenk1=b,k2=0,andk3=0,if b > m1 thenk1=m1,k2=b−m1,andk3=0.when the surge section is open,0≤b≤m1+m2+m3,–if b ≤ m1 thenk1=bandk2=k3=0,ifm1<b≤m1+m3thenk1=m1,k2=0andk3=b−m1,ifb>m1+m3thenk1=m1,k3=m3andk2=b−m1−m3.The value of b determines the number of patients in each section of the ED. Hence, two indexes suffice to represent the state of the system, (xn, bn). xn∈ {0, 1} represents the status of the surge section in stage n; 0 is for closed and 1 is for open. bnis the number of the patients in the system at the nth decision epoch. The possible values for bndepend on the status of the surge section. That isbn∈B0={0,1,…,m1+m2}when the surge is closed andbn∈B1={0,1,…,m1+m2+m3}when the surge is open.There are two types of possible actions/decisions at each stage. LetA={0,1}be the set of possible actions. Possible actions are given by the state to be chosen until the next decision. That is,xn+1=an,irrespective of the value of xn.an=0(an=1) means the surge section is closed (open) between stage n andn+1. We can not close the surge section when we have more thanm1+m2patients in the system because it will result in evacuating patients which is not allowed. Therefore, for states withbn>m1+m2the possible action is onlyan=1. In other word, there is no decision making in these cases and this action is mandatory.Letpijnandqijnbe the probabilities of having j patients in the system at stage n given that i beds were occupied at stagen−1when the action at stagen−1wasan=0andan=1,respectively. When the chosen action at stagen−1is 0, we havec1=m1+m2servers and the queueing model will be M(t)/M/c1/c1. With the initial condition of having i patients at stagen−1,pijncan be calculated using the modified RK4 (explained in Section 2) for time interval(tn−1,tn]. When the action at stagen−1is 1, we havec2=m1+m2+m3servers and the queueing model will be M(t)/M/c2/c2. In this case,qijncan be obtained by running modified RK4 for this queue.The objective is to minimize the cost of running a ED with a surge section. There are three different types of costs in this system; (1) Start-up cost for opening the surge section, (2) cost of running the surge per unit of time and (3) cost of a patient on a stretcher per unit of time. IfOxa(n)is the immediate opening cost of the surge section at stage n while the status of surge is x ∈ {0, 1} and action a ∈ A has been selected, then(15)Oxa(n)={Coifxn=0andan=1atn0otherwise,where Cois the constant start-up cost of the surge section. There is another cost between two decision epochs whenever the surge is open. If the selected action at tnindicates that the surge is open for the coming interval(tn,tn+1)then the running cost of surge, Ra, has to be considered depending on the action, a at stage n, and independent of tn(16)Ra(n)={CrΔtifan=1atn0otherwise,where Cris the cost per unit of time of running the surge section. The third term of the costs is an expected cost. Depending on the current state at stage tn, (x, b), and the chosen action a, there will be an expected cost of having patients on the stretchers for interval(tn,tn+1),called Sa(n, b).(17)Sa(n,b)={Cs∑j=1m2j∫tntn+1pb,m1+jn(t)dtifa=0Cs∑j=1m2j∫tntn+1qb,m1+m3+jn(t)dtifa=1.where Csis the cost of having a patient on stretcher for a unit of time andpb,kn(t)andqb,kn(t)are the probabilities of having k beds occupied at the time t after tnwith b beds occupied initially and the surge is closed and open, respectively.There is also an additional term for the cost when the system is full and we reject arrivals. When surge section is closed, then the probability of rejecting a patient is equal to the probability of havingm1+m2in the system. Let Crej be a cost of rejecting one patient. We define Fx(n, b) as the rejection cost by following(18)Fx(n,b)={Crej∫tntn+1λ(t)dtifx=0,b=m1+m20otherwise.Now we take the sum of all the costs defined above and have the costs at stage n for state of (x, b) and action a as follows(19)rn(x,b,a)=Oxa(n)+Ra(n)+Sa(n,b)+Fx(n,b).At the last stage,tnyN˜,the costs must be given. Suppose we want to close surge at the end of the planning horizon. Then, it can be assumed(20)rnyN˜(x,b)={0ifxnyN˜=0Motherwise,where M is a large number. Now we are able to use the backward induction for solving our MDP model. This algorithm provides an efficient method for solving the finite-horizon discrete-time MDPs (for more details see Puterman, 1994).Letun*(xn,bn)be the cumulative optimal cost function of the system from the decision epocht˜nwhen the state att˜nis (xn, bn), to the end of the planning horizon,t˜nyN˜. The algorithm is as follows1.Setn=nyN˜and(21)unyN˜*(xnyN˜,bnyN˜)=rnyN˜(xnyN˜,bnyN˜),forallxnyN˜,bnyN˜.Substituten−1for n and computeun*(xn,bn)for each xnand bnby(22)un*(xn,bn)=minan∈A{rn(xn,bn,an)+∑j∈Banγbnjan(n+1)un+1*(an,j)}whereγbnjan(n+1)={pbnjn+1ifan=0,qbnjn+1ifan=1.The optimal action is(23)πn*(xn,bn)=argminan∈A{rn(xn,bn,an)+∑j∈Banγbnjan(n+1)un+1*(an,j)}.The sequence of actions is called a policy.Ifn=1,stop. Otherwise return to step 2.The algorithm provides the optimal policy for running the ED. We use these policies to obtain control policies for the infinite planning horizon problem. If the decisions in different cycles are independent, then we can use a general (mt, Nt)-policy for all cycles. We will show the condition for independence of decisions in different cycles in the following section.In this section, we use numerical computations to discuss the periodic behavior of Ntand mt. We also show how fast the policies reach their equilibrium and that they have a phase delay in respect to the arrival rate function. We did a number of numerical solutions of the problem described here and if1μis small enough compared to T (1μT<0.1), then we found in all numerical examples that two cycles are sufficient to reach the equilibrium. The other parameters do not have a significant effect on the policies as long as the system is not saturated.In a non-time-dependent ergodic MDPs with infinite planning horizon, decisions converge to a steady state. That is, in the long run for a specific state there will be a specific optimal action all the time. However, for time-dependent MDPs, it is a different story since the time-dependent parameters can be changed for a same state in two different points of time. Puterman (1994) discussed the periodic MDPs and used the Cesaro limit for analyzing them. We use a different approach here. In this section, first we will show that our MDP is periodic. Using the periodicity of MDP and cyclic classes, we will then prove that there exists a mixing time (see Levin, Peres, & Wilmer, 2006) such that the probability of being in a state converges. Then we will prove that the decisions are independent of the final decisions after going backward a finite amount of time to show how far we must go in order to obtain the stationary policies at a specific location in the cycle of arrival rates. Finally, we will prove that the stationary policies at a fixed location of a cycle are periodic. Knowing that the policies will be eventually periodic, we can extend our results from a finite to an infinite planning horizon. A related discussion has been done by Martin-Löf (1967), where he showed that there exists a periodic control which provides an optimal expected future cost for a periodic continuous-time Markov chain, and it can be approximated by discretizing in time.The periodic Markov chain is a recurrent chain with the property that if the system occupies some state at the present time it will only occupy the same state afterp,2p,3p,…transitions, where p is a positive integer describing the periodicity of the system (Howard, 1960). Considering (x, b, τ) as the state of the system where τ is the location of decision epoch in the cycle of the arrival rate function, it is evident that our model is a periodic MDP. The policy for a specific state of a Markov chain is repetitive in the long run when it converges. Because periodic Markov chain states are revisited periodically, policies repeat with the same period as the Markov chain.For obtaining the contour points at each decision epoch, we use the outcomes of the MDP model. To find Nt, we look at the decisions at each stage n for each state (0, b), where b ∈ B0 and find the minimum value for b at which one opens the surge. This minimum value is equal to N(tn), where tnis the time at stage n. For mt, we investigate the decisions at each stage n for each state (1, b), where b ∈ B1. mtwill be the maximum value of b for closing the surge section at stage n. We putm(tn)=−1if we do not close the surge even if the system is empty at stage n.Fig. 1shows Ntand mtas an example of the case study at KGH. We putμ=0.25per day per bed,m1=12,m2=28,m3=20,α=5per day,β=10per day,Co=200,Cs=50per day per stretcher andCr=100per day. Decisions are made weekly, therefore there are 52 decision points in each cycle. We setT=364days to be equivalent to 52 weeks. The planning horizon is 3 cycles. Fig. 1 shows that except for decisions close to the end of the planning horizon, both Ntand mtexhibit a periodic behavior, with the same cycle length as the arrival rate function, but shifted by a certain amount. It can be observed that policies match the periodic pattern after a short time moving away from the terminal stage which shows that with this setting reaching to equilibrium happens very quickly.One might expect that the minima of Ntand mthappen at the maximum of λt, since the arrival rate is higher and intuitively the surge section needs to be open. That is, as λtgets larger, we potentially have more patients, the quality of service gets poorer and the cost function increases if the surge section is closed. Hence, it makes sense to reduce Ntand mtto increase the chance of having the surge open. However, the minimum of Ntand mthappens before the peak of λt. The model predicts that the maximum arrival rate will happen in the near future and increases the chance of opening the surge and keeping it open before reaching this peak. In this sense, it avoids imposing the extra cost because of the high chance of having lots of occupied stretchers. At the maximum point of the arrival rate function, the value of Ntincreases. The reason is at this point, the function changes from increasing to decreasing and the worst case has been past already. So if we have not opened the surge by now, we can decrease the chance of it by increasing Nt. However, if it is open, mtdoes not increase as early as Nt. It is worth noting that the maximum value of Ntand mtoccur where λtis still decreasing. The reason is that there exists a minimum of the arrival rate ahead and it is safe to decrease the chance of opening to reduce cost related to running the surge section. This causes a phase delay in Ntand mtcompared to what is expected of non-time-dependent contour points.

@&#CONCLUSIONS@&#
