@&#MAIN-TITLE@&#
Non-linear temporal scaling of surgical processes

@&#HIGHLIGHTS@&#
Simultaneous and global analysis of sets of surgeries.Global non-linear realignment of sets of sequences.Comparative analysis of surgeons’ expertise on sets of neurosurgeries.

@&#KEYPHRASES@&#
Temporal analysis,Dynamic time warping,Surgical process modelling,Surgical technical skills,Surgery,

@&#ABSTRACT@&#
ObjectiveSurgery is one of the riskiest and most important medical acts that is performed today. Understanding the ways in which surgeries are similar or different from each other is of major interest. Desires to improve patient outcomes and surgeon training, and to reduce the costs of surgery, all motivate a better understanding of surgical practices. To facilitate this, surgeons have started recording the activities that are performed during surgery. New methods have to be developed to be able to make the most of this extremely rich and complex data. The objective of this work is to enable the simultaneous comparison of a set of surgeries, in order to be able to extract high-level information about surgical practices.Materials and methodWe introduce non-linear temporal scaling (NLTS): a method that finds a multiple alignment of a set of surgeries. Experiments are carried out on a set of lumbar disc neurosurgeries. We assess our method both on a highly standardised phase of the surgery (closure) and on the whole surgery.ResultsExperiments show that NLTS makes it possible to consistently derive standards of surgical practice and to understand differences between groups of surgeries. We take the training of surgeons as the common theme for the evaluation of the results and highlight, for example, the main differences between the practices of junior and senior surgeons in the removal of a lumbar disc herniation.ConclusionsNLTS is an effective and efficient method to find a multiple alignment of a set of surgeries. NLTS realigns a set of sequences along their intrinsic timeline, which makes it possible to extract standards of surgical practices.

@&#INTRODUCTION@&#
More than half a million surgeries are performed every day worldwide [1], which makes surgery one of the most important component of global health care.Competing demands are motivating a better understanding of surgical processes: surgical procedures are getting more complex [2], residents now have to be trained while performing less procedures [3], the surgical interventions have to be more and more justified [4] and the procedures have to cost less money [5], et cætera. A better understanding of surgical practices is the key component to addressing these issues. surgical process modelling (SPM) is the general process that aims at understanding surgeries, in order to improve the quality of care and the training/assessment of surgeons.This article addresses the issue of analysing sets of surgeries. Let us consider an example related to the training of neuro-surgeons. Surgical training is critical to ensure a smooth expertise transition between senior and junior surgeons. This training is generally provided in a one-on-one scheme between a junior surgeon and his or her senior, which makes this process extremely expensive and time-consuming. Let us give a brief example showing how a better understanding of senior surgical practice (i.e., understanding sets of senior surgeries) can make it possible to improve and optimise the training of surgeons. Let us assume that the analysis of a set of senior surgeries tells us that all senior surgeons perform one step of the surgery in the exact same way. This information can be exploited by directing the training of junior surgeons towards a standard and stereotyped practice for this step. By contrast, if one part is very patient-specific, the analysis of a the same set will show that the behaviour of senior surgeons is less standard. The training can then be directed towards a patient-specific care.The idea that a set of observations may leverage more information than any individual observation is not new. The most famous example set dates back at least a century ago, when Francis Galton noted that the crowd at a county fair accurately guessed the weight of an ox when their individual guesses were averaged [6]. Galton realised that the average was closer to the ox's true weight than the estimates of most crowd members, and also much closer than any of the separate estimates made by cattle experts.Analysing a set of observations inℝhas long been studied and is now very well understood. However, analysing and simultaneously comparing a set of sequences is much more challenging, because of the particular properties that are induced by time (e.g., periodicity, symmetry, autocorrelation). Computational biologists have long known that the key to understanding a set of sequences is to find their multiple alignment. To illustrate this, Fig. 1presents the closure phase of 12 recordings of surgeries, as well as their multiple alignment (computed using the method proposed in this article). This example demonstrates how simultaneously aligning a set of surgeries (i.e., computing their multiple alignment) directly highlights critical elements of the closure phase. We can for example observe the closure of the surgical route layer by layer (muscle→fascia→skin), and also that almost all surgeons pause before the final stitches.Two important issues however prevent from using the methods developed in computational biology for the multiple alignment of surgical sequences:1.Surgeries are very particular sequences: surgeries are sequences of surgical activities over time, whereas DNA/RNA sequences encode biological structures (with no reference to time). This makes surgeries exhibit very different properties, such as autocorrelation: it is likely that a surgeon using a scalpel at time t will still be using it at time t+1, while observing the letter A in a DNA sequence does not increase the likelihood of observing it at the next position in the sequence. This is why time series dedicated measure, such as dynamic time warping (DTW) [7], have proved to be extremely relevant for the analysis of surgical processes [8,9]. Multiple alignment methods that have been developed in computational biology, are however dedicated to the Levenshtein distance [10]. New methods have thus to be developed to enable multiple alignment dedicated to DTW, in order to unlock the value of surgical datasets.Multiple sequence alignment is NP-complete [11], which prevents its computation for more than a few short sequences. As surgical datasets are rapidly growing, efficient and effective heuristics have to be developed to simultaneously analyse sets of recordings of surgeries.This work, capitalising on our recent discoveries for time series averaging [12,13], introduces non-linear temporal scaling (NLTS): a multiple alignment method for surgical processes. We show that NLTS effectively supports the extraction of high-level knowledge, by realigning the surgeries along their intrinsic timeline, i.e., along the standard sequencing of actions that occur over the course of the different surgeries. We consider surgeries as sequences of activities that are performed by the surgeon during the surgery. Mehta et al. [14] proposed to represent surgical activities as as triplet composed of an action, an anatomical structure and an instrument. For example, the surgeon can cut the skin using a scalpel. In this paper, we embrace this representation and use its formalisation introduced in [8]. In general, activities that are performed by both hands are recorded, as well as the use of the microscope. Fig. 2illustrates a set of 6 surgeries.Without loss of generality with regard to the issues that are addressed by surgical processes modelling, we use the training of surgeons as the main theme to support our explanations for the development of the article.This article addresses the issue of being able to compare a set of surgical processes; Section 2 describes this issue. Section 3 introduces our method NLTS. Section 4 details experiments carried out on neurosurgeries. Section 5 discusses these results and shows that our method makes it possible to support the extraction of high-level knowledge about the standards of neurosurgeries. We use the example of the training of neurosurgeons to illustrate that our approach captures interesting knowledge about the surgeries. Section 6 concludes this paper and presents some future work.History of surgical process modelling. Several initiatives have already been proposed to better understand surgical practice, mainly focusing on the assessment of surgeries. The first approach was to assess surgeries with regard to patient outcomes [15]. In addition to requiring a long-term follow-up with the patient, this method is very dependent upon the patient and the conditions of the surgery. It consequently cannot be used for an objective assessment of surgeries.Human grading techniques have been proposed to improve the objectivity of the assessment [16]. Junior surgeons are evaluated by their seniors with regard to a list of surgical skills. These tests are however subjective depending on the evaluator [17].Time-motion approaches have been introduced to improve objectivity and to automate the information acquisition on a surgery [18,14]. The idea was to use statistical information like the average duration of the surgery or the number of actions performed by the surgeon. These methods are very objective and easy to record. However, they do not provide enough information about the standard practices during the surgery. Assessing junior surgeons on such criteria can also be misleading. For example, senior surgeons are on average faster than junior surgeons [19]. It is obviously very undesirable for the junior to try to speed up their surgery without having reached the dexterity and experience of senior surgeons.Recording surgeries has recently gained interest, either using sensor devices, or directly by an observer in the operating room (OR). An universal and adaptable recording scheme has been introduced [20]. It shows how to decompose a surgical intervention into manual work steps. This data contains a lot of information, since it is much closer to the reality in the OR than, for instance, a record of only the number of actions performed during the surgery. An example of recorded surgeries is given in Fig. 2. It is usually assumed that this data is rich enough for the knowledge that scientists want to extract. Automating the analysis of such a dataset is however very challenging. Surgical process modelling (SPM) is the field that aims at unlocking this issue [21–23,20,24–26].Analysing a set of surgeries. In this article, we focus on the understanding of the similarities and differences that take place in a set of surgeries. We highlighted above that this is challenging because every surgery is different from another one. Yet senior surgeons successfully train junior surgeons every year. Surgery is indeed a very standardised practice that can be taught. The problem is that surgery is standardised at a high-level (phases, steps of each phase, ways of performing each step, et cætera). The challenge is to be able to support the recognition of these standard practices from the low-level description of the data, i.e., from the actions that are performed by the surgeon.From the data analysis perspective, the first step to unlock this issue is to be able to compare two surgeries in a consistent way. For a measure to be consistent, it has to provide a graduated evaluation of how similar two surgeries are. Similarity measures for surgeries were first studied in [27]. Dynamic time warping (DTW) is based on the Levenshtein distance and was introduced for speech recognition in the 1970s [7]. We recently demonstrated that DTW is sound for surgical processes comparison [8,9]. DTW operates non-linear distortions on the time-axis, in order to find the best alignment of the two sequences. DTW optimally realigns (or stretches) sequences with each other, which makes it possible to compare them along their intrinsic timeline. We use the term intrinsic timeline to describe the fact that each surgery has its own timeline that is independent of the ones of other surgeries. Fig. 3illustrates this process on the anatomical structures that are targeted during two surgeries.A lot of information can be retrieved very easily from the DTW-realigned sequences (variability, transitions, phases, et cætera). Improving the understanding of surgical processes would require a set of surgeries to be simultaneously realigned. DTW is unfortunately able to align a pair of sequences only. This is exactly the scientific issue that this article unlocks. Next section will introduce a method that makes it possible to re-align a set of sequences, in order to be able to provide high-level information about surgical processes.In this section, we present our method for the non-linear temporal scaling (NLTS) of surgeries. We start by giving some notations and presenting our method NLTS. Then, we detail how this set can be analysed to extract high-level information about the surgeries.LetS={S1,…,SN}be the original set of N sequences (surgeries). Let E be the space of states of sequences inSas:(1)E=⋃n=1N⋃ℓ=1length(Sn)Sn(ℓ)Optimally aligning a set of sequences under time warping has long been studied in computational biology. It is known as the multiple sequence alignment of the set, and is often considered the “Holy Grail” in computational biology [28]. Multiple sequence alignment is NP-complete [11], which prevents its computation for more than a few short sequences.In this section, we propose Non-linear temporal scaling (NLTS): a method to align (or scale) a set of sequences under time warping. Our method builds on compact multiple alignment[13], which was recently introduced to enable the averaging of large set of homogeneous time series. In addition, scalable methods exist for the definition of an average sequence under time warping [12].Non-linear temporal scaling (NLTS) starts with a set of sequences and performs as follows:1.Compute the average sequenceS¯of the set of sequencesS.Compute the compact multiple alignment ofSfromS¯.Unpack every column of the compact multiple alignment to its maximum width.Algorithm 1 details the computation of NLTS; Fig. 4illustrates the approach; we describe its steps in the following paragraph.Computation of the average sequence. The first step consists of computing the average sequenceS¯ofS(line 1). To this end, we use DTW barycenter averaging (DBA) [12,29], but other methods like COMASA [13] could be used depending on time requirements. The computation of the average sequence is detailed in Algorithm 2. Note that DBA is initialised with the medoid sequence (Algorithm 3).Computation of the compact multiple alignment. The compact multiple alignment is computed by aligning the average sequenceS¯to every one of the sequences ofSindependently. This alignment is performed by the function assocDTW. This function simply returns, for every element of the first sequence, the elements of the second sequence that have been linked to it by DTW. In our case, it consists of finding which elements of the sth sequence have been associated with the ℓth element ofS¯(line 5). These elements are then stored in elements[s][ℓ]. Moreover, we store in widths[ℓ] the maximum number of elements that have been associated with every ℓth element ofS¯, i.e., in every column of the corresponding compact multiple alignment (lines 6–8).Unpacking the compact multiple alignment. The last part of the algorithm unpacks the compact multiple alignment. The compact multiple alignment provides a set of sequences that is consistently aligned. However, the first column can, for example, hold four elements of the first sequence (e.g. <aaab>), one element of the second sequence (e.g. <a>), and two elements of the third sequence (e.g. <ab>). As a result, for every column ℓ of the alignment, we scale every subsequence elements[s][ℓ] to the maximum number of elements contained in this column, i.e., widths[ℓ] (line 15). In the latter example, it would correspond to stretch the single element of the second sequence to four elements (<a> → <aaaa>) and the two elements of the third sequence to four elements as well (<ab> → <aabb>). A web application is available here11http://germain-forestier.info/src/aim2014/ (Accessed: 10 October 2014).which allows the reader to try NTLS easily. Let us note that the unpacking step uses the maximum width as reference as it guarantees that the scaling does not lead to any loss of information, because other functions would lead to a “contraction” of one of the aligned sub-sequences. Other functions such as the mean or the median would indeed lead to two different elements to have to be merged, which would lose information about the original sequences.Result. The algorithm outputs a set of sequencesS★, which correspond to a multiple sequence alignment ofS.S★aims at supporting a detailed temporal analysis of the set of sequences with regard to their sequencing. Note that the information about the specific time at which the elements of the sequences is not available from the visual representation any more. All sequences ofS★have the same length.NLTS makes it possible to realign a set of sequences, by finding a multiple sequence alignment of the set. In this section, we propose different methods that can be used to analyse this aligned set of sequences.Probability distribution of the states over time. LetS★be the set of sequences scaled with NLTS. We want to study the distribution of the different states in every position (or column) of the multiple alignment. To this end, we define the (discrete) probability distribution of the states over the sequencing induced by the multiple alignment.Definition 1Spˆ★=〈pˆ1,…,pˆL〉is the sequence of probability with maximum likelihood estimatespˆℓover E defined by:pˆℓ:E→[0,1]⊂ℝe↦|{{S★(ℓ)=e|∀S★∈S★}}|NAlgorithm 1Non-linear temporal scalingRequire:S={S1,…,SN}LetS★={S1★,…,SN★}be the resulting set of scaled sequencesLet mean(.) return the average sequence of a set for DTWLet assocDTW(S, T) return the elements associated mapping built by DTW from S to TLet scale(S, n) return the uniform scaling [30] of the sub-sequence S to n elements1:S¯←mean(S)2:L←length(S¯)3:widths[L]←[0, …, 0]4:fors←1toNdo5:elements[s]=assocDTW(S¯,Ss)6:for ℓ←1 to Ldo7:widths[ℓ]←max(widths[ℓ], size(elements[s][ℓ]))8:end for9:end for10:fors←1toNdo11:Ss★←〈〉12:for ℓ←1toLdo13:targetLength←widths[ℓ]14:forn←1totargetLengthdo15:Ss★←Ss★.scale(elements[s][ℓ],targetLength)16:end for17:end for18:end for19:returnS★For example, to create the set of states for the position ℓ=1, we create a set the first states of all sequences inS★. If we are considering the targeted anatomical structures of three surgeries, the first states distribution could be {skin, skin, skin} meaning that the first state “skin” is identical for all three surgeries. This sequence of probabilitySpˆ★thus informs about the distribution of the states over time. The more similar these states are at position ℓ, the more standardised the action ℓ is. For example, the set of states {skin, skin, skin} is very standardised (all the surgeon are targeting the skin at ℓ) but the set of states {skin, fascia, muscle} is heterogeneous (all the surgeons are targeting a different structure at ℓ).Entropy of the states. Entropy is a measure of uncertainty of a random variable. In our case, the entropy of every state ofSpˆ★gives information about how diverse the behaviour of surgeons is at state ℓ of the surgery. The entropy is null when all the surgeons perform the same action in the set. The entropy is maximal when every surgeon performs a different action. This can be used as a measure of the predictability of the action for models of surgeries. This entropy –H(pˆℓ)– is defined as:(2)H(pˆℓ)=−∑eEpˆℓ(e)·logbpˆℓeH(pˆℓ)makes it possible to locate the states or phases of the surgeries, for which the behaviour of surgeons is standard or heterogeneous.Algorithm 2meanRequireS={S1,…,SN}Let DBA be the averaging sequence method introduced in [12]LetI be the number of iterationsLetmean be the returned average sequence ofSmean←medoid(S)fori←1toIdomean←DBA(mean,S)end forreturnmeanAlgorithm 3medoidRequireS={S1,…,SN}Letmedoid be the returned medoid ofSLetinertia←∞forSinSdosqrDist←0forTinSdosqrDist←sqrDist+DTW(S, T)2end forifsqrDist<inertiatheninertia←sqrDistmedoid←Send ifend forreturnmedoidEntropy based encoding ofS★. Entropy has a direct connection with compression. This is because encoding an element e with probability p(e) requires −log2(p(e)) bits. The length of the compressed string encodingS★on a state-by-state basis is given by:(3)LS★=∑ℓ=1L∑n=1N−log2pˆℓSn★ℓ(4)=∑ℓ=1LN·−∑eEpˆℓ(e)·logbpˆℓe(5)=N·∑ℓ=1LH(pˆℓ)This lengthLS★gives information about the general uncertainty onS★. It evaluates the predictability of the behaviours of surgeons over the whole surgeries.

@&#CONCLUSIONS@&#
