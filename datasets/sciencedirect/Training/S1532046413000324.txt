@&#MAIN-TITLE@&#
A method for estimating from thermometer sales the incidence of diseases that are symptomatically similar to influenza

@&#HIGHLIGHTS@&#
We created models to estimate incidence of symptomatically-like-influenza diseases.We only use as input to the models thermometer sales data.When estimating ED SLI cases at the county level, the mean error was less than 20%.

@&#KEYPHRASES@&#
Thermometers,Symptomatically-like influenza,Estimation,H1N1,

@&#ABSTRACT@&#
Early detection and accurate characterization of disease outbreaks are important tasks of public health. Infectious diseases that present symptomatically like influenza (SLI), including influenza itself, constitute an important class of diseases that are monitored by public-health epidemiologists. Monitoring emergency department (ED) visits for presentations of SLI could provide an early indication of the presence, extent, and dynamics of such disease in the population.We investigated the use of daily over-the-counter thermometer-sales data to estimate daily ED SLI counts in Allegheny County (AC), Pennsylvania. We found that a simple linear model fits the data well in predicting daily ED SLI counts from daily counts of thermometer sales in AC. These results raise the possibility that this model could be applied, perhaps with adaptation, in other regions of the country, where commonly thermometer sales data are available, but daily ED SLI counts are not.

@&#INTRODUCTION@&#
The 2009 H1N1 influenza outbreak highlighted the need for methods that not only detect an outbreak but also estimate incidence so that public-health decision makers can allocate appropriate resources in response to such an outbreak. Several studies [1–3] have attempted to estimate incidence during the 2009 H1N1 outbreak, but they were performed months after the outbreak and were based on data that are either not easy to collect (e.g., confirmed laboratory cases) or not available in a timely fashion (e.g., surveys). Some influenza surveillance systems were also in operation during the H1N1 outbreak, but they did not provide daily estimates of influenza activity [4,5].Previous research indicates that data on over-the-counter (OTC1All the abbreviations used in this paper are listed in a glossary located after the References section.1) sales of retail healthcare products, such as cough and cold medications, can support the early detection of disease outbreaks [6,7]. In this paper, we provide support that thermometer sales (TS) increase significantly and early during an influenza outbreak.We explore the hypothesis that TS data can be used to estimate accurately the number of patient cases that present to EDs and are symptomatically like influenza (SLI). We developed and evaluated a model to estimate the number of SLI cases in EDs in Allegheny County (AC), Pennsylvania based on TS. To train this model, we used ED visit data from hospitals in AC and TS data from AC. We then generalized the model to predict daily ED SLI cases from the daily TS in any region in which we are able to collect TS data. Unlike counts of ED SLI cases, which are not readily available for most counties in the US, there exists TS data for a significant number of locations throughout the US, with at most a one day delay. Given this availability, the method and model we present is intended to help public health epidemiologists throughout the US to estimate the extent of an influenza outbreak as it presents to EDs with little delay; the evaluation of this method beyond AC is proposed as a next step in the future pursuit of this line of research.The remainder of this paper is organized as follows. In the next section, we provide an overview of previous research that aimed to detect and characterize influenza outbreaks using OTC sales. We summarize a project that facilitates obtaining daily OTC sales data across the US with little delay. We then discuss a method we developed to estimate SLI cases in AC. We describe the experimental methodologies we used to evaluate the performance of the models in AC, and we present and discuss the results of those experiments. We present methods to adjust TS data so that these models can produce estimates for other regions, not just AC. Finally, we present conclusions and close the paper with a summary.This section provides background information about the use of OTC healthcare-product sales to detect disease outbreaks. We then provide an overview of the 2009 H1N1 influenza epidemic in the US and of several published studies that estimate its level of activity. The section then describes a system we have developed to estimate from ED reports the expected number of daily SLI cases that visit EDs in a region. We close the section by describing two influenza surveillance systems that can use the predictions produced by the models we present in this paper.Several studies have measured the value of using OTC-related data for the detection of outbreaks. These are either survey-based studies that are designed to reveal healthcare seeking behavior or retrospective studies to understand the correlation between OTC data and outbreaks.Survey-based studies have shown that a high percentage of individuals prefer to self treat using OTC healthcare products when they feel ill before, and sometimes instead of, seeking medical attention [8,9,7]. Metzger et al. [7] found that among the individuals they surveyed, purchasing an OTC healthcare product was the most common first action (37% of the time) to treat their illnesses.Retrospective studies show high correlation between known outbreaks and the sales of OTC healthcare products. Campbell et al. [10] found that for some OTC categories the correlation is high enough that they could detect seasonal outbreaks of respiratory diseases based on OTC sales earlier than methods that use physician office visits (up to 7days earlier). Magruder [11] obtained similar results in a study of the National Capital area (Washington DC and its suburbs), and found that, on average, sales of influenza remedies preceded office visits by 2.8days and that there was an average correlation of 0.90 between them. Das et al. [12] found that the ratio of sales of cough and influenza medicines to sales of analgesics was highly correlated with the ratio ED SLI visits to other syndrome ED visits, with a correlation coefficient (r2) of 0.6. In this previous research, the OTC data used were collected only from the individual locations (mostly cities) that were studied. In the next section we describe a service that collects OTC data from across the US.The National Retail Data Monitor (NRDM) project has greatly reduced the effort to obtain OTC sales data for use in biosurveillance. NRDM collects daily sales data for products in 18 OTC categories across the country [13,6]. Public health departments can access such information through a web-based interface or via web service protocols. NRDM was developed in our lab, the Real-time Outbreak and Disease Surveillance Laboratory (RODS), with the cooperation of selected retail chains that sell OTC medications. Using data from NRDM, our laboratory studied the effects of a single outbreak and other health events relative to the sales of OTC products. One of these internal studies, for instance, found that TS increased significantly and early during the 2003–2004 influenza outbreak [6]. The models we present in the current paper use TS from NRDM to estimate SLI cases that present to EDs and in the population.Although the NRDM is a powerful information resource, it has several limitations. First, in most areas of the US, there are retail stores selling OTC healthcare products that do not report data to the NRDM. Second, for many areas where OTC sales data are collected, the OTC market share of some of the retail store chains that provide data to NRDM is not known with certainty. Third, the daily sales number reported for a product category is the sum of units that are sold and the units that are returned. Thus, a negative number of reported units on a particular date means that there were more units of a product category returned (which were bought at earlier, unknown dates) than units sold (which can be zero) on that date. Likewise, a positive number of units reported simply means that there were more units sold than units returned (which can be zero) on that day. Also, a zero number of units reported means that there was the same number of units sold and returned on that date, whereas when nothing is reported from a store for a given product type (i.e., no sales record is created), it means that no units of that type were sold or returned.We have addressed these limitations in multiple ways. In areas where there is incomplete coverage and market share information is available, we make adjustments to the sales data. When market share information is lacking, we estimate it. Finally, if we aggregate sales data over a large enough region (such as a county), the effects of returned units are not as significant. These methods are described in Appendix A.In April of 2009, pandemic H1N1/09 influenza infected thousands in Mexico and the US. Although influenza activity during the summer of 2009 in the US was low, starting in late August of that year a second wave of influenza caused by H1N1 occurred across the country [14,15]. It peaked during the second half of October, and finally it largely subsided in December [14,15,3,16]. Although it is difficult to determine exact dates, the literature indicates a period from August 23rd, 2009 (the start of the “last two weeks of August” [14]) through December 12th, 2009 (“declined to less than 10% during the week ending December 12” [15]). In AC, the epidemic had its highest activity level in late October [3].Due to difficulties in obtaining an accurate count of total H1N1 cases [2], several researchers developed methods to estimate those counts and other characteristics of the outbreak. Early attempts to estimate the incidence and severity of pandemic H1N1 in the US include studies by Reed et al. [1] and Presanis et al. [2]. The former used a multiplicative model coupled with a Monte Carlo simulation to predict that between 1.8 and 5.7 million H1N1 cases had occurred in the US from April to July 2009. The latter used a Bayesian evidence-synthesis framework to estimate that during the same period as Reed et al. between 0.16% and 1.44% of symptomatic H1N1 patients were hospitalized and that between 0.0007% and 0.048% died. Later in 2009, the Centers for Disease Control and Prevention (CDC) used the method described in Reed et al. to estimate that between April and December 12, 2009 around 55 million people (approximately 18% of the US 2009 population) had been infected with H1N1 in the US [16].Ross et al. conjectured that asymptomatic and mild cases were missed by the CDC estimates [3]. To partially overcome that limitation, they performed a study to determine the seroprevalence of antibodies to the pandemic 2009 H1N1 influenza strain in residents of AC. They found that seroprevalence against pandemic H1N1 across age groups was approximately 21%. They then extrapolated the results from their sample to both the local county population and the general US population. They estimated that about 63 million people in the entire US became infected through early December 2009.Table 1shows a summary of the methods described in this section.Tsui et al. have developed the Bayesian Case Detection (BCD) system that provides a differential diagnosis of a patient case that is obtained from an electronic medical record. Its current implementation can diagnose SLI diseases and shigellosis [17]. The version of BCD we used takes as input free-text ED reports. The free-text ED reports are collected from several EDs in AC. BCD has a natural language processing component that extracts patient symptoms and signs from a free-text ED report and codes the clinical findings with Concept Unique Identifiers (e.g., “the patient reports a severe cough today” would yield Cough=present) from the Unified Medical Language System (UMLS). These coded findings are input to a Bayesian network model of disease, which outputs a posterior probability over the modeled diseases that the patient might have.Tsui et al. performed a preliminary evaluation of the BCD system to detect SLI cases using free-text reports from seven EDs in AC [17]. Laboratory-confirmed positive and negative cases of influenza were used as gold standards. The researchers obtained an area under the ROC curve of 0.80 (95% CI: 0.76–0.85). We used the BCD system to estimate the number of daily SLI cases that presented to eight monitored EDs in AC. These estimates are computed by summing the posterior SLI probabilities of the patients who visited those EDs on a given date.A limitation of the BCD system is that it only monitored approximately 39% of all EDs in AC during 2009, due to the limited number of hospitals providing ED reports to it. We refer to that percentage as BCD’s ED coverage. Since we know this ED coverage, we are able to estimate the total number of ED cases in all of the AC EDs. We explain this adjustment in Section 3.This section describes two surveillance systems that utilize methods different than the one we introduce. It also discusses how the method we introduce can complement those systems.The CDC’s outpatient influenza-like-illness (ILI) surveillance network (ILINet) collects information on patient visits to more than 3000 healthcare providers for influenza-like illness in all 50 states, the District of Columbia and the US Virgin Islands. ILINet defines ILI as “fever (temperature of 100°F [37.8°C] or greater) and a cough and/or a sore throat in the absence of a KNOWN cause other than influenza” [5]. Thus, in this particular context, ILI is a type of SLI that considers only those three specific symptoms. ILINet reports on a weekly basis ILI activity for the entire US, as well as individually for each of the ten major US surveillance regions that the CDC has defined, usually with a 1–2-week reporting lag [4]. The CDC also uses data reports collected through ILINet to create a measure of ILI activity by state. The limitations of ILINet are that (1) the information it provides has a 1–2week reporting lag, and (2) the finest geographical granularity for its estimates is the state level, although the CDC only broadly shares the larger, region-level numerical data.The models presented in this paper complement ILINet. ILINet reports ILI activity at many types of outpatient clinics [5] at a regional level with a 1–2week lag. The methods we presented here provide ED-derived estimates at the county level with just a one-day lag.Google, Inc. developed “Flu Trends” [4] to predict ILI activity across the US based on Internet searches made using the Google search engine. To build Flu Trends, Google researchers performed a variable selection experiment to isolate the top search terms, which they call the “ILI-related search queries.” Using the fraction represented by those queries as the explanatory variable, they created a linear model to predict the weekly ILI percentages across the nine major US regions reported by the CDC [5]. They found that the predictions made by the resulting model were highly correlated to the CDC weekly estimates of ILI [1] over the US at the regional level. They also found that they could consistently predict ILI percentages one to two weeks prior to the publication of the CDC weekly reports.Despite its usefulness, the Google Flu Trends model has limitations. First, the high correlations observed are only validated for large populations (they were computed between estimates and data at the CDC’s surveillance region level, and at the state level for Utah). Second, like the ILINet estimates, Flu Trends estimates are for weekly activity. Although in principle Flu Trends estimates could be produced daily (i.e., using queries made during the last day), to our knowledge the accuracy of predictions for this shorter time period are not available and have not been reported.The models in this research also complement Flu Trends. Whereas the latter makes weekly predictions at the regional and state levels based on Internet searches, the current research can provide daily estimates at the county level.In this section we present a novel method for estimating SLI cases from OTC TS in EDs. Due to data availability, we created this model for estimating ED SLI cases in AC, but the methodology is flexible and can be extended to make estimates for other regions (Section 6).To create a model for AC, we first gathered training data as follows. We obtained non-negative daily sales of pediatric and adult thermometers from May 1 through December 31, 2009 (n=245days) in AC from the NRDM. We will refer to the data from this period as the 2009 dataset. We compared these TS data with the expected number of daily SLI cases that presented to EDs monitored in AC during the same period according to BCD. Fig. 1shows a plot of TS during that eight-month period (solid line) and the number of ED SLI cases estimated by BCD during the same period (dash-dotted line). We found that the strongest cross-correlation of the two curves is 0.9 when the expected cases lag behind the TS data by one day; a zero-day lag had almost the same cross-correlation (0.89). Fig. 2shows a plot of the estimated cases as a function of TS, which supports a linear relationship between those two quantities (black line).The rationale for the selection of the 2009 dataset is twofold. First, the BCD system officially started operating in AC in May 2009, and hence, we only had data starting at that time. Second, we wanted to devise a model that could estimate from thermometer sales not only SLI activity during outbreaks (high activity periods) but also during non-outbreak periods (low activity periods). The 2009 dataset contains sub-periods of both high (during the 2009 H1N1 outbreak) and low SLI activity and thus was the suitable for creating the aforementioned model. A model that is capable of estimating SLI activity only during outbreaks is more limited in its usefulness.Eq. (1) describes a linear model of SLI as a function of TS for AC, where S and I denote the slope and intercept parameters of the model, respectively, ED_SLI_BCD represents SLI cases in the EDs in AC that have BCD deployed, and TS_NRDM denotes thermometer sales reported by NRDM for AC.(1)ED_SLI_BCD(AC,date)=I+S·TS_NRDM(AC,date)Eq. (1) only predicts the number of SLI cases that present to EDs in AC that have BCD installed. To predict the total number of ED cases of those diseases in AC, we need to adjust that equation to incorporate the ED coverage of BCD in AC. Let ED_SLI_T(AC, date) be the total number of ED SLI cases (the T stands for total) during date in AC. We can estimate ED_SLI_T using Eq. (2), where EDcov is the ED coverage of BCD, which is discussed in more detail later in this section.(2)ED_SLI_T(Ac,date)=ED_SLI_BCD(AC)/EDcov(AC)We combine Eqs. (1) and (2) to obtain Eq. (3) that approximates the total number of daily SLI cases that present to all EDs in AC.(3)ED_SLI_T(AC,date)=I+S·TS_NRDM(AC,date)EDcov(AC)=1EDcov(AC)+SEDcov(AC)·TS_NRDM(AC,date)At the time this research was performed, the ED coverage of BCD in AC was around 39%. We calculated it by dividing the number of visits to EDs in AC where BCD is deployed by the total number of visits to EDs in AC from May 1st, 2009 through December 31st, 2009. We obtained the latter count from a system that our laboratory has deployed in all EDs in AC, except for one ED in a federal hospital.For the sake of example, suppose that in the model given by Eq. (3) the slope (S) is 0.5 and the intercept (I) is 20. If on a given day d, the net number of thermometers sold in AC is 10, then the model would predict that the total ED SLI cases in AC on that day is approximately 64=20/0.39+(0.5/0.39)·10, where 0.39 is the estimated ED coverage of BCD in AC.This section describes experiments that evaluate how well Eq. (1) performs when using AC data for training a model with data from one period of time of mdays and testing with data from a subsequent period of n days. To do so, we create training and testing sets, perform least squares linear regression on the training set to obtain slope (S) and intercept (I) parameters, and then use Eq. (1) with those parameters to predict ED cases for each day in the test set. The next training period begin n days after the start of the former training period.For example, for a training set of m=42days (6weeks) and a test set of n=14days (2weeks) we proceed as follows. We train a model with TS and BCD data from for example 5/6/2009 (a Sunday) through 6/16/2009; we then apply that model to predict BCD-estimated SLI cases from 6/17/2009 through 6/30/2009. The TS data and BCD estimates from 5/20/2009 (i.e., n=14days after 5/6/2009) through 7/02/2009 (i.e., 42days after 5/20/2009) become the next training set.To evaluate the performance of the models after the 2009 H1N1 outbreak had largely dissipated, we included the first three months of 2010. For the sake of uniformity, we start on 5/6/2009, which is a Sunday, instead of on 5/1/2009, and include data up to 4/3/2010, which is a Saturday. We will refer to this dataset of 333days as the experimental dataset. A plot of that set is shown in Fig. B1 in Appendix A.Based on the above arrangement, we performed three experiments with different training and testing set sizes. In all these experiments the smallest training set consists of three weeks of data, and larger training sets increase in periods of three weeks, with the largest set consisting of to 15weeks. That is, m=21, 42, 63, 84, and 105days. We stopped at 105days because that is approximately the number of days in the primary wave of the 2009 H1N1 outbreak in AC. The experiments differ in the number of days used for the testing set:•Experiment 1 (E1): Each testing set consists of 7days (1week) of data. The total number of training sets in this experiment is 190.Experiment 2 (E2): All the testing sets consist of 14days (2weeks) of data. The total number of training sets is 94.Experiment 3 (E3): Each testing set consists of the same number of days as its corresponding training set. That is, n=m. The total number of training sets is 28.The rationale of picking the sizes of the testing sets in the first and second experiment is to see how well the model can estimate disease activity during periods of time close to the date when the estimate is produced, which may be of greater public-health interest. The reason for selecting the size of the testing set on the third experiment was to see how well the models performed on a testing set the same size as its training set.We evaluated the goodness of the regression performed to create each of the linear models described above with the coefficient of determination, denoted as R2. It measures the fraction of the variability of the modeled response variable (e.g., expected number of daily ED SLI cases computed by BCD) that is explained by a regression [18]. Relationships with a strong positive (or negative) slope that are close to being linear would be expected to have an R2 value near 1. Associations with a slope near zero would be expected to have an R2 value near zero. We calculate R2 with Eq. (4)[18], where•m is the number of days in the training set used to generate a model (i.e., m can be 21, 42, 63, 84, and 105).PredictedValueirepresents a given model’s prediction of daily ED SLI cases from thermometer sales on day i of the training set,the variable ActualValueiis the number of SLI cases estimated by BCD on that same day, andthe bar (¯) denotes the arithmetic mean of the quantity below it (during the given period of m days).We evaluated the predictive performance of each of those models using a measure known as the mean absolute percentage error (MAPE) [19,20], which is computed using Eq. (5). A MAPE value of X means that, on average, a model’s predictions are X% greater or smaller than the actual quantity. Thus, the closer the MAPE values are to zero (with zero indicating that the predictions and actual values are the same), the better is the forecasting performance of an estimation method. As in the case of R2, the value of n in Eq. (5) for this experiment is the number of days in the testing set for which we generate a prediction (i.e., n can be 7, 14, 21, 42, 63, 84, and 105), the variable ActualValueiin Eq. (5) is the number of SLI cases estimated by BCD on day i in that set, the variable PredictedValueirepresents a given model’s prediction of daily ED SLI cases from thermometer sales on that same day, and the parallel bars (||) denote the absolute value of the quantity they enclose.(5)MAPE=1n∑i=1n|ActualValuei-PredictedValuei|ActualValuei·100To assess the forecasting performance of a method, Lewis [21] suggested four ranges of MAPE values, namely, [0%, 10%], (10%, 20%], (20%, 50%], and (50%, ∞). He labeled these ranges as having highly accurate, good, reasonable, and inaccurate forecasting performance, respectively. We use these as regions of reference to facilitate our analysis.In the next section we summarize the performance for each experiment using the average MAPE, the minimum and maximum MAPE values, and the minimum and maximum R2 values.

@&#CONCLUSIONS@&#
Based on the results of the experiments presented here, we conclude that it is possible that linear models trained to estimate SLI ED cases based on thermometer sales can have good forecasting performance. We showed this in the case for Allegheny County (AC), Pennsylvania. In our experiments we found that under most testing conditions the methods achieved good forecasting performance, with only occasional, transient declines. Given these results and the timeliness with which the TS data can be obtained from NRDM, we think the methods presented in this paper can be helpful for epidemiologists and public health officials.The results presented here raise the possibility that similar models could be applied in other regions of the country, where thermometer sales data are commonly available, but daily ED SLI counts are not. In this paper, we describe how to transform the AC model to produce such estimates. At the time that this study was performed, we did not have access to estimates of daily ED SLI cases in other counties in the US. Thus, we could not test how accurately the AC-derived model predicts ED SLI counts in other counties in the US, many of which do have TS data that are available through the NRDM. Even more broadly, it will be important to test how well the approach described here will work in countries other than the US. In addition, in the future, it will be useful to evaluate how well models developed using data from one outbreak are able to perform in making predictions in subsequent outbreaks. We view these tasks as important directions for future research.We hypothesize that other signals of SLI activity, such as laboratory confirmed SLI cases, may exhibit a similar linear relationship with TS, as well as with the sales of other relevant OTC medications. Investigating such relationships is another promising direction for future research.