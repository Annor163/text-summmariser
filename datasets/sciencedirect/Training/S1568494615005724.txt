@&#MAIN-TITLE@&#
Multiobjective evolutionary algorithm based on multimethod with dynamic resources allocation

@&#HIGHLIGHTS@&#
The proposed MMTD employs both Pareto dominance-based concept and decomposition strategy in the process of population evolution.The proposed algorithm employs these multimethod simultaneously based on dynamic resources allocation procedure.The proposed MMTD is flexible and many algorithms or multiple operators in their constituent algorithms can be integrated in their evolutionary process. The impact analysis of different operators in constituent algorithms of the MMTD framework is part of work in this paper.Experimental results demonstrate that MMTD has significantly performed better than state-of-the-art MOEAs such as MOEA/D, NSGA-II, AMALGAM, MOPSO: a proposal for multiple objective particle swarm optimization, MOSaDE, DECMOSA-SQP in terms of reducing the inverted generational distance (IGD) metric and time cost on both ZDT test problems [68] and CEC’09 test instances.

@&#KEYPHRASES@&#
Multiobjective optimization,Pareto optimality,MOEA/D,NSGA-II,Multimethod (MMTD),

@&#ABSTRACT@&#
In the last two decades, multiobjective optimization has become main stream and various multiobjective evolutionary algorithms (MOEAs) have been suggested in the field of evolutionary computing (EC) for solving hard combinatorial and continuous multiobjective optimization problems. Most MOEAs employ single evolutionary operators such as crossover, mutation and selection for population evolution. In this paper, we suggest a multiobjective evolutionary algorithm based on multimethods (MMTD) with dynamic resource allocation for coping with continuous multi-objective optimization problems (MOPs). The suggested algorithm employs two well known population based stochastic algorithms namely MOEA/D and NSGA-II as constituent algorithms for population evolution with a dynamic resource allocation scheme. We have examined the performance of the proposed MMTD on two different MOPs test suites: the widely used ZDT problems and the recently formulated test instances for the special session on MOEAs competition of the 2009 IEEE congress on evolutionary computation (CEC’09). Experimental results obtained by the suggested MMTD are more promising than those of some state-of-the-art MOEAs in terms of the inverted generational distance (IGD)-metric on most test problems.

@&#INTRODUCTION@&#
Many real-world search and optimization problems are naturally posed as multi-objective optimization problems (MOPs). All these types of problems usually contain conflicting objective functions in their formulation and need to be optimized simultaneously. The stationary gas turbine combustion process optimization [1], optimization of material distribution of functionally graded materials (FGMs) [2–4], optimization of vehicle crashworthiness design problems [5] and improvement of energy consumption in wireless sensor networks are some practical examples of optimization problems. For more details the interested readers may refer to [6,7,5,8–11]. Without any loss of generality, we consider the optimisation problem:(1)minimizeF(x)=(f1(x),…,fm(x))Tsubject tox∈Ωwhere Ω is the decision variable space, x=(x1, x2, …, xn)Tis a decision variable vector and xi, i=1, …, n are their decision variables, F(x):Ω→Rminvolves m≥2 real valued conflicting objective functions and Rmis the objective space.If Ω is closed and connected region in Rnand all the objective functions are continuous in x then problem (1) will be a continuous MOP. Furthermore, If m=1, then a problem (1) will become a single objective problem (SOP). If m≤3, then problem (1) will called MOPs. However, if m≥3, then problem (1) is normally known many objectives function problem.A solution u=(u1, u2, …, un)∈Ω is said to be Pareto optimal if there exist no another solutionv=(v1,v2,…,vn)∈Ωsuch thatfj(u)≤fj(v)for all j=1, …, m and alsofj(u)<fj(v)for at least index k. An objective vector is said to be Pareto optimal if their corresponding decision vector is Pareto optimal. All Pareto optimal solutions in the decision space of MOP is called Pareto set (PS) and their corresponding image in their objective space is called Pareto front (PF). The idea Pareto optimality was first proposed by Francis Ysidro Edgeworth in 1881 and then later on generalized by Vilfredo Pareto in 1986 as discussed in [12,13].Multiobjective evolution optimization has become main stream in last two decades. Since the development of first multiobjective evolutionary algorithm (MOEA) known as “vector evaluated genetic algorithm (VEGA) [14]” by David Schaffer in 1985, different kinds MOEAs have been designed in the field evolutionary computing and successfully applied to different complicated problems [15–17]. MOEAS are mainly inspired by the biological process of evolution and operate on set of solutions. They are nature inspired stochastic method and need no derivative information. Dur to population based nature, they can find a diversified set of solutions for the given MOPs in single simulation run unlike traditional techniques [18,9,19,11,20]. In general, classical MOEAs can be divided into three main different classes, namely, the Pareto dominance based MOEAs (e.g., [21–29]), the decomposition based MOEAs (e.g., [30–40,19,41,42]), and Indicator Based algorithms (e.g., [43–49]).Among above mentioned three classes, Pareto dominance based MOEAs are very commonly used in the existing specialized literature of EC. These algorithms utilize Pareto dominance concepts and different diversity maintenance techniques to evaluate their population in the whole process of optimization. In this category, a fast elitist multiobjective non-dominated sorting genetic algorithm: NSGA-II [22] and SPEA2: Improve strength Pareto evolutionary algorithm [24] are two leading stochastic approaches. NSGA-II [22] evaluates their population using Pareto ranking procedure together with crowding distance technique. SPEA 2 [24] is also exercises Pareto dominance concept along with clustering methods in the selection process of their offspring population. Both these algorithms are using the crowding distance technique and clustering strategies for the purposes to prevent premature convergence and improve diversity in their current population to ensure convergence and uniformly distributive set of solutions. Furthermore, the fitness assignment mechanisms exploited in both NSAG-II [22] and SPEA2 [24] promote an adequate selection pressure to drive their population toward the true Pareto front with good convergence manner. However, employing the same strategies without modification in NSAG-II [22] framework are not suitable for many objective optimization problems. Recently, various modification have been proposed in original version of NSGA-II framework of [22] and several enhanced versions have been proposed in the existing literature [50–56] for solving many objective optimization problems.Recently indicator based EAs (IBEAs) are another promising frameworks. They directly involve performance indicator such as hypervolume in the selection process of their offspring solution. IBEAs with the hypervolume measure have strong theoretical support and high search ability. In [44], Hypervolume also called S metric selection evolutionary multiobjective optimization algorithms (SMS-EMOA) is recently developed. It exactly uses the hypervolume function to measure their solutions consuming high time complexity as resultant this approach is unsuitable and undesirable for problems with high dimensionality. However, high time complexity issues have been properly resolved in general indicator-based evolutionary algorithm (IBEA) [43,46]. General IBEA approximates the hypervolume contributions by aggregating the hypervolume differences of pairwise solutions in minimum time. A scalarizing function-based hypervolume approximation method has been suggested in general IBEA [43]. In [57], the idea scalarizing function-based hypervolume approximation method has been introduced and solved many objective optimization problems with great success.MOEA/D11The source codes of MOEA/D can be found in Qingfu Zhang's homepage, Jmetal, MOEA Framework, Dr. Shih-Hsin Chen's Web and MOS web.: multiobjective evolutionary based on decomposition [32] is another newly efficient developed paradigm that decomposes a MOP under attack into a number of different single objective optimization subproblems and then optimize all these subproblems simultaneously using generic EA. To date, MOEA/D [32] have many enhanced version (i.e., For example: [35,36,40,11,19,41,42,58]). One of the key features of this paradigm is neighbourhood structure that defined based on Euclidean distance between weight vectors of decomposition functions. In [35], two different neighbourhood schemes in combination with restricted replacement strategy have been introduced for solving complicated problems. In MOEA/D, different subproblems require different amounts of computational resources. In [36], dynamical resource allocation strategy for different subproblems has been introduced. In [59], a Gaussian process model have been embed in MOEA/D [32] for solving expensive MOPs. In [60], each subproblem records more than one solution to maintain search diversity in their population evolution. Multiple search operators with self-adaptive procedures have been suggested for population evolution [61,41,40]. Two well-known MOEA/D and NSGA-II [62] have combined at population level in [63] for solving hard optimization and search problems. In [64], two different aggregation functions have been simultaneously incorporated. A new NBI-style Tchebycheff approach has been introduced in [65] to handle the portfolio optimization problems. A decomposition-based multiobjective evolutionary algorithm with an ensemble of neighborhood sizes (ENS-MOEA/D) has been proposed for solving CEC’09 test instance [66]. In ENS-MOEA/D, two ensemble neighbourhood sizes (NSs) with online self-adaptation manner has been proposed for the purpose to overcome the user-specific tuning of neighbourhood size (T) parameter used in MOEA/D [36]. In [67], ant colony optimization (ACO) has been incorporated into MOEA/D for solving the multiobjective Knapsack problems (MOKPs) and the multiobjective traveling salesman problem (MTSPs). An improved version of MOEA/D with adaptive weight vector adjustment (MOEA/D-AWA) has been proposed in [68]. MOEA/D uses fixed weight vectors which cannot work if Pareto fronts (PFs) of the considered MOPs are complicated (i.e., discontinuous PF or PF with sharp peak or low tail).Different strategies/techniques/search operators have different strengths at different stages of population evolution. Pareto dominance concepts and concept of decomposition are two well-known procedures. Each one have its some own key features and limitations. Therefore, combined use of these two concepts in a master algorithm can bring significant advancement and success to field of evolutionary computation. Inspired from their remarkable achievements and some existing works in the EC literature [69,70,62,40,41,37,42], We have suggested novel MOEA based on multimethod (MMTD) with dynamic resource allocation in this paper. The suggested algorithm exploits two popular algorithms known as MOEA/D [32] and NSGA-II [22] and evolve their population in dynamical manners. We have tested our MMTD on CEC’09 benchmark functions [71] and ZDT test problems [72] using inverted generational distance (IGD) as a performance indicator. MMTD have been tackled almost all test problems in robust manner as compared to state-of-the-art MOEAs selected in our comparative analysis.The core contributions of the proposed algorithm are summarized and highlighted as follow:•The proposed MMTD employs both Pareto dominance-based concept and decomposition strategy in their evolutionary process for population evolution.The proposed algorithm employs two well-known MOEAs based their individual performances simultaneously and dynamically.The proposed MMTD is flexible and many algorithms or even different multiple operators can be accommodated as a constituent algorithms/search operators in their whole process of population evolution. The impact analysis of different operators in MMTD constituent algorithms is also part of research work in this paper.Experimental results demonstrate that MMTD has significantly performed better than state-of-the-art MOEAs such as MOEA/D [32], NSGA-II [22], AMALGAM [70], MOPSO: A proposal for multiple objective particle swarm optimization [73], MOSaDE [74], DECMOSA-SQP [75] in terms of Inverted generational distance (IGD) metric values and less time cost.Two different test suites like widely used ZDT test problems [72] and complicated CEC’09 test instances [71] have been used in our carried out experiments.Eight years ago Qingfu Zhang and Hu Li have been developed a novel class of evolutionary algorithm known as MOEA/D [32] for solving multiobjective 0/1 knapsack and test suites of continuous MOPs. An Algorithm 1 provides the pseudocode of MOEA/D. Aggregation functions such as Weighted Sum Approach [76], Tchebycheff Function [76], Normal-Boundary Intersection Method [77], Normalized Normal Constraint Method [78] and some others [79] can apply as aggregation function in MOEA/D framework. In this paper, we have used the Tchebycheff approach which is formulated as follows:(2)minimizegte(x|λ,z★)=max1≤j≤m{λj|fj(x)−zj*|}where x∈Ω,z*={z1*,z2*,…,zk*}Tis the reference point,zj*=min{fj(x)|x∈Ω}for each j=1, 2, …, m, λ=(λ1, λ2, …, λm) such that λj≥0,∑j=1mλj=1. In the initialization Step 6 of Algorithm 1, B(i) contains the indices of the T closest vectors of λi. Euclidean distance is used to measure the closeness between any two weight vectors. Therefore, λiis the closest vector to itself (i.e., iϵB(i)). If jϵB(i), then jth subproblem can be regarded as a neighbor of the ith subproblem. Furthermore, for each ith subproblem, we chose their T neighboring subproblems in the initialization step Algorithm 1.Algorithm 1Framework of the MOEA/D.[1:] Inputs: MOP: multiobjective optimization problem; N: population size; Tgen: total generation or function evaluations; a uniform spread of N weight vectors, λ1, …, λN; T: the number of weight vectors in neighborhood of each weight vector;[2:] Output: {x(1), …, x(N)} and {F(x(1)), …, F(x(N))}[3:]   Initialization:[4:] Uniformly and randomly generate a population of size N, P={x(1), …, x(N)} in the search space, Ω;[5:] Generate a set of N weight vectors, {λ1, λ2, …, λN};[6:] Compute the Euclidian distances between any two weight vectors and then find the T closest weight vectors to each weight vector. For each subproblem i=1, 2, …, N, set B(i)={i1, …, iT}, where λi1, …, λiTare the T closest weight vectors to λi;[7:] Generate an initial population of size N, x1, x2, …, XNand compute the F-function values, F(xi), i=1, 2, …, N;[8:] Initialize z=(z1, …, zm)Tby problem-specific method;[9:] Set CG=1;[10:] while CG<Tgen do[11:]   fori=1:Ndo[12:] Randomly select three indices, r1, r2, r3 from the population P, then create a new solutiony˜iusing DE as a crossover over xr1, xr2, xr3;[13:] Apply a repair scheme on they˜ito get the new solution yiwithin search space domain;[14:] Compute the F-function values of yi, F(yi);[15:]Update of z: for each j=1, …, m, if fj(yi)<zj, then set zj=fj(yi);[16:]Update of Neighboring Solutions:[17:] For each index j∈B(i)={i1, …, iT}[18:]ifg(y|λj, z)≤g(xj|λj, z) then[19:]xj=y and F(xj)=F(y)[20:]end if[21:]   end for[22:]   CG=CG+1[23:] end whileWe chose three solutions, xk, xland xmin the neighbor of each ith subproblem for an offspring yicreation. We have used differential evolution (DE) as a crossover in Algorithm 1. Each offspring produce by DE and then followed by polynomial mutation could hopefully be better than maximum number of T neighboring solutions of each ith subproblem as explained in Algorithm 1.A fast non-dominated sorting genetic algorithm (NSGA-II) [22] well-known MOEA for solving both real-world and diverse test MOPs. It has three main features, firstly, their computational complexity is O(MN2) while NSGA [80] has O(MN3), where M denotes the number of objectives and N is the population size, secondly, Elitism scheme has been used in NSGA-II [22], where NSGA [80] has no such scheme and finally a crowding distance estimator scheme has been introduced in NSGA-II [22] is an alternative for sharing function of the NSGA [80]. Algorithm 2 explains their algorithmic procedure of NSGA-II [22].Algorithm 2Framework of NSGA-II [22].[1:] Input: MOP: multiobjective optimization problem; N: population size; Tgen: total generations or function evaluations;[2:] Output: Pareto Set (PS): {x(1), …, x(N)} and Pareto Front (PF): {F(x(1)), …, F(x(N))};[3:] Generate uniformly and randomly an initial population P of size N in the search space Ω;[4:] Compute the F-function values of the population P, {F(x(1)), …, F(x(N))};[5:] Set CG=1;[6:]   while CG<Tgen do[7:]   Apply binary tournament selection, to select a pairs of solutions;[8:]   Use variation operators and generate an offspring set Q of size N;[9:]   Combine both parent and offspring population, R=P∪Q to get a population of size 2N;[10:]   Use fast non-dominated sorting procedure R;[11:]   Select best solutions with high ranks and crowding distances from R f size N to form a new populationP˜;[12:]   Replace an old population P withP˜;[13:]   CG=CG+1;[14:] end whileA fast non-dominated sorting procedure divide the population into different layers or fronts Flbased on their corresponding fitness values and for each solution two entities, Npand Sp, are calculated according to the procedure as illustrated in Algorithm 3:1Domination count, Np, the number of solution which dominates solution p.A set of solution that the solutions p dominates, Sp.A fast non-dominated sorting technique of the NSGA-II [22].[1:] calculate Npand Sp;[2:] for each p∈P;[3:] SP=∅; // A set of solutions that the solutions p dominates.[4:] NP;  // The number of solutions which dominates the solution p[5:] for each q∈P;[6:] if (p≺q) then  // If p dominates q[7:] SP=SP∪{q}[8:] else if (q≺p) //Add q to set of solutions dominated by P[9:] Np=Np+1;  // Increment the domination counter of P[10:] if Np=0 then p belongs to the first front F1[11:] Prank=1[12:] F1=F1∪{p};  // All solutions in the first non-dominated front will have their domination count as zero[13:] [Second Part:] Divide solutions in to different fronts;[14:] l=1;  // Initialize the front counter[15:] Fl=∅;[16:] Q=∅;  // Used to store the member of the next front[17:] for each p∈Fl[18:] for each q∈SP[19:] Nq=Nq−1[20:] if Nq=0 then  // q belongs to the next front[21:] qrank=l+1;[22:] Q=Q∪{q};[23:] l=l+1;[24:] Fl=Q;The crowding distance technique [22] is used for the estimation of density of the solutions encompassing ith the population P, this metric computes the average distance of two solutions on either side of the ith solution along each objective as shown in Fig. 1. This quantity denoted by idistanceserves as an estimate of the perimeter of the cuboid form by the nearest neighbors of ith solution.Crowding distance computation demands for sorted population and their objective function value should in ascending order of magnitude. Thereafter, for each objective function, the boundary solutions are assigned an infinite distance value. All other intermediate solutions are assigned a distance value equal to the absolute normalized difference in the function values of two adjacent solutions. This calculation is continued with other objective functions. The overall crowding-distance value is calculated as the sum of individual distance values corresponding to each objective. Each objective function is normalized before calculating the crowding distance. Algorithm 4 is used to calculate the crowding distance of each ith solution in the set I as explained under:Algorithm 4Crowding distance assignment of I in NSGA-II [22].[1:] L=|I|;  // Compute the number of solution in non-dominated set I[2:] for each i, set I[i]distance=0;  // Initialize distance[3:] for each objective m;[4:] I=sort(I, m);  // Sort using each objective values.[5:] I[1]distance=I[L]distance=∞;  // So that the boundary solutions are always selected[6:] fori=2to(L−1) do[7:]I[i]distance=I[i]distance+(I[i+1].m−I[i−1].mfmmax−fmmin[8:] end forAlgorithm 5MOEA based on multimethod (MMTD) with dynamic resources allocation.[1:] Input: MOP: the multiobjective optimization problem; N: the population size; Tgen: Total Generations or Resources; Parameters of MOEA/D; Parameters of NSGA-II[2:] Output: {x1, …, xN} and {F(x1), …, F(xN)};[3:] Initialization[4:] Generate an initial population P of size N by uniformly and randomly within Ω.[5:] Calculate the F-function values of each member of population P.[6:] Divide the population P into two different subpopulation PAand PB, where |PA|=|PB|= N/2.[7:] Set DG={GA, GB}[8:] Set CG=GD, current generations allocation.[9:] Execution of Constituent Algorithms[10:] while CG≤Tgen do[11:]   Execute A over sub-populations PAfor GAgenerations to produce new subpopulationPA′.[12:]   Execute B over sub-populations PBfor GBgenerations to produce new subpopulationPB′.[13:]   Combine new subpopulations,Q=PA′∪PB′, after DGgenerations.[14:]   Combine previous P and current population Q, C=P∪Q.[15:]   Select N best individuals from the combined population C using fast non-dominated sorting procedure.[16:]   Update the Resources Allocation to Constituent Algorithms[17:]   Update DG={GA, GB} (Details can be found in the Algorithm6.)[18:]   CG=CG+DG, where DG=|GA+GB|[19:] end whileAlgorithm 6Resources allocation to constituent algorithms.Step 1:Compute the resources/times/generations, GA, allocated to method A as follow:(3)GA=⌊0.1×DG⌋ifδ1δ1+δ2<0.1⌊DG×δ1δ1+δ2⌋if0.1≤δ1δ1+δ2≤0.9⌊0.9×DG⌋ifδ1δ1+δ2>0.9Compute the resources GBof the method B as(4)GB=DG−GA,Where DGdenotes dynamic generations/resources, δ1 denotes the number of successful solutions of the method A that enter into the next phase of MMTD for GAgenerations and δ2 denotes the number of solutions of the method B that successfully enter to next phase of MMTD by executing method B for GBgenerations. Each successful solution will be rewarded by 1 while unsuccessful will get 0 reward.In the execution steps of Algorithm 5, We allow method A to execute on subpopulation PAfor GAgenerations. Similarly, algorithm B does operate on subpopulation PBfor GBgenerations. The proposed algorithm is then combines the current subpopulationsPA′andPB′of the constituent algorithms (i.e., (A) MOEA/D [32] and (B) NSGA-II [22] or vice versa) after GD=GA+GBgenerations. Next we combine both previous and current population Q=QA∪QBto ensure elitism strategy. Further, We select N fittest individuals of high ranks and crowding distances to push them to the next phase of GDgenerations of MMTD algorithm. Algorithm 6 counts the successful individuals of each constituent algorithm that get through to the next phase GDgenerations. We update the values of GAand GBbased on the entry of successful individuals of each employed algorithm in MMTD. We are awarding each successful individual by 1 and unsuccessful by 0. The constituent algorithms will receive resources based on successful solutions that next enter to the evolutionary process of MMTD. These recourses are allocated to each algorithm in form of generations/times and as well as population individuals. The more efficient is the constituent algorithm, the more he will get rewards in the form times as well population individuals for further execution.Test functions which is also known as artificial landscapes are necessary for MOEAs performance evaluation in order examine their convergence behaviors and robustness on different test suits. However, the selection and design of test suites with diverse characteristics such as multi-modality, deception, isolation and particularly location of true Pareto-optimal front is also most challengeable and difficult job. The benchmark functions designers are mostly incorporate global optimum either in the center of search range or upon problems bounds [72,82]. These kind of test functions [72,82] are relatively simple as compared to the test instances recently designed for the special session of MOEAs competition in 2009 IEEE Congress on Evolutionary Computation (CEC’09) [71]. The authors of CEC’09 test instances have included extension, stretching and rotation in the objective functions of their test functions. Problems furnished with such characteristics and some others are very challengeable test functions for EC communities. We have selected ten unconstrained problems from the CEC’09 test suite [71] and five test function from the ZDT test problems. The features related to ZDT problems are provided in Table 2. Most importantly, all these selected test problems should be treated as black-box problems (i.e., the mathematical formulations of these problems could not be used in the suggested algorithms). The characteristics related PF nature of CEC’09 test instances are described in Table 1. The Matlab/c++ codes of the CEC’09 test instances [71] can be downloaded from links: dces.essex.ac.uk/staff/qzhang or http://www.ntu.edu.sg/home/EPNSugan.Different performance metrics have been suggested for the MOEAs performance evaluation and valuation. The main purposes of most metrics is examine that which algorithm is better than other and in what aspects. However, it is very difficult to decide a concise definition for the algorithmic performance. General distance (GD), spacing (S), error ratio (ER), hypervolume and inverted generational distance (IGD) and several others are widely used performance indicators in various comparative analysis [83,84]. In this paper, We have chosen the inverted generational distance (IGD) as a performance indicator as shown in Fig. 2. It requires a reference set of optimal solutions p* of the problem under attack and their approximated set of optimal solutions A produced by particular algorithm. Let P* be a set of uniformly distributed solutions which is expanded along the real/true PF. Let A be an approximate set to the PF, the average distance from P* to A is defined as [32,36]:D(A,P)=∑v∈P*d(v,A)|P*|whered(v,A)is the minimum Euclidean distance betweenvand the points in A. If P* is large enough to represent the PF very well, D(A, P) could measure both the diversity and convergence of A in a sense. It should be noted if IGD=0, then final set of non-dominated solutions generated by specific algorithm will be similar to that present in P. Any other value will indicate how far away the approximated Pareto front (PF) from global PF of the undertaken MOP. A smaller value of the IGD is more desirable.In our carried out experiments, we have selected P=500 evenly distributed solutions along the true PF dealing with bi-objective test instances and p=1000 individuals for test instances with three objective function. We have used IGD metric just because it one of the criteria for CEC’09 test instances [71]. Secondly, IGD has ability of finding both diversity and convergence rate. If the reference set of the test problem is not known in advance then IGD is not applicable in such cases.In this paper, the ZDT test problems [72] have been used with aim of giving an idea that how our proposed algorithm acts on most complicated and widely used test problems. The ZDT test problems have been tackled with following parameters settings:•N=100: the population size for 2-objective ZDT test problems.pm=1/n: the mutation rate, where n=10.η=20: the distribution index, used in polynomial mutation [12].F=0.5: scaling factor of DE.CR=0.5: crossover rate of DE.Each algorithm stops after 250,00 function evaluations or when Generations=250.λ1, …, λNare weight vectors used in MOEA/D. Each individual weight takes a value form:0H,1H,…,HHH=N/2−1.G={GA, GB}={25, 25}, G=|GA+GB|=50 in the initial phase of MMTD.The CEC’09 [71] are managed with following parameter settings:•N=600: for 2-objective test instances.N=1000: for 3-objective test instances.T=0.1N: the neighborhood size for each subproblem in MOEA/D. item pm=1/n: the mutation rate, where n=30.η=20: the distribution index, used in polynomial mutation.F=0.5: scaling factor of DE.CR=1.0: crossover rate of DE.Each algorithm stops after 300,000 function evaluations.G={GA, GB}={50, 50}, G=|GA+GB|=100 in the initial phase of MMTD.A set of N weight vectors which are required for the implementation of the MOEA/D [32] are generated as per criteria:1Uniformly randomly generate 5,000 weight vectors for forming the set W1. Set W is initialized as the set containing all the weight vectors (1, 0, …, 0, 0), (0, 1, …, 0, 0), …, (0, 0, …, 0, 1).Find the weight vector in set W1 with the largest distance to set W, add it to set W and delete it from set W1.If the size of set W is N, stop and return set W. Otherwise, go to 2.♣ PC Configuration:•Operating system: Windows XP Professional.Programming language of the algorithms: Matlab.CPU: Core 2 Quad 2.4GHz.RAM: 4GB DDR2 1066MHz.Execution: 30 times with different random seeds for each test problem.To establish a fair comparison among the used algorithms, the number of non-dominated solutions found by each algorithm were limited to 100 for bi-objective problems and 150 solutions for three-objective problems for calculating the IGD-metric values.Table 3presents the IGD-metric values of the approximated Pareto front gave rise by each algorithm in comparative analysis of proposed MMTD algorithm against sate-of-the-art MOEAs including (b) MOEA/D [32], (c) NSGA-II [22] and (d) AMALGAM [70]. In this Table 3, each 1st row holds the best IGD values, median IGD values, mean IGD values, standard deviation of IGD values, maximum IGD values obtained by MMTD for each ZDT test problem within allowed 250,00 function evaluations. Similarly, 2nd provides the IGD-metric values provided by MOEA/D [32], 3rd row maintains the IGD-metric values of the NSGA-II [22] and 4th row caters the IGD-values of the AMALGAM [70] for each ZDT test problems. All these IGD-statistics are gathered by executing each algorithm 30 times dealing with each ZDT bi-objective problem with same parameters setting as described in the subsection 4.2. The proposed MMTD have brought out much promising experimental results for almost all five ZDT test problems compared to their competitors.Table 4presents the average CPU time elapsed by each algorithm in seconds by (a) MMTD (b) MOEA/D [32] and (c) NSGA-II [22]) while coping with ZDT test problem. It can seen from Table 4, MMTD has tackled all ZDT test problems [72] more faster than all other used algorithms in our comparative analysis. This faster behavior contribution of the MMTD could to be attributed to the idea of employing multiple search techniques and update them at every GD=50 dynamically. Fig. 3exhibits the best approximation of PF discovered by each algorithm in their 30 independent runs while dealing with ZDT test problems, where the 1st panel (left) is made by MMTD, 2nd panel obtained by MOEA/D [32], 3rd panel exhibited by NSGA-II [22] and 4th panel is of the AMALGAM [70]. These figures in these panels clearly indicate that final approximated PF are uniformly distributive and well converge to the true/real PF (RPF) of each ZDT problems. We have also plotted all 30 PFs against the RPF of each test problem in Fig. 4in order to display the distribution ranges of each algorithm. These Fig. 4 clearly shows that MMTD has gathered all 30 PFs very close to RPF of each ZDT test problem.Fig. 5illustrates the dynamical behaviors of the MOEA/D [32] and NSGA-II [22] in the evolutionary process of the MMTD. Furthermore, These figures are clearly indicate that both constituent algorithms have received equal resources at the initial phase and then resources (i.e.,generations/times and population) are allocated dynamically to each embed algorithm for further execution of DG=50 generations.Table 7 summaries the IGD-metric values in terms of best, median, mean, standard deviation (std) and worst/maximum gathered by (a) MMTD, (b) MOEA/D [32], (c) NSGA-II [22] and (d) AMALGAM [70] for each CEC’09 test instance [71] within allowable 300,000 function evaluations. In Table 7, each 1st row provides the IGD-metric values of the proposed MMTD for each CEC’09 test instance [71]. Similarly, 2nd row piles up the IGD-metric values determined by MOEA/D [32], 3rd row dedicated to the contribution of the NSGA-II [22] and finally 4th row of Table 7 accumulates the IGD-metric values of the AMALGAM [70] in their 30 independent simulation runs dealing with each CEC’09 test instance [71]. A lower values of the IGD-metric designate the performance that which algorithm is performed better than other and one can seen in Table 7 that MMTD has offered promising better results with minimum average IGD-metric values for almost all CEC’09 test instance [71] as compared to all competitors used in our comparative analysis.Table 5provides the average CPU time exhausted by each algorithm in seconds to cope with CEC’09 problems, where in Table 5, the 1st column maintains the average CPU time of the MMTD and 2nd column offerings the average CPU time of the MOEA/D [32], 3rd column provides the average CPU times of the NSGA-II [22] and 4th column keeps the record of the average CPU time exhausted by AMALGAM [70]. Table 5 shows that MMTD solves all test problems in faster way as compared to NSGA-II [22] and AMALGAM [70]. This best behavior of the MMTD can further improve by employing same nature of MOEAs.Furthermore, we have also included the mean and standard deviation (std) of the IGD-mertic values of the MOPSO [73], differential evolution with self-adaptation and local search for constrained multiobjective optimization algorithm (DECMOSA-SQP) [75] and multi-objective optimization based on self-adaptive differential evolution algorithm (MOSADE) [74] in Table 6for the further performance judgement of the MMTD. This Table 6 confirms that MMTD has tackled the most CEC’09 test instance with minimum IGD-mean and IGD-std against aforementioned MOEAs.Fig. 6shows the dispersion of non-dominated set of solutions display by each algorithm in its best run out of 30 independent runs on each CEC’09 test instance. In these plots of best approximated Pareto fronts (PFs) against RPF, the 1st panel (left) is displayed by MMTD, 2nd panel is provided by MOEA/D [32], 3rd panel is for NSGA-II [22] and last 4th panel is output AMALGAM [70] (Fig. 7). All these panels designate that MMTD have created best approximated PF in terms of diversity and proximity for most CEC’09 test instance [71] against MOEA/D [32], NSGA-II [22] and AMALGAM [70]. In Fig. 8, we have figured out 30 PFs altogether for each problems to visualize the distribution ranges of MMTD in their 30 independent executions (Fig. 9).Fig. 10provides the evolution in average IGD-metric values versus the number of function evaluations and Fig. 11demonstrates that resources allocation of MMTD procedure for the purses to visualize the performance of constituent algorithm in their whole course of optimization. Fig. 11 clarifies that MOEA/D [32] has performed better than NSGA-II [22] in the evolutionary process of the MMTD.The performance of evolutionary algorithms are greatly effected with use of evolutionary operators. Operators include crossover, mutation, selection. Different search operators suite different optimization and search problems. No operators can perform always better on different problems. In this paper, we examined the effect of the use of different crossovers including the simulated binary crossover (SBX) [12] in NSGA-II [22] framework and differential evolution (DE) in MOEA/D [32] framework for solving 10 unconstrained test instances of the test suite reported in [71]. We have also carried out experiments by using different population sizes dealing with each test problems.Table 8provides the IGD values in terms of best, median, mean, standard deviation and maximum by executing proposed MMTD 30 times on each CEC’09 test instance [71] with population sizes (i.e., N=600 for 2-objective and N=1000 for 3-objective test instances). We also test the efficacy of the MMTD with different population sizes (i.e., N=300 for 2-objective and N=500 for 3-objective test instances) and the IGD-metric values of this experiment can be seen from Table 10 where Table 9provides the IGD-metric values of NSGA-II-SBX [22] on each CEC’09 test instance.Tables 8 and 10provides approximated set of non-dominated solutions with better average IGD values than its constituent algorithms. Based on these preliminary experimental results, we are confident by saying that the performance of MMTD can be further improved by using different existing robust techniques and operators in its framework for solving complicated test and real-world problems.Existing multiobjective evolutionary algorithms (MOEAs) tackle the given multiobjective optimization problems (MOPs) either as a whole or decompose it into a number of single objective subproblems (SOP) by using traditional aggregation function. MOEA based on decomposition (MOEA/D) [32] solves the MOPs at hand not directly as like NSGA-II. Decomposition based MOEAs have shown remarkable performances as compared to MOEAs based on Pareto dominance concept. The key feature of this paradigm is their neighbourhood relationship among their subproblems which are defined based on the Euclidian distance between the weight vectors of their aggregation functions. On the other hand, the strengths of NSGA-II [22] is their fast non-dominated sorting procedure. In principal, different techniques are performing differently at different stages of population evolution. Therefore, the combined use in a master algorithm would be reasonable and arguable research to cope with complicated optimization and search problems.In this paper, we have simultaneously utilized multimethod including MOEA/D [32] and NSGA-II [22] for population evolution with dynamic resources allocation scheme and developed MMTD for solving two different test suites of continuous MOPs. The proposed algorithm have been obtained promising experimental results in terms of proximity and diversity for both ZDT test problems [72] and CEC 2009 test instances [71] against to state-of-the-art MOEAs.In future, We intend to examine the performance of the methodology on vehicle crashworthiness design problems [5]. Moreover, We will be applying MMTD to tackle different material distribution properties of the functionally graded materials (FGMs) as discussed in [85–88].In addition, the rise of multi-core processors and substantial improvements in multiprocessing systems can be motivation for us to implement our proposed algorithm on parallel multicore systems in our future study plan.

@&#CONCLUSIONS@&#
