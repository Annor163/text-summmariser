@&#MAIN-TITLE@&#
An alternative adaptive differential evolutionary Algorithm assisted by Expected Improvement criterion and cut-HDMR expansion and its application in time-based sheet forming design

@&#HIGHLIGHTS@&#
An alternative adaptive DE algorithm is suggested.Two new mutation strategies are proposed.EI criterion is employed to identify scale factor adaptively.Cut-HDMR is used to determine crossover constant due to coupling characteristic.The suggested method is successfully applied to time-based sheet forming optimization.

@&#KEYPHRASES@&#
Evolutionary computations,Differential Evolution (DE),Expected Improvement (EI),High Dimensional Model Representation (HDMR),Surrogate model,Sheet forming,

@&#ABSTRACT@&#
Differential Evolution (DE) is one of the most powerful stochastic real parameter optimizers. An alternative adaptive DE algorithm called Expected Improvement (EI)-High Dimensional Model Representation (HDMR)-DE is suggested. The EI criterion and the Kriging-HDMR are used to adjust scale factor F and crossover constant Cr, respectively. Considering the expensive computational cost of evaluation, the Kriging is integrated to evaluate the objective function when an accuracy criterion is met. To compare the performance, the suggested method, it has been compared with four popular adaptive DE algorithms over 25 standard numerical benchmarks derived from the IEEE Congress on Evolutionary Computation 2005 competition. To verify the feasibility of the suggested algorithm, a real-world application, time-dependent variable Blank Hold Force (BHF) optimization problem is also carried out by the EI-HDMR-DE. The results show that the EI-HDMR-DE improves the performance of adaptive DE and has potential capability to solve some complicated real-world applications.

@&#INTRODUCTION@&#
Differential Evolution (DE), proposed by Storn and Price [1] is well known as an Evolutionary Algorithm (EA) for solving global optimization problems. Owing to its simplicity and powerful search ability, the DE has received a wide variety of real-world applications and showed excellent performance on multiplier problems in multidiscipline. For the DE, there are several strategies trial vector generation and different problems may be suitable for different strategies [2]. Additionally, control parameter settings have great influence on DE's performance [3]. For these reasons, when the DE is applied to a particular problem, it is commonly necessary to try various strategies and different combinations of control parameters. Obviously, such a trial-and-error strategy is commonly time-consuming. To address this issue, numerous DE variants have been proposed in the past years.For the DE, there are three main control parameters: mutation scale factor F, crossover constant Cr, and population size NP. Storn and Price [4] indicated that a reasonable value for NP might be assigned between 5n and 10n (n denotes the dimensionality of a problem), and an initial choice of F is 0.5. The effective range of F is commonly between 0.4 and 1. The parameter Cris utilized to control how many parameters should be changed in a population member. When the value of Cris small, only few number of parameters should be altered in each generation. Moreover, the stepwise movement tends to be orthogonal to the present coordinate axes. Conversely, most of the directions of the mutant vectors should be inherited preventing the generation of axis orthogonal trends. In extremity, when the value of Cris set to 1, the trail vector becomes a pure mutant operation. The lower value Crmakes search change in each direction independently. It suggests that the lower Crvalue should be more suitable for the low coupled functions, such asf(X)=∑i=1nfi(xi). As mentioned by Ronkkonen and Kukkonen [11], Crshould lie in (0, 0.2) when the function is separable, while in (0.9, 1) when the parameters of the function are coupled. Actually, several suggestions have been reported concerning the rules for tuning the control parameters and such kinds of settings might potentially confuse users. For example, Kenneth [12] recommended to use the trial vector generation strategy DE/current-to-rand/1 and parameter setting. Gämperle et al. [3] examined different parameter settings for the DE. Their experimental results showed that the searching capability and convergence ratio are sensitive to the selection of the control parameters. They also suggested that NP be between [3n, 8n], F equals 0.6, and Crbe between [0.3, 0.9]. However, most of these settings lack sufficient experiments and theoretical foundation. Therefore, it is urgent to build an appropriate strategy to update an optimal set of control parameters in each cycle for the DE. Zaharie [13] proposed a parameter Adaptation strategy for the DE (ADE) based on controlling the population diversity, and implemented a multi-population approach. Liu and Lampinen [14] developed a Fuzzy Adaptive Differential Evolution (FADE) by using fuzzy logic controllers whose inputs incorporate the relative function values and individuals of successive generations to tune the control parameters F and Cr. Brest et al. [15] suggested a self-adaptation scheme called jDE. They encoded control parameters F and Crinto the individual and adjusted them by introducing two additional control parameters τ1 and τ2. In the jDE, a set of F and Crvalues should be assigned to each individual population. Brest and Maučec [16] also proposed a method for reduction of population size of the DE. The method improves the efficiency and the robustness of the DE and can be applied to any DE variant. Qin et al. [2] developed a Self-adaptive DE (SaDE) algorithm, in which both trial vector generation strategies and control parameters F and Crare self-adapted by learning from previous experiences. The major feature is to use a normal distribution to approximate F. A set of F values should be randomly sampled according to pre-defined normal distribution and applied to each target vector in the present population. Similarly, the SaDE adjusts the range of Crfor a given problem according to previous Crvalues which have generated trial vectors successfully. The JADE proposed by Zhang and Sanderson [17] generates new F values according to a truncated Cauchy distribution and new Cr values according to a normal distribution. The parameters of the Cauchy distribution and the normal distribution are updated by using new F and Cr values at each generation. The SaNSDE developed by Yang et al. [18] can be considered as a multi-distribution version of the SaDE. In the SaNSDE, two different distributions are used to generate the new F values. The fitness improvement related to each successful Cr is also considered in the SaNSDE in updating the mean of the Gaussian distribution for generation of new Cr. Because various mutation strategies with different parameter settings might be suitable for different stages of the DE. Mallepeddi et al. [24] proposed the EPSDE (Ensemble of mutation strategies and Parameters in the DE) for selecting a combination of mutation strategy and parameter setting. In the EPSDE, combinations of mutation strategy and parameter setting are generated at the individual level and better combinations should be propagated to the next iteration. Elsayed et al. [25] proposed a differential evolution algorithm with Self-Adaptive multi-combination Strategies (SAS-DE), in which four mutation strategies, two crossover strategies, and two constraint handling techniques are used. Fan and Xuefeng [26] suggested a Discrete Mutation Control Parameters Self Adaptive DE (DMPSADE). Wang et al. [27] suggested a hybrid approach that combines the adaptive DE algorithm with Back Propagation Neural Network (BPNN), called ADE-BPNN. In the ADE-BPNN, ADE is implemented to search the global initial connection weights and thresholds of BPNN. The BPNN is utilized to thoroughly search the optimal weights and thresholds. Yi et al. [28] implemented pbest roulette wheel selection and retention to develop a new adaptive DE.In this study, an alternative adaptive DE is suggested. Compared with the other adaptive DEs, the distinctive characteristics of the suggested method is to use the Expected Improvement (EI) criterion to tune the F and employ the High Dimensional Model Representation (HDMR) to determine the Cr. The rest of paper is organized as follows. The DE is briefly introduced in Section 2. The details of suggested new DE algorithm are described in Section 3. Numerical tests and an application by the suggested algorithm are presented in Sections 4 and 5, respectively.Without loss of generality, an optimization problem can be formulated as follows.(1)minxf(x)wherexis a vector of n design variable in design spaceΩ=∏i=1n[Li,Ui]and f: Ω⊆ℜn→ ℜ called as objective function.The DE begins with a randomly generated populations (samples) in design space,PG={xi,G|i=1,2,…,popsize}. Sequentially, the DE iteratively uses the trial vector generation strategy and the selection operator to generate populations until a stopping criterion is met. The framework of the classical DE can be demonstrated in Table 1.For the mutation operator, five commonly used mutation strategies for generating a mutant vector are described as shown in Table 2. After the mutation operation, crossover operation should be applied to each pair of the target vectorxi, Gand corresponding mutant vectorvi, Gto generate a trail vector which usually can be expressed as follows.(2)uj,i,G={vj,i,Gxj,i,Gifrandj(0,1)≤Crorj=jrandotherwisewhere j=1,2,…,n, jrandis a randomly selected integer, randj(0, 1) represents a number drawn uniformly between 0 and 1,xj, i, G,uj, i, G, andvj, i, Gdenote the jth element ofxi, G,ui, G, andvi, Grespectively.After crossover phase, each new trial vectorui, Gundergoes boundary constraint check. If it is out of constraint boundary and can be reset as follows.(3)uj,i,G={min{Uj,2Lj−uj,i,G}max{Lj,2Uj−uj,i,G}ifuj,i,G<Ljifuj,i,G>UjFinally, a greedy selection operator can be used to select the betweenxi, Gandui, Gto step to the next generation as(4)xi,G+1={ui,Gxi,Giff(ui,G)≤f(xi,G)otherwiseGenerally, the performance of the DE largely depends on the values of the control parameters, F and Cr. Similar to other search algorithms, the exploration and exploitation of a design space should be addressed. As mentioned in Črepinšek‘s literature (2013), exploration is the process of visiting entirely new regions of a search space, whilst exploitation is the process of visiting those regions of a search space within the neighborhood of previously visited points. In the previous developed DEs, the SaDE Qin et al. [2] used various DEs for each individual to maintain a good balance between exploration and exploitation. In our opinion, exploitation and exploration can be adjusted by F. Moreover, another important parameter Crcommonly is determined by the separable and dependent characteristics of given problems. Therefore, the performance of DE might be further improved in these two issues. In the proposed algorithm, the EI criterion is used to tune the mutation scale parameter F and the HDMR expansion is used to update the crossover constant Cr, respectively. The framework of EI-HDMR-DE is briefly demonstrated in Table 3 and details of the EI-HDMR-DE should be described in this section.As mentioned before, some theoretical studies on the DEs have indicated that the scale factor F is a key role in controlling the population diversity and the explorative power of the DE. Generally, a higher value of F accounts for larger perturbation to the target vectors, thus avoiding premature convergence at local optima. Considering the characteristic of F, the EI criterion is imported to determine the mutation scale factor F. In this study, two alternative mutation strategies, called DE/current-to-sbest and DE/current-to-umost are suggested.In DE/current-to-sbest, a mutation vector is generated as following form:(4)vi,G=xi,G+Fi·(xbest,Gs−xi,G)+Fi·(xr1,G−xr2,G)wherexbest,Gsis randomly chosen from as one of the top 50 best individuals obtained by the first term of EI criterion introduced later in Eq. (9) and Fican be determined by the EI criterion and should be discussed later.In DE/current-to-umost, a mutation vector is generated as following form:(5)vi,G=xi,G+Fi·(xmost,Gu−xi,G)+Fi·(xr3,G−xr4,G)wherexmost,Guis randomly chosen from as one of the top 50 uncertain individuals obtained by the second term of EI criterion introduced later in Eq. (10) and Fican be determined in the same way as Eq. (4).Finally, in the mutation phase, a mutation vector is generated by using forming manner:(6)vi,G=xi,G+wi(Fi·(xbest,Gs−xi,G)+Fi·(xr1,G−xr2,G))+(1−wi)(Fi·(xmost,Gu−xi,G)+Fi·(xr3,G−xr4,G))where wiis 0 or 1 and should be generated randomly.Compared with other mutation strategies, the most attractive characteristic of the suggested strategy considers the exploitation of optima and the exploration of uncertain areas explicitly. In Eq. (6), the second term (Eq. (4)) is to find the potential best population and the third one (Eq. (5)) is to locate the uncertain areas. To make the mathematical meaning clearly, the EI criterion and its Fiprediction procedure are briefly introduced in Section 3.2.2.The EI criterion is used to add new sample (population) to the present sample set upon the Present Best Sample (PBS) y*, the improvement at the samplexis(7)I(x)=max{0,y*−Y(x)}which is a random variable because Kriging models the response y(x) as a realization of a Gaussian process (GP) Y(x). The, the EI is the expectation of I(x) as(8)EI(x)={(y*−y^)Φ(y*−y^(x)s^(x))+s^φ(x)(y*−y^(x)s^(x))ifs^(x)>00,ifs^(x)=0wheres^is the predicted Standard Deviation (STD),y^denotes the predicted response value by the surrogate model. The response can be treated as realization of a random variable y(x) which follows by Gaussian with variance s2(x). Functions Φ and φ denote the Cumulative Distribution Function (CDF) and Probability Density Function (PDF) of the normal distribution, respectively.In Eq. (8), term(9)EICDF=(y*−y^)Φ(y*−y^(x)s^(x))denotes the difference between the present minimum and the predicted value multiplied by the probability that predicted response value is smaller than y*. Therefore, this term is large wherey^is likely smaller than y*. It enhances the accuracy of a surrogate model solely in the region of the present minimum, and performs the capability of the exploitation. Therefore, for DE/current-to-sbest, top 50 best individuals can be obtained by Kriging model according to Eq. (9).Conversely, term(10)EIPDF=φ(x)(y*−y^(x)s^(x))is the STD of response multiplied by the probability thaty^is equal to y*. It is large errors where there is high uncertainty in the value of prediction itself, whether the present minimum will be lowered or not. It improves the overall accuracy of a surrogate model, and performs the capability of the exploration. Similarly, for DE/current-to-umost, top 50 most uncertain individuals can be obtained according to Eq. (10).Commonly, the value of the EI is predicted by the Kriging model in a famous Efficient Global Optimization (EGO) Jones et al. [5]. Kriging models the response of the response of Y(x) as a realization of a regression model F(x) and a stochastic process Z(x)(11)Y(x)=F(x)+Z(x)(12)F(β,x)=fβ(13)E(Z(w)Z(x))=σ2R(θ,w,x)where β is the regression coefficient, and f is the regression vector. The stochastic process is assumed to follow Gaussian distribution with mean zero, process variance σ2, and correlation model R(θ,w, x) between Z(w) and Z(x) with parameter θ. The output response of Kriging can be predicted at a pointxas(14)y^(x)=Fβ^+rTR−1(y−Fβ^)where F is the matrix of linear equations constructed by the regression function,β^=(FTR−1F)−1FTR−1y, R is the matrix correlation, for given two samples of Design of Experiment (DoE)xi,xj,Rij=R(θ,xi,xj),ris the vector of two given correlations between the samplexgenerated by the DoE, andy=[y1,y2,…,ym]Tis the vector of the m current observations.The Kriging prediction variance can be estimated as(15)s2(x)=σ^2[1+uT(FTR−1F)−1u−rTF−1r]where the estimated process varianceσ^2=(y−Fβ^)R−1(y−Fβ^)m,u=FTR−1r−f,f=[f1,f2,⋯,fm].In the DE, any trail vector is composed of two samples (populations)xi, Gandxj, G. Thus, the center point of a trail vector can be obtained as(16)xcij,G=xi,G−xj,G2.Then, the value ofEI(xcij,G)can be easily obtained by Kriging surrogate model. Because the value of EI criterion should be large when populations are sparsely distributed. Therefore,EI(xcij,G)should be normalized and set to Fidirectly as(17)Fi=EI(xcij,G).Then, Eq. (6) can be rewritten as(18)vi,G=xi,G+wi(EI(xbest,Gs−xi,G2)·(xbest,Gs−xi,G)+EI(xr1,G−xr2,G2)·(xr1,G−xr2,G))+(1−wi)(EI(xmost,Gu−xi,G2)·(xmost,Gu−xi,G)+EI(xr3,G−xr4,G2)i·(xr3,G−xr4,G))HDMR introduced by Rabitz et al. [6] is a general set of quantitative model assessment and analysis tools for recognizing the high dimensional relationships between input variables and output responses. Similar to Taylor expansion, a HDMR expresses a high dimension function as a finite hierarchical correlated function expansion in terms of the input variables, which can efficiently reduce sampling effort for learning the behavior of high dimension systems and intelligently identify the correlated relationship amongst variables. Shorter et al. [7] used the HDMR to build an efficient chemical kinetics solver. Li et al. [9] proposed a HDMR-based random sampling method and developed an approach to approximate its different component functions. Recently, Shan and Wang [21] combined the Radial Basis Function (RBF) with the cut-HDMR for high dimension expensive underlying problems. Wang et al. [22] used Moving Least Square (MLS) as a basis function for the HDMR and applied to high dimensional problems. In this study, because the EI is predicted by the Kriging method, the Kriging-HDMR is utilized to disclose the correlative relationship for given problems.Let the n-dimensional vectorx=[x1,x2,…,xn]T∈Rnwith n which denotes the number of input variables of an underlying problem, and f(x) is the response function. HDMR expresses the response function f(x) as a finite expansion for a given multivariable response function in terms of input variables as(19)f(x)=f0+∑i=1nfi(xi)+∑1<i<j≤nfij(xi,xj)+∑1<i<j<k≤nfijk(xi,xj,xk)+⋯+∑1<i1<⋯<il≤nfi1i2⋯il(xi1,xi2,…,xil)+⋯+f12⋯n(x1,x2,…,xn)where f0 denotes a constant term representing the zeroth order effect to f(x). The function fi(xi) is a first-order term expressing the effect of variable xiacting alone, although generally nonlinear, upon the output response f(x). The function fij(xi, xj) is the second-order term that describes the cooperative effects of the variables xiand xjupon the output response f(x). The higher order terms give the cooperative influences of increasing numbers of input variables acting together to the output f(x). The last termf12…n(x1,x2,…,xn)contains any residual dependence of all input variables correlated together in a cooperative way to influence the output response f(x). Once all relevant component functions in Eq. (19) are determined, component functions constitute a HDMR expansion, thereby replacing the original computationally expensive method of calculating f(x) by a computationally efficient model. For engineering problems, the original Eq. (19) can be simplified such that the HDMR with only low order correlations to second-order among input variables is widely used for representing the behavior of response as(20)f(x)≅f0+∑i=1nfi(xi)+∑1<i≤j≤nfij(xi,xj)In this study, the cut-HDMR based Kriging interpolation procedure is used to construct a surrogate. Using the cut-HDMR method, a cut pointxcis defined in the design space. In the convergence limit, the cut-HDMR is invariant to the choice of cut pointxc. In this study,xcis selected as the center point of Hypercube. Response functions are determined by evaluating the input–output responses of the system relative to the defined cut pointxcalong associated lines, planes, sub volumes, etc. (i.e. cuts) in the input variable space. This procedure reduces to the optimal functions of cut-HDMR in Eq. (19) possess the following form.(21)f0=f(xc),(22)fi(xi)=f(xi,xci)−f0,(23)fij(xi,xj)=f(xi,xj,xcij)−fi(xi)−fj(xj)−f0(24)fij(xi,xj,xk)=f(xi,xj,xk,xcijk)−fij(xi,xj)−fik(xi,xk)−fjk(xj,xk)−fi(xi)−fj(xj)−fk(xk)−f0(25)⋯f12…n(x1,x2,…,xn)=f(x)−f0−∑ifi(xi)−∑ijfij(xi,xj)−∑ijkfijk(xi,xj,xk)−⋯wherexci,xcij,xcijkare respectivelyxwithout terms xi, (xi, xj), and (xi, xj, xk). The higher order terms are evaluated as cuts in the design space through a cut point. Therefore, each first-order term fi(xi) is evaluated along its variable axis through the center point. Each second-order term fij(xi, xj) is evaluated in a plane defined by the binary set of input variables (xi, xj) through the cut point; etc. The procedure of subtracting the lower order expansion functions removes their dependence to assure a unique contribution from the new expansion function. The last term presented as Eq. (24) is determined by the difference between and all other component functions in Eq. (25). Finally, substituting the Kriging expression into the HDMR, a simple expression can be given as follow.(26)f(x)≅f0+∑i=1naiφ(xi,xci)+∑1<i<j≤naijφ(xi,xj,xci)where φ can be obtained by the Kriging interpolation. Considering Cris related with correlative terms. Crcan be updated in each iteration by following(27)Cr=∑aij∑aij+∑i=1naiwhere ∑aijis the sum of all coefficient values of 2-order relative terms,∑i=1naiis sum of all coefficient values of independent terms. According to Eq. (27), the Crused in the suggested algorithm is essentially the proportion of correlative terms. Generally, Crshould be 0 when the function is completely separable, while Cris 1 when the function's parameters are full coupled. Obviously, Eq. (27) is accord with Ronkkonen and Kukkonen [11] deduction.To assess the performance of the suggested method, we have carried out different experiments using a test suite proposed in the CEC2005 special session on real-parameter optimization. The test suite consists of 25 benchmark functions, involving:➢Unimodal functions f1–f5Basic multimodal functions f6–f12Expanded multimodal function f13 and f14Hybrid composition functions f15–f25The details of these test functions can be found in KanGAL report (2005). All functions are tested in 30n and some of test functions are tested in 50n. Considering the limited computational resource, all algorithms in this test are assigned to 6e+04 Number of Function Evaluations (NFEs) and NP is set to 5n. For each algorithm, the mean and STD of the minimum function error values should be given. The number of independent runs for each test is 50. As recommended in CEC2005, the NFEs should be set to 1.0e+04n. However, considering the limited computational cost in practice, the NFEs is set to 6.0e+04 in this test. In our opinion, such setting is more feasible for practical problems, especially for simulation-based problems.Because the suggested method can be categorized as an adaptive DE, 4 popular self-adaptive DE variants, involving jDE, SaDE, JADE and EPSDE are employed to compare the suggested method as: jDE with Flower=0.1, Fupper=0.9 and τ1=τ2=0.1, SaDE, JADE with c=0.1, p=0.05 and Cr=0.9, EPSDE. All tested DE variants start from the same initial populations in each run so that any difference in their performances may be attributed to their internal search operators only. However, because the suggested EI-HDMR-DE uses the HDMR to update Cr, there are additional 60 populations (for 30n problems) and 100 populations (for 50n problems) generated by 2-level FF. As mentioned before, these initial populations should be on the each variable axis and used to construct the initial cut-HDMR model and check the correlative relationships among the design variables.Moreover, as mentioned before, R2 is used to determine whether the surrogate-based evaluation strategy is activated by using the LOOCV. In this test, the R2 is set to 0.9.

@&#CONCLUSIONS@&#
