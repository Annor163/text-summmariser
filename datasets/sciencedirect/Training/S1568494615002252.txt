@&#MAIN-TITLE@&#
A repeating pattern based Query-by-Humming fuzzy system for polyphonic melody retrieval

@&#HIGHLIGHTS@&#
Devising a bar-indexing method to reduce the processing time.Providing an effective strategy to deal with MIDI files.Using repeating pattern as a search index not only saves the database storage space and computing cost, but also raises the accuracy of the system.Proposing fuzzy inference system to raise the capability for fault tolerance and raise the system accuracy.

@&#KEYPHRASES@&#
Fuzzy inference system,Content-based music information retrieval,Query-by-Humming,Repeating pattern,Pitch contour,

@&#ABSTRACT@&#
Query-by-Humming involves retrieving music with a melody that matches the hummed query. An improved Query-by-Humming system for extracting pitch contour information based on a fuzzy inference model is introduced. In addition, an improved content-based music repeating pattern extraction model is introduced. Our bar-indexing method can extract the melody, identify repeating patterns and handle polyphonic MIDI files. To verify the effectiveness of the system, 15 volunteers recorded queries that were fed as input to the system and the longest common subsequence (LCS) was used to identify the most related top N matches. The system achieves 70% accuracy among the top 5 items retrieved.

@&#INTRODUCTION@&#
The Internet is commonly used to search for information such as text, images, video, and music. The capacity of storage devices is growing, and so is the amount of information stored. Multimedia files have become commonplace due to enhanced bandwidth and fast transmission networks. Traditional record shops are replaced with Internet-based pay-per-download and streaming services. The objective of Music Information Retrieval (MIR) is to quickly and correctly find the right contents from a music database. Several music file-formats are commonly used, including MIDI, MP3, Wave, and Voice. MIDI (musical instrument data interface) is a popular format as it contains semantic music information and not the actual audio. Moreover, MIDI files require less storage space than audio data, they are faster to process and therefore result in faster and more accurate query results.Monophonic melodies are more common than polyphonic melodies in music information retrieval systems since most people are only able to sing, hum and whistle monophonically. Furthermore, humans perceive and remember monophonic melodies even though they hear polyphonic music. Therefore, the first task is to extract the main monophonic melody from a polyphonic melody to simplify the query matching.Previous studies have explored several innovative query models, including Query-by-Humming [1â€“7], Query-by-Tapping [8], Query-by-Example [9], Query-by-Tags [10], and Query-by-Descriptions [11]. Query-by-Humming in particular has received much attention. This is probably because humming is a simple, intuitive and direct way for individuals to express music. However, it is more difficult to retrieve music based on humming compared to other approaches.Several approaches translate hummed melodies into MIDI [12] as it simplifies comparison. Several music matching methods have been studied such as Bayesian classifiers [13], hidden Markov models [14,15], string matching [16,17], dynamic programming [18,19], dynamic time warping (DTW) [20,21], and tree based searching [22,23]. However, most of the previous approaches are computationally expensive. Previous research has used repeating patterns as a search index, since a repeating pattern is usually the prominent and recognizable part of a music piece. In such systems, when a user hums a repeating pattern as a query, the query-by-humming system uses this repeating pattern as the search index when searching the music database.This study explores an improved music retrieval method based on humming. First, a method for extracting the perceivable main melody of a complete polyphonic musical piece is described. The output from several existing main melody extraction algorithms are used as input to the system and the one with the highest average pitch is selected. The melodies are coded using more symbols than previous methods and hence more of the musical information is preserved. In addition, fuzzy inference is employed to make the method more robust to the errors that are introduced when the recorded humming audio is converted into semantic music data. The objective of the method is to achieve more accurate retrieval results with less computational effort compared to previous approaches.The remainder of this paper is organized as follows. Section 2 introduces definitions and notations used throughout the paper and previous research is reviewed. Section 3 presents the details of our approach. Section 4 documents the test results. Finally, Section 5 concludes the paper and indicates areas of further study.

@&#CONCLUSIONS@&#
This study introduces an improved content-based music retrieval method that employs a bar-indexing method that reduces the processing time and provides an effective strategy to deal with MIDI files. In addition, the bar-indexing approach is robust to small variation in melody when extracting repeating patterns.An improved pitch interval coding is introduced using seven symbols. We use a fuzzy inference system to transform time intervals of pitch queries into symbolic representations, since input humming queries may contain slight pitch errors, resulting in erroneous notes when translated to MIDI. By using a fuzzy inference, soft membership functions provide more robust classification of these input pitch contour errors. LCS is applied as approximate matching algorithm to locate the top N retrieval results. Experimental evaluation demonstrates that the FIS improves retrieval accuracy.In summary, the advantages of our method are as follows: (1) The method can be applied to complete and polyphonic music, which is useful for the automatic establishment of music databases. (2) The use of repeating patterns as a search index requires less database storage space, require less computation and yield better retrieval accuracy. The repeating pattern of each music composition is easy to remember and thus suitable as a query. (3) The FIS adds fault tolerance and improves to retrieval accuracy.Future work involves increasing the size of the database including other types of music to test system scalability and robustness of the method to other genres of music, improving the audio to MIDI conversion process with improved acoustical analysis algorithms utilizing recent advances in digital signal processing research, and improving the general retrieval accuracy by for instance introducing score-informed constraints and extending the model to include timbre in addition to temporal and chromatic information. Another possibility is to explore whether more musically inclined participants achieve higher retrieval accuracies than less musically inclined participants.