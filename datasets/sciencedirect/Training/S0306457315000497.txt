@&#MAIN-TITLE@&#
Expressive signals in social media languages to improve polarity detection

@&#HIGHLIGHTS@&#
To capture the sentiment of messages, several expressive forms are investigated.Expressive signals enrich the feature space of baseline and ensemble classifiers.Only adjectives play a fundamental role as expressive signal.Pragmatic particles and expressive lengthening could lead to the de finition of erratic polarity classifiers.

@&#KEYPHRASES@&#
Sentiment analysis,Polarity detection,Expressive signals,

@&#ABSTRACT@&#
Social media represents an emerging challenging sector where the natural language expressions of people can be easily reported through blogs and short text messages. This is rapidly creating unique contents of massive dimensions that need to be efficiently and effectively analyzed to create actionable knowledge for decision making processes. A key information that can be grasped from social environments relates to the polarity of text messages. To better capture the sentiment orientation of the messages, several valuable expressive forms could be taken into account. In this paper, three expressive signals – typically used in microblogs – have been explored: (1) adjectives, (2) emoticon, emphatic and onomatopoeic expressions and (3) expressive lengthening. Once a text message has been normalized to better conform social media posts to a canonical language, the considered expressive signals have been used to enrich the feature space and train several baseline and ensemble classifiers aimed at polarity classification. The experimental results show that adjectives are more discriminative and impacting than the other considered expressive signals.

@&#INTRODUCTION@&#
The goal of sentiment analysis is to define automatic tools able to extract subjective information, such as opinions and sentiments from natural language texts, in order to create structured and actionable knowledge to be used by either a decision support system or a decision maker. This issue is usually addressed at document level (Yessenalina et al., 2010), in which the naive assumption is that each document expresses an overall sentiment. When dealing with social media contents coming from microblogs (like Facebook and Twitter), a lower granularity level could be more useful and informative (Jagtap and Pawar, 2013; Zhang et al., 2011). This new kind of virtual communication has led to new types of contents and diffusion models that need to be modeled explicitly starting from the language. The characteristics that distinguish well-formed contents (e.g. reviews) from microblogs messages relate to the use of canonical, coherent and at least paragraph-length pieces of text. However, sentiment analysis on social media leads towards new and more complex scenarios: the sentiment is conveyed in at most two sentence passages often with an informal linguistic register and with non-standard spelling (Eisenstein, 2013). These novel scenarios lead researchers to move from a traditional approach, which solves the sentiment analysis task by using machine learning models (Pang and Lee, 2008), to a communication-oriented paradigm.The first expressive signals that have been considered in the literature to aid the detection of sentiment in a given message are concerned with lexical elements (e.g., adjectives, verbs, adverbs). Pak and Paroubek (2010) investigated the relationships of several part-of-speech (POS) tags with respect to the message subjectivity/objectivity. For instance, interjections and adjectives are relevant indicators of subjective texts, while objective messages contain more common and proper nouns. Once positive and negative texts have been annotated with their part-of-speech tags, the resulting corpus is used to train a sentiment classifier. A further approach that exploits the part-of-speech characteristics is presented in (Kouloumpis et al., 2011), where the combination of n-grams and POS tags shows a significant improvement in detecting the sentiment orientation of messages. In the context of social language processing, the use of emoticons has attracted machine learning researchers for the sentiment classification task (Hogenboom et al., 2013; Liu et al., 2012; Zhao et al., 2012). Emoticons are considered to be handy and reliable indicators of sentiment, and hence could be used either to automatically generate a training corpus or to act as evidence feature to enhance sentiment classification. With regard to expressive lengthening (e.g., “I loooooove you”), not much has been investigated for evaluating its contribution in polarity classification. An exception is (Brody and Diakopoulos, 2011), where the lengthening phenomenon in microblogs has been shown to be strongly associated with subjectivity and sentiment.Inspired by the wide availability of emotional signals in social media and the promising results obtained by our previous contribution (Pozzi, Fersini, Messina and Blanc, 2013), in this paper we investigate the contribution of the most used expressive signals. To the best of our knowledge, no studies consider the combination of adjectives, initialisms for emphatic and onomatopoeic expressions, emoticons and word lengthening as possible additional features able to drive the detection of polarity in online social media. In this paper different contributions are given: (1) the analysis of three main language characteristics of social media language, (2) a text normalization procedure to better conform social media messages to a canonical language, (3) a feature expansion approach to improve polarity detection, (4) an analysis of the impact of the expressive signals studied both independently on each others and jointly in traditional learning models and (5) an analysis of the impact of the expressive signals in ensemble models, which have not been yet investigated in the state of the art. To the best of our knowledge, two main research papers (Fersini et al., 2014; Wang et al., 2014) deal with ensemble learning for sentiment analysis, but the focus is on the classification model instead of the impact of the expressive signals. Experimental results highlight not only the link between the characteristics of social media language with the polarity of the messages, but also their beneficial effects with respect to sentiment classification accuracy when jointly considered.The paper is organized as follows. In Section 2 the main expressive forms in online social media are outlined. In Section 3 the text normalization procedure together with the proposed feature expansion approach are detailed. In Section 4 the baseline classifiers and ensemble methods, used to evaluate the impact of the proposed approach, are presented. In Section 5 the experimental investigation is detailed, while in Section 6 a detailed analysis about the behavior of the classifiers and the role of the expressive signals considered is reported. Finally, in Section 7 conclusions are derived.To better capture the sentiment orientation of the messages, several valuable expressive forms should be taken into account when tackling polarity detection in online social environments. Although microblogs make available several expressive signals, most of them are platform-dependent. For example, Twitter has ‘hashtags’ (words prefixed with the symbol ‘#’) which allow users to easily specify topics and summarize the overall sentiment. Differently from Twitter where posts are plain texts, messages on Google+ and Tumblr can be characterized by formatted text. For instance, the bold style can be used to empathize the sentiment (e.g., ‘The iPhone is so beautiful!’) and the strikethrough (a typographical presentation of words with a horizontal line through their center) can be used to convey humor (i.e. the sentiment orientation can be reversed). People use the strikethrough to look like an edit, as if you were crossing something out on paper, but so it is still readable by people (e.g., That was kinda strikethrough …ehmmm..hilarious:)’).In order to investigate expressive signals that are independent on the platform, this paper focuses on: (1) adjectives, (2) pragmatic particles, such as emoticon, emphatic and onomatopoeic expressions and (3) expressive lengthening. In our investigation, Twitter has been exploited thanks to its availability of data that are public by default: the percentage of public profiles available in Twitter is much higher than other social media. For example, in 2012, just over 11% of Twitter users were using the private profiles, compared to over 53% of Facebook (Dey et al., 2012). This turns Twitter into a gold mine of free data.Adjectives. Adjectives are lexical components that operate on the substructure of a sentence to either describe or modify a given element. In this work, we argue that adjectives are strictly related to positive and negative opinions and therefore could contribute to better detect the sentiment of a given text message. Starting from the idea proposed in (Benamara et al., 2007), our paper is aimed at evaluating the spread of adjectives in online social media and their role in polarity prediction. To this purpose, a Part-Of-Speech tagging has been applied in order to tag each term of a message with respect to its verbal form. Canonical (J), comparative (JJR) and superlative (JJS) adjectives11The used tag set represents a standard for Part-Of-Speech tagging and it has been defined in the Penn Tree Bank Project (released through the Linguistic Data Consortium). See https://www.cis.upenn.edu/treebank/.have been detected and considered as positive (or negative) according to one of the most used lexicon (Hu and Liu, 2004) known as DictHuLiu.22http://www.cs.uic.edu/∼liub/FBS/sentiment-analysis.html.The lexicon is composed of 4783 negative and 2006 positive words. Since online conversational text differs markedly from traditional written genres like newswire, we used a supervised POS tagger33www.ark.cs.cmu.edu/TweetNLP/.proposed by Owoputi et al. (2013) and trained on manually-annotated social media contents.Pragmatic particles. Pragmatic particles, such as emoticons, emphatic and onomatopoeic expressions, represent those linguistic elements typically used on social media to elicit a given message. Emoticons are introduced as expressive, non-verbal components into the written language, mirroring the role played by facial expressions in speech (Walther and DAddario, 2001). Their role is mainly pragmatic: emoticons give a positive or negative sense to written sentences by a visual expression. According to this consideration, we formulate the hypothesis that there exists a relationship between the sentiment orientation of emoticons and messages. In order to corroborate this hypothesis (a descriptive analysis will be subsequently conducted), emoticons have been distinguished in two main categories, i.e. positive and negative. Instances of positive emoticons are ‘:-)’, ‘:)’, ‘=)’, ‘:D’, while examples of negative ones are ‘:-(’, ‘: (’, ‘=(’, ‘; (’.Initialisms for emphatic expressions represent a further pragmatic element used in non-verbal communication in online social media. Although they act as constituent, these emphatic abbreviations play a similar role of emoticons: expressions such as ‘ROFL’ (Rolling On Floor Laughing) clearly represent positive expressions, while abbreviations as ‘BM’ (Bad Manner) denote negative statements.Onomatopoeic expressions in online social media can help to convey emotions: some expressions such as ‘bleh’ and ‘wow’ are clear indicators of negative and positive emotional states and therefore can help to distinguish the polarity of a text message. In order to deal with onomatopoeic forms, a regular expression has been defined to map these text elements to the corresponding sentiment orientation dictionaries (positive and negative).The complete list of pragmatic particles is available as supplementary material.Expressive lengthening. In text-based social media, word styling (as bold, italic and underlining) is not always available and often replaced by some linguistic conventions. Moreover, the informal nature of expressions leads social media users to make use of orthographic styles that are actually close to the spoken language. In this paper, we claim that the commonly observed phenomenon of expressive lengthening (usually known as word lengthening or word stretching) is an indication of emphasis that is strongly associated with subjectivity and sentiment (Brody and Diakopoulos, 2011). These expressive forms, which are specific to informal social communication, are usually denoted by some orthographic conventions that mark important expressions used to help polarity detection.Example 1 [negative]: One. More. Source. C’mon google, just one more #PLEAAASSEEEEETo better capture the positive or negative orientation of a message, also an expressive lengthening should be considered depending on the sentiment. However, in order to identify its polarity, the corresponding canonical (condensed) form need to be extracted. The main problem when addressing word lengthening is the selection of the correct root. For instance consider the term “gooood” that appears in the following two messages:Example 2 [positive]: Thanks togoooodit’s Friday!!!!Example 3 [positive]: The new Oreo cookies are reallygooood!When dealing with sentiment analysis its fundamental to detect the correct root of the lengthened word, to subsequently identify the corresponding polarity. Although some approaches in the literature are aimed at tackling expressive lengthening, they are usually based on strict assumptions that make difficult (uncertain) the association of polarity to the original word. For instance, repeated characters are replaced with a single instance of that letter. With respect to the case reported above, both gooood will be replaced with god originating therefore an error in the subsequent polarity association. For this reason, we decided to consider only the presence of a lengthening without its potential sentiment orientation.The hypothesis underlying this paper is that the main expressive signals mentioned above are strictly related to positive and negative opinions, and therefore could contribute to better detect the polarity of a given text message. In order to corroborate this hypothesis, a preliminary Bayesian analysis is conducted to clarify the relationships between these expressive forms and the sentiment orientation of messages. In order to support our hypothesis that the sentiment orientation of a given expressive signal agrees with the sentiment of the message, conditional probabilities have been computed.In particular, given an expressive form e occurring in a message m and the polarity label setΩ={+,−}(where + stands for positive and−for negative), the conditional probability can be estimated as:(1)P(pol(e∈m)=se∣pol(m)=sm)=I(pol(m)=sm∧pol(e)=se)I(pol(m)=sm),se,sm∈Ωwhere pol( · ) denotes the polarity label and I( · ) is the indicator function. The discussion about the descriptive analysis is based on two benchmarks presented in Section 5.Unlike well-formed documents (e.g., reviews), the writing style and the lexicon of microblogging messages are widely varied. Moreover, messages are often highly ungrammatical, and filled with spelling errors. As reported in Eisenstein (2013), the non-standard spelling on the social media is mainly due to the fast writing of the users, length limits of messages in online microblogs and finally the spread of common illiteracies until they become “the norm”.One approach to deal with language of social media consists in conforming the texts to a canonical language. For this purpose, we captured a set of patterns using dictionaries a priori defined and regular expressions (REGEX). The text normalization approach includes:•URL removal: URLs do not provide valuable information for the sentiment analysis task. To this purpose, all the tokens matching the REGEX (https?∣ftp∣file)://[-a-zA-Z0-9+&@#/%?=∼_∣!:,.;]∗[-a-zA-Z0-9+&@ #/%=∼_∣] have been removed;Sharing symbols elimination: most of the social media provide specific tools that allow users to share as much as possible their messages (e.g., Hashtags, Mention and Retweet on Twitter). Analogously to URLs, all the symbols related to the sharing tools have been removed because ineffective with respect to polarity detection;Spell-Checker: messages in online social media are often highly ungrammatical and filled with spelling errors. In order to overcome this issue, misspelled tokens have been corrected using the Google’s Spell Checker API.44https://code.google.com/p/google-api-spelling-java/.Since the Google’s algorithm takes the neighborhood (context) of a misspelled token into account in suggesting the correction, the whole previously filtered tweet is considered as a query rather than the single token55The spell checking is performed later than the identification of expressive lengthening.;Slang correction: in order to aggregate terms with the same meaning but represented with different slangs, a dictionary66http://www.chatslang.com/terms/social_media.of a priori defined slang expressions with their meaning, such as ‘btw’ (by the way), ‘thx’ (thanks), ‘any1’ (anyone) and u (you) has been used (Balahur et al., 2014).Most of the works on sentiment analysis have relied on machine learning approaches: by using a bag of words representation, the main goal is to learn a positive/negative classifier based on given weights associated to the words in the text. According to these strategies, the traditional feature vector representing a message m (used to train a given classifier) only includes terms that belong to a common vocabulary V of terms derived from a message collection:(2)m→=(wt1,wt2,⋯,wt∣V∣,class)where wtidenotes the weight of term i belonging to the message m.Less effort has been devoted to enrich the feature space used by the learning machines: to the best of our knowledge no studies consider the combination of adjectives, initialisms for emphatic and onomatopoeic expressions, emoticons and word lengthening as a set of possible additional features used to improve polarity detection.To this purpose, we propose to enhance the traditional feature vector by including indications about the expressive signals previously introduced. The novel feature vector of a message m is defined as:(3)m→new=(wt1,wt2,⋯,wt∣V∣,p+,p−,a+,a−,l,class)where psrepresents the pragmatic elements (emoticons, initialisms for emphatic and onomatopoeic expressions) with polaritys∈{+,−},asdenotes the adjectives with polarity s, l denotes the expressive lengthening and class is the ground truth polarity.In this section a brief overview of the traditional machine learning approaches used for polarity detection is given. In the following, Multinomial Naïve Bayes, Decision Tree, Support Vector Machines and Bayesian Networks are presented.Multinomial Naïve Bayes. Multinomial Naïve Bayes (MNB) is a classifier often used for text categorization. Givenxk,0.15em0exk=1,2,⋯,Kbe the k-th training vector and ykis the corresponding label such thatyk∈{1,2,⋯,Y}, its main goal is to compute the model probability as:(4)P(yk∣xk1,⋯,xkn)=P(Hi)P(xk1,⋯,xkn∣yk,∑jxkj)This probability model is based on the assumption that the sample length and the class hypothesis are marginally independent.Regarding polarity classification, the approach has been investigated in Pang et al. (2002), Pang and Lee (2004) and Go et al. (2009).Support Vector Machines. Support Vector Machines (SVMs) are learning machines that try to find the optimal hyperplane discriminating samples of different classes (Cortes and Vapnik, 1995). A good separation is achieved by the hyperplane that has the largest distance to the nearest training data point of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier. In this paper, we exploited the probabilistic extension of the original SVMs (Hastie and Tibshirani, 1998).The main goal is to estimate(5)py=P(yk=y∣xk)We first estimate pairwise class probabilities following the setting of the one-against-one approach for multi-class classification(6)τyy′≈P(yk=y∣yk=y0.35em0exor0.35em0exy′,xk),1em0exy′=1,2,⋯,K,1em0exy0.25em0ex≠0.25em0exy′After collecting all pairwiseτyy′values, the following optimization problem has been solved:(7)APTARANORMALminp1em0ex12∑y=1Y∑y′:y′≠y(τy′ypy−τyy′py′)2(8)subjectto1em0expy≥0,∀y,1em0ex∑y=1Ypy=1Regarding polarity classification, Support Vector Machines have been investigated in (Go et al., 2009; Pang and Lee, 2004; Pang et al., 2002).Decision Trees. Decision Trees (DT) are classifiers presented as binary tree-like structure, where each node corresponds to a variable and edges represents possible realization of that variable. Given a samplexk=(xk1,⋯,xkn), leaf nodes correspond to the possible class hypothesis yk. The main goal of Decision Trees is to build a model of the class hypotheses based on the observed attributes of training data. Since this classifier outputs a dichotomic decision tree, it can be used to determine the class label of unclassified sample by considering its descriptive attribute realizations. Building a decision tree model from a training dataset involves two phases. In the first phase, a splitting attribute and a split index are chosen. The second phase involves splitting the records among the child nodes based on the decision made in the first phase. For evaluating whether a node should be splitted or not, the Entropy Deviance (Aha et al., 1991) measure has been used.Regarding polarity classification, Decision Trees have been investigated in Bifet and Frank (2010) and Jia et al. (2009).Bayesian Networks. Bayesian Networks (BN) are probabilistic graphical models that compactly represent the joint probability distribution of n random variables. The main assumption, captured graphically by a dependency structure, is that each variable is directly influenced by only few others. A probability distribution is represented as a directed acyclic graph (DAG) whose nodes represent random variables and whose edges denote direct dependencies between a nodehk={xk∪yk}and its set of parents Pa(hk). Formally, a Bayesian Network asserts that each node is conditional independent of its non-descendants given its parents. Given n features, the joint probability distribution can be decomposed as:(9)P(hk1,⋯,hkn)=∏j=1nP(hkj∣hk1,⋯,hkj−1)=∏j=1nP(hkj∣Pa(hkj))whereP(hkj∣Pa(hkj))is described by a conditional probability distribution (CPD).Regarding polarity classification, Bayesian Networks have been investigated in Bai (2011) and Airoldi et al. (2006).Given a space of possible models, classical statistical inference selects the single model with the highest likelihood given the training data and uses it to make predictions. This may lead to over-confident inferences and decisions that do not take into account the inherent uncertainty of the natural language in wider context as social media. Instead, the idea behind a ensemble mechanism is to exploit the characteristics of several independent classifiers by combining them in order to achieve higher performance than the best single classifier. In order to understand whether the typical social media expressive signals have an impact on several learning schemes, also the main ensemble approaches have been considered.Regarding polarity classification, various ensamble approaches have been investigated in Whitehead and Yaeger (2010), Xia et al. (2011), Hassan et al. (2013) and Wang et al. (2014).Majority Voting. One of the most popular ensemble system is Majority Voting (MV), which is characterized by a set of “experts” that classifies the message polarity by considering the vote of each classifier as equally important and determines the final polarity by selecting the most popular label prediction (Dietterich, 2002). Let C be a set of independent classifiers and poli(m) the label assigned to a message m by classifier i ∈ C. Then, the optimal label polMV(m) is assigned as follows:(10)polMV(m)={argmaxsm∑i∈CI(poli(m)=sm)if∑i∈CI(poli(m)=sm)>∑i∈CI(poli(m)=sm′)∀sm′0.25em0ex≠0.25em0exsm∈Ωpol^(m)otherwisewhere I( · ) is the indicator function, Ω is the set of labels andpol^(m)is the label assigned to m by the “most expert” classifier, i.e. the classifier that is able to ensure the highest accuracy.Bayesian Model Averaging. The most important limit introduced by Majority Voting is that the models to be included in the ensemble have uniform distributed weights regardless their reliability. However, the uncertainty left by data and models can be filtered by considering the Bayesian paradigm. In particular, through Bayesian Model Averaging (BMA) all possible models in the hypothesis space could be used when making predictions, considering their marginal prediction capabilities and their reliabilities:(11)P(pol(m)∣C,D)=∑i∈CP(pol(m)∣i,D)P(i∣D)whereP(pol(m)∣i,D)is the marginal distribution of the label predicted by classifier i andP(i∣D)denotes the posterior probability of model i. The posteriorP(i∣D)can be computed as:(12)P(i∣D)=P(D∣i)P(i)∑j∈C0.12em0exP(D∣j)P(j)where P(i) is the prior probability of i andP(D∣i)is the model likelihood. In Eq. (12),∑j∈CP(D∣j)P(j)is assumed to be a constant and therefore can be omitted. Therefore, BMA assigns the label polBMA(m) to m according to the following decision rule:(13)polBMA(m)=argAPTARANORMALmaxpol(m)P(pol(m)∣C,D)=argAPTARANORMALmaxpol(m)∑i∈CP(pol(m)∣i,D)P(i∣D)=argAPTARANORMALmaxpol(m)∑i∈CP(pol(m)∣i,D)P(D∣i)P(i)The implicit measureP(D∣i)can be easily replaced by an explicit estimate, known as F1-measure, obtained during a preliminary evaluation of the classifier i. In particular, by performing a cross validation, each classifier can produce an averaged measure stating how well a learning machine generalizes to unseen data. Considering ϕ-folds for cross validating a classifier i, the measureP(D∣i)can be approximated as(14)P(D∣i)≈1ι∑ι=1ϕ2×Piι(D)×Riι(D)Piι(D)+Riι(D)wherePiι(D)andRiι(D)denotes precision and recall obtained by classifier i at fold ι. The measureP(D∣i)can be estimated both for positive and negative polarities. In this way P(l(m)∣i, D) Eq. (13) is tuned according to the ability of the classifier to fit the training data. This approach allows the uncertainty of each classifier to be taken into account, avoiding over-confident inferences. For more details on BMA for polarity detection, please refer to (Pozzi, Fersini and Messina, 2013; Fersini et al., 2014).In order to verify whether the proposed normalization techniques and feature expansion improve polarity detection, three benchmark datasets have been considered: Gold Standard Movie, Gold Standard Person (Chen et al., 2012) and SemEval 2013 - Task 2.77http://www.cs.york.ac.uk/semeval-2013/task2/(Nakov et al., 2013).Gold Standard Movie and Person contain respectively 1500 manually labeled Twitter data. Although the original dataset is composed of 3 different polarities (POS, NEG and NEU), a reduction of instances has been performed in order to deal only with positive and negative opinions. The resulting datasets are therefore unbalanced: Person is composed of 105 ( ≃ 26.44%) negative and 292 ( ≃ 73.56%) positive opinions, while Movie includes 96 ( ≃ 18.6%) negative and 420 ( ≃ 81.4%) positive orientations. The SemEval benchmark is composed of 4922 manually labeled tweets, 3474 ( ≃ 70.58%) positive and 1448 ( ≃ 29.41%) negative.Concerning the traditional baseline classifiers (also enclosed in the ensembles), WEKA toolkit has been used, while BMA and MV have been developed from scratch. Regarding the classifier configurations, probabilistic SVMs have been trained with linear kernel (with cost parameter equal to 1.0 and tolerance to misclassification equal to 0.0010). K2 search algorithm has been exploited to learn the structure of the Bayesian Network. For Decision Trees, C4.5 (J48 in Weka) has been adopted while for Multinomial Naive Bayes no particular setting is required. In order to evaluate the performance achieved by the investigated approaches, a 10-folds cross validation has been adopted.As performance evaluation, we employed the classical state-of-the-art measure for classification known as Precision (P), Recall (R) and F1-measure (Zaki and Meira, 2014). In particular, in order to directly compare the ensemble learning techniques with the baseline classifiers, we employed accuracy:(15)Acc=#0.35em0exofmessagessuccessfullypredictedtotal0.35em0ex#0.35em0exofmessagges

@&#CONCLUSIONS@&#
In this paper, three valuable expressive signals have been explored for sentiment classification purposes. The role and impact of adjectives, pragmatic particles and expressive lengthening have been investigated on two benchmark datasets. The experimental results show that, although adjectives give the highest contribution in polarity detection, jointly considering all the proposed features leads to promising results. There are many potential future extensions of this work. It would be interesting to investigate the contributions of additional expressive signals that could be grasped from social media, such as repeated exclamation marks and the use of upper-words. Emoji and symbols related to sharing tools could be also useful sentiment information. Concerning emoji, which are platform/plugin dependent and implemented as their own character set, specific decoding processes (Suttles and Ide, 2013) will be implemented in order to deal with tweets that might contain Android/iPhone-specific emojis. In order to deal with this kind of information (e.g. hashtags), which are typically provided as a single token although they contain multiple words (e.g. #greatstart), the approach presented in Maynard and Greenwood (2014) could be exploited. A more challenging ongoing research relates to a communication-oriented paradigm to better model the user-generated contents in online social media. In addition to lexical information, cues about the language style (formal, informal and semi-formal) and the subjectivity/objectivity of the message should be considered as a gold mine. A final interesting aspect relates to the explicit modeling of non-literal meaning Reyes et al. (2013), such as irony and sarcasm, for a better modeling of polarity classification in real world environments. In this context, the role of most of the expressive signals needs to be deeply investigated.Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.ipm.2015.04.004.