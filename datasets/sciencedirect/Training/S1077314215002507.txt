@&#MAIN-TITLE@&#
Primary object discovery and segmentation in videos via graph-based transductive inference

@&#HIGHLIGHTS@&#
We propose an efficient graph transduction process that detects recurring primary objects and learns cohort object proposals over space-time in video, by exploiting both appearance cues learned from rudimentary detections of object-like regions, and the intrinsic structures within video data.We develop a robust object segmentation method against the changes in appearance, shape and occlusion in challenging videos which is underpinned by this set of rich descriptions from graph transductive inference.We present extensive experiments on challenging datasets that demonstrate the superior performance of our approach compared with the state-of-the-art methods.

@&#KEYPHRASES@&#
Graph-based transductive inference,Video object segmentation,Object proposal,

@&#ABSTRACT@&#
The proliferation of video data makes it imperative to develop automatic approaches that semantically analyze and summarize the ever-growing massive visual data. As opposed to existing approaches built on still images, we propose an algorithm that detects recurring primary object and learns cohort object proposals over space-time in video. Our core contribution is a graph transduction process that exploits both appearance cues learned from rudimentary detections of object-like regions, and the intrinsic structures within video data. By exploiting the fact that rudimentary detections of recurring objects in video, despite appearance variation and sporadity of detection, collectively describe the primary object, we are able to learn a holistic model given a small set of object-like regions. This prior knowledge of the recurring primary object can be propagated to the rest of the video to generate a diverse set of object proposals in all frames, incorporating both spatial and temporal cues. This set of rich descriptions underpins a robust object segmentation method against the changes in appearance, shape and occlusion in natural videos. We present extensive experiments on challenging datasets that demonstrate the superior performance of our approach compared with the state-of-the-art methods.

@&#INTRODUCTION@&#
Segmenting object from video remains an open challenge with recent advances relying upon prior knowledge supplied via interactive initialization or correction [1–6]. Yet fully automatic video object discovery and segmentation [7–12] remains useful in scenarios where the human in the loop is impractical, such as video summarization or ingest pre-processing for video indexing or recognition. This is a very challenging task due to the lack of prior knowledge about object appearance, shape or position. Furthermore, variance in illumination and occlusion relationships introduce ambiguities that in turn induce instability in boundaries and the potential for localized under- or over-segmentation.This paper proposes a novel automatic primary video object discovery and segmentation algorithm in which the segmentation of each frame is driven by set of rich object models learned from spatio-temporally dense and coherent object proposals. Following [9–14], the primary video object refers to the object that presents saliently, in terms of either appearance or motion, in most of the frames. The core novel contribution is our graph transduction approach to the efficient learning of the dense video object proposals which enables the detection and segmentation of objects in complex dynamic scenes without suffering from appearance variation or object occlusion over time. In contrast to previous techniques, our algorithm learns and extracts object proposals from scratch to account for the evolution of object’s appearance, shape and location with time, as opposed to selecting from existing per-frame detections of object-like regions [9–13].Our strategy is to create feature-based rudimentary detections of regions for the primary object by learning from weakly labelled examples of object-like regions. These detections serve as informative indicators of the appearance and location of the object. We propagate this learned prior knowledge on an undirected space-time graph consisting of regions, solving the transduction learning efficiently with a fast convergence technique [15]. Inference at the region level further makes our dense video object proposal extraction approach a practical solution for automatic object segmentation on natural video sequences.We describe our proposed video object proposal algorithm in Section 3, presenting the utilization of video object proposals for robust video object segmentation in Section 4. In Section 6, we evaluate our video object proposal and segmentation approach on benchmark dataset and additional dataset comprising challenging video clips exhibiting clutter, occlusion and agile motion, comparing against state-of-the-art semi-automatic and automatic algorithms.

@&#CONCLUSIONS@&#
