@&#MAIN-TITLE@&#
Precise localization of eye centers in low resolution color images

@&#HIGHLIGHTS@&#
Use of color information for accurately localizing eye centers.Statistical analysis of the color distribution of the skin, eye areas and irises.Radial symmetry computation both in grayscale images and in chrominance eye maps.We report high accuracy rates for low resolution color images.

@&#KEYPHRASES@&#
Eye localization,Eye detection,Facial feature detection,Radial symmetry,

@&#ABSTRACT@&#
The localization of eye centers and tracking of gaze constitutes an integral component of many human–computer interaction applications. A number of constraints including intrusiveness, mobility, robustness and high-price of eye tracking systems have hindered the way of the integration of eye trackers in everyday applications. Several ‘passive’ systems based on a single camera have been lately proposed in the literature, exhibiting though subordinate precision compared to the commercial, hardware-based eye tracking devices. In this paper we introduce an automatic, non-intrusive method for precise eye center localization in low resolution images, acquired from single low-cost cameras. To this end, the proposed system uses color information to derive a novel eye map that emphasizes the iris area and a radial symmetry transform which operates both on the original eye images and the eye map. The performance of the proposed method is extensively evaluated on four publicly available databases containing low resolution images and videos. Experimental results demonstrate great accuracy in challenging cases and resilience to pose and illumination variations, achieving significant improvement over existing methods.

@&#INTRODUCTION@&#
Eyes represent the most distinctive features of the human face, while their position and movements are a significant source of information about the cognitive and affective state of human beings; eyes hold a key role in expressing interest, intention and attention. Precise eye center localization constitutes the cornerstone for gaze monitoring and can be applied in an ever increasing range of applications [1]. These include face alignment and normalization, liveness detection (e.g. for security applications), non-glasses type 3D technologies, monitoring of drivers' attention and vigilance, visual attention analysis (e.g. for marketing purposes), attentive human–computer interaction (HCI) interfaces and interactive gaze-based interfaces for disabled people.Although many commercial, off-the-shelf products for eye detection and tracking are available in the market, they all require dedicated, high-priced hardware. The most common approaches in research and commercial systems use active infrared (IR) illumination, to obtain accurate eye location through corneal reflection [2,3]. Although these approaches yield high-precision localization, their intrusiveness is controversial and they cannot be used outdoors, in daytime applications, due to ambient infrared illumination. Other hardware approaches require the use of special equipment such as contact lenses, special helmets and electrodes [4,5], causing discomfort to the users and introducing limitations, thus rendering them cumbersome for everyday applications. Algorithmic approaches constitute non-intrusive techniques which can be incorporated in many applications where the use of extra dedicated hardware is impracticable.Despite active research in the field, eye center localization with high precision from completely unobtrusive and remotely located (i.e. not requiring special helmets, glasses or chin rests) image-based systems, remains a very challenging task. Eyes present great variability in shape and color depending on eye state (open/closed or anything in between), iris direction, facial expression, head pose and ethnicity. Occlusions caused by hair, glasses, reflections, shadows or pose (self-occlusions) make the localization process notably difficult. Furthermore, imaging conditions such as lighting, contrast, camera characteristics and further processing (e.g. compression) have a strong influence on how eyes appear in the image. The localization process becomes even more challenging when dealing with low resolution images derived from inexpensive imaging devices such as webcams, mobile devices or pinhole cameras.In this paper, a fast, fully automatic method for accurate eye center localization in low resolution images and videos is presented. The goal of the proposed system is to locate eye centers accurately and robustly for HCI applications, reporting accuracies comparable to the commercial hardware-based eye trackers, with the use of a single low-cost camera.The layout of the paper is organized as follows. In Section 2, a literature review in the area of eye localization is presented. In Section 3 a detailed description of the proposed algorithm is given. Section 4 presents the experimental setup and Section 5 the results obtained using the proposed algorithm, compared with the state-of-the-art systems for eye localization. The concluding Sections 6 and 7 report implications and inferences of the work presented in this paper.

@&#CONCLUSIONS@&#
In this paper we proposed a new, fully automated method for precise eye center localization, exploiting radial symmetry and color information. Our system constitutes a non-intrusive method based solely on a single low-cost camera. It combines simplicity with high precision, providing accurate localization, robustly tackling challenging scenarios of partial occlusions, illumination and pose variations.An extensive evaluation of the proposed approach was performed on low resolution images and videos, containing many different cases of challenging conditions. A comparison with existing systems demonstrated a significant improvement in performance, especially for very accurate eye center localization. Given the high accuracy rates achieved by the proposed method, we believe that our system can represent a very promising low-cost alternative for everyday HCI applications.In view of building statistical color models for the eye regions and the irises, experiments were performed using the MUCT database [52]. The MUCT database was selected as it provides great diversity in illumination conditions and subjects' ethnicity. Moreover, it is meticulously landmarked and thus different facial regions can be accurately pinpointed.To build the color model of the eyes we first transformed the image in the YCbCr color space and extracted the points located inside the polygons that enclose both eye regions. From these points the mean value for each of the YCbCr channels was calculated. In a corresponding manner, in order to build the skin model, the skin patch under and between the eyes was considered (surrounding skin area) and the mean value was calculated. As a result, 3755 values, one for each image in the database, were collected to build each of the models.In order to model the tone distribution of the irises, only the iris region out of the delineated eye region was retained, discarding the sclera regions (the white parts of the eye). The resulting color models for the eye areas and the irises are presented in Figs. 3 and 4, respectively.