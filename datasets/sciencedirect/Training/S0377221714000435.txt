@&#MAIN-TITLE@&#
Nonsmooth multiobjective programming with quasi-Newton methods

@&#HIGHLIGHTS@&#
A nonsmooth quasi-Newton algorithm is proposed for solving nonsmooth multiple objective programming.A tractable subproblem is solved to obtain the descent direction.The global and local convergence results for the new algorithm are presented under reasonable assumptions.The efficiency of the new algorithm is shown by a numerical example.

@&#KEYPHRASES@&#
Multiobjective programming,Pareto optimality,Critical point,Quasi-Newton methods,

@&#ABSTRACT@&#
This paper proposes a new algorithm to solve nonsmooth multiobjective programming. The algorithm is a descent direction method to obtain the critical point (a necessary condition for Pareto optimality). We analyze both global and local convergence results under some assumptions. Numerical tests are also given.

@&#INTRODUCTION@&#
In reality, many problems posed for solution can be formulated as multiobjective programming which have multiple conflicting objectives (see, Das & Dennis, 1998; Handi, Kell, & Knowles, 2007). For example, consider the integration of noisy data from multiple sources using a multiple source integration technique. While a single-objective optimization is often used in this setting, rather than viewing the data as from a single information source, multiple noisy analysis of the data can yield better results if properly formulated as a multiobjective programming problem with a set of objective functions of the formF(x)=F̲(x)+G̲, i.e.,(1.1)F1(x)=F̲1(x)+G1⋮Fm(x)=F̲m(x)+Gm,whereF=(F1,…,Fm)T∈Rm,F̲=(F̲1,…,F̲m)T∈Rm,G̲=(G1,…,Gm)T∈Rm, the function value of each objective functionFj,j∈{1,…,m}can be expressed as the sum of the value of an ideal functionF̲jand some random noiseGjon it.Many algorithms have been proposed for solving multiobjective programming, but only a few deal with a nonsmooth setting. The reason is mainly because it is difficult to obtain the first and second order conditions on the nonsmooth objective functions. Qu, Goh, and Chan (2011) presented a quasi-Newton method to get the critical point of the smooth multiobjective programming. This paper extends this method to solve nonsmooth multiobjective programming in which the directional derivative of every objective function exists. Further, we propose a nonsmooth version of the quasi-Newton method for finding the critical point of the multiobjective program.There are two solution approaches for solving multiobjective programming. One is the scalarization approach, i.e., by some scalarization procedure one or several equivalent parameterized single objective problems are solved and the corresponding number of Pareto optimal points are obtained (see Das & Dennis, 1998). However, the scalarized problems may lead to scalar optimization problems that are more complicated than the individual optimization of the original objectives (see Donoso & Fabregat, 2007). Another drawback of this approach, as shown in the applications, is that the parameters are not known in advance and a modeler has to choose them.The other approach is the non-scalarization method. In the method, based on a non-efficient solution, a Pareto optimal point that dominates the non-dominated solution is generated. Recently, to compute a point satisfying the first-order conditions for Pareto optimality which is defined as a critical or stationary point, descent-type methods have been extensively proposed to solving multiobjective programming that do not rely on scalarization approaches (see Fliege, Grana drummond, & Svaiter, 2009; Vieira, Takahashi, & Saldnha, 2012). At every iteration, these methods have two features: (i) A descent direction is generated by solving a tractable subproblem; (ii) Along the obtained direction, in order to find a feasible point that dominates the current one, a line search method is conducted. As a generalization of these ideas, Qu et al. (2011) presented a quasi-Newton method to get the critical point of the smooth nonconvex multiobjective programming. This generation has the following features: (i) By using a quasi-Newton update, the computation of a Hessian matrix is unnecessary; (ii) For the global convergence analysis, it does not require the convex assumption. However, these methods are solution methods for smooth multiobjective programming. Qu, Goh, and Liang (2013) also extended the classical trust-region method for real-valued minimization to solve nonsmooth multiobjective programming where only the standard directional derivative of each objective can be guaranteed. In addition, since the submission of our paper, Neto, Silva, Ferreira, and Lopes (2013) have recently presented a subgradient method for solving quasiconvex nondifferentiable unconstrained multiobjective programming by extending the classical subgradient method for real-valued minimization to a multiple objective case. These two methods are in contrast to our methods of extending the classical quasi-Newton method to solving nonsmooth multiobjective programming. Qu, Goh, and Liang (2013) and Neto et al. (2013) extended the classical trust-region method and subgradient method for the real-valued minimization to multiple objective cases, respectively. However they offered no numerical tests for solving nonsmooth multiobjective programming.In this paper, we extend the quasi-Newton method proposed by Qu et al. (2011) to a nonsmooth case and present a new algorithm to compute the critical point of nonsmooth multiobjective programming under non-convexity. This work uses the nonsmooth quasi-Newton method to approximate second-order information of each objective function, although the second order derivatives may not exist. At each iteration, the descent direction is obtained by solving a linear programming subproblem with convex quadratic constraints. This subproblem improves the performance by constraining the descent direction norms with an small positive scalar which can control the descent direction approaching zero. For the new algorithm, we establish a global convergence result under suitable assumptions. The superlinear convergence result is also presented. A numerical example is given and the performance comparison of our method with the subgradient method and scalarization approach is reported to show the efficiency of the proposed algorithm.We organize the rest of this paper as follows. Section 2 presents some preliminaries and analyzes the relationship between criticality and descent direction for a smooth case. Section 3 considers nonsmooth multiobjective programming in which the objective functions are locally Lipschitzian. At x we use functionsϕj(·,·):Rn×Rn→Rand12dTBj(x)dto approximate first-order and second-order information ofFj(x), respectively, although the first and second order derivatives ofFjmay not exist. In Section 4, under standard assumptions, the global convergence of the new method is proved and the superlinear convergence of the new method is prensented. A numerical test is carried out in Section 5 to show the efficiency of the new algorithm.We now introduce some notations. R is the set of real numbers;R+denotes the set of non-negative real numbers andR++is the set of strictly positive real numbers; DefineR+m=R+×⋯×R+︸m;R++m=R++×⋯×R++︸m;-R++m={-v:v∈R++m};For anyu,v∈Rm, denoteu⩽v⇔v-u∈R+m⇔vj-uj⩾0,j∈I;u<v⇔v-u∈R++m⇔vj-uj>0,j∈I.Given any open setX⊂Rn,Fis a k-times continuously differentiable function from X toRm, i.e.,F∈Ck(X,Rm)fork=1,2. For anyF=(Fj)m×1∈C2(X,Rm)andx∈X,DF(x)∈Rm×n,∇Fj(x)∈Rnand∇2Fj(x)∈Rn×nare the Jacobian of the function F at x, the gradient and the Hessian matrix ofFjat x, respectively; As introduced, the symbolF∈C1,1is used analogously, whileF∈C0,1means that F is locally Lipschitz.DF(x)andD2F(x)denote the Jacobian matrix and Hessian matrix, respectively, if they exist. For anyF∈C0,1(Rn,Rm), the classic directional derivative of F at x in direction d is defined as(2.1)F′(x;d)≔limα↓0F(x+αd)-F(x)α.The Clarke derivative (generalized Jacobian) of F at x is defined as(2.2)∂F(x)≔convA|A=limk→∞DF(xk),for some{xk}⊂{ΘF:xk→x}, whereΘhis the set of all points for which F is Fréchet differentiable (see Clark, 1983). If F is Fréchet differentiable at x, then∂F(x)=DF(x);R(∂F(x))denotes the range or image space of the generalized Jacobian of the function F at x.x∉Ximplies that x is not in X. Define the index set byI={1,…,m}. Unless explicitly mentioned,‖·‖represents both the Euclidean norm inRnand the induced operator norms on the corresponding matrix spaces; LetO(·)ando(·)be the infinitesimal of higher and lower orders respectively.In this paper, we consider the following unconstrained nonsmooth multiobjective programming(2.3)minx∈RnF(x),whereF=(F1,…,Fm)T:X→RmandX⊆Rnis the domain of F which is assumed to be open.Since no unique solution which minimizes all objective functions simultaneously exists, we must decide which objective to improve. Hence the concept of optimality has to be replaced by the concept of Pareto optimality or efficiency, as explained below:Definition 2.1Givenx∗∈X,(i)x∗is a globally efficient point or Pareto optimum of F iff there does not existx∈Xs.t.F(x)⩽F(x∗),andF(x)≠F(x∗);x∗is weakly efficient or a weak Pareto optimum of F iff does not existx∈Xsuch thatF(x)<F(x∗);x∗is locally efficient or locally weakly efficient of F iff there exists a neighborhoodV⊂Xsuch thatx∗is efficient or weakly efficient for F restricted to V.These definitions have been extensive used, for example Qu, Goh, and Liang (2013), Qu, Goh, Wu, and Souza (2013) and Vieira et al. (2012). Note that if X is convex and F isRm-convex (i.e., if F is componentwise-convex), then local Pareto optimality is equivalent to global Pateto optimality. However, in non-convex situations, the equivalence is invalid and a necessary (but in general not sufficient) condition for Pareto optimality is defined as follows. (See Qu et al. (2011), Fliege et al. (2009) and Vieira et al. (2012) for a descent-type algorithm for multiobjective programming).(i)x∗∈Xis a critical point (or stationary point) for F, if(2.4)R(∂F(x∗))∩(-R++m)=∅.Assume that a directional derivative of the corresponding componentwise functionFjin direction d exists. Thend∈Rnis a descent direction for F at x if for anyj∈I, the directional derivative of the corresponding componentwise functionFjin direction d satisfies the following condition:(2.5)Fj′(x;d)<0,where the directional derivative at x in the direction d is defined as (2.1).In general, for a smooth case, i.e., whenF∈C1(X,Rm), efficiency is not equivalent to criticality. They are related as follows, which is presented by Fliege et al. (2009):(i)Ifx∗∈Xis a locally weak Pareto optimum, thenx∗is a critical point for F.If X is convex, F isRm-convex andx∗∈Xis critical on F, thenx∗is weak Pareto optimal.If X is convex,F∈C2(X,Rm), for anyj∈Iandx∈X,∇2Fj(x)is positive definite and ifx∗∈Xis critical on F, thenx∗is Pareto optimal.Statement (i) implies that a point critical on F is necessary for a locally weak Pareto optimum and statement (iii) means that only under some assumption of strict convexity, criticality is equivalent to locally weak Pareto optimality.Section 3 considers a solution of the critical point to nonsmooth multiobjective programming (2.1) by using a nonsmooth version of the quasi-Newton method, whereF:X→Rmis supposed to be locally Lipschitzian, i.e.,F∈C0,1(X,Rm).From Definition 2.2(i), ifx∗∈Xis critical on F, then there does not exist a descent direction atx∗. We now make an assumption to guarantee the existence of the standard directional derivative.A 3.1For anyx∈Xandd∈Rn, supposelimUj∈∂Fj(x+αd),α↓0{UjTd},∀j∈Iexists.Under this assumption, we have the following conclusion about a critical point.UnderAssumption 3.1, ifx∗∈Xis critical on F, then there is no descent direction for an objective function without worsening of another objective function, i.e., ifd¯is a descent direction forFj0atx∗, then there is at least onej1=j1(d¯)s.t.Fj1′(x∗;d¯)⩾0.It follows from 3.1 and Proposition 2.1 of Qi and Sun (1993), that the standard directional derivativeFj′(x;d)exists and is equal to the limit in 3.1, i.e.,Fj′(x;d)=limUj∈∂Fj(x+αd),α↓0{UjTd},∀j∈I. Then from (2.4) that ifx∗∈Xis critical on F andd¯is a descent direction forFj0atx∗, then there is at least onej1=j1(d¯)s.t.Fj1′(x∗;d¯)⩾0. Otherwise, ifd¯is a descent direction for each functionFjatx∗, then from 3.1Fj′(x;d¯)<0,∀j∈I. Therefore (2.4) is not true, which contradicts thatx∗∈Xis critical on F. This contradiction implies that the conclusion holds. □By Lemma 3.1, a critical point implies that there is no descent direction for all componentwise objective functions. Extending this argument to a general case, we have the following Lemma 3.2.Lemma 3.2UnderAssumption 3.1,x∗∈Xis critical on F iff one of the following two conditions is satisfied: there exists at least onej0=j0(d)∈Is.t.(i)there does not exist a descent direction atx∗forFj0, i.e.,Fj0′(x∗;d)⩾0,∀d;in the special case, there exists at least onej0∈Isuch that0∈∂Fj0(x∗).Ifx∗∈Xis critical for F, then from Definition 2.2(i), (ii) is true. Similar with the proof of Lemma 3.1,Fj′(x;d)=limUj∈∂Fj(x+αd),α↓0{UjTd},∀j∈I. Then from (2.4) that ifx∗∈Xis critical on F, there exists at least onej0=j0(d)∈Isuch thatFj0′(x∗;d)⩾0.However, if either (i) or (ii) or both hold, then from Definition 2.2(i) and the assumption in this Lemma,x∗is critical on F. □1.By Lemma 3.2, a critical point implies that there is no descent direction for at least one componentwise objective function or in the special case, it is a stationary point for at least one componentwise objective function. In this paper, we propose a solution approach satisfying statement (i) of Lemma 3.2, i.e., the search stops only when no descent direction is found.In general case, if F isRm-concave, then there are no local minima for anyFj,j∈Iin X as our assumption that X is open, i.e., there does not exist any j such that condition (ii) satisfied. Condition (i) is satisfied when the current iteration is critical. In this case it is impossible to find a critical point satisfying condition (ii) in X. Therefore in this paper, we seek a critical point satisfying condition (i), namely there does not exist a direction pointing away from all critical points.Lemma 3.2 implies that if x is noncritical for F, then there existsd∈Rnsuch thatFj′(x;d)<0,j∈I, which means that d is a descent direction for F at x, i.e., there existsα0>0such that for allα∈(0,α0](3.1)Fj(x+αd)<Fj(x),∀j∈I.Theorem 3.3 provides the relationship between efficiency and criticality for the Lipschitz case.Suppose that assumptionAssumption 3.1holds.(i)Ifx∗∈Xis a locally weak Pareto optimum, thenx∗is a critical point of F.If X is convex, F isRm-convex andx∗∈Xis critical on F, thenx∗is a weak Pareto optimum.If X is convex, F is strictlyRm-convex andx∗∈Xis critical for F, thenx∗is Pareto optimal.(i)Assume thatx∗is weakly efficient.x∗is noncritical, which means that there existα0>0andd∈Rnsuch that (3.1) holds, in contradiction with the weak efficiency ofx∗. Thereforex∗is critical for F.From the assumption of this Theorem, ifx∗∈Xis critical on F, then for anyx∈X, there exists somej0such thatFj0′(x∗;d)=limUj∈∂Fj0(x∗+αd),α↓0{UjTd}exists and is positive ford=x-x∗. The convexity ofFj0andd=x-x∗also implies that(3.2)Fj0(x)-Fj0(x∗+αd)⩾(1-α)UjT(x-x∗),∀Uj∈∂Fj0(x∗+αd).Letα↓0in (3.2), then according to the continuity ofFj0,(3.3)Fj0(x)-Fj0(x∗)⩾Fj0′(x;x-x∗)⩾0.This means thatx∗is a weak Pareto optimum.From the strict convexity of F, (3.3) holds strictly for anyx≠x∗. Then the conclusion immediately follows. □Forx∈X, we defined(x)at x as the optimal solution of a nonsmooth problem NSP(x)(3.4)NSP(x)minmaxj∈Iϕj(x,d)+12dTBj(x)ds.td∈Rn,whereϕj(x,d)and12dTBj(x)dcarry certain first-order and second-order information ofFj(x), respectively, although the first and second derivatives ofFj(x)may not exist in general. Here we assume that-ϕ(·,d)is l.s.c. for any d andϕ(x,αd)⩽αϕ(x,d),∀x∈L0,0⩽α≤1, whereL0={x∈Rn:F(x)⩽F(x0)}is the level set. We assume thatBj(x)is positive definite for anyx∈Xand j. Given∊⩾0NSP(x)can be approximately expressed as the following smooth convex problem(3.5)NSP∊(x)mints.tϕj(x,d)+12dTBj(x)d⩽t,∀j‖d‖≤1,t⩽-∊,d∈Rn.When∊=0,NSP∊(x)is equivalent toNSP(x)and its feasible set is always nonempty and a unique optimal solution is guaranteed. Further at this case when functionFjis twice continuously differentiable,ϕj(x,d)=∇Fj(x)TdandBj(x)=∇2Fj(x), then (3.5) reduces to problem (3.5) given by Fliege et al. (2009). Under suitable assumptions if the feasible set ofNSP∊(x)is empty for some sufficiently small∊>0, then there dose not exist a descent direction at x and a good estimate to a critical point is obtained. The reason for choosing some small enough positive∊in subproblemNSP∊(x)is that witht≤0replaced byt⩽-∊, we can exclude the trivial solution(d∗;t∗)=(0;0). If∊is nonzero,NSP∊(x)maybe infeasible. In this case the current point x is a good estimate to a critical point of F. These can be expressed by the following theorem under the following Assumptions 3.2 and 3.3.A 3.2For allx∈X,d∈Rn,liminft↓0ϕ(x,td)t⩽F′(x;d),whereϕ=(ϕ1,…,ϕm)T.For allx∈X,ϕ(x,0)=0andϕ(x,·)is lower semicontinuous.SupposeAssumptions 3.1, 3.2 and 3.3hold. Givenx∈X, for a sufficiently small positive scalar∊, if the feasible set ofNSP∊(x)is nonempty, then xis noncritical and any feasible solutiond∊(x)is a descent direction for F; otherwise, x is a good estimate of the critical point of F.Ifd∊(x)is a feasible point toNSP∊(x)as∊is positive, then xis noncritical andd∊(x)is a descent direction for F.If the feasible set ofNSP∊(x)is empty with∊sufficiently small, then there does not exist a descent direction. This can be proved by contradiction, i.e., if there is a directiond¯∈Rn, such that(3.6)Fj′(x;d¯)<0,j∈I.The above inequality together with Assumptions 3.2 and 3.3 imply that there is an positive scalarα¯such that for anyα∈(0,α¯],(3.7)ϕj(x,αd¯)α+12αd¯TBj(x)d¯⩽Fj′(x;d¯)+12αd¯TBj(x)d¯<0.For anyα∈(0,α¯], we define-∊=αFj′(x;d¯)+12α2d¯TBj(x)d¯, then we can see thatαd¯is feasible toNSP∊(x). This contradicts that the feasible set ofNSP∊(x)is empty. So x is a good estimate of the critical point of F for small enough∊. □Define(3.8)S(x,∊)≔(d;t)∈Rn+1|ϕj(x,d)+12dTBj(x)d⩽t,∀j,‖d‖≤1,t⩽-∊.Then the optimal solutiond¯∊(x)≔(d∊(x);t∊(x))of problemNSP∊(x)and its corresponding optimal value isv∊(x)can be expressed as(3.9)v∊(x)=min(d;t)∈S(x,∊)t,and(3.10)d¯∊(x)≔(d∊(x);t∊(x))=argmin(d;t)∈S(x,∊)t,whered∊(x)is the search direction. Note that(3.11)v∊(x)≔+∞when the feasible setS(x,∊)is empty. If∊=0, then define(3.12)v(x)≔v0(x)=inf‖d‖≤1maxj∈Iϕj(x,d)+12dTBj(x)d.(3.13)d(x)≔d0(x)=argmin‖d‖≤1maxj∈Iϕj(x,d)+12dTBj(x)d.Now we will discuss some stability analysis of functionv∊(x)and study its relationship withd¯∊(x)and the stationarity of x.Lemma 3.5IfAssumptions 3.1, 3.2 and 3.3hold, then:(i)the following conditions are equivalent:(a)x∈Xis noncritical on F;for sufficiently small∊>0, the solution setS(x,∊)is nonempty and0∉S(x,∊);v∊(x)<0.the feasible setS(x,∊)is nonempty forx∈Xiffv(x)=v∊(x).Ifx∗is critical, then the value functionv∊(·)defined by(3.9)is noncontinuous atx∗.(i)Assume that (a) holds. Then for the sufficiently small∊>0, Theorem 3.4 implies that there always exists a descent direction satisfying the constraints ofNSP∊(x), i.e.,S(x,∊)is nonempty and from Assumption 3.3 that0∉S(x,∊). This implies that (b) holds.By transitivity, (b) implies (c) and (c) implies (a).If the feasible setS(x,∊)is nonempty forx∈X, thenv(x)=v∊(x)follows from the definition ofv(·)andv·(·). On the other hand whenv(x)=v∊(x), thenv∊(x)=v(x)≤0implies thatS(x,∊)is nonempty.Ifx∗is critical, it follows from (i) and (3.9) that the value functionv∊(·)is infinity and is therefore noncontinuous atx∗.□Based on the above discussions, with the current pointx∈X, we can iteratively find descent directions by solvingNSP∊(x)and use the obtained descent direction to update the current iterate which results in the following new algorithm with an appropriate line search method. The termxkis the term being evaluated at iteration k.Algorithm 1Step 0.Initialization: Letx0be the initial decision vector chosen from X. Give a sufficiently small positive scalar∊and a positive initial matrixBj(x0). Setk≔0.Step 1.Generation of Search Direction: Solve the subproblemNSP∊(xk), terminating if the problem is infeasible.Step 2.Line Search: Choose an appropriate step sizeαksuch thatxk+αkd∊∗(xk)∈Xand setxk+1≔xk+αkd∊∗(xk), whered∊∗(xk)is the optimal solution toNSP∊(xk).Step 3.Update: Generate the positive definite matrixBj(xk+1),j∈I. Setk≔k+1. Go to Step 1.1.In the above algorithm, it is easy to obtain a descent direction by solving subproblemNSP∊(xk)since the subproblem is a linear programme with convex quadratic constraints which can be easily computed by employing some well-known methods, such as interior point or proximal point methods.When the subproblemNSP∊(xk)is infeasible, it follows from the above discussions that the current iteration is a good approximation to a critical point. Therefore it can be deduced that the algorithm is well-defined.In Step 2,αkcan be chosen as follows. Ifxkis noncritical, then from the positive definiteness ofBj(xk),∀j, there isα¯j>0, such that for anyαj∈(0,α¯j],xk+αjd(xk)∈XandFj(xk+αjd(xk))⩽Fj(xk)+βv∊(xk),j∈I, whereβ∈(0,1/2). Letα¯=minj∈Iα¯j, thenxk+αjd(xk)∈Xand∀α∈(0,α¯],Fj(xk+αjd(xk))⩽Fj(xk)+βv∊(xk),∀j∈I. So in Step 2 we can chooseαk∈(0,α¯].In Step 3, we use the Broyden–Fletcher–Goldfarb–Shanno (BFGS) update criterion to updateBj(xk+1)similar to the update developed by Li and Fukushima (2000), but the latter is used for unconstrained scalar optimization. For anyj∈I,Bj(xk+1)inherits the positive definiteness ofBj(xk)as long asxkis noncritical.We now present the global and local convergence results for Algorithm 1.We first give the global convergence theorem for Algorithm 1, followed by the local convergence result for Algorithm 1 under some reasonable assumptions.To prove global convergence, we provide some basic assumptions.A 4.1The level setL0is bounded.For any convergent subsequence{xk}k∈K, ifdk→0, thenmaxj∈I(Fj(xk+dk)-Fj(xk))⩽maxj∈Iϕj(xk,dk)+o(‖dk‖).Define(4.1)ψ(x)=sup‖d‖≤1maxj∈I{-ϕj(x,d)}.It follows from Assumption 3.3 thatψ(x)⩾0. Furthermore, under our Assumptions 3.1, 3.2 and 3.3 the following conclusion aboutψis obvious.SupposeAssumptions 3.1, 3.2 and 3.3hold. Ifx∗is such thatψ(x∗)=0, thenx∗is critical on F.For the global convergence result we also need the following assumption.Assume that for sufficiently large k, the step-lengthαk=1is accepted.Assumption 4.3 implies that we use trust region methods to solve problem (2.1), that is by using‖d‖⩽Δto replace‖d‖≤1in subproblemNSP∊(x), whereΔ>0is the trust region radius, the global convergence of the trust region methods is similar to the following global convergence of Theorem 4.2.Suppose that there is a constant c such that‖Bj(x)‖⩽c, for anyx∈L0and j. UnderAssumptions 3.1, 3.2 and 3.3 and 4.1, 4.2, 4.3, every accumulation point of the sequence{xk}is critical on F.By Lemma 4.1, it suffices to show that any accumulation point is the solution ofψ(·)=0. Letd¯kbe the maximum in (4.1) forx=xk. Then for anyα∈[0,1]from (3.12), the assumption aboutϕj,∀j∈Iand 4.1 we have(4.2)-v(xk)⩾maxj∈I-ϕj(xk,d¯k)-12d¯kTBj(xk)d¯k⩾max0⩽α≤1maxj∈I-αϕj(xk,d¯k)-12α2d¯kTBj(xk)d¯k⩾max0⩽α≤1-αψ(xk)-12α2c⩾12ψ(xk)min1,ψ(xk)c.Without any loss of generality, we may assume that the subsequence{xk}k∈Kconverges tox∗. Then from 3.2, there exists somek¯where the steplengthαk=1is accepted for any sufficiently largek⩾k¯andk∈K. It follows from 4.2 and (3.1) that(4.3)12∑k∈K,k⩾k¯ψ(xk)min1,ψ(xk)c⩽∑k∈K,k⩾k¯maxj∈I[Fj(xk)-Fj(xk+1)]⩽maxj∈I[Fj(x0)-Fj(x∗)]<+∞.This means that(4.4)∑k∈Kψ(xk)min1,ψ(xk)c<+∞.Now we will proveψ(x∗)=0by contradiction. Assume thatψ(x∗)>0, which together with Assumption 4.3 implies that there areβ>0andε0>0such that for all0<ε⩽ε0and for all‖xk-x∗‖k∈K⩽ε,(4.5)ψ(xk)⩾β>0.This means that∑k∈Kψ(xk)min1,ψ(xk)c⩾∑k∈{k|‖xk-x∗‖k∈K⩽ε}ψ(xk)min1,βc=+∞.This contradicts (4.4). Therefore,ψ(x∗)=0. It then follows from Lemma 4.1 thatx∗is critical on F. □We consider the local convergence for Algorithm 1 where every objective functionFj,j∈I, is assumed to be locally Lipschitzian and semismooth. The functionFj,∀j∈I, is semismooth at x ifFjis locally Lipschitizian at x and 3.1 holds. We assume that for anyj∈I,ϕj(x,d)≔UjTd, whereUj∈∂Fj(x). It is obvious that this definition forϕsatisfies the assumptions given above. For the local convergence result we also assume that subproblemNSP(x)is used to generate the descent direction d instead ofNSP∊(x)where we assume that the iterations will proceed indefinitely and every norm of the descent direction is less than 1. The optimal solution forNSP(x)is as follows.Givenx∈Rn, definef(x)≔maxj∈I{fj(x)}, wherefj(x)≔UjTd+12dTBj(x)d, then it follows from the strict convexity offjthat f is also strictly convex and the subdifferential of f can be defined as follows,(4.6)∂f(x)=Conv∪j∈I∇fj(x)|fj(x)=f(x),∀xi.e., the subdifferential of the maximum of functions can be expressed as the convex hull of the union of differentials of the ‘active’ functions at x, where “Conv” denotes the convex hull. The optimality condition for problemNSP(x)can be expressed, asx¯is the optimal solution toNSP(x)equivalent to the following condition,(4.7)0∈∂f(x¯).The above condition together with (4.6) suggests that there existsλ¯=(λ¯1,…,λ¯m)T∈R+msuch that∑j∈Iλ¯j=1and(4.8)0=∑j∈Iλ¯j∇fj(x¯)=∑j∈Iλ¯j(U‾j+Bj(x¯)d),whereU‾j∈∂Fj(x¯).Therefore at iteration k, the descent directiondkby solvingNSP(xk)can be generated as follows, there existsλk=λ1k,…,λmkT∈R+msuch that∑j∈Iλjk=1and(4.9)dk=-∑j∈IλjkBj(xk)-1∑j∈IλjkUjk,whereUjk∈∂Fj(xk)and∑j∈IλjkBj(xk)is positive definite since everyBj(xk),∀j∈I, is positive definite andλk∈R+m.To present the supperlinear convergence result, we need the following assumptions:A 4.4Given0<c0⩽c1<∞and0<b0⩽b1<∞, for allx∈L0, assume thatc0⩽‖Bj(x)‖⩽c1,∀j∈I;b0⩽‖Uj‖⩽b1,∀Uj∈∂Fj(x),∀j∈I;Letx¯be an accumulation point of the sequence{xk}generated from Algorithm 1;Suppose the following conditions hold,(4.10)U‾j-Ujk-Bj(xk)(x¯-xk)=o(‖x¯-xk‖),∀j∈I;(4.11)λjk-λ¯j=o(‖x¯-xk‖),∀j∈I;(4.12)∑j∈IλjkBj(xk)-1-∑j∈Iλ¯jBj(x¯)-1=o(‖x¯-xk‖),∀j∈I,whereo(·)denotes the infinitesimal of higher order.Assumption 4.4 implies that∑j∈IλjkBj(xk)-1and‖∑j∈Iλ¯jU‾j‖are bounded from above. Assumption (4.10) implies that the matrixBj(xk)generated in every step satisfies some quasi-Newton Eqs. (4.11) and (4.12) imply that the parametersλkand the matrixBj(xk),∀j, converge toλ¯andBj(x¯)respectively when{xk}converges tox¯.With the above assumptions, we can present the superlinear convergence result for Algorithm 1.Theorem 4.3Suppose thatA4.3–4.6hold. If for anyi∈I,Fjis locally Lipschitzian and semismooth atx¯, then{xk}is superlinearly convergent tox¯.It follows from the assumption of this Theorem and Theorem 4.2, that 0 is the unique solution toNSP(x¯), which implies that there existsλ¯=(λ¯1,…,λ¯m)T∈R+msuch that∑j∈Iλ¯j=1and(4.13)0=∑j∈Iλ¯jBj(x¯)-1∑j∈Iλ¯jU‾j,whereU‾j∈∂Fj(x¯). Then(4.14)‖xk+1-x¯‖=xk-x¯-∑j∈IλjkBj(xk)-1∑j∈IλjkUjk⩽xk-x¯-∑j∈IλjkBj(xk)-1∑j∈IλjkUjk⩽∑j∈IλjkBj(xk)-1U‾j-Ujk-Bj(xk)(x¯-xk)+∑j∈IλjkBj(xk)-1∑j∈I‖U‾j‖λjk-λ¯j+∑j∈Iλ¯jU‾j∑j∈IλjkBj(xk)-1-∑j∈Iλ¯jBj(x¯)-1=o(‖x¯-xk‖),here the fourth equality comes from A4.4–4.6. The above inequality (4.14) means that the conclusion of this theorem holds. □We carry out numerical experiments for Algorithm 1 to solve a nonsmooth multiobjective program (2.1). When applying Algorithm 1, it is important to solve the subproblemNSP∊(x). Howeverϕj(·,·)inNSP∊(x)is implicitly defined. Therefore, we must give the explicit formulation ofϕj(·,·)for some given class of Lipschitzian functions, that is for anyj∈I, we consider to explicitly defineϕj(·,·)when the functionFjis Lipschitzian piecewiseC1and a discrete minimax of some class of functions respectively. More classes of functions for definingϕj(·,·)be found in Qi and Sun (1993) where the functionϕ(·,·)is used to approximate the first-order information of the objective function in the trust-region method for solving single-objective optimization problems. It is easy to show from the definition ofϕj(·,·)and the discussion by Qi and Sun (1993) that-ϕ(·,d)is l.s.c. for any d andϕ(x,αd)⩽αϕ(x,d),∀x∈L0,0⩽α≤1andϕj(·,·)satisfies Assumptions 3.2, 3.3, 4.1 and 4.2. Therefore our algorithm withϕj(·,·)defined as follows is globally convergent for the problem with functionsFjthat are Lipschitzian piecewiseC1and discrete minimax of some class of functions respectively.1.We first consider that the functionFjis Lipschitzian piecewiseC1. For anyx∈X,{x|Fj(x)<∞}can be expressed as a union of some convex polyhedra, for each of which the function is given by a formula of aC1function, that is there is a set of functions{Fji}i=1MiwithFjias aC1function,∀i=1,…,Misuch that{x|Fj(x)<∞}={x|Fji(x)<∞,i=1,…,Mi}. Then for anyj∈I, the subdifferential of functionFjatx∈Xcan be given as follows,∂Fj(x)=Co{∇Fji(x)|Fj(x)is given byFji(x)atx,i∈{1,…,Mi}}. Then at this case for anyj∈I,ϕj(·,·)can be defined as,ϕj(x,d)=maxv∈∂Fj(x)vTd.For the above definition ofϕj, the subdifferential∂Fjis needed to be calculated. But it is still an open problem to obtain the subdifferential∂FjifFjis not a simple analytical function (see Bagirov & Ganjehlou, 2008). Again, it is difficult to use our method.Second, for anyj∈I,Fjcan be expressed as the discrete minimax of some class of functions that is for anyx∈X,Fj(x)≔max1⩽i⩽Mi{Fji(x)}withFji∈C1,∀i=1,…,Mi. Then for anyj∈I,ϕj(·,·)can be defined as,ϕj(x,d)=max1⩽i⩽Mi{Fji(x)+∇Fji(x)Td}-Fj(x).We present an example of numerical tests where every objective function can be expressed as the discrete minimax of some class of functions.ϕj(·,·)satisfies Assumptions 3.2, 3.3, 4.1 and 4.2 and Algorithm 1 used to solve this problem is globally convergent. We also compare the performance of Algorithm 1 with both the subgradient method presented by Neto et al. (2013) and the scalarization method where the weights assigned to two objectivesF1andF2are 0.5 and 0.5 respectively. We note that the resulting single objective optimization problem can be solved by the nonsmooth Newton method proposed by Qi and Sun (1993) or by the nonsmooth trust region method proposed by Qu, Goh, and Liang (2013). In this paper, we utilize the latter method to solve the resulting scalar optimization problem. All algorithms are coded in Matlab, the numerical test run on a PC, CPU Main Frequency 3.10gigahertz, EMS 4G, run circumstance Matlab 7.0, numeric type double float. We choose the parameter∊=10-6. The convergence criterionv∊(xk)>-∊is used for the termination test, that is, when the condition is satisfied, the computation stops. The maximization iteration is set as 200.Consider the following problem,F(x)=(F1(x),F2(x))=(max{F11(x),F12(x)},max{F21(x),F22(x)}),whereF11(x)=-1.0+8x1+8x2-32x1x2;F12(x)=3.6-12x1-4x3+4x1x3+10x12+2x32,F21(x)=x1+x22+x32+sin2(x1+x2+x3);F22(x)=cos(x3)(0.1+x2)exp-x10.1+x3,-10-4<xi<1+10-4,i=1,2,3.F is clearly Lipschitz continuous and satisfies Assumption 3.1. We chooseϕj(·,·)andBj(·)as follows. Leti1(x)=argmaxk=1,2F1k(x),i2(x)=argmaxk=1,2F2k(x). Defineϕ1(x,d)=∇F1i1(x)(x)Tdandϕ2(x,d)=∇F2i2(x)(x)Td. Thusϕ1andϕ2defined as above can satisfy Assumptions 3.2, 3.3 and 4.1, 4.2.In Step 3, we use the BFGS update criterion to updateBj(xk+1). We first define an index setK∼j={k:yjkTsk⩾∊min{-v∊(xk),1}}, wheresk=xk+1-xk,yjk=∇Fjij(xk)(xk+1)-∇Fjij(xk)(xk),j=1,2. Then the new quasi-Newton matrixBj(xk+1)is determined by(5.1)Bj(xk+1)=Bj(xk)-Bj(xk)skskTBj(xk)skTBj(xk)sk+yjkyjkTyjkTsk,ifk∈K∼jBj(xk),otherwise.It is easy to see from (5.1) that for anyj∈I,Bj(xk+1)inherits the positive definiteness ofBj(xk)as long asxkis noncritical.We now solve this bi-objective optimization Problem 40 times individually by Algorithm 1, the subgradient method (Neto et al., 2013), and the scalarization method with the initial pointx0randomly generated in{(x1,x2)|-10-4<xi<1+10-4,i=1,2,3}. We obtain the level curves for our algorithm as shown in Fig. 1. Table 1lists the numerical results for the applications of Algorithm 1 the subgradient method, and the scalarization method, respectively. The minimum, maximum and average number of iterations and the average computational time (CPU time) are reported in Table 1. The results generally show that our method is efficient in solving this problem.

@&#CONCLUSIONS@&#
