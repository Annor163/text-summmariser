@&#MAIN-TITLE@&#
Cross grouping strategy based 2DPCA method for face recognition

@&#HIGHLIGHTS@&#
An algorithm reduces the redundancy among row and column vectors of all images.In this algorithm, the cross-covariance matrix (CCM) is calculated.CCM completely preserves the covariance information of PCA between local geometric structures in the image matrix which is partially maintained in 2DPCA and its variants.A new grouping strategy that reduces the intra-group correlation is proposed.Compared to 2DPCA this algorithm is more robust to changes in lighting conditions.

@&#KEYPHRASES@&#
Facial image recognition,Grouping strategy,2DPCA,Cross-covariance,Singular value decomposition,

@&#ABSTRACT@&#
Grouping strategy exactly specifies the form of covariance matrix, therefore it is very essential. Most 2DPCA methods use the original 2D image matrices to form the covariance matrix which actually means that the strategy is to group the random variables by row or column of the input image. Because of their grouping strategies these methods have two main drawbacks. Firstly, 2DPCA and some of its variants such as A2DPCA, DiaPCA and MatPCA preserve only the covariance information between the elements of these groups. This directly implies that 2DPCA and these variants eliminate some covariance information while PCA preserves such information that can be useful for recognition. Secondly, all the existing methods suffer from the relatively high intra-group correlation, since the random variables in a row, column, or a block are closely located and highly correlated. To overcome such drawbacks we propose a novel grouping strategy named cross grouping strategy. The algorithm focuses on reducing the redundancy among the row and the column vectors of the image matrix. While doing this the algorithm completely preserves the covariance information of PCA between local geometric structures in the image matrix which is partially maintained in 2DPCA and its variants. And also in the proposed study intra-group correlation is weak according to the 2DPCA and its variants because the random variables spread over the whole face image. These make the proposed algorithm superior to 2DPCA and its variants. In order to achieve this, image cross-covariance matrix is calculated from the summation of the outer products of the column and the row vectors of all images. The singular value decomposition (SVD) is then applied to the image cross-covariance matrix. The right and the left singular vectors of SVD of the image cross-covariance matrix are used as the optimal projective vectors. Further in order to reduce the dimension LDA is applied on the feature space of the proposed method that is proposed method+LDA. The exhaustive experimental results demonstrate that proposed grouping strategy for 2DPCA is superior to 2DPCA, its specified variants and PCA, and proposed method outperforms bi-directional PCA+LDA.

@&#INTRODUCTION@&#
The automated face recognition is an active research area because of the growth in its application in many areas such as face identification and intelligent user interfaces. The face recognition is basically comparing an input face with the face models stored in a database of known faces and matching the input face with a known face in the database. One of the difficult tasks in the face recognition procedure is the high dimensionality of the facial images. Researchers have developed different algorithms, known as subspace methods, for dimension reduction. One of the most popular approaches to reduce image dimension is the Principal Component Analysis (PCA) [1]. This method produces the most expressive subspace for face representation and recognition. LDA [2] and Fisherfaces [3] methods are the examples of most discriminating subspace methods and other subspace methods [4–6] are modifications or extensions of these methods.PCA method reduces the redundancy between image pixels. In this method, image matrix has to be transformed into a vector. Transforming an image matrix into a vector increases computational time required to obtain eigenvectors of the image covariance matrix. Recently, to overcome this problem, 2DPCA is proposed by Yang et al. [7]. In 2DPCA, the image matrix is not transformed into a vector but the image covariance matrix is constructed directly using the original image matrix. That is why the computational complexity is reduced in 2DPCA compared to PCA. PCA, on the other hand, requires fewer coefficients than 2DPCA for image representation and therefore is more efficient than 2DPCA in terms of storage requirements. Xu et al. [8] provided that 2DPCA is a localized PCA. In their work, a lower dimensional representation of the image matrix is obtained by first applying 2DPCA on the row vectors of the image matrix and then applying 2DPCA on the column vectors of the projected image matrix. Wang et al. [9] showed that 2DPCA is a special case of the block image based PCA which has been used for face recognition in a number of systems. Specifically, the blocks are the lines of the raw images. In their experimental studies, they also showed that 2DPCA achieves higher accuracy than typical rectangle block based PCA. Xu et al. [10] used Coupled Subspace Analysis algorithm to overcome the curse of dimensionality dilemma and small sample size problem. Xu et al. [11] also proposed an algorithm, which aims to reduce the redundancy between row vectors and between column vectors by using 2nd or even higher order tensors. Zuo et al. [12] proposed a fast facial-feature extraction technique, BDPCA+LDA, for face recognition. In their work, they first transform an image matrix into BDPCA feature subspace. They do this transformation by using the row projection and the column projection matrices constructed from the application of 2DPCA on the row of the images and the application of 2DPCA on the column of the images, respectively. Then, they apply LDA on this low dimensional BDPCA subspace. In their work, they showed that the BDPCA+LDA framework has a number of significant advantages over the PCA+LDA framework. Noushath et al. [13] applied 2DPCA followed by image matrix based on linear discriminant analysis in order to obtain a lower dimensional representation of the image matrix. Ye [14] proposed Generalized Low Rank Approximation of Matrices (GLRAM) claiming that this method is superior to 2DPCA both in terms of compression and classification performance. However GLRAM lacks a criterion to automatically determine the dimensionality of the projected image matrix. Liu and Chen [15] proposed non-iterative version of GLRAM (NGLRAM) to overcome disadvantages of GLRAM. Yang and Liu [16] presented a horizontal and vertical 2DPCA-based discriminant analysis (HVDA) method for the face verification. In their work, they provide some theoretical justifications for 2DPCA. One of the theoretical justification is the property of 2DPCA that leads to robust transform matrices to image translations and pose variations (mirror images). In their work, they showed that 2DPCA-based methods are less sensitive to imprecise eye detection and face cropping and improved the traditional PCA-based methods for face verification.Another 2DPCA based recognition algorithm can be found in [17]. In this study, a new face recognition scheme combining 2D and 3D information was proposed. Their method is based on 2DPCA and performs 2DPCA algorithm on the column vectors of the image matrix instead of the row vectors as in 2DPCA. Thus, this method reduces the redundancies between columns of the image matrix. It requires 3D facial data in the training process but can process 2D pictures in the recognition stage. According to the experimental results, this method is very robust for pose variation scenarios.The above mentioned studies show that subspace methods, used for recognition and representation of images, try to group the elements in some manner and than reduce the redundancy exists in these groups. Examples of most common grouping strategies are analyzed in [18]. Grouping strategy exactly specifies the form of covariance matrix, therefore it is very essential. PCA method, for example, is used to eliminate redundancy among the pixel values of the 1D image vector while 2DPCA method is used to reduce redundancy among row vectors of the image matrix. Most 2DPCA based methods [8–16,18–21] use the original 2D image matrices to form the covariance matrix which actually means that the strategy is to group the random variables by row or column of the input image. In this paper a novel grouping strategy is proposed. The main contributions of this paper are as follows:1.A definition of image cross-covariance matrix is proposed by developing a new grouping strategy.This new covariance matrix preserves the covariance information of PCA between local geometric structures in the image which is partially maintained in 2DPCA and its variants.In this new grouping strategy intra-group correlation is weak according to the 2DPCA and its variants because the random variables spread over the whole face image. This also makes the algorithm less sensitive to the lighting condition changes because the new grouping strategy reduces the intra-group correlation.Further in order to reduce the dimension, LDA is applied on the feature space of the proposed method. This also increased the recognition performance according to bi-directional PCA+LDA.All these make the proposed algorithm superior to PCA, 2DPCA and 2DPCA variants in terms of recognition accuracy. Beside, if we evaluate the PCA, 2DPCA, 2DPCA variants and the proposed method for the time required and computational complexity, following results revealed. The length of the object forming the group specifies the covariance matrix dimension, and the covariance matrix dimension specifies the time required and the computational complexity of this algorithm. In 2DPCA method, its variants and the proposed method groups are constructed using the row or/and column vectors so the time requirements and the computational complexity in all these methods are close to each other; however all are much more smaller than PCA.The developed algorithm constructs image cross-covariance matrix from the summation of the outer products of the column and the row vectors of the image matrix. As a second step, singular value decomposition (SVD) is applied to the image cross-covariance matrix. The resulting right and left singular vectors are used as the optimal projection vectors for the feature extraction.The remaining of this paper is organized as follows: Section 2 introduces the standard 2DPCA method. Section 3.1 compares the proposed method with 2DPCA and its variants. Cross-covariance matrix of the face images is obtained and diagonalized in Section 3.2. The covariance matrix relationships between the proposed method and PCA, 2DPCA and 2DPCA variants are determined in Section 3.3. Feature extraction and image recognition are demonstrated in Section 3.4. Feature vectors are calculated in bi-directional way by applying LDA after the proposed method (proposed method+LDA) as is given in Section 3.5. Finally, Section 4 provides experimental results in order to show the performance of the proposed method.2DPCA is a linear subspace method, which is used for feature extraction. The idea behind this method is to find the optimal projection directions, which can maximize the scatter of the transformed images. For the optimal projection directions, eigenvectors corresponding to the maximum d eigenvalues of the image covariance matrix are used [7].The main difference of 2DPCA from traditional PCA is that 2DPCA does not require transforming image matrices into vectors. Thus it reduces the computational complexity of construction of the image covariance matrix and reduces the computation time of the eigenvectors of the covariance matrix. Suppose that the training set has M image matrices Ai, i=1, 2, …, M with the dimension of m×n and the average of the training images is denoted byA¯. Then, the covariance matrix of the images Gtcan be computed as:(1)Gt=1M∑i=1M{Ai−A¯}T{Ai−A¯}A¯=1M∑i=1MAi.The optimal projection axis, xopt, is the eigenvector of Gtcorresponding to the largest eigenvalue. In general, it is not enough to have only one optimal projection axis. It usually needs to select a set of projection axes: x1, …, xd. The optimal projection axes are the orthonormal eigenvectors corresponding to the first d largest eigenvalues of Gt. Then the set of feature vectors, which represent the image matrix, is obtained by the following linear transformation:(2)yk=Aixkwhere k=1, …, d. With this transformation, each image of a person in the training set is represented by d feature vectors. The following section describes the proposed algorithm in detail.In this study a novel algorithm for face recognition is introduced. In this proposed algorithm variations between the row and column vectors of face images are used for face recognition. The proposed algorithm is also based on the traditional 2DPCA but it differs from the 2DPCA and its variants in grouping strategies.In statistics and probability theory, the concept of “covariance” of a random vector X is used as the matrix of covariances between the scalar components of X. But the term cross-covariance is sometimes used to refer to the covariance between two random vectors (assumed to be centered), X=[x1x2⋯xm]Tand Y=[y1y2⋯yn]T. So the cross-covariance matrix ΣXYbetween X and Y[22] is the m×n dimensional matrix and is defined as follows:(3)ΣXY=E[XYT].The scope of this study is to use the variations among the column and row vectors of image matrices for face recognition. That is why the two random vectors X and Y in the above definition correspond to the column vector and to the row vector of the image matrix respectively. The elements of E[XYT] are the cross-covariances between the components xiand yiof the vectors X and Y.The proposed method and many others given in the introduction section are based on 2DPCA. Most of them try to group the elements of the image matrix in some manner. They aim to reduce the redundancy which exists in these groups. Examples of most common grouping strategies are analyzed in [18]. As they mentioned in their study, grouping strategy exactly specifies the form of covariance matrix, therefore it is very essential. Different grouping strategies of most of the existing methods, based on 2DPCA, are illustrated in Fig. 1. In these figures, each pane corresponds to a pixel (a random variable) in the image and the panes in a round rectangle constitute a group. As it can be seen from Fig. 1, most common groupings are given as column based grouping (Fig. 1a), row based grouping (Fig. 1b), diagonal based grouping (Fig. 1c), and block based grouping (Fig. 1d).In 2DPCA, each column vector of the image matrix is supposed to be a random vector so image groups consisted of the column vectors. In A2DPCA [19] each row image, in DiaPCA [20] a diagonal of the image matrix and in MatPCA [21] partitioned blocks are supposed to be random vectors, which form the image groups.In contrast to traditional PCA, in which any two extracted random variables are uncorrelated, there still exist two kinds of correlation on the feature space [18]. These two correlations are defined as inter-group and intra-group correlations. While inter-group correlation refers to the correlation between the random variables belonging to different selected objects, for example the row vectors of different images in 2DPCA, intra-group correlation refers to the correlation between the random variables belonging to the same selected object for example the row vectors of the same image in 2DPCA. As for normalized face images, neighboring pixels are highly correlated, so the 2DPCA method and its variants given in Fig. 1 suffer from the relatively high intra-group correlation because rows, columns, diagonals or blocks in an image matrix are highly correlatedIn this study a new grouping strategy, where the intra-group correlation is relatively weak, is proposed. In the proposed strategy, a group consists of a column and a row vector as given in Fig. 2, where the panes in a round with straight line constitute a group and the panes in a round with dotted line constitute another group. The intra-group correlation is weak according to the most existing grouping strategies because these random variables spread over the whole face image. This makes the proposed algorithm superior to 2DPCA and its variants mentioned above. This can also be seen from the experimental studies (Figs. 6–8). The proposed method achieves higher recognition accuracies compared to 2DPCA.The proposed method is performed in two steps. First, image cross-covariance matrix is defined from the summation of the outer products of the column and the row vectors of the image matrix. This new matrix represents the variations between row and column vectors of the image matrix and it has the same dimension with the original image matrix. In the second step, singular value decomposition is applied to the image cross-covariance matrix. The left and right singular vectors are computed and used as the optimal projection vectors. The feature extraction and image recognition are then achieved.Suppose that an m×n dimensional image matrix is denoted by A and M images are used in the training set. The mean imageA¯can be computed as follows:(4)A¯=1M∑i=1MAi,i=1,2,…,M.Before the construction of the image cross-covariance matrix, the mean image is subtracted from each image in the training set, resulting in mean subtracted image matrixA¯¯i,(5)Ai¯¯=Ai−A¯=a¯¯11a¯¯12·a¯¯1na¯¯21·······a¯¯m1··a¯¯mn=r1ir2i·rmi=[c1ic2i·cni]whererji, (j=1, 2, …, m) denotes the row vectors ofA¯¯i, andcki, k=1, 2, …, n denotes the column vectors ofA¯¯i.The image cross-covariance matrix (Crc) with the size of m×n can be computed from the summation of the outer products of column and row vectors of the image matrices as follows:(6)Crc=1M∑i=1M1mn∑j=1m∑k=1n(cki)⊗(rji)=1M∑i=1M(ravgi)⊗(cavgi)Twhere ⊗ denotes the outer product operation andravgi=[r¯1ir¯2i…r¯mi]Tandcavgi=[c¯1ic¯2i…c¯ni]Tare the row and column mean vectors withr¯jiandc¯kiwhich are the jth row and kth column means respectively. The elements of the row and the column mean vectors are given below,(7)r¯ji=1n∑k=1n(a¯¯jki);j=1,…,mc¯ki=1m∑j=1m(a¯¯jki);k=1,…,n.Diagonalization of the cross-covariance matrix given in Eq. (6) can be achieved by using SVD [23]. SVD generalizes the eigendecomposition to rectangular matrices. With this operation a rectangular matrix is decomposed into three simple matrices: Two orthogonal matrices and one diagonal matrix. SVD uses the eigendecomposition of a semi-definite matrix to derive a similar decomposition for a rectangular matrix. Let X and Y be n×p and n×q data matrices and Cxybe the p×q matrix, whose elements are the cross-covariances between X and Y. The goal of SVD is to find linear combinations of the data Xaiand Ybi[i=1, …, r;r=min(p, q)], with the maximum covariance, subject to the p×1 vectors aiand q×1 vectors bi, satisfying the orthogonality constraints(8)aiTaj=biTbj=1i=j0i≠j.The solution is found by taking the SVD of Cxy, denoted here by Cxy=ADBT, where A is a p×r semiorthogonal matrix, D is an r×r diagonal matrix, and B is a q×r semiorthogonal matrix. The ith columns of A and B contain the left and right singular vectors aiand bi, and the ith singular value of D is the covariance of Xaiand Ybi. The vectors Xaiand Ybiare referred to as the ith pair of SVD expansion coefficients. It is desirable to find the directions in p space and q space so that when the variables in the two sets of data are projected onto these axes, they are as similar as possible. The next step is to find a second set of directions, orthogonal to the first, with similar properties, and so on up to r such pairs of directions. Stated another way, a p×r matrix A and q×r matrix B are sought, such that the quantity(9)∥XA−YB∥2is minimized subject to A and B being semiorthogonal. The notation ∥·∥ refers to the Frobenius norm of a matrix.A solution to the problem is to let A and B be the matrices of left and right singular matrices of SVD of Cxy.SVD is applied to the image cross-covariance matrix Crcin Eq. (6) whose elements are the cross-covariances between the image row and column mean vectors. Then the right singular matrix(CrcCrcT)with the size of m×m and the left singular matrix(CrcTCrc)with the size of n×n of the SVD of the image cross-covariance matrix are obtained. n×1 dimensional eigenvectors (left singular vectors), {φs} ofCrcTCrcmatrix and m×1 dimensional eigenvectors (right singular vectors) {ψs} ofCrcCrcT, that is,(10)CrcTCrcφs=λsφs,s=1,…,RCrcCrcTψs=λsψs,s=1,…,Rare found. Here X in Eq. (9) corresponds to the image row mean vector while Y is corresponding to the image column mean vector which are given in Eq. (6). And also the left and the right singular matrices A and B in Eq. (9) correspond to the left singular matrix(CrcTCrc)and the right singular matrix(CrcCrcT). The algorithm then uses the right and the left singular vectors for feature extraction.It is stated in [24] that 2DPCA can work in either row or column direction of the images. The covariance matrix given for 2DPCA in Eq. (1) exactly represents the row covariances that each row is considered as an object inRn.Using the row identification in Eq. (5), the image covariance matrix in Eq. (1) can be rewritten as(11)Gt=1M∑i=1M(A¯¯i)T(A¯¯i)=1M∑i=1M∑j=1m(rji)T(rji)=G11+G22+⋯+Gmmwhere Gjkis the covariance of the jth and kth image row vectors(12)Gjk=1M∑i=1M(rji)T(rki).In the light of this definition the covariance matrix in traditional PCA can be rewritten as(13)S=E[XXT]=S11S12·S1mS21S22·S2m····Sm1Sm2·Smmmnxmnwhere X is the mn×1 dimensional image vector which is obtained by concatenating the image rows into a vector form and Sijis an n×n dimensional cross-covariance matrix between the row vectors rjand rkfor i≠j and Gii=Sii, i=1, …, m. Each row of the covariance matrix in Eq. (13) includes the cross-covariances between the corresponding row and all other rows and also the covariance of that row.From Eqs. (11) and (13), it can easily be seen that the covariance matrix of 2DPCA preserves the elements only in the main diagonal of the covariance matrix of PCA [25]. It is also stated in [25] that the covariance matrix of 2DPCA is equivalent to the average of the main diagonal of the covariance matrix of PCA. This implies that 2DPCA eliminates the covariance information other than the main diagonal that can be useful for recognition.The relationships between the covariance matrices of the 2DPCA variants given in [18] with PCA can be defined in the similar manner as in 2DPCA case. While 2DPCA is using a row image matrix as an object, its variants use a column, a diagonal or a block of the image matrix as an object. 2DPCA and its variants differ from each other according to the selected object, but their feature extraction schemes are similar. Thus it is considered that covariance matrices of 2DPCA variants preserve only the covariance information between the elements of the selected objects. For example if we take the column vectors as an object, the image covariance matrix in 2DPCA can be written as;(14)Gt=1M∑i=1M(A¯¯i)(A¯¯i)T=1M∑i=1M∑j=1n(cji)(cji)T=G11+G22+⋯+Gnnwhere Gjkis the covariance of the jth and kth image column vectors(15)Gjk=1M∑i=1M(cji)(cki)T.The relationship between traditional PCA and 2DPCA which works on column direction can be obtained in a similar manner. Thus the covariance matrix of traditional PCA can be rewritten as(16)S=E[XXT]=S11S12·S1nS21S22·S2n····Sn1Sn2·Snnmnxmnwhere X is the mn×1 dimensional image vector which is obtained by concatenating the image columns into a vector form and Sijis an m×m dimensional cross-covariance matrix between the column vectors cjand ckfor i≠j and Gii=Sii, i=1, …, n. Each row of the covariance matrix in Eq. (16) includes the cross-covariances between the corresponding column and all other columns and also the covariance of that column.In this paper, we proposed a framework for investigating the information which may possibly be useful but neglected by 2DPCA and its variants. With this proposed method we use the variations between the image rows and columns. In order to do this we construct the image cross-covariance matrix as in Eq. (6). Then the eigenvectors which diagonalize the image cross-covariance matrix are used as the optimal projection vectors. In our case the image cross-covariance matrix is a rectangular matrix. So SVD is used for this eigendecomposition. With SVD of the image cross-covariance matrix the right and left singular vectors obtained from the right and left singular matrices’ eigendecomposition respectively are used as the optimal projection vectors. From Eq. (6), the image cross-covariance matrix is simply formed from the summation of the outer product of the row and column mean vectors with the size of m×1 and 1×n respectively.(17)Crc=1M∑i=1M(ravgi)⊗(cavgi)T=1M∑i=1Mr¯1ir¯2i·r¯mi⊗[c¯1ic¯2i·c¯ni]Now we are applying SVD to the image cross-covariance matrix. SoCrcCrcTis the right singular matrix of this decomposition. Recall that the right singular matrix is defined as,(18)CrcCrcT=1M∑i=1Mr¯1ic¯1ir¯1ic¯2i·r¯1ic¯nir¯2ic¯1i·······r¯mic¯1i··r¯mic¯nir¯1ic¯1ir¯2ic¯1i·r¯mic¯1ir¯1ic¯2i·······r¯1ic¯ni··r¯mic¯ni=1M∑i=1M(ci)r¯1ir¯1ir¯1ir¯2i·r¯1ir¯mir¯1ir¯2i·······r¯mir¯1i··r¯mir¯miwhere(ci)=(c¯1i)2+(c¯2i)2+⋯+(c¯ni)2is a coefficient obtained from the summation of squares of the elements of the image column mean vector andr¯ji,j=1,2,…,mare the elements of the row mean vectorravgi=[r¯1ir¯2i…r¯mi]T. As a further step the right singular matrix can be rewritten as(19)CrcCrcT=1M∑i=1M(ci)[(ravgi)(ravgi)T]That is why the right singular matrix which is obtained from the SVD of the image cross-covariance matrix is in fact consisting of the covariance of the row mean vector(ravgi). Substituting the equivalence of(ravgi)as[(r¯)1i(r¯)2i…(r¯)mi]Tand((r¯)ji,j=1,2,…,m)as given in Eq. (7) into Eq. (19) the equality of the right singular matrix in Eq. (19) can be rearranged as follows:(20)CrcCrcT=1M∑i=1M(ci)(S11+S12+⋯+S1n+S21+⋯+Sn1+⋯+Snn)where Sijis the cross-covariance of the ith column vector with jth column vector of the image matrix. The right singular matrix in Eq. (20) includes all the cross-covariances between each column and all other columns and also the covariances of each column as in Eq. (16). Thus the right singular vectors in fact diagonalize the covariance matrix, which is constructed taking each column vector of the image matrix as an object. While doing this it also preserves all the covariance information included in PCA given in Eq. (16) which 2DPCA and its variants do not preserve. As it is proved in [25] the covariance matrix of 2DPCA is equivalent to the average of the main diagonal of the covariance matrix of PCA. Similarly in our case the proposed approach expands the averaging so as to include the covariance information which is given in PCA (Eq. (16)) totally. This can be seen from Eq. (20).A similar relationship between the covariance matrix of PCA and the left singular matrix is defined as,(21)CrcTCrc=1M∑i=1Mr¯1ic¯1ir¯2ic¯1i·r¯mic¯1ir¯1ic¯2i·······r¯1ic¯ni··r¯mic¯nir¯1ic¯1ir¯1ic¯2i·r¯1ic¯nir¯2ic¯1i·······r¯mic¯1i··r¯mic¯ni=1M∑i=1M(ri)c¯1ic¯1ic¯1ic¯2i·c¯1ic¯nic¯1ic¯2i·······c¯nic¯1i··c¯nic¯niwhere(ri)=((r¯)1i)2+((r¯)2i)2+⋯+((r¯)mi)2is a coefficient obtained from the summation of squares of the elements of the image row mean vector and(c¯)ji,j=1,2,…,mare the elements of the column mean vectorcavgi=[(c¯)1i(c¯)2i…(c¯)ni]T. As a further step the left singular matrix can be rewritten as(22)CrcTCrc=1M∑i=1M(ri)[(cavgi)(cavgi)T]That is why the left singular matrix which is obtained from the SVD of the image cross-covariance matrix is in fact consisting of the covariance of the column mean vector(cavgi). Substituting the equivalence of(cavgi)as[(c¯)1i(c¯)2i…(c¯)ni]Tand(c¯)ki,k=1,2,…,n)as given in Eq. (7) into Eq. (22) the equality of the left singular matrix in Eq. (22) can be rearranged as follows:(23)CrcTCrc=1M∑i=1M(ci)(S11+S12+⋯+S1m+S21+⋯+Sm1+⋯+Smm)where Sijis the covariance of the ith row vector with jth row vector of the image matrix. The left singular matrix in Eq. (23) includes all the cross-covariances between each row and all other rows and also the covariances of each row as in Eq. (13). Thus the left singular vectors in fact diagonalize the covariance matrix which is constructed taking each row vector of the image matrix as an object. While doing this, it also preserves all the covariance information included in PCA given in Eq. (13) which again 2DPCA and its variants do not preserve. Here the covariance matrix given in Eq. (23) expands the averaging so as to include the covariance information which is given in PCA (Eq. (13)) totally. This can be seen from Eq. (23).The eigenvectors of the right and the left singular matrix obtained from SVD of the image cross-covariance matrix are used as the optimal projection vectors for feature extraction. These eigenvectors give the information of the variation between row and column vectors of the image matrix. d right eigenvectors and d left eigenvectors, corresponding to d largest eigenvalues of the image cross-covariance matrix, are used for the feature extraction (d<R). For a given image A, feature vectors are calculated from the following two linear transformation:(24)Yk1=AφkYk2=ATψkwhereYk1andYk2,k=1,…,dare the left and the right feature vectors of image matrix A, respectively. In the classification procedure, a nearest neighbor classifier [26] is used. The distance between the arbitrary feature sets of the classes and the test image, Dc, is calculated from the following formula,(25)Dc=∑k=1d∥Yk1c−Yk1test∥+∑k=1d∥Yk2c−Yk2test∥where c=1, …, C and C is the class number in the training set. Dcis minimized if the test image belongs to the class C.An approximation of a face image matrix(A˜)can be obtained using d2 eigenimages as discussed in [27]. An eigenimage, Eij, is calculated from the outer product of the right {ψs} and the left {φs} singular vector which belongs to the right singular matrix,CrcCrcT, and the left singular matrix,CrcTCrcrespectively.(26)A˜=∑i=1d∑j=1dDijEijEij=ΨiΦiTDij=〈A,Eij〉where 1≤i≤d and 1≤j≤d. Here Dijis the coefficient obtained from the inner product of image A with the eigenimage Eij. Summation of the products of these coefficients with corresponding eigenimages gives the approximation of image A, if d numbers of right and left eigenvectors are used. In order to reconstruct the original face image matrix, all of the right and the left eigenvectors i=1, …, m and j=1, …, n need to be used.If we use the left and the right singular vectors to perform feature extraction in bi-directional way as stated in [12], we can use the transformation given below to extract the total feature matrix Y of the image matrix A:(27)Y=ψkAφkThe feature matrix Y is then transformed into feature vector y by concatenating the columns of Y. The LDA projector WLDAis calculated then to obtain the final feature vector z(28)z=WLDATy.In the experimental study, the AR-Face database [28], ORL face database [29] and FERET face database [30] are used.AR-Face database contains over 4000 face images of 126 people (70 men and 56 women), including frontal views of face with different facial expressions, lighting conditions and occlusions. The pictures of people were taken in two different sessions separated by two weeks time interval. Each session contains 13 images for each person. In this study, only 37 individuals (20 males and 17 females) were selected and used. Only the non-occluded images were used for each individual. The face portion of the images were cropped and then normalized to 50×40 pixels. The normalized images for one person are shown in Fig. 3.Four different databases are constructed from AR-Face in order to use in experimental study and four different experiments are performed to evaluate the performance of the proposed method. In the first experimental study, the first image from the first row of Fig. 3 from AR-Face database is used for each person as the training set. The remaining images from the first row of Fig. 3 are used for the test set. In the second experimental study, the performance of the proposed method is evaluated when there are facial expression variations between the images. In this experiment, the first images from each row of Fig. 3 (normal expressions from both session) are used for the training set for each person and the second, the third and the fourth images from each row of Fig. 3 are used for the test set. In the third experimental study, the performance of the proposed method is evaluated when there are variations in lighting conditions. In this experiment, again, the first images from each row of Fig. 3 are used for the training set for each person and the last three images of each row of Fig. 3 are used for the test set. In the fourth experimental study, the performance of the proposed method is evaluated when there are time differences between the training set images and the test set images. That is why images from the first row of Fig. 3 are used as the training set and the images from the second row of Fig. 3 are used as the test set for each person. The same experiments are performed using both PCA and 2DPCA methods in order to compare results with that of the new method. Results are summarized in Tables 1 and 2.Table 1 presents the top-one recognition accuracy [8], which belongs to first two experiments, and Table 2 presents third and the fourth experimental results. Numbers in brackets are the eigenvectors’ number, for which top-one recognition accuracy is obtained. According to the experimental results, using cross variations between the row and column vectors of the image matrix can remove more redundancy than using the variations between the row vectors of the image matrix for face recognition. Also better recognition accuracy can be achieved by using less number of eigenvectors for the proposed method than 2DPCA and PCA. First column of Table 1, for example, reveals that the recognition accuracy is increased 4.5 points in respect of 2DPCA and 7.21 points in respect of PCA.In each of these four experimental studies, the proposed method outperforms PCA and 2DPCA in context of both in recognition accuracy and the number of eigenvectors used. The maximum recognition accuracy difference between 2DPCA and the proposed method is achieved when there are lighting condition changes between the images. So, the proposed method gives better recognition accuracy results compared to 2DPCA when there are lighting condition changes between images.This database contains 40 individuals each containing 10 different images. They were taken in two years’ time. The images were taken at different lighting conditions, facial expressions and facial details. The background of the images is dark homogeneous. The size of each image is 112×92 pixels, with 256 gray levels per pixel. The images were taken with a tolerance for some tilting and rotation of the face of up to 20° and with some variation in the scale of up to about 10%. Five image samples from ORL database are shown in Fig. 4.Three different experiments are performed using this database. In the first experiment, only the one image per person is used as the training set and all the remaining images per person are used as the test set. In the second experiment, first two images per person are used as the training set and all the remaining images are used as the test set. Finally, in the third experiment, leave-one-out strategy is applied to the database. The performance of the proposed method in each of these three experiments is compared with 2DPCA method. Top-one recognition accuracy is given for the experiments, Table 3, and numbers in brackets are the eigenvector numbers, for which the top-one recognition accuracy is obtained.According to the experimental results, using more image in the training set increases the recognition accuracy. In the second experiment, for example, when first two images are used as the training set, the recognition accuracy is increased 3.5 points compared to 2DPCA.The FERET face database is one of the standard databases which is used in testing and evaluating face recognition algorithms. The FERET database contains more than 10,000 images of over 1000 individuals. Within FERET database, the standardized FA contains 994 images, and FB contains 992 images, image sets are used in this work. Example normalized images’ face images in the FERET database are given in Fig. 5.The proposed method was tested on a subset of the FERET database. This subset includes 762 images of 127 individuals (six images per person). This subset involves frontal views with variations in facial expression, illuminations, facial details, and time differences. In our experiments, the facial portion of each original image was cropped based on the localization of eyes to a size of 60×60. The cosine similarity measure is used to calculate the similarity score between any pair of query and target images. Two experimental studies are performed using this database. In the first experiment leave-one-out strategy is used. As the purpose of this experiment is to compare the recognition accuracy of the proposed method with 2DPCA and its variants, the experimental study is performed for also 2DPCA and its variants which are A2DPCA, DiaPCA, MatPCA and GridPCA. The maximum recognition rates for all of these methods are given in Table 4. Fig. 6shows the cumulative eigenvalue curves for proposed method, 2DPCA, A2DPCA, DiaPCA, MatPCA and GridPCA against the preserved feature dimension. It is clear that with the same dimension proposed method keeps far more energy than all 2DPCA methods. Our proposed method is remarkably better than the others because its grouping strategy implies lower intra-group correlations. The performance statistics is cumulative match score and it is given in Fig. 7for all these methods. In the second experiment, first three images are used as the training set and remaining images as the test set. The performance statistics of the second experiment is cumulative match score and it is given in Fig. 8for all these methods.We also use the left and the right singular vectors to perform feature extraction in bi-directional way as stated in [12]. Applying LDA after the proposed method for the leave-one-out strategy, the recognition rate, which is (%)92.26 as given in Table 4, is increased to (%)96.59. Another experiment for proposed method+LDA is performed on FERET database. In this experiment randomly selected three images are used as the training set and remaining three images are used as the test set. To reduce the randomness of the experimental results, the average results of 10 trials are reported. For the comparison purposes the experiment is also performed for BDPCA. For the proposed method+LDA the recognition rate is achieved as (%)82.62, for BDPCA+LDA the recognition rate is achieved as (%)67.14 and for PCA+LDA the recognition rate is achieved as (%)64.18.

@&#CONCLUSIONS@&#
In this work, a new face recognition algorithm, which reduces the redundancy among row and column vectors of the face image matrix, is presented. In order to do this, a novel grouping strategy is proposed, which reduces the intra-group correlations and results in an increase on the recognition performances. Another important point, which contributes to the improvement of the recognition performances, is that the proposed method preserves all of the correlation information of pixel pairs for estimating the image covariance matrix as in PCA. In the proposed algorithm, image cross-covariance matrix is constructed from the summation of the outer products of the column and the row vectors of the image matrix. Singular value decomposition (SVD) is, then, applied to the image cross-covariance matrix. Right and left singular vectors obtained from SVD of the image cross-covariance matrix are used as the optimal projection vectors.Experimental studies show that the proposed method outperforms PCA, 2DPCA and 2DPCA variants in terms of recognition accuracy. The computational cost of the proposed method is superior to 1DPCA, since less time is required in order to find eigenvalues and corresponding eigenvectors. Experiments on the AR-Face, the ORL face and the FERET face database show that the proposed method improves the results and is valid for more general cases. The recognition performances are also evaluated in the cases, where proposed method+LDA is used. This also improves the recognition performances. It should be noted that as there are two feature vector sets obtained in the proposed method for image representation; the storage requirement in the proposed method is more than what is required for the PCA and 2DPCA methods. In the future work, it is planned to address two points. The first one is related about the recognition performance improvements. In order to increase the recognition performance of the proposed method combination of this method with improved LDA based methods given in [31,32] will be investigated. Because as it is stated in [31,32] proposed improved LDA methods are said to be more robust to non-ideal conditions such as variations of expression, illumination, pose and so on. And the second one is related about the computational cost and time requirements. In this sense QR decomposition implementation is considered instead of SVD [33–35] to reduce the computational complexity and the time requirements.