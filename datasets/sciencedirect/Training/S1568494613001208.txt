@&#MAIN-TITLE@&#
A hybrid genetic algorithm for constrained multi-objective optimization under uncertainty and target matching problems

@&#HIGHLIGHTS@&#
This paper proposed a hybrid genetic algorithm for optimization under bounded uncertainty.Local search is used for anti-optimization technique.The anti-optimization is achieved with Hooke and Jeeves method.Anti-optimization requires only a few additional percentage of total computation cost.The proposed algorithm has great potential for solving constrained multi-objective optimization problems under certainty.

@&#KEYPHRASES@&#
Genetic algorithm,Uncertainty,Local search,Anti-optimization,Target matching problem,

@&#ABSTRACT@&#
This work presents a new approach for interval-based uncertainty analysis. The proposed approach integrates a local search strategy as the worst-case-scenario technique of anti-optimization with a constrained multi-objective genetic algorithm. Anti-optimization is a term for an approach to safety factors in engineering structures which is described as pessimistic and searching for least favorable responses, in combination with optimization techniques but in contrast to probabilistic approaches. The algorithm is applied and evaluated to be efficient and effective in producing good results via target matching problems: a simulated topology and shape optimization problem where a ‘target’ geometry set is predefined as the Pareto optimal solution and a constrained multiobjective optimization problem formulated such that the design solutions will evolve and converge towards the target geometry set.

@&#INTRODUCTION@&#
All engineering analysis/design problems involve uncertainty or imprecision or approximation to varying degrees. The uncertainty present in many engineering analysis problems can be modeled using fuzzy sets and fuzzy logic, probabilistic approach, and interval analysis. Fuzzy set theory was firstly introduced by Zadeh [1]. The application of fuzzy sets concept into structural analysis was studied by Ayyub [2] systematically. In his work, a fuzzy set was utilized to describe every objective function. Fuzzy set theory has several advantages including the fact that the mathematics is formally defined and it can provide a potentially simpler approach. The disadvantages of fuzzy set theory include validation necessary, justification of each step necessary, complexity when using many variables and the fact that the membership function may be heuristically defined. For problems with distribution description of the variety in the system parameters, probabilistic approach is often used [3]. Probabilistic approaches offer an attractive framework for designing structures in the presence of uncertainty, but they require much information about probabilistic models. When such information is inaccurate, large errors could be incurred in the calculation of failure probabilities [4]. In the framework of probabilistic uncertainties, reliability-based optimization methods have been investigated extensively [5–7]. When less information is given and only range of each uncertainty quantity can be specified, interval method is widely used. Bounded uncertainty approach, a convex model of uncertainty proposed by Ben-Haim and Elishakoff [8], was an extension to the interval analysis [9]. Some disadvantages of interval analysis include slow computations, no additive or multiplicative inverses for intervals, no strict distributive law, and large number of subproblems [10,11].Anti-optimization technique, on one hand, represents an alternative and complement to traditional methods, and on the other hand, it is a generalization of the mathematical theory of interval analysis [12]. When the available uncertainty data is limited, a probability distribution may not be able to be estimated accurately, but bounds for the uncertain variables may be at least estimated. The designer will generally seek for the least favorable solution for the structure within the domain defined by the bounds on the uncertain variables. This search for the worst condition for a given problem was named anti-optimization by Elishakoff [13]. The term anti-optimization was also used in a more general sense, to describe the task of finding the worst scenario for a given problem. Venter and Haftka [14] presented a two species genetic algorithm (GA) effectively reducing the two-level problem to a single level. Min–max formulation was applied to the design of a composite laminate plate subject to uncertainty where a significant reduction in computational cost is obtained.Structural topology optimization [15] is an increasingly powerful design tool that can be used to obtain optimal arrangements of structural materials to comprise mechanical systems. Genetic algorithms (GAs) [16–21] are optimization strategies that directly address the discrete nature of the topology optimization problems. In recent years, hybrid GAs [22,23] have become more homogeneous and some great successes have been achieved in the optimization of a variety of classical hard optimization problems. Ishibuchi and Murata [24] proposed a Multiple Objective Genetic Local Search (MOGLS) algorithm. The algorithm used a weighted sum of multiple objectives as a fitness function. Jaszkiewicz [25,26] suggested an algorithm called Random Directions Multiple Objective Local Search (RD-MOGLS), and compared a slight variant called the Pareto Memetic Algorithm (PMA) with other well-known algorithms. Lee et al. [27] enhanced the performance of genetic algorithm by incorporating local search, ant colony optimization. In trying to solve constrained optimization problems using GAs, Wang and Tai [28] suggested a technique combining Pareto ranking and weighted sum for the local search selection process. In all of these algorithms, the basic idea is simple: a local search is applied to new offsprings generated (by crossover or mutation), and the improved offspring then competes with the population for survival to the next generation. Local search algorithms were suggested in order to reach a quicker and closer result to the optimum solution. GAs are always criticized for the time-consuming evolutionary process. Efficiency of GAs gets worsened by two species algorithm proposed by Venter and Haftka [14] when used in anti-optimization technique. To improve the efficiency of GA, this paper integrates a simple genetic local search algorithm as the anti-optimization technique within a GA framework. The local search procedure based on Hooke and Jeeves method is used to decide the search path. Section 2 describes a geometric representation method for defining structural geometry while Section 3 outlines the proposed hybrid GA. Formulations and numerical results of target matching test problems with non-conflicting and conflicting objectives in the context of structural topology optimization are presented in Section 4. Some concluding remarks are given in Section 5.As in any structural topology optimization procedure, the geometry of the structure has to be represented and defined by some form of design variables. As the overall genetic algorithm developed in this work is meant for applications in structural topology optimization, it is necessary to represent structural geometry in form of chromosome. The represented scheme is briefly described here. A more complete description and evaluation of the overall representation scheme can be found in [21]. A square design space is discretized into a 50 by 50 mesh of identical square elements as shown in Fig. 1(a). The solid elements touching the boundaries of the design space correspond to input/output elements, marked with the black elements. There are four input/output elements, connected to each other by six Bezier curves just like in the illustration of Fig. 1(b). Three active curves and three inactive curves, are prescribed such that there is one connecting curve between any two points (i.e., every I/O point is directly connected to the other three by one curve each). The structure is generated based only on the active curves which are in ‘on’ state. Although the inactive curves, which are in the ‘off’ state, temporarily contribute nothing to the current structure, they are still very important in subsequent generations because they may be turned ‘on’ later through the crossover or mutation operations during the evolutionary procedure. The set of elements through which each active curve marked with thick line passes form the ‘skeleton’ (Fig. 1(c)). Some of the elements surrounding the skeleton are then included to fill up the structure to its final form (Fig. 1(d)) based on the skeleton's thickness values.In order to use a genetic algorithm for structural optimization, the topological/shape representation variables have to be configured as a chromosome code. The structural geometry in Fig. 1(d) is encoded as a chromosome in the form of a graph as shown in Fig. 2.Each vertex of the graph holds a design variable, and the vertices are connected by edges depicted by the line segments. The vertices and edges here are the terminology as used in graph theory. Each start, control or end point is at the center of the element containing it with the same configuration/sequence as the Bezier curves, therefore its location is actually referenced by the element number. To ease illustration, the inactive curves are shown by dotted graph and the active curves are represented as solid graph. The topology/shape emerges from the interaction among the curves. Altering curve states or small shifts in control point positions can lead to topological changes with entire openings (holes) created or destroyed. It is a versatile geometric representation which can define a large variety of topological and shape configurations, using only a fairly small number of variables.In any genetic algorithm, two important reproduction operations of crossover and mutation are needed for the evolutionary procedure. In this implementation, the crossover operator works by randomly sectioning any single connected subgraph from a parent chromosome and swapping with a corresponding subgraph from another parent. As a result, two offspring are produced which have a mix of the topological/shape characteristics of the two parents. An example illustrating this operation is shown in Fig. 3. The closed loop, which are shown in Fig. 3, cutting across portions of the chromosomes represent the sectioning or crossover loop. Applying the same crossover loop to parent chromosomes and swapping the subgraph contained within the loop will produce two children. The ‘on’ and ‘off’ state of different pairs which are crossed by the loop are also swapped. If the ‘on’ variables dominate a curve, i.e. when the number of ‘on’ variables is more than the number of ‘off’ variables, the curve in the child chromosome will be active. Otherwise, the curve will be inactive.The mutation operator is devised to work by selecting at random any vertex on the graph and altering its value to another value within the allowable range. Mutation about the on-off state is simple, which is altering the state of curve. When the selected curve is active, it will be inactive after mutation, and vice versa.This paper integrates a simple genetic local search algorithm as the anti-optimization technique within a hybrid GA framework. The uncertain parameters are assumed to vary randomly between a lower and upper limit. The robustness of the objective function can be achieved by finding a robust solution that has the best worst-case performance over a set of possible scenarios, which is the same as minimizing the maximum value of the objective functions. Consider a structure subject to uncertain variables p and normal design variables x. A general constrained multi-objective optimization problem subjected to uncertainty is formulated as:(1)minxmaxpf(x,p)subjecttogj(x,p)≤0,j=1,2,…,qhk(x,p)=0,k=1,2,…,rThe “max” part requires simply identification of the uncertain variables p that maximize the objective, whereas the “min” part is with respect to the design variables that minimize the objective. The formulation considered leads to a nested optimization problem which will be solved by means of a GA for optimization and a local search for anti-optimization. Generally speaking, this is a sort of min–max search, where the “max” part is dealt with by a local search algorithm, and the “min” part is realized by a GA. The technique alternates between optimization (general GA) and anti-optimization (local search).Local search applied to all solutions in the current population in the algorithm is inefficient. In the proposed algorithm, the computation time spent by local search can be reduced by applying local search to only selected solutions in selected generations. Generally, a local search procedure using Hooke and Jeeves method [29] to decide the search path can be shown in Fig. 4where h is the step size, hmin is the minimum step length, nsis the number of steps, nmax is the maximal number allowed, ρ is the step length adjustment factor and the design variable x here is the coordinates of the element number. There are four main control parameters in the local search heuristic, the initial step size h0, hmin, nmax, and ρ. Normally, h0 and hmin in the Hooke and Jeeves algorithm are set according to the design space. The element hiof vector h0 can be set as half-length of the ith coordinate interval while element of hmin can be set as half-length in each direction of the basic finite element. nmax is set to a large number to avoid the possible failure of the local search. The value of ρ can be set to 0.5. Fig. 5plots the resulting search path based on the deteriorate(x,y) function which is introduced in the following Section 3.2A local search strategy needs a comparison between an initial solution and its neighboring solution. A technique combining Pareto ranking and weighted sum is suggested in this work for the local search selection process. There are only three combinations for the two solutions: both feasible, both infeasible, and one feasible and the other infeasible. The main idea of the technique is to use a tournament selection operator and to apply a set of criteria in the selection process. For an anti-optimization procedure, any infeasible solution is preferred to any feasible solution. When both solutions are feasible, Pareto ranking based on objectives (RankObj) is calculated. The one with bigger rank value is preferred. If the situation still ties, a more sophisticated acceptance rule is used for handling the situation. The fitness function of the solution x is calculated by the following weighted sum of the m objectives:(2)f(x)=w1f1(x)+w2f2(x)+⋯+wmfm(x)where f(x) is a combined objective andw1,w2,…,wmare nonnegative weights for the objectives set according to different orders of magnitude among them. Constant weight values are used in this work to fix the search direction based on user's preference. The solution with a bigger f(x) will survive. When both solutions are infeasible, Pareto ranking based on constraints (RankCon) is calculated. The one with bigger rank value is preferred. If the rank is same, the one with worse fitness value survives. A tournament selection criterion can be described to decide whether a current solution x should be replaced by a neighboring solution y. Fig. 6summarizes the selection criterion as the deteriorate(x,y) function.The overall algorithm uses a framework which combines the method stated in [28] and local search. The pseudo code of the algorithm is shown in Fig. 7.Various kinds of test problems [30–34] have been established for testing multi-objective GAs. However, all of these test problems have well-defined objectives/constraints expressed as mathematical functions of decision variables and therefore may not be ideal for evaluating the performance of a GA intended to solve problems where the objectives/constraints cannot be expressed explicitly in terms of the decision variables. One of such problems is structural topology optimization, where a procedure (structure geometry representation scheme) first transforms decision variables into the true geometry of the designed structure and then finite element analysis of the designed structure is carried out for evaluating the objectives/constraints. The test problem for such GA must use the same structure geometry representation scheme, chromosome encoding and reproduction operators. At the same time, the problem should be computationally inexpensive so that it can be run many times for the GA parameters to be changed or experimented with and the effect thereof can be studied for the purpose of fine-tuning the GA. A structural topology optimization problem under uncertainty requires finite element analysis which consumes a great deal of time. Taking the running time into consideration, the test problem needs to be designed without any need for structural analysis. A test problem can be designed such that simple geometry-based (rather than structural analysis based) objectives/constraints help design solutions converge towards the predefined target geometry. This type of test problem may be termed as “Target Matching Problem (TMP)”, which is capable of using exactly the same GA (including structural geometry representation scheme, chromosome encoding and reproduction operators) as that intended for solving the actual topology optimization problem. The present problems are similar to the Target Matching Problem solved in [28,35,36]. The target matching problems defined here as constrained optimization problems under uncertainty are more difficult (e.g. more nonlinear) and expensive.The TMP has one support point, two loading points and one output point. The loading point 1 is positioned anywhere along the left boundary and loading point 2 and output point is positioned anywhere along the right boundary. The support point is positioned in a specified area marked as “under uncertainty” and its position is random in the area as shown in Fig. 8. In this problem, the target geometry is shown in Fig. 9(a). The aim is therefore to evolve structures that match as closely as possible this target geometry. For comparison, the target geometry neglecting uncertainty is shown in Fig. 9(b). The target geometry under uncertainty has more elements (material), and its support point location is different from the one neglecting uncertainty. These will make the Bezier curves representing the geometry be very different.The problem is formulated with the following two objectives and two constraints: distance objective fdistance, material objective fmaterial, forbidden area constraint gforbidden and prescribed area constraint gprescribed. Such a problem is defined with the help of Fig. 8. The optimization problem may then be defined as:(3)minxmaxs{fdistance(x,s),fmaterial(x,s)}subjecttogforbidden=∑i=1nfyi≤0gprescribed=np−∑i=1npzi≤0where s is referred to the position of support point, x referred to the positions of control points of Bezier curves, the fdistance denotes the centroid-to-centroid Euclidean distance between the actual loading point 1 and the actual support point, andfmaterial=∑i=1nxi. xi, yiand ziare the material density of the ith element in the design space, forbidden area and prescribed area respectively with a value of either 0 or 1 to represent that the element is either void or material (solid). n, nfand npdefined the total number of elements in the discretized design space, in the forbidden area, and in the prescribed area respectively.The optimization procedure has been implemented through a C++ program running in the windows 7 Pro environment of a PC. The optimization was run for 1001 generations with a population size of 100 per generation. The local search procedure is triggered once every ten generations. By the end of evolutionary process 132,113 objective function evaluations have been performed. Because of complexity of the target matching problems, this calculation was relatively time-consuming with the average GA run taking 24min and 37s on an i7-2600 CPU. One of the solutions at the end of 1001 generations is shown in Fig. 10which has a distance objective fdistance value of 49.5 and a material objective fmaterial value of 142. It is the same as the target solution shown in Fig. 9(a).As can be seen from the result, the support point is on the extreme point. The following Fig. 11illustrates how the solution shown in Fig. 10 is obtained by applying local search. Apply the Hooke and Jeeves method to determine the search path using the tournament selection criteria stated in Section 3. Each data point is labeled with its index where some indexes are coincided. At the start point (labeled with 1), fdistance is 37.6 and fmaterial is 119. After the local search, the worst case labeled as 9 is obtained with a distance objective fdistance value of 49.5 and a material objective fmaterial value of 142. This figure demonstrates the Hooke and Jeeves direct search method for function maximization.Fig. 12shows a plot of the best distance objective fdistance and the corresponding solution's fmaterial versus generation number. fdistance and fmaterial values on the plot corresponding to any particular generation number belong to that generation's non-dominated feasible solution having the best distance objective. The plot starts at generation number 6, as until this generation there is no feasible solution in the population. Fig. 13shows plots of the best material objective fmaterial and the corresponding solution's distance objective fdistance versus generation number.Fig. 14shows the plot of the non-dominated solutions positioned in the objective space at some sample generations, viz. the 51st, 101st, 301st, 501st and 1001st generation. Although Fig. 14 shows all the non-dominated solutions at any particular generation shown, only one or two distinct points (in the objective space) can be seen for that generation. However, a few distinct solutions in the design variable space may have the same objective function values and therefore, such solutions would coincide in the objective space. The number shown in parenthesis next to every point marker indicate the number of such coincident solutions which are non-dominated among all the solutions in the population at the indicated generation.A few variants of the local search methodology can be implemented. They are tested in computational experiments using this target matching problem. The results from these variants are then compared to results obtained from the proposed local search methodology. In this section, these variants of the hybrid algorithm are briefly described as follows:Local search applied only on final generation: In this case, local search is used only after the genetic algorithm is terminated, i.e. after the final generation is obtained. Local search is applied to every variable of the final elite solutions (and not just the mutation variable as in the proposed local search). It is referred to as the “final elites method” in this experiment.Initializing local search when a worse solution is generated by mutation: When a solution with worse performance is obtained from the mutation about the uncertain variables, local search is initialized with the new solution. The basic idea of this variant is simply that the mutation has found a local search direction in which a high probability of deterioration has been demonstrated. More exploitation in this direction is therefore worthwhile. It is referred to as the “search worse method” in this experiment.Local search only in the start stage: In the start stage, there is more scope for the individuals to be deteriorated and so worse results are expected to appear easily. In this experiment, the local search will be executed in the first 100 of 1000 generations. It is referred to as the “start stage method” in this experiment.A comparison of the performance of the variants in target matching problem 1 with nonconflicting objectives is shown in Table 1.In the table, “generation expended” means the average number of generations expended to obtain the optimal solution. If the method used can not arrive at the optimal solution, the number will be 1001 in this experiment. “number of evaluations” refers to the average number of function evaluations executed before obtaining the optimal solution. If the method used can not arrive at the optimal solution, then it refers to the total number of all the evaluations performed up to the final generation.

@&#CONCLUSIONS@&#
An effective genetic algorithm has been presented here together with a local search concept helping to anti-optimize the uncertain design variables. The use of local search strategy helps to direct and focus the genetic search in uncertainty design variable space. The paper also demonstrates its effectiveness in solving structural optimization problem and attempts to distinguish between the conflicting and non-conflicting objective functions. Two multicriterion target matching problems have been formulated to be useful test problems to demonstrate the validity of the presented algorithms and because the Pareto optimal solutions of these test problems are known, it is possible to quantitatively evaluate how closely the algorithm can reach the true exact optimum. For both target matching problems, good results can be obtained within a reasonable number of generations of the evolutionary procedure to arrive at a set of Pareto optimal solutions. From the literature review it can be seen that GAs are few used to handle uncertainty analysis because of time consuming and high cost. With the strategy proposed in this article, the computation cost consumption for uncertainty problems is comparable to the cost consumption for problems neglecting uncertainty. GAs, while being slower, are more suitable to handle multi-objective optimization problems. So the authors believe that the use of the hybrid GA has great potential for solving constrained multi-objective optimization problems under uncertainty.