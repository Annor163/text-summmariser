@&#MAIN-TITLE@&#
Behavioral-based performability modeling and evaluation of e-commerce systems

@&#HIGHLIGHTS@&#
We model customers’ shopping behavior with deterministic and stochastic Petri nets.We employ hierarchical composition of sub-models to build a performability model.We propose taxonomy, specify operational profiles and use discrete-event simulation.Highly available e-commerce system will not always lead to higher user-perceived QoS.Performability measures are turned into business-oriented metrics for server sizing.

@&#KEYPHRASES@&#
Consumer behavior,Discrete-event simulation,Performability,Stochastic Petri nets,System availability,Service reliability,Workload characteristics,

@&#ABSTRACT@&#
Assuring high quality of web services, especially regarding service reliability, performance and availability of e-commerce systems (unified under the term performability), has turned into an imperative of the contemporary way of doing business on the Internet. Recognizing the fact that customers’ online shopping behavior is largely affecting the conduct of e-commerce systems, the paper promotes a customer-centric, holistic approach: customers are identified as the most essential “subsystem” with a number of important, but less well-understood behavioral factors. The proposed taxonomy of customers and the specification of operational profiles is a basis to building predictive models, usable for evaluating a range of performability measures. The hierarchical composition of sub-models utilizes the semantic power of deterministic and stochastic Petri nets, in conjunction with discrete-event simulation. A handful of variables are identified in order to turn performability measures into business-oriented performance metrics, as a cornerstone for conducting relevant server sizing activities.

@&#INTRODUCTION@&#
As e-commerce becomes mainstream, achieving and retaining customers’ satisfaction regarding the quality of web services being delivered becomes an ultimate goal: the principal element of the contemporary way of doing business on the Internet, a crucial factor that affects both the existence and the progress of Internet companies. The complexity to face and cope with this challenge is even bigger, knowing the fact that e-commerce web services rely heavily on large-scale systems, consisting of thousands of computers, networks, software components, and users. Large systems are inherently complex, whilst the randomness in the way customers demand those web services initiate the problem of managing and planning the capacity of hardware resources.In fact, the true challenge is to achieve an optimal balance among: (1) implementation investments, (2) the costs needed to continually upgrade and maintain a particular e-commerce web site, (3) the performability of the underlying system, (4) the achieved level of customers’ satisfaction, all related to (5) the delivered quality of web services. It can be accomplished solely through a proactive, continuous and scientifically-based capacity planning procedure, not by the application of ad hoc, non-regular procedures and rules of thumb, based on one’s subjective opinion and experience. In that context, Menascé and Almeida (2002) define the capacity planning as being “the process of predicting when future load levels will saturate the system and determining the most cost-effective way of delaying system saturation, as much as possible,” taking into account “the evolution of the workload due to existing and new applications, and the desired service levels”.The absence of such methodology can easily push a company into a “no-win situation:” the inappropriate capacity of hardware resources implies poor performance (long response times), reduced service reliability and system availability (unexpected and frequent crashes, long-lasting downtimes). These, in turn, imply poor QoS levels being delivered to customers, who, due to their increased dissatisfaction, abandon e-commerce web sites massively and prematurely. This can be devastating for the Internet companies, imposing financial and sales losses, decreased productivity, customers’ disloyalty and endangered reputation. The average downtime cost per hour may range from thousands to millions of dollars, depending on the type of industry (Patterson 2002).Based on a Ponemon Institute (2011) study, Emerson Network Power (2011) released a report that reveals and analyzes the financial impact of infrastructure vulnerability. For instance, downtime can be particularly costly for e-commerce companies with revenue models that depend on the data center’s ability to deliver IT and networking services to customers, with the highest cost of a single event topping US$1 million (more than US$11,000 per minute). According to the Information Technology and Intelligence Corp. (2011), their high availability survey and trends for 2010 revealed that while companies cannot achieve zero downtime, one out of ten companies said it needs greater than 99.999% availability.Moreover, according to Dun & Bradstreet, Inc., which licenses information on businesses and corporations for use in business-to-business marketing and supply chain management, 59% of Fortune 500 companies experience a minimum of 1.6h of downtime per week. If one takes the average Fortune 500 company (at least 10,000 employees, paid an average of US$56 per hour (US$40 per hour salary plus US$16 per hour in benefits)), the labor part of downtime costs for an organization this size would be US$896,000 weekly, translating into more than US$46 million per year (Arnold 2010). Faced with ever-increasing financial problems, Internet companies cannot keep pace with ever-increasing needs for upgrading the existing hardware infrastructure due to steadily growing service demands, which closes the vicious circle.In order to avoid such an unpleasant scenario, predictive models have to be built and evaluated on a regular basis. To investigate the impact of the inherent performance characteristics of the hardware infrastructure on the quality of service levels being delivered by the e-commerce system, it is inevitable to take into account the unexpected and stochastic changes in the workload, causing service reliability degradation and traffic bursts (or peak rates) that can easily exceed the average traffic levels by the order of ten (Banga and Druschel 1999, Jiang and Dovrolis 2005). This is crucial, since even small increases in the traffic intensity can significantly degrade system performance, whereas large ones can even cause functional breakdowns, making the e-commerce systems completely unavailable to customers’ service requests.Analyzing the genesis of the workload itself, a single fact emerges: customers’ online shopping behavior is the main underlying factor affecting the behavior of e-commerce systems’ hardware infrastructure. Actually, customers’ behavior during the course of an online shopping session is the true generator of all performability-related problems that arise at the server-side. It is, to a certain extent, irrational and stochastic, as being a reflection of people’s intrinsically different mindsets, resulting in rather different and unexpected decision-making processes when shopping online. As a result, customers exhibit heterogeneous, yet predictable navigational patterns, when surfing throughout the e-commerce web site for the duration of online shopping sessions. Capturing those navigational patterns and defining them quantitatively, in line with a relevant taxonomy of customers’ behaviors, is a basic premise to performing both modeling and evaluation of a wide gamut of performability measures.Buying decisions have costs and benefits and qualitative rationale for doing them. But, this also involves people making these decisions – people with their own backgrounds, incentives and experiences. The last couple of years have seen an upswing of researchers who are trying to explain these kinds of unexpected behaviors and why consumers don’t make purchasing decisions purely based on micro-economic principles. This blend of the economics and emotions has been subject to investigation of a separate branch in economics, known as behavioral economics (Ariely 2009, Curran 2010). What can we learn from behavioral economics to improve the way we make business decisions and improve business successes? According to Latino (2000): “reliability is a combination of two trains of thought. The first is what one calls the hard side of reliability. The hard side consists of all the tools that you physically go and measure reliability with … The other train of thought is the behavioral side.” What causes people to perform tasks in such a way that it causes performability setbacks?Scarcity is the basic economic problem that ascends because people have unlimited wants, but limited resources. Because of scarcity, various economic decisions must be made to allocate resources in an efficient manner. Standard economics assumes that we are rational – that we know all the relevant information about our decisions, that we can estimate the value of the different options, and that we are unobstructed in assessing the implications of each possible choice (Ariely 2009). The outcome is that we are supposed to be making rational and pragmatic decisions. On the basis of these assumptions, economists draw in-depth conclusions about shopping trends.We are all far less rational in our decision-making than standard economic theory assumes. Moreover, our irrational behaviors are neither random, nor meaningless – they are systematic and predictable: some people tend to spend more when shopping online than when they count out the cash; automated bill pay, another favorite of retailers and service providers, makes use of a similar lack of “tangible” payment; many decisions involve weighing the value of money now versus its more unclear future value; and, in many situations consumers are driven by emotion, not thought (Dratch 2014).A survey by University of Southern California’s Center for the Digital Future (2013) says that 76% of adult Internet users buy online, and for 59% of the Internet users “online purchasing has reduced their buying in traditional retail stores” (the most popular online purchases are for books, clothes, and travel, each reported by 66% of online buyers). Nevertheless, 48% of the Internet users are “very concerned or extremely concerned about the privacy of personal information when or if buying online,” whereas 44% are “very concerned or extremely concerned about the security of credit card information when buying online.”To put it differently, some customers know exactly what they want (they are focused and passionate) and frequently place an order, whereas others browse or search repetitively and almost never place an order (they are just curious or reluctant), being affected by those security related issues, anxious about the privacy of their personal information when purchasing from their favorite online stores. In conventional economics, the assumption that we are all rational implies that, in everyday life, we compute the value of all the options we face and then follow the best possible pathway. But, we do not always base these judgments on our essential values – our likes and dislikes.In our holistic approach, we identify customers as the most essential “subsystem” of an e-commerce system, with a number of important, but less well-understood behavioral factors. The modeling of customers’ classes and the specification of the operational profiles is a basis to building predictive models, suitable for evaluation of a number of performability measures. Performance and dependability are often modeled separately, based on the assumption that the faults of an individual subsystem do not necessarily affect performance. Conjointly, performability assessment is defined as “quantifying how well the object system performs in the presence of faults over a specified period of time” (Meyer and Sanders 2001).In this study, the performability evaluation strategy is based on a hierarchical composition approach that combines results from: (1) dependability (continuity of and readiness for correct service, based on system availability and service reliability); and (2) performance models. The proposition is that “the faults” in the system are the behavioral factors at play here, that can undermine one’s business goals, and “a failure” is an instance in time when a customer displays behavior that is contrary to some micro-economic principles. Dependable behavior, in our context, refers to human behavior that is situation-adequate, as well as goal-oriented. We combine the best practices of modeling systems’ behavior with stochastic Petri nets and the flexibility coming out from building and executing discrete-event simulations. Performability measures can then be turned into business-oriented performance metrics – a valuable resource for e-commerce web site’s top management teams in creating their policies, including the processes of decision making, both on an operational and strategic level. Nonetheless, these analyses also represent a cornerstone for conducting relevant capacity planning activities – improving e-commerce systems’ performance by horizontal and vertical scaling.The remainder of this paper is organized as follows: Section 2 focuses on related work and identifies most of the pro and con arguments. The rationale behind the introduction of the novel, customer-centric, holistic approach is explained in Section 3. Section 4 is devoted to workload characterization, which can be decomposed into two basic parts: a qualitative aspect – modeling the operational environment, and a quantitative aspect – modeling the arrival intensity. A model of the server-side is given in Section 5. In Section, 6 we shift our attention to performability evaluation. We discuss the hierarchical composition approach, identify inter-dependencies and information exchange among various sub-models, perform discrete-event simulations and analyze a range of behavioral-based service reliability, performance and performability measures. Finally, Section 7 concludes the paper with a discussion of the theoretical and practical contributions, limitations and implications for future research.The assessment of performance, service reliability and system availability as a function of the system’s workload intensity is a key step in the design, analysis and tuning of computer systems, including e-commerce systems. Having defined the measures needed, several general approaches, mutually not exclusive, can be undertaken when it comes to predicting their values, including the following: (1) making an educated guess based on experience with previous, similar systems; (2) building one or more prototypes and taking measurements; (3) using discrete-event simulation to model and evaluate the system; (4) constructing and solving analytical models of the system (Sahner et al. 1996).The current research activities affecting e-commerce systems originate from the period between 1994 and 2002 and are very heterogeneous in relation to the ranges, depths, approaches, techniques, and methodologies being employed. In most cases, the up-to-date research activities have been focused mainly on the performance analysis of e-commerce systems, while dependability issues, encompassing both the service reliability and system availability considerations, have been taken into account either partially, separately and narrowly, or not mentioned at all. This is quite reasonable, since performance-related issues occur more frequently than those affecting dependability, and they are subject to rigorous service-level agreements that impose high quality of service levels of web services being delivered to end users.The most complete and profound work on the performance of e-commerce systems has been concluded over time by Menascé and Almeida (2002, 2000b) and Menascé et al. (1994), through their comprehensive approach encompassing the development of analytical performance evaluation models, primarily based on the probability theory and the theory of queuing networks. By applying the basic operational laws, including the Utilization Law, the Forced Flow Law, the Service Demand Law, Little’s Law, as well as the Response Time Law, they have developed analytical models both on a macro level (whole systems), including finite and infinite queue lengths and/or users, and also on the micro level (particular hardware components), in the case of open and closed systems, taking into account one or more workload classes. In addition, their analytical models have been implemented in Microsoft Excel using Visual Basic for Applications (VBA) programming language.Recently, various classes of stochastic Petri nets (PNs) have been also employed, as well. For instance, Christensen et al. (1999) have developed a predictive model for capacity planning of web servers, based on the usage of the class of timed hierarchical colored Petri nets. Kihl et al. (2002) have proposed computer simulations for performance modeling and evaluation of e-commerce systems, whilst Brosso et al. (2002) have proposed the usage of XML Petri nets – the Petri Net Modeling Language (PNML) – to represent SPNs for web based systems. Additionally, research effort regarding e-commerce systems’ performance has been also made by Menascé et al. (2002b), Kounev and Buchmann (2003), Urgaonkar et al. (2005), as well as Ferrari et al. (2006).Besides the existence of a relatively big and ever-increasing number of e-commerce systems worldwide, there is a considerably smaller number of research endeavors that are entirely and exclusively dedicated to modeling and evaluation of performability measures of such systems, integrating both performance and dependability issues, in spite of the on-going, high dynamics in development and exceptional attractiveness of this substance. One of the rare attempts to address performability of systems that are similar to e-commerce systems on electronic funds transfer systems was by Araújo et al. (2011). The dependability evaluation, encompassing reliability and availability issues have been investigated in a rather limited number of isolated and specific cases (Callou et al. 2012, Hecht 2001, Microsoft® Corp. 2001, Wei et al. 2011).Speaking strictly about the modeling and evaluation techniques for addressing performability, one can state that they are based mostly on a variety of probabilistic, discrete-state models, including: (1) combinatorial reliability models: series–parallel reliability block diagrams (RDBs), fault trees (FTs) and reliability graphs (RGs); (2) directed, series–parallel acyclic task-precedence graphs; (3) Markov and semi-Markov models, including Markov chains, semi-Markov reward models and Markov reward models; (4) product-form queuing networks (PFQNs); and (5) various classes of stochastic Petri nets. For instance, Callou et al. (2012) have used a Petri net-based approach for quantification of a data center’s dependability by applying the hierarchical composition approach, while, yet again, Araújo et al. (2011) have addressed performability of EFTs using stochastic Petri nets.Recently, Robidoux et al. (2010) have proposed extensions in the form of dynamic reliability block diagrams (DRBDs) for addressing dependability issues. These can be converted into colored Petri nets (CPNs), in order to perform dynamic analysis of their behavioral features, along with an analysis of the correctness of the model (Xu et al. 2009). In addition, Wei et al. (2011) have presented a hierarchical methodology that combines the advantages of the reliability block diagrams and the class of generalized stochastic Petri nets (GSPNs) to quantify both reliability and availability.Besides these, in order to address performability issues, attempts have been made to employ Markov reward models (Donatiello and Grassi 2001, Pattipati et al. 2001), the semi-Markov reward models (Ferrari et al. 2006), the Markov regenerative reward models (Logothetis and Trivedi 1997), as well as combinatorial multistate models (Veerarghavan and Trivedi 1994).Each particular approach has its own advantages and drawbacks in terms of user-friendliness, ease of construction and use, efficiency and accuracy of solution algorithms, and availability of software tools for obtaining a numerical solution. No single approach is the best, or even inevitably suitable for every system and every measure of interest. For instance, analytical models require relatively high level of abstraction of the real system in order to be computationally tractable, that is, mathematically solvable, which imposes the problem of inaccuracy. However, once an analytical model is set up and either a closed-form solution or a numerical solution is obtained, it is both easy and fast to perform predictions, trade-off studies, what-if and sensitivity analyses, and compare design alternatives regarding the capacity planning issues. Discrete-event simulation seems to be a flexible approach, since it allows capturing system’s behavior in an arbitrary level of details or abstraction. Nevertheless, building up a simulation model can be a very time-demanding task, due to its complexity. Yet another drawback is the fact that simulation runs are, in general, long-lasting activities in order to assure statistically significant results.The combinatorial reliability models, including reliability block diagrams, fault trees and reliability graphs are straightforward and easy to understand, but they cannot represent neither the dependent behavior of components, nor they can address performance considerations. Alternatively, the wide gamut of Markov processes’ classes offer great flexibility for modeling all performability components at once, including performance, reliability and availability, but they are not always intuitive and perceptive. In addition, the size of their state-space grows much faster than the number of systems and components involved in the analysis, thus making the model specification and analysis exceptionally difficult.Finally, queuing networks are extremely intuitive to be developed, but only those having a product-form yield an efficient solution method. Besides, they cannot capture the behavior of systems exhibiting features like parallelism, simultaneity, synchronicity, blocking, mutual exclusion, etc. All of these features can be successfully addressed by various classes of stochastic timed Petri nets, which are graphical and mathematical modeling tools that possess semantic power for modeling any kind of systems with an arbitrary complexity. Besides the already known methodologies for obtaining analytical solution (both steady-state and transient solution) of certain classes of stochastic Petri nets, there is a plethora of dedicated software tools that support obtaining a numerical solution, and are also usable for addressing various performability measures, like SHARPE (Sahner et al. 1996), DSPNexpress (Lindemann et al. 1999), and TimeNET (Zimmermann and Knoke 2007). A comprehensive survey of such software tools can be found in Haverkort and Trivedi (2001).Several significant conclusions can be drawn from the survey in the previous section, including the following: (1) Addressing e-commerce systems’ performability is a recent, yet not enough investigated and elaborated issue, in spite of the ever increasing number of such systems worldwide. (2) In most cases, the focus has been put solely on obtaining performance metrics, whilst dependability considerations either have not been taken into account at all, or they have been elaborated partially and isolated from performance. (3) The performability research has been carried out very rarely, affecting systems that are, in a way, similar to e-commerce systems. (4) Besides the existence of a variety of approaches and techniques for addressing performability issues, none of them is exclusively customer-centric: none of them is based purely and solely on the customers’ dynamic and stochastic behavior during online shopping sessions.Despite the fact that e-commerce systems are actually computing systems, they possess many unique characteristics, reflecting the e-commerce client–server paradigm, the specifics of the online interaction with customers via Internet, as well as the internal multi-tier architecture of web sites. In addition, e-commerce systems include many communication components that cannot be seen with ordinary computing systems, whereas e-commerce system users exhibit a dynamic and stochastic behavior, causing service reliability degradation and Internet traffic bursts. Since e-commerce systems present a particular class of computing systems, they have to be treated in a unique manner, in order to be modeled and evaluated properly.In this context, we expand the meaning of the term “e-commerce system” by including customers as its fundamental and inevitable ingredient, besides the hardware resources residing at the e-commerce web site. The notion of an “e-commerce system” now refers to the unity between the humans and the machine via Internet, and their mutual interaction, as well as interoperability. This is quite natural and understandable reasoning, since e-commerce web site’s hardware infrastructure cannot perform without customers, and, vice versa, they cannot exist or perform without e-commerce hardware infrastructure. The resulting synergy that comes out from the interaction between these two elements drives the modern e-commerce paradigm. By including customers, the notion of e-commerce systems complies entirely with the Blanchard’s (1991) definition of a system, as being “a collection of multiple elements that are interrelated and work in cooperation, functioning together to achieve a desired goal or specific objectives.”We employ a somewhat hybrid evaluation methodology that combines the best practices of modeling systems’ behavior with stochastic Petri nets and the flexibility coming out from building and executing discrete-event simulations. To be more precise: (1) we utilize the semantic expressing power of the classes of generalized stochastic Petri nets (GSPNs) (Ajmone-Marsan et al. 1984) and deterministic and stochastic Petri nets (DSPNs) (Choi et al. 1993, Ciardo and Lindemann 1993) to capture the crucial features of a system’s behavior, using the basic graphical syntax primitives inherent to these two classes as basic building blocks. However, instead of solving the resulting models analytically, (2) we turn to SimPy/Python simulation programming environment (Matloff 2008, Müller and Vignaux 2003) to obtain a numerical solution.Throughout all segments within this research, the underlying idea is that the dynamic and stochastic online behavior of customers is the main reason for overloading the hardware infrastructure of e-commerce systems, which results in series of phenomena, including the unexpectedly prolonged response time, as being one of the most prominent performance indicators. Therefore, it is crucial to precisely describe the global workload of an e-commerce web site in terms of its main components, a process known as workload characterization (Menascé 2003, Menascé and Almeida 2002, Menascé and Almeida 2000a,b, Menascé et al. 2002, 1999). In fact, the workload characterization is the key aspect that defines the service demand: the demand for various hardware resources (CPU, HDD, RAM) of an e-commerce system.The workload characterization can be decomposed into two basic components: modeling the operational environment (a qualitative aspect), and modeling the arrival rates (a quantitative aspect).The “operational environment” concept, in a general sense, could embrace different dimensions – in this particular case, we partition the “input space” of the client-side of an e-commerce system by grouping customers that exhibit as nearly as possible homogenous online shopping behavior.A number of authors have independently tried to identify some basic classes of customers, given in Table 1. Two behavioral aspects are important: buying behavior (purchasing behavior), and online behavior. Nevertheless, most of the analyses have been performed by taking into account solely the economic motivations for online shopping. A segmentation of online consumers provides a valuable understanding of to whom online marketers might direct their offers. But, what usually is known about these segments is the hours active/month, unique domains accessed/month, pages accessed/month, percent buying, that is, not much about their online behavior.Menascé (2003) points out that workload characterization can be done at multiple levels and time scales, for example, at the business, session, function and HTTP request layer. Our workload characterization encompasses the second and the third layer, since we assess the customers’ behavior during online shopping sessions, while they invoke various specific e-commerce functions (login, search, browse, add-to-cart, and alike). Despite the fact that the number of sessions submitted to an e-commerce site is huge, and regardless of the different e-shoppers’ mindsets and purchasing behaviors, it is still possible to identify specific groups of mutually similar sessions. This can be done by analyzing web server’s HTTP logs by using clustering algorithms (Menascé et al. 2002, 1999). In such a way, different customer’s classes can be defined as being sets of customers exhibiting similar navigational patterns, a specific and unique online shopping behavior during web sessions. Each identified class can be graphically visualized, in most convenient way, by its corresponding customer behavior model graph (CBMG) (Menascé and Almeida 2002, 2000b).To gain insight into these segments, we analyzed online behavior using a sample of active online consumers of a regional e-commerce online bookstore. Based on the analytical data from 2000 registered byers for 10,000 offered items, we draw conclusions on the behavior of the average e-commerce user in the region, by using parallel threshold non-hierarchical clustering method (Reddy and Acharyulu 2009). Complementary findings of the six months research on the strategies applied on the regional e-commerce online bookstore Kupikniga.mk have been published by Antovski and Armenski (2012). Customers differ, and various customers behave in a rather different manner while shopping online. So a qualitative analysis of customers’ typical behaviors has been carried out, regardless of their socio-economic, demographic, ethnic, cultural and other characteristics, their innate and gained habits to go for shopping, as well as regardless of their immediate motivation to shop online.As a result, we have identified and qualitatively described five generic customer’s classes (simultaneously determined as several cluster centers), which include the following: (1) passionate, (2) focused, (3) reluctant, (4) curious, and (5) selective customers. Each particular class represents a single typical online shopping behavior pattern.Minimizing intracluster variance of the average distance of all points of a cluster, while maximizing intercluster variance of the distance between clusters, is the purpose of clustering (Menascé et al. 1999). To achieve this goal, the number of clusters could easily be made equal to the number of points. However, one needs to select a relatively small number of clusters in order to get a compact representation of the workload: the ratio between the intra and intercluster variance, and the ratio between the intra and intercluster coefficient of variation, are important in determining the quality of the clustering process. Our taxonomy of customers is quite general and fine-grained enough, at the same time – however, it might be closely related to the bookstore case. As e-commerce sites become more sophisticated, they can process their logs to identify user profiles based on the navigation and buying patterns, resulting in an expanded or reduced number of clusters. Yet, the proposed taxonomy is still simple and compact to capture the most typical online behaviors that can be encountered in any B2C e-commerce web site, be it an existing one or still in a design phase.In order to quantitatively capture different online behavior patterns, a suitable predictive model has to be constructed, as well. The DSPN model of the online shopping behavior, originally proposed by Mitrevski and Hristoski (2011), is used as a fundamental building block during the construction of a series of stochastic Petri net models for the evaluation of a plethora of performability measures. This stochastic model (Fig. 1), which reflects the decision-making process during an online shopping session, depicts the complexity of the interaction between a typical customer and an e-commerce web site in a quite simplified and clear way. For simplicity, while still preserving generality, it has been supposed that an customer can invoke some e-commerce functions where he/she resides for a certain time, the think time (e.g. “search” and “checkout” with exponentially distributed think time with rates λ and μ, respectively).For the sake of clarity, we briefly turn to the dynamics of the DSPN model: the token in place PSEARCHdenotes that a customer is about to make a new search through the products catalogue, which is a time-consuming activity. The firing time of transition TEND_SEARCHis exponentially distributed with rate λ. The product is either found (firing of transition TFOUNDwith probability pFOUND), or not found (firing of transition TNOT_FOUNDwith probability 1-pFOUND). In addition, it is the customer’s decision to add the product to the shopping cart (firing of transition TADD with probability pADD) or not (firing of transition TNOT_ADDwith probability 1-pADD). The firing of immediate transition TADDleaves a token in place PIN_BASKET(removes all (zero or one) tokens and puts back one), just to indicate that the shopping cart is not empty (the number of products is irrelevant). Regardless of the search outcome, the customer can either (a) make a new search (probabilities pCONTINUE_1, pCONTINUE_2 and pCONTINUE_3, respectively), (b) end shopping without placing an order (probabilities pEND_1, pEND_2 and pEND_3, respectively), or (c) proceed to checkout provided that the shopping cart is not empty (probabilities pCHECKOUT_1, pCHECKOUT_2 and pCHECKOUT_3, respectively). One can expect the probability of a new search to be the highest when no product was found, and the probability of ending without placing an order to be the lowest when the shopping cart is not empty. On the other hand, checking-out is also a time-consuming activity. The firing time of transition TReview-Submit-Verifyis exponentially distributed with rate μ. The consumer reviews and submits delivery address and credit card information, credit card authorization is verified, and order is placed (token in place PORDER_PLACED). Right away, the system sends the customer an e-mail confirmation regarding the purchase (firing of transition TE-MAIL) and the lifecycle of the e-commerce application ends (token in place PEND).While the customer stays in any of the tangible states, a timeout mechanism can be activated due to his/her inactivity (firing of transition TTIMEOUT), meaning that a deterministic time τ (with resampling policy) has run out and the session has been terminated forcibly and prematurely by the server-side of the e-commerce system. Otherwise, the session terminates regularly (in a timely manner), with two possible outcomes: either successfully (with an order placed), or unsuccessfully (without placing an order). However, in the latter case, two situations are possible, too: either (1) the customer has previously put one or more products into the shopping cart, but he/she has not bought them; or (2) the customer has left the virtual store without putting anything into the shopping cart.The DSPN model is suitable for obtaining various client-side related performance metrics, since it is also based on a CBMG of a particular e-commerce web site, but includes a stochastic temporal specification of the think times (Fig. 2). One should note that the search/browse behavior varies over time, so this process is not stationary over large timescales. It is anticipated that a better understanding of how individuals use the web could lead to improved design of web sites and web interfaces, but then again online merchants are interested in click rates because they contain information about an individual’s interest in the content of a web page (Scott and Smyth 2003). A user browses the products catalogue when he or she is looking around to see what is there, usually moving with a mind open to discover new things. In contrast, a user searches when he or she needs to locate a specific product. These events appear according to a two-state Markov modulated Poisson process (MMPP) – a doubly stochastic Poisson process where the rate process is determined by a continuous-time Markov chain. A two-state MMPP means that the Markov chain changes state from “search” to “browse” with intensity r1, and transits back with intensity r2. When the MMPP is in state “search,” the stochastic process is a Poisson process with rate λ1, and when the MMPP is in state “browse,” rate λ2 is used. Nevertheless, one can still deal with the mean rate in a two-state MMPP (Heffes 1980), given as follows:(1)λ=λ1r2+λ2r1r1+r2Consequently, the semantics of the timed transition TEND_SEARCH(Fig. 1) resembles, more or less, the meaning of the verb “to search” – “try to find something by looking or otherwise seeking carefully and thoroughly” (“browse” and/or “search by keywords”), and does not jeopardize the correctness of the results obtained.Based on the qualitative, narrative description of each particular customer class, a quantitative definition of each of them has been made, using the parameters of the DSPN model (the firing rates of the exponential transitions and the weights of the immediate transitions). Table 2summarizes the qualitative and quantitative definition of customers’ classes, by setting the intrinsic parameters of the DSPN model. This way, one can simulate the online behavior of an individual customer belonging to a specific class (by varying the numeric parameters within the DSPN model). For instance, the probability pEND_2of ending an online session without placing an order, after putting an item in the shopping cart, is considerably bigger with reluctant, and even more with selective customers, while the probability pCHECKOUT_2of ending an online session with placing an order is noticeably lower with selective, and even more with curious customers (to name a few).Given the customers’ classes being defined previously, one has to specify how they comprise the workload. An operational profile (OP) defines, in percentages, the participation of each particular e-commerce class within the workload mix during a certain period of time. Let N denote the total number of distinctive customers’ classes being identified. Intuitively, the operational profile can be specified by a corresponding row-vector P= [p1, p2, p3, …, pN], having N elements, representing the probabilities of each particular customer class to participate within the overall workload mix, given that p1+p2+p3+…+pN=1.Within each specific operational profile, customers, belonging to specific classes, participate in various proportions, whilst each particular class is characterized by a specific frequency (intensity) and a specific sequence of invoked specific e-commerce functions (login, register, search, add-to-cart, checkout, etc.). Each invocation of any of these functions results in generating and sending a corresponding HTTP request from the customer’s browser towards the server(s) of the e-commerce system. The system has to accept and process all of these HTTP requests, and each of them has to be answered by sending a corresponding HTML code back to the client’s computer. By generating a unique service demand, each operational profile poses a characteristic and rather different workload to the e-commerce system, as it is its own fingerprint.To rationalize the needs of our research, eight characteristic operational profiles have been defined (Table 3), including the following: OP#1(100%; 0%; 0%; 0%; 0%), OP#5(20%; 20%; 20%; 20%; 20%), whilst the rest six of them can be represented by a vector (80%; a%; b%; c%; d%), where abcd are combinations of the values 0 and 10, of class 4, given that a+b+c+d=20. The underlying idea is to carry out various evaluations for operational profiles in which the percentage of the most desirable class of customers (the class of passionate customers) is 20% less than that one in the OP#1, and also to investigate the impact of the equal distribution of the customers’ classes within the workload mix.Fig. 3shows the formal GSPN model of the operational environment. A customer, represented by a token in the place PSTART, is going to start his/her online session, by firing the immediate transition TSTART. The selection of the corresponding class is done when the token arrives at the place PSELECT, when N immediate transitions TCLASS_1, TCLASS_2, …, TCLASS_Nbecome concurrently enabled, each having specific firing weight w1, w2, …, wN. The probability of firing the immediate transition TCLASS_i, i=1, …, N, represents the probability of occurrence of a class i customer, given by the following expression:(2)PTCLASS_i=w(TCLASS_i)∑j=1NwTCLASS_j=wi∑j=1Nwj.When a transition TCLASS_ifires, a single token appears in the place PEXECUTE(the “Class i” customer can carry out his/her online session) and i tokens appear in the place PCLASS(due to multiplicities of the outgoing arcs originating from the transition TCLASS_itowards the place PCLASS), thus identifying the corresponding class that the new customer belongs to. Strictly adhering to the formal definition of SPNs, the row-vector [w1, w2, …, wN] represents the operational profile, timed transitions have marking-dependent firing rates, and immediate transitions have marking-dependent weights (they depend on the number of tokens in PCLASSin all the models that include a sub-model of the operational environment: Figs. 10, 12 and 13).Besides the identification of basic customer classes and the specification of various operational profiles, the process of workload characterization also includes the rates at which particular shopping sessions have been initiated at the e-commerce web site (customers’ arrival rates). The process describing customers’ arrivals is the Poisson process, since: (1) there is a zero probability of two arrivals at exactly the same instant of time; (2) the number of arrivals in the future is independent of what has happened in the past; and (3) the number of arrivals in the future is independent and identically distributed (i.i.d.) random variable over time, so the process is stationary. The time elapsed between two consecutive arrivals is exponentially distributed, with a mean 1/α, where α denotes the intensity of arrivals of customers in the system. As a matter of fact, α is the arrival rate in a general context that applies to all customers. If there are N classes of customers being defined in total, and p1, p2, …, pNare the probabilities that correspond to the participation of each particular class within a specific operational profile, given that p1+p2+…+pN=1, then customers belonging to class i (i=1, …, N) arrive with an intensity αi=pi.α (Bolch et al. 2006).E-commerce sites, especially those of the leading Internet retailers, have multi-tier hardware architecture, consisting of multiple servers, distributed throughout two or more LAN segments. In such a way, the site’s architecture becomes more scalable, more flexible, more reliable and highly available (Schroeder et al. 2000). We keep in mind the simplest possible two-tier hardware architecture of a medium-to-large scale e-commerce system, consisting of a front-end server (FES), a web server (WS), a database server (DbS), an application Server (ApS) and an authentication server (AuS), distributed into two high-speed LAN segments (Fig. 4).Each HTTP request may need several operations, based on the types of processing by some of the back-end servers, before completing. Moreover, a request may have to be processed more than once in a particular back-end server. Table 4summarizes the different back-end servers (Kihl et al. 2002), along with the mean processing time and standard deviation (σ). We assume that the processing time has a normal distribution and can vary up to ±10% (±3σ) of its mean. In addition, the propagation time (transmission delay) via Internet WANs has been considered as a random variable with a Normal distribution and parameters N(μ=0.5s; σ=0.13s), which yields 99.7% of the values within the interval [0.1, …, 0.9] s. At the server-side, the transmission delays between the servers have been neglected, due to the usage of high-speed LAN segments, as well as the propagation times in routers and firewalls.In this section, we will show how the complex concept of performability can be assembled in a bottom-up fashion, using a hierarchical composition approach (Fig. 5). Note that the hierarchical composition is a means for defining how a model is composed from other (sub-)models, and should not be confused with hierarchical Petri nets; nor should sub-models be confused with subnets (generally speaking, they do not even have to be “nets” of any kind).The modeling has been done by applying stochastic Petri nets (used in a CBMG manner, but relying on the use of random think times and their distribution functions, instead of using a matrix that represents the average think times between states of the CBMG), whereas the evaluation of the corresponding metrics has been performed by discrete-event simulation in SimPy/Python – an object-oriented, process-based, general-purpose discrete-event simulation package based on standard Python programming language. Discrete-event simulation (DES) utilizes a mathematical/logical model of a physical system that portrays state changes at precise points in simulation time.Both the nature of the state changes and the time at which the changes occur, require precise description. Within DES, time advances not at equal size time steps, but rather until the next event can occur, so that the duration of activities determines how much the clock advances. All of the following aspects of the e-commerce paradigm have been successfully modeled in SimPy: the client-side (the customer’s online shopping behavior); the server-side (the hardware configuration of a typical e-commerce web site, on a system level); various classes of customers (the qualitative component of the workload specification); the workload intensity (the quantitative component of the workload specification); the HTTP requests generation for the main functions invoked by the customer; the propagation delays of the HTTP requests being forwarded from clients’ browser towards e-commerce servers and the delays of the corresponding responses, via Internet; and evaluation of plethora of metrics for both client and server-side. Our SimPy implementation internally consists of three processes (named Source, Customer, and Request), along with their corresponding process execution methods (PEMs) (Fig. 6).The Source process implements the generation of customers according to the given arrival rate, and according to the probability distribution of their type. It also defines the parameters of the simulation runs. The Customer process implements the client-side, the customer’s online behavior during the online session. Finally, the Request process implements the server-side, with propagation of each particular HTTP request through the e-commerce web site’s hardware infrastructure, being already specified. Each web site’s server has been modeled on a system level, rather than on a component level. Since HTTP requests are processed by a particular server in a FIFO (FCFS) manner, each of them has been modeled as a resource facility with an infinite queue length, for simplicity reasons. Random variates are provided by the standard Python random module, which implements pseudo-random number generators for various distributions.Wang and Trivedi (2009) interpret the concept of user-perceived service reliability as follows: “During the user interaction (session) with the system, the user issues multiple tasks (or requests) at different time points for different services in the system. The user-perceived service reliability is the probability that all tasks in the user session are successfully completed.” In our case, we look at it in the opposite direction, from a system’s perspective, using the “language” of business-oriented performance metrics: if not all tasks in a customer’s session are successfully completed, both the buy-to-visit ratio and the revenue throughput decrease. Moreover, during a session, all those multiple requests/tasks consume system resources, possibly reducing service accessibility – the ability of other customers to initiate a transaction in the service when desired (load levels saturate the system). Yet again, in Wang and Trivedi’s own words, “longer user think time can decrease the service reliability.” These are the main reasons why we adopt the probability for a successful outcome of a session as a measure of the behavioral-based service reliability.Having defined customers’ classes, a GSPN model of a single customer’s online shopping session (Fig. 7) has been derived directly from the DSPN model. It does not include the timeout mechanism, and contains two absorbing places: PORDER_PLACED(a successful session) and PEND(an unsuccessful session). Therefore, it is suitable for assessing the conditional probability for a successful outcome, by customers’ classes.The Bowman–Shelton test of normality has shown that the conditional probability for a successful outcome of sessions follows the normal probability distribution for each particular class of customers (Fig. 8) (200 simulation runs were performed per class, each simulating a time interval of 2h, with α=1.0customers/s). It has been concluded that the highest average successful rate (0.853s−1) is evident for the class of passionate customers, followed by the classes of focused (0.568s−1) and reluctant (0.198s−1) customers. Contrary to some initial expectations, the class of curious e-shoppers (0.099s−1) has exhibited an insignificant, yet a higher average successful rate than the class of selective e-shoppers’ (0.025s−1), a fact that confirms the sorting of preferable customers’ classes in a descending order, as follows: (1) passionate; (2) focused; (3) reluctant; (4) curious; and (5) selective ones. Such arrangement of customer classes is necessary when characteristic operational profiles are being defined.The analysis of the partial coefficients of elasticity, obtained by series of simulation runs in which the conditional probability for a successful outcome of sessions (dependent variable) has been evaluated against the values of the weights of immediate transitions (independent variables) within the GSPN model in Fig. 7, has shown that the successfulness of sessions is a result of the complex process of decision-making, and is least dependent on the probability of putting a product into the shopping cart (pADD), and the probabilities of initiating an order (pCHECKOUT_1, pCHECKOUT_2, and pCHECKOUT_3) representing the weights of immediate transitions within the GSPN model. The box and whiskers plot (Fig. 9) confirms the definitive sorting order of customers’ classes.Next, using the GSPN behavioral-based service reliability model (Fig. 10), it is possible to evaluate the total probability for a successful outcome of a session, for various operational profiles. This model combines the GSPN model of the operational environment in Fig. 3 and the GSPN model of a single customer’s online shopping session in Fig. 7.Again, as in the case of the conditional probability, the application of the Bowman–Shelton test of normality has shown that the distribution of the total probability follows the Normal distribution. As expected, the OP#1, which is 100% comprised of the class of passionate customers, has resulted with the highest total probability (P¯SUCCESS=98.27%) for a successful outcome of sessions, while OP#5, which defines a mix of uniformly distributed classes of customers, has resulted with the lowest total probability (P¯SUCCESS=50.48%) for a successful outcome of sessions. Within operational profiles where the participation of the passionate customers’ is 20% less than in OP#1, the average value of the total probability for a successful outcome of sessions varies between 84.45% and 91.97% (Fig. 11).The performance sub-model considers only the execution behavior of a shopping session, independently of the outcome result. Therefore, the complexity of the decision-making process during an online shopping session is “hidden” by refinement of the Petri net-based system specification and including a number of timed transitions – TSEARCH_WITHOUT_ITEMS_ADDED, TSEARCH_WITH_ITEMS_ADDED, TEND_ITEMS_NOT_ADDED, TEND_ITEMS_ADDED, TFOUND_SELECT_ADDand TCHECKOUT(with exponentially distributed firing times with rates λ, λ, η, η, ψ and φ, respectively), leading to increased number of tangible states with nonzero sojourn times. The success of the user session depends not only on the number of requests during the session, but also on the user think times. In addition, the mechanism of timing failure (firing of deterministic transition TTIMEOUT) comes into play – a timing failure happens when a customer’s session has been aborted prematurely and forcibly by the e-commerce system, due to his/her inactivity.Such an irregular behavior can be put and analyzed in a broader context, as well. Namely, the customer is directly responsible for triggering a timing failure of the shopping session, due to his/her inattentive behavior. Since the online shopping session is the basic interaction that occurs between the client and the server processes within the e-commerce system, the customer is directly inducing performability degradation (i.e. “faded” perception that the system performs “well” over a specified period of time) by causing a timing failure. In other words, “shorter user think times result in shorter session duration, and the system can stay up during the session and serve all the requests successfully” (Wang and Trivedi 2009).Since the model includes a deterministic time (τ) that implements the timeout mechanism, the corresponding stochastic Petri net model necessarily belongs to the class of DSPNs. The DSPN representation in Fig. 12is suitable for evaluating the mean session length, regardless of the outcome (successful/unsuccessful), in the presence of timing failures (multiple customers and concurrent session execution was used during 250 simulation runs, each simulating a time interval of 2h, with τ=600s and marking-dependent firing rates η, ψ and φ (so they depend on the number of tokens in PCLASS)). The duration of each individual shopping session is accumulated, regardless of its outcome (with or without timing failure). At the end of the simulation, it is divided by the total number of sessions in order to calculate the mean session length. In a session, the remaining firing time (RFT) of the deterministic transition TTIMEOUTis resampled (reset to τ) in each new tangible marking of the Petri net (possibly the same). The firing of TTIMEOUTindicates that the server is unable to process further customer’s requests because the maximum allowed time between requests elapsed (token in place PTIMEOUT_EXPIRED).Slightly modified, the DSPN representation in Fig. 13assumes rescheduling a new session at the end of each regularly terminated session (sequential session execution was used during 1000 simulation runs, each simulating a time interval of 2h, with τ=600s). Such an assumption is suitable for evaluating two performance metrics, including the mean time to timing failure, as well as the mean number of sessions until timing failure.A propos to the performance measures, simulations have shown that the mean session length is shortest with operational profiles OP#4 (254.30s) and OP#8 (254.87s), while OP#5 exhibits the longest mean session length (324.00s) (Fig. 14).Further on, an evaluation of the mean time to timing failure has been performed. It is highest with OP#5 (311.80min), whereas OP#1 (122.07min) and OP#2 (124.55min) exhibit lowest mean time to timing failure (Fig. 15).Finally, the mean number of sessions until timing failure has been evaluated, too. It is highest with OP#5 (77.92), which is almost as twice as large a value than with other operational profiles (33.40–40.40) (Fig. 16).The behavioral-based service reliability, the performance, and the e-commerce system’s availability, are all brought together under the performability umbrella. The analysis of performability measures is carried out in two specific cases: (1) when the e-commerce system is comprised of a single module (a standard configuration); (2) when, besides the main module, there is an additional, redundant (spare) and non-active module within the e-commerce system, waiting to be activated in the case of a failure of the main module (a cold standby configuration). The corresponding GSPN models of both configurations are shown in Fig. 17and Fig. 18, respectively. One should note that both models incorporate GSPN sub-models of e-commerce system’s availability.The evaluation of performability measures has been carried out taking into account the mean time to failure (MTTF) and the mean time to repair (MTTR) parameters of the e-commerce system. In the case of the cold standby configuration, besides the previously mentioned ones, the mean activation time (MAT) of the spare module has been taken into account, as well. The actual values of all of these parameters correspond to the specification of a “well managed system” (Araújo et al. 2011): MTTF_main=360h, MTTR_main=8h, MTTF_spare=140h, MTTR_spare=10h, MAT=0.125h.Both of the performability models comply with the hierarchical composition approach, since there is an information exchange between them and the previously introduced behavioral-based service reliability and performance models. The firing rates of the exponential transitions TSESSION(Fig. 17) and TSESSION_MAIN, TSESSION_SPARE(Fig. 18) are based on the mean session length metrics being evaluated with the performance sub-model, whilst the firing weight of the immediate transition TORDER_PLACED(Fig. 17, Fig. 18) is, in fact, equivalent to the total probability for a successful outcome of a session, being evaluated with the behavioral-based service reliability sub-model. Borrowing the queuing terminology, the exponential transitions are said to be of infinite server type (Ajmone-Marsan 1990).For these two configurations, the following performability measures have been evaluated: (1) mean time to an unsuccessful session; (2) mean number of successful sessions until an unsuccessful session. Customers with different online shopping behavior arrive randomly and independently, according to the operational profile (multiple customers and concurrent session execution was used during 250 simulation runs, each simulating a time interval of 30days, with arrival rates α=0.01, 0.05, 0.1, 0.5, 1, 5, 10, 15, 20, 25 and 30s−1).Fig. 19shows that the mean time to an unsuccessful session is inversely proportional to customers’ arrival rate, for all operational profiles. Its function decreases monotonously from ∞ (for α=0customers/s), and asymptotically approaches a limiting value, which is different and characteristic for each operational profile (for α→∞customers/s). The operational profile OP#1, comprised of 100% passionate customers, exhibits the smallest, while the operational profile OP#5, where all classes of customers are being included equally, exhibits the largest value of the mean time to an unsuccessful session.In order to detect the existence of a statistically significant correlation among the dependent variable (the mean time to an unsuccessful session) and the independent variables (the total probability for a successful outcome of sessions and the mean session length), a correlation analysis has been performed and the value of the Pearson’s correlation coefficient has been evaluated, for each pair of variables. It has been concluded that there is a statistically significant correlation (both positive and strong) only between the mean time to an unsuccessful session and the total probability for a successful outcome of sessions (correlation=0.987).The functional relationship between the mean number of successful sessions to an unsuccessful session and the customers’ arrival rate is graphically presented in Fig. 20, for all operational profiles. It can be described by a logarithmic function, for each particular operational profile. For a given arrival rate α, the operational profile OP#1, including 100% of passionate customers, yields the highest value, while the operational profile OP#5, where customers’ classes have been equally distributed, yields the lowest value of this performability measure.The evaluation of both the mean time to an unsuccessful session and the mean number of successful sessions to an unsuccessful one, for the cold standby configuration, performed under the same operational conditions as with the standard configuration, has shown that there is no significant change, due to the fact that the extra operational time of the whole system, being gained by activation of the spare module, has been still small enough to significantly influence the results. Table 5depicts the descriptive statistics of the availability for both configurations being investigated (16,000 simulation runs were used, each simulating a time interval of 30days). Nevertheless, the absolute increase of system availability of only 1.02 percentage points could easily be converted to 3.7days, or 89.1h of additional operational time per year (i.e. 1.7h per week). These figures are in line with the findings that “59% of Fortune 500 companies experience a minimum of 1.6h of downtime per week” (Arnold 2010), as discussed in the beginning of this article – and this is how it might be masked.Knowing the total probability for a successful outcome of sessions, and assuming some percentage participation of various operational profiles in the mix of customers, it is easy to estimate the gain in the number of successful sessions per year, given a specific arrival rate α. An example scenario is presented in Fig. 21(the percentage participation of operational profiles OP#1–8 is 1%, 2%, 15%, 10%, 55%, 3%, 6% and 8%, respectively). If one supposes that each successful session yields a profit of just $1, the total extra profit per year can be easily estimated, as well. In that context, the analyses show that if the system availability increased by roughly 1%, than the Internet company would make an additional profit of more than $1 million per year, at an arrival rate of just five customers/s.

@&#CONCLUSIONS@&#
