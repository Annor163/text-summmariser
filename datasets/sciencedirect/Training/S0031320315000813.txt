@&#MAIN-TITLE@&#
Euclidean-distance-based canonical forms for non-rigid 3D shape retrieval

@&#HIGHLIGHTS@&#
Our method computes canonical forms of 3D meshes, without using geodesic distances.Our method maximises the Euclidean distance between a small set of feature points.Our method has a lower time complexity than other approaches yet provides comparable retrieval results.

@&#KEYPHRASES@&#
Shape retrieval,Canonical forms,

@&#ABSTRACT@&#
Retrieval of 3D shapes is a challenging problem, especially for non-rigid shapes. One approach giving favourable results uses multidimensional scaling (MDS) to compute a canonical form for each mesh, after which rigid shape matching can be applied. However, a drawback of this method is that it requires geodesic distances to be computed between all pairs of mesh vertices. Due to the super-quadratic computational complexity, canonical forms can only be computed for low-resolution meshes. We suggest a linear time complexity method for computing a canonical form, using Euclidean distances between pairs of a small subset of vertices. This approach has comparable retrieval accuracy but lower time complexity than using global geodesic distances, allowing it to be used on higher resolution meshes, or for more meshes to be considered within a time budget.

@&#INTRODUCTION@&#
Content-based 3D shape retrieval is a key research topic, as the large and ever increasing number of available 3D models makes effectively searching for models with a desired shape an increasingly important task. In the case of non-rigid models, where similar objects may appear in many different poses, the task of accurately comparing shapes is an especially challenging problem. One of the most effective approaches to solving this non-rigid retrieval problem is to convert each shape to a canonical form, i.e. a standard pose, and perform rigid shape retrieval on those [1,2]. Lian et al. [3] gave a method which computes a canonical form (see Fig. 1) for a mesh using the method of Elad and Kimmel [4] to map the geodesic distances between every pair of points on the surface to 3D Euclidean distances using multidimensional scaling (MDS). A view-based method is then used to perform shape retrieval. The drawback of this method is the high, super-quadratic, computational cost of geodesic distance computation, which requires the models to be simplified to approximately 2000 vertices to achieve a reasonable run-time.Our method computes a canonical form without the need for geodesic distances. Instead of mapping geodesic distances to Euclidean distances, we instead maximise the Euclidean distances between a subset of feature points while attempting to preserve the original mesh edge lengths. These feature points are selected based upon the conformal factor of the vertices [5]. This is a pose-invariant measure that represents the amount of local work required to globally transform the mesh into a sphere.We selectNfeature points, where N is the number of mesh vertices, which allows the distances between each pair of feature points to be computed in linear time. This reduced computational complexity compared to using geodesic distances means that our algorithm can not only produce canonical forms much faster for simplified meshes, but also allows canonical forms to be computed for higher resolution meshes within a reasonable time. When substituting our canonical forms into Lian et al.׳s retrieval method [3], we achieve comparable results to those using Elad and Kimmel׳s canonical forms [4], but much more quickly. We are also able to produce canonical forms for the dataset used by Lian et al., but without the need to simplify the models first. Another way in which greater speed can be put to use is to allow a larger number of meshes to be compared within a fixed time budget if the search space is a large database.

@&#CONCLUSIONS@&#
We have presented a novel linear-time method for producing canonical forms of meshes for non-rigid shape retrieval. Our method maximises the Euclidean distance between a small number of feature points, while attempting to preserve the original edge lengths. The feature points are chosen based on the conformal factors of the mesh vertices, which concentrates the feature points at the extremities of the model. Our method has lower computational complexity, and is much faster in practice, than methods that require all pairs of geodesic distances to be computed, while resulting in only a small drop in performance for both the SHREC׳11 and McGill datasets. We furthermore show that when considering models with a similar basic shape (humanoids), our method can provide the best retrieval performance.Using the original meshes of both datasets only produces a very small improvement over using simplified versions of the models when using one variant of our method, and produces a small decline in retrieval results for another. This may be because of the large dissimilarity between the classes in these datasets. This means that any finer details of the models, which are lost during simplification, are mostly unnecessary for distinguishing between models of different classes. Our method for finding feature points based on the conformal factors of the mesh vertices is able to find very similar points at different mesh resolutions, therefore the pose of the canonical forms will be similar over a wide range of mesh resolutions. The higher resolution meshes may also exhibit more noise, which could negatively affect the retrieval process.None declared.