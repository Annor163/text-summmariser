@&#MAIN-TITLE@&#
Performance based analysis between k-Means and Fuzzy C-Means clustering algorithms for connection oriented telecommunication data

@&#HIGHLIGHTS@&#
The partition based clustering algorithms k-Means and Fuzzy C-Means algorithms are taken for analysis via its computational time.The distance between servers and user connections of telecommunication data are taken for clustering.The computational time and number of connections in each server was reported by the algorithms after clustering process.The distribution of data points by k-Means algorithm is even to all the data centers, but, it is not even by the FCM algorithm.From the experimental analysis, the computational time of k-Means algorithm is less than the FCM algorithm.

@&#KEYPHRASES@&#
k-Means algorithm,Fuzzy C-Means algorithm,Data clustering,Data analysis,Telecommunication data,

@&#ABSTRACT@&#
Data mining is the process of discovering meaningful new correlation, patterns and trends by sifting through large amounts of data, using pattern recognition technologies as well as statistical and mathematical techniques. Cluster analysis is often used as one of the major data analysis technique widely applied for many practical applications in emerging areas of data mining. Two of the most delegated, partition based clustering algorithms namely k-Means and Fuzzy C-Means are analyzed in this research work. These algorithms are implemented by means of practical approach to analyze its performance, based on their computational time. The telecommunication data is the source data for this analysis. The connection oriented broad band data is used to find the performance of the chosen algorithms. The distance (Euclidian distance) between the server locations and their connections are rearranged after processing the data. The computational complexity (execution time) of each algorithm is analyzed and the results are compared with one another. By comparing the result of this practical approach, it was found that the results obtained are more accurate, easy to understand and above all the time taken to process the data was substantially high in Fuzzy C-Means algorithm than the k-Means.

@&#INTRODUCTION@&#
Data mining (DM) is the extraction of useful and non-trivial information from the large amount of data that is possible to collect in many and diverse fields of science, business and engineering. DM is part of a bigger framework, referred to as knowledge discovery in databases (KDD) that covers a complex process from data preparation to knowledge modeling. Within this process, DM techniques and algorithms are the actual tools that analysts have at their disposal to find unknown patterns and correlation in the data. Typical DM tasks are classification (assign each record of a database to one of a predefined set of classes), clustering (find groups of records that are close according to some user defined metrics) and association rules (determine implication rules for a subset of record attributes). A considerable number of algorithms have been developed to perform these and others tasks, from many fields of science, from machine learning to statistics through various computing technologies like neural and fuzzy computing. What was a hand tailored set of case specific recipes, about ten years ago, is now recognized as a proper science. It is sufficient to consider the remarkable wide spectrum of applications where DM techniques are currently being applied to understand the ever growing interest from the research community in this domain.Data mining can be viewed as an essential step in the process of knowledge discovery. Data are normally preprocessed through data cleaning, data integration, data selection, and data transformation and prepared for the mining task. Started as little more than a dry extension of DM techniques, DM is now bringing important contributions in crucial fields of investigations and in the traditional sciences like astronomy, high energy physics, biology and medicine [8] that have always provided a rich source of applications to data miners. An important field of application for data mining techniques is also the World Wide Web. The Web provides the ability to access one of the largest data repositories, which in most cases still remains to be analyzed and understood. Recently, data mining techniques are also being applied to social sciences, home land security and counter terrorism. A DM system is therefore composed of a software environment that provides all the functionalities to compose DM applications, and a hardware back-end onto which the DM applications are executed.This paper discusses about one of the application areas of partition based clustering algorithms k-Means and Fuzzy C-Means by means of an experimental approach choosing a real time telecommunication data. Many applications have been proposed by using different algorithms. Now, it is necessary to discuss some of the applications of related areas. This will be helpful to understand the related breakthrough in computations and engineering applications. Ling-Zhong Lin and Tsuen-Ho Hsu give a study about designing a model of FANP in brand image decision-making in their paper [21]. They discuss that both theoretical and practical efforts in band images often neglect the characteristics having interactions and mutual influence among attributes or criteria, even in the stages of different brand life cycles. This study aims to create a hierarchical framework for brand image management. The analytical network process and fuzzy sets theory have been applied to both mindshare in brand images and inherent interaction/interdependencies among diverse information resources. A real empirical application is demonstrated in the department store. Both the theoretical and practical background of this paper have shown the fuzzy analytical network process can capture expert's knowledge existing in the form of incomplete and vague information for the mutual inspiration on attribute and criteria of brand image management.Chien-wen Shen et al. presents a fuzzy AHP-based fault diagnosis for semiconductor lithography process [22]. This study proposes the approach of fuzzy analytic hierarchy process (FAHP) for the ambiguous fault evaluations of lithography process. The application of FAHP has several advantages over conventional approaches because it is able to enumerate the managerial causes of lithography faults and to homogenize the differences among the subjective judgments of on-site engineers. Together with the fuzzy set theory, this study provides a systematic mechanism to construct a hierarchy of FAHP model and a FAHP diagnosis map for the lithography process. A paper titled as “Application of quality function deployment to improve the quality of Internet shopping website interface design,” is presented by Hui-Ming Kuo and Cheng-Wu Che [23]. They analyzed that the popularization and rapid development of the Internet has fostered the growth of online shopping leading it to become an important new channel for consumers to make purchases. The Internet users’ rate of satisfaction has declined since online shopping has become an important consumer option. In order to improve customer satisfaction and to enhance the shopping experience, it is very important to understand the customer quality needs particular to the Internet shopping website, then to meet these needs through suitable website interface design. A B2C shopping website is used as an example in this study. Quality function deployment (QFD) is utilized to attain an understanding of customer quality needs, quality elements, and the relationship between them. Suggestions for improving the quality of website design are proposed based on the case study and the major performance indices discussed. Conclusions can be used as reference for online shopping website operators wishing to enhance the keenness of their websites in the highly competitive online shopping market.“Fuzzy control of interconnected structural systems using the fuzzy Lyapunov method”, a study carriedout by C.W. Chen [24]. In this study, a closed-form, easy-to-use fuzzy control method for interconnected structural systems is developed. First, the structural systems are reviewed. Interconnected schemes are employed to represent the structural systems and their subsystems. The representation of the interconnected systems consists of J interconnected subsystems. Stability is ensured by the criteria derived from the fuzzy Lyapunov functions. The fuzzy Lyapunov function is defined as the fuzzy blending of quadratic Lyapunov functions. Common solutions can be obtained by solving a set of linear matrix inequalities that are numerically feasible. To verify the effectiveness of the interconnected structural system, explanatory examples are presented for a practical tuned mass damper mounted on a building structure. Finally, the proposed control method is demonstrated using an example in which the interconnected technique is utilized to represent large-scale structural systems.A paper presented by Cheng-Wu Chen titled as “Stability conditions of fuzzy systems and its application to structural and mechanical systems” [25]. This paper provided the stability conditions and controller design for a class of structural and mechanical systems represented by Takagi–Sugeno (T–S) fuzzy models. In this design procedure of controller, parallel-distributed compensation (PDC) scheme was utilized to construct a global fuzzy logic controller by blending all local state feedback controllers. A stability analysis was carried out not only for the fuzzy model but also for a real mechanical system. Furthermore, this control problem can be reduced to linear matrix inequalities (LMI) problems by the Schur complements and efficient interior-point algorithms are now available in Matlab toolbox to solve this problem. A simulation example was given to show the feasibility of the proposed fuzzy controller design method.Data mining is to be performed on various types of databases and information repositories, but the kind of patterns to be found are specified by various data mining functionalities like class/concept description, association, correlation analysis, classification, prediction, cluster analysis etc. Among these, Cluster analysis is one of the major data analysis method widely used for many practical applications in emerging areas [8,11]. The quality of a clustering result depends on both the similarity measure used by the method and its implementation and also by its ability to discover some or all of the hidden patterns. There is a number of clustering techniques that have been proposed over the years [3]. Different clustering approaches may yield different results. The partitioning based algorithms are frequently used by many researchers for various applications in different domains. This research work deals two of the partitioning based clustering techniques as stated. With these discussions, about data mining and clustering methods, the next section discusses some of the application areas of the two algorithms.The rest of the paper is structured as follows. Section 2 presents some of the application areas of chosen algorithms and their approaches. In Section 3, the basics of k-Means and fuzzy clustering methods are described. Section 4 discusses about the experimental setup of the proposed method is discussed. Section 5 covers the experimental studies, results, and a brief discussion. Finally, Section 6 presents the conclusions of the research work.Clustering means creating groups of objects based on their features in such a way that the objects belonging to the same groups are similar and those belonging in different groups are dissimilar. Clustering is one of the standard workhorse techniques in the field of data mining. Its intention is to systematize a dataset into a set of groups, or clusters, which contain similar data items, as measured by some distance function. The major applications of clustering include document categorization, scientific data analysis, customer/market segmentation and www. The other areas include pattern recognition, artificial intelligence, information technology, image processing, biology, psychology, and marketing. Some of the areas specifically used clustering concepts nowadays are:•Marketing: Help marketers discover distinct groups in their customer bases, and then use this knowledge to develop targeted marketing programs.Land use: Identification of areas of similar land use in an earth observation database.Insurance: Identifying groups of motor insurance policy holders with a high average claim cost.City-planning: Identifying groups of houses according to their house type, value, and geographical location.Earth-quake studies: Observed earth quake epicenters should be clustered along continent faults.Data clustering has attracted the attention of many researchers in different disciplines. It is an important and useful technique in data analysis. A large number of clustering algorithms have been put forward and investigated. Clustering is an unsupervised learning technique. Unlike classification, in which objects are assigned to predefined classes, clustering does not have any predefined classes. The main advantage of clustering is that interesting patterns and structures can be found directly from very large data sets with little or none of the background knowledge. The cluster results are subjective and implementation dependent. The quality of a clustering method depends on the similarity measure used by the method and its implementation; its ability to discover some or all of the hidden patterns and the definition and representation of cluster chosen by the user [12].A variety of data clustering algorithms are developed and applied for many applications domain in the field of data mining [11]. Clustering techniques have been applied to a wide variety of research problems. Hartigan provides an excellent summary of many published studies reporting the results of cluster analysis [9]. For example, in the field of medicine, clustering diseases, treatment curves for diseases, or symptoms of diseases can lead to very useful taxonomies. In the field of psychiatry, the correct diagnosis of clusters of symptoms such as paranoia, schizophrenia, etc. is essential for successful therapy. In archeology, researchers have attempted to establish taxonomies of stone tools, funeral objects, etc. by applying cluster analytic techniques. In general, whenever one needs to classify a “mountain” of information into manageable meaningful piles, cluster analysis is of great utility.A review of the most common partition algorithms in cluster analysis: A comparative study is discussed in a research work [14]. The main objective of this study is to compare several partition methods in the context of cluster analysis, which are also called nonhierarchical methods. In this work, a simulation study is performed to compare the results obtained from the implementation of the algorithms k-Means, k-Medians, PAM and CLARA when continuous multivariate information is available. Additionally, a study of simulation is presented to compare partition algorithms qualitative information, comparing the efficiency of the PAM and k-modes algorithms. The efficiency of the algorithms is compared using the Adjusted Rand Index and the correct classification rate. Finally, the algorithms are applied to real databases with predefined classes.An enhanced k-Means algorithm to improve the Efficiency Using Normal Distribution Data Points is discussed by Napoleon and Ganga Lakshmi. This paper [15] proposes a method for making the k-Means algorithm more effective and efficient; so as to get better clustering with reduced complexity. In this research, the most representative algorithms k-Means and the enhanced k-Means were examined and analyzed based on their basic approach. The best algorithm was found out based on their performance using normal distribution data points. The accuracy of the algorithm was investigated during different execution of the program on the input data points. The elapsed time taken by proposed enhanced k-Means is less than k-Means algorithm. Benderskaya et al. describes [7] Self-organized Clustering and Classification: A Unified Approach via Distributed Chaotic Computing. The paper describes a unified approach to solve clustering and classification problems by means of oscillatory neural networks with chaotic dynamics. It is discovered that self-synchronized clusters once formed can be applied to classify objects. The advantages of distributed clusters formation in comparison to centers of clusters estimation are demonstrated. New approach to clustering on-the-fly is proposed.A Novel Approach to Medical Image Segmentation is presented by Shanmugam et al. in their paper [13]. In this research, a novel approach is used to segment the 2D echo images of various views. A modified k-Means clustering algorithm, called “Fast SQL k-Means” is proposed using the power of SQL in DBMS environment. In k-Means, Euclidean distance computation is the most time consuming process. However, here it computed with a single database table and no joins. This method takes less than 10s to cluster an image size of 400×250 (100K pixels), whereas the running time of direct k-Means is around 900s. Since the entire processing is done with database, additional overhead of import and export of data is not required. The 2D echo images are acquired from the local Cardiology Hospital for conducting the experiments. A Fast Fuzzy C-Means algorithm (FFCM) is proposed by Al-zoubi et al. [2] based on experimentations, for improving fuzzy clustering. The algorithm is based on decreasing the number of distance calculations by checking the membership value for each point and eliminating those points with a membership value smaller than a threshold value. They applied FFCM on several data sets. The experiments demonstrate the efficiency of the proposed algorithm.An Application of fuzzy models for the monitoring of ecologically sensitive ecosystems in a dynamic semi-arid landscape from satellite imagery is discussed by Meng-Lung Lin and Cheng-Wu Chen [26]. The purpose of this paper is for better understanding of landscape dynamics in arid and semi-arid environments. Land degradation has recently become an important issue for land management in western China. This study shows that it is possible to derive important parameters linked to landscape sensitivity from moderate resolution imaging spectro radiometer (MODIS) and the derived imagery, such as normalized difference vegetation index (NDVI) time-series data. The results of landscape sensitivity analysis prove the effectiveness of the method in assessing landscape sensitivity from the years 2001–2005. Practical implications – the novel strategy used in this investigation is based on the T–S fuzzy model, which is in turn based on fuzzy theory and fuzzy operations. Originality/value – simulation results based on fuzzy models will help to improve the monitoring techniques used to evaluate land degradation and to estimate the newest tendency in landscape green cover dynamics in the Ejin Oasis.Tsung-Hao Chen and Cheng-Wu Chen present a study about an application of data mining to the spatial heterogeneity of foreclosed mortgages [27]. The loss given a default (LGD) is a key component when calculating the credit risk associated with an asset portfolio. However, the issue of default probability has not often been addressed in past mortgage loan data mining studies. The LGD has rarely been used to assess the comprehensive credit risk for a portfolio of mortgage loans. The location of a mortgaged property is strongly correlated with the price of that property as well as providing social, demographic, and economic information which inherently characterizes the mortgage loan population. To make an accurate assessment of the credit risk associated with the loan portfolio, one requires a specific data mining technique capable of determining the heterogeneity of the portfolio across regions. The sample used in this study consists of data on two thousand foreclosed mortgages in Kaohsiung City. They first test the homogeneity between the different city districts; second, they estimate the magnitude of the heterogeneity, including the spatial heterogeneity; third, a prior distribution for the heterogeneity is formulated using data mining methods; finally, the overall LGD, showing the credit risk for a given default probability is calculated.Feng-Hsiag Hsiao et al. given a detailed study on “Robust Stabilization of Nonlinear Multiple Time-Delay Large-scale Systems via Decentralized Fuzzy Control” [28]. To overcome the effect of modeling errors between nonlinear multiple time-delay subsystems and Takagi–Sugeno (T–S) fuzzy models with multiple time delays, a robustness design of fuzzy control is proposed in this work. In terms of Lyapunov's direct method, a delay-dependent stability criterion is hence derived to guarantee the asymptotic stability of nonlinear multiple time-delay large-scale systems. Based on this criterion and the decentralized control scheme, a set of model-based fuzzy controllers is then synthesized via the technique of parallel distributed compensation (PDC) to stabilize the nonlinear multiple time-delay large-scale system. Finally, a numerical example with simulations is given to demonstrate the concepts discussed throughout this work.Cluster analysis is sensitive to both the distance metric selected and the criterion for determining the order of clustering [6]. Different approaches may yield different results. Consequently, the distance metric and clustering criterion should be chosen carefully. The results should also be compared to analyses based on different metrics and clustering criteria, or to an ordination, to determine the robustness of the results. In the partitioning methods, the centroid based technique is k-Means method and Fuzzy C-Means (FCM), which is the special kind of k-Means method. Many researchers suggest these algorithms are performing well to implement some kind of inputs. Both the algorithms work based the given distance measure.An important step in most clustering is to select a distance measure, which will determine how the similarity of two elements is calculated. This will influence the shape of the clusters, as some elements may be close to one another according to one distance and farther away according to another. For example, in a 2-dimensional space, the distance between the point (x=1, y=0) and the origin (x=0, y=0) is always 1 according to the usual norms, but the distance between the point (x=1, y=1) and the origin can be 2, √2 or 1 if you take respectively the 1-norm, 2-norm or infinity-norm distance. The variety of common distance functions is as follows:•The Euclidean distance. This type of distance is also called as the distance as the crow flies or 2-norm distance.The Manhattan distance (aka taxicab norm or 1-norm).The maximum norm (aka infinity norm).The Mahalanobis distance corrects data for different scales and correlations in the variables.The angle between two vectors can be used as a distance measure when clustering high dimensional data.The Hamming distance measures the minimum number of substitutions required to change one member into another.Another important distinction is whether the clustering uses symmetric or asymmetric distances. Many of the distance functions listed above have the property that distances are symmetric (the distance from object A to B is the same as the distance from B to A). In other applications, this is not the case. A true metric gives symmetric measures of distance. The symmetric and 2-norm distance measure is used in this research work. In the Euclidean space Rn, the distance between two points is usually given by the Euclidean distance (2-norm distance). The formula for 2-norm distance is(1)2-Norm distance=∑i=1n|xi−yi|21/2The 2-norm distance is the Euclidean distance, a generalization of the Pythagorean Theorem to more than two coordinates. It is what would be obtained if the distance between two points were measured with a ruler: the “intuitive” idea of distance. Based on this idea of finding the distance, the clustering qualities of the proposed algorithms are analyzed here. As stated in previous sections, this research is to compare the two partitioning based clustering algorithms namely k-Means, FCM are discussed below.The k-Means is one of the simplest unsupervised learning algorithms that solve the well-known clustering problem. The procedure follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters) fixed a priori [1,10]. The main idea is to define k centroids, one for each cluster. These centroids should be placed in a cunning way because of different location causes different result. So, the better choice is to place them as much as possible far away from each other. The next step is to take each point belonging to a given data set and associate it to the nearest centroid. When no point is pending, the first step is completed and an early group age is done. At this point it is necessary to re-calculate k new centroids as bar centers of the clusters resulting from the previous step. After obtaining these k new centroids, a new binding has to be done between the same data set points and the nearest new centroid. A loop has been generated. As a result of this loop, one may notice that the k centroids change their location step by step until no more changes are done. In other words centroids do not move any more. Finally, this algorithm aims at minimizing an objective function, in this case a squared error function. The objective function(2)J=∑j=1k∑i=1nxi(j)−cj2,wherexi(j)−cj2is a chosen distance measure between a data pointxi(j)and the cluster center cj, is an indicator of the distance of the n data points from their respective cluster centers. The algorithm is composed of the following steps:1.Place k points into the space represented by the objects that are being clustered. These points represent initial group centroids.Assign each object to the group that has the closest centroid.When all objects have been assigned, recalculate the positions of the k centroids.Repeat Steps 2 and 3 until the centroids no longer move. This produces a separation of the objects into groups from which the metric to be minimized can be calculated.Although it can be proved that the procedure will always terminate, the k-Means algorithm does not necessarily find the most optimal configuration, corresponding to the global objective function minimum. The algorithm is also significantly sensitive to the initial randomly selected cluster centers. The k-Means algorithm can be run multiple times to reduce this effect. k-Means is a simple algorithm that has been adapted to many problem domains and it is a good candidate to work for a randomly generated data points. One of the most popular heuristics for solving the k-Means problem is based on a simple iterative scheme for finding a locally minimal solution [16,18]. This algorithm is often called the k-Means algorithm. There are some difficulties in using k-Means for clustering data. This is proved by several times in this current as well as in the past research, and an oft-recurring problem has to do with the initialization of the algorithm.Clustering approaches based on fuzzy logic, such as FCM [4,5] and its variants [19,20] have proved to be competitive to conventional clustering algorithms, especially for real-world applications. The comparative advantage of these approaches is that they do not consider sharp boundaries between the clusters, thus allowing each feature vector to belong to different clusters by a certain degree (the so-called soft clustering in contrast to hard clustering produced by conventional methods). The degree of membership of a feature vector to a cluster is usually considered as a function of its distance from the cluster centroids or from other representative vectors of the cluster. The fuzzy features of the k-Means algorithm are some times referred as Fuzzy C-Means algorithm.Traditional clustering approaches generate partitions; in a partition, each pattern belongs to one and only one cluster. Fuzzy clustering extends this notion to associate each pattern with every cluster using a membership function. The output of such algorithms is a clustering, but not a partition some times. Fuzzy clustering is an extensively applied method for obtaining fuzzy models from data. It has been applied successfully in various fields including geographical surveying, finance or marketing. The most widely used clustering algorithm implementing the fuzzy philosophy is FCM, initially developed by Dunn and later generalized by Bezdek [4], who proposed a generalization by means of a family of objective functions. Despite this algorithm proved to be less accurate than others, its fuzzy nature and the ease of implementation made it very attractive for a lot of researchers that proposed various improvements and applications. Usually FCM is applied to unsupervised clustering problems. The basic structure of the FCM algorithm is discussed below. The Algorithm FCM is a method of clustering which allows one piece of data to belong to two or more clusters. This method is frequently used in pattern recognition [2,18,29]. It is based on minimization of the following objective function:(3)Jm=∑i−1N∑j−1Cuijmxi−cj2,1≤m<∞where m is any real number greater than 1, uijis the degree of membership of xiin the cluster j, xiis the ith of d-dimensional measured data, cjis the d-dimension center of the cluster, and ||*|| is any norm expressing the similarity between any measured data and the center. Fuzzy partitioning is carried out through an iterative optimization of the objective function shown above, with the update of membership uijand the cluster centers cjby:(4)uij=1∑k=1c[||xi−cj||/||xi−ck||]2/(m−1),…cj,=∑i=1Nuijmxi∑i=1Nuijm(5)This iteration will stop when maxij{|uij(k+1)−uij(k)|}<ξ,where ξ is a termination criterion between 0 and 1, whereas k is the iteration steps. This procedure converges to a local minimum or a saddle point of Jm. The algorithm is composed of the following steps:Step 1: Initialize U=[uij] matrix, U(0).Step 2: At k-step: calculate the centers vectors C(k)=[cj] with U(k).Step 3: Update U(k), U(k+1).Step 4: If ||U(k+1)−U(k)||<ξ then STOP; otherwise return to step 2.In this algorithm, data are bound to each cluster by means of a Membership Function, which represents the fuzzy behavior of the algorithm. To do that, the algorithm have to build an appropriate matrix named U whose factors are numbers between 0 and 1, and represent the degree of membership between data and centers of clusters. In general introducing the fuzzy logic in k-Means clustering algorithm is the FCM algorithm. FCM clustering techniques are based on fuzzy behavior and provide a natural technique for producing a clustering where membership weights have a natural (but not probabilistic) interpretation. This algorithm is similar in structure to the k-Means algorithm and also behaves in a similar way.Data mining concepts are used in different applications as per the need, demand, nature of the problem and domain. The data mining concepts such as association, clustering, classification, indexing is used as per the process requirements [17]. In this research, the clustering process is achieved using a distance method. The clustering process is aimed to minimize the expenditure of the business application and increase the benefits. The algorithms are implemented in the real time connection oriented telecommunication data and the results are discussed. In this process, the data communication connection structure is evaluated and reconstructed using clustering techniques for the effective data distribution. The data distribution process is affected by the connected server, distance and number of connections available in the specific server. The distance factor also create an impact on the creation of the infrastructure using cable, cost of the cable, manpower, maintenance and the data distribution based on the bandwidth. Therefore the data access points are considered as data points and planned to optimize the network using clustering concepts. In this process, the proposed two algorithms namely k-Means and Fuzzy C-Means are adopted.The data set is collected from a broadband service provider at Chennai city. The connection oriented data set contains 285,520 data connection points with 27 server locations. The 27 servers are treated as 27 clusters in this work and they are called as data centers. The user points are called as data access points. There are 12 data sets available. One data set for each month. The data set contains information about distance, type of connection (single user, multi user), data transfer capacity (256, 512, 1024, 2048), area code and which server the data points are connected. This representation is based on the connections established from the month of January to December. The collected data consists of the connection establishment month, area and the connected data center, type of the data service and the volume of data used in the year. The total connection of data access points is connected according to the geographical location. This connection is made, based on the demand of the customer which is provided by the service provider.Table 1shows the total number of connected data points for each and every month for the 27 servers. The distance between data centers and its data access points in meters are given in the data set. The servers (data centers) are treated as center point in the clustering process. Normally, the distance between one server and the same server is zero. The number of data access points in each data center is represented in Tables 2 and 3before the clustering process.The data access points are currently distributed unevenly based on the request of the user at every month and connection given to the users based on the availability of the nearest data centers. But this caused the issues in the traffic and the distribution of data. It affects the quality of the server to the user as well as the service provider. In the exiting connection, the data center 27 has 279 connections. This is the minimum number of connection in a particular data center. The first data center has 14,101 data access points, which is the maximum of all the data centers. Fig. 1show the distribution of data access points in different data centers before the clustering process.The discussed k-Mean, FCM algorithms are implemented using MATLAB 7.5 and the results are discussed in this section. In the implementation process, the data set is processed based on the distance as stated. Initially, first data center (selected as center point) and the first month (January) are selected. For the selected data center and for the month, the distance is reconstructed and stored in the process matrix. The reconstruction of distance is made by using the Pythagoras theorem. After the reconstruction of distance, the data access points are clustered using any one of the proposed algorithm. In this process, the distance between the data centers and data access points is clustered for the chosen algorithm. After the processing, each data center has some new number of data access points. Next, by choosing the same first data center, the second month (February) data access points are chosen and clustered using the algorithm. The process is repeated up to the last month (December) data. After processing the 12th month data by choosing the first server, the second server is chosen and the process repeated. Hence the number of connections in each data center is considered as application impact and the process time is considered as computation impact. The algorithmic steps involved in the clustering process are summarized below.(a)Selection of algorithm from k-Means or FCM.Selection of data center.Calculation of the distance between data access points based on selected data center.Selection of monthly data.Implementation of the selected algorithm and cluster the distance.According to the processed cluster, the data points are reassigned to the data center.Observe the cluster process start time and completion time.Summaries the number of connection into each data center.Implement the step b to h to all the different data sets.Represent the data connection according to the newly assigned data center.Using the above procedure, the computational time (in seconds) of the two algorithms for the entire 12 data set is calculated and stored. Also, the number of connections in each server is assigned by the algorithm and stored in the result matrix. This work mainly discusses about the time complexity between the two algorithms. The experimental results of both the algorithms are discussed in the subsequent sections.The k-Mean clustering algorithm is implemented as per the discussion above. Table 4is the processing time for the k-Means algorithm. The total elapsed time to cluster the first month data set for the entire 27 data center is given in the last column. The average processing time of all the 12 month data is available in the last row, which is found to be 17.925s. Tables 5 and 6shows that the results of k-Means algorithm by choosing the first server for all the 12 month data set. After the clustering process, the first server contains 556 data points. Before clustering, the first server has 1268 data points. The last row consists of average processing time of the first server data points. The data points in each data center points are clustered (distributed) using the k-Means algorithm based on the neighborhood distance. The total of 285,520 data points is distributed. The sum of the average of the entire server is 23,793. Multiplying this value by 12, the result is equal to the total number of data access points 285,520. Like, by choosing the first server as a center point, the second server is chosen and the clustering process repeated. The k-Means algorithm is executed 12 times and the average results are listed in Tables 7 and 8. These tables contain only the average data points. The average data points in the first server is found to be 839, the second server is 818 and so on.The average results of k-Means algorithm given in Tables 7 and 8 are represented by means of a graph in Fig. 2. In this clustering process, the data center 23 is assigned with a minimum of 9853 data access points and the maximum of 11,185 in the data center 2. It is clear that from Fig. 2, the distribution of data points in each and every data center is almost closer to one another. In the distribution process, the data access points are equally divided for all the data centers. The average processing time of 12 runs of the k-Means clustering is observed and it is summarized in Table 9. The total of 285,520 data points with different data center distance is processed. The algorithm takes a minimum of 15.919s in the 7th run and a maximum of 19.796s in the 5th run. The graphical representation of the average processing time of 12 runs listed in Table 9 is given in Fig. 3.The implementation of Fuzzy C Means (FCM) method is discussed for the same data set. As per the discussion of the previous sections, the FCM method is executed and the results are given in Table 10. Initially, the new distance matrix is formed. Based on the new distance between the data access points and the data centers, the clustering process is carried out by the FCM algorithm. By choosing the first data center as a center point, the processing time for all the 12 month data set is clustered and the processing time is given in Table 10. The average processing time for the entire 12 month data set is found to be 101.007s.Tables 11 and 12are the results of FCM algorithm for the first data center as a center point. This result is the single execution result of all the 12 months data set. In these tables, the FCM algorithm assigns 518 data access points for the first server, 960 points for second server and so on. The average of all the 12 month data set for the first server is 461; second server is 911 and so on. Like, the algorithm is executed 12 times (by trial and error method) and the average data access points are tabulated in Tables 13 and 14.In the FCM clustering process, the minimum and maximum data points assigned by the algorithm is 4348 and 15,763 respectively. The minimum number of data points assigned to the first data center and the maximum is assigned to the 5th data center. Fig. 4represents the distribution of data access points by the FCM clustering method. The number of connections is more for some clusters and for some other, it is very less. The processing time of 12 runs of the algorithm is listed in Table 15. The maximum time 101.007s is taken by the algorithm for the first run and the minimum time 69.920s is taken by the 10th run. The process time of FCM is comparatively high with the previous two methods. Fig. 5shows the graphical representation of the results of FCM algorithm.

@&#CONCLUSIONS@&#
Cluster analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. Here it is necessary to summarize with listing some important issues and research trends for clustering algorithms. There is no clustering algorithm that can be universally used to solve all problems. Usually, algorithms are designed with certain assumptions and favor some type of biases. In this sense, it is not accurate to say “best” in the context of clustering algorithms, although some comparisons are possible. These comparisons are mostly based on some specific applications, under certain conditions, and the results may become quite different if the conditions change. In summary, clustering is an interesting, useful, and challenging problem. It has great potential in applications like object recognition, image segmentation, and information filtering and retrieval. However, it is possible to exploit this potential only after making several designs choices carefully. The k-Means and Fuzzy C-Means are very well known clustering algorithms in the partition based algorithms and they have been used in many application areas. It is very well known that each of the two algorithms has pros and cons. On because of its simplicity, the k-Means runs faster, but vulnerable to noises. Fuzzy C-Means is a little bit more complex and hence runs slower, but stronger to noises. In order to confirm this stronger quality of these two algorithms, one of the applications area is chosen to test this notion in this work.From the experimental approach, by several executions of the program for the proposed two algorithms in this research work, the following results were obtained. Usually, the time complexity varies from one processor to another processor, which depends on the speed and type of the system. The partitioning based algorithms work well for finding spherical-shaped clusters in small to medium-sized data points. The advantage of the k-Means algorithm is its favorable execution time. Its drawback is that the user has to know in advance how many clusters are searched for. From the experimental analysis, the computational time of k-Means algorithm is less than the FCM algorithm. Further, k-Means algorithm stamps its superiority in terms of its lesser execution time. Also, the distribution of data points by k-Means algorithm is even to all the data centers, but, it is not even by the FCM algorithm. This means that the data points are evenly distributed by k-Means algorithm. But, the FCM algorithm has some variations in the distribution.