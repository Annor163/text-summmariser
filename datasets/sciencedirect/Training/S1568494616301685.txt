@&#MAIN-TITLE@&#
Multi-criteria decision making approach in E-learning: A systematic review and classification

@&#HIGHLIGHTS@&#
A review regarding application of MCDM techniques in E-learning is conducted.Five major databases have been considered for this review.ScienceDirect, Emerald, Taylor and Francis, IEEE, and Springer have been selected.A systematic and meta analysis methodology called “PRISMA” has been proposed.Papers between 2001 and 2015 have been considered for this review.

@&#KEYPHRASES@&#
MCDM techniques,E-learning,Classification,PRISMA,

@&#ABSTRACT@&#
Academic research on E-learning has increased extensively over the past few years. Although, many multi-criteria decision making methods have been proposed to evaluate and examine the effectiveness of E-learning, there is a lack of study concerning systematic literature review and classification of research in this area. Regarding this, five major databases including ScienceDirect, Emerald, Taylor and Francis, IEEE, and Springer have been selected and a systematic methodology proposed. Consequently, a review of 42 published papers appearing in 33 academic journals and international conferences between 2001 and 2015 have been obtained to achieve a comprehensive review of MCDM application in E-learning. Accordingly, the selected papers have been classified by the year of publication, MCDM techniques, and journals and conferences in which they appeared. In addition, the significant criteria in evaluating E-learning were found. This study supports researchers and practitioners in effectively adopting MCDM techniques regarding E-learning evaluation and provides an insight into its state-of-the-art.

@&#INTRODUCTION@&#
E-learning, a term introduced in 1998 by Jay Cross, founder of Internet Time Group, has become extremely popular [125,47,96]. In general, E-learning is an innovative approach in education delivery via electronic information frameworks for enhancing the quality of teaching and learning [153,16,60,10]. Lara et al. [84] expressed that E-learning is the use of Internet by learners in order to learn specific information and content. Whereas, Bhuasiri et al. [10] defined E-learning as utilizing modern Information and Communications Technology (ICT) and computers to deliver data, instructions, and learning contents. E-learning can appear in different forms of designation and use synonymously as web-based learning, online learning, course-learning, virtual classrooms learning, and digital collaboration learning [134,30,141,71,150,70].Moreover, E-learning brings advantages to world organizations and stakeholders. Based on the previous literature and research, main advantages of E-learning that highly motivate users in efficiently learning contents include: access flexibility, on-demand availability, personalized instruction, timely content delivery, content standardization, increased convenience, accountability, self-pacing, confidence, and interactivity. Further advantages of E-learning lie behind cost reduction, consistent delivery of learning materials, and enhancement of tracking for universities [35,33,121,155,161,75,55,92]. Moreover, further research indicated that E-learning systems decrease costs of classroom equipment, training, printed materials, traveling, and labor [24,142,129,121,152,155,160].World governments have been emphasizing and investing in E-learning services among social and public education with the purpose of expanding E-learning systems as a new method of effective education. According to Bates [8], E-learning has been supported by governments due to the economic competition, lifelong learning, social equality and accessibility, better education, cost effectiveness, commercializing of education and geographic reasons. The overall European Commission’s E-government Action Plan for the period of 2011–2015 intends to facilitate the transition of administrations to a new generation of E-government services at local, regional, national and European levels [36]. In addition, effective E-learning implementations and quality improvement have been the main challenges in the developing countries [139,76,10,48,136,128,58,12,113,50,6].Although E-learning has been developing for several years, the evaluation of E-learning is still a crucial task for organizations. The term “evaluation” is referred to as the process by which people judge about value and worth of materials [114]. According to Tzeng et al. [147], the main reason for evaluating E-learning is to understand the effectiveness, efficiency, and appropriateness of a course of action. The evaluation of E-learning enables E-learning managers and decision makers to highlight good or bad actions, identify errors, correct mistakes, detect risks, achieve optimum investment, and consequently it allows individuals to learn efficiently [119]. Over the last years, a considerable number of studies using different kinds of evaluation methods have been conducted in order to evaluate E-learning by examining related influencing criteria. [102,22,94,103,106,31,148,100].During the evaluation of E-learning, criteria show multiple and sometimes conflicted attributes. Moreover, the criteria evaluation becomes much more accurate if the opinions of experts and managers are considered. This type of evaluation assists to find the most influential criteria in respective areas [146,32,79,77,78]. An alternative to that is Multi-Criteria Decision Making (MCDM) which is an efficient approach for evaluating multiple criteria. MCDM supports experts and managers to balance and weight various factors in order to simplify and clarify decisions for managers [65,37]. Hence, the MCDM approach has been recently considered an appropriate and effective method for evaluating E-learning. Over the last decade, many researchers have adopted different MCDM methods to determine and prioritize different aspects of E-learning [63,51,81,10,5,91,89,162,147].However, further research is required for E-learning evaluation using MCDM techniques, since E-learning is still broad and the application of MCDM in this domain is less mature compared to its usage in other research areas. Therefore, existing papers on E-learning which applied MCDM methods need to be reviewed in order to provide an outlook towards the next generation of E-learning. In this research, we reviewed and classified academic journal and international conference papers which used MCDM techniques in E-learning evaluation published between 2001 and 2015. The purpose of this literature review is to provide an overview about the application of MCDM methods in E-learning.The reminder part of this manuscript is divided into the following sections: an introduction of MCDM and its specific methods is presented in Section 2. The research methodology used in this study is explained in Section 3. Sections 4 and 5 focus on summarizing the previous related works and finding the significant factors respectively. In Section 6, based on different indices, selected papers are classified and presented. Finally, discussions, conclusions, and future works are presented in Sections 7 and 8, respectively.We hope that this research will accentuate the importance of MCDM application in E-learning and provide researchers and practitioners with insight into state-of-the-art in E-learning evaluation.MCDM is a collection of methodologies to compare, select, or rank multiple alternatives that typically involve incommensurate attributes [61,82,85]. MCDM approach deals mainly with different classes of decision problems such as classification, sorting, and ranking to support experts and decision makers in finding consistent and robust solutions for multi-criteria problems [140,68,108]. MCDM is one of the decision methodologies that has been extensively used in complex areas like science and industry, in which they are highly capable of enhancing quality decisions by making its process more explicit, rational, and efficient [73,40,116].According to Simon [137], the MCDM process comprises four major phases which are as following:iIntelligence phase: this phase aims at clarifying the goal of the decision by means of defining the problem.Design phase: the formulation of MCDM model for decision problem is defined at this phase. Then, a set of criteria and alternatives based on the goal are determined.Choice phase: in this phase criteria are evaluated by the selected MCDM method. Then, a suitable solution to the decision problem is recommended.Implementation phase: in this phase, the suitable solution is implemented.Fig. 1shows the process of MCDM approach according to its four main phases.There are a number of well-known multi-criteria decision making methods for the purpose of alternative analysis and prioritization. According to Turskis and Zavadskas [146], multi-criteria decision making techniques vary in complexity and possible solutions. Each MCDM method has its own privilege, strength, and weakness for certain applications. In this review, most important and widely used MCDM techniques such as AHP, ELECTRE, TOPSIS, ANP, and DEMATEL are summarized and explained in the subsequent sections.The Analytical Hierarchy Process (AHP) was proposed by Saaty [122]. The AHP method is a comprehensive framework designed to be applied to certain, uncertain, rational and irrational multiple criteria decision problems. This method serves the evaluation, ranking and criteria selection, which results in optimized and predicted decisions [67,44,46,52,111,2,126]. Basically, AHP is expressed by a unidirectional hierarchy, which shows the relationship between goals and criteria levels. AHP utilizes the concept of hierarchy to simplify complex decision problems into elements [19,64,135]. This hierarchy is decomposed into several levels, in which the highest level represents decision goals and the lower level respective decision criteria. Sub-criterion elements are constructed under each relevant criterion [99]. The AHP method has been completely described by Tung et al. [145].The origin of Elimination and Choice Expressing Reality (ELECTRE) method goes back to 1996 when Roy and Vanderpooten [120] published an article on this very topic [41]. ELECTRE is capable of handling discrete criteria of both quantitative and qualitative in order to provide a complete order of alternatives. The concordance, discordance indices and threshold values are used in this technique. Based on these indices, graphs for strong and weak relationships are developed. These sorts of graphs are used in an iterative procedure to obtain the ranking of alternatives [39]. Besides this, the index is defined in the range (0–1) and provides a judgment on degree of credibility of each outranking relation. Moreover, it represents a test to verify the performance of each alternative. The ELECTRE approach has been completely described by Macary et al. [93].Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) was first introduced by Huang and Yoon in 1980 [116]. TOPSIS applies a simple concept of maximizing distance from the negative-ideal solution and minimizing the distance from the positive-ideal solution [7,115]. The chosen alternative must be as close as possible to the ideal solution and as far as possible from the negative-ideal solution. The ideal solution represents the maximal benefit solution determined from a composite of best performance values. The negative-ideal solution represents the minimal benefit solution, which is also the composite of worst values. TOPSIS makes full use of attribute information, provides a cardinal ranking of alternatives, and does not require attribute preferences to be independent. To apply this technique, attribute values must be numeric, monotonically increasing or decreasing, and have commensurable units. The TOPSIS approach has been completely described by Nilashi and Ibrahim [107].The theory of Analytic Network Process (ANP) was first introduced by Saaty [123] as a new essential phase in decision making theory. ANP is a special case of AHP, which changes problems to a network shape. In this network, goals and alternatives are interconnected. However, AHP aims at modeling problems into a hierarchy structure [124,45]. ANP enables feedback connections and loops between nodes to illustrate interdependence. The similarity between AHP and ANP lies in the use of pair-wise comparisons to measure the weights of alternatives, and finally to rank those for the process of decision [29,69,123]. However, the main difference between AHP and ANP is that ANP approaches decision problems more holistically by considering the dependence and feedback among the criteria [130,72,123,112,3]. The ANP method has been fully described by Ergu et al. [34].The Decision Making Trial and Evaluation Laboratory (DEMATEL) method originated from the Geneva Research Centre, Battelle Memorial Institute [43,42]. The DEMATEL method has been successfully applied in many fields by analyzing complex scientific, political and economic problems [109,110,21,87,131,56,127]. DEMATEL is especially practical and useful for visualizing the structure of complicated causal relationships using matrices or digraphs. The matrices or digraphs portray a contextual relation between the elements of the system, in which a number represents the strength of influence. Hence, the DEMATEL method can convert the relationship between the causes and effects of criteria into an intelligible structural model. The DEMATEL approach has been fully explained by Ahmadi et al. [1].Our review has conducted the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement of Moher et al. [101] as our reference methodology. PRISMA comprises systematic reviews and meta-analyses. A systematic review refers to a review of clearly formulated questions that use systematic and explicit methods. Meta-analysis refers to the use of statistical techniques in a systematic review to integrate the results of included studies [101]. The aim of PRISMA is to support researchers to complete the reporting of a transparent literature review [88]. This methodology has been widely conducted in different fields such as health, technology, and environment for the purpose of gathering a comprehensive literature review [57,26,13,88,117,154,138,28,38,27,149].In order to conduct PRISMA methodology in this study, three main steps need to be accomplished. These steps consist of literature search, selection of eligible papers, and data extraction and summarizing.In this stage, five electronic databases were chosen to provide a comprehensive application of MCDM in E-learning. These databases enclose ScienceDirect, Taylor and Francis, IEEE, Springer and Emerald Publishers. Papers published in academic journals and international conferences by these five databases are considered to be worthy of comment and reliable. The literature search was performed according to the following descriptors: “MCDM, MCDA, AHP, ANP, TOPSIS, DEMATEL, ELECTRE, LP, E-learning, web-based learning, online learning, virtual learning, network learning” and their combinations. Because research on MCDM in E-learning is relatively new, we did not consider the period of time restrictions. Hence, papers were gathered from 2001 to 2015. In summary, a total of 283 academic papers were extracted based on the above mentioned search strategies. After the removal of duplicated papers with redundant information, 221 potentially relevant articles remained. Titles and abstracts were then screened and irrelevant studies were removed, so that a total of 92 potentially relevant studies were remained (see Fig. 2).In this phase, full text of the papers extracted from previous stage reviewed independently by the authors for the purpose of eligibility. In final, a careful step was identified for paper selection to reach a consensus. Papers which had applied MCDM methods in E-learning were chosen. Another 3 papers that did not explicitly mention the use of MCDM methods in their content were identified among reviewing those selected papers. Master and doctoral dissertations, textbooks, book chapters, unpublished working papers, non-English papers, and abstract only papers were excluded. During the data extraction phase, we also had to exclude any studies that failed to provide a multi-criteria analysis in E-learning even they had used methods like Genetic Algorithm (GA) and Data Envelopment Analysis (DEA). Eventually, we selected 42 academic papers regarding MCDM application in E-learning, from 33 academic journals and international conferences which met our inclusion criteria.In the final stage of methodology, necessary data were gathered and any disagreement between authors was discussed and solved. Then, these 42 papers were summarized and significant factors were found (Sections 4 and 5). Next, academic papers were classified into different categories, including: publication year, MCDM techniques, and journal and conference in which they appeared (Section 6). The action of summarizing and categorizing papers enabled us to obtain several critical and impressive hints. As a result, several potential future works and recommendations were proposed. It is worth mentioning that the research investigation was performed carefully and it provided a comprehensive basis concerning MCDM application in E-learning.It should be noted that the main difficulty during applying PRISMA methodology was about implicit expressing of methods in abstract and methodology parts of the papers. Therefore, authors required to go through the whole content of papers and take a deeper look with more details to assess the exact employed method for E-learning criteria evaluation. Although it consumed a considerable amount of time in selection phase, it assisted us to select the most suitable publications in conducting this review.Previous studies regarding application of MCMD in E-learning which were extracted from last stage are summarized and categorized in following sub-sections. Based on the analysis, these 42 papers are classified into three main categories, including individual, integrated and others MCDM techniques.Based on the analysis of our data set papers, fourteen out of forty two (33.3%) papers have implemented AHP as an individual approach for evaluating E-learning. In following, these academic papers that applied AHP method for E-learning evaluation are summarized.Alice et al. [4] adopted AHP to rank and choose the suitable E-learning websites based on specific criteria in order to support students who intend to participate in interview.Begičević et al. [9] established a set of criteria regarding the evaluation of web-based learning. Then, AHP was employed to support web-based learning by using multi-criteria modeling in the process of group decision making.Chen and Yang [17] implemented AHP method’s basic theory analysis to evaluate the capability of self-learning in online learning. Therefore, they first established the evaluation index system based on experts’ opinion. Then, they used AHP to construct a network self-learning evaluation model as a comprehensive evaluation of data source.Colace et al. [25] proposed AHP method to select the most suitable E-learning platform with respect to its technological and pedagogical aspects. They argued that the hierarchical structure of the problem allows decision makers to compare various features of E-learning platforms.Gupta et al. [51] applied AHP technique to determine the quality of E-learning system. AHP was used to weight and rank E-learning quality requirements which are necessary to be noticed by stakeholders. They argued that the ranking obtained by using AHP could be an asset to educational system of organization.Jeong and Yeo [63] used pairwise comparison feature of AHP to evaluate nine extracted criteria concerning E-learning quality context. After evaluating and identifying criteria related weights, a quality model for E-learning system was established.Munkhtsetseg et al. [104] prepared a well-defined set of criteria regarding to E-learning system evaluation. Then, AHP as a structured technique was applied to evaluate and select the most suitable open source E-learning system.Murakoshi et al. [105] designed an AHP hierarchical diagram to compare the effectiveness of traditional classroom learning with online learning. Moreover, AHP results were used to enhance online learning system. They argued that web-based learning system can be effectively evaluated and improved by using AHP.Qin and Zhang [118] explored affecting factors in E-learning training domain according to three aspects, including: organizational aspect, personal characteristics aspect and training aspect. Then, AHP was adopted to analyze and rank those factors with respect to experts’ point of view.Sharma et al. [133] utilized AHP to evaluate and improve the contents of online courses with respect to the opinion of various social clusters, including: academicians, researchers, students, alumni staffs and industry employees.Shee and Wang [134] applied AHP to examine evaluation-based activities taking place before and after adoption phases of web-based E-learning system. In fact, AHP was used for the purpose of enhancing the quality of web-based learning. Prior to this process, learners’ perceptions of the relative importance of chosen criteria were empirically investigated.Yang and Chen [156] established several indexes regarding web-based learning evaluation based on experts’ points of view. Then, AHP method was adopted to analyze the self-learning capability of web-learning platform. In fact, AHP method determined the weights of the indexes, according to pairwise comparison of factors.Yigit et al. [158] applied AHP to evaluate and select the most suitable learning object. The purpose of their research was to prevent wasting time in searching the large number of learning objects repository. The results showed that AHP selected the reliable learning object that can optimize time and efficiency.Zhang et al. [162] investigated people's perceptions and attitudes towards E-learning adoption based on innovation adoption perspective in China. As a result they established a set of criteria for E-learning adoption behavior. Then, AHP was adopted and put forward the hierarchical structural model to evaluate and assess the key factors influencing E-learning adoption intention.Based on the analysis of our data set papers, eleven out of 42 (26.2%) papers applied FAHP as their methodology in the context of E-learning. These academic papers that implemented FAHP method in E-learning evaluation are summarized as follows.Bo et al. [11] applied the fuzzy synthetic judgment and AHP approach to evaluate the effectiveness of network education in China. In fact, they evaluated the effectiveness of network education by FAHP with respect to the primary factors that influence the efficiency of network education.Chao and Chen [15] applied FAHP to examine E-learning system effectiveness and accordingly to send the results back to managers in schools. The main purpose of their investigation was to improve E-learning practice. They utilized Consistent Fuzzy Preference Relations (CFPR) in AHP method for two main reasons. First, FAHP advantages on computational simplicity. Second, its capability of preserving the comparisons consistency compared to traditional AHP method.Chen [20] utilized FAHP to develop a fuzzy evaluation model and prioritize the measures of intellectual capital (IC) in E-learning service companies. They argued that prioritization of ICs supports E-learning companies to understand the critical success factors in E-learning services. As a result, it brings competitive advantages to firms.Jie [62] applied FAHP to evaluate online course quality. In this process, FAHP was developed to prioritize the relative weights of online course quality factors summarized into 4 main categories (course content, instructional design, service design, and system support). They indicated that FAHP results provide guidance to teachers and system designers. As a result, this guideline supports them to find the best policy for improving online course effectiveness.Lai [83] proposed a feasible appraising framework based on FAHP to evaluate the sustainability of virtual communities under E-learning platform in a university. In fact, FAHP adopted to determine the relative weights of criteria in selecting the suitable virtual learning communities. Moreover, a case study was conducted to validate applicability and validity of FAHP framework.Li et al. [86] set up a two-level internet learning quality assessment index system on the basis of AHP to evaluate Internet learning quality. In this study, a fuzzy comprehensive assessment method consists of factor set, assessment set, and fuzzy relation matrix was combined with AHP. They argued that the application of FAHP as a mathematical comprehensive assessment model is operative and reliable with decisive results. They further mentioned that FAHP can be used as a scientific and reasonable method for evaluating Internet teaching quality in a qualitative and quantitative way.Lin [89] adopted an evolution model which combined triangular fuzzy numbers with AHP which resulted in a novel FAHP evaluation model. FAHP approach was developed to prioritize the relative weights of course website quality factors. They argued that FAHP evaluation model is capable of proposing a practical reference to system designers seeking to enhance course website effectiveness.Liu et al. [90] applied FAHP to evaluate and provide a practical and feasible E-learning platform. In this process, a hierarchical model was first developed to define goals, criteria and sub-criteria of E-learning platform selection. Then, experts’ pairwise comparison judgments of AHP were converted to triangle fuzzy number to solve fuzzy problem in traditional AHP. At the end, a case study was proposed to prove the validity and feasibility of FAHP method.Lo et al. [91] adopted FAHP to examine the factors which are essential for successfully implementing customized E-learning system. They argued that the proposed hierarchical framework allows companies to analyze the key factors influenced in E-learning system implementation in a more complete structural view. Moreover, they mentioned that this FAHP framework supports employees in work abilities and therefore they get motivated to participate into firm activities.Tseng et al. [143] applied FAHP to choose suitable course materials, since tremendous course materials in Internet can cause confusion. FAHP was performed by asking experts to assign weight value to each criterion. Then, experts’ value preferences converted into fuzzy numbers and they were checked for consistency. Eventually, the final priority weight of each criterion was computed and proposed. They argued that by FAHP evaluation method, learners can obtain customized course materials based on their own criteria in the presented framework.Yang and Chen [157] used theory of fuzzy mathematics combined with AHP to analyze students' self-learning capability in network environment. They argued that, FAHP approach supports teachers to obtain students' comprehensive and objective assessment by presenting weights and ranks of criteria.Based on the analysis of our data set papers, two out of 42 (4.8%) academic papers proposed Linear Programming (LP) as an MCDM approach to tackle E-learning evaluation problems. In following, these academic papers which have adopted LP method as a MCDM technique are summarized.Matsatsinis and Fortsas [97] aimed at a methodology development to calculate questions' difficulty degree and as a result to create suitable exams for distance education trainees. In order to do so, they applied LP to solve the multi-objective problems of assessing the questions’ difficulty degree. Then, they developed exams from a database of questions whose difficulty degree had been previously calculated.Matsatsinis et al. [98] utilized LP to measure satisfaction indexes and to compute criteria weights with the purpose of improving E-learning satisfaction system. They argued that the evaluation process is fully dependent on the users' judgments. Hence, LP model was considered suitable to employ users’ judgments for evaluating E-learning satisfaction.Based on the analysis of our data set papers, one out of 42 (2.4%) academic papers applied FANP to deal with the E-learning evaluation issues. In following, this academic paper has been summarized.Tseng et al. [144] adopted ANP combined with fuzzy set theory to evaluate the effectiveness of teaching and training in an E-learning system. Their research purpose was to support managers and decision makers. The results indicated that the FANP method is a simple, suitable, and effective method for evaluating the effectiveness of E-learning systems, specifically when the context of interdependent measures is taken into account. They argued that the proposed FANP framework can be applied in various settings of E-learning system effectiveness.Based on the analysis of our data set papers, one out of 42 (2.4%) academic papers proposed ELECTRE to handle the E-learning evaluation and selection process. This paper has been summarized as follows.Mastalerz [95] presented ELECTRE to deal with the problem of choosing the suitable E-learning platform. The proposed ELECTRE method started with defining a set of criteria and determining their family. Next, based on the decision maker's preference analysis, the equivalence and preference thresholds were determined. The author indicated that ELECTRE uses quantitative and qualitative data which highly expand its range of usage. He argued that this approach is a reliable and effective method for evaluating E-leaning IT system.Based on the analysis of our data set papers, ten out of 42 (23.8%) academic papers have used MCDM integrated methodology. In following, these academic papers have been summarized.7 academic papers (16.7%) in our data set have applied the integration of AHP technique to examine and evaluate the E-learning effectiveness.Hwang et al. [59] proposed an integrated group-decision approach comprises AHP, Decision Support System (DSS), Fuzzy theory, and Grey system theory to evaluate educational web sites. The major contribution of their research was to help students and teachers who look for suitable educational and informative Internet resources. They suggested that it is highly suitable and reliable to employ an integrated approach for the evaluation of educational web sites.Ho et al. [54] developed an integrated multi-criteria decision making approach, where they combined AHP and Quality Function Deployment (QFD) to evaluate and select the best virtual learning system. According to authors, the main reason of integrated approach adoption was to guarantee benchmarking to be highly consistent and reliable. This ensures that the selected methodology framework will achieve the requirements and satisfy the stakeholders most.Kurilovas and Zilinskiene [81] presented a new integrated AHP approach called “MCEQLS (Multiple Criteria Quality Evaluation of Learning Software) AHP” to evaluate the quality of E-learning scenarios according to their suitability. The refined MCEQLS approach consists of several numbers of scientific principles and methods such as principles of MCDM, technological quality criteria classification, fuzzy set theory, and experts’ additive utility function. They argued that MCEQLS AHP method is quite objective, exact and simple to use by learner groups in order to select scenario alternatives.Bhuasiri et al. [10] first identified multiple factors regarding to the success of E-learning system in developing countries. Then, they used the integration of AHP with Delphi method to compare the relative importance of factors among two stakeholder groups, including ICT experts and faculty members. Finally, critical success factors were classified and prioritized by their level of importance.Wang and Lin [151] combined fuzzy AHP and Association Rule (AR) to evaluate interactivity in an online learning system. In this process, they used FAHP and AR to calculate the fuzzy relative weights among elements and also to find out the associated rules between criteria.Cobo et al. [23] developed a new integrated multi-criteria approach comprising AHP and data mining technique to evaluate and classify the level of interactivity of students in online teaching-learning environment. In this process, AHP and data mining techniques were used to identify similar patterns and similar behavior of students. They indicated that the integration of MCDM and data mining method is particularly suitable for identifying users behavioral patterns by analyzing records generated in learning management system.Chen and Fu [18] applied integrated methods for a comprehensively evaluation of teaching websites. First, indicators of teaching websites were identified. Then, AHP was implemented to calculate the weight of each target. Finally, the intelligence methods, Back-Propagation Neural Network (BPNN), and Support Vector Machines (SVM) have been used for classification of criteria.Two papers (4.8%) utilized integrated TOPSIS to weight and rank influential criteria in E-learning.Kang et al. [66] used the hierarchy concept of AHP to analyze and determine the weights of related indexes based on different aspects of E-learning system. Then, TOPSIS was used to rank the criteria, since the weights of indexes were known. They concluded that the proposed integrated AHP and TOPSIS methods can be applied in actual practice.Büyüközkan et al. [14] adopted an “Axiomatic Design” based approach for fuzzy group decision making to evaluate the quality of E-learning web sites. Then, fuzzy TOPSIS as a multi-criteria decision making technique was applied to validate the outcomes. They argued that the proposed integrated TOPSIS methodology has the advantages of incorporating requirements and reducing the problem size.One paper (2.4%) utilized integrated DEMATEL to evaluate E-learning effectiveness.Tzeng et al. [147] proposed a new novel hybrid MCDM model where DEMATEL was used to find the dependent and independent relations of E-learning programs criteria. Then, AHP method and fuzzy set theory technique were used in accordance with the subjective perception of environment. Their empirical experimental results showed that the proposed model is capable of evaluating E-learning programs effectively, even when the evaluation criteria are numerous and intertwined.This group of academic papers has also taken advantage of multi-criteria analysis approach for evaluating E-leaning system. However, they did not employ above MCDM mentioned techniques. Based on the analysis of our data set papers, three (7.1%) academic papers used other MCDM methods to evaluate E-learning context. In following, these academic papers were summarized.Alptekin and Karsak [5] presented a decision modeling framework to evaluate and address the problem of designing E-learning products. Their research contribution was to maximize overall learner satisfaction. In order to do so, they employed Quality Function Deployment (QFD) and fuzzy linear regression to select suitable E-learning products. In this process, QFD was employed to organize skills and functions of E-learning products with respect to learner needs. Moreover, fuzzy regression was adopted to determine the functional relationships between learner needs and E-learning product characteristics. Finally, E-learning products alternatives were examined and ranked in accordance with deviations from the value of product characteristic.Kurilovas and Serikoviene [80] implemented integration of MCEQLS (Multiple Criteria Evaluation of the Quality of Learning Software) and TFN (Trapezoidal Fuzzy Numbers) methods to evaluate the quality and reusability of learning objects (LOs). In their research, fuzzy numbers theory was established to weight LOs quality criteria and MCEQLS approach was employed to rank the final evaluation results. The research results showed that the proposed method is quite objective, exact, efficient, and simple for selecting qualitative reusable LOs alternatives.Yuen [159] proposed the Primitive Cognitive Network Process (P-CNP) considering as a multi-criteria evaluation method for selecting the most suitable E-Learning platform. “The cognitive network process is the cognitive architecture which comprises five cognitive decision processes: the Problem Cognition Process (PCP), Cognitive Assessment Process (CAP), Cognitive Prioritization Process (CPP), Multiple Information Fusion Processes (MIP), and Decisional Volition Process (DVP)”. In addition, the author proposed an illustrative example to compare P-CNP method with AHP method. Research finding showed the validity and usability of the proposed method in relation to AHP technique.After summarizing the academic papers, in this section, we focus on finding the most significant criteria used in the evaluation of E-learning performance (see Table 1). A considerable number of criteria for evaluating E-learning have been proposed and summarized in Appendix A. In this appendix, the full information about the method of each paper and its effectiveness on selected criteria has been also presented. It should be noted that the criteria evaluated in previous studies were in different fields of E-learning such as the evaluation of platform, web-courses, teaching and training effectiveness. Therefore, this study focuses on finding the significance of these factors by calculating the frequency of their usage (see Table 2).According to Table 1, the first most important criteria in E-learning evaluation are usability and response-time where each of them was used in 35.7% of selected papers. These major criteria are followed by interactivity (33.3%), web & course design (30.9%), accessibility (28.6%), reliability (19%), cost-effectiveness (19%), functionality (19%), security (14.2%), stability (14.2%), trust (7.1%), accuracy (7.1%), flexibility (7.1%), interoperability (7.1%), and continuity (7.1%).Various usability related attributes have been found in the papers, such as “ease of use”, “user-friendly”, “user-friendliness”, “usefulness”, and “useful-content”. Response-time related attributes include “answering time”, “transferring time”, “timely response”, and “login time”. Interactivity related attributes consist of “system interaction”, “social interaction” and “community interactive leaning”. Web and course design attributes include “curriculum design”, “design of user interface”, “display of instructional materials”, “display of webpage” and “service design”. Accessibility attributes consist of “ease of access”, “access time”, “access speed”, “internet access”, and “accessibility of learning materials”.In this section, an overview of papers classification based on different perspectives is presented, as shown in Fig. 3. According to this figure, the academic papers are classified based on different main categories, including publication year, utilized MCDM approach, journal and conference in which they appeared.Distribution of MCDM techniques applied in E-learning is shown by publication year between 2001 and 2015 (see Fig. 4). It is clear from the chart that MCDM application in E-learning has allocated a greater number of papers over the last 6 years in comparison with that of the first 8 years (78.6% vs. 21.4%). The frequency of MCDM applications in E-learning remained almost constant throughout the first 6 years, following by a gradual increase in 2007 and 2008. However, it is clear from the chart that there was an upward trend in the number of academic papers from 2009 onwards. In 2009, the frequency of research papers rose to 5 and in 2010 the application of MCDM in E-learning experienced a dramatic rose, reaching to the peak of 11 papers. Over the next two years, the number of MCDM applications in E-learning stayed constant at 5, following by a slight decrease over the last 2 years.Distribution of papers based on the application of MCDM techniques is presented in Fig. 5. From the chart, it is clear that AHP has been the most popular MCDM technique for evaluating E-learning in relation to others. This technique was closely followed by fuzzy AHP to take advantage of fuzzy logic in E-learning evaluation. In addition, 10 out of 42 academic papers utilized integrated approach to overcome the shortage of individual MCDM techniques. However, the related numbers belong to FANP and ELECTRE methods were far less than any other MCDM techniques, standing at 1 similarly.Distribution of research papers by publication year and MCDM techniques is shown in Fig. 6. In general, AHP application in E-learning has an upward trend between 2001 and 2014, where it reached to the peak of three publications in 2010. From the chart, it can be observed that using fuzzy concept combined with MCDM methods especially with AHP, have become more popular from 2009 to 2012. From the discussion on research papers in Section 4.2, the reason behind using fuzzy set theory method can be discussed by the fact that fuzzy logic treats with human reasoning and uses linguistic terms for assessing E-learning in multi-criteria situations. In case of Integrated MCDM methods, they have been applied since 2004. While, the application of integrated approach increased considerably from 2009 onwards. Utilizing MCDM integrated methods in recent years can show the urge of researchers to come up with more reliable methodologies and accurate results.Research papers have been selected from a total of 33 different journals and conferences. Distribution of academic papers by journal and conference is shown in Table 1. As can be seen, “Computers & Education” has the most contribution in publishing the academic papers regarding the application of MCDM techniques in E-learning domain (9.5%). “Expert Systems with Applications”, “Operational Research”, “Technological and Economic Development of Economy”, as well as International Conference on “Computer Science and Education”, International Conference on “Computing, Communications and Applications”, and International Conference on “Networking and Digital Society” have 4.8% contribution in publication of our data set papers, separately.

@&#CONCLUSIONS@&#
