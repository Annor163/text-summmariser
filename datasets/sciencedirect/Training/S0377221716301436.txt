@&#MAIN-TITLE@&#
Quantifiers induced by subjective expected value of sample information with Bernstein polynomials

@&#HIGHLIGHTS@&#
Develop a SEVSI-induced quantifier in a new functional form by introducing the Bernstein polynomial of higher order.It inherits many excellent properties of Bernstein polynomials and is characterized by the operability for practical use.It can be associated with a specified DM and help produce more convincing results in the quantifier guided OWA aggregation.

@&#KEYPHRASES@&#
Uncertainty modeling,Personalized quantifier,Bernstein polynomials,Ordered weighted averaging (OWA) aggregation,

@&#ABSTRACT@&#
A kind of personalized quantifier, the so-called SEVSI-induced quantifier as an acronym for Subjective Expected Value of Sample Information, is developed in this paper by introducing Bernstein polynomials of higher degree. This allows us to provide a novel solution to improve the final representation of the quantifier that generally performed poorly in our previous work, thus enhancing the quality of global approximation of functions and improving the operability of this kind of quantifier for practical use. We show some properties of the developed quantifier. We also prove the consistency of the OWA aggregation under the guidance of this type of quantifier. Finally, we experimentally show that the developed quantifier outperforms the one with the piecewise linear interpolation in many aspects of geometrical characteristics and operability. Thus it could be considered as an effective analytical tool to help handle the complex cases involving people's personalities or behavior intentions that have to be considered in decision making under uncertainty.

@&#INTRODUCTION@&#
In natural language there are many linguistic quantifiers exemplified by terms such as more than 10, most, some, few, and about half. So far there have been several attempts to deal with this topic, notable among these are the work by Liu (2005), Liu and Han (2008), Yager (2004, 1996), and Zadeh (1983, 1965). And a detailed overview can be found in Guo (2014). This paper is a direct continuation of our previous work (Guo, 2014) in which we proposed a kind of personalized quantifier, the so-called SEVSI-induced one as an acronym for Subjective Expected Value of Sample Information, which can be associated directly with a specified decision maker (DM) and used as a tool to investigate and formalize his/her decision attitude or behavior intention. This makes us believe that it has a wide range of applications in increasingly complex situations. In particular, it may help to bring about more intuitively appealing and convincing results in decision making under uncertainty, especially in the ordered weighted averaging (OWA) aggregation under the guidance of quantifier. Noted that the quantifier was realized in Guo (2014) by the piecewise linear interpolation and represented as a piecewise linear function, of which the number of pieces depends on the number of the alternatives in the given sample. Theoretically, the more pieces of the piecewise function, the better performance of the global approximation by this interpolation. For practical applications, however, too many pieces may throw users into confusion and such piecewise functions may become difficult to handle. Besides, the smoothness of the fitted curves by this interpolation may still need improving. Hence, more efforts should be made to tackle these issues so as to further perfect this kind of quantifier.In this paper, we develop a new type of SEVSI-induced quantifier by introducing Bernstein polynomials of higher degree, thus providing a novel solution to the unsolved problems mentioned above. The consistency of the OWA aggregation under the guidance of the developed quantifier is also addressed and proved. Our aim is to develop a kind of personalized quantifier with excellent properties and pleasing operability, so as to provide an effective analytical tool with a sound theoretical basis for practical applications in more complex situations. Since the Regular Increasing Monotone (RIM) quantifier is a basis for constructing another two kinds of relative quantifiers, namely the Regular Decreasing Monotone (RDM) quantifier and the Regular UniModal (RUM) quantifier (Yager, 1996), all of the quantifiers considered in this paper are assumed to be RIM.The rest of this paper is organized as follows: Section 2 briefly recalls the OWA operator and Bernstein polynomials. In Section 3, the SEVSI-induced quantifier with Bernstein polynomials of higher degree is investigated in considerable detail. Section 4 makes use of two numerical examples to illustrate and examine the developed quantifier, followed by conclusions in Section 5.Yager (1988) introduced the concept of the OWA operator that is defined as follows.The OWA operator of dimension n is a mapping F: Rn→ R with an associated weighting vectorW=(w1,w2,…,wn)Tsuch that(1)FW(x1,x2,…,xn)=∑j=1nwjyj,where wj∈ [0, 1],∑j=1nwj=1, and yjis the jth largest ofxi(i=1,2,…,n). With the help of vector notations, Eq. (1) can be expressed asFW(x1,x2,…,xn)=WTY,whereY=(y1,y2,…,yn)Tis called an OWA argument vector.It is well known that an OWA weighting vector plays a key role in the aggregation process (Ahn, 2011, Bustincea, Fernandeza, Kolesárováb, & Mesiar, 2015). Yager (2009), Yager (2004), Yager (1996) suggested an effective approach to obtain an OWA weighting vector via the RIM quantifiers that can be denoted by a fuzzy subset Q with the following properties: 1)Q(0)=0, 2)Q(1)=1, 3)Q(x) ≥ Q(y)if x ≥ y. These quantifiers were denoted as basic unit-interval monotonic (BUM) functions in Yager (2004). Using a quantifier Q, we can obtain the OWA weights as(2)wj=Q(jn)−Q(j−1n),j=1,2,…,nIt is clear that wj∈ [0, 1] and∑j=1nwj=1. Eq. (1) can then be rewritten as(3)FQ(x1,x2,…,xn)=FW(x1,x2,…,xn)=∑j=1n[Q(jn)−Q(j−1n)]yj.This is called the quantifier guided OWA aggregation (Yager, 1996).Yager (1993), Yager (1988) further introduced a characterizing measure called the attitudinal character that can be used to characterize an OWA weighting vector with respect to any distinction between preferences for large or small argument values. The attitudinal character is defined as(4)AC(W)=∑j=1nwjn−jn−1.It can be shown that AC(W) ∈ [0, 1]. Specifically, larger values of AC(W), closer to 1, are an indication of preference for larger argument values in the aggregation. While lower values of AC(W), closer to 0, are an indication of preference for smaller argument values in the aggregation. Values of AC(W) in the middle, near 0.5, can be a reflection of no preference for either large or small argument values at all. Given a connection between Eq. (2) and Eq. (4), the measure of attitudinal character can be rewritten as(5)AC(Q)=∑j=1n[Q(jn)−Q(j−1n)]n−jn−1.Further algebraic manipulation of the formula leads to the following simple form(6)AC(Q)=1n−1∑j=1n−1Q(jn).Obviously, ifn→+∞, then the concept of attitudinal character can be associated directly with a quantifier Q(Yager, 2004). In this case, let(7)λQ=limn→∞AC(Q)=∫01Q(x)dx.Recall the concept of classical Bernstein polynomials that is defined as follows.Let f(x) ∈ C[0, 1]. A sequence of Bernstein polynomials of f is (Cheney, 1982)(8)Bn(f;x)=∑k=0nf(kn)Cnkxk(1−x)n−k,where the binomial coefficients are given byCnk=n!k!(n−k)!, and the Bernstein basic functions are defined byBnk(x)=Cnkxk(1−x)n−k(k=0,1,…,n). According to Bernstein's proof of the Weierstrass Approximation Theorem,limn→∞Bn(f;x)=f(x)for any function f(x) ∈ C[0, 1] (Cheney, 1982).Bernstein polynomials have some best properties among all approximating polynomials (Ghosh & Osman, 2012), some of which are briefly introduced as follows.1) Normalization of the Bernstein basic functions, i.e.,∑k=0nBnk(x)=1whereBnk(x)≥0for any x ∈ [0, 1].ProofTrivial from the binomial expansion. □2) End-point interpolation, i.e.,Bn(f;0)=f(0), andBn(f;1)=f(1).ProofTrivial from the algebraic manipulation of Eq. (8). □3) Positive linear operator, i.e., for any f(x), g(x) ∈ C[0, 1],Bn(f+g;x)=Bn(f;x)+Bn(g;x),Bn(af;x)=aBn(f;x)where a ∈ R, and Bn(f; x) ≥ 0 if f(x) ≥ 0.ProofTrivial from the algebraic manipulation of Eq. (8).□Thus it can be easily deduced that Bn(f; x) ≥ Bn(g; x) if f(x) ≥ g(x) for any x ∈ [0, 1].4) Linear invariant, i.e., for any linear functionl(x)=ax+bwhere a, b ∈ R,Bn(l;x)=l(x).ProofIt is clear from the property 3) thatBn(ax+b;x)=aBn(x;x)+bBn(1;x), whereBn(1;x)=∑k=0nCnkxk(1−x)n−k=(x+(1−x))n=1,andBn(x;x)=∑k=0nknCnkxk(1−x)n−k=∑k=1nknCnkxk(1−x)n−k=∑k=0n−1k+1nCnk+1xk+1(1−x)n−k−1=x∑k=0n−1Cn−1kxk(1−x)n−k−1=x(x+1−x)n−1=x.ThusBn(ax+b;x)=aBn(x;x)+bBn(1;x)=ax+b, i.e.,Bn(l;x)=l(x).□This means all of the linear functions are the fixed points of Bn.5) Geometrically shape-preserving property, i.e., Bn(f; x) is monotonically increasing (or convex) over [0, 1] if the function f(x) ∈ C[0, 1] does so.Proof(a) Assume that f(x) ∈ C[0, 1] is monotonically increasing (or decreasing) over [0, 1]. We shall prove Bn(f; x) does so by checking the sign of its first derivative over [0, 1]. Note that(xk(1−x)n−k)′=kxk−1(1−x)n−k−(n−k)xk(1−x)n−k−1.Thus,B′n(f;x)=∑k=0nf(kn)Cnk(xk(1−x)n−k)′=∑k=0nf(kn)Cnkkxk−1(1−x)n−k−∑k=0nf(kn)Cnk(n−k)xk(1−x)n−k−1=∑k=1nf(kn)Cnkkxk−1(1−x)n−k−∑k=0n−1f(kn)Cnk(n−k)xk(1−x)n−k−1=∑k=0n−1f(k+1n)Cnk+1(k+1)xk(1−x)n−k−1−∑k=0n−1f(kn)Cnk(n−k)xk(1−x)n−k−1=n∑k=0n−1f(k+1n)Cn−1kxk(1−x)n−k−1−n∑k=0n−1f(kn)Cn−1kxk(1−x)n−k−1=n∑k=0n−1[f(k+1n)−f(kn)]Cn−1kxk(1−x)n−k−1.When f(x) is monotonically increasing over [0, 1], thenf(k+1n)−f(kn)≥0⇒Bn′(f;x)≥0,which implies Bn(f; x) is also monotonically increasing over [0, 1]. On the other hand, when f(x) is monotonically decreasing over [0, 1], thenf(k+1n)−f(kn)≤0⇒Bn′(f;x)≤0,which implies Bn(f; x) is monotonically decreasing over [0, 1], too.(b) Assume f(x) ∈ C[0, 1] is convex (or concave) over [0, 1]. We shall prove Bn(f; x) does so by checking the sign of its second derivative over [0, 1], that is,B′′n(f;x)=n∑k=0n−1[f(k+1n)−f(kn)]Cn−1k×[kxk−1(1−x)n−k−1−(n−k−1)xk(1−x)n−k−2]=n∑k=1n−1[f(k+1n)−f(kn)]Cn−1kkxk−1(1−x)n−k−1−n∑k=0n−2[f(k+1n)−f(kn)]×Cn−1k(n−k−1)xk(1−x)n−k−2=n∑k=0n−2[f(k+2n)−f(k+1n)]×Cn−1k+1(k+1)xk(1−x)n−k−2−n∑k=0n−2[f(k+1n)−f(kn)]×Cn−1k(n−k−1)xk(1−x)n−k−2=n(n−1)∑k=0n−2[f(k+2n)−2f(k+1n)+f(kn)]×Cn−2kxk(1−x)n−k−2When f(x) is convex over [0, 1], then12[f(k+2n)+f(kn)]≥f(12[k+2n+kn])=f(k+1n)⇒Bn′′(f;x)≥0,which implies Bn(f; x) is also convex over [0, 1]. On the other hand, when f(x) is concave over [0, 1], then12[f(k+2n)+f(kn)]≤f(12[k+2n+kn])=f(k+1n)⇒Bn′′(f;x)≤0,which implies Bn(f; x) is concave over [0, 1], too.□6) Integral property, i.e., for any Bernstein basic functionBnk(x),∫01Bnk(x)dx=1n+1for allk=0,1,…,n.ProofLetInk=∫01Bnk(x)dx(k=0,1,…,n). It is clear thatInk≥0(k=0,1,…,n) and∑k=0nInk=∑k=0n∫01Bnk(x)dx=∫01∑k=0nBnk(x)dx=1.Note thatInk=∫01Bnk(x)dx=Cnk∫01xk(1−x)n−kdx=Cnk1k+1∫01(1−x)n−kdxk+1=Cnk1k+1([(1−x)n−kxk+1]01−∫01xk+1d(1−x)n−k)=Cnk1k+1∫01(n−k)xk+1(1−x)n−k−1dx=Cnkn−kk+1∫01xk+1(1−x)n−k−1dx=Cnk+1∫01xk+1(1−x)n−k−1dx=∫01Bnk+1(x)dx=Ink+1.That meansInk=Ink+1for allk=0,1,…,n−1. ThusInk=∫01Bnk(x)dx=1n+1holds for allk=0,1,…,n.□This section is partially based on an interactive testing process that was developed in our previous work (Guo, 2014) to extract from a specified DM information about his/her decision attitude or behavior intention with sample information. Without loss of generality, the set of sample information is assumed to be a multi-attribute decision matrix with m alternatives and n criteria, denoted byD=(dij)m×nwhere dij∈ R. LetD¯=(d¯ij)m×nbe the normalization ofD=(dij)m×nwhered¯ij∈[0,1]. Note that the values of each criterion inD¯=(d¯ij)m×nare rearranged in descending order in terms of the idea of OWA aggregation. The specified DM is then asked, based on personal preference or decision attitude, to provide his/her expected or satisfactory value for each criterion with respect toD¯. The set of subjective expected values of criteria provided by this DM can be expressed via a vector, denoted byν¯=(v¯1,v¯2,…,v¯n)Twherev¯j∈[0,1](j=1,2,…,n). Thus the information can be extracted, with the help ofD¯andν¯, from this DM about his/her decision attitude or behavior intention, which is denoted by an attitudinal weighting vector (an OWA weighting vector in nature),S=(s1,s2,…,sm)T, where (Guo, 2014)(9)s0=0,si=1∑j=1n(d¯ij−v¯j)2∑k=1m1∑j=1n(d¯kj−v¯j)2,i=1,2,…,m.It can be shown that si≥ 0(i=0,1,…,m) and∑i=0msi=1.According to Eq. (2), letQ(im)=∑k=0iskfor alli=0,1,…,mwhere Q represents an undetermined quantifier associated directly with this DM. In this way only some discrete values of Q are determined whereQ(0)=0,Q(1)=1. Based on these values, more efforts are made in the following to fit a continuous and smooth function over [0, 1] with the Lagrange interpolation and Bernstein polynomials, respectively.Let the step lengthh=1mand the isometric nodesxi=ih(i=0,1,…,m). In this way, our personalized quantifier can be fitted as a Lagrange interpolation polynomial of degree m, i.e.,(10)QL,m(x)=∑i=0mli(x)Q(xi)=∑i=0m∏j=0j≠imx−xjxi−xjQ(xi),x∈[0,1],where the interpolating basic functions are given byli(x)=∏j=0j≠imx−xjxi−xj=∏j=0j≠imx−jhih−jh=∏j=0j≠immx−ji−j,x∈[0,1],i=0,1,…,m.Eq. (10) can then be rewritten as(11)QL,m(x)=∑i=0m∏j=0j≠immx−ji−jQ(im),x∈[0,1].Thus the attitudinal character associated directly with the quantifier QL, mis defined by(12)λQL,m=∫01QL,m(x)dx=∑i=0mQ(im)∫01∏j=0j≠immx−ji−jdx.LetCi(m)=∫01∏j=0j≠immx−ji−jdx(i=0,1,…,m) andx=th. Then,(13)Ci(m)=1m∫0m∏j=0j≠imt−ji−jdt=(−1)m−im(m−i)!i!∫0m∏j=0j≠im(t−j)dt,thus Eq. (12) can be rewritten as(14)λQL,m=∑i=0mQ(im)(−1)m−im(m−i)!i!∫0m∏j=0j≠im(t−j)dt.It is worth noticing that the notationCi(m)in Eq. (13) is called the Cotes coefficient where∑i=0mCi(m)=1(Cheney, 1982). Given the polynomial integral in Eq. (13), the calculations ofCi(m)(i=0,1,…,m) do not get into real trouble. However, the non-negativity ofCi(m)cannot be ensured for alli=0,1,…,mwith the increasing of m. Indeed, there isCi(m)<0when m ≥ 8 (Cheney, 1982). This may lead to the computational instability of the attitudinal characterλQL,m. Moreover, with the degree m getting higher, the fitting function QL, m(x) may suffer from serious oscillation and larger errors of computation, known as the Runge's phenomenon. Therefore, the use of the Lagrange interpolation polynomial of higher degree, especially of degree more than 8, is not meant to be considered for practical applications.Let's now try another type of polynomial approximation with Bernstein polynomials. From the structure of Eq. (8), our personalized quantifier can be defined by(15)QB,m(x)=Bm(Q;x)=∑i=0mQ(im)Cmixi(1−x)m−i,x∈[0,1],where the binomial coefficients are given byCmi=m!i!(m−i)!. According to Bernstein's theorem on approximation of function, it is certain thatlimm→∞QB,m(x)=Q(x)for any undetermined quantifier Q(x) ∈ C[0, 1]. Thus, the fitting function QB, m(x) is characterized by many excellent properties of Bernstein polynomials that may ensure the high performance of global approximation. Obviously, the function QB, m(x) is monotonically increasing over [0, 1] as the undetermined quantifier Q(x) is assumed to be RIM. In other words, QB, m(x) ≥ QB, m(y)if x ≥ y for any x, y ∈ [0, 1]. In addition, according to the aforementioned end-point interpolation property, it is easy to understand thatQB,m(0)=Bm(Q;0)=Q(0)=0andQB,m(1)=Bm(Q;1)=Q(1)=1. Therefore, our personalized quantifier QB, mis also denoted by a BUM function.Let's first investigate the attitudinal character associated with QB, m. Note that∫01QB,m(x)dx=∫01∑i=0mQ(im)Cmixi(1−x)m−idx=∑i=1mQ(im)∫01Bmidx=1m+1∑i=1mQ(im)=1m+1∑i=1m∑k=1isk=1m+1∑i=1m(m−i+1)si=1m+1[∑i=1m(m+1)si−∑i=1misi]=1−1m+1∑i=1misi.Thus, the attitudinal character associated with QB, mcan be measured by(16)λQB,m=∫01QB,m(x)dx=1−1m+1∑i=1misi,where si(i=1,2,…,m) are given by Eq. (9). Some special cases are worth pointing out. As the involved DM gives more preference for the larger sample values with higher SEVSI, then the attitudinal weighting vectorS→(1,0,…,0)T. In this case, it is clear thatλQB,m=1−1/(m+1). Whenm→+∞, thenλQB,m=1. This is clearly an optimistic attitude. On the other hand, by giving more preference for the smaller sample values with lower SEVSI, the DM may provide such a vectorS→(0,0,…,1)TwithλQB,m=1−m/(m+1). Whenm→+∞, thenλQB,m=0. This is clearly pessimistic. If the DM gives a preference for the sample values in the middle between the large and small ones, then the significant weights will be dispersed as evenly as possible around the middle positions in S. In this case,λQB,m≈0.5, which is obviously an indication of neutral attitude. WhenS=(1/m,1/m,…,1/m)T, thenλQB,m=1−1m+1·1m∑i=1mi=1−1m(m+1)·m(m+1)2=12,which is an indication of complete neutrality. As some extreme cases, let us see what happens if the DM intends to give his/her preference at random, or the sample data are not representative enough to be used to extract correct attitudinal information. Given the manner in which the SEVSI is provided, it is clear that the vector S and the resulting quantifier QB, mmay show a presentation of some kind of overall evaluation on the performance by this DM. Accordingly, the value ofλQB,min this case also gives a similar indication that is actually difficult to explain with logical arguments.We now look at the consistency of the OWA aggregation guided by QB, m.Theorem 1Let QB, mbe a SEVSI-induced quantifier with Bernstein polynomials generated from an attitudinal weighting vectorS=(s1,s2,…,sm)Twhere si(i=1,2,…,m) are given by Eq. (9). LetλQB,m∈[0,1]be the attitudinal character associated with QB, m. If the quantifierQ¯B,mis generated from the reverse order of S,S¯=(sm,sm−1,…,s1)T, thenλQ¯B,m=1−λQB,m.ProofFrom Eq. (16) andS¯=(sm,sm−1,…,s1)T, it is easy to understand thatλQ¯B,m=1−1m+1(sm+2sm−1+3sm−2+⋯+ms1)=1−1m+1∑i=1mism−i+1=1−1m+1∑i=1m(m−i+1)si=1−1m+1[(m+1)∑i=1msi−∑i=1misi]=1−1m+1[(m+1)−∑i=1misi]=1m+1∑i=1misi=1−λQB,m.□Theorem 2Let QB, mand PB, mbe two SEVSI-induced quantifiers with Bernstein polynomials generated respectively from two attitudinal weighting vectorsSq=(s1q,s2q,…,smq)TandSp=(s1p,s2p,…,smp)Twheresiq,sip(i=1,2,…,m) are given by Eq. (9). LetλQB,mandλPB,mbe two attitudinal characters associated with QB, mand PB, m, respectively. For Sqand Sp, letQ(im)=∑k=1iskqandP(im)=∑k=1iskp(i=1,2,…,m). IfQ(im)≥P(im)for alli=1,2,…,m, then 1)FQB,m(X)≥FPB,m(X)for any argument vectorX=(x1,x2,…,xn)T; 2)λQB,m≥λPB,m; and 3) QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1].Proof1) ForX=(x1,x2,…,xn)T, we suppose that x1 ≥ x2 ≥ ⋅⋅⋅ ≥ xn. From Eq. (3), we haveFQB,m(X)=∑j=1nwjxj=∑j=1n[QB,m(jn)−QB,m(j−1n)]xj=∑j=1n−1QB,m(jn)(xj−xj+1)+xn.Similarly,FPB,m(X)=∑j=1n−1PB,m(jn)(xj−xj+1)+xn. We then calculate(17)FQB,m(X)−FPB,m(X)=∑j=1n−1[QB,m(jn)−PB,m(jn)](xj−xj+1).Note thatQB,m(jn)−PB,m(jn)=∑i=1m[Q(im)−P(im)]Cmi(jn)i(1−jn)m−i≥0.Givenxj≥xj+1for allj=1,2,…,n−1, it is certain thatFQB,m(X)≥FPB,m(X).2) Note thatλQB,m=∫01QB,m(x)dx=∫01∑i=1mQ(im)Cmixi(1−x)m−idx=∑i=1mQ(im)∫01Cmixi(1−x)m−idx=∑i=1mQ(im)∫01Bmi(x)dx=1m+1∑i=1mQ(im).Similarly,λPB,m=∫01PB,m(x)dx=1m+1∑i=1mP(im). SinceQ(im)≥P(im)for alli=1,2,…,m, which implies∑i=1mQ(im)≥∑i=1mP(im), we further get1m+1∑i=1mQ(im)≥1m+1∑i=1mP(im),i.e.,λQB,m≥λPB,m.3) LetBmi(x)=Cmixi(1−x)m−i(i=1,2,…,m) whereCmi=m!i!(m−i)!and x ∈ [0, 1]. It is certain thatBmi(x)≥0for alli=1,2,…,m. SinceQ(im)≥P(im)for alli=1,2,…,m, thenQ(im)Bmi(x)≥P(im)Bmi(x),i=1,2,…,m,x∈[0,1],which implies∑i=1mQ(im)Bmi(x)≥∑i=1mP(im)Bmi(x),x∈[0,1].It is clear from Eq. (15) that QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1].□Theorem 3LetSq=(s1q,s2q,…,smq)TandSp=(s1p,s2p,…,smp)Tbe two attitudinal weighting vectors wheresiq,sip(i=1,2,…,m) are given by Eq. (9). For Sqand Sp, letQ(im)=∑k=1iskqandP(im)=∑k=1iskp(i=1,2,…,m). Ifskqslp≥skpslqfor any l ≥ k (k,l=1,2,…,m), thenQ(im)≥P(im)for alli=1,2,…,m.ProofSimilar to Theorem 2 in Liu and Han (2008). Omitted. □Theorem 4LetSq=(s1q,s2q,…,smq)TandSp=(s1p,s2p,…,smp)Tbe two attitudinal weighting vectors wheresiq,sip(i=1,2,…,m) are given by Eq. (9). For Sqand Sp, letQ(im)=∑k=1iskqandP(im)=∑k=1iskp(i=1,2,…,m). Ifsjq−sj+1q≥sjp−sj+1pfor anyj=1,2,…,m−1, thenQ(im)≥P(im)for alli=1,2,…,m.ProofSimilar to Theorem 3 in Liu and Han (2008). Omitted.□Theorem 5Let QB, mand PB, mbe two SEVSI-induced quantifiers with Bernstein polynomials. For any argument vectorX=(x1,x2,…,xn)T,FQB,m(X)≥FPB,m(X)if and only if QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1].Proof: 1) Sufficiency. We shall prove “QB, m(x) ≥ PB, m(x)⇒FQB,m(X)≥FPB,m(X)”.Given the fact that QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1] andxj≥xj+1for allj=1,2,…,n−1, it is clear from Eq. (17) thatFQB,m(X)≥FPB,m(X).2) Necessity. We shall prove “FQB,m(X)≥FPB,m(X)⇒QB, m(x) ≥ PB, m(x)”.It is obvious thatQB,m(0)=PB,m(0)=0andQB,m(1)=PB,m(1)=1. In view of the arbitrariness of X, letX(k)=(1,1,…,1︸k,0,0,…,0︸n−k)T(k=1,2,…,n−1). SinceFQB,m(X(k))≥FPB,m(X(k))for allk=1,2,…,n−1, then, from Eq. (17),QB,m(kn)≥PB,m(kn)for allk=1,2,…,n−1. Given the arbitrary parameters k and n, it is clear that QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1].□Theorem 6Let QB, mand PB, mbe two SEVSI-induced quantifiers with Bernstein polynomials. LetλQB,mandλPB,mbe two attitudinal characters associated with QB, mand PB, m, respectively. If QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1], thenλQB,m≥λPB,m.ProofSince QB, m(x) ≥ PB, m(x) for any x ∈ [0, 1], then∫01QB,m(x)dx≥∫01PB,m(x)dx, i.e.,λQB,m≥λPB,m.□CorollaryLet QB, mand PB, mbe two SEVSI-induced quantifiers with Bernstein polynomials. LetλQB,mandλPB,mbe two attitudinal characters associated with QB, mand PB, m, respectively. For any argument vectorX=(x1,x2,…,xn)T, ifFQB,m(X)≥FPB,m(X)thenλQB,m≥λPB,m.ProofTrivial from Theorem 5 and Theorem 6.□Generally speaking, the fact of QB, m(x) ≥ PB, m(x) orFQB,m(X)≥FPB,m(X)cannot be deduced simply fromλQB,m≥λPB,m. The consistency of the OWA aggregations guided by QB, mand PB, mis roughly summarized in Fig. 1for a better understanding of this part.It is clear from above that our personalized quantifier shown as Eq. (15) not only is denoted by a BUM function, but also inherits many excellent properties of Bernstein polynomials that may help enhance the performance of global approximation of the fitting functions. In fact, as the value of m increases, the fitting functions are achieving better approximation performance. More notably, this functional form, a polynomial of higher degree, is much easier to handle compared with a piecewise function with many pieces. Thus this study, as a direct continuation of our previous work, actually develops a SEVSI-induced quantifier in a relatively simple functional form with the good theoretical properties and the pleasing operability for practical use.This section aims at illustrating and examining, by two numerical examples (adapted from (Guo, 2014)), the SEVSI-induced quantifier with Bernstein polynomials through a comparative analysis of the quantifier with the piecewise linear interpolation as presented in our previous work.Example 1Quantifier generation. Assume there is no available quantifier for an involved DM who may show, let's say, a consistent preference or attitude towards attribute values in assessment. We then decide to generate a personalized one for him/her by our developed technique.Step 1. Prepare a collection of multi-attribute sample information involving the assessments for ten prototype missiles, the specifications of which are shown in Table 1. Obviously, the attribute Price (C4) is a cost criterion and the others are benefit ones. This set of sample information can be regarded as a multi-attribute decision matrix with 10 alternatives and 4 criteria, denoted byD=(dij[d˜ij])10×4.Step 2. Let's work out the normalization of D first. For the crisp values dijin D, letd¯ijbe the normalization of dij, where(18)d¯ij={dij∑k=110dkj2|j∈J+1/dij∑k=110(1/dkj)2|j∈J−,i=1,2,…,10,j=1,2while for the intervalsd˜ij=[d˜ijL,d˜ijU], letd^ij=[d^ijL,d^ijU]be the normalization ofd˜ij, where(19)d^ijL={d˜ijL∑k=110(d˜kjU)2|j∈J+1/d˜ijU∑k=110(1/d˜kjL)2|j∈J−,d^ijU={d˜ijU∑k=110(d˜kjL)2|j∈J+1/d˜ijL∑k=110(1/d˜kjU)2|j∈J−,i=1,2,…,10,j=3,4.HereJ+represents a set of benefit criteria, andJ−represents a set of cost ones. It is clear thatd¯ij∈[0,1](i=1,2,…,10;j=1,2) andd^ij⊆[0,1](i=1,2,…,10;j=3,4). For simplicity, we take here the inferior limits of the normalized intervalsd^ij(i=1,2,…,10;j=3,4). After the rearrangement of the values of each criterion in descending order, the corresponding reordered normalized decision matrix is shown asD¯=(d¯ij)10×4=[0.5220.3460.4190.3220.3810.3340.3660.2900.3260.3280.3050.2840.3040.3220.2740.2780.2830.3160.2670.2730.2720.3100.2520.2630.2610.3100.2290.2630.2390.3040.2290.2540.2390.2980.2130.2500.2170.2870.1910.241].Step 3. The involved DM is then asked to provide his/her expected or satisfactory value for each criterion with respect toD¯=(d¯ij)10×4. Assume the set of expected values provided by this DM isν¯1=(0.29,0.32,0.25,0.27)T.Given the middle position where each component weight of the vectorν¯1is nearly located in the corresponding column vector ofD¯, it is clear to see that this DM shows a preference for the sample values in the middle between the large and small ones. This is clearly a neutral attitude.Step 4. With the observed dataD¯andν¯1, determine the attitudinal weighting vector associated directly with this DM by using Eq. (9), denoted byS1=(0.002,0.006,0.029,0.157,0.363,0.276,0.092,0.037,0.027,0.011)T.It is clear from S1 that the significant weights are evenly dispersed around the middle positions, implying that this DM is characterized by a neutral attitude represented here as the quantifier Q1. According toQ1(im)=∑k=1iskfor alli=1,2,…,10, we getQ1(110)=0.002,Q1(210)=0.008,Q1(310)=0.037,Q1(410)=0.194,Q1(510)=0.557,Q1(610)=0.833,Q1(710)=0.925,Q1(810)=0.962,Q1(910)=0.989,Q1(1)=1.Step 5. On the basis of these discrete values of Q1, fit a continuous quantifierQB,10(1)by using Eq. (15), shown asQB,10(1)(x)=∑i=110Q1(i10)C10ixi(1−x)10−i=−5.394x10+42.35x9−116.55x8+137.04x7−48.51x6−28.476x5+18.06x4+2.28x3+0.18x2+0.02x,x∈[0,1].The attitudinal character associated withQB,10(1)can then be measured asλQB,10(1)=∫01QB,10(1)(x)dx=0.501,which is showing an actual level of the neutral attitude Q1.Step 6. The OWA aggregation under the guidance ofQB,10(1)can then be implemented by using Eq. (3) for this DM's future decisions.□Let's look at some other cases for the different subjective expected values ofD¯=(d¯ij)10×4. Assume the DM provides his/her set of expected values asν¯2=(0.22,0.29,0.21,0.25)T,which is showing a preference for lower sample values as each component weight of the vectorν¯2is near the bottom of the corresponding column vector ofD¯. With this vector, we getS2=(0.001,0.003,0.007,0.012,0.019,0.031,0.060,0.167,0.360,0.340)T.Clearly, the distribution of S2 presents a one-sided tendency towards the bottom, implying that this DM is characterized by a pessimistic attitude represented here as the quantifier Q2. Similarly,Q2(110)=0.001,Q2(210)=0.004,Q2(310)=0.011,Q2(410)=0.023,Q2(510)=0.042,Q2(610)=0.073,Q2(710)=0.133,Q2(810)=0.300,Q2(910)=0.660,Q2(1)=1.A continuous quantifierQB,10(2)can then be generated asQB,10(2)(x)=∑i=110Q2(i10)C10ixi(1−x)10−i=0.366x10−2.01x9+1.17x8+0.84x7+0.504x5−0.21x4+0.24x3+0.09x2+0.01x,x∈[0,1].The attitudinal character associated withQB,10(2)can then be measured asλQB,10(2)=∫01QB,10(2)(x)dx=0.204,which is showing a lower level of the pessimistic attitude Q2.On the other hand, if the DM provides his/her set of expected values asν¯3=(0.50,0.34,0.40,0.30)T,which is an indication of preference for higher sample values as each component weight of the vectorν¯3is at the top of the corresponding column vector ofD¯, we then haveS3=(0.809,0.071,0.028,0.020,0.017,0.014,0.012,0.011,0.010,0.008)T.Clearly, the distribution of S3 presents a one-sided tendency towards the top, implying that this DM is characterized by an optimistic attitude represented here as the quantifier Q3. In this case,Q3(110)=0.809,Q3(210)=0.880,Q3(310)=0.908,Q3(410)=0.928,Q3(510)=0.945,Q3(610)=0.959,Q3(710)=0.971,Q3(810)=0.982,Q3(910)=0.992,Q3(1)=1.A continuous quantifierQB,10(3)can then be generated asQB,10(3)(x)=∑i=110Q3(i10)C10ixi(1−x)10−i=−0.57x10+5.69x9−25.83x8+70.32x7−127.05x6+158.76x5−138.6x4+83.4x3−33.21x2+8.09x,x∈[0,1].The attitudinal character associated withQB,10(3)is measured asλQB,10(3)=∫01QB,10(3)(x)dx=0.851,which is showing a higher level of the optimistic attitude Q3.Geometrical representation of the exemplified quantifiers with Bernstein polynomials is shown in Fig. 2in an effort to make these quantifiers quite understood.□For a comparative analysis, let's look at another functional form of our personalized quantifier with the piecewise linear interpolation as presented in our previous work. Under the circumstances, this type of SEVSI-induced quantifier is defined by Guo (2014)(20)QD¯,ν¯(x)=(mx−i)si+∑k=1isk,i−1m≤x≤im,i=1,2,…,m,and the attitudinal character associated withQD¯,ν¯is measured by Guo (2014)(21)λQD¯,ν¯=AC(QD¯,ν¯)=∫01QD¯,ν¯(x)dx=1−1m∑i=1misi+12m,where si(i=1,2,…,m) are given by Eq. (9). More specifically, the quantifiers generated from the above Sk(k=1,2,3) are respectively represented asQD¯,ν¯1(x)={0.0154x0.0≤x≤0.10.0589x−0.00440.1≤x≤0.20.2874x−0.05000.2≤x≤0.31.5673x−0.43400.3≤x≤0.43.6268x−1.25780.4≤x≤0.52.7600x−0.82440.5≤x≤0.60.9200x+0.27960.6≤x≤0.70.3704x+0.66430.7≤x≤0.80.2712x+0.74360.8≤x≤0.90.1226x+0.87740.9≤x≤1.0,QD¯,ν¯2(x)={0.0109x0.0≤x≤0.10.0291x−0.00180.1≤x≤0.20.0684x−0.00970.2≤x≤0.30.1206x−0.02540.3≤x≤0.40.1856x−0.05140.4≤x≤0.50.3104x−0.11370.5≤x≤0.60.5989x−0.28680.6≤x≤0.71.6741x−1.03950.7≤x≤0.83.6028x−2.58240.8≤x≤0.93.3992x−2.39920.9≤x≤1.0.QD¯,ν¯3(x)={8.0761x0.0≤x≤0.10.7134x+0.73630.1≤x≤0.20.2777x+0.82340.2≤x≤0.30.2001x+0.84670.3≤x≤0.40.1668x+0.86000.4≤x≤0.50.1448x+0.87100.5≤x≤0.60.1244x+0.88330.6≤x≤0.70.1094x+0.89370.7≤x≤0.80.1027x+0.89910.8≤x≤0.90.0848x+0.91520.9≤x≤1.0.The attitudinal characters associated with these quantifiers can then be measured asλQD¯,ν¯1=0.501,λQD¯,ν¯2=0.175,λQD¯,ν¯3=0.886.Geometrical representation of these quantifiers with the piecewise linear interpolation is shown in Fig. 3.□It is clear from above that the SEVSI-induced quantifier with the piecewise linear interpolation may sometimes suffer from some limitations mainly concerning the treatment of too many pieces, the number of which depends on the number of the alternatives in the given sample. In fact, a piecewise function with a large number of pieces may bring some confusion to users and become difficult to handle. Generally, the use of piecewise functions with pieces more than 8 is rarely considered for practical applications (Cheney, 1982). Besides, there is a need, if necessary, for significant improvement on the smoothness of the fitted curves by this interpolation. By contrast, the quantifier with Bernstein polynomials of higher degree can eliminate these limitations with better theoretical properties such as the excellent shape-preserving property and a sufficient degree of smoothness. More notably, the quantifier in this functional form has become much easier to handle either for theoretical analysis or for practical applications, as mentioned before.Example 2. Quantifier examination. Assume there is a multi-attribute decision matrix with 4 alternatives ai(i=1,2,3,4) and 3 benefit criteria, shown asP=(pij)4×3=[0.6910.7130.7560.7390.7300.2790.6720.7050.7330.7110.7220.325].For convenience, leta1=(0.691,0.713,0.756)T,a2=(0.739,0.730,0.279)T,a3=(0.672,0.705,0.733)T,a4=(0.711,0.722,0.325)T.Let's investigate the preliminary evaluations of ai(i=1,2,3,4) with the OWA aggregation under the guidance ofQB,10(k)(k=1,2,3) generated from Example 1. More details are provided as shown in Table 2, whereλ(k), W(k), and F(k)( · )(k=1,2,3) are determined by Eqs. (16), (2), and (3), respectively.It is clear from Table 2 that in terms of the idea of OWA aggregation, the OWA weighting vector W(1) is an indication of preference for argument values in the middle between the large and small ones as the significant weights are dispersed as evenly as possible around the middle positions. This is clearly a reflection of neutral attitude. Similarly, the vector W(2) is an indication of preference for lower argument values as more of the total weight moves to the weights at the bottom. This is clearly a reflection of pessimistic attitude. And the vector W(3) is an indication of preference for higher argument values as more of the total weight moves to the top. This is clearly a reflection of optimistic attitude. Also, from Table 2 it can be seen that for the same decision information, different attitudes may lead to different assessments, which points to the necessity of considering the different attitudes of the involved DMs in increasingly complex environments.Let's now look at the evaluations of ai(i=1,2,3,4) with the OWA aggregation under the guidance ofQD¯,ν¯k(k=1,2,3) so as to make a direct comparison of results between these two kinds of functional form. More details of these are summarized and shown in Table 3, where λk, Wk, and Fk( · )(k=1,2,3) are determined by Eqs. (21), (2), and (3), respectively.By comparison with Tables 2 and 3, we clearly see that our personalized quantifier, either represented as Bernstein polynomials of higher degree or as piecewise linear functions, can surely produce the consistent results reflecting the decision attitudes or behavior intentions of the involved DMs in terms of what we expect. Thus our work on this research topic has been proven fruitful. By contrast, the quantifier with Bernstein polynomials of higher degree, characterized by the excellent theoretical properties and the pleasing operability, definitely outperforms the one with the piecewise linear interpolation in many aspects of geometrical characteristics and operability, and therefore it could be considered to put to practical use in many areas.

@&#CONCLUSIONS@&#
In this paper, we develop a new type of SEVSI-induced quantifier with Bernstein polynomials of higher degree, thus further perfecting this kind of personalized quantifier as proposed in our previous work. The developed quantifier actually inherits many excellent properties of Bernstein polynomials, and has become much easier to handle in comparison with the one with the piecewise linear interpolation whether for theoretical analysis or for practical applications. As for the application of the SEVSI-induced quantifier in different functional forms, here is some advice from a more practical point of view: if there is only a small quantity of the alternatives in the given sample (more specifically, the number of the alternatives is less than 8) and there is no need for the smoothness of the fitted curves, the quantifier with the piecewise linear interpolation would be a good choice given its simplicity and relatively fast convergence rate in the circumstances; otherwise, the quantifier with Bernstein polynomials should be taken into account. Just because of what we did for the quantifier, it is becoming much more efficient and flexible to deal with such a complex case in which the involved DMs are allowed to have some unusual even extreme decision attitudes. Also, it may help to predict the involved DMs’ future decisions, and with good reason.