@&#MAIN-TITLE@&#
Guided depth enhancement via a fast marching method

@&#HIGHLIGHTS@&#
We propose a new depth enhancement method for RGB-D sensors.It extends the fast marching method to incorporate color and depth information.It outperforms state-of-the-art local methods in terms of visual and metric qualities.It achieves visually comparable results to time-consuming global methods.It provides better inputs to the applications based on RGB-D sensors.

@&#KEYPHRASES@&#
Depth enhancement,Image inpainting,Fast marching method,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Along with recent advancements on range imaging technologies, nowadays, it is quite convenient to obtain depth and color images simultaneously. For instance, commercially available time-of-flight (TOF) cameras [1,2] can produce depth and color image pairs up to 320×240pixels and 100 frames per second. Kinect [3–5], a type of device developed by Microsoft in recent years, can capture aligned depth and color images at a frame rate of 30fps in VGA resolution. The comparably high quality, together with the real-time nature, makes these sensors attractive to all. They have therefore been extensively used in indoor applications, such as 3D scene reconstruction [6–8], activity recognition [9], and 3D object detection [10,11].Depth data obtained by the sensors are compelling, particularly compared to those generated by stereo-vision technologies, but they are still inherently defective [7,12]. A typical example is illustrated in Fig. 1. The depth map contains numerous invalid regions where range measurements are missing, due to occlusions, reflective or dark surfaces, or the limit of depth of field. Meanwhile, the alignment of the depth map to the displaced color image leads to large invalid regions along the map's boundary. In addition, the underlying range sensing technique also results in heavy noise, especially on object boundaries. These defects more or less influence the use of depth information. Therefore, a preprocessor concerning depth inpainting and denoising is desired.Although a great number of research and practical applications using depth maps have been released, research on the enhancement of them is relatively deficient. Therefore, in this work, we study on depth map enhancement, particularly via taking advantage of aligned color images. This task, which contains depth inpainting and denoising, is referred to as guided depth enhancement by us, in that color images are employed as guidance. To achieve the task, we propose a new method that extends the simple but effective fast marching method [13,14] to incorporate color information for inpainting and apply an edge-preserving guided filter for noise reduction.The paper is organized as follows. We briefly review the most related work in Section 2 and present the proposed inpainting method in Section 3. A guided filtering [15] method for depth denoising is presented in Section 4. Experiments on both real-world Kinect data and the Middlebury dataset [16] are demonstrated in Section 5, followed by a conclusion in Section 6.

@&#CONCLUSIONS@&#
To enhance defective depth maps captured by range imaging sensors, in this paper we have proposed a novel approach based upon FMM. Our method is able to take advantage of both color and depth information for depth enhancement. Comparative experiments show that our method outperforms other state-of-the-art local methods in terms of both visual quality and RMSE. Moreover, it achieves visually comparable results to time-consuming global methods. We believe that our method can provide better inputs to the applications based on range imaging sensors.