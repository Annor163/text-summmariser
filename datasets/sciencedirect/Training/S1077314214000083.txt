@&#MAIN-TITLE@&#
Estimating scene flow using an interconnected patch surface model with belief-propagation inference

@&#HIGHLIGHTS@&#
An interconnected surface model for estimating the 3D motion of a scene is proposed.A novel uncertainty measure for the motion estimation is incorporated.The proposed method is compared against a modern optical flow based method.Either equivalent or better results are achieved using the proposed method.

@&#KEYPHRASES@&#
Motion,Tracking,Markov random fields,Stereo,Scene-flow,

@&#ABSTRACT@&#
This article presents a novel method for estimating the dense three-dimensional motion of a scene from multiple cameras. Our method employs an interconnected patch model of the scene surfaces. The interconnected nature of the model means that we can incorporate prior knowledge about neighbouring scene motions through the use of a Markov Random Field, whilst the patch-based nature of the model allows the use of efficient techniques for estimating the local motion at each patch. An important aspect of our work is that the method takes account of the fact that local surface texture strongly dictates the accuracy of the motion that can be estimated at each patch. Even with simple squared-error cost functions, it produces results that are either equivalent to or better than results from a method based upon a state-of-the-art optical flow technique, which uses well-developed robust cost functions and energy minimisation techniques.

@&#INTRODUCTION@&#
Scene flow is the dense non-rigid three-dimensional motion field of a scene, and is analogous to the concept of optical flow for describing the motions between a pair of 2D images [1]. Estimating scene flow is difficult because some scene surfaces may contain little texture and may move in a nonlinear way. This leads to an under-constrained problem unless some prior knowledge about the form of the solution is introduced. The scene flow problem therefore has many similarities to the optical flow problem: the difference is that multiple cameras are required in order to estimate scene flow since a single camera does not provide sufficient information. Current approaches to estimating scene flow involve two methods of regularisation: either a local prior is introduced or a global prior is introduced. Algorithms that commonly use surface patches or surfels [2] and employ a local prior have their roots in the Lucas–Kanade method for estimating optical flow [3]. Techniques employing a global prior use either image or surface-based regularisation [1], and have similarities to the Horn and Schunck optical flow method [4].This article presents a method that combines both local and global constraints for estimating scene flow. This is achieved by the use of an interconnected surface patch model: the local prior is provided by the surface patch, whilst the interconnected nature of the model provides the global prior. Since the interconnected patch model forms an undirected graph, Markov Random Field inference techniques can be used to find the most likely patch motions given a local motion observation at each patch.An important aspect of the presented method is the combination of both local and global energy minimisation into a single framework. Local motion estimates at each patch are provided by a Gauss–Newton minimisation, whereas Markov Random Field inferences are made using Loopy Belief Propagation.For optical flow, it has been shown that local approaches are more robust against noise, whilst global approaches recover a dense motion field [15]. The combination of local and global approaches for optical flow estimation has therefore already been proposed [15], but, to our knowledge, such an approach for estimating scene flow has not yet been investigated. The method presented here can be seen as an extension of the method of Bruhn et al. [15] to the scene flow problem.We show that by using a combination of local and global approaches, it is possible to estimate the scene flow for multiple frames of a scene, even if it contains many surfaces with little texture. In order to achieve this, a method for estimating the scene flow confidence at each patch is introduced so that patches with the most information constrain neighbouring patches with less texture. Since our confidence measure is a covariance matrix at each patch, Belief Propagation messages can be encoded using simple Gaussian distributions, leading to a straightforward implementation of the algorithm.Obtaining measures of confidence for optical flow is well known and used as the criteria for the KLT feature detector, which selects the optimal textures for 2D template tracking [16,17]. Using such a confidence measure has been shown to improve the performance of other computer vision tasks, especially when the image textures are randomly selected [18]. This insight applies also to the scene flow problem, since we are interested in finding a confidence measure for an arbitrary patch from the scene surface, rather than for a set of sparse patches selected by a feature detector.The proposed technique calculates the image gradients on each surface patch with respect to its rigid-body motions. We extend existing 2D methods for evaluating motion estimation confidence, by using the inverse of the Hessian matrix of image gradients with respect to its rigid-body motions. This yields a covariance matrix for each patch, which may be visualised by overlaying ellipsoids at each patch (see Fig. 1)) to demonstrate its effectiveness.Earlier versions of this work appear in two conference papers [19,20]. This article adds a more rigorous Bayesian framework for the presented scene flow method and also provides comparative results against a method based upon state-of-the-art optical flow techniques. The rest of the article is organised as follows. Section 2 provides a brief survey of existing approaches to scene flow estimation. Section 3 describes how both local and global priors can be used to accurately estimate scene flow. Section 4 shows experimental results for our proposed method, and demonstrates effective motion tracking through multiple applications of the scene flow algorithm. Finally, Section 5 draws conclusions and provides suggestions for future work. We believe that our scene flow certainty estimates could also be used for 3D feature detection in a similar manner to the 2D KLT feature detector [16].

@&#CONCLUSIONS@&#
This article has presented a method for estimating scene flow, by combining local and global approaches to regularisation. This was achieved by using a set of interconnected patches, for which each patch provided a local regularisation of the solution and the interconnected nature of the model provided global regularisation. The results show that the performance of the proposed method is either equivalent to or better than results obtained using a state-of-the-art optical flow algorithm at each camera view. An important point here is that the optical flow techniques have been successively refined over 30years, and it is a mark of achievement that the proposed method performs well against these well established techniques.The second contribution of this article has been a method of estimating the scene flow confidence at each patch, using the Hessian matrix of patch image gradients with respect to the motions. This method can be seen as an extension of existing methods for estimating the confidence of 2D feature points, and was used in this article for propagating measurements between patches in a probabilistic way when incorporating the global motion prior.There are several interesting avenues for further work. For the case of 2D tracking, the knowledge of motion estimation confidences has been used to implement a feature detector that selects the best features for tracking [16,17]. This principle could therefore be extended to give a feature detector that finds the best features for 3D patch tracking. Finding texture features on a surface is not new, as a few authors have already proposed this idea for the purpose of mesh matching [42,50]. However, the selection of surface features for 3D tracking would be both novel and useful, and is a relatively straightforward extension of the work proposed here.Another interesting avenue for further work would be the application of the new technique to a mesh model. The current surface description does not include any knowledge of connectivity, and instead this has to be inferred by using the Euclidean distance between patch centres. If possible, a mesh model should therefore be employed to ensure that only the true neighbouring surface points are used when enforcing smooth motion. Even with the change of scene description, it should be noted that this method would still be relevant: the patch should be used as a motion estimation tool at each mesh node, and the propagation of the Gaussian densities should be carried out in exactly the same way. It is fairly easy to envisage how the method described in Section 3 could therefore be used to improve existing mesh based techniques. This would lead to a probabilistic Laplacian mesh deformation instead [26,7]. These all assume equal measurement noise at each point of the surface model, but the ellipsoids in Fig. 1 clearly show that this is invalid.