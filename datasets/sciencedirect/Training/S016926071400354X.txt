@&#MAIN-TITLE@&#
An enhanced method for registration of dental surfaces partially scanned by a 3D dental laser scanning

@&#HIGHLIGHTS@&#
A novel method is proposed for the accurate registration of partially scanned dental surfaces.The results showed that our method accurately registered partially scanned dental surfaces.Our method and its application are useful for orthodontic and prosthodontic treatment.

@&#KEYPHRASES@&#
Depth map,Depth map-based registration,Surface registration,Iterative closest point,3D dental laser scanning,

@&#ABSTRACT@&#
In this paper, we propose the fast and accurate registration method of partially scanned dental surfaces in a 3D dental laser scanning. To overcome the multiple point correspondence problems of conventional surface registration methods, we propose the novel depth map-based registration method to register 3D surface models. First, we convert a partially scanned 3D dental surface into a 2D image by generating the 2D depth map image of the surface model by applying a 3D rigid transformation into this model. Then, the image-based registration method using 2D depth map images accurately estimates the initial transformation between two consequently acquired surface models. To further increase the computational efficiency, we decompose the 3D rigid transformation into out-of-plane (i.e. x-, y-rotation, and z-translation) and in-plane (i.e. x-, y-translation, and z-rotation) transformations. For the in-plane transformation, we accelerate the transformation process by transforming the 2D depth map image instead of transforming the 3D surface model. For the more accurate registration of 3D surface models, we enhance iterative closest point (ICP) method for the subsequent fine registration. Our initial depth map-based registration well aligns each surface model. Therefore, our subsequent ICP method can accurately register two surface models since it is highly probable that the closest point pairs are the exact corresponding point pairs. The experimental results demonstrated that our method accurately registered partially scanned dental surfaces. Regarding the computational performance, our method delivered about 1.5 times faster registration than the conventional method. Our method can be successfully applied to the accurate reconstruction of 3D dental objects for orthodontic and prosthodontic treatment.

@&#INTRODUCTION@&#
Dentistry requires the accurate reconstruction of 3D dental objects (e.g., whole teeth) for orthodontic and prosthodontic treatment [1]. The 3D surface model of dental objects could be reconstructed by the fabrication of plaster models [2]. The plaster models are fabricated by pouring impression. Instead of fabrication, oral radiology can provide the dentist with the detailed information of dental objects Whereas oral radiology has been widely used as a routine technique in dental clinical practice, the accurate segmentation of a 3D dental object for the reconstruction is very difficult due to similar intensities between nearby objects and noises in cone-beam computed tomography (CBCT) images [3–5]. Furthermore, the equipment for oral radiology (e.g., CBCT) is expensive and the radiation required to enhance both contrast and spatial resolution could be high [1].For the alternative to oral radiology, in order to perceive the anatomical information of maxillofacial structure, a 3D dental laser scanning has been recently introduced to acquire the 3D geometry of the teeth robustly [6,7]. The equipment of laser scanning is usually simple and the scanning speed is fast. However, due to the limited field of view of the scanner, a single surface model acquired by the laser scanner cannot cover the whole teeth. In order to resolve this limitation of dental laser scanning, a set of surface models taken at different positions, which include partial information of one or two teeth are acquired and each surface model should share overlapped region with neighboring surface model. Then, they should be integrated to generate the unified surface model of the whole teeth. However, considering that each surface model is acquired at different position and orientation, the accurate registration method is required to integrate the set of surface models into the single surface model of the whole teeth with the minimization of the artifacts near the overlapped boundaries of each consecutive surface model.Various kinds of surface-based registration methods have been proposed to find the optimal transformation between a set of surface models taken at different positions and orientations [8–20]. Maal et al. [8] proposed a surface-based registration based on iterative closest point algorithm (ICP)[9] to evaluate the treatment outcomes in oral and maxillofacial surgery. However, the surface overlap region of this method should be the whole surface. And this method cannot be applied to the surface registration between partially overlapped surfaces. Swennen et al. [10] proposed a point-based rigid registration to plan orthognathic and facial orthomorphic surgery by computing the rotation and translation from the surface information and searching the corresponding points and shapes. However, this method required the positional information of anatomical feature points. Albrecht et al. [11] introduced a 3D surface registration represented by signed distance function and registered surfaces by means of their distance images and a combination of feature images and curvature images. However, this method required a heavy computation for the generation of the signed distance function.Surface-based registration methods can be mainly categorized into relational matching [12,13] and minimization techniques. The relational matching technique [12,13] is a method for finding the best correspondences between structural descriptions for the recognition of objects in digital images. It extracts and aligns local surface features to establish the point correspondences between two surfaces. Local surface features such as spin-images [14], splashes [15], point signatures [16], harmonic shape images [17], spherical attribute images [18], and tripod-operators [19] have been proposed. In order to register two surfaces using these local surface features, the corresponding point pairs between two surfaces should be determined in overlapping regions, which are shared in two surfaces to be registered. However, it is difficult to find the exact overlapping region without any prior knowledge. Furthermore, although the overlapping regions are correctly determined, a point on one surface is unfortunately corresponding to multiple similar points on the other surface (i.e., the multiple point correspondence problem) resulting in the increase of the registration error.In the minimization techniques, a similarity metric between two surfaces is defined and optimized as a function of the unknown transformation. In ICP algorithm [9,20], the similarity metric is defined as the point-to-point distance between corresponding point pairs, which are established by finding the closest point in the other surface of each point in one surface. In [21], the similarity metric is based on the point-to-plane distance. These similarity metrics can accurately register two surfaces when two surfaces are relatively well aligned before registration since the closest point pairs might probably be equal to the exact corresponding point pairs. However, they are not adequate for the registration of initially ill-aligned surfaces since it is less probable that the closest point pairs are the exact corresponding point pairs. Moreover, the multiple point correspondence problem also occurs when a point on one surface has the multiple closest points on the other surface model.In this paper, we propose the fast and accurate registration method of partially scanned dental surfaces in a 3D dental laser scanning. To overcome the multiple point correspondence problem for the accurate registration of 3D surface models, we propose the depth map-based registration method to initially register 3D surface models. First, we convert the 3D surface model into a 2D image by generating the 2D depth map image of each partially scanned surface model by applying a 3D rigid transformation into this model. The corresponding point pairs in each 3D surface model are converted into corresponding image pixels in each 2D depth image. Then, the image-based registration method using 2D depth map images accurately estimates the initial transformation between two surface models. Each pixel in one image corresponds to a pixel in the other image without the multiple correspondence, which guarantees one-to-one point correspondence. To increase the computational efficiency, we decompose the 3D rigid transformation into out-of-plane transformation (i.e., x-, y-rotation, and z-translation) and in-plane transformation (i.e., x-, y-translation, and z-rotation). For the in-plane transformation, we accelerate the transformation process by transforming the 2D depth map image instead of transforming the 3D surface model. For the accurate registration of 3D surface models, we enhance ICP method for the subsequent fine registration to align 3D surface models exactly. Our initial depth map-based registration well aligns each surface model. Therefore, our subsequent ICP method can accurately register two surface models since it is highly probable that the closest point pairs are the exact corresponding point pairs.The remainder of this paper is organized as follows. Section 2 describes the proposed method of our registration method including coarse and fine registration. Section 3 presents the results of the application of the proposed method to clinical datasets along with a comparison to other previous methods. Finally, we summarize the results and discuss future work in Section 4.The goal of surface registration is to find an optimal transformation such that the floating (i.e., moving) surface best matches the reference (i.e., fixed) surface. Our registration method is composed of the following steps, as shown in Fig. 1. First, we perform coarse registration for global surface matching, which serves as an initial estimate for the next fine registration. In coarse registration, a 2D depth map image is generated from each 3D dental surface model, which is acquired by dental laser scanning and used for accurate initial matching. Then, we further align two surface models using our fine registration method.For the accurate initial matching, our coarse registration is based on a 2D depth map image, which is computationally generated from a 3D dental surface model. To establish the correspondence between points, surface-based registration methods [14–19] usually compute local surface features around points and compare them between points from different surface models. When a point on one surface model has multiple similar points on the other surface model, the multiple point correspondence problem occurs. However, the multiple point correspondence problem usually does not occur in image-based registration methods. Therefore, in this paper, we propose a novel image-based registration method into the registration of surface models for preventing the multiple point correspondence problem. We convert a 3D surface model to an image by generating 2D depth map image of the surface model. For image-based registration methods, points from surface models are encoded into image pixels, which are the regular grids. The corresponding image pixel pairs, which represent the corresponding point pairs, are defined as the same pixel coordinate of images. Thus, a pixel on one image dose not correspond to multiple pixels on the other image in image-based registration methods, which guarantees one-to-one point correspondence.The depth map image is generated by projecting the triangular mesh surface model along the z-axis. If we project only three vertices of each triangular surface model, holes in the depth map image can be generated due to the empty space between the vertices when they are not close enough. In order to remove the hole in the depth map image, the inner points in a triangle should be sampled and also projected to the depth map image as follows. With three triangular vertices v1, v2, and v3, an inner point, p, can be computed by barycentric interpolation as follows:(1)p=αv1+βv2+γv3,α+β+γ=1,α,β,γ≥0Then, we generate the set of sampled points which would be projected into the depth map image as follows:(2)SP=⋃i=1npi,1,pi,2,...,pi,j,...,pi,m(i),where SP is the set of sampled points with n number of triangles, m(i) is the number of sampled points in the ith triangle, and pi,jis a jth inner point in the ith triangle computed by Eq. (1). Before the projection of these sampled points, we compute the bounding box of a surface model and compute a width (w), a height (h), and the center position (c) of the bounding box. By projecting pi,jin SP, the 2D depth map image (DM) with the size of m×n is determined by:(3)DM(x,y)=argmin(x,y)∈Spzi,j,S=(x,y)x=pxi,j−cxw+0.5×mandy=pyi,j−cyh+0.5×n,where cxand cyare x- and y-coordinate of c, andpxi,j,pyi,j, andpzi,jare x-, y-, and z-coordinates of pi,j. After the projection of all the points in SP, DM is finally generated. In Figs. 2 and 3, we generate the 2D depth map image (Fig. 3) from the partially scanned surface models in a 3D dental laser scanning (Fig. 2).Our depth map-based registration method is composed of the following steps, as shown in Fig. 1(b) and (c). First, the reference depth map image (DMR) and the floating depth map image (DMF) are generated from the reference and floating surface model, respectively. Then, our registration method generates transformed floating depth map images (DMTF) by changing transformation parameters and finds the optimal DMTFamong them. Because DM is two-dimensional, DMTFs should be generated by transforming the 3D surfaces model using the 3D rigid transformation.Our registration method performs the optimization of transformation parameters in 6D space including three rotational and three translational parameters. To reduce the number of searches and the computational complexity, we decompose 3D rigid transformation into out-of-plane (i.e., x-, y-rotation, and z-translation) and in-plane transformations (i.e., x-, y-translation, and z-rotation). For out-of-plane transformation, the position of a transformed vertex, νout-of-plane,iis calculated by applying x-, y-rotation, and z-translation into the vertex of each surface model,viin Eq. (4). For in-plane transformation, the position of a transformed vertex,vin−plane,iis calculated by applying x-, y-translation, and z-rotation into the vertex of each surface model,viin Eq. (5).(4)vout-of-plane,i=RxRy(vi−vc)+Tz,(5)vin-plane,i=Rz(vi−vc)+Tx+Ty,where Rx, Ry, and Rzare the transformation matrix representing x-, y-, and z-rotation, respectively. Tx, Ty, and Tzare the transformation matrix representing x-, y-, and z-translation, respectively.vcis the rotational center position, which is the center of the mass of the surface model. For in-plane transformation, DMTFcan be generated by not transforming 3D surface model itself but transforming 2D DMFresulting in the much decrease of transformation time. Using out-of-plane and in-plane transformations, our depth map-based registration method is also decomposed into out-of-plane and in-plane registrations.In out-of-plane registration, DMTFis generated after the out-of-plane transformation of the 3D floating surface model. Then, we find the optimal DMTFand out-of-plane transformation parameters among DMTFs. As the depth map image is generated by reflecting z-coordinate values of points of its corresponding surface model, it is possible to assume that each depth map image is acquired by the same modality. Image-based registration in the same modality generally uses the sum of squared difference (SSD) and the normalized cross correlation (NCC) as the similarity measure. However, if the z-position of the dental laser scanner is changed, the corresponding pixels have different z-coordinate values resulting in the intensity change of the depth image. Therefore, SSD is not directly applicable in our environmental setting. However, NCC can be used to measure the similarity for the corresponding pixels having not the same pixel values, but linearly correlated pixel values. We can assume that z-coordinate values are linearly correlated during the change of the z-position of the scanner. Thus, in this paper, we use NCC as the similarity measure as follows:(6)NCC(DMR,DMF;T)=∑Ω(DMR(x)−DMR¯)(DMTF(x)−DMTF¯)∑Ω(DMR(x)−DMR¯)2∑Ω(DMTF(x)−DMTF¯)2,whereDMR¯is the mean of DMR, andDMTF¯is the mean of DMTF. The optimization stage searches for the optimal DMTFand out-of-plane transformation parameters by maximizing NCC. We use Powell's method with the optimization order of x-, y-rotation, and z-translation. To accelerate the processing speed and avoid the local maxima, a multi-resolution approach is applied. We use three-level Gaussian pyramid with a down-sampling factor of 2 in each dimension. Note that z-translation parameter can be computed by the subtraction betweenDMR¯andDMTF¯because the mean values of depth map images represent the mean z-coordinates of the corresponding surface models.In-plane registration method generates the candidate DMTFs by the in-plane transformation of the out-of-plane registered floating depth map image in the previous step. Then, we find the optimal DMTFand the optimal in-plane transformation parameters among the DMTFs by maximizing Eq. (6). We also use Powell's method with the optimization order of x-, y-translation, and z-rotation. To accelerate the processing speed and avoid the local maxima, a multi-resolution approach is applied as out-of-plane registration method. We use three-level Gaussian pyramid with a down-sampling factor of 2 in each dimension.Subsequently, we perform the fine registration after the depth map-based registration (Fig. 1(d)). Although the depth map-based registration is accurate for coarse registration, its accuracy is not perfect because the generation of 2D depth map image involves projecting only surface point in the closest triangles from the view point and losing the information of surface points in the other triangles. To perform more accurate registration, our surface registration method computes the similarity metric for every surface point in overlapping region. We enhance iterative closest point (ICP) algorithm [9] for the fine surface registration. ICP algorithm is widely used for the alignment of 3D surfaces when the initial estimate of the relative pose is known. Since we compute the accurate initial estimate using depth map-based registration in the previous section, ICP algorithm is appropriate for our fine registration. ICP starts with the reference and floating surface models, and an initial guess for their relative rigid transformation. Then, the overlapping region between the reference and initially transformed floating surface models is determined by finding the common region in bounding boxes from both surface models. The fine registration iteratively refines the transformation by repeatedly generating corresponding point pairs on the reference and transformed floating surface models, and minimizing the following average surface distance (ASD), which is the surface distance in only the current overlapping region.(7)ASD=1nOFST∑i=1nOFSTmax(threshold−md(PiOFST,ORS),0),where ORS is the overlapped reference surface model that is the overlapping region in the reference surface model, OFSTis the overlapped transformed floating surface model that is the overlapping region in the transformed floating surface model, nOFSTis the number of points in OFST,piOFSTis the ith point in OFST, and md(PiOFST, ORS) is the minimum distance betweenpiOFSTand ORS, which is defined as follows:(8)md(PiOFST,ORS)=minj∈1,...nORSd(PiOFST,PjORS),where nORSis the number of points in ORS andpjORSis the jth point in ORS. As described in [22], our fine registration method is decomposed into the following stages. First, our fine registration selects the set of points on the reference surface model randomly, and the closest point for each randomly selected point is found in the transformed floating surface model using Eq. (8). Some point pairs are rejected with point-to-point distance greater than a threshold which is computed by over the 95% confidence interval of all point-to-point distance and the others are used for computing point-to-point error metric using Eq. (7).For the error minimization, we employ the closed-form iterative minimization technique [23,24]. The closed-form iterative minimization consists of following steps. From the reference and transformed floating surface models, we compute the overlapping region using bounding boxes and a set of corresponding point pairs using the current transformation is generated using Eq. (8). Then, the mean square objective function parameterized by the 3D rigid transformation parameters (R,t) is minimized and the cross-covariance matrix H which can be decomposed by singular value decomposition.(9)H=UΛVT.New rotation matrix R is VUT and new translation vector t isp¯OFST−R∘p¯ORSwherep¯ORSandp¯OFSTis the center of mass in PORSand POFSTrespectively. After updating rigid transformation parameters, the floating surface model is transformed by updated parameters. Then, the previous steps are revisited using newly transformed floating surface model until ASD from Eq. (7) is converged.

@&#CONCLUSIONS@&#
