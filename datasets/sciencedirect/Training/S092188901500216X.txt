@&#MAIN-TITLE@&#
Real-time Unsupervised Segmentation of human whole-body motion and its application to humanoid robot acquisition of motion symbols

@&#HIGHLIGHTS@&#
This paper proposes a framework for real-time unsupervised segmentation of human motions and automatic symbolization of the motions.The segmentation is based on prediction uncertainty and symbolization is based on competitive learning of human motion.Their integration was verified on the human motion datasets.

@&#KEYPHRASES@&#
Motion segmentation,Motion primitive,Competitive learning,

@&#ABSTRACT@&#
An interactive loop between motion recognition and motion generation is a fundamental mechanism for humans and humanoid robots. We have been developing an intelligent framework for motion recognition and generation based on symbolizing motion primitives. The motion primitives are encoded into Hidden Markov Models (HMMs), which we call “motion symbols”. However, to determine the motion primitives to use as training data for the HMMs, this framework requires a manual segmentation of human motions. Essentially, a humanoid robot is expected to participate in daily life and must learn many motion symbols to adapt to various situations. For this use, manual segmentation is cumbersome and impractical for humanoid robots. In this study, we propose a novel approach to segmentation, the Real-time Unsupervised Segmentation (RUS) method, which comprises three phases. In the first phase, short human movements are encoded into feature HMMs. Seamless human motion can be converted to a sequence of these feature HMMs. In the second phase, the causality between the feature HMMs is extracted. The causality data make it possible to predict movement from observation. In the third phase, movements having a large prediction uncertainty are designated as the boundaries of motion primitives. In this way, human whole-body motion can be segmented into a sequence of motion primitives. This paper also describes an application of RUS to AUtonomous Symbolization of motion primitives (AUS). Each derived motion primitive is classified into an HMM for a motion symbol, and parameters of the HMMs are optimized by using the motion primitives as training data in competitive learning. The HMMs are gradually optimized in such a way that the HMMs can abstract similar motion primitives. We tested the RUS and AUS frameworks on captured human whole-body motions and demonstrated the validity of the proposed framework.

@&#INTRODUCTION@&#
In robotics, various imitative learning frameworks have been proposed  [1–3]. These approaches symbolize body movement into a set of model parameters, which are referred to as motion symbols, recognize observed motion as motion symbols, and generate motion data from the motion symbols  [4–8]. This research on constructing intelligence through encoding bodily senses and movement into motion symbols in robotics has been inspired by the discovery of mirror neurons  [9,10] and by the hypothesis of mimesis  [11]. Mirror neurons fire not only when a macaque monkey observes another monkey performing a particular motion but also when the first monkey has just performed the same motion. The relationships between mirror neurons and various functions such as symbolization, recognition, generation of behaviors, communication, theory of mind, and language have attracted much attention. The mimesis hypothesis posits that intelligence in human beings originated in gesture communication, so that people would have gained the ability to memorize gestures performed by others, recognize behaviors, and synthesize behaviors before acquiring language.When a humanoid robot memorizes human behavior as a motion symbol through observation, the robot needs to segment seamless human behavior into motion primitives and to encode these motion primitives into model parameters. That is, symbolization of behaviors should follow motion segmentation. In previous frameworks to symbolize human behaviors, motion primitive data must be provided by manually segmenting measured behaviors, such as captured human motions. Using manually selected motion primitives has the advantage that it is easy to give motion labels to them because they are intuitive. However, when a humanoid robot needs to memorize a large amount of motions in the form of motion symbols, manual segmentation is not practical because of the required labor. Additionally, a humanoid robot must be able to segment seamless human behavior by itself in order to incrementally develop motion symbols by encoding unknown motion primitives into new model parameters. Thus, for a humanoid robot that coexists in our daily lives, automatic segmentation of human behaviors is a fundamental intelligent processing that leads to memorizing, recognizing, and synthesizing behaviors based on the motion symbols.In this study, we propose a novel approach to Real-time Unsupervised Segmentation (RUS) for human whole-body motions. RUS detects boundaries of motion primitives that are frequently observed in human behaviors. As illustrated by Fig. 1, in the first phase, human behavior is divided into a sequence of short feature movements that are encoded into Hidden Markov Models (HMMs), referred to as “feature HMMs”. This phase converts continuous human behavior into a sequence of discrete features. In the second phase, causality among the discrete features is extracted from sequences of these features by a correlation matrix. In the third phase, the correlation matrix is used to estimate prediction uncertainty for the discrete feature that will follow the current sequence of discrete features. Large prediction uncertainty implies that the current movement is unpredictable, and unpredictable movement is identified as a boundary of motion primitives. In this way, motion primitives can be derived. Additionally, this paper applies RUS to AUtonomous Symbolization (AUS) of human whole-body motions. The derived motion primitives are used as training data for HMMs, which are then referred to as “motion symbols”. Each motion primitive is classified as a motion symbol, and the corresponding HMM retrains the motion primitive incrementally using competitive learning. RUS and AUS allow a humanoid robot to observe human behaviors, derive motion segments, and acquire motion symbols by itself. We tested a framework integrating RUS and AUS on captured human behaviors and demonstrated its validity.Segmentation has been studied from various points of view, including motion, speech, and sentence structure. Mori et al. developed a technique for supervised segmentation of daily human movements  [12]. Two of their assumptions are that the boundaries of daily human motion segments are unclear and that motion boundaries are distributed. Human subjects are asked to evaluate, on a scale from one to four, the possibility that each frame in a sequence of human movements is a boundary. The evaluation scores are taken as the distribution of motion boundaries. Since the distribution is based on manual segmentation, criteria for segmentation similar to intuitive segmentation can be obtained. However, this approach has the drawback that it is not scalable to large motion datasets. As the number of motion datasets to be processed increases, the labor necessary for manual segmentation also increases. Kohlmorgen et al. proposed a system for automatic segmentation of time series data  [13], and Kulic et al. or Janus et al. applied their system to incremental segmentation and clustering of human motion pattern primitives  [14,15]. This segmentation algorithm assumes that same motion primitives have same underlying distribution. The window of motion data is represented by the Gaussian distribution, and the node with this distribution is added to an HMM. The node path corresponding to the motion data is estimated by Viterbi algorithm in the HMM, and the boundary of the motion primitive can be detected at the switching point between the end nodes in the path. The derived motion segments are placed into the closest group, and the large group forms multiple child groups. This incremental process results in the clustering structure of the motion primitives. The method of tuning several parameters in the segmentation and grouping is not described, which is critical to appropriate segmentation and clustering of motion primitives. Grave et al. developed an approach to segmenting and classifying the motion to manipulate an object. The likelihood of a motion segment terminating at a specific point being generated by an HMM and the likelihood of a motion segment starting at the same point begin generated by the following HMM are computed, and the point is searched for that maximizes the combined likelihood. The initial HMMs require a dataset of presegmented motion data  [16].An approach to extracting periodic motion primitives from a conductor’s hands has also been proposed  [17]. This approach is based on the COMPRESSIVE technique, which measures the compression rate of hand movements. The compression rate is computed from the length and frequency of motion chunks. A motion with a high compression rate is regarded as a motion primitive. This method can segment periodic human movements into a sequence of motion primitives. Because this approach counts the occurrence of a specified motion chunk to compute its frequency by observation of human motion, the system has to store all observations simultaneously. Moreover, the extraction of motion primitives that have a high compression rate is time consuming. It is, therefore, difficult to apply this approach to segmenting long whole-body motions of humans in real time. Tae-hoon et al.  [18] have proposed a method to segment rhythmic movement into motion primitives. Their method detects the moments when the velocity of each joint angle becomes zero and approximates a temporal sequence of these stopped moments by a sine function. The sine functions for all of the joints are superposed into a reference function for boundaries of motion primitives. Motion primitives can be extracted from rhythmic human movements by these reference functions. This method results in all of the derived motion primitives having the same interval because the reference function is represented by a periodic function.Shiratori et al. also propose a method to derive motion segments from dance movement, based on an assumption that the dance movement is a sequence of motion primitives with boundaries at stopped moments  [19]. To extract the motion primitives, the method focuses on the speed of a performer’s hands and legs, selects a pose when one of the body parts stops as a candidate for a key pose, and chooses boundaries of motion primitives from among the candidates by taking into account the rhythm of the music. In this method, the dance movement is divided into motion primitives by assuming that the motion primitives start and end at frames with zero motion velocity. This assumption may be reasonable in dance situations, but it is not clear that this assumption is useful for daily human actions.In the fields of natural language processing and speech recognition, research on segmentation has been conducted for a long time because segmentation of words from sentences or speech without clear boundaries between words is a fundamental process  [20]. Language segmentation approaches developed thus far can be categorized into three strategies: utterance-boundary strategy  [21,22], predictability strategy  [23,24], and word-recognition strategy  [25]. The utterance-boundary strategy hypothesizes that the ends of words have features similar to the ends of sentences or of utterances. The predictability strategy is based on predicting a phoneme or character by the immediately preceding phonemes or characters. The word-recognition strategy is an approach to checking whether a sequence of phonemes or characters matches one of a set of registered words. In recent years, the performance of computers has improved and connectionist models, such as neural networks, have been applied to the utterance-boundary strategy and the predictability strategy. Although these models make it possible to detect boundaries of words, it is still impossible to recognize a sequence of phonemes or characters as a word. Moreover, it is hard for the models to implement real-time learning, for which optimizing parameters of the models consumes a substantial amount of time. In contrast, the word-recognition strategy enables a sequence of phonemes or characters to be recognized as a word at the same time that segmentation is performed. However, a word-recognition strategy model that allows for real-time segmentation has not been proposed yet.Human whole-body motionOis represented by a sequence of vectors of joint angles. Dividing human whole-body motion into short movementso(i)results in human motion being expressed as a sequence of short movements as shown by Fig. 2.(1)O=[o(1),o(2),…,o(k)].A short movement is also represented by a short sequence of joint angle vectors at thetth frame,oˆ(t).(2)o(i)=[oˆ((i−1)wspan+1),oˆ((i−1)wspan+2),…oˆ(iwspan)]wherewspanis the number of frames in each short movement.We introduce a set ofNDpieces of HMMs, into which the short movemento(i)is encoded. The HMMs corresponding to the short movement are referred to as a “feature HMM”. HMM is a stochastic model that is used to categorize input data, especially in speech recognition. HMM is defined by a set of variablesλ={Q,A,B,Π}, whereQ={q1,…,qn}is a set of nodes,A={aij}is the matrix whose(i,j)element represents the transition probability from theith node to thejth node,B={b1,b2,…,bn}is the set of probability density functions, andΠ={π1,π2,…,πn}is the set of initial node distributions. A probability density function is defined by the Gaussian distribution form(3)bi(oˆ)=1(2π)m|Σi|exp{−12(oˆ−μi)TΣi−1(oˆ−μi)}whereμi,Σi, andmdenote the mean vector, the covariance matrix of the HMM, and the dimension of the input data, respectively.We first calculate the likelihoods of a short movement being generated by feature HMMs and select the HMMλRfwith the largest likelihood. Let us denote the likelihood of a short movemento(i)being generated from thekth HMMλkfby the conditional probabilityP(o(i)|λkf). The HMMλRfrepresents the HMM with the largest likelihood,P(o(i)|λkf). Then,(4)λRf=argmaxλkf:k=1,2,…,NfP(o(i)|λkf)whereNfis the number of feature HMMs. As shown by Fig. 2, the short movemento(i)is provided for the HMMλRfas training data such that the parameters of the HMM can be optimized by the Baum–Welch algorithm  [26], which is an expectation–maximization algorithm. The optimizing procedures are iterated over a sequence of short movements. Note that the initial parameters of the feature HMMs are set randomly.A phase of extracting causality from among short movements follows the optimization of the feature HMMs. A short movement is recognized as the feature HMM with the largest likelihood that the movement is generated by that HMM. Thus, a sequence of short movements can be converted to a sequence of the feature HMMs corresponding to those movements. In this study, theNspieces of the feature HMMs with the largest likelihood are selected. The selection of several feature HMMs improves the robustness of the conversion from short movements to binary features. The set of the selected feature HMMs,S(i), forms a binary feature vector corresponding to the short movement. The binary vectorxˆ(i)is a column vector withNfelements, each zero or one. Each element ofxˆ(i)is set as follows.(5)xˆ(i)=[xˆ1(i)xˆ2(i)…xˆNf(i)]T(6)xˆk(i)={1λkf∈S(i)0λkf∉S(i)whereTdenotes matrix transposition.Aligning theMpieces of the binary feature vectors in columns creates a feature vectorx(i)that is a unit vector.(7)x∗(i)=[xˆ(i−M+1)T⋯xˆ(i)T]T(8)x(i)=x∗(i)‖x∗(i)‖.Fig. 3illustrates an overview of conversion from the continuous motion data to the binary feature vector. The correlation matrix extracts the causality of the feature vectors from the sequence of feature vectors. Correlation learning is a scheme where the causality between an input vector and an output vector{ul,yll=1,2,…,K}is represented by the correlation matrixW0=∑l=1KylulT. In an ideal situation, where all input vectors are orthogonal to each other, each output vectorykcan be predicted from its corresponding inputukas follows:(9)yk=W0ukbecauseulTuk=1only ifl=k.The correlation matrix can be computed as described above if all pairs of input and output vectors are known in advance. In segmentation of human whole-body motion, however, it is preferable to determine the correlation matrix incrementally while a robot observes human motions rather than to learn it from the complete set of pairs of input and output vectors at once. Therefore, we propose an approach to incremental computation of the correlation matrix(10)W(i)=αW(i−1)+ηx(i)x(i−1)T,whereαandηdenote the stabilizing and learning coefficients, respectively. In this approach, a current feature vectorx(i)is given as an output, and the feature vectorx(i−1)immediately precedingx(i)is given as an input. The matrixx(i)x(i−1)Tprojects the preceding feature vectorx(i−1)on to the current feature vectorx(i). Eq. (10) gradually updates the correlation matrix from the previous matrixW(i−1)by incrementing the current dynamicsx(i)x(i−1)Tof the feature vectors. This correlation matrix can extract the causality of feature vectors and predict the feature vector one step ahead of the current feature vector. The norm of the predicted feature vectorWxis bounded below one by setting the stabilizing and learning coefficients so that the sum of them becomes one,α+η=1.We intuitively suspect that we can easily predict the movement following the current observation at an intermediate time point within a motion primitive but that it is difficult to predict movement at the transition between two motion primitives. This intuition leads to the assumption that an error between actual movement and predicted movement can be used as a criterion for the boundary of a motion primitive. We can calculate the errorE(i)between the actual feature vector and the predicted feature vector as(11)E(i)=‖x(i)−Wx(i−1)‖.The error can be interpreted as the prediction uncertainty, and the moments when this uncertainty is large will be considered the boundaries of motion primitives. In our implementation, we detect the boundaries as the moments when the error exceeds a specified thresholdEth. The time of the boundary for a motion primitive can be derived askBsuch thatE(kB−1)>EthE(kB)<Eth.A framework to symbolize human whole-body motions has been developed, where human motion primitives are encoded into their corresponding HMMs  [6]. This framework enables a humanoid robot not only to memorize human motions as motion symbols but also to observe and generate human-like motions using motion symbols. Furthermore, motion data are decomposed into features typified by principal components or independent analysis, and the feature series are subsequently encoded into the HMM in order to reduce the dimensionality and noise in the original motion data  [27]. The previous framework needs manual segmentation of seamless human motions in order to derive motion primitives, which are then given to the HMMs as training data. In this study, we integrate RUS with AUtonomous Symbolization of human motions (AUS). This integration makes it possible for a humanoid robot to autonomously acquire motion symbols from observation without manual intervention.Symbolization of motion primitives by competitive learning happens after segmentation.step1Initially, a robot hasNSHMMs (λk:k=1,2,3,…,NS). Randomly set the parameters of each HMM.Compute the likelihoods that derived motion primitiveOsegment(i)is generated by the HMMs. Select the HMM with the largest likelihood,λR, as the resultant motion primitive:(12)λR=argmaxλk:k=1,2,…,NSP(Osegment(i)|λk).Store the motion primitiveOsegment(i)as training data for the HMMλR.When the number of stored motion primitives for the training data of HMMλRreaches a specified quantity, optimize parameters of the HMM such that the likelihood of the motion primitives being generated by the HMM are maximized. After optimization, remove the motion primitives. When the number of stored motion primitives is less than the specified quantity, skip the optimization.Derive the next motion primitiveOsegment(i+1)through the RUS method; then, go to step2.In the motion recognition process, the resultant motion primitive is the motion symbol with the largest likelihood, as computed by Eq. (12). In the motion generation process, the initial nodeq(1)is selected according to the initial node probabilityΠ, and the joint angleso(1)at timet=1is subsequently sampled according to the output probabilitybq(1)(o). The nodeq(2)at timet=2is selected according to the transition probabilitiesaq(1)ifrom nodeq(1)to theith node, and the joint angleso(2)are sampled according to the output probabilitybq(2)(o). These processes are iterated to generate a sequence of joint angles. This simple motion generation adopts a Monte-Carlo-based method  [6].Experiments using the RUS and AUS frameworks were conducted on captured human whole-body motions. A human subject performing a seamless sequence of motion primitives was measured by an optical motion capture system. The positions of 34 markers attached to the subject were available, and an inverse kinematics computation converted these position data to a time series of 46-dimensional vectors. Each vector consists of 20 joint angles, vertical body position, roll, pitch angles, and their corresponding velocities  [28]. Thus, human whole-body motion was represented by 46-dimensional vectors. Short movementso(i)were defined to consist of five frames of the vector series. The short movements were encoded into feature HMMs. We set the type of the HMM to left-to-right, the number of nodes to three, and the number of HMMs to 50 (Nf=50). A feature vectorx(i)was created by aligning four 50-dimensional binary vectors, each element of which corresponds to a feature HMM. The resultant feature vectorx(i)was a 200-dimensional vector:x(i)=[xˆ(i−3)T,xˆ(i−2)T,xˆ(i−1)T,xˆ(i)T]T. The stabilizing and learning coefficients of the correlation matrix were set to 0.99 and 0.01 (α=0.99,η=0.01).In the first experiment, the human subject performed seven kinds of motion primitives: “left punch”, “bend”, “right kick”, “left punch”, “right punch”, “left punch” and “bend”. Four-minute human behavior was recorded where seven motion patterns were observed in random order. This recorded data was iteratively given to RUS and AUS as the training data, and they incrementally learned the boundaries of motion segments and subsequent motion primitives. Fig. 4shows a sequence of snapshots for subject movements, time stamps for the boundaries of the motion primitives detected by RUS, and profiles of two joint angles and their velocities from the captured human motion. As shown by Fig. 4, a seamless human motion is appropriately segmented into motion primitives, each of which can be given one of the labels “left punch”, “bend”, “right kick”, “left punch”, “right punch”, “left punch”, or “bend”. The profile of joint angular velocities shows that RUS does not segment the human behavior into motion primitives based on detection of a zero-velocity posture; that would have segmented the behavior into shorter motion primitives.We measured the computational times for several processes in RUS. A computer with a 3.6 GHz Xeon processor was used for these measurements. The average times for using inverse kinematics to convert captured human data into the 46-dimensional vector, derivation of the feature vectorx(i)after the inverse kinematics computation, and detection of the boundary from the feature vector were 7.3 (ms), 0.3 (ms), and 0.6 (ms), respectively. This result implies that RUS can be processed in real time since the sampling rate for motion capture was 30 (Hz). Additionally, the times required to train a feature HMM and to update a correlation matrix in the training phase were 6.3 (ms) and 0.8 (ms), respectively. These computational costs also validate RUS from a practical point of view.We evaluated the validity of RUS by conducting a cluster analysis of the derived motion primitives. A total of 333 motion primitives were identified by RUS. Each motion primitive was encoded into its corresponding HMM. This procedure resulted in 333 HMMs. It is difficult to measure distances among the motion primitives directly. However, distances among the HMMs could be measured by use of Kullback Leibler information.(13)D∗(λip,λjp)=1TGilnP(OGi|λip)−lnP(OGi|λjp),whereλkp(k=1,2,3,…,333)is the HMM for thekth motion primitive,OGkis the motion primitive generated by the HMMλkp, andTGkis the number of frames in the motion primitiveOGk. Kullback Leibler informationD∗(λip,λjp)is asymmetric, but symmetry is obtained by Eq. (14)(14)D(λip,λjp)=D∗(λip,λjp)+D∗(λjp,λip)2.Thus, the HMM-based distancesD(λip,λjp)replace the actual distances among the motion primitives. The motion primitives are located in a multidimensional space such that the distanced(xi,xj)between theith andjth motion primitives in the space are as close as possible to the HMM-based distanceD(λip,λjp)for each pairi,j. The distanced(xi,xj)is measured as the Euclidean distance between the two locationsxiandxjcorresponding to theith andjth motion primitives the space. A multidimensional scaling algorithm computes the locationxifor theith motion primitives such that it can minimizes the following error function.(15)E=1NC2∑i=1N∑j=i+1N(D(λip,λjp)2−d(xi,xj)2)24D(λip,λjp)2.Eq. (15) represents the error between the HMM-based distance and the Euclidean distance in the form of a four-dimensional polynomial; this expression makes it possible to compute the locationxiby the Newton–Raphson method.Fig. 5shows the relation between the number of dimensions of the space and the error given by Eq. (15). The relation reveals that the rate of change of the error,γ=Ed−Ed+1Ed, becomes zero in 4-dimensional space (Edis the distance error of thed-dimensional space). Therefore, we constructed a 4-dimensional space where the motion primitives were distributed. Fig. 6shows the constructed space: each point represents each motion primitive; the color and shape of the point signifies the categorization of the motion primitive. Each motion primitive is categorized according to motion symbols. The motion symbols are autonomously acquired, as described in the next section, and each motion primitive is categorized into the motion symbol with the largest likelihood of generating that motion primitive. The motion labels, such as “right kick”, “left kick”, “right punch”, “left punch”, “retract right leg”, “retract left leg”, and “bend”, are manually assigned to the motion symbols. The next section describes the automatic acquisition of the motion symbols in detail. Fig. 6 shows that motion primitives categorized into the same motion group are located close to each other and that motion primitives form a cluster structure of motion patterns.The validity of RUS followed by AUS was experimentally verified. A humanoid robot autonomously acquired motion symbols from motion primitives determined as in the previous subsection. We had 20 motion symbols whose parameters were initially set to random values. The competitive learning algorithm incrementally chose one HMM corresponding to a derived motion primitive and optimized the HMM from that motion primitive. In this incremental optimization phase, five HMMs were not optimized at all because these HMMs were not chosen as a motion symbol corresponding to a motion primitive. Therefore, these five HMMs were removed from the set of motion symbols. AUS caused the humanoid robot to acquire 15 motion symbols by using RUS.We have already constructed a space by locating 333 motion primitives in 4-dimensional space, as described in the previous section. The 15 acquired motion symbols were located in this space based on the distance between the two HMMs that represented the motion symbol and motion primitives. Fig. 7shows the constructed space by locating the motion symbols and the motion primitives in 4-dimensional space; this space is referred to as “motion symbol space”. A motion symbol is located within a cluster formed by motion primitives. This associates the HMM developed to a motion symbol that is representative of the motion primitives. The seven motion labels, such as “right kick”, “left kick”, “right punch”, “left punch”, “retract right leg”, “retract left leg”, and “bend” can be manually assigned to the motion symbols. Fifteen motion symbols were acquired. Note that the number of motion labels differs from the number of motion symbols. As shown in Fig. 7, a cluster corresponding to a motion label may include multiple motion symbols. For example, three motion symbols are located in one cluster for the motion label “bend”.We tested motion recognition based on the acquired motion symbols. Fig. 4 shows the experimental result, where seamless human behaviors are segmented into motion primitives and each motion primitive is identified by the motion symbol that has the largest likelihood of containing the motion primitive. Three obtained motion primitives of “left punch” were classified into the 10th motion symbol, and two obtained motion primitives of “bend” were classified into the 12th motion symbol. Similar motion primitives were classified into the same motion symbol.We also tested motion generation based on the acquired motion symbols. Fig. 8shows the motions generated by the motion symbols. We selected one motion symbol out of the several motion symbols included in a cluster corresponding to each motion label. The motions of “right kick”, “left kick”, “right punch”, “left punch”, “retract right leg”, “retract left leg”, and “bend” can be generated from these motion symbols. Fig. 9shows that a small humanoid robot can perform human-like whole-body motion according to the generated motions. This experiment validates the generation of a humanoid robot’s whole-body motion from the acquired motion symbols. Therefore, we can confirm that RUS can be used for AUS for a humanoid robot.A humanoid robot integrated into daily life is expected to memorize many motion symbols so that the robot can recognize and generate a large variety of motions. We tested RUS and AUS on a large motion dataset. We recorded motions performed by three subjects. The dataset consists of 2 h and 48 min of motion data. This motion data was repeatedly given to RUS and AUS in the same manner that in the previous section. We set the numbers of feature HMMs and motion symbols to 300 (Nf=300) and 50 (Ns=50), respectively.Fig. 12 shows the motion symbol space, where the motion symbols are located in a 6-dimensional space. In Fig. 12, the motion symbols are classified into six groups; figures on each row display only those motion symbols classified into the corresponding group. Additionally, Fig. 10shows the relation between the number of dimensions of the motion symbol space and the distance error, which is measured by the actual distances among the motion symbols and the distances among locations of the motion symbols in the space. The rate of change of the error (γ=Ed−Ed+1Ed) converges toγ=0.003in 6-dimensional space. Group 1 in Fig. 11shows  that the motion symbols to which the label “run” can be assigned (λ13andλ15) are located close to the motion symbol to which the label “walk” can be assigned (λ16). Group 4 shows that the motion symbols to which the label “swing a bat” can be assigned (λ11,λ14, andλ25) and the motion symbols to which the label “raise a hand” can be assigned (λ10,λ28,λ29, andλ41) are included in the same group. Group 5 includes motion symbols representing “sitting” (λ3,λ5, andλ7). Group 6 includes the motion symbols representing “stretching exercise” (λ4,λ36, andλ38). Motion symbols with the same label are located close to each other in the motion symbol space.The motion primitives determined by RUS are also located in the motion symbol space. The location occurs by conversion of the motion primitives to HMMs, and measurement of distances between the motion primitives and the motion symbols. Motion primitives that are recognized as the same motion symbol form clusters in the motion symbol space. The degree of separationS=σintraσinnercan be computed by inner-class varianceσinnerand inter-class varianceσintra. The large degree of separation implies that motion primitives identified as the same motion symbol are close to each other and that motion primitives identified as different motion symbols are located distantly from each other. The large degree of separation verifies that seamless human whole-body motion can be segmented to a sequence of motion primitives, which are frequently observed motion patterns.Fig. 13shows two degrees of separation for motion primitives determined by RUS, and for motion primitives determined by a random segmentation method. Note that the random segmentation method is designed such that the mean and variance of the length of the motion primitives derived by the random segmentation method is equal to the mean and variance of the lengths of the primitives determined by RUS. In this evaluation, we set the number of motion symbols to 10, 20, 30, 40, and 50, and then computed separation measures for each case. Fig. 13 demonstrates that the degree of separation for RUS is larger than that for random segmentation in all conditions.The performance of motion recognition and generation from motion symbols depends on the number of nodes in the HMMs for the motion symbols. The relationship between the likelihood of training motion data being generated by the corresponding HMM and the number of nodes is shown by Fig. 14. For this figure, “bend” motion  data, 300 frames captured at 100 (fps), was used. As the number of nodes increases, the likelihood becomes larger. The likelihood converges at five nodes. Based on this, we choose 10 as a sufficient number of nodes for each motion symbols.We tested the influence of the data sampling rate on the performance of RUS and AUS. We used an optical motion capture system with a sampling rate of 10 (ms) to measure a human subject performing the “bending” motion. The measured original data was down-sampled to motion data with sampling times of 20 (ms), 30 (ms),⋯, 300 (ms). The motion data were given to the corresponding HMMs as training data. We compared the original motion data with motion data generated by the HMMs. The comparison looks for correspondence between motion frames in the original motion data and in the generated motion data because the sampling rate of the original motion data is different from that of the HMMs. The HMMλχtraining motion data with sampling time ofχ(ms) generates motion data with the same sampling time; then, the expected time to stay on theith node,τiχ, can be calculated using the probability of transition from theith node to theith node,aiiχ, as follows:(16)τiχ=11−aiiχ.To adapt the HMMλχto motion data with a sampling time of 10 (ms), the transition probability for the expected time to stay on theith node,τiχ, is multiplied byχ10. The result of this is that the original motion data and the motion data generated by the modified HMM are of the same length. This makes it possible to calculate the correspondence between two frames of the original motion data and the generated motion data. Fig. 15 shows average errors between corresponding frames and sampling times. For sampling times in the range 10 (ms) to 300 (ms), the average error remains below 0.05 (rad). A sampling time of 50 (ms) has sufficient temporal resolution for human whole-body motions.The performance of RUS depends on the number of feature HMMs. We investigated the relationship between RUS performance and the number of the feature HMMs. We introduce two measures, “accuracy” and “completeness”, to quantify the performance; these are analogous to those Brent et al. adopted to segment English sentences  [25]. English sentences have clear boundaries for words, and it is easy to compare the detected boundaries with the correct boundaries. However, the boundaries of motion primitives in seamless human whole-body motion are unclear. A human subject was asked to identify the boundaries of the motion primitives, and detected boundaries within 1.0 (s) of these chosen boundaries are regarded as correctly detected. Comparison between the automatically detected boundaries and the manually identified boundaries yields the accuracy and completeness. For detection by RUS, True positive, false positive, and false negative are defined as a correctly detected boundary, an incorrectly detected boundary, and an undetected boundary, respectively. From the counts of the true positives (Ntp), false positives (Nfp), and false negatives (Nfn), the accuracy and completeness are defined as follows:(17)Zaccuracy=NtpNtp+Nfp(18)Zcompleteness=NtpNtp+Nfn.Fig. 16shows the accuracy and completeness for a 4 min motion capture. We set the number of the feature HMMs to10,20,…,110. Ten feature HMMs led to low completeness because the derived motion primitives are long. As the number of the feature HMMs was increased, completeness was improved. More than 20 HMMs resulted in a high accuracy, 90%, and good completeness, 70%.A feature vectorxis formed by aligningMpieces of binary-valued vectorsxˆ. The variableMrepresents the time constant of RUS. We conducted the experiment to determine the relationship between the size of the feature vector and the RUS. Fig. 17shows the size of the feature vector and the corresponding performance of RUS. We chose the degree of separation as the measure of performance. By incrementing the size of the feature vectors from two to ten and comparing RUS to random segmentation, we see that RUS provided motion primitives with a large degree of separation. Additionally, this experiment verified that RUS does not require a special tuning of the size of the feature vector.

@&#CONCLUSIONS@&#
