@&#MAIN-TITLE@&#
Stepwise calibration of focused plenoptic cameras

@&#HIGHLIGHTS@&#
A novel method for the calibration of focused plenoptic monocular cameras is proposed.In this way, the camera will deliver metric depth information instead of disparities.We detach the intrinsic camera parameters related to either brightness or depth data.We present novel initialization methods for all parameters.The accuracy is demonstrated on independent ground-truth validation data.

@&#KEYPHRASES@&#
Focused plenoptic camera,Light-field,Plenoptic 2.0,Metric calibration,

@&#ABSTRACT@&#
Monocular plenoptic cameras are slightly modified, off-the-shelf cameras that have novel capabilities as they allow for truly passive, high-resolution range sensing through a single camera lens. Commercial plenoptic cameras, however, are presently delivering range data in non-metric units, which is a barrier to novel applications e.g. in the realm of robotics. In this work we revisit the calibration of focused plenoptic cameras and bring forward a novel approach that leverages traditional methods for camera calibration in order to deskill the calibration procedure and to increase accuracy. First, we detach the estimation of parameters related to either brightness images or depth data. Second, we present novel initialization methods for the parameters of the thin lens camera model—the only information required for calibration is now the size of the pixel element and the geometry of the calibration plate. The accuracy of the calibration results corroborates our belief that monocular plenoptic imaging is a disruptive technology that is capable of conquering new markets as well as traditional imaging domains.

@&#INTRODUCTION@&#
A considerable number of machine vision users think that multi-view triangulation is required in order to retrieve accurate 3-D information using cameras without a priori information about the scene. This is predominantly accomplished either by passively taking images from different vantage points (stereo vision) or by actively projecting a known pattern from a separate location (Kinect). In other words, the notion that 3-D information is lost when light rays traverse the front lens of the camera is widespread. Experts know, however, that this is not the case as light rays are differently diffracted by a lens depending on the distance to the emitting object [1]. In fact, one of the potential outputs of monocular plenoptic cameras is range sensing.Plenoptic (also light-field) imaging is about measuring light in a higher dimensionality than in standard 2-D imaging. In fact, light transmission can be contemplated in a higher-dimensional space, the so-called plenoptic function [2]. Current plenoptic imaging samples the plenoptic function in 4-D , viz. 2-D projection position on the chip together with the direction of incoming light rays. The quest for this extra information is anything but new, but advances in parallel computation and modern workmanship of microlens arrays (MLAs) have recently made commercial products possible [3–5]. In a nutshell, monocular plenoptic cameras capture the 3-D image produced by the main lens within the camera by using an MLA in front of the sensor chip. By capturing the whole 3-D image, classical habits when using planar sensors like keeping the aperture size small in order to increase depth of field are lifted and more light can be gathered from the scene. Different camera designs open up new possibilities to trade off lateral precision against angular resolution of the reprojected ray directions. The original monocular plenoptic cameras focus the image on the MLA, achieving a limited spatial resolution at that particular depth equal to the number of valid microlenses. These microlenses produce defocused images that sample the ray direction at the position of the microlens. In 2009 Lumsdaine and Georgiev introduced the focused plenoptic camera (or plenoptic camera 2.0), which makes it possible to adapt this rather rigid trade-off between angular and spatial resolutions towards more spatial resolution [6]. This is performed by a modification of the focus distance to the main lens with the result that microlenses produce focused images that, on the other hand, more loosely sample ray direction.Many characteristics of plenoptic cameras are in conformity with the standard reference on disruptive technologies in Ref. [7]. For instance, plenoptic cameras initially produce a deficient standard output (fair images) at a higher cost, which makes them of no interest to the average consumer. They, however, clearly have the potential to improve and open up new markets while sharply reducing costs. Their current applications are offline refocusing and total focusing (i.e., increased depth of field) of 2-D images. More relevant potential applications are passive, 3-D video recording, 3-D modeling, range-based segmentation and tracking, industrial inspection (e.g. in narrow cavities), and imaging in challenging, low-light environments (e.g. underwater or in space). Most of these applications rely on the capability of plenoptic cameras to provide metric information of the scene in the form of 2.5-D depth images. This is, however, not yet commercially available as depth is currently being delivered in internal units related to image processing (disparities). We address the metric calibration of focused, monocular plenoptic cameras in order to transform their depth output into metric space.

@&#CONCLUSIONS@&#
