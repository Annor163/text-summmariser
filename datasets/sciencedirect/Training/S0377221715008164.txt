@&#MAIN-TITLE@&#
Optimal search for parameters in Monte Carlo simulation for derivative pricing

@&#HIGHLIGHTS@&#
We provide a general framework for searching parameter space in Monte Carlo simulation.We provide two online algorithms to search for suitable parameter values in simulation for pricing.This paper gives the competitive ratios of the two algorithms.We prove the optimality of the algorithms.Experimental results on the performance of the algorithms are presented and analyzed.

@&#KEYPHRASES@&#
Finance,Monte Carlo simulation,Deterministic online algorithm,Randomized online algorithm,Competitive ratio,

@&#ABSTRACT@&#
This paper provides a novel and general framework for the problem of searching parameter space in Monte Carlo simulations. We propose a deterministic online algorithm and a randomized online algorithm to search for suitable parameter values for derivative pricing which are needed to achieve desired precisions. We also give the competitive ratios of the two algorithms and prove the optimality of the algorithms. Experimental results on the performance of the algorithms are presented and analyzed as well.

@&#INTRODUCTION@&#
Derivatives, a main category of financial instruments, play essential roles in financial markets; thus it is important to price them efficiently and accurately. However, most complex derivatives are not known to have closed-form formulas for their prices; consequently, they are priced using numerical methods such as Monte Carlo simulation. Originated from studies in physics, Monte Carlo methods have been applied in finance (Boyle, 1977), many studies of which have focused on problems of pricing derivatives via Monte Carlo methods (e.g., Belomestny, Bender, & Schoenmakers, 2009; Kimura & Shinohara, 2006). For example, some papers focus on coping with financial derivatives with early exercise opportunities, such as American options and Bermuda options (e.g.,Bacinello, Biffis, Millossovich, 2009;Broadie and Detemple, 1996; Ibáñez, 2004; Kan, Reesor, Whitehead, and Davison, 2009; Liu, 2010; Longstaff and Schwartz, 2001; Rogers, 2002). Other studies concern methods for pricing derivatives under different assumptions for underlying assets, such as Lévy processes (e.g., Becker, 2010; Dingeç & Hörmann, 2012; Ribeiro & Webber, 2006) and Carr–Geman–Madan–Yor processes (e.g., Ballotta and Kyriakou, 2014).Standard Monte Carlo simulation has a simple bound ofO(1/N)for the standard error for N paths (Hull, 2009). However, when Monte Carlo simulation is combined with other approximation techniques or is used to price complicated financial instruments, analytical analysis of its convergence is difficult to obtain (e.g., Dingeç & Hörmann, 2012; Glasserman & Li, 2005; Kan et al., 2009; Liu, 2010; Longstaff & Schwartz, 2001; Miao & Lee, 2013). In addition, computing the standard error after sampling each additional path is not applicable for some approximation techniques, such as least-squared Monte Carlo (Liu, 2010; Longstaff & Schwartz, 2001), because each additional path necessitates recalculating the prices of all other paths. Aggravating the absence of analytical convergence in most simulation methods, there has been little research on general frameworks for searching for parameter values (e.g., the number of paths) in Monte Carlo simulation that are required to achieve desired precisions while minimizing running time or other computational resources.The problem of searching for an object in an unknown environment is central to many areas of computer science and operational research; many variants of search problems have been studied (e.g., Baeza-Yates, Culberson, & Rawlins, 1993; Chrobak, Kenyon, Noga, & Young, 2008; Kao, Reif, & Tate, 1993). Online algorithms are usually adopted to deal with the problem of searching in an unknown environment as they can process the sequence of requests piece-by-piece in a serial fashion without having the entire input available from the start. Competitive analysis was developed to analyze online algorithms; the competitive ratio of an online algorithm for an optimization problem is the worst-case ratio between the cost of the solution found by the online algorithm and the cost of an optimal solution.Viewing our problem as a problem of searching in an unknown environment, we provide a general framework for searching parameter space in Monte Carlo simulation, which is orthogonal to the previous studies in this field. Specifically, we propose two optimal online algorithms (one deterministic and one randomized) to search for suitable parameter values for derivative pricing which are needed to achieve desired precisions. We also conduct a competitive analysis of the proposed online algorithms and give the algorithm parameters that minimize the competitive ratios in order to yield the best performance; finally, the optimality of the algorithms are also proved. Furthermore, experimental results present the performance of the algorithms and show that the algorithms can be applied to the pricing of various kinds of options, i.e., vanilla call and put options, American options, and Bermudan options. The selected pricing methods and options in the experiments are for demonstration purposes; our proposed search algorithms can be applied to any effective simulation pricing method in a straightforward manner.This paper is organized as follows. In Section 2, some preliminaries for derivative pricing are introduced. In Section 3, we describe the proposed deterministic and randomized online algorithms and provide the competitive ratios and the proofs of their optimality. In Section 4, experimental results on the performance of the algorithms are presented and analyzed. In Section 5, we conclude the paper and provide some limitations of our work and future research directions.Derivatives are popular financial instruments, whose values depend on other more fundamental financial assets called the underlying assets. The most common underlying assets include stocks, bonds, commodities, and currencies; the most common types of derivatives are forwards, futures, options, and swaps. Hereafter, the underlying asset is assumed to be a stock and the derivative is assumed to be an option for simplicity of discussion.Vanilla options give their owners the rights to buy or sell the underlying stocks for the exercise price X and have no other unusual features. European-style vanilla options allow holders to exercise the options only at the maturity date T with the payoff(1)P(T)=max(θ·(ST−X),0),where STdenotes the stock price at time T,θ=1is for call options, andθ=−1is for put options.American options allow holders to exercise the options prior to the maturity date T. The value to exercise an American option at time t (0 ≤ t < T) isθ·(St−X). The holders exercise the options early if it is more beneficial than keeping them.Bermudan options are a hybrid of American and European options, where the buyer has the right to exercise at the date of expiration, and on certain specified dates that occur between the purchase date and the maturity date.A risk-neutral measure is heavily adopted in the pricing of financial derivatives due to the fundamental theorem of asset pricing (Schachermayer, 2009). This theorem implies that in a complete market, the price of a derivative is the discounted expected value of the future payoff under the unique risk-neutral measure. Particularly, a European-style option’s value at time 0 equals the discounted expected payoff at time T (Harrison & Pliska, 1981), i.e.,(2)e−rTE[P(T)],where r is the risk-free rate.In finance, the geometric Brownian motion is widely used to model the stock price process (e.g., Black & Scholes, 1973), which can be represented as the following differential form under the risk-neutral probability:(3)dSt=rStdt+σStdWt,where r is the risk-free rate, σ is the volatility of the stock prices, and the random variable dWtis the standard Brownian motion. Eq. (3) has the following solution (Shreve, 2004):(4)St=S0e(r−σ2/2)t+σWt.When Monte Carlo methods are used to price derivatives, risk-neutral valuation (Schachermayer, 2009) is usually adopted. Numerous paths are sampled to obtain the expected payoff in a risk-neutral world and then discount this payoff at the risk-free rate (see Eq. (2)). We now use the pricing of a European-style vanilla call option to demonstrate the standard procedure of Monte Carlo simulation. This option provides a payoff at time T as in Eq. (1) withθ=1. Assuming the stock price follows the geometric Brownian motion in Eq. (4), the option can be priced via the following steps:1.Sample a normal random variable WT∼ N(0, T) and plug it into Eq. (4) to obtain ST.Calculate the payoffmax(ST−X,0)from the option.Repeat steps 1 and 2 for d paths to obtain d sample values of the payoff from the option.Calculate the mean of the sample payoffs to obtain an unbiased estimate of the expected payoff in a risk-neutral world.Discount the expected payoff at the risk-free rate to obtain an estimate of the option price.The precision of the above estimated price in general depends on the number of paths; it is usually measured by the standard error of the estimate (i.e., the standard deviation of the sample means’ estimates of a population mean). The standard Monte Carlo simulation has a simple bound ofO(1/N)for the standard error for N paths. However, when Monte Carlo simulation is combined with other approximation techniques or is used to price complicated financial instruments, analytical analysis of its convergence is difficult to obtain. Even so, for an effective simulation method, in general, the standard error should be a decreasing function of the number of paths (see Fig. 1).This section first formulates the problem in Monte Carlo simulation of finding the parameter value that yields a desired precision. For simplicity of discussion, the parameter hereafter is assumed to be the most common one: the number of paths. Algorithms for different parameters share the same methodology as long as the precision measure is a decreasing function of the parameter.Given a desired precision goal, the search problemPis defined as follows: find the least number of paths required to achieve the given precision. We call this number thegoaland denote it as N hereafter. In the following discussion, we provide an optimal deterministic online algorithm and an optimal randomized online algorithm for the problem.This section describes the proposed deterministic online algorithmDAfor search problemP. It is a deterministic geometric sweep algorithm with geometric ratio r ≥ 2, and is modified from the work of Baeza-Yates et al. (1993).Fig. 2 shows an outline of AlgorithmDA,in which each iteration first runs the simulation with d paths, tests whether the desired precision has been achieved, and then updates the number of paths d with the multiplier r. The algorithm ends when thegoalis achieved.We proceed to present the competitive ratio of AlgorithmDAwith its proof.Theorem 3.1For any fixed r ≥ 2, AlgorithmDAhas the worst-case competitive ratio(5)r2r−1.For a givengoal(N∈N+), let kbe an integer, and let δ be a real number satisfying 0 ≤ δ < 1, where k and δ are such thatN=rk+δ. The worst-case competitive ratio with thegoalN=⌊rk⌋+1for AlgorithmDAismaxk≥1{∑i=0k+1⌊ri⌋⌊rk⌋+1}≤maxk≥1{∑i=0k+1rirk}=maxk≥1{rk+2−1(r−1)rk}=maxk≥1{r2−1rkr−1}.Above, the numerator of the competitive ratio is the total number of paths that AlgorithmDAhas tried and the denominator isgoal(N), the least number of paths required to achieve the precision, in the worst-case scenario. Obviously, for any fixed r, k → ∞ yields the maximum for the above ratio; thus the worst-case competitive ratio for AlgorithmDAislimk→∞r2−1rkr−1=r2r−1.□Recall from Theorem 3.1 that AlgorithmDAis a class of algorithms indexed by the parameter r. In order to obtain the best performance possible, we seek a value of r that minimizes Eq. (5).Corollary 3.2The unique solution of the equationr2−2r=0for r > 1 isr*=2,which minimizes Eq.(5).To minimize Eq. (5), we first definef(r)=r2/(1−r),which is a continuous function. We find the minimum by taking the derivative:f′(r)=r2−2r(1−r)2.The unique solution forf′(r)=0isr=2.□In this subsection, we prove the optimality of AlgorithmDAby showing that it achieves a lower bound for the worst-case competitive ratio for any deterministic algorithm.Lemma 3.3The worst-case competitive ratio for any deterministic algorithm is at least 4.Any deterministic algorithm can be defined by a sequences0,s1,…,sk,…,where skis the number of paths tried at stage k. Let thegoalbe reached at stage i. Then the worst-case competitive ratio ismaxi≥0(∑j=0isjsi−1+1).The above term is lower bounded by 4, which is proved in Baeza-Yates et al. (1993).□Since the lower bound in Lemma3.3is achieved by AlgorithmDAwithr=2,AlgorithmDAwithr=2is optimal.According to Theorem 3.1, the competitive ratio of AlgorithmDAwithr=2is equal to 4. Combining this and Lemma 3.3, the claim is proved.□We now proceed with the proposed randomized online algorithmRAfor problemP(see Fig. 3). AlgorithmRA, modified from the SmartCow algorithm of Kao et al. (1993), is a randomized geometric sweep algorithm with geometric ratio r > 1. This algorithm is similar to the deterministic algorithmDAexcept that the initial number of paths is randomly generated with a random real θ uniformly chosen from [0, 1).The following theorem proves the competitive ratio of AlgorithmRA.Theorem 3.5For any fixed r > 1, AlgorithmRAhas competitive ratio(6)rlnr.Recall that the givengoalis set toN=rk+δ∈N+,where k is an integer and δ is a real value satisfying 0 ≤ δ < 1.As shown in AlgorithmRA, the number of paths tried at stagei∈{0,1,2,⋯}is⌊ri+θ⌋,where θ is uniformly distributed between 0 and 1. Let m be the first stage where rm≥ rk; clearly,m=k. Let Dbe a random variable that denotes the sum of the number of paths at each stage. Since AlgorithmRAmay or may not achieve the desired precision at stagem(=k),depending on whether or not⌊rm+θ⌋≥rk+δ,we denote F as the event that AlgorithmRAreaches thegoalat stage m. Additionally, becauserk+δ∈N+,F is equivalent to the event thatrm+θ≥rk+δ. ThenE[D]=Prob(F)×E[∑i=0k⌊ri+θ⌋|F]+Prob(F¯)E[∑i=0k+1⌊ri+θ⌋|F¯]≤Prob(F)×E[∑i=0kri+θ|F]+Prob(F¯)E[∑i=0k+1ri+θ|F¯]=Prob(F)×rk+1−1r−1×E[rθ|F]+Prob(F¯)×rk+2−1r−1×E[rθ|F¯]=Prob(F)×rk+1−1r−1×r−rδProb(F)lnr+Prob(F¯)×rk+2−1r−1×rδ−1Prob(F¯)lnr=1(r−1)lnr[(rk+1−1)(r−rδ)+(rk+2−1)(rδ−1)]=1(r−1)lnr(rk+2+δ−rk+1+δ−r+1)=1(r−1)lnr(rk+δ(r2−r)−(r−1))=1lnr(Nr−1)≤(rlnr)N.The competitive ratio is simply the expected sum E[D] divided by N:rlnr,which is exactly the ratio claimed in the theorem.□According to Theorem 3.5, AlgorithmRAhas competitive ratiorlnr,where r is an algorithm parameter. Similar to the deterministic online algorithm in Section 3.1, we seek a value of r that minimizes Eq. (6) to obtain the best performance possible.Corollary 3.6The unique solution of the equation−1(lnr)2+1lnr=0for r > 1 isr*=e,which minimizes Eq.(6).To minimize Eq. (6), we first definef(r)=r/lnr; f(r) is a continuous function. We find the minimum by taking the derivative:f′(r)=ln(r)−1(lnr)2.The unique solution forf′(r)=0isr=e.□This subsection proves the optimality of AlgorithmRAby showing that it achieves a lower bound for the worst-case competitive ratio for any randomized algorithm. To prove the lower bound for randomized algorithms, we use Yao’s corollary of the von Neumann minimax principal (Yao, 1977). Particularly, we will define a probability distribution for inputs to the problemP, and then lower bound the performance of any deterministic algorithm given this input distribution. Here we adopt the family of probability distribution functions suggested in Kao et al. (1993) and denote a particular distribution function by fϵ. The density function used in Kao et al. (1993) isfϵ(x)={ϵx−(1+ϵ)ifx≥1,0,otherwise.In addition, we use OptD(ϵ) to denote the optimal competitive ratio of any deterministic algorithm with the input distribution fϵ and OptR to denote the optimal competitive ratio for any randomized algorithm. According to Lemma 4.1 in Kao et al. (1993), our goal is to show thatℓ=limϵ→0OptD(ϵ)exists, and find a value for this limit; thus we can say that OptR ≥ ℓ.Any deterministic algorithm can be defined by a sequences0,s1,…,sk,…,where skis the number of paths tried at stage k. Here we assumes0=1for convenience. Using this notation, we prove the following lemma.Lemma 3.7Let algorithmXbe a deterministic algorithm defined by the sequences0,s1,…,sk,….For input distribution fϵ, the expected competitive ratio ofXisϵ1+ϵ(1+∑i=0∞si+1si(1+ϵ)).The goal can be specified by defining a variable Q which is distributed according to fϵ and represents the least number of paths that achieves the desired precision. We also define Boolean conditions Cifori=0,1,2,⋯,where Ciis true when algorithmXachieves thegoalat stage i. Formally,Ciistrueifandonlyif{1≤Q≤s0,wheni=0,si−1<Q≤si,wheni≥1.Moreover, if R is a random variable that denotes the competitive ratio achieved by algorithmX, then(7)E[R]=∑i=0∞piE[R|Ci],wherepi=Prob(Ci). When computing the expected value E[R|Ci], there are two cases:i=0and i ≥ 1. Fori=0,it is obvious thatQ=1by the definition for Ci; thusE[R|Ci]=1. For i≥ 1, the total number of paths tried by the algorithm is∑j=0isj.So the expected competitive ratio under i ≥ 1 is given by(8)E[R|Ci]=E[∑j=0isjQ|Ci]=E[1Q|Ci]∑j=0isj.From Kao et al. (1993), we have(9)E[1Q|Ci]=ϵpi(1+ϵ)(si−1−(1+ϵ)−si−(1+ϵ)).Combining Eq. (9) with Eq. (8) yields E[R|Ci] under i ≥ 1. By Eq. (7), we have(10)E[R]=p0×1+∑i=1∞piE[R|Ci]=p0+ϵ1+ϵ∑i=1∞[(si−1−(1+ϵ)−si−(1+ϵ))∑j=0isj]=p0+ϵ1+ϵ·[∑i=1∞(si−1−(1+ϵ)∑j=0isj)−∑i=1∞(si−(1+ϵ)∑j=0isj)]=p0+ϵ1+ϵ·[∑i=0∞(si−(1+ϵ)∑j=0i+1sj)−∑i=0∞(si−(1+ϵ)∑j=0isj)+1]=ϵ1+ϵ[1+∑i=0∞(si+1si(1+ϵ))].Equality (10) holds sincep0=0because of the continuity of fϵ.□We now show that AlgorithmRAis optimal.Theorem 3.8The optimal competitive ratio for any randomized algorithm is given byminr>1{rlnr}.Since this ratio is achieved by AlgorithmRA, AlgorithmRAis optimal.Assume that the sequences0,s1,…,sk,…defines the optimal deterministic algorithm for a fixed ϵ, and let OptD(ϵ) denote the competitive ratio given in Lemma 3.7.For a fixed ϵ, to lower bound OptD(ϵ), we need only find a lower bound for(11)R(ϵ)=∑i=0∞si+1si(1+ϵ)=s1+∑i=1∞si+1si(1+ϵ).Recall thats0=1is fixed. By settingti=si+1si,we obtain a new sequence witht0=1. Eq. (11)can be rewritten in terms of this new sequence ass1+s1−ϵ∑i=0∞ti+1ti(1+ϵ).This is easily bounded by(12)R(ϵ)=s1+s1−ϵ∑i=0∞ti+1ti(1+ϵ)≥s1+s1−ϵR(ϵ).From Inequality (12), we haveR(ϵ)≥s11−s1−ϵ,henceOptD(ϵ)≥ϵ1+ϵ(1+s11−s1−ϵ).By settingsi=s1iand recalling Lemma 3.7, the geometric algorithm has exactly the competitive ratio stated as a lower bound above. So for fixed ϵ, we haveOptD(ϵ)=minr>1{ϵ1+ϵ(1+r1−r−ϵ)}.We know that OptR ≥ limϵ → 0OptD(ϵ), so we can bound OptR by(13)OptR≥limϵ→∞minr>1{ϵ1+ϵ(1+r1−r−ϵ)}=minr>1limϵ→∞{ϵ1+ϵ(1+r1−r−ϵ)}=minr>1{rlnr}.Eq. (13) is exactly the bound claimed in this theorem.□

@&#CONCLUSIONS@&#
This paper brings a novel and orthogonal dimension to Monte Carlo simulation methods for derivatives pricing. We provide two general and optimal online algorithms—one deterministic and one randomized—to search for the desired parameter values in Monte Carlo simulation for derivative pricing. Our experiments on various types of options and algorithms show that the proposed approach efficiently and effectively determines a suitable number of paths for pricing these options with Monte Carlo simulation within a desired precision. Furthermore, the proposed search algorithms can be applied to any effective simulation pricing method in a straightforward manner.For future work, note that the proposed search algorithms can be applied to “effective” simulation methods only, i.e., the standard error must be a decreasing function of the searched parameter values. It would be of interest to develop search algorithms applicable without this constraint. Also, the space of only one parameter can be searched by our proposed algorithms. Therefore, it is important to develop search algorithms that can search the space of multiple parameters, since for some financial applications, there is more than one parameter related to the precision of results using Monte Carlo methods, including for instance the pricing of barrier options (e.g. Bernis, Gobet, & Kohatsu-Higa, 2003).