@&#MAIN-TITLE@&#
Horn clause verification with convex polyhedral abstraction and tree automata-based refinement

@&#HIGHLIGHTS@&#
We construct a correspondence between Horn clauses and finite tree automata (FTA).We construct a refined clauses from an FTA of the clauses and an infeasible trace.We propose a splitting operator on FTAs and describe its role in verification.We demonstrate the feasibility of our approach in practice.

@&#KEYPHRASES@&#
Horn clauses,Abstract interpretation,Finite tree automata,Tree automata determinisation,

@&#ABSTRACT@&#
In this paper we apply tree-automata techniques to refinement of abstract interpretation in Horn clause verification. We go beyond previous work on refining trace abstractions; firstly we handle tree automata rather than string automata and thereby can capture traces in any Horn clause derivations rather than just transition systems; secondly, we show how algorithms manipulating tree automata interact with abstract interpretations, establishing progress in refinement and generating refined clauses that eliminate causes of imprecision. We show how to derive a refined set of Horn clauses in which given infeasible traces have been eliminated, using a recent optimised algorithm for tree automata determinisation. We also show how we can introduce disjunctive abstractions selectively by splitting states in the tree automaton. The approach is independent of the abstract domain and constraint theory underlying the Horn clauses. Experiments using linear constraint problems and the abstract domain of convex polyhedra show that the refinement technique is practical and that iteration of abstract interpretation with tree automata-based refinement solves many challenging Horn clause verification problems. We compare the results with other state-of-the-art Horn clause verification tools.

@&#INTRODUCTION@&#
The formalism of Constrained Horn clauses (CHCs), as an intermediate language for verification of programs in various languages, has become popular due to its well understood properties and expressiveness; this has led to a range of tools for analysis and verification of CHCs. Given a program and a property ϕ to be verified, a set of CHCs V, such that V is satisfiable if and only if ϕ holds, is called a verification condition for ϕ. CHC verification conditions can be obtained from imperative, functional or concurrent languages, among others, by a variety of semantics-based techniques including big- and small-step semantics, Hoare triples, or other intermediate forms such as control-flow graphs [1–6]. We do not consider the process of generating CHC verification conditions in this paper.There are several approaches to checking the satisfiability of CHC verification conditions, including abstract interpretation and counterexample-guided abstraction refinement (see Section 7). In this paper we apply tree-automata techniques to refinement of abstract interpretation in Horn clause verification. We go beyond previous work on refining trace abstractions [7]; firstly, we handle tree automata rather than word automata and thereby can capture traces in any Horn clause derivations rather than just transition systems; secondly, we show how algorithms manipulating tree automata interact with abstract interpretations, establishing progress in refinement and generating refined clauses that eliminate causes of imprecision.Our approach is similar in spirit to counterexample-guided abstraction refinement (CEGAR) or iterative specialisation approaches, in which a refined set of clauses is generated by eliminating one or more of the infeasible paths from the original set of clauses until the safety or unsafety of the clauses is proven. More specifically, we show how to construct tree automata capturing both the traces (derivations) of a given set of Horn clauses and also one or more infeasible traces discovered after abstract interpretation of the clauses. From these we construct a refined automaton in which the infeasible trace(s) have been eliminated and a new set of clauses is constructed from the refined automaton. This guarantees progress in that the same infeasible trace cannot be generated (in any abstract interpretation). In addition, the clauses are restructured during the elimination of the trace, which can lead to more precise abstractions in subsequent iterations. The refinement is manifested in the refined clauses, rather than in an accumulated set of properties as in the CEGAR [8] approach. We rely on the abstract interpretation of the clauses to generate useful properties, rather than hoping to find them during the refinement itself.We also show how we can introduce disjunctive abstractions selectively by splitting states in the tree automaton. This splitting induces splitting in the predicates of the original set of clauses and its analysis using convex polyhedra leads to disjunctive abstractions. The approach is independent of the abstract domain and constraint theory underlying the Horn clauses. Experiments using linear constraint problems and the abstract domain of convex polyhedra show that the refinement technique is practical and that iteration of abstract interpretation with tree automata-based refinement solves many challenging Horn clause verification problems. We compare the results with other state-of-the-art Horn clause verification tools.The main contributions of this paper are the following: (1) we construct a correspondence between computations using Horn clauses and finite tree automata (FTA) (Section 4). (2) We construct a refined set of clauses directly from a tree automaton representation of the clauses and an infeasible trace; the trace is eliminated from the refined clauses (Section 4.4). (3) We propose a “splitting” operator on FTAs (Section 3) and describe its role in Horn clause verification (Section 5.1). (4) We demonstrate the feasibility of our approach in practice applying it to Horn clause verification problems (Section 6).This paper is an extended version of [9]. The paper has been extended in the following directions: (1) the proofs of all propositions have been provided; (2) further information about the implementation of our tool chain is given (see Section 6); (3) further experiments comparing our results with the state-of-the-art verification tools in the literature are provided (see Sections 4.5.1 and 4.5.2); (4) further experimental results on some additional benchmarks from the software verification competition 2015 have been provided (see Section 1).To motivate readers, we present an example set of CHCs P in Fig. 1which will be used throughout this paper. This is an interesting problem in which the computations are trees rather than linear sequences.After applying abstract interpretation to this set of clauses, we obtain the following set of constrained facts (also called approximation):Sincefalseis in our approximation, our tool generates an abstract derivation forfalsewhich in our case is the clause c3 followed by the clause c1 and is represented by a trace term c3(c1). Since this abstract counterexample is infeasible, our refinement procedure removes this from the set of clauses in Fig. 1 to produce a new set of clauses as shown in Fig. 2. Our refinement can be viewed as a program transformation guided by a counterexample. From the set of refined clauses, it can be seen that the counterexample c3(c1) is impossible to construct. This refinement split the predicate mc91 of the original clauses and as a result of this we gain some precision. We again analyse the refined clauses using abstract interpretation until its safety or unsafety is proven. In the sections to follow we describe our abstraction-refinement procedure which led to this result in detail.The architecture of our abstraction-refinement scheme is shown in Fig. 3. It is accompanied by our main Algorithm 1 to give the early picture of our approach.Algorithm 1Algorithm for abstraction-refinement of Horn clauses.Input: A set of Horn clauses POutput: safe or unsafe1. analyse P using abstract interpretation producing constrained facts M (Algorithm 3);2. iffalse∉Mthen returnsafe ;3. iffalse∈Mthen produce derivation t offalseusing P ;4. if t is feasible returnunsafe ;5.P′←refinedCls(P,t)(Algorithm 4) ;9.P←P′and goto step 1 ;Finite tree automata (FTAs) are mathematical machines that define so-called recognisable tree languages, which are possibly infinite sets of terms that have desirable properties such as closure under Boolean set operations and decidability of membership and emptiness.Definition 1Finite tree automatonAn FTAAis a tuple(Q,Qf,Σ,Δ), where Q is a finite set of states,Qf⊆Qis a set of final states,Σis a set of function symbols, andΔis a set of transitions. We assume that Q andΣare disjoint.Each function symbolf∈Σhas an arityn≥0, written asar(f)=n. The function symbols with arity 0 are called constants.Term(Σ)is the set of ground terms or trees constructed fromΣwheret∈Term(Σ)ifft∈Σis a constant ort=f(t1,t2,…,tn)wherear(f)=nandt1,t2,…,tn∈Term(Σ). SimilarlyTerm(Σ∪Q)is the set of terms/trees constructed fromΣand Q, treating the elements of Q as constants.Each transition inΔis of the formf(q1,q2,…,qn)→qwherear(f)=n. Givenδ∈Δwe refer to its left- and right-hand-sides aslhs(δ)andrhs(δ)respectively. Let⇒be a one-step rewrite in whicht1⇒t2iff t2 is the result of replacing one subterm of t1 equal tolhs(δ)byrhs(δ), from someδ∈Δ. The reflexive, transitive closure of⇒is⇒⁎. We say there is a run (resp. successful run) fort∈Term(Σ)ift⇒⁎qwhereq∈Q(resp.q∈Qf), and we say that t is accepted if t has a successful run. An FTAAdefines a set of terms, that is, a tree language, denoted byL(A), as the set of all terms accepted byA.Definition 2Deterministic FTA (DFTA)An FTA(Q,Qf,Σ,Δ)is called bottom-up deterministic iffΔhas no two transitions with the same left hand side.We omit the adjective “bottom-up” in this paper and just refer to deterministic FTAs. Runs of a DFTA are deterministic in the sense that for everyt∈Term(Σ)there is at most oneq∈Qsuch thatt⇒⁎q.FTAs are closed under Boolean set operations, but for our purposes we mention only union and difference of language of automata, where in addition we assume that the signatureΣis fixed and that the states of FTAs are disjoint from each other when applying operations (the states can be renamed apart).Definition 3Union of FTAsLetA1,A2be FTAs(Q1,Qf1,Σ,Δ1)and(Q2,Qf2,Σ,Δ2)respectively. ThenA1∪A2=(Q1∪Q2,Qf1∪Qf2,Σ,Δ1∪Δ2), and we haveL(A1∪A2)=L(A1)∪L(A2).Determinisation plays a key role in the theory of FTAs. As far as expressiveness is concerned, we can limit our attention to DFTAs since for every FTAAthere exists a DFTAAdsuch thatL(A)=L(Ad)[10]. The standard construction builds a DFTAAdwhose states are elements of the powerset of the states ofA. The textbook procedure for constructingAdfromA[10] is not viewed as a practical procedure for manipulating tree automata, even fairly small ones. In a recent work Gallagher et al. [11] developed an optimised algorithm for determinisation, whose worst-case complexity remains unchanged, but which performs dramatically better than existing algorithms in practice. A critical aspect of the algorithm is that the transitions of the determinised automaton are generated in a potentially very compact form called product form, which can often be used directly when manipulating the determinised automaton.Definition 4Product transitionA product transition is of the formf(Q1,…,Qn)→qwhere Qiare sets of states and q is a state. The product transition represents a set of transitions{f(q1,…,qn)→q∣qi∈Qi,i=1..n}. ThusΠi=1n|Qi|transitions are represented by a single product transition.Alternatively, we can regard a product transition as introducing ϵ-transitions. An ϵ-transition has the formq1→q2whereq1,q2are states. ϵ-Transitions can be eliminated, if desired. Given a product transitionf(Q1,…,Qn)→q, introduce n new non-final statess1,…,sncorresponding toQ1,…,Qnrespectively and replace the product transition by the set of transitions{f(s1,…,sn)→q}∪{q′→si∣q′∈Qi,1=1..n}. It can be shown that this transformation preserves the language of the FTA.Given FTAsA1andA2there exists an FTAA1⧹A2such thatL(A1⧹A2)=L(A1)⧹L(A2). To construct the difference FTA we use union and determinisation and exploit the following property of determinised states [11].Property 1LetAdbe the DFTA constructed fromA. Let Q be the states ofA. Then there is a runt⇒⁎qinAif and only if there is a runt⇒⁎Q′inAdwhereQ′∈2Q, such thatq∈Q′.Furthermore recall that a term is accepted by at most one state in a DFTA. This gives rise to the following construction of the difference FTAA1⧹A2. We first form the DFTA for the union of the two FTAs and then remove those of its final states containing the final states ofA2. In this way we remove the terms, and only the terms (by Property 1), accepted byA2. The availability of a practical algorithm for determinisation is what makes this construction of the difference FTA feasible.Definition 5Construction of difference of FTAsLetA1,A2be FTAs(Q1,Qf1,Σ,Δ1)and(Q2,Qf2,Σ,Δ2)respectively. Let(Q′,Qf′,Σ,Δ′)be the determinisation ofA1∪A2. LetQ2={Q′∈Q′∣Q′∩Qf2≠∅}. ThenA1⧹A2=(Q′,Qf′⧹Q2,Σ,Δ′).Next we introduce a new operation over FTA called state splitting, which consists of splitting a state q into a number of states, based on a partition of the set of transitions whoserhsis q. We define this splitting as follows:Definition 6Splitting a state in an FTALetA=(Q,Qf,Σ,Δ)be an FTA. Letq∈QandΔq={t∈Δ∣rhs(t)=q}. LetΦ={Δq1,…,Δqk}(k>1) be some partition ofΔq. Introduce k new statesq1,…,qk. Then the FTAsplitΦ(A)is(Qs,Qfs,Σ,Δs)where:•Qs=Q⧹{q}∪{q1,…,qk};Qfs=Qf⧹{q}∪{q1,…,qk}ifq∈Qf, otherwiseQfs=Qf;Δs=unfoldq(Δ⧹Δq∪{lhs(t)→qi∣t∈Δqi,i=1..k}), whereunfoldq(Δ′)is the result of repeatedly replacing a transitionf(…,q,…)→s∈Δ′by the set of k transitions{f(…,q1,…)→s,…,f(…,qk,…)→s}until no more such replacements can be made.L(A)=L(splitΦ(A)).LetA=〈Q,Qf,Σ,Δ〉andsplitΦ(A)=〈Qs,Qfs,Σ,Δs〉. Letsplit(q)mean that the state q is split and letq1,…,qkbe the new states introduced during splitting. We write⇒⁎for derivations inAand⇒s⁎for derivations insplitΦ(A). We first prove by induction on the depth of terms that for all terms t and statesq∈Q,(1)(split(q)→(t⇒⁎q≡∃i.(t⇒s⁎qi)))∧(¬split(q)→(t⇒⁎q≡t⇒s⁎q)).Base case: Let a be a term of depth 1split(q)→a⇒⁎q≡a→q∈Δ∧∃i.(q∈Δqi∧a→qi∈Δs)followingDefinition6≡∃i.(a⇒s⁎qi)¬split(q)→a⇒⁎q≡a→q∈Δ∧a→q∈Δs≡a⇒s⁎q)Inductive case: Letf(t1,…,tn)⇒qwheref(t1,…,tn)is a term of depthk+1and assume that the property holds for all terms with depth at most ksplit(q)→f(t1,…,tn)⇒⁎q≡∃r1,…,rn.(f(r1,…,rn)→q∈Δ∧t1⇒⁎r1∧⋯∧tn⇒⁎rn)∧(split(r1)∨¬split(r1))∧⋯∧(split(rn)∨¬split(rn))≡∃r1,…,rn.[f(r1,…,rn)→q∈Δ∧(split(r1)∧∃i1(t1⇒s⁎r1,i1))∨(¬split(r1)∧t1⇒s⁎r1)∧⋯(split(rn)∧∃in(tn⇒s⁎rn,in))∨(¬split(rn)∧tn⇒s⁎rn))]byinductivehypothesisafterrearrangingformula,sincet1,…,tnhavedepthatmostk≡∃r1,…,rn∃i1,…,in.[f(r1,…,rn)→q∈Δ∧((t1⇒s⁎r1,i1∨t1⇒s⁎r1)∧⋯∧(tn⇒s⁎rn,in∨tn⇒s⁎rn))]afterrearrangingformula,movingquantifiersoutwardsandeliminatingsplit(ri)∨¬split(ri),1≤i≤n≡∃i,r1,…,rn∃i1,…,in.[f(r1,i1,…,rn,in)→qi∈Δs∧((t1⇒s⁎r1,i1∨(r1,i1=r1∧t1⇒s⁎r1))∧⋯∧(tn⇒s⁎rn,in∨(rn,in=rn∧tn⇒s⁎rn)))]applyingDefinition6tointroducef(r1,i1,…,rn,in)→qisincef(r1,i1,…,rn,in)→qiisincludedafterapplyingunfoldtof(r1,…,rn)→qi≡∃i.f(t1,…,tn)⇒s⁎qi¬split(q)→f(t1,…,tn)⇒⁎q≡[Similartopreviouscasebutwheref(r1,i1,…,rn,in)→qisintheunfoldingoff(r1,…,rn)→qinDefinition6]≡f(t1,…,tn)⇒s⁎qFinally, ifq∈Qfandsplit(q)thenqi∈Qfswhere qiis a new state introduced during the splitting. It follows from this and property (1) that for all t,∃q∈Qf.t⇒⁎q≡∃q′∈Qfs.t⇒s⁎q′. Thus for all t,t∈L(A)ifft∈L(splitΦ(A)).□A constrained Horn clause (CHC) is a first order predicate logic formula of the form∀(ϕ∧p1(X1)∧…∧pk(Xk)→p(X))(k≥0), where ϕ is a conjunction of constraints with respect to some constraint theory, Xi,Xare (possibly empty) vectors of distinct variables,p1,…,pk,pare predicate symbols, p(X) is the head of the clause andϕ∧p1(X1)∧…∧pk(Xk)is the body.There is a distinguished predicate symbolfalsewhich is interpreted as false. In practice the predicatefalseonly occurs in the head of clauses; we call clauses whose head isfalseintegrity constraints, following the terminology of deductive databases. They are also sometimes referred to as negative clauses. We follow the syntactic conventions of constraint logic programs and write a clause asp(X)←ϕ,p1(X1),…,pk(Xk).An interpretation of a set of CHCs is represented as a set of constrained facts of the formA←ϕwhere A is an atomic formulap(Z1,…,Zn)whereZ1,…,Znare distinct variables and ϕ is a constraint overZ1,…,Zn. This set may be infinite. The constrained factA←ϕis shorthand for the set of variable-free factsAθsuch thatϕθholds in the constraint theory, and an interpretation M denotes the set of all facts denoted by its elements; M assigns true to exactly those facts.M1⊆M2if the set of denoted facts of M1 is contained in the set of denoted facts of M2.Minimal models: A model of a set of CHCs is an interpretation that satisfies (whenever the body of a clause holds under the given interpretation then so does the head) each clause. There exists a minimal model with respect to the subset ordering, denotedM〚P〛where P is a satisfiable set of CHCs.M〚P〛can be computed as the least fixed point (lfp) of an immediate consequences operator (calledSPDin [12, Section 4]), which is an extension of the standard TPoperator from logic programming, extended to handle the constraint theory D. Furthermorelfp(SPD)can be computed as the limit of the ascending sequence of interpretations∅,SPD(∅),SPD(SPD(∅)),…. This sequence provides a basis for abstract interpretation of CHC clauses. The minimal model of P is equivalent to the set of atomic logic consequences of P.Given a set of CHCs P, the CHC verification problem is to check whether there exists a model of P. Obviously any model of P assigns false to the bodies of integrity constraints. We restate this property in terms of the derivability of the predicatefalse. LetP⊨Fmean that F is a logical consequence of P, that is, that every interpretation satisfying P also satisfies F.Lemma 1P has a model if and only ifP⊭false.Writing I(F) to mean that interpretation I satisfies F, we have:P⊭false≡thereexistsaninterpretationIsuchthatI(P)and¬I(false)bydefinitionof⊨≡thereexistsaninterpretationIsuchthatI(P)(since¬I(false)istruebydefn.offalse)≡Phasamodel.□This lemma holds for arbitrary interpretations (only assuming that the predicatefalseis interpreted as false), uses only the textbook definitions of “interpretation” and “model” and does not depend on the constraint theory. We have yet another equivalent formulation of the CHC verification problem.Lemma 2P has a model if and only iffalse∉M〚P〛.Follows from the equivalence of the minimal model of P with the set of atomic logical consequences of P[13]. See also Proposition 2 later.□It is this formulation that is most relevant to our method, since we compute over-approximations ofM〚P〛by abstract interpretation. That is, iffalse∉M′whereM〚P〛⊆M′then we have shown that P has a model. An assertion ϕ is an invariant (over-approximation) for a predicate q in P, ifP⊨∀(q→ϕ). If a set of Horn clauses P have a model then we say that P is safe, otherwise we say that P is unsafe.Before constructing the trace automaton we introduce identifiers for each clause. An identifier is a function symbol whose arity is the same as the number of atoms in the clause body. For instance a clausep(X)←ϕ,p1(X1),…,pk(Xk)is assigned a function symbol with arity k. More than one clause can be assigned the same function symbol, but all the clauses with the same identifier have the same structure, including their constraints; that is, they differ only in one or more predicate names. Given a set of CHCs and a setΣof ranked function symbols, letidP:P→Σbe the assignment of function symbols to clauses.Definition 7Trace FTA for a set of CHCsLet P be a set of CHCs. Define the trace FTA for P asAP=(Q,Qf,Σ,Δ)where•Q is the set of predicate symbols of P;Qf=Q;Σis a set of function symbols;Δ={c(p1,…,pk)→p∣wherec∈Σ,c=idP(cl),wherecl=p(X)←ϕ,p1(X1),…,pk(Xk)}.Let P be the set of CHCs in Fig. 1. LetidPmap the clauses toc1,…,c4respectively. ThenAP=(Q,Qf,Σ,Δ)where:For each trace term there exists a corresponding derivation tree called an AND-tree, which is unique up to variable renaming. The concept of an AND-tree is derived from [14,15].Definition 8AND-tree for a trace termLet P be a set of CHCs and lett∈L(AP). Denote byAND(t)the following labelled tree, where each node ofAND(t)is labelled by a clause and an atomic formula.1.For each subtermcj(t1,…,tk)of t there is a corresponding node inAND(t)labelled by an atom p(X) and a clausep(X)←ϕ,p1(X1),…,pk(Xk)which is a renamed version of some clause c in P, such thatcj=idP(c); the node׳s children (ifk>0) are the nodes corresponding tot1,…,tkand are labelled byp1(X1),…,pk(Xk).The variables in the labels are chosen such that if a node n is labelled by a clause, the local variables in the clause body do not occur outside the subtree rooted at n.Let P be a set of CHCs. The set of constraints of a tracet∈L(AP), represented asconstr(t)is the set of all constraints in the clause labels ofAND(t).We say that a trace term t is feasible ifconstr(t)is satisfiable.Let P be a set of CHCs andt∈L(AP). The FTA At(whose construction is trivial) such thatL(At)={t}is called the FTA for t. The states ofAtare chosen to be disjoint from those ofAP.Consider the FTA in Example 1. Lett=c3(c2(c1,c1)). Eacheirepresents a label in the trace. ThenAt=(Q,Qf,Σ,Δ)is defined as:Q={e1,e2,e3,e4}Qf={e1}Σ={c1,c2,c3,c4}Δ={c1→e3,c1→e4,c2(e3,e4)→e2,c3(e2)→e1}andΣis the same as inAP. The trace t is not feasible sinceconstr(t)={A≤100,B>91,A≤100,C=A+11,C>100,D=C−10,D>100,B=D−10}and this is not satisfiable.Consider the FTA in Example 1 and a linear tracet=c3(c1). Lete1anderepresents the labels in the trace. ThenAt=(Q,Qf,Σ,Δ)is defined as:Q={e,e1}Qf={e}Σ={c1,c2,c3,c4}Δ={c1→e,c3(e1)→e}andΣis the same as inAP. The trace t is not feasible.Let P be a set of CHCs andt∈L(AP). Let p(X) be the atom labeling the root ofAND(t). Then the constrained trace atom of t is∀X.(∃Z¯.constr(t)→p(X)), whereZ¯=vars(constr(t))⧹X.We now restate standard soundness and completeness results from constraint logic programming [13] in terms of the concepts defined above. We assume that the underlying constraint theoryThas a complete satisfiability procedure. Note that the domain of linear arithmetic constraints, which is used in our experiments, satisfies these conditions.Proposition 2Let P be a set of CHCs, whose underlying constraint theoryThas a complete satisfiability procedure. LetAPbe the trace FTA for P. Then1.for allt∈L(AP),P∪⊨A, where A is the constrained trace atom of t;p(c) is a variable-free atomic formula such thatP∪⊨p(c), iff(a)there exists a feasible tracet∈L(AP)whose constrained trace atom is of the form∀X.ϕ→p(X)where the constraintϕ[X/c]is true; andp(c) is inM〚P〛, the minimal model of P.The proof depends on a close correspondence betweenAND-trees(Definition 8) and derivations defined as sequences in [13]; we do not elaborate the correspondence in detail but just note that for eachAND-treewith constrained trace atom∀X.(∃Z¯.constr(t)→p(X))there exists one or more derivations for p(X) with answer constraint∃Z¯.constr(t). Conversely for each derivation for p(X) with answer constraint ϕ there exists a uniqueAND-treewhose root is labelled with p(X) and whose constrained trace atom is∀X.ϕ→p(X).1.LetAND(t)be theAND-treefor t (Definition 8), let p(X) be the atom labeling the root and let∀X.ϕ→p(X)be the constrained trace atom for t.⇒there is some derivation (as defined in [13]) for p(X) having answer constraintϕ→p(X);P∪T⊨ϕ→p(X)by [13] (Theorem 6.0.1, Part 2).P∪T⊨p(c)is equivalent toP∪⊨X=c→p(X).⇒there is a derivation for p(X) with answer constraint ϕ, whereT⊨X=c→ϕ(by [13] (Theorem 6.0.1, Part 4));there is a trace term t andAND-treeAND(t)with root labelled by p(X) and constrained trace atom∀X.ϕ→p(X), whereT⊨ϕ[X/c].Follows directly from [13] (Theorem 6.0.1, Parts 1 and 2)□For part 2(a) of the proof, note that the constrained trace atom in theAND-treecan be more general than the atom p(c). For example, say thatp(1)is a consequence of the set of CHCs; then the constrained trace atom could be∀X.X≥0→p(X).Proposition 2establishes the correspondence between the semantics of CHCs and the feasible traces of the trace FTA for the CHCs. Essentially, the set of feasible traces of the FTA is a representation of the minimal model of the clauses.If we transformAPto another FTA while preserving the set of traces, we also preserve the feasible traces. More generally, we can transformAPto another FTAA′so long asL(A′)⊆L(AP)and the elements ofL(AP)⧹L(A′)are all infeasible. In this case the feasible traces ofL(A′)are still a representation of the minimal model of P. We will exploit this in our refinement procedure (see Section 5).Now we describe a procedure (Algorithm 2) for generating a set of clausesP′from an FTAA=(Q,Qf,Σ,Δ)and a set of clauses P. We assume thatΣis the same as that ofAP; soΣis the range of the functionidPmapping clauses of P to function symbols. The transitionsΔare not in product form; a modification of the algorithm and its correctness proposition is possible for product form (which is in fact an enabling factor which makes possible the determinisation of FTAs in practice) but we omit that here for the simplicity of presentation. We first introduce an injective function for renaming the states ofAsince we need predicate names for the generated clausesρ:Q→PredicatesThe functionρmaps each FTA state to a distinct predicate name. The algorithm simply generates a clause for each transition, applying the renaming function from states to predicates, and introducing variables arguments according to the pattern obtained from any clause with the corresponding identifier (all clauses with the same identifier having the same variable pattern).Algorithm 2Generating a set of clauses represented by an FTA.Input: An FTAA=(Q,Qf,Σ,Δ), set of Horn clauses P, injective functionsρ:Q→Predicates,idP:P→ΣOutput: A set of Horn clausesP′represented byAand functionidP′:P′→ΣP′←∅;for eachci(q1,…,qn)→q(wheren≥0)∈Δdo|letc=p(X)←ϕ,p1(X1),…,pn(Xn)betheclauseinPwhereidP(c)=ci;cnew=ρ(q)(X)←ϕ,ρ(q1)(X1),…,ρ(qn)(Xn);idP′(cnew)=ci;P′←P′∪{cnew};endreturnP′;Apart from generating a set of clausesP′, Algorithm 2 also generates the clause identification mappingidP′, preserving the function symbols from the FTA. In this way the set of traces is preserved from P toP′. The correctness of Algorithm 2 is expressed by the following proposition.Proposition 3Let P be a set of CHCs and letAbe an FTA whose signature is the same as that ofAP. LetP′be the set of clauses generated fromAand P byAlgorithm 2. ThenL(A)=L(AP′). Furthermore ifL(A)⊆L(AP)andL(A)includes all the feasible traces ofL(AP)then the minimal model ofP′is the same as the minimal model of P, modulo predicate renaming.We first prove thatL(A)=L(AP′), that is,∀t.t∈L(A)≡t∈L(AP′). The proof is by induction on the depth of t. LetA=〈Q,Qf,Σ,Δ〉andAP′=〈Q′,Qf′,Σ,Δ′〉and we assume thatQ=QfandQ′=Qf′•Base case.thasdepth0andt∈L(A)≡∃t→q∈Δ≡∃c=p(X)←ϕ∈PwhereidP(c)=t≡∃cnew=ρ(q)(X)←ϕ∈P′andidP′(cnew)=t≡∃t→ρ(q)∈Δ′≡t∈L(AP′)Inductive case: Assume that for all terms t of depth at most k,t⇒⁎qinAifft⇒⁎ρ(q)inAP′. Lett=ct(t1,…,tn)have depthk+1.ct(t1,…,tn)∈L(A)≡∃ct(q1,…,qn)→q∈Δ∧ti⇒⁎qi,1≤i≤n≡∃ct(q1,…,qn)→q∈Δ∧ti⇒⁎ρ(qi),1≤i≤nbyind.hyp.sincedepthoft1,…tnisatmostk≡∃c=p(X)←ϕ,p1(X1),…,pn(Xn)∈PwhereidP(c)=ct∧ti⇒⁎ρ(qi),1≤i≤n≡∃cnew=ρ(q)(X)←ϕ,ρ(q1)(X1),…,ρ(qn)(Xn)∈P′andidP′(cnew)=ct∧ti⇒⁎ρ(qi),1≤i≤n≡∃ct(ρ(q1),…,ρ(qn))→ρ(q)∈Δ′∧ti⇒⁎ρ(qi),1≤i≤n≡ct(t1,…,tn)∈L(AP′)Consider the following transitions, relating to the signature for the program in Fig. 1. The set of states is {[false],[mc91],[e,false],[mc91,e1]}. (These are elements of the powerset of the set of states {false,mc91,e,e1} obtained from the union of FTA in Example 1 and FTA in Example 3, which were generated by the determinisation algorithm)The clauses generated by Algorithm 2 are the following, with the renaming functionρ={[false]↦false,[mc91]↦mc91,[e,false]↦false_1,[mc91,e1]↦mc91_1}. Below we also show the clause identifiers (theidfunction for the generated clauses) showing that several clauses can have the same identifier, thus preserving tracesAbstract interpretation [16] is a technique which derives sound over-approximations by computing abstract fixed points. Convex polyhedron analysis (CPA) [17] is a program analysis technique based on abstract interpretation [16]. When applied to a set of CHCs P it constructs an over-approximationM′of the minimal model of P, whereM′contains at most one constrained factp(X)←ϕfor each predicate p. The constraint ϕ is a conjunction of linear inequalities, representing a convex polyhedron. The first application of convex polyhedron analysis to CHCs was by Benoy and King [18].We summarise briefly the elements of convex polyhedron analysis for CHC; further details (with application to CHC) can be found in [17,18]. The abstract interpretation consists of the computation of an increasing sequence of elements of the abstract domain of tuples of convex polyhedra (one for each predicate)Dn. We construct a monotonic abstract semantic functionFP:Dn→Dnfor the set of Horn clauses P, approximating the concrete semantic “immediate consequences” operator.SinceDncontains infinite increasing chains, a widening operator for convex polyhedra [17] is needed to ensure convergence of the sequence. The sequence computed isZ0=⊥n,Zn+1=Zn∇FP(Zn)where∇is a widening operator for convex polyhedra and the empty polyhedron is denoted⊥. The conditions on∇ensure that the sequence stabilises; thus for some finite j,Zi=Zjfor alli>jand furthermore the value Zjrepresents an over-approximation of the least model of P. Algorithm 3 presents convex polyhedral analysis for Horn clauses. For each constrained fact derived from the set of clauses P using this algorithm, there is a derivation tree (trace term) associated with it. These are syntactically possible trace terms using the clauses in P but may not be feasible due to abstraction. Thus all such trace terms are inL(AP).Algorithm 3Algorithm for convex polyhedral abstraction.Input: CHCs POutput: a set of constrained facts Zii←0;Z0←⊥;New←⊥;repeat|forallp(X)←Body∈Pdo|New←New⊔solve(p(X),Body,Zi)endZi+1←Zi∇(New⊔Zi)▹Upperboundandwiden;i←i+1;untilZi⊑Zi−1;returnZi;Much research has been done on improving the precision of widening operators. One technique is known as widening up-to, or widening with thresholds [19]. A threshold is an assertion that is combined with a widening operator to improve its precision.Our tool for convex polyhedral abstract interpretation, called CPA in the rest of this paper, uses the Parma Polyhedra Library [20] to implement the operations on convex polyhedra, and incorporates a threshold generation phase based on the method described by Lakhdar-Chaouch et al. [21], as well as a constraint strengthening pre-processing which propagates constraints both forwards and backwards in the clauses of P.Recently, a technique for deriving more effective thresholds was developed [21], which we have adapted and found to be effective in experimental studies. In brief, the method collects constraints by iterating the concrete immediate consequence functionSPDthree times starting from the “top” interpretation, that is, the interpretation in which all atomic facts are true. The thresholds are computed by the following method. LetSPDbe the standard immediate consequence operator for CHCs mentioned in Section 4.1. That is, if I is a set of constrained facts,SPD(I)is the set of constrained facts that can be derived in one step from I. Given a constrained factp(Z¯)←C, defineatomconstraints(p(Z¯)←C)to be the set of constrained facts{p(Z¯)←Ci∣C=C1∧…∧Ck,(1≤i≤k)}. The functionatomconstraintsis extended to interpretations byatomconstraints(I)=⋃p(Z¯)←C∈I{atomconstraints(p(Z¯)←C)}.LetI⊤be the interpretation consisting of the set of constrained factsp(Z¯)←truefor each predicate p. We perform three iterations ofSPD(represented asSPD(3)) starting withI⊤(the first three elements of a “top-down” Kleene sequence) and then extract the atomic constraints. That is,thresholdsis defined as follows:thresholds(P)=atomconstraints(SPD(3)(I⊤))A difference from the method in [21] is that we use the concrete semantic functionSPDrather than the abstract semantic function when computing thresholds. The set of threshold constraints represents an attempt to find useful predicate properties and when widening they help to preserve invariants that might otherwise be lost during widening. See [21] for further details. Threshold constraints that are not invariants are simply discarded during widening. Thresholds constraints are not necessarily over-approximations (invariants).The operationthresholds(P)can become expensive and generate a very large number of constraints. Alternatively we can generate more general threshold constraints (called abstract threshold), possibly losing precision while gaining efficiency, by following more closely the approach defined in [21], using the abstract semantic function FP. Then the threshold operation P becomesthresholds(P)=atomconstraints(FP(3)(I⊤))The effectiveness of abstract interpretation can be improved by combining it with specialisation with respect to some property. Therefore we specialise (pre-process) the set of clauses with respect to the property to be verified using the method described in [22]. The method is summarised as follows: the inputs are a set of CHCs P and an atomic formula A (a property) and the output is PA, a set of specialised clauses.1.Compute a query-answer transformation[22] of P with respect to A, denotedPqa, containing predicatespqandparepresenting query and answer predicates for each predicate p in P.Compute an over-approximation M of the model ofPqausing abstract interpretation.Strengthen the constraints in the clauses in P, by adding constraints from the answer predicates in M. That is, for each clausep(X)←ϕ,p1(X1),…,pk(Xk)in P, we construct a clausep(X)←ϕ,ϕ0,ϕ1,…,ϕn,p1(X1),…,pk(Xk)in PA, wherepa(X)←ϕ0,p1a(X)←ϕ1,…,pna(X)←ϕnare inM′.The method propagates constraints globally, both forwards and backwards, and makes explicit constraints from the original clauses. This allows better analysis of the transformed clauses. Furthermore, the method is independent of the abstract domain and the constraints theory underlying the clauses.If an over-approximation of the clauses derived by polyhedral abstraction does not containfalse, the clauses are safe. However iffalseis contained in the approximation, we do not know whether the clauses are unsafe or whether the approximation was too imprecise. In such cases we can produce a trace termt∈APusing the clauses in P which justifies the abstract derivation offalse. The feasibility of this trace can be checked by a constraint satisfiability check. If the trace is feasible, then it corresponds to a proof of unsafety. Otherwise, refinement is considered based on this trace. In some other approaches, a more precise abstract domain is derived from the trace. In our refinement approach, which is described next, we aim to generate a modified set of clauses that could yield a better approximation. This is achieved through the steps shown in Algorithm 4.Algorithm 4Algorithm for clause refinement using FTA operations.Input: A set of Horn clauses P and an infeasible tracet∈APOutput: A set of refined Horn clausesP′1. construct the trace FTAAP(Definition 7);2. construct an FTAAtsuch thatL(At)={t}(Definition 11);3. compute the difference FTAAP⧹At(Definition 5);4. generateP′fromAP⧹Atand P (Algorithm 2) ;returnP′;BothAPandAtin Algorithm 4 are deterministic FTAs by construction, however their union is not. Determinisation is used to generate the difference FTA (step 3) and its result is in product form. The programP′has the same model (modulo predicate renaming) as P, since the steps result in the removal of an infeasible trace but all other traces are preserved.Removal of one trace from the clauses might not seem much of a refinement. However, modifying the clauses to remove a single trace can result in significant restructuring, which arises as a side-effect of determinisation which isolates the infeasible trace. This in turn can induce a more precise abstract interpretation, with less precision loss due to convex hull operations and widening.The correctness of this refinement follows from Proposition 3. In particularfalse∈M〚P〛if and only iffalse∈M〚P′〛(assuming that the predicate renaming at least preserves the predicate namefalse).Example 5Consider again the FTA shown in Example 4. This is in fact the determinisation ofAP∪Atwhere P is the set of clauses in Fig. 1 andAtwhere t is the infeasible trace c3(c1). The only accepting state ofAtis e; thus to construct the differenceAP⧹Atwe need only to remove from the automaton the states containing e, namely [mc91,e]. We can also remove any transitions containing this state in the right hand side. This leaves the following FTA and refined program in Fig. 2, using the same renaming function as in Example 4. In this program, the infeasible trace corresponding to c3(c1) cannot be constructedIt can be seen that although the infeasible trace was very simple, its removal led to a considerably restructured set of clauses. We have not shown the product form here, which is in fact somewhat more compact.The refinement process guarantees progress; that is, the infeasible computation once eliminated never arises again. Due to the construction of theidmapping forP′the traces in the languages of the FTAs of P andP′are preserved, apart from the eliminated trace.Proposition 4ProgressLet P be a set of CHCs, and t be a trace in P. LetP′be a refined set of CHCs obtained from P after the removal of t. Then t cannot be generated in any approximation ofP′.The proof of this proposition follows from the following points:1.APrecognizes all syntactically possible traces of P, which is an over-approximation of the traces of P since the constraints in P are not taken in account while constructingAP.After the removal of the trace t from all possible traces of P (step 3 of Algorithm 4) the language ofAP⧹Atdoes not contain t (difference automata).Then using Algorithm 2 to generateP′fromAP⧹Atand P, t will be syntactically impossible trace inP′(follows from Proposition 3).Since t is syntactically impossible trace inP′, there is no constrained fact associated with it in any abstract domain usingP′(see Section 4.5).□Progress is an interesting and relevant refinement property but it gives no guarantees that a proof will eventually be found if such exists. In the worst case the algorithm will just eliminate longer and longer infeasible traces. Even if there exists some convex polyhedral approximation that establishes P׳s satisfiability, the abstract interpretation algorithm involving the widening heuristic cannot guarantee to find it.We also apply a tree-automata-based transformation to split states representing predicates where convex hull operations have lost precision. A typical case is where a number of clauses with the same head predicate contain disjoint constraints, such as a predicate representing an if–then–else statement in an imperative program. The clauses defining the statement will have a clause for the then branch and a clause for the else branch. The respective constraints in these clauses are disjoint since one is the negation of the other. The convex hull will thus contain the whole space for the variables involved in these constraints.As defined in Definition 6, the FTA state corresponding to such a predicate can be split. We partition the transitions corresponding to the clauses according to the disjoint groups of constraints and apply the procedure in Definition 6, preserving the set of traces. Thus the feasible traces and the model of the resulting clauses is preserved. This enhances precision of polyhedral analysis [23].Splitting has to be carried out in a controlled manner to prevent blow up in the size of FTA and hence on the size of the clauses generated. With this in mind we split only those states appearing in a counterexample trace, but this is not necessary in our approach to avoid a counterexample.It would have been possible to formulate the splitting operation directly on CHCs, without any reference to FTAs. However, since the whole procedure is based on transformations that preserve the set of feasible traces, we preferred to present splitting as a language-preserving operation on FTAs.Our tool consists of an implementation of a convex polyhedra analyser for CLP written in Ciao Prolog11http://ciao-lang.org/.interfaced to the Parma Polyhedra Library [20] as well as an implementation of an FTA determiniser written in Java. It takes as an input a CLP program and returns “safe”, “unsafe” or “unknown” (after resources are exhausted). The input is first pre-processed using the method described in Section 4.5.2. The benchmark set contains 216 CHCs verification problems (179 safe and 37 unsafe problems), taken mainly from the repositories of several state-of-the-art software verification tools such as DAGGER [24] (21 problems), TRACER [25] (66 problems), InvGen [26] (68 problems), and also from the TACAS 2013 Software Verification Competition [27] (52 problems). These problems are also available in C (http://akira.ruc.dk/~kafle/comlan-vmcai15-benchmarks.zip) and they were first translated to CLP form.22Thanks to Emanuele De Angelis for the translation.The chosen problems are representatives of different categories of the Software Verification Competition (loops, control flow and integer, SystemC, etc.) as well as specific problems used to demonstrate the strength of different verification tools. The benchmarks in CLP form are available from http://akira.ruc.dk/~kafle/VMCAI15-Benchmarks.zip. The experiments were carried out on an Intel(R) computer with a 2.66GHz processor running Debian 5 in 6 GB memory.The results of our experiments are summarised in Fig. 4. Column CPA summarises the results using our own convex polyhedra analyser (Section 4.5) with no refinement step. Column CPA+R shows the results obtained by iterating the CPA algorithm with the refinement step described in Section 5, Algorithm 4. Column CPA+R+Split incorporates the FTA-based state splitting into the refinement step (Section 5.1). In all the above cases, we used a concrete threshold generation as described in Section 4.5.1. Column QARMC shows the results obtained on the same problems using the QARMC tool [28,29]. The columns VeriMAP(GenPH), TRACER-SPost, TRACER-WPre respectively report results using the VeriMAP system implementing Iterated Specialisation method with the generalisation operator GenPH [30], TRACER [25] using the strongest postcondition (SPost) and the weakest precondition (WPre) options. The results in these three columns are taken from [30] since we could not run these tools. We used the same set of benchmarks as in [30]. The last column ELDARICA reports results using Eldarica tool33http://lara.epfl.ch/w/eldarica.which uses disjunctive interpolants for the Horn clause verification purpose [31].The results show that CPA is reasonably effective on its own, solving 74% (160/216) of the problems. When combined with a refinement phase we can solve further 22 problems. Although only one infeasible trace is eliminated in each refinement step, the refined program splits some of the predicates appearing in the trace, which we noted to be a crucial point of precision for polyhedral analysis [23]. When adding the state splitting refinement we solve an additional 13 problems. Further splitting would solve more problems but we are unwilling to introduce uncontrolled splitting due to the blow up in program size that could result. The maximum number of iterations required to solve a problem was 8. Although the timeout limit was 5min, only 5% of the solved problems required more than 1min.Our implementation uses the product form for DFTAs produced by the determinisation algorithm, although the formalisation of refinement in Section 5 uses only standard FTA transitions. Although the traces for clauses with predicates produced from product states differ from the original clauses, they can be regarded as representing the original traces, by unfolding the clauses resulting from ϵ-transitions. Product form adds to the scalability of the approach, especially for Horn clauses with more than one body atom. Empirically we have not shown this here but this is due to the scalability of the product form during determinisation of FTAs (see [11]).On the set of verification problems considered, our results (CPA+R+Split) improve on other tools both in average time and the number of instances solved. The results of VeriMAP and QARMC are close to ours while results of TRACER are bit far. This is due to the fact that TRACER uses symbolic execution and does not scale well. Out of 216 problems QARMC solves 178 problems with an average time of 59s whereas we can solve 195 problems with an average time of 50s. However, all unsafe programs in the benchmark set are solved by QARMC in contrast to ours. Surprisingly enough, the number of unsafe problems solved by VeriMAP and our tool is the same. Since both of our tool use convex hull and widening, the precision lost due to these operators in the rest of the unsafe programs cannot be recovered. The model checking algorithm implemented in Eldarica for Horn solving is similar in spirit as the one described in [29] but uses disjunctive interpolation for counterexamples generalisation instead of tree interpolation which is strictly more general than tree interpolation [31]. We suspect that it is due to this, the average time taken by Eldarica is slightly less than that of QARMC though it solves lesser number of instance than QARMC. Our results show that for these set of examples, tools using polyhedral abstraction seems more powerful than the others.Convex polyhedral analysis is good at finding the required invariants to prove the safety of a program and due to this our tool and VeriMAP solved more safe problems than QARMC. On the other hand, QARMC seems to be more effective at finding bugs. Most of the problems challenging to us come from some particular categories e.g. SystemC (modeled over fixed size integers) and Control Flow and Integer Variables of [27] which requires some specific techniques to solve. Safe problems challenging to us are also challenging to QARMC though this is not the case for unsafe problems.We chose a subset of 132 problems from SV-COMP 201544http://sv-comp.sosy-lab.org/2015/benchmarks.php.[32]. This set contains benchmarks from the categories which were not reported in our experiments before such as recursive benchmarks which needs recursive analysis. Additionally it contains some benchmarks from Loop category such as loop-acceleration, loop-lit, loop-new. We used SeaHorn [33,5], a verification framework based on LLVM, for Horn clause generation. SeaHorn first compiles C to LLVM intermediate representation (LLVM IR), also known as bitcode using clang, a C-family front-end for LLVM.55http://clang.llvm.org/.The bitcode is further simplified and optimised reusing the vast amount of work done on LLVM (e.g. function inlining, dead code elimination, CFG simplifications, etc.) whose purpose is to make the verification task easier. The resulting bitcode is translated to Horn clauses using different semantics for example small step, large block encoding, etc. More details can be found in [33,5]. These benchmarks are available in C as well as in Horn clause form from http://akira.ruc.dk/~kafle/comlan-vmcai15-benchmarks.zip. The results are summarised in Table 1. The column CPA+R+Split+AT reports results using our tool described above which now uses abstract threshold as described in Section 4.5.1 rather than the concrete one. The results show that our tool with the option abstract threshold (column 2) scales more than the concrete one (column 1) though the number of instances solved is the same. In these benchmarks, though we solve a few more problems than QARMC, it is much faster than our tool.

@&#CONCLUSIONS@&#
