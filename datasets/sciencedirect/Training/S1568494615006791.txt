@&#MAIN-TITLE@&#
A novel adaptive cuckoo search algorithm for intrinsic discriminant analysis based face recognition

@&#HIGHLIGHTS@&#
A novel adaptive cuckoo search algorithm, without using a Levy step, is proposed.The new algorithm improves the objective function values with a faster rate.Our evolutionary face recognition algorithm provides improved recognition rate.Optimal dimension reduction is achieved using PCA+IDA algorithm.ACS–IDA algorithm search optimal eigenvectors to improve accuracy.

@&#KEYPHRASES@&#
Evolutionary algorithm,Cuckoo search,Principal component analysis,Intrinsic discriminant analysis method,Face recognition,

@&#ABSTRACT@&#
This paper presents a novel adaptive cuckoo search (ACS) algorithm for optimization. The step size is made adaptive from the knowledge of its fitness function value and its current position in the search space. The other important feature of the ACS algorithm is its speed, which is faster than the CS algorithm. Here, an attempt is made to make the cuckoo search (CS) algorithm parameter free, without a Levy step. The proposed algorithm is validated using twenty three standard benchmark test functions. The second part of the paper proposes an efficient face recognition algorithm using ACS, principal component analysis (PCA) and intrinsic discriminant analysis (IDA). The proposed algorithms are named as PCA+IDA and ACS–IDA. Interestingly, PCA+IDA offers us a perturbation free algorithm for dimension reduction while ACS+IDA is used to find the optimal feature vectors for classification of the face images based on the IDA. For the performance analysis, we use three standard face databases—YALE, ORL, and FERET. A comparison of the proposed method with the state-of-the-art methods reveals the effectiveness of our algorithm.

@&#INTRODUCTION@&#
Over the years, a quite significant amount of research work on machine recognition of faces is found in the literature. Machine recognition of faces is important for person identification. Pattern recognition problems have different constraints in terms of complexity of implementations. Hence, we face difficult yet interesting technical challenges. Researchers in pattern recognition, image processing, neural sciences, and computer vision have raised up a number of stimulating issues linked to the face recognition by machines. Likewise, different methods facing the face recognition issues are studied, resulting in a large body of research. Existing methods for face recognition have been verified on different sets of images of varying modalities.Face recognition (FR) deals with many interesting steps. However, three important steps in face recognition are extraction/normalization of faces, feature selection and recognition. Existing methods for developing face recognition systems are based on different analysis. Out of all these FR techniques, appearance-based approaches, which relied on statistical exploration, have been found fit well for face recognition. The appearance-based methods are applied directly to images and process the image as two-dimensional patterns. In this method, a two dimensional face image of size m×n pixels is represented by a vector in a mn—dimensional space called as sample space. It is important to note here that sample space has a very large dimension, thereby demanding ample time for the pattern classification and sinking the accurateness of the prediction of different classes. Therefore, there is a strong need for dimensionality reduction before pattern recognition. The most common linear tools used are principal component analysis (PCA) [1,2], linear discriminant analysis (LDA) [2–5], the well known locality preserving projections (LPP) [6] etc. Some of the nonlinear tools used are the isometric mapping [7], the locally linear embedding (LLE) [8,9], and the Laplacian eigenmaps (LEM) [10,11]. Note that the record of the nonlinear methods used needs rigorous computation work to tune different parameters in order to achieve the best output [12–14] and lack in their ability to handle testing data [15]. Hence, the linear dimension reduction tools are extensively deployed in face recognition.It is interesting to mention here that PCA and LDA are the two popular linear techniques used for reduction of the dimension in face recognition. In general, PCA employs the resemblance features, among the different classes of samples. It projects the data (high dimension) onto a set of basis functions (which are mutually orthogonal to each other) to get a compact demonstration of the original data. Thus, a reduction in dimensionality is achieved. In a nutshell, PCA reduces the dimension of the problem. PCA based features are coined as eigenfaces [1] and are typically used for the development of a face recognition system. On the other hand, LDA uses the discriminatory features, among the different classes of samples. LDA is basically a linear supervised dimensionality reduction process. It maps the data points of different classes much apart from each other. But the data points of the same class are mapped very close to each other. Note that LDA based features are coined as Fisherfaces [16] and are used to develop the face recognition system. Another interesting idea of Intrinsicfaces based face recognition algorithm is reported by Wang and Yu [17]. They proposed a firsthand intrinsic face model, where an individual face model is separated into 3 constituents. These are—(i) the commonness difference; (ii) the individuality difference; (iii) the intrapersonal difference. By employing the intrinsic face model, intrinsic discriminant analysis (IDA) method is used to maximize the individuality difference. At the same time, the intrapersonal difference is minimized. Note that IDA based features are coined as Intrinsicfaces [17] and also used for the development of the face recognition system. The authors have handled the singularity problem through the use of a perturbation. However, the complexity of the algorithm increases by introducing perturbation. Further, the selection process for selecting optimal eigenvectors is not accurate. This has motivated us to investigate a novel perturbation free IDA based algorithm for face recognition. The idea is to use PCA+IDA, thereby increasing the performance accuracy.In the classical face recognition technique, the general practice is to select the top M principal components for the dimension reduction. Because, the top M principal components contain the most information of a face image, as they are related to the respective top M eigenvalues. The rest N–M lower order principal components are discarded. But, there is no guarantee (no concrete evidence) that the top M principal components provide the optimum performance in face recognition. There may be some important information, related to pattern classification, present in the lower order principal components. Some lower order principal components also play crucial role in pattern classification. Hence, it is important to select the M optimal principal components instead of the top M principal components. This leads to a search process that may be employed to find the M optimal principal components out of all N principal components obtained by the principal component analysis (PCA) [18]. The face recognition approach generally uses a minimum distance classifier for classification of facial image. Therefore there is a strong need to use optimal principal components for a better classification. Such a problem can be coined as an optimization problem; we need to explore the search space to get a candidate solution for a given problem. The optimization processes are used to find the optimal principal components that can be efficiently used for classification purposes.In a nutshell, the motivation behind this proposal is to integrate PCA and IDA with a new modified evolutionary technique in order to get improved results in face recognition. As per the above discussions, IDA is basically a perturbation based algorithm which requires more computation time. To make it perturbation free, we need to integrate PCA for avoiding the singularity problem. Further, there is a strong need to deploy an efficient evolutionary technique (optimization algorithm) to find the optimal principal components out of all principal components obtained by the principal component analysis (PCA). In this context, we are motivated to investigate a new optimization technique called the adaptive cuckoo search algorithm which is faster and useful for finding the optimal principal components. This clarifies the reason why the adaptive cuckoo search algorithm is integrated with PCA and IDA to form a face recognition algorithm.In the recent past, the evolutionary algorithms (EAs) have demonstrated the ability to handle the problem related to computer vision and pattern classification. The genetic algorithm (GA) has been successfully implemented for eigenface based face recognition in the evolutionary pursuits (EP) [19] to find the optimal basis vectors. The EP has a better recognition rate as compared to PCA [18] and the Fisher's Linear Discriminant (FLD) [2]. Further, the authors in [20] used GA and FLD to develop GA-Fisher algorithm for the face recognition algorithm. The mutation in GA only gives phenotypically changes, but never goes for a physical dispersal. The offspring of the GA never finishes at the matching location as their parents. So, this affects the search procedure. To overcome all these problems, the bacterial foraging optimization (BFO) technique was proposed in [21,22]. The BFO algorithm is based on the mathematical modeling of foraging behavior of E. coli bacteria living in human intestine. This reveals us to propose BFO-Fisher algorithm [23] based face recognition using BFO algorithm and FLD. In this paper [23], BFO-Fisher is also compared with the GA-Fisher [20], and shown that BFO has better ability than GA for sourcing of principal components for dimension reduction. The disadvantage in the BFO algorithm is that after reproduction, one bacterium gives rise to two offspring bacteria, and they start searching for nutrients from the same location. To overcome this problem, we proposed a novel crossover BFO algorithm [24] using the crossover mechanism of GA and foraging behavior of BFO. In this method [24], 50% of offspring bacteria are randomly placed in the search space. But for both BFO [21] or CBFO [24] algorithm, the step size is fixed. So the selection of the best step size for a given problem is a tedious job, which can be solved manually via experimentations and observations. An attempt was made by the authors in [25] to provide an analysis for the adaptive chemotaxis in BFO. However, the initial value of the step size was decided by several experiments.As the BFO algorithm has many parameters to initialize beforehand, it is computationally expensive, while considering the time required converging to the global minima or near global minima. In the recent past, cuckoo search (CS) [26,27] algorithm has come around, which has less parameters compared to BFO [21,22]. This reveals that CS is faster than the BFO. This warrants us to investigate the adaptive CS algorithm, which can be applied in face recognition for finding the optimal principal components for dimension reduction. In the CS algorithm, one has to define the step size, which is, generally, taken from the Levy distribution. So, here we proposed a novel adaptive cuckoo search (ACS) algorithm, which is free from the Levy step size and it adaptively decides the step size with zero parameter initialization. Further, we also introduce an efficient face recognition algorithm called ACSIDA. To back up our statements, the ACS algorithm is compared to CS [26,27] algorithm using the standard benchmark functions. For the evaluation of our newly proposed ACSIDA algorithm, experiments are presented using three different well known Yale, ORL, and FERET face databases.It is noteworthy to mention here that some interesting papers related to the face classification/recognition are also proposed recently. The idea of diversive curiosity to improvise learning in Backpropagation algorithm for improved pattern classification is proposed in [28]. Dai at al. [29] proposed a two-phased and Ensemble scheme integrated Backpropagation algorithm for avoiding the local minima problem of the standard Backpropagation algorithm and successfully used it for pattern classification. Several EAs proposed recently have been successfully applied in different optimization engineering. In [30,31], several EAs such as Cuckoo Optimization Algorithm (COA) have been employed to achieve optimal performance for synchronization of bilateral teleoperation systems in presence time delay and modeling uncertainties. Replication and comparison of computational experiments in applied evolutionary computing were discussed in [32]. For performing statistical tests, the readers can refer to [33]. They have explained how to use nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms. The authors in [34] proposed PSO with adaptive mutation and inertia weight and its application in parameter estimation of dynamic systems. Identification of nonlinear systems using modified particle swarm optimization is presented in [35]. The authors in [36] discussed intelligent identification and control using improved fuzzy particle swarm optimization. An adaptive gradient descent-based local search in memetic algorithm for solving engineering optimization problems is proposed in [37]. Adaptive fuzzy sliding mode control for synchronization of uncertain non-identical chaotic systems using bacterial foraging optimization was presented in [38]. Authors in [39] discussed Swarm-based structure-specified controller design for bilateral transparent teleoperation systems via μ synthesis.In the literature, it is seen that the optimization algorithms (evolutionary algorithms) proposed earlier use many parameters. There is no clear indication how to choose different initial values for different parameters. This has motivated us to investigate a parameter free algorithm. In the CS algorithm, one has to define the step size, which is, generally, taken from the Levy distribution. But, here we propose a novel adaptive cuckoo search (ACS) algorithm, which is free from the Levy step size and it adaptively decides the step size with zero parameter initialization. To be precise, our proposed ACS algorithm is a parameter free algorithm. This may be useful for face recognition.The outline of this paper is as follows. Section 2 provides the basics of the related work like PCA, IDA and CS algorithm. In Section 3, we propose a new adaptive cuckoo search algorithm known as ACS, and the algorithm is validated with standard benchmark functions. In Section 4, we propose a method called ACSIDA for dimension reduction of IDA using PCA with the help of ACS. Section 5 presents the experimental results and discussions. Finally, conclusions are given in Section 6.

@&#CONCLUSIONS@&#
