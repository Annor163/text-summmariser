@&#MAIN-TITLE@&#
Improving brain–computer interface classification using adaptive common spatial patterns

@&#HIGHLIGHTS@&#
An adaptive common spatial patterns method is proposed for EEG spatial filtering.The method is evaluated for intra- and inter-subject classifications.The method is compared to existing techniques and shows superior performance.The effects of adding misclassified trials to training data are investigated.The method is potentially applicable to various real-time BCI tasks.

@&#KEYPHRASES@&#
Brain–computer interface,Common spatial patterns,Electroencephalography,Adaptive,Nonstationarity,

@&#ABSTRACT@&#
Common Spatial Patterns (CSP) is a widely used spatial filtering technique for electroencephalography (EEG)-based brain–computer interface (BCI). It is a two-class supervised technique that needs subject-specific training data. Due to EEG nonstationarity, EEG signal may exhibit significant intra- and inter-subject variation. As a result, spatial filters learned from a subject may not perform well for data acquired from the same subject at a different time or from other subjects performing the same task. Studies have been performed to improve CSP׳s performance by adding regularization terms into the training. Most of them require target subjects׳ training data with known class labels. In this work, an adaptive CSP (ACSP) method is proposed to analyze single trial EEG data from single and multiple subjects. The method does not estimate target data׳s class labels during the adaptive learning and updates spatial filters for both classes simultaneously. The proposed method was evaluated based on a comparison study with the classic CSP and several CSP-based adaptive methods using motor imagery EEG data from BCI competitions. Experimental results indicate that the proposed method can improve the classification performance as compared to the other methods. For circumstances where true class labels of target data are not instantly available, it was examined if adding classified target data to training data would improve the ACSP learning. Experimental results show that it would be better to exclude them from the training data. The proposed ACSP method can be performed in real-time and is potentially applicable to various EEG-based BCI applications.

@&#INTRODUCTION@&#
Brain–computer interface (BCI) is a communication technique that aims to identify a subject׳s brain intents and translate them into machine commands to control the operations of electromechanical devices. Electroencephalography (EEG) might be the most widely used noninvasive imaging technique in BCI. Due to the non-stationary nature of EEG, which is usually caused by changes of electrodes impedance or positions, subjects׳ attention, fatigue, eye movements, or muscular activity, EEG signals exhibit large intra- and inter-subject variation [1]. As a result, an observed EEG pattern from a subject might not be repeatable from the same subject at a different time or from different subjects performing the same task. Various methods have been proposed to address the nonstationarity in EEG-based BCI [1,2]. These methods were focused on either feature extraction process [1,3–16], or feature modelling and classification [16–29]. Some methods adapt to the intra- and/or inter-subject variation through supervised adaptive learning [20,24,30], semi-supervised or unsupervised learning [3,4,7,11,17–19,23,31–34], while others try to identify stationary patterns that are common within a single subject or across multiple subjects [1,5,6,8–10,12,14,13,15,21,22,25–27,35,36]. Among these studies, methods developed based on common spatial patterns (CSP) have been paid special attention. CSP is a two-class spatial filtering technique that maximizes the variance of band-passed EEG signals from one class while minimizing the signal variance from the other [37]. It is efficient in extracting representative features for BCI classification, and can be extended for multi-class BCI applications. The original CSP method is a supervised and subject specific technique that requires training data from a target subject with known class labels. It is typically used on a subject-by-subject basis, and might not perform well for multi-subject BCI.In order to improve the multi-subject performance of CSP, prior information from different subjects can be added to the CSP learning via regularization. The regularization is typically implemented in two ways [14]. One is to calculate a weighted average of covariance matrices of EEG data from different subjects [3,38,4,6,7,12,39]. Fixed experiential weights are often used [3,4,12,39], but adaptive weights are also proposed to better quantify the similarity between training and testing data [40,41,38,6,7]. The other is to regularize the CSP objective function by adding a penalization term to impose prior information from multiple subjects [5,15,14,10,9]. By incorporating multi-subject information, the regularized CSP methods can outperform the conventional CSP in multi-subject BCI classification tasks. Most of the regularized CSP methods require labelled training data from target subjects. If training data are unlabelled, an estimation of their class labels is performed so that the data can be assigned to a specific class to update the covariance matrix of this class [3,9,7,4]. Erroneous estimations would affect the CSP learning and deteriorate the BCI classification performance.In this work, a different method to perform adaptive CSP (ACSP) learning is investigated. The method uses unlabelled EEG data from target subjects to learn spatial filters without an estimation of class labels for the target data, and updates spatial filters for both classes simultaneously using adaptive weights. There is no classification needed during the adaptive learning, and spatial filters can be updated in real-time to adapt to intra- and inter-subject variation in EEG. It can be used to classify single trial EEG data from single or multiple subjects. The proposed method was evaluated using multi-subject motor imagery EEG data from BCI competitions III and IV.The remaining part of the paper is organized as follows. The classic CSP method is introduced in Section 2.1. The proposed ACSP method is described in Sections 2.2, 2.3, and 2.4. Section 2.5 explains the experimental EEG data used in this study, and how the method was evaluated. Experimental results are described and discussed in Section 3. Finally, Section 4 summarizes the paper.The proposed adaptive CSP method is developed based on the classic CSP approach [42,43]. CSP is a supervised two-class spatial filtering technique that aims to maximize feature variation for one class and simultaneously minimize feature variation for the other. Given anM×NmatrixEi(y)that represents the ith trial of EEG data collected under a brain task with class label y,y∈{1,2}, the normalized class-specific spatial covariance matrixCyis computed as:(1)Cy=1ny∑i=1nyEi(y)EiT(y)tr(Ei(y)EiT(y)),whereEi(y)is mean-centered, M is the number of channels, N is the number of time points, nyis the number of EEG trials in class y, and T is the matrix transpose operator. Based on the covariance matrix, the CSP training is to maximize the following Rayleigh coefficient:(2)WCyWTW∑yCyWT,which is equivalent to solve the generalized eigenvalue problem [40,14,37]:(3)C1WT=C2WTΛ,where the matrix W consists of spatial filters in rows, andΛis a diagonal matrix assorted in descending order of eigenvalues ofC2−1C1that measure the variance ratio between the two classes. With the projection matrix W, the spatial filtering of a trialEi(y)is computed as:(4)Zi=WEi(y).The columns ofW−1are the common spatial patterns that are considered as time-invariant EEG source distribution vectors. The discrimination is based on the feature projections on W with maximal variations, which are the first and last m rows ofZi. Based onZi, a feature vector is constructed for the ith trial with the rth spatial filter:(5)xr=log[Var(zr)∑j=12mVar(zj)],whereVar()is the variance calculator, and zris the rth row ofZi. The logarithmic transformation is applied to make the distribution of xrmore close to Gaussian.In CSP and some of its extensions for multi-subject analysis, the spatial filter W is calculated and then fixed for the processing of new data [6,12,15]. When there is no or unlabelled training data from target subjects, fixed spatial filters are usually not sufficient to characterize spatial covariance structures of new data. CSP extensions have been proposed to adapt to unlabelled data [3,38,9,7,4]. For example, in an adaptive method proposed in [3], the class label of each testing trial is first estimated. Then the trial is assigned to the estimated class to update its covariance matrix with a fixed weight, and CSP features are updated and reclassified. In a parametric model-based adaptive method [4], CSP features extracted from a testing trial are modelled by a two-component Gaussian mixture model (GMM). The expectation maximization (EM) algorithm is used to estimate class labels for testing trials. The classified trials showing high posterior class probabilities are added to the estimated class to update its covariance matrix and CSP features. This process is repeated multiple times until the overall change of class labels between two contiguous iterations is below a predefined threshold. In another adaptive method [7], an initial classification is first performed on a testing trial, and then the covariance matrix of the estimated class is updated based upon a weight calculated using the Kullback–Leibler divergence (KLD) between the training and testing trials. After updating the covariance matrix, CSP features are updated and reclassified. This process can be repeated multiple times. An initial classification is required in these methods to assign a testing trial to a class to update the class spatial covariance matrix. Ideally, if the new trial is from class y, then it should be similar to training trials from y in terms of feature variation, data distribution, or normalized spatial covariance matrix, and be correctly classified by a classifier. Due to EEG nonstationarity, however, the expected similarity may not be apparent, and it is possible that the new data is more similar to training data of the opposite class. If the new trial is mis-classified, the spatial filters updated based on the erroneous classification could affect the BCI classification. In this work, a different way to perform the ACSP learning is proposed. Instead of estimating class labels for new EEG trials, a similarity measure between new and training data in each class is calculated, and spatial filters of both classes are simultaneously updated based on the similarity measure. Three different similarity measures are used based upon which the ACSP method is developed. The details of the proposed method are described as follows.Given a new EEG trial from a target subject with an unknown class label and a normalized spatial covariance matrixCnew, the following method is proposed to calculate the new class covariance matrices:(6)C¯1=ϕ1n1+sgn(ϕ1)Cnew+n1n1+sgn(ϕ1)C1,C¯2=ϕ2n2+sgn(ϕ2)Cnew+n2n2+sgn(ϕ2)C2,where n1 and n2 are numbers of training trials from classes 1 and 2, respectively.ϕ1≥0andϕ2≥0are two measures that quantify the similarity between the target and training data in the two classes, and need to be estimated. sgn(x) is the sign function that equals to 1 ifx>0, and equals to 0 if x=0. Three different similarity measures are used to estimate ϕy,y∈{1,2}.When a new EEG trial is projected onto existing spatial filters of the two classes using Eq. (4), the feature variance xris computed using (5). ϕyis calculated as the ratio of the sum of feature variance in class y to the overall feature variance of the two classes:(7)ϕy=∑r(xry)∑r(xr1)+∑r(xr2),where xr1 is computed from the first rth row of the feature projection on W, xr2 is from the last rth row of the feature projection, and xryis the rth feature in class y. The feature variance defined in (5) was originally proposed as a primary CSP-based feature for BCI classification, where a class with a greater projected feature variance has a higher possibility to be the true motor imagery class. Therefore, it may be used as a similarity indicator between training and target data, based upon which a weight parameter can be derived to update the class covariance matrices.KLD is a distance measure between two probability distributions, and used to quantify the similarity between distributions of target and training data. If EEG data in each trial are normalized to zero mean and standard deviation, then we may assume that EEG data follow a zero mean M-dimensional multivariate Gaussian distribution, where M is the number of EEG channels. The probability distributions of a new target EEG trial and training data are represented asfnew=N(0,Cnew)andfy=N(0,Cy), respectively. The KLD between fnewand fyis calculated as:(8)KL(fnew,fy)=12{tr(Cy−1Cnew)−log[det(Cnew)det(Cy)]−M},wheredet()is the determinant operator, andy∈{1,2}. Since KLD is not a symmetric distance measure,KL(fnew,fy)≠KL(fy,fnew). KLD can be symmetrized by addingKL(fnew,fy)andKL(fy,fnew)together:(9)KLD(fnew,fy)=12[KL(fnew,fy)+KL(fy,fnew)]The parameter ϕyis computed as:(10)ϕy=1−KLD(fnew,fy)KLD(fnew,f1)+KLD(fnew,f2).IfCnewis not from class y, theoretically the value ofKLD(fnew,fy)/(KLD(fnew,f1)+KLD(fnew,f2))is relatively large, resulting in a small ϕy. On the contrary, a large ϕywill be obtained to assign a greater weight toCnew.Frobenius norm (FN) is a matrix norm defined as the square root of the sum of the absolute squares of its elements. It can be used to measure the distance between two matrices. In this work, FN is used to estimate the similarity betweenCnewandCy:(11)FN(Cnew,Cy)=∑i,j[Cnew(i,j)−Cy(i,j)]2.The parameter ϕyis estimated using(12)ϕy=1−FN(Cnew,Cy)FN(Cnew,C1)+FN(Cnew,C2).IfCnewis not from class y, theoretically the difference betweenCnewandCyis greater than the case thatCnewis from class y, resulting in a small ϕy. Contrarily, a large ϕywill be assigned toCnew.ϕ1 and ϕ2 can be estimated by using one of the three similarity measures. After calculatingC¯yusing (6), the remaining steps are the same as the CSP method to obtain updated spatial filters for feature extraction.It can be observed from (6) that the weights forCyandCneware also related to the number of training trials. More training trials lead to less weights for the target data. A greater number of training trials means a higher opportunity to provide more prior information about target subjects, and consequently a lower chance that the new trial may exhibit considerably different patterns. When the number of training trials is large, the weights assigned toCneware relatively small, and have a slight effect on the overall covariance matrices. However, such small variation may result in a significant change of feature distribution and final classification results. It was confirmed by the experimental results of this study.The proposed ACSP method is equivalent to a simplified EM algorithm [44,45], where the EEG data is characterized by a zero-mean two-component multivariate GMM. The two components correspond to the two classes in CSP. The probability of each component is approximated using the weights ofCnewandCyshown in (6) (the E-step), and the covariance matrix of each component is estimated using the weighted average ofCnewandCy(the M-step). To facilitate the real-time processing, no iteration between the E-step and the M-step is performed. The proposed method is quite different from another EM-based approach described previously [4], where the GMM is used to model CSP features instead of EEG data, and a decision of class label is made in each EM iteration. By assigning partial membership to each target EEG trial, it is expected that the proposed ACSP method can adapt to intra- and inter-subject variation and provide a better learning performance than the classic CSP method.In the following sections, the ACSP implementation using the feature variance-based distance is called ACSP-Ia, the one using the symmetrized KLD is named ACSP-Ib, and the other using FN is denoted as ACSP-Ic. Although different similarity measures could be used, the proposed ACSP can be implemented following a general procedure:•Step 1: A spatial filter W is computed using the classic CSP with EEG training data.Step 2: Input a new EEG trial from a target subject.Step 3: ACSP-Ia: Compute feature projection of the new data on W using (4) and (5). ACSP-Ib and -Ic: Compute the covariance matrixCnewof the new data, and the KLD or FN betweenCnewandCy,y∈{1,2}using (9) or (11).Step 4: Estimate ϕ1 and ϕ2 using (7) (ACSP-Ia), or (10) (ACSP-Ib), or (12) (ACSP-Ic).Step 5: ComputeC¯1andC¯2using (6), and update the spatial filter W. Project the target and training data onto the updated W and extract features using (4) and (5).Step 6: Features extracted from the training data are used to train/retrain a data classifier to classify features extracted from the target data.Step 7: Go to Step 2 for the next target trial.In existing ACSP studies [3,7,4], classified target trials are added to training data to improve the CSP learning performance. This procedure is denoted as accumulative ACSP in this work. On the contrary, non-accumulative ACSP does not include classified trials to update the training data. The proposed ACSP method can be implemented in the accumulative or non-accumulative way, and we examined both cases in the experiments. For the accumulative ACSP, we examined two different implementations. The first is to add classified target trials to training data of the estimated class, and the update of spatial covariance matrix is class-specific. The second implementation is to updateC1andC2toC¯1andC¯2using (6) after the classification. This is equivalent to add target trials to training data of both classes with the weights shown in (6). The first class-specific accumulative implementation is denoted as “ACCU-1” in the experimental study, and the second implementation that updates spatial filters for both classes is called “ACCU-2”. In the non-accumulative ACSP, classified trials are not added to training data, and as a result,C1andC2are not updated toC¯1andC¯2after the classification of each target trial althoughC¯1andC¯2are computed during the ACSP learning.Intuitively, the accumulative ACSP would outperform the non-accumulative one because previous studies have shown improvements induced by including target subjects׳ data into the CSP training. This is usually true if there is a feedback loop or “ground truth” to know true class labels of target trials. However, if the true class label is not instantly available in real-time BCI applications, mis-classified target trials will be added to training data of a wrong class and affect the CSP learning and final classification. The non-accumulative ACSP does not add classified trials to the training data, and would be an alternative option to the accumulative one if it outperforms the accumulative ACSP in this situation. A comparison study was performed between the non-accumulative and accumulative ACSP and the results are reported in Section 3.

@&#CONCLUSIONS@&#
