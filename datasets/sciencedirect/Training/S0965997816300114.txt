@&#MAIN-TITLE@&#
Study on the reconstruction method of stereo vision in glass flume

@&#HIGHLIGHTS@&#
A new 3D reconstruction method with refraction revision is proposed for the experiments in glass flume.The revision process for refraction distortion only need to know few parameters and no additional equipment is required.In the proposed method, the camera calibration need not be operated in water and this method is simple to apply.

@&#KEYPHRASES@&#
Stereo vision,Three-dimensional reconstruction,Underwater positioning,Distortion correction,Light refraction,Flume experiment,

@&#ABSTRACT@&#
In three-dimensional reconstruction experiments based on stereo vision theory in a glass flume, there is usually more than one medium in the travel path of the light, such as air, glass and water. These media not only degrade image quality, but also change the light route. Large errors are generated if the effects of these media are ignored. To solve the problems of media effects, a new method of object reconstruction for the glass flume is proposed, based on computer vision theory and laws of refraction. Firstly, the light refraction effects are analyzed and a coordinate correction formula is developed. Secondly, correction parameters are obtained based on a stereo vision method to correct the coordinates of a target point. Finally, model experiments in glass flume are described and the errors are analyzed. The experimental results show that the proposed method is effective in correcting refraction distortion, and improves the accuracy of three-dimensional reconstruction of target points.

@&#INTRODUCTION@&#
Measurement methods based on computer vision are untouched measurement techniques with high accuracy. These forms of measurement mainly rely on the methods of digital image analysis, which make it suitable for glass flume model experiments. Thus, they have been widely used in the ocean engineering field. Many experiments have been made in glass flumes in recent years – for example, for vision techniques that locate the accurate positions of moving objects, and to study the deformation of structures. These applications include six degrees-of-freedom (6-DOF) motion measurement, particle image velocimetry (PIV) and particle tracking velocimetry (PTV), among others. Many related studies have been reported in the literature [1–7].However, the media effect is usually ignored in research and applied procedures. This factor is negligible for experiments conducted in air, but is significant for experiments in a glass flume. When cameras outside the flume take photographs of the target objects, the light travels through at least three media: air, water and glass. Since these affect the geometrical relationships of the image, the reconstruction methods differ from those used for experiments in air [8–10]; however, few studies of this problem have been reported.In some flume experiments, the optical axis of the camera is perpendicular to the glass flume, and refraction is ignored or regarded as optical distortion in the calculations. This approach is usually used in PIV and PTV exiperiments. The approach utilizes the vertical imaging principle and computation is mature in camera calibration, but the measurement result is valid only for a small-scale field.In other experiments, in order to make camera position flexible, an optical prism is used to correct refraction distortion without changing the calculation process. When measuring objects in this way, different experiments may need different prisms, making the operation very complicated and more costly. Refractive index matching is used for distortion correction in some experiments [11,12], most commonly in microscope-based analysis; due to the cost problem and amount of disturbance, however, this approach is difficult to apply to large-scale measurements and these physical methods may limit the application scope of vision technology.To date, no appropriate method is available for reconstructing target objects in a glass flume. In this work, we improve the experimental convenience through changing the vision reconstruction algorithms. Firstly, we examine the refraction routes of reconstruction experiments in a flume, then derive the geometrical relationship between the true position and the pseudo-position of an object. A new reconstruction method for flume experiments is also proposed based on stereo vision theory. The last part of the paper describes model experiments designed to evaluate the performance of the proposed algorithm.To derive the 3D coordinates of an object using vision theory, images are captured by two cameras at different viewing angles to the object. In Fig. 1, P(X, Y, Z) is a point in space; subscripts l and r indicate left and right view; pland prand are image points of P in different image planes; and Oland Orare the optical centers of the two cameras. Target P is located at the intersection of projected lines Olpland Orpr.To calculate the coordinates of P, the cameras must first be calibrated to determine the necessary intrinsic and extrinsic parameters [13]. The relationship between the 3D point P and its projection p(u, v) in the image coordinate system is given by(1)s[uv1]=[αγu000βv000010][RT01][XYZ1],where s is an arbitrary scale factor. The first matrix on the right-hand side is the camera intrinsic matrix in which (u0, v0) are the coordinates of the principal point; α and β are the scale factors on the image u and v axes; and γ is a parameter describing the skewness of the two image axes. The middle matrix on the right-hand side is the camera extrinsic matrix, in which R and T are the rotation and translation which relate the world coordinate system to the camera coordinate system.In practice, especially using industrial cameras, γ in Eq. (1) is usually ignored. The camera parameter matrix M is defined as Eq. (2):(2)M=[m11m12m13m14m21m22m23m24m31m32m33m34]=[f/Sx0u000f/Syv000010][RT01].In Eq. (2), f is the focal length; Sxand Syare the pixel dimensions of two axes. For a point pair in different images, the relationship between 2D points and their corresponding 3D points is expressed as(3){m11lX+m12lY+m13lZ+m14l−m31lulX−m32lulY−m33lulZ=ulm34lm21lX+m22lY+m23lZ+m24l−m31lvlX−m32lvlY−m33lvlZ=vlm34lm11rX+m12rY+m13rZ+m14r−m31rurX−m32rurY−m33rurZ=urm34rm21rX+m22rY+m23rZ+m24r−m31rvrX−m32rvrY−m33rvrZ=vrm34r,where l and r are defined as above.To ensure that the flow field is not disturbed, the cameras must be outside the flume; the image light will then pass through air, glass and water. The light path in the experiment is shown in Fig. 2.In Fig. 2, Olis the optical center of the left-hand camera; Oris the optical center of the right-hand camera; h is the distance between the left-hand optical center and the glass surface of the flume; d is the thickness of the glass; pland prare the image points of P in the left-hand and right-hand images; P′ is the point reconstructed from pland pr; λ and η are the outer and inner surfaces of the glass; A1, A2, C1, C2 are the intersections of the image light and glass surface; and l1,l1′,l1′′, l2, l3,l3′,l3′′are lines normal to the glass.Because of refraction effects, P and P′ are not the same points. The refractive indices of air, glass and water are nair, nglassand nwater, where nair(1.0003) < nglass(1.3333) < nwater(1.5000). Thus P′ is closer to the observation position thanP. In order to determine the true position P, the pseudo-position P′ must be modified.Firstly, the glass thickness is assumed to be fixed. A parallel relationship λ//η is defined in Fig. 2. P and P′ are collinear according to their geometrical relationship, which is simply proved as follows:∵P ∈ [OlA1B1C1],  P′ ∈ [OlA1B1C1],  P ∈ [OrA2B2C2],  P′ ∈ [OrA2B2C2] and [OlA1B1C1]⊥λ,  [OrA2B2C2]⊥λ,  P ∈ l2,  l2⊥λ∴P′ ∈ l2. So P and P′ are collinear in l2.To deduce the correction formula, the coordinate system is then defined with thex−yplane on the glass surface. Let Ol(X0, Y0, Z0) be the optical center of left-hand camera; P(X, Y, Z) is the real position of the target; P′(Xw, Yw, Zw) is its pseudo-position. In Fig. 2, the relationshipsX=XwandY=Yware readily found. In addition, Eq. (4) is deduced from the geometrical relationship in Fig. 2:(4)Z−h−d=((Xw−x0)2+(Yw−y0)2−h·tgα−d·tgβ)·ctgγ.Defining therefractive ratios as n1 and n2, withn1=sinα/sinβ,n2=sinβ/sinγ, we can obtain the equations from Eq. (5) to Eq. (7):(5)tgα=(Xw−X0)2+(Yw−Y0)2/(Zw−Z0),(6)tgβ=sinα/n12−sin2α,(7)ctgγ=n12·n22−sin2α/sinα.Combined with Eq. (4), these give the correction equation(8)Z=h+d+(Xw−X0)2+(Yw−Y0)2·n12n22−sin2αsinα−h·n12n22−sin2αcosα−d·n12n22−sin2αn12−sin2α.Ifn1=n2=1,Z=Zw−Z0in Eq. (8), the coordinates of the target object in water are not affected when the image system and target objects are both in the same medium. Furthermore, if these parameters (e.g., distance between optical center and glass surface, thickness of glass, refractive index) are already known, the true position of a target point in the glass flume is computed accurately.Suppose two cameras in a binocular vision system are placed outside the flume (Fig. 3) and the target objects are under water. Three reference points are marked on the outer surface of the glass wall of the flume (the red dots in Fig. 3) to correct the coordinate system and calculate the distance between optical center and the glass.The procedure is:(1)The cameras are calibrated in air to determine their intrinsic and extrinsic parameters. Then, if the object is also in air, the position of the object is calculated from Eq. (3). The extrinsic parameters of the left-hand and right-hand cameras are referred to as Rl, Tland Rr, Tr. The optical center of the left-hand camera is POL.Provided the signature dots P1, P2, P3 are not collinear, their positions may be found from Eq. (3), and the distance h between the glass surface containing P1, P2, P3 and POLis obtained.After vision calibration, the world coordinate system is usually not satisfied with the requirements of Eq. (8). So the original coordinate system must be revised. The glass surface containing P1, P2, P3 is taken as thex−yplane. In this reference system, suppose the new coordinates ofPi(i=1,2,3)arePi′(i=1,2,3). The relationship between PiandPi′is expressed as Eq. (9):(9)Pi′=Rt·Pi+Tt,(i=1,2,3),where Rtand Ttare the rotation matrix and translation matrix relating the original coordinate system to the new coordinate system.The origin of the measurement coordinate system is now moved to the optical center Olof the left-hand camera. The media refraction ratios n1 and n2 are calculated and the glass thickness d must be known. The geometrical relationship is shown in Fig. 2.In the new coordinate system, the rotation matrix of the left-hand camera is RtRland the translation matrix is null. The new rotation matrix of the right-hand camera is RtRrand the translation matrix isRtTr+RtRrPOL.Utilizing the extrinsic parameters and the intrinsic parameters of the cameras, the pseudo-position P′(Xw, Yw, Zw) is readily obtained (Fig. 2).In Fig. 2, the angle α is given byα=arctg(Xw2+Yw2/Zw).After steps (1)–(7), the coordinates (X, Y, Z) of Pare corrected by Eq. (8), giving the revised equations(10){X=XwY=YwZ=h+d+Xw2+Yw2·n12n22−sin2asina−h·n12n22−sin2acosa−d·n12n22−sin2an12−sin2aIn short, the cameras are calibrated first, then the correction parameters in Eq. (8) are computed, and finally the position of the target object is obtained from Eq. (10).In this section, the proposed method is evaluated under the real experimental conditions shown in Fig. 4. Two cameras (model JAI CM-140CL) were placed outside the flume. The glass was 8mm thick. Three reference points marked on the glass surface formed a right triangle (shown as red circles in Fig. 4). The water was 1m deep. Target objects with red LEDs were placed in the water. During the experiment, the object was moved by a stepmotor in 10mm steps.Following the procedure set out in Section 5, the cameras were calibrated, then the parameters used in Eq. (10) were computed step by step. The distance between the optical center of the left-hand camera and the glass surface was calculated to be 63.29cm. The refraction indices of air, glass and water were taken to be 1.0, 1.3 and 1.5, respectively. During the experiment, the target objects always moved along a route perpendicular to the surface of the flume. The original distance between object and glass was 10cm. The target object was able to move only a total distance of 80cm due to the limited size of the flume.Fig. 5 shows the changes of X- and Y-axis coordinates of the three LEDs on the target object. We see that the positions of the LEDs in the x–y plane are fixed, but the object moves; thus the object positions in the x–y plane are not disturbed by media refraction. However, the geometrical relationship in Fig. 2 shows that the coordinates change along the Z-axis.The Z coordinates of the LEDs are shown in Fig. 6, in which the ‘*’ symbols represent the reconstruction results from Eq. (3), and the ‘o’ symbols represent the revised reconstruction results from Eq. (10).Fig. 6 shows that the revised coordinates along the Z-axis are larger than reconstruction results and the differences of the Z coordinates before and after correction increase as the distance between the object and the glass increases. To test the effect of the coordinate corrections, Fig. 7 shows the differences between the adjacent positions in Fig. 6. Meanwhile, comparing the data in Fig. 7 with the standard step of 10mm, the percent root-mean-square difference (PRD) is used to evaluate experimental results. PRD is defined by Eq. (11):(11)PRD=∑i=1N(dorg(i)−drec(i))2/∑i=1Ndorg2(i)×100%,where dorgis the original data and drecis the experimental data; N is the number of sample points. Table 1indicates the comparison results computed by PRD. From Fig. 7 and Table 1, it is concluded that the revised values of the coordinates is much closer to the true value, meaning that the proposed method succeeds in reducing refraction distortion in flume experiments.

@&#CONCLUSIONS@&#
