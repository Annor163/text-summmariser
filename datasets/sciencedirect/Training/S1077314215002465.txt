@&#MAIN-TITLE@&#
Tensor low-rank and sparse light field photography

@&#HIGHLIGHTS@&#
We present a computational camera system for efficient light field image and video acquisition.Our mathematical framework models the intrinsic low dimensionality of light fields using tensor low-rank and sparse priors.We design and implement a prototype compressive light field camera that avoids capturing redundancy of high-dimensional plenoptic function.

@&#KEYPHRASES@&#
Computational photography,Low-rank tensor factorization,Low-rank and sparse decomposition,Compressive sensing,

@&#ABSTRACT@&#
High-quality light field photography has been one of the most difficult challenges in computational photography. Conventional methods either sacrifice resolution, use multiple devices, or require multiple images to be captured. Combining coded image acquisition and compressive reconstruction is one of the most promising directions to overcome limitations of conventional light field cameras. We present a new approach to compressive light field photography that exploits a joint tensor low-rank and sparse prior (LRSP) on natural light fields. As opposed to recently proposed light field dictionaries, our method does not require a computationally expensive learning stage but rather models the redundancies of high dimensional visual signals using a tensor low-rank prior. This is not only computationally more efficient but also more flexible in that the proposed techniques are easily applicable to a wide range of different imaging systems, camera parameters, and also scene types.

@&#INTRODUCTION@&#
One of the main goals of computational photography is to design camera systems which record visual information that can be processed so as to facilitate new imaging modalities. Examples of such modalities include motion deblurring, extended depth of field as well as multi-spectral and light field imaging. It could be argued that an “ultimate” computational camera would capture all visual information so as to allow for the most general processing algorithms to be applied after the fact.The plenoptic function [1] was introduced as a ray-based model for light that encompasses all visual information: spatial, angular, and temporal light variation as well as the color spectrum. So what makes it hard to design a camera that captures the plenoptic function in a single image? The shear amount of required plenoptic samples make this a “big data” problem with extreme challenges for camera optics, sensor electronics, and computation. Consider the example of a light field video recorded at 30 Hz, with 11.1 Megapixel resolution, 10 × 10 angular samples, and three color channels—about 100 billion light rays (∼100 GB of raw data) have to be recorded, processed, and stored per second. Clearly, camera technology today is not suited for this task.However, high-dimensional visual signals are highly redundant. Compression algorithms, for instance, exploit this fact to minimize the memory footprint of images and videos. Moreover, recent proposals have shown that images [2], videos [3], and light fields [4] can be recovered from only a few measurements using sparsity-constrained optimization. In this paper, we present a new mathematical framework for efficient high-dimensional visual signal processing, acquisition, and storage. We demonstrate that there is a large amount of correlation between the dimensions of time-varying light fields, which can be exploited by a low-rank prior applied to the five-dimensional tensor space containing spatial, temporal, and angular light variation. This prior is a good model for exploiting view-independent and slow-moving scene parts whereas an additional sparse term captures view-dependent effects and fast motions.We also propose a light field camera design that is well-suited for capturing coded projections of the plenoptic function that can be reconstructed by the proposed algorithms. In contrast to existing, dictionary-based light field capture systems [4], our tensor low-rank and sparse light field recovery does not require a learning phase, which is computationally expensive (tens to hundreds of hours). Further, the LRSP prior is flexible enough to be applied to a wide range of scenes and optical systems. In particular, we make the following contributions:•We present a computational camera system for light field image and video capture that facilitates efficient acquisition without a dictionary learning phase.We introduce a mathematical framework that models intrinsic low-dimensionality of light fields using tensor low-rank and sparse priors. We show that this model captures redundancy in the high-dimensional plenoptic function well and allows for new optical setups to be derived.We design and implement a prototype compressive light field camera that is evaluated both by simulation and experiments.

@&#CONCLUSIONS@&#
