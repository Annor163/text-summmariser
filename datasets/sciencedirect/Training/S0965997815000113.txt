@&#MAIN-TITLE@&#
The Ant Lion Optimizer

@&#HIGHLIGHTS@&#
The Ant Lion Optimizer inspired by the hunting mechanism of antlions is proposed.The ALO algorithm is benchmarked on 29 well-known test functions.The results on the unimodal functions show the superior exploitation of ALO.The exploratory ability of ALO is confirmed by the results on multimodal functions.The results on real problems confirm the performance of ALO in practice.

@&#KEYPHRASES@&#
Optimization,Benchmark,Constrained optimization,Particle swarm optimization,Algorithm,Heuristic algorithm,Genetic algorithm,

@&#ABSTRACT@&#
This paper proposes a novel nature-inspired algorithm called Ant Lion Optimizer (ALO). The ALO algorithm mimics the hunting mechanism of antlions in nature. Five main steps of hunting prey such as the random walk of ants, building traps, entrapment of ants in traps, catching preys, and re-building traps are implemented. The proposed algorithm is benchmarked in three phases. Firstly, a set of 19 mathematical functions is employed to test different characteristics of ALO. Secondly, three classical engineering problems (three-bar truss design, cantilever beam design, and gear train design) are solved by ALO. Finally, the shapes of two ship propellers are optimized by ALO as challenging constrained real problems. In the first two test phases, the ALO algorithm is compared with a variety of algorithms in the literature. The results of the test functions prove that the proposed algorithm is able to provide very competitive results in terms of improved exploration, local optima avoidance, exploitation, and convergence. The ALO algorithm also finds superior optimal designs for the majority of classical engineering problems employed, showing that this algorithm has merits in solving constrained problems with diverse search spaces. The optimal shapes obtained for the ship propellers demonstrate the applicability of the proposed algorithm in solving real problems with unknown search spaces as well. Note that the source codes of the proposed ALO algorithm are publicly available at http://www.alimirjalili.com/ALO.html.

@&#INTRODUCTION@&#
In recent years metaheuristic algorithms have been used as primary techniques for obtaining the optimal solutions of real engineering design optimization problems [1–3]. Such algorithms mostly benefit from stochastic operators [4] that make them distinct from deterministic approaches. A deterministic algorithm [5–7] reliably determines the same answer for a given problem with a similar initial starting point. However, this behaviour results in local optima entrapment, which can be considered as a disadvantage for deterministic optimization techniques [8]. Local optima stagnation refers to the entrapment of an algorithm in local solutions and consequently failure in finding the true global optimum. Since real problems have extremely large numbers of local solutions, deterministic algorithms lose their reliability in finding the global optimum.Stochastic optimization (metaheuristic) algorithms [9] refer to the family of algorithms with stochastic operators including evolutionary algorithms [10]. Randomness is the main characteristic of stochastic algorithms [11]. This means that they utilize random operators when seeking for global optima in search spaces. Although the randomised nature of such techniques might make them unreliable in obtaining a similar solution in each run, they are able to avoid local solutions much easier than deterministic algorithms. The stochastic behaviour also results in obtaining different solutions for a given problem in each run [12].Evolutionary algorithms search for the global optimum in a search space by creating one or more random solutions for a given problem [13]. This set is called the set of candidate solutions. The set of candidates is then improved iteratively until the satisfaction of a terminating condition. The improvement can be considered as finding a more accurate approximation of the global optimum than the initial random guesses. This mechanism brings evolutionary algorithms several intrinsic advantages: problem independency, derivation independency, local optima avoidance, and simplicity.Problem and derivation independencies originate from the consideration of problems as a black box. Evolutionary algorithms only utilize the problem formulation for evaluating the set of candidate solutions. The main process of optimization is done completely independent from the problem and based on the provided inputs and received outputs. Therefore, the nature of the problem is not a concern, yet the representation is the key step when utilizing evolutionary algorithms. This is the same reason why evolutionary algorithms do not need to derivate the problem for obtaining its global optimum.As another advantage, local optima avoidance is high due the stochastic nature of evolutionary algorithms. If an evolutionary algorithm is trapped in a local optimum, stochastic operator lead to random changes in the solution and eventually escaping from the local optimum. Although there is no guarantee for resolving this issue completely, stochastic algorithms have much higher probability to escape from local optima compared to deterministic methods. A very accurate approximation of the global optimum is not guaranteed as well, but with running an evolutionary algorithm several times the probability of obtaining a better solution is increased.Last but not least, the simplicity is another characteristic of evolutionary algorithms. Natural evolutionary concepts or collective behaviours are the main inspirations for the majority of algorithms in this field where they are so simple. In addition, evolutionary algorithms follow a general and common framework, in which a set of randomly created solutions is enhanced or evolved iteratively. What makes algorithms different in this field is the method of improving this set.Some of the most popular algorithms in this field are: Genetic Algorithms (GA) [14,15], Particle Swarm Optimization (PSO) [16], Ant Colony Optimization (ACO) [17], Differential Evolution (DE) [18], Evolutionary Programming (EP) [19][20]. Although these algorithms are able to solve many real and challenging problems, the so-called No Free Lunch theorem [21] allows researchers to propose new algorithms. According to this theorem, all algorithms perform equal when solving all optimization problems. Therefore, one algorithm can be very effective in solving one set of problems but in effective on a different set of problems. This is the foundation of many works in this field. Some of the recent algorithms are: Grey Wolf Optimizer (GWO) [22], Artificial Bee Colony (ABC) algorithm [23], Firefly Algorithm (FA) [24,25], Cuckoo Search (CS) algorithm [26,27], Cuckoo Optimization Algorithm (COA) [28], Gravitational Search Algorithm (GSA) [29], Charged System Search (CSS) [30–33], Magnetic Charged System Search [34,35], Ray Optimization (RO) [36–38] algorithm, Colliding Bodies Optimization (CBO) [39–44] algorithm, Hybrid Particle Swallow Swarm Optimization (HPSSO) [45], Democratic Particle Swarm Optimization (DPSO) [46,47], Dolphin Echolocation (DE) [48,49], and Chaotic Swarming of Particles (CSP) [50].This paper also proposes a new algorithm called Ant Lion Optimizer (ALO) as an alternative approach for solving optimization problems. As its name implies, the ALO algorithm mimics the intelligent behaviour of antlions in hunting ants in nature. The rest of the paper is organized as follows:Section 2 presents the main inspiration of this paper and proposes the ALO algorithm. Experimental results of the test functions are provided in Section 3. Sections 4 and 5 solve several real problems to demonstrate the applicability of the proposed algorithm. Finally, Section 6 concludes the work and discusses possible future research.In this section the inspiration of the ALO algorithm is first presented. The mathematical model and the ALO algorithm are then discussed in details.Antlions (doodlebugs) belong to the Myrmeleontidae family and Neuroptera order (net-winged insects). The lifecycle of antlions includes two main phases: larvae and adult. A natural total lifespan can take up to 3years, which mostly occurs in larvae (only 3–5weeks for adulthood). Antlions undergo metamorphosis in a cocoon to become adult. They mostly hunt in larvae and the adulthood period is for reproduction.Their names originate from their unique hunting behaviour and their favourite prey. An antlion larvae digs a cone-shaped pit in sand by moving along a circular path and throwing out sands with its massive jaw [51,52]. Fig. 1(a) shows several cone-shaped pits with different sizes. After digging the trap, the larvae hides underneath the bottom of the cone (as a sit-and-wait predator [53]) and waits for insects (preferably ant) to be trapped in the pit [53] as illustrated in Fig. 1(b). The edge of the cone is sharp enough for insects to fall to the bottom of the trap easily. Once the antlion realizes that a prey is in the trap, it tries to catch it. However, insects usually are not caught immediately and try to escape from the trap. In this case, antlions intelligently throw sands towards to edge of the pit to slide the prey into the bottom of the pit. When a prey is caught into the jaw, it is pulled under the soil and consumed. After consuming the prey, antlions throw the leftovers outside the pit and amend the pit for the next hunt.Another interesting behaviour that has been observed in life style of antlions is the relevancy of the size of the trap and two things: level of hunger and shape of the moon. Antlions tend to dig out larger traps as they become more hungry [54] and/or when the moon is full [55]. They have been evolved and adapted this way to improve their chance of survival. It also has been discovered that an antlion does not directly observe the shape of the moon to decide about the size of the trap, but it has an internal lunar clock to make such decisions [55].The main inspiration of the ALO algorithm comes from the foraging behaviour of antlion’s larvae. In the next subsection the behaviour of antlions and their prey in nature is first modelled mathematically. An optimization algorithm is then proposed based on the mathematical model.The ALO algorithm mimics interaction between antlions and ants in the trap. To model such interactions, ants are required to move over the search space, and antlions are allowed to hunt them and become fitter using traps. Since ants move stochastically in nature when searching for food, a random walk is chosen for modelling ants’ movement as follows:(2.1)X(t)=[0,cumsum(2r(t1)-1),cumsum(2r(t2)-1),…,cumsum(2r(tn)-1)]where cumsum calculates the cumulative sum, n is the maximum number of iteration, t shows the step of random walk (iteration in this study), and r(t) is a stochastic function defined as follows:(2.2)r(t)=1ifrand>0.50ifrand⩽0.5where t shows the step of random walk (iteration in this study) and rand is a random number generated with uniform distribution in the interval of [0,1].To have an image of this random walk, Fig. 2is provided that illustrates three random walks over 500 iterations. This figure shows that the random walk utilized may fluctuate dramatically around the origin (red1For interpretation of color in Fig. 2, the reader is referred to the web version of this article.1curve), have increasing trend (black curve), or have descending behaviour (blue curve).The position of ants are saved and utilized during optimization in the following matrix:(2.3)MAnt=A1,1A1,2……A1,dA2,1A2,2……A2,d::::::::::An,1An,2……An,dwhere MAntis the matrix for saving the position of each ant, Ai,jshows the value of the j-th variable (dimension) of i-th ant, n is the number of ants, and d is the number of variables.It should be noted that ants are similar to particles in PSO or individuals in GA. The position of an ant refers the parameters for a particular solution. Matrix MAnthas been considered to save the position of all ants (variables of all solutions) during optimization.For evaluating each ant, a fitness (objective) function is utilized during optimization and the following matrix stores the fitness value of all ants:(2.4)MOA=f[A1,1,A1,2,…,A1,d]f[A2,1,A2,2,…,A2,d]::f[An,1,An,2,…,An,d]where MOAis the matrix for saving the fitness of each ant, Ai,jshows the value of j-th dimension of i-th ant, n is the number of ants, and f is the objective function.In addition to ants, we assume the antlions are also hiding somewhere in the search space. In order save their positions and fitness values, the following matrices are utilized:(2.5)MAntlion=AL1,1AL1,2……AL1,dAL2,1AL2,2……AL2,d::::::::::ALn,1ALn,2……ALn,dwhere MAntlionis the matrix for saving the position of each antlion, ALi,jshows the j-th dimension’s value of i-th antlion, n is the number of antlions, and d is the number of variables (dimension).(2.6)MOAL=f([AL1,1,AL1,2,…,AL1,d])f([AL2,1,AL2,2,…,AL2,d])::f([ALn,1,ALn,2,…,ALn,d])where MOALis the matrix for saving the fitness of each antlion, ALi,jshows the j-th dimension’s value of i-th antlion, n is the number of antlions, and f is the objective function.During optimization, the following conditions are applied:•Ants move around the search space using different random walks.Random walks are applied to all the dimension of ants.Random walks are affected by the traps of antlions.Antlions can build pits proportional to their fitness (the higher fitness, the larger pit).Antlions with larger pits have the higher probability to catch ants.Each ant can be caught by an antlion in each iteration and the elite (fittest antlion).The range of random walk is decreased adaptively to simulate sliding ants towards antlions.If an ant becomes fitter than an antlion, this means that it is caught and pulled under the sand by the antlion.An antlion repositions itself to the latest caught prey and builds a pit to improve its change of catching another prey after each hunt.Random walks are all based on the Eq. (2.1). Ants update their positions with random walk at every step of optimization. Since every search space has a boundary (range of variable), however, Eq. (2.1) cannot be directly used for updating position of ants. In order to keep the random walks inside the search space, they are normalized using the following equation (min–max normalization):(2.7)Xit=Xit-ai×di-citdit-ai+ciwhere aiis the minimum of random walk of i-th variable, biis the maximum of random walk in i-th variable,citis the minimum of i-th variable at t-th iteration, andditindicates the maximum of i-th variable at t-th iteration.Eq. (2.7) should be applied in each iteration to guarantee the occurrence of random walks inside the search space.As discussed above, random walks of ants are affected by antlions’ traps. In order to mathematically model this assumption, the following equations are proposed:(2.8)cit=Antlionjt+ct(2.9)dit=Antlionjt+dtwhere ctis the minimum of all variables at t-th iteration, dtindicates the vector including the maximum of all variables at t-th iteration,cjtis the minimum of all variables for i-th ant,djtis the maximum of all variables for i-th ant, andAntlionjtshows the position of the selected j-th antlion at t-th iteration.Eqs. (2.8) and (2.9) show that ants randomly walk in a hyper sphere defined by the vectors c and d around a selected antlion. A conceptual model of this behaviour is illustrated in Fig. 3.Fig. 3 shows a two-dimensional search space. It may be observed that ants are required to move within a hypersphere around a selected antlion.In order to model the antlions’s hunting capability, a roulette wheel is employed. As Fig. 3 show ants are assumed to be trapped in only one selected antlion. The ALO algorithm is required to utilize a roulette wheel operator for selecting antlions based of their fitness during optimization. This mechanism gives high chances to the fitter antlions for catching ants.With the mechanisms proposed so far, antlions are able to build traps proportional to their fitness and ants are required to move randomly. However, antlions shoot sands outwards the center of the pit once they realize that an ant is in the trap. This behaviour slides down the trapped ant that is trying to escape. For mathematically modelling this behaviour, the radius of ants’s random walks hyper-sphere is decreased adaptively. The following equations are proposed in this regard:(2.10)ct=ctI(2.11)dt=dtIwhere I is a ratio, ctis the minimum of all variables at t-th iteration, and dtindicates the vector including the maximum of all variables at t-th iteration.In Eqs. (2.10) and (2.11),I=10wtTwhere t is the current iteration, T is the maximum number of iterations, and w is a constant defined based on the current iteration (w=2 when t>0.1T, w=3 when t>0.5T, w=4 when t>0.75T, w=5 when t>0.9T, and w=6 when t>0.95T). Basically, the constant w can adjust the accuracy level of exploitation.Fig. 4also shows the decreasing behaviour using Eqs. (2.10) and (2.11). These equations shrink the radius of updating ant’s positions and mimics sliding process of ant inside the pits. This guarantees exploitation of search space.The final stage of hunt is when an ant reaches the bottom of the pit and is caught in the antlion’s jaw. After this stage, the antlion pulls the ant inside the sand and consumes its body. For mimicking this process, it is assumed that catching prey occur when ants becomes fitter (goes inside sand) than its corresponding antlion. An antlion is then required to update its position to the latest position of the hunted ant to enhance its chance of catching new prey. The following equation is proposed in this regard:(2.12)Antlionjt=Antitiff(Antit)>fAntlionjtwhere t shows the current iteration,Antlionjtshows the position of selected j-th antlion at t-th iteration, andAntitindicates the position of i-th ant at t-th iteration.Elitism is an important characteristic of evolutionary algorithms that allows them to maintain the best solution(s) obtained at any stage of optimization process. In this study the best antlion obtained so far in each iteration is saved and considered as an elite. Since the elite is the fittest antlion, it should be able to affect the movements of all the ants during iterations. Therefore, it is assumed that every ant randomly walks around a selected antlion by the roulette wheel and the elite simultaneously as follows:(2.13)Antit=RAt+REt2whereRAtis the random walk around the antlion selected by the roulette wheel at t-th iteration,REtis the random walk around the elite at t-th iteration, andAntitindicates the position of i-th ant at t-th iteration.With the proposed operators in the preceding subsections, the ALO optimization algorithm can now be defined. The ALO algorithm is defined as a three-tuple function that approximates the global optimum for optimization problems as follows:(2.14)ALO(A,B,C)where A is a function that generates the random initial solutions, B manipulates the initial population provided by the function A, and C returns true when the end criterion is satisfied. The functions A, B, and C are defined as follows:(2.15)∅→A{MAnt,MOA,MAntlion,MOAL}(2.16){MAnt,MAntlion}→B{MAnt,MAntlion}(2.17){MAnt,MAntlion}→C{true,false}where MAntis the matrix of the position of ants, MAntlionincludes the position of antlions, MOAcontains the corresponding fitness of ants, and MOALhas the fitness of antlions.The pseudo codes the ALO algorithm are defined as follows:Initialize the first population of ants and antlions randomlyCalculate the fitness of ants and antlionsFind the best antlions and assume it as the elite (determined optimum)whilethe end criterion is not satisfiedforevery antSelect an antlion using Roulette wheelUpdate c and d using equations Eqs.(2.10) and (2.11)Create a random walk and normalize it using Eqs.(2.1) and (2.7)Update the position of ant using(2.13)end forCalculate the fitness of all antsReplace an antlion with its corresponding ant it if becomes fitter (Eq. (2.12))Update elite if an antlion becomes fitter than the eliteend whileReturneliteThe Matlab codes for the overall framework of the ALO algorithm as well as the functions A and B are provided in Appendix A.1–A.3.In the ALO algorithm, the antlion and ant matrices are initialized randomly using the function A. In every iteration, the function B updates the position of each ant with respect to an antlion selected by the roulette wheel operator and the elite. The boundary of position updating is first defined proportional to the current number of iteration. The updating position is then accomplished by two random walks around the selected antlion and elite. When all the ants randomly walk, they are evaluated by the fitness function. If any of the ants become fitter than any other antlions, their positions are considered as the new positions for the antlions in the next iteration. The best antlion is compared to the best antlion found during optimization (elite) and substituted if it is necessary. These steps iterative until the function C returns false.The ALO algorithm is developed in Matlab and offered as an open-source optimization toolbox. The main user interface of this toolbox is illustrated in Fig. 5. The software designed allows users to define the number of search agents, maximum number of iterations, number of variables, upper bounds of variables, lower bounds of variables, and the name of the objective function easily. As shown in Fig. 5, these variables can be defined in the “parameters” section of the software. After defining the parameters, the problem starts to be optimized as soon as the user clicks on the “start optimization” button. The software then interactively draws the convergence curve (and history if chosen) and updates the obtained best optimum so far in the convergence curve section. Eventually, the information of the best obtained optimum is shown in the “final results” section. Note that the source codes of the ALO algorithm and the toolbox can be downloaded from http://www.alimirjalili.com/ALO.html or http://www.mathworks.com/matlabcentral/profile/authors/2943818-seyedali-mirjalili.Theoretically speaking, the proposed ALO algorithm is able to approximate the global optimum of optimization problems due to the following reasons:•Exploration of the search space is guaranteed by the random selection of antlions and random walks of ants around them.Exploitation of search space is guaranteed by the adaptive shrinking boundaries of antlions’ traps.There is high probability of resolving local optima stagnation due to the use of random walks and the roulette wheel.ALO is a population-based algorithm, so local optima avoidance is intrinsically high.Intensity of ants’ movement is adaptively decreased over the course of iterations, which guarantees convergence of the ALO algorithm.Calculating random walks for every ant and every dimension promotes diversity in the population.Antlions relocate to the position of best ants during optimization, so promising areas of search spaces are saved.Antlions guide ants towards promising regions of the search space.The best antlion in each iteration is saved and compared to the best antlion obtained so far (elite).The ALO algorithm has very few parameters to adjust.The ALO algorithm is a gradient-free algorithm and considers problem as a black box.In the next sections several test beds and real problems are employed to benchmark and confirm the performance of the ALO algorithm in solving optimization problems.

@&#CONCLUSIONS@&#
