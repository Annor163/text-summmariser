@&#MAIN-TITLE@&#
On correlated

@&#HIGHLIGHTS@&#
This paper studies the impact of correlation on the multitesting problem.An approximation for the distribution of the proportion rejections is provided. This approximation is used to develop multitesting adjusting procedures.The obtained results suggest that the proposed methodology gets a good compromise between Type I and Type II errors.

@&#KEYPHRASES@&#
False discovery rate,Multiplicity problem,SGoF strategy,Tail probability of proportion of false positives,z,-values,

@&#ABSTRACT@&#
Multiple-testing problems have received much attention. Different strategies have been considered in order to deal with this problem. The false discovery rate (FDR) is, probably, the most studied criterion. On the other hand, the sequential goodness of fit (SGoF), is a recently proposed approach. Most of the developed procedures are based on the independence among the involved tests; however, in spite of being a reasonable proviso in some frameworks, independence is not realistic for a number of practical cases. Therefore, one of the main problems in order to develop appropriate methods is, precisely, the effect of the dependence among the different tests on decisions making. The consequences of the correlation on the z-values distribution in the general multitesting problem are explored. Some different algorithms are provided in order to approximate the distribution of the expected rejection proportions. The performance of the proposed methods is evaluated in a simulation study in which, for comparison purposes, the Benjamini and Hochberg method to control the FDR, the Lehmann and Romano procedure to control the tail probability of the proportion of false positives (TPPFP), and the Beta–Binomial SGoF procedure are considered. Three different dependence structures are considered. As usual, for a better understanding of the problem, several practical cases are also studied.

@&#INTRODUCTION@&#
The increase of the available information is a direct consequence of the technological advances. Modern science frequently produces data on thousands of different characteristics (variables). Probably, the—omic technologies (genomics, transcriptomics, proteomics, etc.) stand for the most relevant examples although other fields like astrophysics, brain imaging or spatial epidemiology have also increased substantially the size of the collected data. A usual practice in these fields is to measure all this information in two or more groups of individuals and, by using one particular statistical test, determining whether, in those groups, the behavior of the collected variables is different or not. However, the probability of spurious effects, or false positives, greatly increases when a massive number of tests is performed simultaneously. The aim of the classical multiple comparison procedures (the Bonferroni correction is the most popular one) is to control the probability of committing any Type I error i.e., to control the family wise error rate (FWER). This aim can be too restrictive and in large-scale problems provokes a huge decrease in the statistical power (increase the Type II error). In order to deal with this effect, more liberal criteria have been proposed (see Farcomeni (2008) for a recent and extensive review of modern multiple hypothesis testing methods).Conventionally, in the multiple testing framework,N(null) hypotheses are tested (each one denoted byH0,i,1≤i≤N). Table 1depicts schematically the possible situations. Of course, in practice, only the total number of rejections,r, is really observed and known. Note that controlling the FWER is equivalent to control theP{r−R>0}. Seeger (1968) introduced and Benjamini and Hochberg (1995) studied and popularized the false discovery rate (FDR), defined as the expected proportion of spurious effects i.e.,FDR=1−E[R/r]. The FDR is a frequentist well established definition for the multiple hypothesis testing errors and it has some interesting properties: on one hand, it is equivalent to the FWER when all null hypotheses are true (R=0) and, on the other hand, it is more liberal than the FWER criterion otherwise. The second point is that it allows to increase considerably the number of rejections. Note that, in a number of large-scale experiments (for instance in microarray genome-wide scans), it is usually presupposed that most of the nulls are true; the goal is often to identify a subset of interesting factors for future confirmatory studies and the relative role of type I and type II errors can change respect to the usual one in the (single) hypothesis testing framework.Several generalizations for the FWER and the FDR criteria and different procedures to implement them have been proposed (see, for instance, Sarkar (2007) and references therein). Most recent works deal with the problem of controlling the tail probability of false positives. Genovese and Wasserman (2006) proposed to control the tail probability of the false discovery proportion (FDP) by the so labeled FDX (false discovery exceedance) i.e., for a fixedα, to controlP{1−R/r>α}. Similarly, the generalized family-wise error rate (gFWER), proposed by Dudoit et al. (2004), is defined by the probability of committing more thankType I errors i.e., byP{r−R>k}. In addition, we highlight the sequential goodness of fit (SGoF) strategy, proposed by Carvajal-Rodríguez et al. (2009) and deeply explored by de Uña-Álvarez (2011). The SGoF method rejects an amount of null hypotheses equal to the difference between the observed and the expected amounts ofp-values below a given threshold under the assumption that all nulls are true (we denote byH0=⋂i=1NH0,i, in bold, this hypothesis). Frequently, the developed procedures assume the independence hypothesis i.e., that thep-values associated with each single hypothesis, or equivalently, thez-values are independent; here, thez-value attached to eachp-value,pi, is defined aszi=Φ−1(pi),1≤i≤N, whereΦdenotes the cumulative distribution function (CDF) of the standard normal. Although this assumption is reasonable in a number of situations (see Clarke and Hall (2009)), it may be a source of serious mistakes. This paper deals with the effect of correlation on thez-values distribution and its impact on the final decision to be made.Although it is reasonable to assume that, under the null, each singlep-value is uniformly distributed on[0,1], and even this proviso is true when the null is simple and the distribution of the test statistic is continuous and known, the truep-value distribution is only stochastically dominated by the uniform if its distribution is discrete or thep-value is estimated by a resampling method (see, for instance, Farcomeni (2008)). Under independence and assuming thep-values to be uniformly distributed, thez-values follow a standard normal distribution,N(0,1).The Hedenfalk data Hedenfalk et al. (2001) stands for an illustrative and well-known example which, in the present framework, has been previously considered by several authors. One of the goals of this microarray study was to find genes differentially expressed in breast cancer patients with mutations in the BRCA1 gene relative to those with BRCA2 mutation. A total of 3226 (=N) genes were studied on 7 patients with BRCA1- and on 8 with BRCA2-mutation. The mean and standard deviation for thez-values obtained from the 3226 two-side Student–Welch tests (one for each gene) on the Hedenfalk data; directly downloaded from http://faculty.washington.edu/~jstorey/qvalues/results.html, without any data pre-processing, were −0.471 and 1.15, respectively. At levelα=0.05(zα=Φ−1(α)=−1.64), the number of significant genes was 498 (15.4%). By using the traditional Benjamini–Hochberg (BH) FDR correction, the number of detected effects (significant genes) was only two. By considering the SGoF criterion for independent data, the total number of effects was 312. Of course, all these numbers could change and, in fact, they do it, when other statistical test (for instance, a non-parametric one) is used.The key for knowing how many genes to select (or, at least, to measure the committed error) is to know the distribution of the random variable(1)RN(x)=#{zi≤x,1≤i≤N}/N,x∈R.This problem has been previously considered in the literature and there exist a number of papers which deal with it (see Efron (2010) and references therein). However, many of them assume hypotheses which are only reasonable for particular settings. In Section  2 we are concerned with theRN(⋅)distribution in a general framework. This distribution depends on some unknown parameters. In particular, on some unknown parameter which are the elements of theZvector correlation matrix, whereZis the (theoretical)N-dimensional variable from where thez-values were drawn. In Section  3 some different methods for approximating theRN(⋅)-distribution are proposed. The most commonly used tests (the Student–Welch test and the Mann–Whitney one) are explicitly considered. In addition, a general procedure based on resampling is also explored. In Section  4 the obtained results are applied in order to control the tail probability of false positives. Two algorithms, one to control the median and another one for applying the SGoF strategy, are proposed. In Section  5, the behavior of these methods is checked in a simulation study. The results suggest that both procedures get a good compromise between the false and true discoveries. Finally, in Section  6, the practical application is illustrated through three different real problems. Both the tables and the technical results are provided as supplementary material (see Appendix A).Let us consider a typical two-sample problem (thek-sample generalization is straightforward). LetXandYbeN×n1andN×n2matrices, respectively. They contain the data information, therefore we haveNvariables measured onn1+n2subjects,n1on one group (following one particularN-dimensional distribution,DN1(μ1,Σ1)) andn2on the other group (following anotherN-dimensional distribution,DN2(μ2,Σ2)). Once a statistical comparison criterion, test, has been fixed, we obtainNp-values. By assuming that, under the null, each univariatep-value is uniformly distributed on[0,1], the marginal null distribution of thez-values vector,Z={z1,…,zN}(zi=Φ−1(pi),1≤i≤N) is normal (mean zero and standard deviation one). Thez-values vector always, not only under the null, follows aN-dimensional distribution,LN(μ,Σ). Note that, for eachx∈R, the random variableRNdefined in (1) is(2)RN(x)=#{zi≤x,1≤i≤N}/N=FˆN(Z,x),whereFˆN(Z,x)denotes the empirical cumulative distribution function (ECDF) referred to the data vectorZand evaluated at pointx. The right-side version (survival curve) of theRN(⋅)cumulative distribution function (CDF) has been studied by Efron (2009, 2010). In particular, assuming thatZis a normally distributed vector, Schwartzman (2010) proved that, underH0, the following approximation holds,V[RN(x)]=⋅1NΦ(x)[1−Φ(x)]+(1−1N)(α1+α22x2)φ2(x),whereφ(⋅)denotes the density function of the standard normal distribution andV[⋅]is the variance operator. Finally, if the elements in the variance–covariance matrix of the vectorZ,Σ, are denoted byρi,j(1≤i,j≤N), one hasαk=1N(N−1)∑i=1N∑j≠iNρi,jkk>0.From definition (2) and ifz̄=N−1∑i=1Nzi(mean), andsz2=(N−1)−1∑i=1N(zi−z̄)2(variance), the following equality can be easily derived:(3)RN(x)=FˆN(Z,x)=FˆN(Z̃,(x−z̄)/sz),whereZ̃=(Z−z̄)/sz(centeredZ-vector). Hence, for a fixedr∈[0,1], the CDF for the random variableRN(x)(x∈R)has the expression(4)FRN(x)(r)=P{RN(x)≤r}=P{FˆN(Z̃,(x−z̄)/sz)≤r}=P{(x−z̄)/sz≤FˆN−1(Z̃,r)},whereFˆN−1(Z,r)=inf{s∈R/FˆN(Z,s)≥r}. Under the independence assumption and assuming that all nulls are true, it is easy to derive that the random variableN⋅RN(x)follows a binomial distribution with parametersΦ(x)andN. This distribution is used by Carvajal-Rodríguez et al. (2009) in order to implement the SGoF strategy for independent tests. The expected value forz̄(E[z̄]=N−1∑i=1NE[zi]) does not depend on the correlation matrix structure; in fact, underH0(always assuming that, under the null, each singlep-value is uniformly distributed on[0,1]),E[z̄]=0. However, since underH0,∑i=1Nρi,i=N, it is had the following expression for thez̄variance,(5)V[z̄]=E[(1N∑i=1Nzi)2]=E[1N2∑i=1Nzi⋅∑j=1Nzj]=1N2∑i=1N∑j=1NE[zi⋅zj]=1N2∑i=1N∑j=1Nρi,j=1N2∑i=1Nρi,i+N(N−1)N2⋅1N(N−1)∑i=1N∑j≠iNρi,j=1N+(1−1N)⋅α1.Moreover, still underH0, the expected value ofsz2also depends on the correlation matrix elements; in particular,(6)E[sz2]=1N−1{E[∑i=1Nzi2]+NE[z̄2]−2E[∑i=1Nzi⋅z̄]}=1N−1{∑i=1Nρi,i−1N∑i=1N∑j=1Nρi,j}=1N−1{(1−1N)∑i=1Nρi,i−1N∑i=1N∑j≠iNρi,j}=1−α1.It is worth mentioning the inequality−(N−1)−1≤α1≤1(see Schwartzman (2010)). Like in the approximation forV[RN(x)]previously given, bothV[z̄]andE[sz2]have a summand which contains the expression for the independent case and a penalty summand which depends on some correlation-matrix parameters. In particular, in Eqs. (5) and (6), only the value ofα1is explicitly involved in this summand. Curiously, Efron (2010) quoted that the common standardization methods for large-scale datasets often makeα1exactly or very close to zero and then, it can be assumed thatα1=0. In the referred paper and from this assumption, an approximation forV[RN(x)]which mainly depends onα2is given. However, in the discussion of Efron’s manuscript, Schwartzman (2010) questioned this assumption and provided an approximation which depends on bothα1andα2. By assuming thatZis normally distributed, the random variablez̄is also normally distributed and, underH0, its mean and variance are 0 and(1+(N−1)⋅α1)/N, respectively. In addition, the random variablesz2is a quadratic form. The independence betweenz̄andsz2can be derived by the Craig theorem but only for particular correlation-matrix structures. In particular, assuming independence among thez-values (Σ=IN, theN-dimensional identity matrix),N⋅(x−z̄)/szfollows a noncentral StudentT-distribution (tν,δ) withν=N−1degrees of freedom and with noncentrality parameterδ=N⋅x. In this case, sincesupt∈R|FˆN(Z̃,t)−Φ(t)|→0(a.s.), the following approximation holds:FRN(x)(r)=⋅P{tν,δ≤Φ−1(r)}.ForN=1000, the differences between the exact (based on the binomial distribution) and the approximated percentiles range between 0.002 for the percentile 0.90 and 0.003 for the percentile 0.95. In general, forα1≠1, by assuming that (i) theZ-vector follows a multivariate normal distribution and (ii) the distribution of each marginal isN(0,1)then, for eachx∈R, the random variable(x−z̄)/1−α1is normally distributed with meanx/1−α1and varianceV[z̄]/(1−α1)(the explicit expression ofV[z̄]is given in Eq. (5)). Then, it holdsP{(x−z̄)/1−α1≤t}=Φ(t−x/1−α1V[z̄]/(1−α1))∀t∈R.The properties of theΦfunction (see Cao-Abad (1990)) allow to derive the equalitysupt∈R|Φ(t−x/1−α1V[z̄]/(1−α1))−Φ(t−x/szV[z̄]/sz2)|=O(sz−1−α1).Assuming thatV[sz2]→N0then, from Eq. (6),sz2→N(1−α1). Hence, forx∈Randr∈[0,1], the approximation(7)FRN(x)(r)=⋅Φ(FˆN−1(Z̃,r)−x/szV[z̄]/sz2)holds. The above expression has some important wrinkles. On one hand, (1)FˆN(Z̃,⋅)is handled as a fixed function, but it is not. In addition, it can be strongly related with the observedz̄value (in this context, the convergence of the functionFˆNunder dependence has been recently considered by Delattre and Roquain (2012)). This relationship depends on ther-value and on the original correlation matrix structure, and can turn one particular procedure to be excessively conservative (or unconservative). This point is more deeply considered in the Discussion section. On the other hand, (2) sinceV[z̄]depends onα1, the above distribution is still not useful in practice. And (3) the quality of the proposed approximation also depends on the valueO(sz−1−α1). Although assuming that this value is closer to zero for higherNis not a unrealistic proviso; see, for instance, the three real dataset considered in Section  6, the value ofO(sz−1−α1)is directly related with the covariance-matrix structure.In order to check the behavior of the approximation (7), a small Monte Carlo simulation study has been carried out. Two different correlation-matrix structures have been considered. In the Structure I,ρi,j=afor each1≤i≠j≤N(two differentα1’s and three differentN’s were considered). In the Structure II,ρi,j=a⋅4⋅(N−1)/(N−2)for1≤i≠j≤N/2and 0 otherwise. Note that in both structuresα1=a. Table 2 (included as supplementary material, see Appendix A) depicts the observed mean and the standard deviation (mean±sd) for the absolute difference between the estimated (based on Eq. (7)) and the true (computed via resampling) percentiles (cases 90 and 95 were considered) forx=−1.64andx=−1.28. In the two considered structures, both the bias and the standard deviation tend to decrease whenNincreases. In addition the errors were larger forα1=0.15, specially forP95andx=−1.28. The observed errors were worse forα1=0.25(results not shown).Fig. 1plots the observed (based on 5000 Monte Carlo replications) and the estimated (based on the proposed approximation) distribution of the rejection proportions for different correlation matrices. In the upper panel (consideredp-value was 0.05 i.e.x=−1.64), the matrix-structures were those considered in Table 2 (N=1000,α1=0.05). In the lower panel, the correlation-matrix for generating thez-values was estimated by using the covariance matrices of the Hendenfalk data. In this case, the estimated value ofα1(see Section  3) was 0.072 and the consideredp-values (Φ(x)) were 0.05, left, and 0.10, right.The main handicap to use the approximation (7) to theRN(⋅)-distribution is the unknown parameterα1. This section is devoted to the estimation ofα1. The particular and important cases of the parametric Student–Welch and the non-parametric Mann–Whitney tests are explicitly explored. In addition, a more general solution based on resampling is considered.Note that, conventionally, aN-dimensional sample with size one is available. Fortunately, for estimating the covariance matrix of thez-values vector,Σ, connections between theZcorrelation-matrix and the original data covariance structure can be used. In particular, letXkandYk(1≤k≤N)be the random variables from where the samplesXk={xk,1,…,xk,n1}andYk={yk,1,…,yk,n2}were drawn, respectively. When the two-sided Student–Welch test is employed in order to compare the samples, the following approximation can be used:(8)ρi,j=C(zi,zj)=⋅ci,j2π−2⋅(1+ci,j212),whereC(⋅,⋅)denotes the correlation operator andci,j=(n1+n2)−1⋅(n1⋅C(Xi,Xj)+n2⋅C(Yi,Yj))with1≤i,j≤N. A proof for this result is given as supplementary material (see Appendix A). BothC(Xi,Xj)andC(Yi,Yj)can be directly replaced (plug-in method) by their respective sampling correlations (the correlation estimation is a well-known problem, see, for instance, Johnson and Kotz (1970), for normal theory approximation). However, this procedure tends to overestimateci,j2. Arguing as in Efron (2009), we estimateci,j2byc̃i,j2={(n−3)⋅cˆi,j2−1}/(n−5),wherecˆi,jis the usual estimator for the correlation parameter andn=(n1+n2)/2. This estimator can take negative values when the sample sizes are small, in this case, the use ofcˆi,j2is advisable. Otherwise, still following Efron (2009),α1is assumed to be 0 when the value of its estimator is negative.When the non-parametric two-sided Mann–Whitney test is used for comparisons, the following approximation is of interest:(9)ρi,j=C(zi,zj)=⋅Ci,j2π−2⋅(1+Ci,j212)(1≤i,j≤N),whereCi,j=12⋅(Ri,j−1/4)andRi,j=∬Fi(s)⋅Fj(t)dFi,j(s,t),Fi,jstands for the bivariate distribution function from which the data were drawn;Fi,Fjdenote, respectively, theith andjth marginal distribution functions. In practice, these distributions are replaced by their sampling counterparts. The proof is also provided as supplementary material (see Appendix A).Both approximations underestimate the correlation for largeci,j. In fact, they never reach the value 1, even whenci,j2=1. Obviously, when the tests are independent, the correlation is usually overestimated. Fig. 2depicts the relationship between the real correlation of thez-values and the approximated correlation. Two samples (with the same sample size, 25) were drawn, independently, from the same standard bidimensional normal distribution (with correlationc). The Student–Welch and the Mann–Whitney tests were then computed. The observed correlations of thez-values and the ones estimated through Eqs. (8), left, and (9), right, against the value ofc(5000 iterations for eachc-value) were considered.In a more general context, given an arbitrary comparison criterion,F(which it is not necessarily the same for theN-tests), we propose the following resampling algorithm,A1.For1≤b≤B, draw (bootstrap) samplesXkb={xk,1b,…,xk,n1b}andYkb={yk,1b,…,yk,n2b}fromFˆn1(Xk,⋅)andFˆn2(Yk,⋅), respectively, for1≤k≤N.Apply the criterionFon the bootstrap samples in order to obtain theBvectorspb={p1b,…,pNb}(1≤b≤B).Compute the correlation matrix,Σ∗, from the data computed inA2.For1≤b≤B, draw the (bootstrap) samplesXkb={xk,1b,…,xk,n1b}andYkb={yk,1b,…,yk,n2b}fromFˆn1+n2(Zk,⋅)whereZkstands for the pooled sample{Xk,Yk}, for1≤k≤N.In order to check the performance of the proposed approximations, a small Monte Carlo simulation study was carried out. A two-sample problem in which both samples (sizen) are drawn from the same multivariate normal distribution,NN(0,Σ), was considered. Three different scenarios were studied. Structure I and Structure II were previously considered in Table 2,N=1000. In the third scheme, the considered matrices were extracted from the Hedenfalk data, thereforeN=3226. Table 3 (supplementary material, Appendix A) shows the means and the standard deviations (mean±sd) for the absolute difference between the real and the estimatedα1(observed in 500 Monte Carlo iterations) for the asymptotic (AA) and the resampling (RA) approximations (based on 25,B=25, iterations of the algorithmA1–A3). For the Student–Welch test, the results suggest that the quality of the approximations is reasonable for both the asymptotic and the resampling methods. Better results were observed for lowerα1’s. For the Mann–Whitney test, the asymptotic approximations obtained poor results (due to the difficulty in estimatingRi,jwith the scarce considered sample sizes). The resampling method obtained results similar to the Student–Welch case. However, it is worth noting that the use of non-parametric bootstrap can produce erratic results in large-scale multitesting problems Efron (2009).In Section  2 we studied the effects of correlation on theRN-distribution. In this section, we deal with the effects of this correlation on two different multitesting strategies: the FDR and the SGoF method. We propose some alternative procedures which illustrate the practical applications of the approximation to theRN-distribution given in (7).The standard Benjamini–Hochberg procedure for controlling the FDR (BH) is broadly used in practice in order to detect effects from massive data analysis. This method controls the expected value of false discovery proportions (1−E(R/r)) at levels smaller thanα⋅∑i=1Ni−1even under general dependence structures Benjamini and Yekutieli (2001). However, both the FDR variability and shape change in the presence of dependence among the involved tests. Fig. 3shows the observed mean and median of false discovery proportions (FDP) obtained by the BH method (α=0.1) againstα1in 200 (per eachα1-value) replications when theZcorrelation-matrix isρi,j=α1(1≤i≠j≤1000), and where the 20% of nulls are false. The statistical power for each single false null, at nominal levelα=0.05, was 0.8. Although the estimated FDR (dotted black line) is always close to its target (10% in this case, discontinuous red line), its median (continuous black line) decreases and it is really close to zero for largeα1-values. As an alternative, we propose to use a more robust measure and controlling the median of the FDP. There exist clear connections between this criterion, the FDX proposed by Genovese and Wasserman (2006), and the gFWER proposed by Dudoit et al. (2004). In fact, like FDX, our method controls the tail probability for the proportion of false positives (TPPFP) at the particular case of 1/2. Similarly, the gFWER controls the tail probability of the exact number of false positives. However, controlling the proportions (instead of the exact number) is more appropriate for large-scale problems Dudoit et al. (2004).Lehmann and Romano (2005) studied the expressionP{FDP>α}≤γand, fori∈1,…,N, proposed to reject the hypotheses such thatp(i)≤(⌊α⋅i⌋+1)⋅γ/(N+⌊α⋅i⌋+1−i)(⌊t⌋stands for the largest integer number smaller than or equal tot). It was proved that, under certain conditions on the dependence structures, this step-down procedure controls, at levelγ, the probability that the FDP exceedsα. LetZ={z1,…,zN}be a fixedz-values vector and let{z(1),…,z(N)}be its ordered sample (z(1)≤⋯≤z(N)). Our objective is to find an appropriate cut-off point,τ, such that, for a fixed nominal levelα,P{1−R/r>α}=1/2, whererstands for the total number of observed rejections; i.e.,r=#{zi≤τ}. From a conservative point of view, we want to findτsuch thatPH0{RN(τ)>r⋅α/N}=1/2. It is clear that, for1≤i≤N,RN(z(i))=i/N, and hence, for controlling the tail probability of the FDP at levelα, the maximum number of true hypotheses rejected should be⌊α⋅i⌋. Hence, we are looking for the greatestz(i)satisfyingPH0{RN(z(i))≤⌊α⋅i⌋/N}≥1/2. In particular, taking advantage of the approximation ofFRN(⋅)previously provided,τcan be estimated byτˆ=z(k), wherek=max{i∈1,…,N:Φ(FˆN−1(Z̃,⌊i⋅α⌋/N)−z(i)/szV[z̄]/sz2)≥1/2}=max{i∈1,…,N:FˆN−1(Z̃,⌊i⋅α⌋/N)−z(i)/sz≥0}=max{i∈1,…,N:N⋅FˆN(Z̃,z(i)/sz)≤⌊i⋅α⌋}.So, onceFˆN(Z̃,⋅)has been computed, the following step-down algorithm (similar to the BH procedure) controls the median of the FDP:M1.For1≤i≤N, computeFi=N⋅FˆN(Z̃,z(i)/sz).Computeτˆ=z(k)wherek=max{i∈1,…,N:Fi≤⌊α⋅i⌋}.For1≤i≤N, rejectHiiffzi≤τˆ.When a number of nulls are false, it is expected that there exist a larger number of lowz-values, hence the values ofFN(Z̃,t)for smallt’s are larger than they should be under the null. Therefore, stepM2is more restrictive than it should be underH0. However, under the null and by symmetry, the distributions ofFˆN(Z̃,⋅)andFˆN(−Z̃,⋅)are equivalent. Hence, if in the previous procedure the stepM1is replaced byM1∗.For1≤i≤N, computeFi=N⋅FˆN(−Z̃,z(i)/sz),Carvajal-Rodríguez et al. (2009) introduced the Sequential Goodness of Fit (SGoF) method. The focus of SGoF is on the total number of detected effects (r); i.e., those hypotheses whose associatedp-values are lower than the fixed nominal level. This multitesting strategy computes a confidence region (at level1−γ,γ∈(0,1)) for the expected number of rejections when all nulls are true and rejects the excess of observed effects. Equivalently, for a fixed nominal levelα(=Φ(x)), it looks for a cut-off point,τ∈[0,1], such thatPH0{RN(x)≤τ}≥1−γ. The hypotheses with ther−N⋅τsmallestp-values are rejected (remember thatris the observed number of hypotheses whichp-values are belowαi.e.,r=N⋅RN(x)). Obviously, ifr≤τ⋅Nthere are no declared effects.For independent tests, it is easy to check thatN⋅RN(⋅)follows a binomial distribution and the SGoF criterion has interesting statistical properties de Uña-Álvarez (2011). However, under dependency, it can be very anticonservative. de Uña-Álvarez (2012) introduced a correction of the SGoF method based on the Beta–Binomial distribution. In short, it is assumed the existence ofkblocks of tests which share the same within-block correlation. These blocks are based on the order of the sequence; hence, at this time, the order ofp-values plays a fundamental role. Since the number of blocks,k, is fixed, this correlation can be estimated from the sequence ofp-values. Under this assumption, this method was proved to have good properties.The method presents some issues. On one hand, the correlation matrix could not have this (assumed) structure. On the other hand, sometimes the order of thep-values is at random (or they are randomly recorded), and no consequence should be derived from this order. Using the original data structure in order to estimate theα1value, the approximation given in (7) is helpful to compute a cut-off point,τˆ, in the way,τˆ=FˆN(Z̃,(V(z̄)1/2⋅Φ−1(1−γ)+x)/sz).Note that, unlike the previously commented procedures, the SGoF strategy forgets thep-values. It is only interesting if they fall or not belowα. However, it can be proved (see de Uña-Álvarez (2012)) that, asymptotically, it controls the gFWER at levelαfork=N⋅(RN(x)−Φ(x))wherex=Φ−1(α).In order to check the behavior of the proposed procedures, a small simulation study was performed. Two different samples were drawn, sizes ofn1andn2, respectively (the number of iterations was 5000) from twoN-dimensional normal distributions,NN(μi,Σi),Σidenotes the covariance matrix (i∈1,2). Whileμ1=0, different alternatives were considered forμ2. In Table 4,μ2=0(all nulls are true); in Tables 5–7 (all of them included as supplementary material, Appendix A) certain percentage of its first components took the valueϵ. In the first considered structure, theN(=1000) tests were independent. The values ofϵwere 1.06 and 0.706, for equal and unequal sample sizes, respectively (corresponding, approximately, to a statistical power of 0.80 for each single test, at the usual nominal level ofα=0.05). In the second problem, the considered covariance matrices were extracted from both the BRCA1 and BRCA2 groups in the Hedenfalk data (N=3226). The considered values forϵwere equal to those of the independent case. Finally, the two covariance-matrix structures were extracted from the ALL and AML groups of the Golub data,N=7129Golub et al. (1999). This dataset was downloaded from the package golubEsets freely available in the CRAN (www.r-project.org). The considered values forϵwere 106 and 70.6, for equal and unequal sample sizes, respectively. The two-side Student–Welch test (function t.test in the R package) was used for the comparisons, and the approximation given in (8) was employed in order to estimateα1. Joint with the proposed algorithms to control the median (M1∗–M3),NM, and to perform the SGoF strategy,NP, the Benjamini–Hochberg step-down algorithm (BH), the Lehmann–Romano (LR) procedure to control the median and the SGoF strategy based on the Beta–Binomial distribution (BB), were also included. Both the mean and the median were controlled at 5%. The considered confidence region for the SGoF strategy was 0.95 (γ=0.05). For this method, the implementation available at http://webs.uvigo.es/jacobo/BB-SGoF.htm withk=50has been used.Table 4 shows the FWER (with a 95% confidence interval) and a description of the false discovery numbers (Rejection number). In particular, the mean and the standard deviation (mean±sd), the median (P50) and percentiles 25 (P25) and 75 (P75) forμ2=0(H0is true) are provided. In the independent case (α1=0andN=1000), the BH worked really well; it rejected (a little bit) less for equal and (a little bit) more for unequal sample sizes than expected. The LR method rejected a bit lower than it was expected for both considered sample sizes. The BB method performed well although it was anticonservative, particularly for unequal sample sizes. In addition, its observed standard deviations were very large. TheNMandNPmethods performed well too. We want to highlight that the correlations between the observed rejections and the estimated cut-off points for theNPprocedure were very large: 0.828 and 0.812, for equal and unequal sample sizes, respectively. In the second considered case, the Hedenfalk data (α1=0.072andN=3226), the observed rejection proportions for the BH were quite low. However, the most remarkable points are: (1) both median control methods only rejected around 10%, instead of the expected 50%, even lower for unequal sample sizes; and (2) BB rejected above 30% (instead of the expected 5%). In average, this method rejected more than 50 (true) nulls, the observed standard deviations were also very large. TheNPmethod performed well, although is anticonservative for equal (lower) and conservative for unequal (larger) sample sizes. The correlations between the observed number of rejections and the estimated cut-off points were also very large; 0.863 and 0.850, for equal and unequal sample sizes, respectively. With this covariance structure, it was observed that, for 5% of the iterations, the observed rejection proportion was larger than 15.4%. This implies that, for this model, observing a rejection percentage of 15% does not seem to be too strange. Finally, in the third considered case, the Golub data (α1=0.040andN=7129), the observed results were quite similar to those of Hedenfalk data. BH performed well while the LR andNMmethods rejected less and the BB method rejected mored than expected. The behavior ofNPdeserves more attention; for equal (and low) sample sizes, a 13.3% of rejections was observed, while for unequal sample sizes, it performed well and a rejection percentage of 3.2% was observed. In this case, the 5% of the iterations rejected more than the 12.8% of the nulls. The low observed number of rejections in the methods for controlling the median is due to the strong asymmetry of the rejection distributions. Particularly, theNMmethod looks for aτˆsuch thatP{RN(τˆ)>α}≤1/2; the asymmetry makes that slight variations in theτˆvalues will provoke large changes in the observed probability. Note that the results observed for the LR method to control the median were also similar. The problems ofNPare mainly due to the poor estimation ofα1. When the real value ofα1is used in the approximation (7), the observed results improve considerably. In particular, the observed FWERs were 0.051 and 0.054 for the Hedenfalk data (equal and unequal sample sizes, respectively) and 0.046 and 0.055, for the Golub data (equal and unequal sample sizes, respectively).Table 5 shows, for the independent case (N=1000), the FWER and the description of the observed false discovery proportions (FDP) and the statistical power (Power), defined as the proportion of false nulls which are rejected: mean±standard deviation, median (P50) and percentiles 25 (P25) and 75 (P75) were included. For equal sample sizes (n1=15,n2=15), the BH, LR and the BB methods performed similarly. The FWER and the Power increased with the real percentage of false nulls, while the FDP was still under control. The BB method reached a better power, although it reported a greater FWER and FDP too. This effect was also observed for theNPcriterion. However, the observed behavior of theNMmethod was different; for this method, both the FWER and the Power were controlled. The FWER was around the 50% and the statistical power was around 20%. For unequal sample sizes, the behavior was similar but, for the BH and LR procedures, both the FWER and the statistical power were larger. The correlation between the observed rejection proportions and the computed cut-off points ranged between 0.527 and 0.796.Table 6 is similar to Table 5, but the variance–covariance matrices are extracted from the Hedenfalk data (N=3226). For equal sample size, the BH and LR methods performed similarly; the observed powers were very large. However, while the observed FWER grew with the percentages of false nulls, the power was still constant. The SGoF strategy has serious problems with this structure. Note that, for instance, when the percentage of false nulls was 5%, only for 11.7% of the iterations it rejected above the 15.4% (cut-off point observed when all nulls were true), this percentage achieved the 61.7% when the false nulls percentage was 15%. The BB method obtained worse powers despite of committing more mistakes. However, with the same goal, theNPmethod detected the correlation structure and controlled the FWER, while its (poor) statistical power grew with the percentages of false nulls. TheNMmethod performed well and, as in the independent case, it controlled the FWER (around 25%) and obtained relatively good powers (around 80%). This method got almost the same power than the BH and LR ones with half of the FWER. For unequal (and larger) sample sizes, the pattern of results was very similar. TheNPprocedure was more conservative than with an equal sample size. Correlations between the observed percentages and estimated cut-off points oscillated between 0.802 and 0.905.Table 7 is similar to the previous one when the covariance matrices are extracted from the Golub data (N=7129). The five considered methods controlled the FDP while the FWER grew with the percentage of false nulls. LR andNMcontrolled the FWER at 50%. BH, LR, BB andNMmethods achieved similar powers (around 20%). TheNPmethod did not work, being extremely conservative, particularly for unequal sample sizes. The FWER was well controlled but the proportion of detected false nulls was very poor. Probably, the considered sample sizes were too small to successfully handling the variability and the number of tests. In addition, only the 7.5% and 20.1% of iterations with 5% and 15% of false nulls, respectively, rejected more than 12.8% of the nulls. Finally, the correlation among the observed rejection proportions and the cut-off points ranged between 0.754 and 0.897.In this section, we study in detail three real datasets. In particular, we consider the well-known Hedenfalk and Golub data and the less known Shen data, an epigenetic dataset. Since the DNA methylation values are expected to be highly correlated (see, for instance, Issa (2004)); and since the influence of the microarray normalization methods on true biological effects is still under study (Wang et al., 2012), the last problem is particularly appropriated in our context.This dataset has been already considered in this context and even it has been used in order to illustrate the problem in the current work. Hence, in short, the Hedenfalk data Hedenfalk et al. (2001) provides 3226 genes, and the focus is to detect possible differences between the gene expression in BRCA1- (7 patients) and BRCA2-mutation (8 patients). Fig. 4depicts the histogram for the 3226p-values (left) and the kernel density estimation for the respectivez-values (right).At levelα=0.05, the BH procedure declares only two significative effects. The LR method to control the median finds five tests statistically significative. The BB procedure detects around three hundred effects (depending on the parameterkthis number oscillates between 299 and 304). The new proposed procedure to control the median,NM, detects only two significative effects. Finally, always at level 5%, the cut-off point estimated by the approximation given in (7) is 10.97% when theα1estimation is based on the resampling method (A1–A3), and 14.19% when it is based on the, more conservative, asymptotic approximation. Hence since the observed percentage of rejections was 15.44% (see the Introduction section) theNPmethod rejects 143 or 40 nulls, respectively. By letting the value ofα1to vary between 0.01 and 0.25, the cut-off point oscillates among 9.6% y 22.1%. Forα1’s larger to 0.1, the obtained cut-off points were greater than the observed rejected proportion and no effects were detected.In this dataset, probably because of the sparse available sample sizes, the statistical tests are not powerful and then, the obtainedp-values are large. Note that only the smallest five and twop-values satisfied the LR and BH conditions, respectively, at level 5%. These criteria do not depend on the observed data but on thep-values. However, the number ofp-values below thisα(=0.05)is quite large and the SGoF criterion detects this rejection excess in order to declare a larger number of effects. In both the considered procedures, the final number of rejections depends on one parameter;NPonα1and BB on the number of bins. The estimation of these parameters play a relevant role on the final decision to be made.This well-known dataset contains the expression of 7129 genes (Affymetrix proves) assayed using Affymetrix Hgu6800 chip on 20 patients with acute lymphoblastic leukemia (ALL) and 14 patients with acute myeloid leukemia (AML). The data were obtained from the package cited above. Fig. 5depicts the histogram for the 7129p-values (left) and the kernel density estimation for the respectivez-values (right).At levelα=0.05, the total number of observed rejections was 1223 (17.15%). The BH method declares significative the 123 smallest ones. The LR method for controlling the FDP median detects 64 effects, while the proposed method,NM, detects 62 significative genes. Procedures based on the SGoF strategy detect more effects: the BB method, around 814 and 864 (depending on the parameterk) and the new method,NP, rejects 591 when theα1estimation is based on resampling (cut-off point of 8.86%) and 195 when it is based on the asymptotic approximation (cut-off point of 14.63%). The cut-off points range between 8.01% (α1=0.01) and 21.7% (α1=0.2), being 78.4% forα1=0.25. Forα1’s larger than 0.1, the obtained cut-off points were greater than the observed rejected proportion and no effects were detected.It seems that the small sample sizes (taking into account the large variability) and the large number of simultaneous tests (see, de Uña-Álvarez (2011)) provoke again that the SGoF strategy performs better (in the sense that it detects a larger number of effects) than the method directly based on thep-values.The Shen data contains information on 62 Taiwanese cases of hepatocellular carcinoma (HCC) on which tumor and adjacent non-tumor tissues were analyzed using Illumina methylation arrays (Illumina, Inc., San Diego, CA) that screen 26,538 autosomal CpG sites. The reader is referred to Shen et al. (2012) for complete information about the original study. The data are publicly available at the Gene Expression Omnibus (GEO) page, with accession number GSE37988 (http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE37988). Probes corresponding to theXandYchromosomes were removed from the dataset in order to eliminateX-inactivation effects. We considered the crude data (without previous quality control). Due to each CpG is measured on the same subjects, the StudentT-test for paired samples was used in order to compute thep-values. Fig. 6, similarly to Fig. 5, depicts the histogram for the 26,538p-values (left) and the kernel density estimation for the respectivez-values (right).The total number of CpG sites with ap-value less than 0.05 (usual nominal level) was 12,394 (46.7%). The BH method declares significant the 10,451 smallest ones. The LR method for controlling the FDP median detects 9864 effects while the proposed method,NM, is more conservative and only detects 4370 significative genes. The number of effects detected by the BB procedure for the SGoF strategy changed with the selected number of bins: while a small number of bins (below 400) provided around 10,900 significative effects, when the number of bins increases, the number of effects drastically decreases. With 500 bins (k=500), only 103 effects were detected. The estimated value ofα1(via simulations) was 0.024 and the effects identified by theNPmethod were 5970 (cut-off point of 16.88%). This cut-off point oscillates between 15.01% (α1=0.01) and 21.1% (α1=0.2), when considering differentα1’s. Forα1=0.25, the obtained cut-off point is 50%.In this dataset, the new methods show themselves more conservative than, for instance, the BH procedure. The number of detected effects was really high. In the original paper and after a previous quality selection of 26,486 autosomal CpG sites, the number of detected effects by using the Bonferroni correction was 2324. However, we want to point out that the nominal level in this case would beα/26,486, extremely low and with potential problems of computational precision.

@&#CONCLUSIONS@&#
