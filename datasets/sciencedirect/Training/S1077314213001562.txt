@&#MAIN-TITLE@&#
Efficient keyframe-based real-time camera tracking

@&#HIGHLIGHTS@&#
We propose a new keyframe-based global localization framework.We use online map extension to significantly enhance the ability of global localization.Selecting an optimal set of keyframes for scene representation.Fast keyframe recognition for selecting candidate keyframes for online matching.A two-pass keyframe-based matching incorporating temporal information

@&#KEYPHRASES@&#
Keyframe selection,Real-time camera tracking,Global localization,Online map extension,

@&#ABSTRACT@&#
We present a novel keyframe-based global localization method for markerless real-time camera tracking. Our system contains an offline module to select features from a group of reference images and an online module to match them to the input live video for quickly estimating the camera pose. The main contribution lies in constructing an optimal set of keyframes from the input reference images, which are required to approximately cover the entire space and at the same time to minimize the content redundancy among the selected frames. This strategy not only greatly saves computation, but also helps significantly reduce the number of repeated features. For a large-scale scene, it requires a significant effort to capture sufficient reference images and reconstruct the 3D environment. In order to alleviate the effort of offline preprocessing and enhance the tracking ability in a larger scale scene, we also propose an online reference map extension module, which can real-time reconstruct new 3D features and select online keyframes to extend the keyframe set. In addition, we develop a parallel-computing framework that employs both GPUs and multi-threading for speedup. Experimental results show that our method dramatically enhances the computing efficiency and eliminates the jittering artifacts in real-time camera tracking.

@&#INTRODUCTION@&#
Vision-based camera tracking aims to estimate the camera poses from input images or videos. It is the foundation for solving a wide spectrum of computer vision problems, e.g., 3D reconstruction, video registration and enhancement. Offline camera tracking has been well studied, with several state-of-the-art softwares (e.g., bundler,1http://www.cs.cornell.edu/snavely/bundler/.1ACTS2http://www.zjucvg.net/acts/acts.html.2), as well as extensive research findings [24,40,46]. Real-time camera tracking [14,31,30] has recently attracted much attention, as it has found many applications for mobile robotics and augmented reality.In this paper, we propose a practical real-time camera tracking system by combining global localization (GL) and parallel tracking and mapping schemes, which involves an incomplete offline preprocessing for representing the 3D environment using features and an online step for real-time feature matching and reference map (i.e. 3D features and keyframes) extension. Specially, the offline step extracts sparse invariant features from the captured reference images and uses them to represent the scene. The 3D locations of these invariant features can be estimated by the offline structure-from-motion (SfM). Afterwards, taking these features as the reference, for each online image, we can extract the features and establish the correspondences with the reference ones, so that the camera pose can be quickly estimated.We generally call the above scheme as GL scheme because it matches features of the input frame to the whole model directly. It is robust to large camera motion and also precludes the possibility of error accumulation. It, however, has the following common problems with previous work. First, it relies excessively on the feature distinctiveness, which cannot be guaranteed when the space scale is large or the scene contains repeated structures. It was observed that the matching reliability decreases quickly when the number of features increases, which greatly affects the robustness and practicability of this system in camera tracking. Second, since GL scheme relies on the offline reconstruction result, it will fail if the camera moves to a new place which is not covered by reference images. PTAM [28] and MonoSLAM [15] are two state-of-the-art techniques proposed to solve the tracking problem in unknown scenes, which have been successfully adopted by many practical systems. However, they are restricted to deal with a small scene with only thousands of features.In this paper, we solve the above problems and develop a complete real-time tracking system. Our contribution is threefold. First, we propose an effective keyframe-based method to enable global localization in large-scale scenes. A novel keyframe selection algorithm is employed to effectively reduce the online matching ambiguity and redundancy. These keyframes are selected from all reference images to abstract the space with a few criteria: (i) the keyframes should be able to approximate the original reference images and contain as many salient features as possible; (ii) the common features among these frames are expected to be minimum in order to reduce the redundancy; (iii) the features should be distributed evenly in the keyframes such that given any new input frame in the same environment, the system can always find sufficient feature correspondences and compute accurate camera poses.Second, with the extracted keyframes, in the real-time camera tracking stage, we contribute an extremely efficient algorithm to find candidate keyframes which are most similar to the online input frame. Because the frame is only matched with the candidate keyframes, the computation can be greatly saved compared to the conventional global feature matching.Third, we develop an online reference map extension method to significantly enhance the ability of camera tracking and global localization. Especially, while the camera moves into a new place which is not sufficiently covered by reference images, new online keyframes will be inserted into the existing keyframe set, with newly reconstructed 3D features, so that the camera motion can still be reliably estimated.All of above modules are integrated under a parallel-computing framework using GPU and multi-threading for further speedup. A preliminary version of the work appeared in [16]. In this paper, we have made the following improvements.1.Introduced an improved real-time camera tracking framework based on an incomplete offline reference map reconstruction, which combined global localization and online reference map extension to make the camera tracking more robust in a larger scale scene with less offline preprocessing effort.Used GPU to accelerate SIFT feature extraction and reduce system latency.Introduced the two-pass keyframe-based matching, which can quickly obtain a set of evenly distributed 2Dâ€“3D correspondences to make the camera pose estimation more reliable. Temporal information was also utilized to improve the matching efficiency and robustness.

@&#CONCLUSIONS@&#
