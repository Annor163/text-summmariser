@&#MAIN-TITLE@&#
A common framework and taxonomy for multicriteria scheduling problems with interfering and competing jobs: Multi-agent scheduling problems

@&#HIGHLIGHTS@&#
We review multicriteria scheduling problems involving two or more set of jobs.We propose an unified framework for multicriteria scheduling problems with two or more set of jobs.We systematically review and classify existing contributions.We discuss the main advances, and point out future research lines in the topic.

@&#KEYPHRASES@&#
Scheduling,Interfering jobs,Multi-customer,Multi-agent scheduling problems,Sets of jobs,Multicriteria,

@&#ABSTRACT@&#
Most classical scheduling research assumes that the objectives sought are common to all jobs to be scheduled. However, many real-life applications can be modeled by considering different sets of jobs, each one with its own objective(s), and an increasing number of papers addressing these problems has appeared over the last few years. Since so far the area lacks a unified view, the studied problems have received different names (such as interfering jobs, multi-agent scheduling, and mixed-criteria), some authors do not seem to be aware of important contributions in related problems, and solution procedures are often developed without taking into account existing ones. Therefore, the topic is in need of a common framework that allows for a systematic recollection of existing contributions, as well as a clear definition of the main research avenues. In this paper we review multicriteria scheduling problems involving two or more sets of jobs and propose an unified framework providing a common definition, name and notation for these problems. Moreover, we systematically review and classify the existing contributions in terms of the complexity of the problems and the proposed solution procedures, discuss the main advances, and point out future research lines in the topic.

@&#INTRODUCTION@&#
The existence of several objectives is consubstantial to scheduling problems, as it can be seen from different definitions of the field, such as Pinedo (1995), where scheduling is defined as a decision-making process that has as a goal the optimization of one or more objectives. Therefore, it is not surprising that multicriteria scheduling problems have been widely studied in the scheduling literature (see e.g. the reviews by Hoogeveen, 2005; Minella, Ruiz, & Ciavotta, 2008; T’kindt & Billaut, 2001, 2002). In all the problems analyzed in these surveys the criteria considered affect all jobs to be scheduled. Only Hoogeveen (2005) mentions the case of multicriteria scheduling problems with two or more sets of jobs. In these problems, two or more sets of jobs (not necessarily disjoint) have to be scheduled, each one with its own objective(s). Although this is a special case of multicriteria scheduling problems, the existence of several sets makes the problems rather different than their one-set counterpart as, in general, the complexity of these problems changes even if the objective functions are the same (Agnetis, Mirchandani, Pacciarelli, & Pacifici, 2004).As discussed later in this paper, this type of scheduling problems arise in a number of real-life applications and therefore have been subject of interest by researchers and practitioners in the last few years. However, the lack of a unified framework has been a major deterrent for research advances in the field. There is not even a common name which has caused some contributions to ignore past works on the topic, as the keywords and title of the existing results make it difficult to conduct an extensive search (for instance, the same conclusion regarding a specific problem is independently shown by Agnetis, Pacciarelli, & Pacifici, 2007a,chap. 2; Nong, Cheng, & Ng, 2011). Without a common definition and name, the notation and limits for this kind of problems are not clear, which may have hidden valuable contributions and makes the comparison among similar problems very difficult. In addition, this has caused that some scheduling problems dealing with two types of jobs, but with no interference among them, were considered part of the topic. For instance, in some problems described in Leung, Pinedo, and Wan (2010), the jobs in one set have their due date to be equal to their release date plus their processing times. Therefore, these jobs have to be processed in a specific (fixed) time interval and the remaining scheduling problem is how to schedule the jobs in the other set, which can be assimilated to a traditional scheduling problem with machine unavailability.In this paper we will try to move towards an unified view on the topic that allows overcoming the above problems. More specifically, we (1) discuss the different definitions and approaches for the problem and provide a framework consisting of a single definition and notation, (2) give some complexity results and general properties, (3) review and classify the different contributions and results on the topic based on the aforementioned framework, and (4) point out the main research avenues in the field. By doing so, we expect to foster the research in this interesting and challenging scheduling area.The remainder of the paper is structured as follows: Section 2 discusses the problems, their applications and the different names used in the literature. In Section 3 we present the notation and adapt the taxonomy presented by T’kindt and Billaut (2002) for multicriteria scheduling problems. The relationship among the complexities, single criteria and multicriteria scheduling problems is outlined in Section 4, where some general properties are presented as well. Literature is reviewed by classifying the problems into basic problems (discussed in Section 5) if there are no conditions for the machines or jobs, i.e. the most general case indicating only the machine environment and the objectives considered for each set of jobs; and extended problems (discussed in Section 6), where specific conditions are imposed. Finally, Section 7 contains the conclusions and future research lines.We consider two or more set of jobs – not necessarily disjoint – competing or using common processing resources (machines). Each set of jobs has one objective, which may or may not be the same for each set. The objectives of some sets have to be optimized while others have to satisfy one or more constraints. This type of scheduling problems arise from many real-life fields of application (see Mor & Mosheiov, 2010):•Supply chain scheduling: In a supply chain, a classical problem is to minimize overall manufacturing and distribution costs integrating production and delivery. If the customers are competing for a common processing resource then the problem implies interfering jobs. Fan (2010) presents a scheduling problem where the customers are placed at different locations such that delivery times are given. The objective is to minimize the sum of time between job’s release and the delivery to the corresponding customer.Rescheduling: Rescheduling can be defined as the process of updating an existing production schedule in response to disruptions or other changes (Herrmann, 2006, chap. 6), such as the arrival of new jobs to be processed. Rescheduling usually implies more than one set of jobs, so a standard rescheduling problem can be formulated as a two-agent scheduling problem (Leung et al., 2010). In this problem there are usually two sets of jobs: existing jobs which have been already scheduled and new jobs to be scheduled. In this problem, two cases may be distinguished (Pinedo, 1995):–The starting times of the existing jobs cannot be modified (‘frozen’ jobs), so the problem can be considered as a single criteria problem subject to machine/job availability constraints (see e.g. Perez-Gonzalez & Framinan, 2009, 2010a; Perez-Gonzalez, Framinan, & Molina Pariente, 2011).The starting times of the existing jobs can be modified (existing jobs can be rescheduled). If the same objective is considered both for existing and incoming jobs, the problem is again a scheduling problem with one set of jobs. However, in many situations it makes sense to employ different objectives for each set: Some performance measure is minimized for incoming jobs in order to obtain a short completion time for this set of jobs (e.g. minimizing their makespan or flowtime), while the objective for the existing jobs aims to minimize the disruption from their initial schedule. The usual way to achieve the latter objective is either to minimize their tardiness or impose that these jobs cannot be tardy (see e.g. Perez-Gonzalez & Framinan, 2010b; Unal, Uzsoy, & Kiran, 1997); or to consider special disruption measures as the differences between the completion times of the old jobs in the sequence before rescheduling and the new sequence (such as in e.g. Hall & Potts, 2004; Mu & Gu, 2010; Yuan & Mu, 2007; Yuan, Mu, Lu, & Li, 2007).Telecommunications: Packet-switching networks usually support different applications, each one requiring the transmission of data packages that must reach their destination within some time limit. The most important performance objective for some applications (such as file transfer or interprocess communication) is not to exceed certain mean delay, while for other applications (such as voice or video) is to achieve a specific loss rate. Therefore, the idea of several sets of jobs (packets belonging to applications) that must compete for the use of the same resource (the bandwidth) arises naturally. This problems have been addressed by Peha and Tobagi (1990), Peha (1995), and Meiners and Torng (2007). A similar problem is found in Arbib, Smriglio, and Servilio (2004) for internet protocols, where one user wants to maximize the on-time packets transmitted to other user, while guaranteeing certain amounts of on-time packets to a third user.Maintenance scheduling: Some references in the literature address problems about scheduling jobs and preventive maintenance simultaneously (see e.g. Cassady & Kutanoglu, 2003; Ruiz, Carlos Garcia-Diaz, & Maroto, 2007), considering only one criteria for the jobs. However, since production and maintenance have common resources (the machines) and their activities are actually often conflicting, integrated production and maintenance cooperative scheduling is an example of interfering job problems when we consider a multiobjective approach. Khelifati and Bouzid-Sitayeb (2011a) simultaneously address the problem of scheduling production and preventive maintenance operations, taking into account both production and maintenance criteria. Since most machines have to be maintained at regular intervals (i.e. they require given periods of time on each machine), maintenance tasks can be modeled as maintenance jobs to be scheduled along with production jobs. Since maintenance tasks have to be performed within a time window, each maintenance job has both a release date and a due date (representing the earliest and latest time for the task, respectively). The natural objective for scheduling the set of maintenance jobs is thus to minimize a function of the deviation from their release and due dates, while production jobs are scheduled to minimize some performance measure. This approach is adopted by Wan, Vakati, Leung, and Pinedo (2010). Kellerer and Strusevich (2010) give an interpretation of their specific interfering job problem where machine(s) is(are) subject to a compulsory maintenance during the planning period, the length and the deadline of the maintenance operations are given, and the Decision Maker has to decide when to start the maintenance period, while an objective related to the jobs has to be minimized.It is to note that, there are several papers focusing on game theory aspects of the problems and its applications in industrial management, project scheduling, queuing setting, telecommunication services, economic markets, scheduling of trains, etc. These papers are originally cited in Agnetis, Mirchandani, Pacciarelli, and Pacifici (2000), Agnetis et al. (2004, 2007a, chap. 2), and Agnetis, Pacciarelli, and Pacifici (2007b), and they are subsequently cited often by authors dealing with interfering jobs scheduling problems, but it is to note that problems addressed there are not interfering jobs problems, at least in view of the definition given here. This is (another) side effect of the lack of a common framework for the topic.Regarding the name employed to denote this type of problems, different authors have used different denominations:•Peha (1995) call heterogenous-criteria scheduling to the problems where jobs are divided in two classes, and the performance measure differs from class to class. Earlier, Peha and Tobagi (1990) call heterogeneous performance objectives to the same problem, but without an explicit definition.The term interfering job sets first appeared in the review about multicriteria scheduling by Hoogeveen (2005), defined as a scheduling problem with two sets of jobs competing for processing on a single machine. Interfering job sets or Interfering jobs were later used by Balasubramanian, Fowler, Keha, and Pfund (2009), Elvikis, Hamacher, and T’kindt (2009), Elvikis, Hamacher, and T’kindt (2010b), and Huynh-Tuong and Soukhal (2009a, 2009b, 2010) in the multi-machine context. Their definitions are not homogeneous: In the first reference, the definition expresses that the jobs belong to disjoint classes or sets with a criterion associated with each set, while for the latter authors the sets are not disjoint, and there is an objective function for all jobs subject to minimizing another objective function for a subset of jobs, calling this case global objective function (Huynh-Tuong, Soukhal, & Billaut, 2011; Sadi, Soukhal, & Billaut, 2012).The most extended name is two agent or multi agent scheduling problems. In some cases it is called competing agents (Agnetis et al., 2004; Agnetis, De Pascale, & Pacciarelli, 2009; Ding & Sun, 2011; Fan, 2010; Huynh-Tuong, Soukhal, & Billaut, 2010; Kellerer & Strusevich, 2010; Mor & Mosheiov, 2010, 2011), being the main keyword agent. This concept was introduced by Agnetis et al. (2004) when addressing a scheduling problem in which two agents compete to perform their respective jobs on a common processing resource, each agent minimizing an objective function depending exclusively on the completion times of its jobs.In addition, other – less employed – names have been suggested, such as ‘competing users’ (Agnetis et al., 2000; Shen, 1998), ‘customers’ (Baker & Smith, 2003), ‘multiple job classes’ (Soltani, Jolai, & Zandieh, 2010), ‘multi-users’ (Saule & Trystram, 2009), ‘two families of jobs’ (Yuan, Shang, & Feng, 2005), ‘mixed criteria scheduling problem’ (Meiners & Torng, 2007), or even ‘scheduling problem with a floating machine non-availability interval’ (Kellerer & Strusevich, 2010), motivated by the fact that there is a machine maintenance interval which is not fixed. Finally, Arbib et al. (2004) do not give a name for the problem.When trying to consolidate a name for the problem, it does not sound logic to choose one of these aforementioned less-employed names. Besides, multi-customer or multi-users do not imply a multicriteria problem, and ‘class’ or ‘family’ of jobs are terms used generally for batch scheduling which may be confusing. Similarly, ‘heterogeneous criteria’ and ‘mixed criteria scheduling problem’ imply different criteria for each set of jobs, so the case when the sets have the same objective is not considered.While agent is the most extended name, we think that it could also be confusing, as there is an extensive literature on scheduling with multi-agent systems without relationship with our problem (see e.g. Coudert, Grabot, & Archimede, 2002; Shen, Hao, Yoon, & Norrie, 2006). Multi-agent system is a subfield of Distributed Artificial Intelligence where a network of individual agents share knowledge and communicate with each other to solve a problem beyond the scope of a single agent (Balaji & Srinivasan, 2010, chap. 1). This approach can be applied to scheduling in order to solve problems with competitive and negotiating algorithms controlled by agents (see e.g. Khelifati & Bouzid-Sitayeb, 2011a), but many references do not consider two or more set of jobs to be scheduled.Finally, the term sets (or classes, or families) of jobs could be adopted, but it must be taken into account that there may be problems with several sets of jobs that do not necessarily compete for a resource, even if they have different objectives, and that these scheduling problem could be disaggregated into two single-criterion scheduling sub-problems.Regardless if each job belongs to an agent, is a part of a customer order, an operation of a department or user, belongs to disjoint sets or not, etc. the key feature is that the job interferes with other jobs for the same resources. Although we think that interfering jobs is the most suitable term to name our problem, the most employed is multi-agent scheduling problem (MASP) so it is the term selected.In the next section, we provide a common notation and taxonomy for these problems.Multi-agent Scheduling Problems (MASPs) consider k=2,…,K sets of nkjobs denotedJ1,…,JK. We definen=∑k=1KnkandJ=J1⋃⋯⋃JK. Each setJkhas assigned a criterion fk. IfJk=Jfor some k, then fkis denoted by f. In this case the problem is called interfering jobs problem with global objective function. Each jobj∈Jkhas to be processed on machine i with processing timepijk, i=1,…,m. If there is only one machine, its processing time is denotedpjk. Additionally, we definepk=∑i=1m∑j∈JkpijkandP=∑i=1m∑j∈Jpij. As many references deal with two disjoint sets of jobs(k=2J1∩J2=∅), we denote these sets asJAandJB, each one with nAand nBjobs, and objective functions fAand fB, respectively.Obviously, some special cases of this notation do not constitute MASPs. For instance, in the problem with two-sets,JA=∅(orJB=∅) constitutes a single-criterion scheduling problem, whileJA=JBdenotes a standard (i.e. not competing) multicriteria scheduling problem. Such cases will not be treated here.A complete sequence σ=[σ1,…,σn] is a permutation of all jobs inJ, where each σj, j=1,…,n, is in someJk. Given a sequence σ, the completion time of job σjin machine i is denoted as Cij(σ), being Cj(σ) the completion time of job σjin the last machine on which this job needs to be processed. Without loss of generality, we omit σ in the completion times unless necessary.A classification for MASPs can be obtained extending on the standard triplet α∣β∣γ notation by Graham, Lawler, Lenstra, and Rinnooy Kan (1979) (see Pinedo, 1995 for a complete description). The α field represents the machine environment, i.e. including the single machine (1), identical machines in parallel (Pm), machines in parallel with different speeds (Qm), unrelated machines in parallel (Rm), flowshop (Fm), jobshop (Jm), or openshop (Om). We denote the case of the permutation flowshop (PFm) in order to obtain a clearer taxonomy of the problems with an empty β field (in the standard notation, the permutation condition in flowshops is indicated in the field β by the notation prmu).β indicates conditions applying to jobs. If a condition is applied only in some sets, then it is indicated by a super-index. Usual restrictions are:•Time-related conditions: Such as release dates (rj) and common due dates (dj=d).Processing-times-related conditions: Such as preemption (prmp); learning effect (learning)/deteriorating jobs (deteriorating) i.e. processing times decrease/increase with the starting time or the position of the job in σ; controlable processing times (ctrl), i.e.pijkis a variable in the problem and can be chosen in a given intervalp¯ijk,p̲ijk, with a cost of the compression of the processing times,cijk, which is penalized in the objective function byCtrlsumk=∑i=1m∑j∈Jkcijkp¯ijk-pijk; and on-line problems (on-line), when processing times only become known on arrival, opposite to off-line problems, which is the usual case, when processing times are known in advance.Batch-related constraints (batch): Parallel batch (p-batch) indicates that a machine can process up to b jobs simultaneously, being the processing time of a batch equal to the largest processing time of the jobs in the batch. In serial batching (s-batch), jobs are processed sequentially with a setup time for each batch (i.e. setup time between two jobs is equal to zero if both jobs are scheduled in the same batch). This case is also called family/part type-dependent setup times, including the case where a family is determined by a set of jobs. There may be batch capacity restrictions (denoted as b⩽x, otherwise we assume b=∞), where each job has a size sizej. Finally, there may be incompatible sets (IS) if jobs from different sets cannot be placed in the same batch.Availability constraints: A case treated in the literature is that of forbidden intervals (I), denoting a time interval where no jobs can be scheduled. The number of forbidden intervals is denoted by n∗.Precedence: This condition can be applied to machines or jobs: Machine precedence is denoted as mi↦mjindicating that jobs must be processed by machine mibefore entering in machine mj. Job precedence is denoted prec.Usually, γ includes the objective function to be minimized. In our proposal, it contains a model indicating the performance measures fkused for each set of jobsJk. Different problems or approaches can be defined using the functions fk. In order to unify the notation, we integrate some of the multicriteria approaches in T’kindt and Billaut (2002) with those found in the MASP literature:•Linear Convex Combination (LCC) approach: We denote Fl(f1,…,fK) if the objective is to minimize a linear convex combination of the K criteria,∑i=1Kλifi, where∑i=1Kλi=1.Epsilon-constraint (∊-constraint) approach: We denote ∊(f1/f2,…,fK), if the objective is to minimize f1 subject to fk⩽∊k, ∊k⩾0 for k=2,…,K. Constraints can be defined for all or for some fk, i.e. ∊k=+∞ for some values of k. An instance of an ∊-constraint problem may not have feasible solutions, and it is denoted feasible if there is at least one feasible solution.Pareto approach: We denote #(f1,…,fK) if the objective is to enumerate all Pareto optima. A schedule σ is weak Pareto optimum if and only if ∄σ′ such that ∀k=1,…,K, fk(σ′)<fk(σ), and it is strict Pareto optimum (or efficient solution or non-dominated solution) if and only if ∄σ′ such that ∀k=1,…,K, fk(σ′)⩽fk(σ) (fk(σ′)<fk(σ)), with at least one strict inequality.Other approaches found in the literature are Goal Programming and Lexicographical approach. The goal programming approach, denoted GP(f1,…,fK), also named feasibility model or decision model, is the special case ∊(f/f1,…,fK), with f constant. The goal here is to find a feasible schedule σ satisfying fk⩽∊k, k=1,…,K. The lexicographical approach, denoted Lex(f1,…,fK), minimizes all criteria in the given order.Note that the order in which fkare considered is only relevant for the ∊-constraint and the lexicographical approaches, as different orders imply different problems.For each approach, different forms of fkcan be considered. Cheng, Ng, and Yuan (2006) distinguish two types depending on the functionsgjkapplied to the completion timesCjk,j∈Jk, k=1,…,K, i.e.: max-form:maxfk=max1⩽j⩽nkgjkCjk, and sum-form:∑fk=∑1⩽j⩽nkgjkCjk. When the jobs are weighted, we denote the functions maxwkfkand∑wkfkrespectively.Ifgjkare non-decreasing functions ofCjkfor allj∈Jk, then they are called regular performance measures (see e.g. Pinedo, 1995). We denote a regular performance measure with capital letter.Among non-regular performances measures, only those related to earliness, defined as Ej=max{0, dj−Cj}, have been found in the review. These performance measures, jointly with the related to the tardiness defined below, are called just in time performance measures (see e.g. T’kindt & Billaut, 2002 for more information).Table 1summarizes the regular and non-regular performance measures encountered in the literature. The usual definitions for lateness (Lj=Cj−dj), tardiness (Tj=max{Cj−dj, 0}), and unit penalty (Ujyields 1 if Cj>dj, 0 otherwise) apply.Finally, we also analyze performance measures employed in the rescheduling literature in order to include them in the notation proposed. In rescheduling, usually two sets of jobs are considered: old jobsJO, and new jobsJN, as well as two schedules: an initial sub-sequence σo, formed by jobs inJO, and a final sequence obtained when jobs have been rescheduled σn, formed by jobs inJ=JO⋃JN. There are two approaches depending on σo(Hall & Potts, 2004): to consider a single disruption, so the original schedule is optimal with respect to the initial scheduling objective, or to consider the most recent of multiple disruptions, so the initial schedule is regarded as arbitrary due to previous disruptions.Different ways to measure the disruption of jobs inJOcan be considered:1.No tardy jobs constraint. In this case, jobs inJOcannot be late, which means that Cj⩽dj,∀j∈JO. There are several (equivalent) ways to model this constraint, such asmaxLjO⩽0,maxTjO=0(equivalent tomaxTjO⩽0),∑TjO=0(equivalent to∑TjO⩽0), and∑UjO=0(equivalent to∑UjO⩽0). All of these models have a weighted counterpart. Note that these constraints are on the form of an ∊-constraint approach. If the objective is to minimize f subject to no tardy jobs for the setJO, it is denoted as 0(f/fO), withfO∈{maxLj,maxTj,∑Tj,∑Uj,maxwjTj,∑wjTj,∑wjUj}.Sequence disruption: Dj(σo, σn)=∣y−x∣ with y the position of the job j in σo, and x its position in σn. When there is no ambiguity, the notation is simplified to Dj, with objectives maxDjand∑Dj.Time disruption: Δj(σo, σn)=∣Cj(σn)−Cj(σo)∣. When there is no ambiguity, the notation is simplified to Δj, with objectives maxΔjand∑Δj.Depending on the approach, machine setting, objective function, etc., there are many different problems in the literature. A broad classification is to divide the problems into basic problems (i.e. when there are no conditions for the machines or jobs, i.e. the most general case indicating only the machine environment and the objectives considered for each set of jobs) and extended problems (i.e. where specific conditions are imposed). Prior to this classification, it is useful to recall the complexity of the different problems and to derive general properties that may apply to some approaches. Both aspects are discussed in the next section.Many contributions in the literature about MASPs are devoted to classify and/or determine the complexity of different problems. In the same way as in single criterion and classical multicriteria scheduling problems, the complexities of some MASPs can be determined by reductions to known problems. In this subsection we intend to give a first step to determine the relationship between the complexities of MASPs and known problems.Complexity theory is based on languages theory and Turing machines (see Garey & Johnson, 1979). A problem belongs to a class of complexity, which informs us of the complexity of the “best algorithm” able to solve it (T’kindt & Billaut, 2002). We know the complexity of a problem if it can be reduced from/to another problem with a known complexity. A search (decision) problem π′ is NP-hard (NP-complete) if and only if another search (decision) problem π is NP-hard (NP-complete) and a reduction of π towards π′ exists. The problem π′ is at least as difficult to solve as the problem π. NP-hard problems are also called NP-hard in the ordinary sense, ordinary NP-hard, binary NP-hard problems, or weakly NP-hard. A subclass of NP-hard problems are the so-called strongly NP-hard problems (NP-hard in the strong sense or unary NP-hard). For detailed definitions we refer the reader to Garey and Johnson (1979), Gawiejnowicz (2008), and T’kindt and Billaut (2002).In order to establish the relationship among the complexities of single-criterion, multicriteria and MASPs, we use the following notation:•Di: Decision problem associated to the criterion fi.SCi: Single criterion problem with criterion fi.MC∗: Multicriteria scheduling problem (i.e. only one set of jobs is considered), * denoting the approach (see Section 3).MASP∗: MASP (i.e. two or more sets of jobs are considered), * denoting the approach.MASP∗DJ: MASP with disjoint sets of jobs, * denoting the approach.MASP∗GO: MASP with global objective, * denoting the approach.The special case of an MASP when all sets of jobs except one are empty is a single-criterion scheduling problem. T’kindt and Billaut (2002) (pp. 39–42) give a complete study about the complexities of single-criterion scheduling problems, providing the reduction trees depending on the machine setting, on the constraints and criteria. Since reduction tree of machine settings and reduction tree of constraints can be applied to multicriteria problems as well as to MASPs, they are not discussed here. Note that the latter allow us to identify the relationship among the complexities of basic and some simple cases of extended problems (under the same machine and criteria conditions). However, application of the reduction tree of criteria to multicriteria and therefore, to MASPs is not direct, since it depends on the approach.Within each approach, reductions can be developed whenever we consider two problems in which all sets (except one) involve the same objective functions, i.e. if α∣β∣f is reduced from α∣β∣g, then problem α∣β∣*(f1,…,fk,…,fK) is reduced from α∣β∣*(f1,…,gk,…,fK). Note that if all K sets in each problem have the same function, then α∣β∣*(f1,…,fk,…,fK) is reduced from α∣β∣*(g1,…,gk,…,gK).Another special case of MASPs is when all sets of jobs are equal. Then, the problem is equivalent to a standard multicriteria scheduling problem. However, there are more MASPs than multicriteria scheduling problems, since it does not make sense to consider multicriteria problems for the ∊-constraint and LCC approaches with equal objectives, while the multi-agent counterpart is well-defined.The relationship among the complexities of the different approaches is the same for multicriteria scheduling problems than for MASPs. We have adapted the reduction tree of multicriteria problems given by T’kindt and Billaut (2002) to MASPs (see Fig. 1, where a solid arrow from problem A to problem B indicates that a reduction exists from A to B). As it is possible to associate a decision problem with an optimization problem, the relation among their complexities is represented in Fig. 1 by dotted arrows. Therefore, the complexity of most problems concerning the goal programming approach are a straightforward consequence of the corresponding ∊-constraint version.Although the reduction tree for multicriteria and MASPs is the same, in general, the complexities of the MASPs are not the same as that of the corresponding multicriteria problems even if the objective functions are the same (Agnetis et al., 2004). Agnetis et al. (2004) give some examples where the complexities are not the same in the case of basic problems of the ∊-constraint approach. Therefore, the tables with the complexities for bicriteria basic problems for LCC, Lexicographical and ∊-constraint approaches provided by T’kindt and Billaut (2002) (pp. 116, 117) do not apply for MASPs. However, for the special case of MASPs with global objective, Huynh-Tuong et al. (2011) develop some reductions to these problems from single-criterion, bicriteria and MASPs with two disjoint sets of jobs. Only ∊-constraint and LCC approaches have been considered. The reductions have been adapted for general cases with more than two objective functions in Fig. 2, where solid arrow applies for regular measures, and dashed arrow implies reductions for objective functions belonging to the set{maxLj,∑wjCj,∑wjTj,∑Uj,∑wjUj}.An algorithm is a finite procedure that finds a solution to an arbitrary instance of a problem. In the literature, there are different methods to solve scheduling problems. Gawiejnowicz (2008), for example, presents a classification of different types of algorithms applied to scheduling in the literature (in particular to time-dependent scheduling problems), which can be extended to scheduling problem in general, and to MASPs in particular: Exact algorithms find the exact solution of a problem (not only feasible solutions). Polynomial-time algorithms are examples of exact algorithms that find the exact solution in polynomial-time. For the problems for which no polynomial-time algorithms are known, exact solutions can be found by enumerative, branch-and-bound (B&B) or dynamic programming algorithms. Pseudopoynomial-time algorithms are applied to NP-hard problems, and, in general, a problem which is strongly NP-hard cannot be solved by them. Approximation algorithms are polynomial algorithms that generate an approximate solution that is close to an optimal solution, measured by the worst-case ratio (approximation ratio), which is a number in single criterion problems. In multicriteria and MASPs with Pareto and Goal Programming approaches and objectives (f1,…,fK), the (β1,…,βK)-approximation schedule is the schedule which provides an approximation ratio of βkfor objective fk(see e.g. Lee, Choi, Leung, & Pinedo (2009) and Saule & Trystram (2009)). A family of approximation algorithms which generate solutions as close to the optimal one as desired is called an approximation scheme. There exist two types of approximation schemata: polynomial-time approximation scheme (PTAS) and fully polynomial-time approximation scheme (FPTAS). Finally, Heuristics and Metaheuristics are algorithms with unknown worst-case ratio. It is not possible to predict the behavior of this algorithm for all instances and their efficiency is evaluated by computational experiments. Some examples found in the MASP literature are Genetic Algorithms (GA), Simulated Annealing (SA), Tabu Search (TS), Variable Neighborhood Search (VNS), or Ant Colony Optimization (ACO).All previous methods can be applied to MASPs regardless the approach. However, the Pareto approach is the most difficult (see Fig. 1), and it is not easy to find methods to determine the set of Pareto optima for MASPs. Usually, a straightforward way is to solve repeatedly instances of the corresponding ∊-constraint problem for decreasing values of ∊ (for example, see Agnetis et al., 2004; Elvikis, Hamacher, & T’kindt, 2010a, 2009). Theoretically, an optimal solution to the ∊-constraint problem is a weak Pareto optimum. However, it is possible to assign an ∊ value to each strict Pareto optimum that it is an optimal solution to the associated ∊-constraint problem (Ehrgott, 2005). For example, if we consider an MASP with two disjoint sets of jobs on a single machine, the problem of finding one schedule which is also non-dominated among the optimal schedules of the ∊-constraint version can be always addressed by binary search (Agnetis et al., 2004).In some cases, only the cardinality (size) of the set of Pareto optima is provided. This size depends on the specific problem, and it can be polynomially bounded or not. Note that, when the number of tardy jobs is considered at least for one set of jobs, it is clear that the number of non-dominated schedules is linear.Agnetis et al. (2004) give a scheme for enumerating the set of Pareto optima when the problem involves two sets of jobs on a single machine. Fig. 3presents a generalization of this scheme for K sets of jobs, 1∥∊(f1/f2,…,fK), considering ∊=(∊2,…,∊K) the bounds of f2,…,fK, and a given vector δ=(δ2,…,δK) with δk>0, ∀k=2,…,K. This method depends on the corresponding ∊-constraint problem, and when it is polynomially solvable, the scheme turns out to be polynomial for those problems with a polynomial number of Pareto optima. Then, this method provides a way to determine the cardinality of the set of Pareto optima in some cases.For certain types of MASPs, some properties on the structure of their optimal solutions can be proved. Some of these properties have been proved by Baker and Smith (2003) for single machine MASPs. Baker and Smith (2003) consider only the LCC approach and some regular performance measures. Here we provide a generalization of these properties for all approaches and regular performance measures. Standard proofs by contradiction apply. These properties may be a starting point to study more complex problems (different layouts or extended problems) to determine their complexities and even to be applied to solution methods (exact or approximate) to solve these problems.The starting point for obtaining these properties is the problem 1∥maxCj, since any job sequence provides the same makespan, and therefore, all schedules are optimal. Consequently, it can be observed that this objective does not have influence on the solution of multicriteria problems and MASPs with two non-disjoint sets and makespan for the global objective function. Then, these problems have the same complexity as the single criterion problem for the other objective. For the rest of the cases, the complexity of MASPs considering makespan for some setJkdepends on the approach selected. The following properties are related to the sequences of jobs in optimal solutions according to the regular performance measures selected:Property 4.1There is an optimal solution for the MASP considering maxCjfor any setJk, in which the jobs belonging to this set are processed consecutively.The previous property implies that, the structure of an optimal solution to a problem with two disjoint sets of jobs considering makespan forJB, isJprecA∪JB∪JsuccA, whereJprecA∪JsuccA=JAandJprecA∩JsuccA=∅. Using this property, we can conclude that the optimal solution to these problems is completely defined by the partitionJprecA,JsuccAof the setJA, a result provided by Agnetis, De Pascale, and Pacciarelli (2009) for the specific case1‖∊maxLjA/maxCjB.Based on this property, it can be observed that the complexity of any MASP with LCC approach for two disjoint sets of jobs and makespan as one of the criteria is the same as the corresponding single criterion problem for the second criterion (Baker & Smith, 2003). This result can be generalized as follows: the complexity of any MASP with LCC approach for more than two disjoint sets of jobs and makespan criterion forJkis the same as the corresponding problem without the kth set (Cheng, Ng, & Yuan, 2008).However, for the ∊-constraint approach (and consequently for the Pareto approach) the problems cannot be reduced from the single criterion case even for two sets of jobs. For example,1‖∊∑wjCjA/maxCjB(see Section 5) is NP-hard (Agnetis et al., 2004), and1‖#∑wjCjA,maxCjBhas an exponential number of non-dominated solutions (Agnetis, Pacciarelli, & Pacifici, 2007b), while1‖∑wjCjis polynomial (Lawler, Lenstra, Rinnooy Kan, & Shyu, 1993, chap. 9).Property 4.2There is an optimal solution for the MASP considering maxLjfor one of the sets,Jk, in which the jobs belonging to this set are ordered by non-decreasing values of the due datesdjk, that is, EDD order (even though they may not appear consecutively in the schedule).There is an optimal solution for the MASP considering∑Cjfor one of the sets,Jk, in which the jobs belonging to this set are ordered by non-decreasing values of their processing timespjk, that is, SPT order (even though they may not appear consecutively in the schedule).Property 4.3 cannot be adapted for∑wjCjusing the WSPT order for any set of processing times and weights (for a counterexample see Agnetis et al., 2007a, chap. 2). Baker and Smith (2003) tried to prove it for1‖Fl(∑wjCjA,FB)whenFB∈{maxCj,maxLj,∑wjCj}ifpiA⩽pjAandpiAwiA⩽pjAwjA. However, Yuan et al. (2005) give a counterexample showing the property to be incorrect. They provide a weakened version of the property, and their proof can be generalized to other approaches when all functions are regular:Property 4.4There is an optimal solution for the MASP considering∑wjCjfor one of the sets,Jk, withpik⩽pjkwheneverwik>wjk, in which the jobs belonging to this set are ordered by non-increasing values ofpjk, that is, in SPT order.In this section we review basic problems where no conditions on machines or jobs are imposed (i.e. the field β is empty) and the problems have the form α∥γ. We classify the problems in disjoint and non-disjoint sets of jobs. The former case can be known as competing sets of jobs, and the latter as interfering sets of jobs.For each case, we classify the problems according to the approach: LCC, ∊-constraints and Pareto. Some results about the GP approach are included whenever appropriate.In most of the problems addressed in this approach, the layout is the one-machine case. Complexities for two sets of jobs are summarized in Table 2where fAand fBare regular functions. As the problem is symmetric, we have indicated the complexities in the upper part of a triangular matrix. These problems have been studied by Baker and Smith (2003), Yuan et al. (2005), Agnetis et al. (2007a, chap. 2) and Soltani et al. (2010).Apart from the cases in Table 2, Agnetis et al. (2007a, chap. 2) show that the general case1‖FlmaxFjA,maxFjB(withmaxFjAandmaxFjBregular functions) can be solved inO(n3logn). Additionally, for more than two sets of jobs, Cheng et al. (2008) show that the complexity of1‖FlmaxFj1,…,maxFjKisO((n1n2…nK)Klogn)forFjk∈Tjk,Ljk,∀k=1,…,K.As discussed in Section 4,1‖Fl(maxCjA,maxCjB)is trivial (Baker & Smith, 2003). Moreover, this problem for K sets of jobs (K>2) is polynomially solvable inO(n+KlogK)(Cheng et al., 2008). However, the weighted version1‖Flmaxwj1Cj1,…,maxwjKCjKis proved to be strongly NP-hard by Cheng et al. (2008) (since1‖GP∑wjACjA,maxLjBis strongly NP-complete). The cases1‖FlmaxFjA,∑UjBand1‖FlmaxFjA,∑CjBare shown to be both polynomially solvable inO(n3logn)by Agnetis et al. (2007a, chap. 2). Although1‖FlmaxCjA,∑wjBCjBis polynomially solvable by the WSPT rule (Baker & Smith, 2003), the problem1‖FlmaxwjACjA,∑wjBCjBis proved to be strongly NP-hard by Feng and Yuan (2007). Nong et al. (2011) give a 2-approximation algorithm for this problem. However, they prove that this problem is NP-hard in the ordinary sense when nAis fixed, and develop a PTAS for the case where preemption of jobs inJBis allowed, which can be applied to the case without preemption.Soltani et al. (2010) develop a GA and SA for1‖FlmaxLjA,∑wjBCjB, which can be seen in Table 2 that it is NP-hard. Baker and Smith (2003) reduce1‖FlmaxCj1,maxLj2,∑wj2Cj3to the latter problem by consolidating jobs inJ1as a single job jAwith processing timep1=∑j∈J1pjand weight w1=1 and consideringJA=J2andJB=jA⋃J3.Regarding other layouts, only the problemPF2‖FlmaxCjA,maxCjBhas been studied by Luo, Chen, and Zhang (2012), showing that it is NP-hard. They provide a dynamic programming algorithm with running timeO(nP4),P=∑j∈Jpj. They also develop a FPTAS with running timeO(n5/δ8), being δ>0 the worst-case ratio.In this section, we review the problem when the sets of jobs are disjoint considering the ∊-constraint approach. Most studies are devoted to one-machine layout and two sets of jobs. Table 3summarizes the complexities for 1∥∊(fA/fB) when fAand fBare regular functions. For the single machine case, Agnetis et al. (2004) proved that the symmetric problems are equivalent, since it is possible to reduce 1∥∊(fB/fA) from 1∥∊(fA/fB) by a binary search in a logarithmic number of instances. Then, in the same way that the LCC approach, we have indicated the complexities in the upper part of a triangular matrix. These problems have been studied by Agnetis et al. (2004), Ng et al. (2006), Agnetis et al. (2007a, chap. 2), Agnetis, De Pascale, and Pacciarelli (2009), and Leung et al. (2010).The general case1‖∊maxFjA/maxFjB, with maxFjregular is polynomial (Agnetis et al., 2004, 2007a, chap. 2). This result is extended by Agnetis et al. (2004) for more than two sets of jobs, giving Agnetis et al. (2007b) an algorithm for the goal programming counterpart. Moreover, Agnetis et al. (2004) prove that1‖∊∑wjACjA/maxFjBis NP-hard by proving that the goal programming counterpart is NP-complete, although1‖GP∑Cj1,maxFj2,…,maxFjKis polynomial inO(n1logn1+n′logn′), withn′=∑k=2Knk(Agnetis et al., 2007b).Although1‖∊∑wjACjA/maxFjBis NP-hard, the case withmaxLjBis shown to be strongly NP-hard by Ng et al. (2006). The case1‖∊∑wjACjA/maxCjBis addressed by Kellerer and Strusevich (2010) by means of an FPTAS. They show it to be equivalent to a single criterion problem with one fixed non-availability machine interval in the case that the non-availability is resumable and the total weighted completion time as objective.As we can see in Table 3, the problem1‖∊∑wjACjA/∑wjBCjBis NP-hard. This complexity also holds for more than two sets of jobs (Lee et al., 2009). These authors provide an FPTAS to solve the goal programming version of this problem for the single machine and the unrelated parallel machines. In the same way, Agnetis et al. (2004) find1‖∊∑Uj1/∑Uj2,…,∑UjKto be polynomially solvable since1‖∊∑UjA/∑UjBis polynomially solvable too. This result implies that the goal programming counterpart is polynomial too, although the weighted version1‖GP∑wj1Uj1,…,∑wjKUjKis proved to be strongly NP-complete by Cheng et al. (2006). These authors present an FPTAS for the problem and prove that it is polynomial when K is arbitrary and the weights and epsilon values of all sets are positive integers. Related to the latter problem, Agnetis et al. (2007a, chap. 2, 2007b) obtain aO∑k=1K′nk∏k=1Knk+nlognrunning time algorithm for the problem1‖GP∑wj1Uj1,…,∑wjK′UjK′,maxfjK′+1,…,maxfjK.Regarding problems considering non-regular performance measures, Mor and Mosheiov (2010) study the general case wheremaxfjk=maxj∈Jkfjk(Ejk), with k=A, B, providing an algorithm to solve the problem in polynomial time withO(nBlognB+(nA)2).With respect to other layouts different from the single machine, although1‖∊maxCjA/maxCjBis trivial, the ∊-constraint problem with the same objective is shown to be NP-hard for even the 2-machine open shop (Agnetis et al., 2004) and, consequently, for the permutation flowshop (Luo et al., 2012). For the last problem, Luo et al. (2012) provide an FPTAS. A consequence is thatPFm‖∊maxCjA/maxTjBis NP-hard, and the structure of the solutions is studied by Perez-Gonzalez et al. (2011) for common and different due dates.PF2‖∊∑CjA/∑UjBandPF2‖∊∑TjA/∑UjBare both NP-hard (Lee, Chen, Chen, & Wu, 2011, 2010). The authors present B&B as well as SA algorithms for both problems.Finally, there are some rescheduling problems where the objective is to minimize a function of one set of jobs subject to that one or more functions of the other set to be bounded. All of them have the form1‖∊(fA/f1B,f2B), and are presented in Table 4. Some properties about feasibility and conditions for optimal schedules are given by Mu and Hao (2010) for1‖∊fA/fB,maxDjBand1‖∊fA/fB,maxΔjBwhenfA,fB∈{maxCj,∑Cj,maxLj}. Polynomially solvable algorithms for1‖∊(maxCjA/maxCjB,maxDjB)and1‖∊maxCjA/maxCjB,maxΔjBare given by Mu and Gu (2010). The rest of the problems can be solved by dynamic programming algorithms (Mu & Gu, 2010; Mu & Hao, 2010).In this section, we review the problem of finding the set of Pareto optima when there are disjoint sets of jobs. As discussed in Section 4, some authors only provide an algorithm to determine the size of the non-dominated sets. For1‖#maxFjA,∑CjB, the size of the non-dominated set is at most nAnB(Agnetis et al., 2004, 2007a, chap. 2). Agnetis et al. (2004, 2007b) provide procedures to determine the size of the non-dominated set with complexityO(nAlognA+nBlognB). For the weighted case,1‖#maxFjA,∑wjBCjB, Agnetis et al. (2007b) show that it may have an exponential number of non-dominated solutions with respect to the instance size. The case with parallel machinesPm‖#maxCjA,∑CjB, is shown to be NP-hard by Balasubramanian et al. (2009), developing several constructive heuristics and a GA. Saule and Trystram (2009) show thatPm‖#maxCj1,…,maxCjKis strongly NP-hard, and provide an approximation algorithm for the problem for an arbitrary number of machines.Agnetis et al. (2004) prove that finding one non-dominated solution for1‖#∑CjA,∑CjBis NP-hard, and the number of non-dominated solutions may be exponential with respect to the instance size. Saule and Trystram (2009) study the case with more than two sets,1‖#∑Cj1,…,∑CjK, proposing an approximation algorithm and extending the approach toPm‖#∑Cj1,…,∑CjK. Lee et al. (2009) develop the same approximation algorithm for the goal programming counterparts1‖GP∑Cj1,…,∑CjKandRm‖GP∑Cj1,…,∑CjK. For the weighted case1‖#∑wjACjA,∑wjBCjB, an algorithm based on the Nash Bargaining Solution is proposed by Agnetis, De Pascale, and Pranzo (2009). For1‖#∑wj1Cj1,…,∑wjKCjKwith K fixed, Lee et al. (2009) develop an FPTAS for computing a δ-efficient set (according to the definition given by Warburton, 1987), with δ the error bound. Additionally, Saule and Trystram (2009) consider the case for parallel machines,Pm‖#∑wj1Cj1,…,∑wjKCjK, developing approximation algorithms for this problem andPm‖#∑wj1Cj1,…,∑wjK′CjK′,maxCjK′+1,…,maxCjK″with K=K′+K″.Finally, Agnetis et al. (2000) consider a job shop problem, J2∥#(fA, fB), assuming that bothJAandJBcontain only one job with nAand nBoperations, and fAand fBnon-regular cost functions fi(Ci). For this problem, the set of non-dominated schedules is identified, and an algorithm to generate them in polynomial time is provided. The running time depends on the number of incompatible pairs, defined as a pair of operations ofJAandJBwhich require the same machine and cannot be done in parallel.For this approach, only one machine problems have been studied. Table 5shows the complexity of these problems with global objective for some regular measures analyzed by Huynh-Tuong et al. (2011) and Huynh-Tuong and Soukhal (2010).Hall and Potts (2004) study several rescheduling problems, shown in Table 6. They considerJAas the set of old jobs, andJis the set of old and new jobs. Objective functions aref∈{∑Cj,maxLj}andfA∈maxDjA,∑DjA,maxΔjA,∑ΔjA, considering all of them with a single disruption. Additionally, the study includes the case with multiple disruption (md) for the problem1‖Fl∑Cj,maxDjA. Finally,1‖FlmaxwjTj,∑FjAis addressed by Li and Cheng (1999), withJAthe set of the new jobs. The objective is to determine the due dates of the new jobs which are calculated depending on their completion times by considering∑FjA=∑j∈JAdj(Cj)as a function cost. The problem is shown to be NP-hard, although the unweighted version is polynomially solvable inO(n4).Similar to the LCC approach, the single machine layout is the most extended case, all of them with global objective function. Taking into account that the problem is not symmetric, most of them have the form 1∥∊(f/fA), whereas 1∥∊(fA/f) has not been tackled in the literature. Table 7shows the complexity of these problems for some regular measures given by Huynh-Tuong et al. (2011) and Huynh-Tuong and Soukhal (2010). Additionally, the problem with more than two sets of jobs1‖∊maxFj/maxFj1,…,maxFjKis polynomially solvable inO(n2)(Sadi et al., 2012). For this approach, Hall and Potts (2004) study some rescheduling problems whose complexities are shown in Table 8. All problems are studied with a single disruption, and for several cases where there may be several job arrivals, multiple disruptions (md) are included. Finally, Sadi et al. (2012) show that Pm∥∊(f/fA) is NP-hard iffA,f∈{maxLj,∑Cj,∑wjCj,∑Uj,∑wjUj,∑Tj,∑wjTj}. They also give a dynamic programming algorithm to solve the problem for m=2 andfA,f∈{maxCj,∑Cj}in running timeO(n2∊).In this case, we are only aware of the work by Ben Ltayef, Loukil, and Teghem (2009), who address the PF2∥#(maxCj, fA) and PF2∥#(maxTj, fA) problems, wherefA∈∑DjA,maxDjA,∑ΔjA,maxΔjA. They give the mathematical formulation for these problems, and present solution procedures based on SA and TS.Extended problems have some condition/s for jobs and/or machines, indicated in the field β. In the next subsections, we review the main contributions for each approach. Note that, given the heterogeneity of the problems addressed, it is not possible to clearly classify the contributions as in the case of basic problems. Nevertheless, we have identified the following categories: Release times and/or preemption; Variable processing times (processing times are not fixed values); Batch and/or set-up; and Others. These categories should be interpreted in a loose manner and only as a way to classify the disparity of contributions.Regarding problems in which release times are allowed,1|rj|FlmaxCjA,maxCjBis shown to be NP-hard by Ding and Sun (2010), who also give an optimal algorithm withO(nA+nB)running time for its preemptive version. For the on-line case, i.e.1|on-line,rj,prmp|FlmaxCjA,maxCjBthey develop an approximation algorithm. The equivalent problem without preemption,1|on-line,rj|FlmaxCjA,maxCjB, is also addressed giving an on-line algorithm with a lower bound of the competitive ratio of the problem.Different contributions are due to Cheng et al. (2008) for some specific cases with more than two sets and regular performance measures. They prove that 1∣prec, I, prmp∣Fl(F1,…,FK) and 1∣prec∣Fl(F1,…,FK) can be solved in pseudo-polynomial time when K is fixed. Finally, the case without precedence 1∥I, prmp∥Fl(F1,…,FK) is polynomial withO((n∗logn∗+nlogn)∏k=1KnkK), where n∗ is the number of forbidden intervals, whenFk∈maxwjACjk,maxLjk.The assumption of preemption for all jobs in both sets has only been studied for the problem1|prmp|∊∑UjA/maxFjBby Agnetis et al. (2004), who show that it is solvable inO(nAlognA+nBlognB). The case1|prmp,rj|∊maxFjA/maxFjBwhere release times for all sets of jobs are added to the preemption hypothesis is addressed by Leung et al. (2010),who show that is polynomially solvable inO(n2). This complexity can be further reduced toO(nAlognA+nBlognB)when the criterion forJAismaxLjAor∑CjA, and toO(n3(nAnB)2)when it is∑UjA. Moreover, they show that1|prmpA,rj|∊∑CjA/maxTjBand1|prmpA,rj|∊maxLjA/maxTjBare solvable inO((nA)nB+1lognA)when ∊=0. Finally, they study some problems on parallel machines:P2|prmp|∊∑CjA/maxFjBis solvable inO(nAlognA+nBlognB)(this result is shown by Wan et al. (2010) too). However, the problem with release dates for all jobs is NP-hard when m⩾2 and fixed. Additionally,Pm|prmp|∊∑UjA/maxFjBis solvable inO(n2nAnB)for m=2, inO(n3m-5(nA)2(nB)2)time for m>2 and fixed, and NP-hard when m is arbitrary. Furthermore, they show that the assumption of release dates transform the problem into NP-hard even for m⩾2 and fixed. Finally, the problemPm|prmp|∊maxFjA/maxFjBis solvable inO(log(αU-αL)nlog(nm)), whereαU=maxj∈JAFjA(P)andαL=minj∈JAFjA(0). When release times are considered, the complexity isO(log(αU-αL)n3).Leung et al. (2010) show that1|rjB|∊maxFjA/maxTjBis NP-hard. Note that this result, although developed independently from Ding and Sun (2010), is a consequence of the NP-hardness of the1|rj|FlmaxCjA/maxCjBshown by the latter authors. The problem is NP-hard too for the criteria∑CjAand∑UjA. However, if preemption is allowed, all corresponding problems are polynomially solvable.Yin, Wu, Cheng, and Wu (2012) consider two problems with release dates for all jobs. First, they prove that1|rj|∊∑CjA/maxLjBis strongly NP-hard. Therefore,1|rj|∊∑TjA/maxLjBis strongly NP-hard too, and they present a mixed integer programming model, a B&B with some dominance rules and a marriage in honey-bees optimization algorithm.Cheng, Ng, and Yuan (2007) study different problems with preemption, precedence constraints and forbidden intervals. They show that the problems1|prmp,I,precB|∊∑FjA/maxFjBcan be polynomially reduced to1|prmp,I|∑FjAinO((nB)2+n∗logn∗), solving it in(O((nB)2+nAlognA+n∗logn∗))when∑FjA∈∑CjA,∑UjA.Finally, for more than two sets of jobs, Agnetis et al. (2007b) address1|prmp|∊F1/maxFj2,…,maxFjKand1|prmp,I|∊F1/maxFj2,…,maxFjKin order to discover some properties that were later applied to their basic counterpart.Pm|prmp|∊∑Fj/∑Fj1,…,∑FjKis considered by Sadi et al. (2012), showing that it is NP-hard. They present a linear programming model for the general case with un-related machines in parallel.The references reviewed in this section assume that the processing times are not fixed in advance. They include deteriorating jobs, learning effect and controllable processing times. For the1|deteriorating|∊maxFjA/maxFjBproblem, Yin, Cheng, and Wu (2012) give a polynomial time algorithm with running timeO((nA)2+nBlognB).1|deteriorating|∊maxLjA/maxCjBand linear deterioration is shown to beO(nAlognA)by Liu and Tang (2008), Liu, Feng, Zhou, and Tang (2010), and Liu, Yi, and Zhou (2011b).There are no such general results when both functions are not under the max form. However, there are algorithms to optimally solve a number of problems inO(nAlognA+nBlognB), such as1|deteriorating|∊∑CjA/maxFjBwith linear deterioration depending on the starting time (Liu & Tang, 2008; Liu, Yi, & Zhou, 2011a, 2011b) and with linear deterioration depending on the position of the jobs (Liu, Zhou, & Tang, 2010); as well as for1|deteriorating|∊∑EjA/maxFjBand1|deteriorating,djA=d|∊∑wjAEjA/maxFjB(Yin et al., 2012).The problem1|deteriorating|∊∑TjA/∑UjBwith ∊=0 is tackled by Gawiejnowicz, Lee, Lin, and Wu (2010) and Gawiejnowicz, Lee, Lin, and Wu (2011). In the first reference, the authors develop a B&B combined with simple heuristics and local search, while in the second present an evolutionary algorithm.Liu, Tang, and Zhou (2010) study the problem1|deteriorating,s-batch|∊∑CjA/maxFjB, where the processing times as well as the setup times of each job are linear functions of its starting time. They tackle two problems depending on the type of the deteriorating function, proposing two algorithms to solve both problems inO(nAlognA)time respectively.Regarding the learning effect,1|learning|∊∑CjA/maxFjBis shown to be solvable inO(nAlognA+nBlognB)if there is a linear deterioration depending on the position of the jobs (Liu, Zhou, et al., 2010). For the1|learning|∊(∑Tj/∑Uj)problem with ∊=0, Wu, Huang, and Lee (2011) present a B&B and develop heuristic algorithms for larger instance sizes. The problem1|learning|∊∑wjACjA/∑UjBwith ∊=0 is addressed by Cheng, Cheng, Wu, Hsu, and Wu (2011) with a position based function. They show that the problem is NP-hard since the corresponding basic case is already NP-hard (Ng et al., 2006), and propose a B&B and three SA-based algorithms.The combination of position-based- learning and deteriorating effects is addressed by Cheng, Wu, Cheng, and Wu (2011), as they show that the1|learningA,deterioratingB|∊∑CjA/maxLjBproblem is NP-hard. A B&B is proposed, as well as several SA-based algorithms. Wu, Cheng, Wu, and Yin (2012) address the same problem with a different position-based function. Again, a B&B and metaheuristics based on ACO are provided and compared.Regarding controllable processing times, Wan et al. (2010) address several 1∣ctrl∣∊(fA/fB) problems:•For the objective∊(CtrlsumA/maxLjA,maxFjB)with ∊=(0, ∊B), the problems where β isctrlA,rjA,prmp; ctrlA, rj, prmp; and ctrlA, prmpAare shown to be polynomial with running timeO(n(logn+k+1)), with k the number of different costs ofJA. However, the case where β isctrlA,rjA,prmpAis strongly NP-hard.When β is ctrlAand ctrlA, prmpA, the problem with objective∊CtrlsumA+∑CjA/maxFjBis polynomial with running timeO((nA)2nBnlogn), andO((nA)2nBn)for∊CtrlsumA+maxTjA/maxFjBand∊CtrlsumA+maxLjA/maxFjB. However, when β isctrlA,rjA,prmpAall of them are strongly NP-hard.Finally, for the parallel machines case, the problemP2|ctrlA,prmp|∊∑FjA+∑CjA/maxFjBis shown to be polynomially solvable inO(nBlognB+(nA)3+(nA)2nB)by Wan et al. (2010).The p-batch case has been studied by Li and Yuan (2012) for different forms of fAand fB, including both incompatible and compatible sets of jobs. Table 9shows the complexities and the running times in the pseudo-polynomial and polynomial cases on a single machine, whereαU=maxj∈JAfjA(P),P=∑j∈JpjandαL=minj∈JAfjA(0).The s-batch case is addressed by Mor and Mosheiov (2011) when set-up times depend on the set and the batches of jobs inJBmust be processed continuously, i.e. the batches of jobs inJAare partitioned into two sequences, scheduled prior to and after the batches of jobs inJB, respectively. They introduce an efficientOn32solution algorithm for the resulting problem1|s-batch,pj=1|∊∑CjA/∑CjB.The problem1|s-batch|∊∑wjBCjB/maxTjA,setup,∑DjAis analyzed by Unal et al. (1997) with ∊=(0,0,0). The objective is to minimize the total weighted completion times of jobs inJB, integrating them into the schedule of jobs inJAmaking any job inJAtardy and without incurring any setup times or changing the relative sequence of the jobs inJA. They show that the problem is NP-hard, and that the specific case wherepj=1∀j∈Jis solvable in polynomial time. This case turns to be strongly NP-hard if there are chain-like precedence constraints on the jobs inJA.Fan (2010) study the1|V(1,∞),direct|∊∑CjA/∑CjBproblem for a particular case where each set of jobs belongs to a customer situated at different locations. Jobs are processed and delivered to each customer by a uncapacitated vehicle. In this case, Cjis the completion time plus transportation time. V(1, ∞), direct specifies that a single delivery vehicle can deliver any number of orders, and that only jobs going to the same customer can be delivered together in the same shipment. The authors prove that the problem is NP-hard, and develop a dynamic programming algorithm with complexityO(n8).In the case of unrelated machines, the only contributions are Elvikis et al. (2009) and Elvikis et al. (2010a) for theQm|pj=p|∊FA,maxCjBproblem, which is used to solve the Parero counterpart. The complexity of this problem depends on the form of FA, and it is reduced from the complexity of the Pareto counterpart indicated in the following subsection.Regarding flowshops, there are very few contributions. Huynh-Tuong and Soukhal (2009a) show that theF3|JA(m1↦m2),JB(m2↦m3)|∊maxCjB/maxCjAproblem is NP-hard. Huynh-Tuong and Soukhal (2009b) provide a pseudo-polynomial algorithm with running timeO(nB∊β), withβ=∑j∈JB(p2j+p3j). Finally, Perez-Gonzalez et al. (2011) analyze the structure of solutions for the problemPFm|dj=d|∊maxCjA/maxTjBwhen ∊=0. As the problem is NP-hard by reduction fromPF2‖∊maxCjA/maxCjB, Perez-Gonzalez and Framinan (2010b) develop some heuristics and a VNS method are proposed which are tested for this problem.Cheng et al. (2007) present a polynomial algorithm to obtain the set of non-dominated solutions for1|prmp,I,precB|#fA/maxfjBwithfA∈{∑Cj,∑Uj}, giving a bound of the running time. The algorithm is valid for the cases without precedence constraints.The problem1|rj,prmp|#∑CjA,∑wjBUjBis shown to be NP-hard by Meiners and Torng (2007). However, they show that if pj=1 is polynomially solvable.Regarding other settings, only Peha (1995) models the problemPm|rj,pj=1|#∑wjACjA,∑wjBUjBfrom a practical application about real-time systems and integrated services networks. They develop an algorithm to solve this problem inO(n2)running time.Tan, Chen, Du, and Li (2011) consider the1|p-batch|#maxCjA,maxCjBproblem where each job has a different size. This problem is shown to be NP-hard by reduction to the case with one set of jobs. They give the mathematical formulation of the problem, and provide an ACO to solve it. Moreover, an evaluation is carried out in order to compare ACO to a GA adapted from the one set problem.Yazdani Sabouni and Jolai (2010) provide one heuristic for each of the following problems: Problem1|p-batch,IS,b⩽n|#maxCjA,maxLjBand equal size of the jobs, problem1|p-batch,IS|#maxCjA,maxLjB, and problem1|p-batch,CS,b⩽n,pjB=p|#maxCjA,maxLjBand equal size of the jobs. They also show that the heuristic for the first problem turns to be optimal ifpjB=p. Finally, Feng, Yu, and Shang (2011) study the problem1|s-batch,IS|#maxCjA,maxLjB, giving a polynomial time algorithm withO(nA+(nB)4).The case of unrelated machines has been only studied in the context where pj=p whenJAandJBhave only one job with nAand nBoperations respectively,Qm|pj=p|#maxFjA,maxFjB, addressed by Elvikis and T’kindt (2012) and Elvikis et al. (2010b). They develop an algorithm that enumerates all Pareto solutions of this problem inO((nA)2nB+nAnBlognB)running time. The algorithms are further refined by Elvikis et al. (2009, 2010a) forQm|pj=p|#FA,maxCjB, with FAany regular function. For this problem, they develop an algorithm to enumerate the set of Pareto solutions by solving iteratively the ∊-constraint version of this problem with different ∊ values. The algorithm hasO(nlogm+nAψ)running time, with ψ depending on the time needed to assign jobs inJA. When FAtakes a regular sum form, the aforementioned generic algorithm reduces its running time toO(n4). Moreover, for∑wjACjA,∑TjAand∑wjATjAwith the due dates and weights agreeable, i.e.dj⩽dj′⇒wj⩾wj′, the running time isO(nlogm+ψ′), with ψ′ the time to solve1|pj=1|∑FjA. Additionally, for∑UjAand∑wjAUjA, the running time isO(nlogm+nAlognA). When FAtakes a regular max form, the non-dominated solutions can be found inO(n3). Furthermore, formaxCjA, there are only two strictly non-dominated solutions, and finally, formaxLjAthey develop anO(nlogm+nAlognA)running time algorithm.Finally, Peha (1995) consider the problemPm|pj=1|#∑wjACjA,∑wjBUjBwhere the complexity of the algorithm isO(nlogn).Some references found in the literature consider MASPs with different objective functions and do not correspond to the previous subsections. Some of them are applied problems.Agnetis et al. (2007a, chap. 2) consider a constraint specific of MASPs, where a coordination protocol is defined by an arbitrator. Each set of jobs belongs to an agent, who submits the jobs one by one to the arbitrator on each step. Between those jobs provided for each agent, the arbitrator selects one according to a priority rule, and schedules it at the end of the current schedule (initially empty). In this problem, the objective is to determine the order to provide the jobs for each agent to the arbitrator, since the priority rule is public information, whereas jobs characteristics are private information of the respective agent. Some rules encountered in the literature include priority rules (such as the well-known SPT, WSPT, EDD); Round-Robin rule (denoted as RR), where jobs are alternated from each set; ork-R, where at most k consecutive jobs of the same set are selected according to ruleR. Considering the single machine problem, Agnetis et al. (2007a, chap. 2) prove that1|RR|Fl∑CjA,∑CjB,1|RR|#∑CjA,∑CjB,1|k-R|Fl(∑CjA,∑CjB)and1|k-R|#∑CjA,∑CjBare solvable using the SPT rule. Although1|WSPT|#∑wjACjA,∑wjBCjBis optimally solvable by WSPT rule, for the LCC case the weights must be the same. Finally, they also prove that, for the problem1|EDD|Fl∑UjA,∑UjB, the coordination rule (for example EDD) turns out to be ineffective.In the previous sections we have mentioned some problems considering the goal programming approach used to solve problems of different approaches. However, there are some references explicitly addressing a goal programming objective. For example,1|p-batch,IS|GP(maxLjA,maxFjB)is solved by Li and Yuan (2012) by an algorithm developed previously to solve1|p-batch,IS|∊(maxFjA/maxFjB), and which can be easily applied to this problem. The running time of this algorithm isO(nnAnBlog(αU-αL))whereαU=maxj∈JAFjA(P)withP=∑i=1m∑j∈Jpij, andαL=minj∈JAFjA(0). Moreover, Cheng et al. (2008) shows that1|prec|GPmaxFj1,…,maxFjKis solvable inO(n2), and the running time isO(n∗logn∗+n2), depending on the number of forbidden intervals, n∗, if we consider the case with preemption. The same problem is polynomially solvable inO(n∗logn∗+nlogn)without the precedence constraint. Finally, Cheng et al. (2006) shows that1|prmp|GP∑Uj1,…,∑UjKis equivalent to the basic case, and this problem with forbidden intervals is reducible in linear time to the equivalent basic problem, with modified due dates.The rest of the references are applied problems. First, Peha and Tobagi (1990) consider a MASP applied to traffic in telecommunications (file transfer or interprocess communication) on a single packet-switched network. They consider two sets of jobs formed by packets,JAandJB, and a lexicographical approach where the objective functions are∑wjAUjA∑j∈JAwjAandmaxwjBLjB∑j∈JBwjB. They present an algorithm withO(n2)for the weighted and the unweighted cases.Arbib et al. (2004) consider two problems with two disjoint sets of jobsJAandJB: in the first problem the objective is to maximize the minimum between∑FjAand∑FjB. The second one is an ∊-constraint approach where the objective is to maximize∑FjAsubject to∑FjB⩾∊. Problems are solved by pseudo-polynomially dynamic programming algorithm.Finally, some authors consider the problem where jobs (inJA) and maintenance tasks (inJB), are scheduled together. PMBis the frequency of the maintenance tasks, indicating that there is a tolerance interval between the earliest and the latest time separating two consecutive occurrences of the maintenance taskj∈JBfor each machine. Bouzid-Sitayeb, Ammi, Varnier, and Zerhouni (2008) develop an ACO and it is compared to a GA for the problemPFm|PMB|LexmaxCjA,∑EjB+∑LjB. Moreover, Khelifati and Bouzid-Sitayeb (2011b, 2011a) consider the same problem for the LCC approach,PFm|PMB|FlmaxCjA,∑EjB+∑LjB, suggesting a multi-agent system and developing a simulation experiment.Some rescheduling problems are studied by Yang (2007). They prove that1|ctrlB|Flf,CtrlsumB,∑ΔjAis polynomially solvable inO((nA)2.5(nB)2.5)time when f is∑Cj. However, when f is∑Tjthe problem is NP-hard, and Yang (2007) solve it by a very large scale neighborhood search method, which is compared to a B&B algorithm.A number of results have been produced for the 1∣rj∣∊(max Cj/fA) problem for different functions fA:•FormaxDjA, the problem is polynomially solvable inO((nB)2n)(Yuan & Mu, 2007). The on-line version is solvable by algorithms with competitive ratio32(Mu & Guo, 2009a, 2009b).For∑DjA, the problem is solvable inO((nlogn+(nB)2)logrmax)withrmax=maxj∈Jrj(Yuan et al., 2007). They show that the symmetric problem1|rj|∊∑DjA/maxCjcan be solved inO(nlogn+(nB)2).FormaxΔjA, it is strongly NP-hard (Yuan & Mu, 2007). However, Mu and Guo (2009b) show that the on-line version is solvable by an algorithm with competitive ratio32.For∑ΔjA, it is strongly NP-hard (Yuan & Mu, 2007).1|deteriorating|∊∑Cj/fAis analyzed by Zhao and Tang (2010) for different functions fA:•FormaxLjAis solvable inO(nlogn)when ∊=0.Two algorithms of identical complexityO(n+nBlognB)are provided formaxDjA, one in the case of job-dependent processing rate, and other where there is a constant processing rate for all jobs.Two algorithms are provided formaxΔjA, one in the case of job-dependent processing rate, and other where there is a constant processing rate for all jobs. The complexity of the first one isO(n+nBlognB); beingO(n5)that of the second one.Regarding learning effect,1|learning|∊∑wjCj/maxCjAis addressed by Li and Hsu (2011). Since the corresponding basic problem is already NP-hard, they present some dominance properties and a lower bound for the B&B algorithm. Then, three GA algorithms are proposed and compared.Finally, regarding batches, the rescheduling problem1|s-batch,FRA|∊maxCj/maxDjAis studied by Mocquillon, LentT, and T’kindt (2008). FRAmeans that the order of jobs inJAis given and it has to be kept. They propose a polynomial time algorithm with running timeO(n+nBlog2nB).

@&#CONCLUSIONS@&#
In this work, we have reviewed a high number of papers containing different contributions to the field of multicriteria scheduling problems considering two or more sets of jobs. Up to 75 papers have been identified as related to the problem in the sense presented in this work, including only those papers written in English. Doing an analysis of the literature we concluded that the most suitable name for this kind of problems is interfering jobs scheduling problem. However, the most used term is multiagent scheduling problem (MASP). Problems have been classified in basic or extended problems, indicating the approach considered (Linear Convex Combination approach; ∊-constraint and Pareto approach). In the following, we will highlight the main conclusions and try to set some possible future research avenues.The first comment refers to the fact that there are much more works solely devoted to extended problems (47) than to basic problems (20). Moreover, eight references consider both types of problems. This may be seen as an indicator that the research has been so far conducted by specific application areas rather than for a systematic approach, which is not surprising given the lack of an integrated framework that hopefully our paper may help to build. While there are clear advantages for the application-oriented approach (such as providing sound, real-life justification for research in the area) more research on the basic problems would set the foundations for gaining further advances on extended problems. Then, extensions of the solution procedures for the former can be implemented in the latter.A second general comment is that most of the works refer to the one machine setting, which is clearly an indication of the fact that we are on the early stages of the research. Moreover, most of the single machine problems are NP-hard, so we can expect that a big number of problems are NP-hard. Therefore, in the next years, the number of contributions addressing other settings would increase. Interestingly, the proportion of works dealing with layouts different than the one-machine is higher for the extended problems than for the basic problems. Again, this point out the direction that most research has been application-driven.Regarding basic problems, the case of disjoint sets of jobs has been the one receiving more attention. Some comments about the main results can be done:•In the one-machine layout, the LCC approach has been found to be polynomially solvable for many objectives, and only some specific cases of weighted objectives are shown not to be polynomial. Outside this layout, only the permutation flowshop with two machines has been studied for a very simple case (maxCjAandmaxCjB), which is already NP-hard.The ∊-constraint approach has been found not to be polynomially solvable except for a very simple case, even for one machine and two objectives. However, relatively few approximate algorithms have been proposed for these problems. The cases with three or more objectives have been addressed only for specific rescheduling-related objective functions.With respect to the Pareto approach, less work has been done, bounding the number of non-dominated solutions for most of the problems, mainly because the complexity of this approach.Basic problem with non-disjoint sets of jobs have been addressed only for the case where one of the sets contains all jobs (called interfering jobs problems with global objective function). An interesting future research line could be to analyze the complexity for the more general case of non-disjoint (interfering) sets of jobs (i.e. when one of sets does not contain all jobs). The contributions with global objective function consider the ∊-constraint and LCC approaches, and they are due to two groups of authors, analyzing complexities for a great number of problems. There are hardly any algorithm proposed for these problems, so it is a open issue for this approach. In contrast, such algorithms have been proposed for the Pareto approach.Regarding the extended problems, the case considering only one constraint has been scarcely studied, and a research avenue could be initiated in this area. Most of the works have been done for the case of disjoint sets of jobs under the LCC approach. In this type of problems, some general results have been presented regarding the learning effect. In contrast, those obtained for controllable processing times are very specific, focusing on the determination of the polynomially solvable cases. Regarding the Pareto approach, it is worth to note that many problems have been found not to be polynomially solvable, and several approximate algorithms (mostly based on metaheuristics) have been presented. Extended problems with non-disjoint sets of jobs have been scarcely studied, all of them for one machine.Regarding solution procedures, there is an extensive contribution on studying the complexity, and a considerable number of one machine problems providing exact procedures have been found. It would be interesting to extend these results to other, more complex, machine layouts, even if it is likely that the complexity would increase. In contrast, there are relatively few approximate procedures available for the rest of the problems addressed with higher complexity (although it can be observed a concentration of similar methods for similar problems, for example some papers considering deteriorating and learning constraints). The relative scarcity of solution procedures is again another sign of a research field in its earliest stages, and it makes difficult to apply the research results. Another consequence of this fact is that there are only a handful of test beds to generate problem instances in which the solution procedures can be tested. Most of them consider the same size of the sets of jobs, avoiding extreme cases. Therefore, it may be interesting to generate a common and exhaustive test bed, considering different cases for the sizes of the jobs, in order to facilitate the comparison among solution procedures.Finally, it is also worth mentioning that, in the case of more than two sets of jobs, most of the work is preliminary and for some specific cases, pointing at other future area of research.