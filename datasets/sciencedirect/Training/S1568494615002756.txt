@&#MAIN-TITLE@&#
The runner-root algorithm: A metaheuristic for solving unimodal and multimodal optimization problems inspired by runners and roots of plants in nature

@&#HIGHLIGHTS@&#
A new optimization algorithm inspired by the plants propagated through runners is proposed.Global search with random large steps is performed at all iterations (exploration).Local search with random small steps (exploitation) is performed only if global search fails.Local search is performed by roots and root hairs.It does not necessarily apply a same number of function evaluations at all iterations.

@&#KEYPHRASES@&#
Meta-heuristic optimization algorithm,Nature inspired,Nonparametric statistical analysis,Robust control,Root,Runner,

@&#ABSTRACT@&#
This paper proposes a new metaheuristic, the runner-root algorithm (RRA), inspired by the function of runners and roots of some plants in nature. The plants which are propagated through runners look for water resources and minerals by developing runners and roots (as well as root hairs). The first tool helps the plant for search around with random big steps while the second one is appropriate for search around with small steps. Moreover, the plant which is placed at a very good location by chance spreads in a larger area through its longer runners and roots. Similarly, the proposed algorithm is equipped with two tools for exploration: random jumps with big steps, which model the function of runners in nature, and a re-initialization strategy in case of trapping in local optima, which redistributes the computational agents randomly in the domain of problem and models the propagation of plant in a larger area in case of being located in a good position. Exploitation in RRA is performed by the so-called roots and root hairs which respectively apply random large and small changes to the variables of the best computational agent separately (in case of stagnation). Performance of the proposed algorithm is examined by applying it to the standard CEC’ 2005 benchmark problems and then comparing the results with 9 state-of-the-art algorithms using nonparametric methods.

@&#INTRODUCTION@&#
During the past four decades nature had been the source of inspiration for developing new optimization algorithms for solving complicated engineering problems. The first attempts to find a cybernetic solution to a practical problem can be found in the works of Rechenberg [1]. However, the first general-purpose and well-explained algorithm of this type is probably the genetic algorithm (GA) developed by Holland [2]. At this time, various nature-inspired optimization algorithms are available, among them the GA, particle swarm optimization (PSO) [3,4], ant colony optimization (ACO) [5,6], artificial bee colony (ABC) algorithm [7,8], simulated annealing (SA) [9,10], teaching-learning based optimization (TLBO) [11], bacterial foraging optimization (BFO) [12], artificial immune system (AIS) [13], shuffled frog-leaping algorithm (SFLA) [14], differential evolution (DE) [15] and its variants like SaDE [16], imperialist competitive algorithm (ICA) [17], and some others have attracted more attentions. It is a well-known fact that metaheuristic optimization algorithms are capable of solving many complicated engineering problems whose solutions cannot effectively be obtained by using classical (often, gradient-based) optimization algorithms. Numerous successful applications of these algorithms can be found in the literature (see e.g. [18–20]).Although the source of inspiration is different for nature-inspired optimization algorithms, they still have many similarities. The main relationships between various nature-inspired optimization algorithms are: application of random variables, ability of dealing with uncertain and non-differentiable cost functions, simultaneous application of more than one computational agent for searching the domain of problem, existing a kind of communication scheme between computational agents (e.g., the crossover operator in GA, the social term in PSO, pheromone trail in ACO, dancing of artificial bees in ABC, etc.), and application of the objective function itself rather than its derivative for performing the search. It can be said that a high percent of metaheuristic algorithms actually model the behavior of a certain living things or a certain physical phenomena by performing an optimization. This kind of modeling through optimization is always iterative and makes use of random variables, but the method is not wholly stochastic and has a kind of memory to remember the good solutions of previous iterations and provide the fittest agents of the colony with a more chance to survive and reproduce.The aim of this paper is to propose a new metaheuristic for solving both unimodal and multimodal optimization problems. The proposed algorithm is inspired by plants such as strawberry and spider plant which propagate through their runners in nature and simultaneously develop roots and root hairs for local search for water resources and minerals (for this reason this algorithm is called the runner-root algorithm (RRA) in the rest of this paper). Similar to some other metaheuristics, RRA does not apply the same number of function evaluations (FE's) at all iterations. More precisely, in RRA the global search for optimal solution (exploration procedure) is performed at all iterations while the local search (exploitation procedure) is performed only when the global search does not lead to a considerable improvement in the value of cost function. Note that the idea of using the runners of plants for developing a metaheuristic algorithm has already been used in the so-called plant propagation algorithm (PPA) [21]. However, the only similarity between the proposed algorithm and PPA is in using the idea of runners.In order to justify the usefulness of developing a new metaheuristic algorithm we should note that the performance of any algorithm of this type frequently depends on the problem itself, and consequently, a metaheuristic algorithm may be very successful in dealing with a certain problem while it is not so successful in dealing with another one. Hence, the performance of different metaheuristics is often examined by subjecting them to some standard benchmark problems of different type (such as CEC benchmarks [22]) and then analyzing the results by using nonparametric statistical methods [23,24]. Another important fact is that according to NFL theorem [25] there is no best algorithm. Hence, any new metaheuristic deserves more study if in dealing with a considerably high percent of benchmark problems it leads to the best results compared to other state-of-the-art algorithms.The rest of this paper is organized as the following. In Section 2 we briefly review the method of propagation of plants like spider and strawberry plant which can move through their runners. The proposed algorithm is explained in Section 3. Section 4 presents the nonparametric comparisons results of RRA with 9 other state-of-the-art algorithms. A practical open problem in the field of robust control theory is solved using RRA and the results are presented in Section 5. Finally, Section 6 concludes the paper.Animals can tolerate environmental changes much better than plants since they have muscle and brain and can decide to move to places with better conditions whenever it is needed. Probably, the most famous examples of this type are the birds which immigrate to warmer places when the weather gets cold. But, the plants are connected to the earth through their roots and cannot move to places with desired conditions anyway. However, some grasses and plants (such as strawberry and spider plant) can be propagated through the so-called runner (or stolon) as shown in Fig. 111The author of Fig. 1(b) is Macleay Grass Man.(vegetative propagation). The runner is a creeping stalk produced in the leaf axils and grows out from the mother (parent) plant. At the second node of runner a new plant, called daughter plant, is formed and then again a new runner arises on the daughter plant to generate another new daughter plant (see Fig. 1). Initially, runner plants produce fewer roots but thereafter put forth excessive fibrous roots and when acquired sufficient growth and roots, the daughter plants can be separated from the mother plant and continue their life individually as the new mother plants. Reproduction of plants such as strawberry can be thought of as a kind of plant movement since both the mother and daughter plants have exactly the same genes and they form actually a same plant. However, the mother plant commonly dies sooner than the daughter plant provided that the daughter does not arrive at a location with a very bad condition by chance.From the mathematical point of view, plants with runners perform a kind of optimization. More precisely, such plants simultaneously perform both the global and local search to find resources like water and minerals by developing runners and roots (as well as root hairs), respectively. Both the runners and roots are developed almost randomly, but when a runner or a root (hair) arrives at a place with more water resources, the corresponding daughter plant generates more runners, roots, and root hairs, which affects the growth of the whole plant as well. It concludes that if a daughter plant traps in a local optimum point it generates more runners and roots which help it reaching farther places and escaping from that point (this observation is modeled by the re-initialization procedure in RRA, which randomly distributes the agents in the domain of problem).Obviously, in order to arrive at a numerical optimization algorithm inspired by plants like strawberry we need to model the behavior of these plants by simple yet effective rules. In this paper it is assumed that the behavior of such plants can effectively be modeled through the following three facts:•Each strawberry mother plant is propagated through its runners. These runners rise randomly and each one leads to a new daughter plant (global search with big steps for resources).Each strawberry mother plant develops roots and root hairs randomly (local search with relatively big and small steps for resources).Strawberry daughter plants which have access to richer resources grow faster, generate more runners and roots, and consequently cover larger areas. On the other hand, the daughter plants which move toward poor resources are more probable to die.The above rules serve as the source of inspiration for developing the proposed RRA which is discussed with more details in the next section.Similar to other metaheuristic optimization algorithms, the proposed algorithm begins with a uniformly distributed initial random population in the domain of problem, each of them called a mother plant. The number of mother plants is considered equal to Npop. Next, at each iteration any mother plant, except the fittest one, generates a daughter plant (using runners) randomly in the domain of problem (global search for better solutions). The distance of each of these daughter plants from the corresponding mother plant is controlled through a constant parameter called drunner(larger drunnerlarger the distance of daughter plant from its mother plant). The fittest mother plant generates a daughter plant exactly at the same location as itself. Using this procedure Npopdaughter plants are generated. In RRA it is assumed that at each iteration each mother plant moves to the location referred to by its daughter plant. If at least one of these daughter plants leads to a considerable improvement in the value of cost function compared to the one obtained from the beginning of algorithm, all of the required mother plants of the next iteration are selected among these daughter plants using a combination of elite and roulette-wheel selection method. More precisely, in this case one of the required Npopmother plants of the next iteration is considered equal to the fittest daughter plant of current iteration (elite selection) and the others are obtained by applying the roulette-wheel method to these daughter plants. This statement is equivalent to the fact that while a considerable improvement in the value of cost function is observed, the algorithm continuously investigates the domain of problem for better solutions only through runners (random large steps) which are developed in the vicinity of current solutions (mother plants of current iteration). The amount of this improvement is measured through a parameter called tol which is equal to the relative (or absolute) change in the minimum values obtained for cost function in two successive iterations by all daughter plants.But if none of the resulted daughter plants leads to a considerably better value for cost function, the algorithm begins the local search procedure by means of its roots and root hairs. In this case the algorithm assumes that the fittest daughter plant (among those obtained in the current iteration) is located exactly at the same valley as the unknown global best solution, and consequently, applying a random change to each variable of that daughter plant separately and accepting it in case of observing any improvement can move it toward the global best solution. More precisely, if the applied random change to the certain variable of fittest daughter plant leads to a better solution, the algorithm accepts it and applies a random change to the other variable of the resulted modified daughter plant. Else, the previous value of that variable is kept and a random change is applied to the next variable of that daughter plant. This routine is applied to all variables of the fittest daughter plant one by one (note that during the global search procedure, random changes are applied simultaneously to all variables of the selected mother plants while during local search only the variables of the fittest daughter plant are subjected to random changes one by one). Clearly, this strategy guarantees the general movement of the fittest daughter plant toward the closest minimum point located at the same valley, which may be the global best solution. Since in this case it may happen that the fittest daughter plant is located either in a very flat or a narrow valley, both the large and small random changes should be applied to each variable of the best daughter plant. The large and small random changes, which play the role of roots and root hairs in nature, are applied separately and controlled by the constant parameters drunnerand droot, respectively (see the following for more details).After performing the global and local (if necessary) search procedures as mentioned above, mother plants of the next iteration are selected among the resulted daughter plants by using elite and roulette wheel method as described before (note that according to the above discussion, at each iteration only one of the daughter plants, which is the fittest one before applying local search, may be subjected to fine tuning through the local search procedure and the others remain unchanged). To sum up, at each iteration first a global search procedure is performed and one daughter plant is generated for every mother plant. If none of the resulted daughter plants leads to a considerable improvement in the value of cost function, variables of the fittest resulted daughter plant are subjected to random changes one by one by both small and large steps.The fact that the local search is not applied at all iterations and not to all of the daughter plants can significantly save the number of FE's. However, since it may happen that eventually the algorithm traps in a local optimum point, in order to increase its functionality the algorithm needs to be equipped with a restart (re-initialization) strategy. For this purpose, after global and possible local searches, if the relative improvement in the value of cost function in two successive iterations be less than tol (as defined before) the value of a counter called stall_coune is increased by one, else it is set equal to zero. If the value of this counter reaches the predefined value stall_max, the algorithm restarts with a new initial random population. More precisely, in this case all of the solutions obtained so far are discarded and only the best solution obtained in the last iteration is memorized only to be compared with those obtained previously or will be obtained later to determine the final best solution (hence, when the algorithm restarts, no solution is transferred from the last iteration which led to re-initialization to the next one). Note that every time the RRA is used to solve a certain optimization problem it may happen that either it restarts several times or it does not restart at all. For comparing purposes, the fitness evaluations consumed before any re-initialization should be counted toward the cumulative sum. In the following we discuss on different parts of this algorithm with more details.Consider the following unconstrained optimization problem(1)minf(x),xl≤x≤xu,wheref:ℝm→ℝis the m–variable cost function to be minimized,x∗=argminf(x)∈ℝmis the global best solution vector to be calculated, andxl,xu∈ℝmare two vectors indicating the lower and upper bounds of variables. In case of dealing with a constrained optimization problem one can use standard methods to convert that problem to an equivalent unconstrained one [26]. As mentioned earlier, RRA begins with a set of Npopm-dimensional randomly-generated vectors in the domain of problem each serves as an initial mother plant. Then, at each iteration any mother plant except the best one generates a random daughter plant and the best one generates a daughter plant exactly equal to itself. Letxmotherk(i)denotes the location of the k-th mother plant (k=1, …, Npop) at the i-th iteration wherexmother1(i)is equal to the fittest daughter plant of the previous iteration (chosen according to the elite selection) andxmotherk(i)(k=2, …, Npop) are the mother plants selected among the daughter plants of the last iteration using roulette wheel. Hence, using this notation, location of the k-th daughter plant at i-th iteration,xdaughterk(i), is calculated as(2)xdaughterk(i)=xmother1(i)k=1xmotherk(i)+drunner×rk,k=2,…,Npop,whererk∈ℝmis a vector whose entries are independent random numbers with uniform distribution in the range [−0.5, 0.5], and drunneris a scalar representing the maximum distance of daughter plants from the mother plant. Note that according to (2) the best daughter plant of the last iteration is necessarily considered as a mother plant, as well as a daughter plant, in the current iteration. Note also that for calculation of any daughter plant a new random vector rkmust be generated (the reason for using the subscript k for rk). The value assigned to drunnermust be sufficiently large such that it can provide the mother plants trapped in local minimums with a chance to get out of there and further look for the global best solution (which may be in a point as far as xu−xlform the current local minimum point). Hence, the runners play the very important role of jumping over local minimums, which effectively help the algorithm to avoid trapping in these points. Clearly, in dealing with an optimization problem with known bounds on variables as given in (1) the value of drunnershould be comparable with the biggest entry of xu−xl.The cost function is evaluated at the locations of daughter plants as calculated in (2). If at least one of these daughter plants leads to a significant improvement in the value of cost function compared to the best daughter plant of the previous iteration, i.e., if the inequality(3)mink=1,…,Npopf(xdaughterk(i))−mink=1,…,Npopf(xdaughterk(i−1))mink=1,…,Npopf(xdaughterk(i−1))≥tol,is satisfied, the algorithm does not begin the local search procedure since (3) means that the global search is still effective (starting the local search procedure when the global search still finds better solutions is not reasonable since local search often consumes a vast number of FE's while its outcome may be dominated by the global search procedure performed in the next iteration). If the cost function is defined such that the denominator of (3) has the chance of being equal to zero, the absolute difference may be used instead of the term in the left hand side of (3). But if (3) is not satisfied, the local search should be done. For this purpose let us denote the best daughter plant among those calculated in (2) as xdaughter,best(i), and the vector obtained by applying a random change to the k-th entry of xdaughter,best(i) as xperturbed,k, i.e.,(4)xperturbed,k=diag{1,1,…,1,1+drunnernk,1,…,1}×xdaughter,best(i),where drunneris the same as before, nk(k=1, …, m) is a random number with normal distribution (μ=0 and σ=1) and diag{1, 1, …, 1, 1+drunnernk, 1, …, 1} is a diagonal matrix whose all diagonal elements except the k-th one are equal to unity and the k-th one is equal to 1+drunnernk. In order to perform the local search, calculate xperturbed,kfor k=1 from (4). If f(xperturbed,1)<f(xdaughter,best(i)) then xdaughter,best(i)←xperturbed,1 else xdaughter,best(i) remains unchanged. Next, calculate xperturbed,kfor k=2 from (4) using the resulted xdaughter,best(i). Again if f(xperturbed,2)<f(xdaughter,best(i)) then do xdaughter,best(i)←xperturbed,2 else keep xdaughter,best(i) unchanged. Repeat this procedure for all of the m variables of xdaughter,best(i). So far the local search with random large steps (model of the function of roots in nature) is completed. Now, a local search with random small steps (model of the function of root hairs in nature) should be treated. This task is performed similar to the local search with random large steps as described before and the only difference is that the following equation is used instead of (4):(5)xperturbed,k=diag{1,1,…,1,1+drootrk,1,…,1}×xdaughter,best(i),where drootis a constant scalar often considered much smaller than drunner, xdaughter,best(i) is the final result of local search with random large steps performed before, and rk(k=1, …, m) is a random number with uniform distribution in the range [−0.5, 0.5] (a random number with normal distribution can be used as well). Note that neither for calculation of (4) nor (5) there is a need to do matrix multiplications and these two equations simply mean that only the k-th entry of xdaughter,best(i) should be subjected to a random change.After performing local search (if necessary) mother plants of the next iteration are selected among the daughter plants of current iteration using a combination of elite and roulette wheel selection. The elite selection can be done simply as the following(6)xmother1(i+1)←xdaughter,best(i).Before applying the roulette wheel method for selecting the remaining required mother plants of the next iteration, the fitness of k-th daughter plant (k=1, …, Npop) is calculated as the following(7)fit(xdaughterk(i))=1a+f(xdaughterk(i))−f(xdaughter,best(i)),where a is a positive real constant controlling the selection pressure. Note that according to (7) the best daughter plant receives the maximum fitness which is equal to 1/a and the other daughter plants receive smaller fitness values. After calculating the fitness values, the probability of choosing the k-th daughter plant of current iteration as a mother plant of next iteration, pk, is calculated as follows(8)pk=fit(xdaughterk(i))∑j=1Npopfit(xdaughterj(i)).Note that many other methods (such as the so-called linear ranking method often used in GA) can also be used instead of (7) for calculating the fitness of daughter plants. Note also that in dealing with (7) we havexdaughterk(i)=xdaughter,best(i)for some k. The algorithm may also get restarted as described before.Pseudo-code of RRA is presented in Table 1. In this table rand represents a random number with uniform distribution within the range [−0.5, 0.5], each entry ofrk∈ℝmis defined the same as rand, and nk(k=1, …, m) is a random number with normal distribution (μ=0 and σ=1).Roughly speaking, exploration and exploitation refer to the ability of an algorithm to visit entirely new regions of search space and searching around the previous solutions, respectively (see [27] for a survey on this subject). It is a common belief among experienced evolutionary algorithms researchers that the functionality of any algorithm of this type strictly depends on its exploration and exploitation abilities and the method used to establish a good ratio between them. It is also believed that the differences between various metaheuristic optimization algorithms, as well as the functionality of a certain algorithm, can be explained by the exploration and exploitation methods and the rate of applying them. In the following we briefly study the exploration and exploitation ability of RRA.According to the previous discussion RRA is equipped with two tools for exploitation: first, the roots and root-hairs, which are specially designed for more search around the best solution of current iteration, and second, the elite selection schema which guarantees the transmission of the best solution of current iteration to the next iteration, and consequently, doing further searches around it. The proposed RRA also makes use of two different strategies for exploration. First, at each iteration all variables of each mother plant (except the best one) are simultaneously subjected to random changes with large steps. The length of these steps should be considered sufficiently large such that the computational agents have a chance to move to any point in the search space. Second, if no considerable improvement is observed in the minimum value obtained for cost function after certain number of successive iterations, the algorithm restarts with an initial random population uniformly distributed in the domain of problem (re-initialization). This re-initialization strategy is very important and effective in the proposed algorithm since it is observed that in dealing with some of the complicated multimodal benchmark problems this algorithm (without providing it with the re-initialization capability) has a good chance to find the global best solution, but if it cannot find it consuming more FE's does not help it anymore. In this case re-initialization can promote the exploration and highly increases the chance of finding the global best solution.In RRA the ratio of exploration and exploitation is managed by control parameters of algorithm. Although any parameter may implicitly affect the exploration-exploitation ability of algorithm, according to the sensitivity analysis presented in Section 4.3 and the simulation results presented in Section 4 the parameters stall_max and tol have the most significant effect on the balance between exploration and exploitation. More precisely, in general it is expected that increasing stall_max or decreasing tol leads to more exploitations since it decreases the chance of re-initialization. Moreover, according to the discussions in [27] RRA applies an adaptive schema for controlling the balance between exploration and exploitation since re-initialization happens when the best fitness does not considerably change for certain number of successive iterations.In this section we apply nonparametric (or distribution-free) inferential statistical methods to compare the performance of RRA with some other state-of-the-art metaheuristic algorithms. Nonparametric methods are mathematical techniques for statistical hypothesis testing which, unlike parametric statistics, make no assumptions (such as normality or homoscedasticity) about the probability distributions of the variables being assessed. These methods are especially useful when the outcomes of stochastic experiments are ordinal, ranked, subject to outliers or measured imprecisely. Currently, various nonparametric methods are available which can be used both for pairwise and multiple comparisons. Among others, the Sign test and Wilcoxon test (for pairwise comparisons) and Multiple sign test, Friedman test, Friedman aligned ranks test and Quade test (for multiple comparisons) are more widely used in the literature. The seminal paper [24] is especially devoted to the application of nonparametric statistical tests for comparing the performance of evolutionary and swarm intelligence algorithms. The data used in the following discussion is exactly adopted from [24], and the readers are referred to that paper for more information on this subject and also for the values assigned to the control parameters of the algorithms discussed in the following.Before applying any nonparametric stochastic test for comparing the performances of algorithms under consideration, one needs to solve a considerably large number of benchmark problems by them. As a general rule, in multiple comparisons the number of algorithms used must be lower than the number of benchmark problems [24], which is fulfilled in the current study. More precisely, here the comparison is made between 10 different continuous optimization algorithms, i.e., PSO, IPOP-CMA-ES [28], CHC [29], SSGA [30,31], SS-Arit [32], SS-BLX [33], DE-Exp, DE-Bin [15], SaDE [16], and RRA. For this purpose these algorithms are used to solve 25 different test problems of dimension 10 appeared in the CEC’2005 special section on real parameter optimization [22]. This set of benchmark problems consists of a wide variety of real parameter optimization problems including 5 unimodal functions (F1: shifted Sphere function, F2: shifted Schwefel's problem, F3: shifted rotated high conditioned Elliptic function, F4: shifted Schwefel's problem with noise in fitness, F5: Schwefel's problem with global optimum on bounds), and 20 multimodal functions (F6: shifted Rosenbrock's function, F7: Shifted rotated Griewank function without bounds, F8: shifted rotated Ackley's function with global optimum on bounds, F9: shifted Rastrigin's function, F10: shifted rotated Rastrigin's function, F11: shifted rotated Weierstrass function, F12: Schwefel's problem, F13: expanded extended Griewank's plus Rosenbrock's function (F8F2), F14: shifted rotated expanded Scaffers F6, F15–F25: hybrid functions defined through compositions of 10 out of 14 previous functions). More details on the benchmark problems and the settings of the parameters used in algorithms can be found in [22] and [24], respectively. In [24] all of the above algorithms (except RRA) have been applied 50 times to each test function, where each of these runs stops either after 100,000 FE's or when the error obtained is less than 10−8. Table 2, which is the exact replication of the data presented in [24], shows the average error obtained for each algorithm (except RRA) over the 25 benchmark functions under consideration. Note that the reason why some entries in Table 2 are less than 10−8 is that the last improvement was so big (especially when IPOP-CMA-ES is used to solve F1–F3 and F6).The proposed RRA is also subjected to the similar experiment as described above. For this purpose, in order to show the effect of re-initialization strategy on the performance of RRA, first each of the benchmark problems under consideration is solved 50 times independently (each of these runs possibly consists of several re-initializations) assuming a certain value for the control parameter stall_max as well as others. Then each of these problems is solved again 50 times independently assuming another value for stall_max (other control parameters are considered exactly the same in two experiments), and finally the averaged results obtained in two cases are compared. For this purpose, first the control parameters of RRA are considered as droot=10−3, drunner=3, Npop=50, a=10−1, stall_max=250, and tol=10−3, and the next time all of them are considered as before except stall_max which is considered equal to 100 (the effect of re-initialization strategy could also be studied by changing the value of tol instead of stall_max, however, changing stall_max seems more effective). The results obtained by applying RRA to CEC’2005 benchmark problems as described above are shown in Table 3. Note that, as it is observed in this table, it is expected that in dealing with unimodal problems increasing the value assigned to stall_max (i.e., decreasing the rate of re-initializations) improves the quality of results, which is generally achieved at the cost of decreasing the performance of algorithm in dealing with multimodal problems. All of the comparisons presented in the next sections are treated using the data presented in Table 2 and in the rightmost column of Table 3 (obtained assuming stall_max=100).The pairwise comparisons can be used to compare the performance of two algorithms when applied to a common set of benchmark problems. Two well-known methods for this purpose are the Sign test and the Wilcoxon signed ranks test. The latter is used in the following to detect the possible significant differences between two algorithms since it is believed that Wilcoxon signed ranks test is safer and more robust compared to the sign test. In the following, RRA is considered as the control whose performance is compared with the other 9 algorithms under consideration.In the following first we briefly explain the Wilcoxon signed ranks test and then apply it to our problem. Let N be the sample size (i.e., the number of pairs which is equal to 25 in our study), which means that there are a total of 2N data points. Moreover, let x1,iand x2,i(i=1, …, N) denote the measurements. The Wilcoxon signed ranks test consists of the following five steps:1.For i=1, …, N, calculatex2,i−x1,iand sgn(x2,i−x1,i), where sgn is the sign function.Exclude pairs withx2,i−x1,i=0. Let Nrdenotes the reduced sample size.Order the remaining Nrpairs from smallest absolute difference to the largest absolute difference.Rank the pairs, starting with the smallest as 1. Ties receive a rank equal to the average of the ranks they span. Let Ridenote the rank.Calculate the test statistic W, which is equal to the absolute value of the sum of the signed ranks as the followingTable 4summarizes the results for Wilcoxon signed rank tests. In this table the (unadjusted) p-values are calculated using the procedure described above. However, these p-values are not suitable to extract a conclusion since the same data (the data for RRA) is tested multiple times. More precisely, an accumulated error is resulted from the combination of pairwise comparisons if we draw a conclusion comprising more than one pairwise comparison. Hence, when the same data is tested multiple times, a post hoc test must be applied to control the Family-Wise Error Rate (FWER), which is defined as the probability of making one or more false discoveries among all the hypotheses when performing multiple hypotheses tests [24]. In the next section we apply a post hoc analysis to determine which of the p-values presented in Table 4 are truly statistically significant.In this section the well-known Holm method is used for post hoc analysis (see [24] for a review of post hoc analysis methods including Holm's method). To briefly explain this method let p1, p2,…, pk−1 be the ordered p-values such that p1≤p2≤⋯≤pk−1 (k=10 for the data provided in Table 4). In the Holm procedure the i-th adjusted p-value (APVi) is equal tomin{v,1}wherev=max{(k−j)pj:1≤j≤i}, i=1, …, k−1. The resulted APV's can be compared directly with the chosen significance level α. More precisely, Holm procedure starts with the most significant p-value, i.e. APV1. If APV1 is below α the corresponding hypothesis is rejected and we are allowed to compare APV2 with α. If the second hypothesis is rejected, the test proceeds with the third one, and so on. Once a certain null hypothesis cannot be rejected, all of the remaining hypotheses are retained as well [24].Table 5shows unadjusted and adjusted p-values (using Holm procedure) for the data given in Table 4. According to the results presented in this table RRA shows an improvement in pairwise comparisons over CHC, SS-Arit, SS-BLX, PSO, and SSGA with the level of significance α=0.05. However, no improvement is observed when RRA is compared with IPOP-CMA-ES, DE-Exp, SaDE, and DE-Bin.Multiple comparisons tests can be used to carry out a comparison which involves more than two algorithms. These tests are divided into two main categories: 1×N and N×N comparisons tests. In the following we discuss only on 1×N comparisons tests, which can be used to highlight a control method among others. The Friedman, Friedman aligned ranks, and Quade tests are three well-known 1×N comparisons tests used in the literature. The procedure of these tests can be found in [24]. In the following we will only report the results obtained by using the standard Friedman test followed by the Holm post hoc procedure.Table 6depicts the average ranks achieved by the Friedman test according to the data provided in Table 2 and the rightmost column of Table 3. Using this test the algorithm which achieves a smaller rank is suspected to be a better performing algorithm (hence DE-Exp is suspected to be the best performing algorithm here). In Table 6 the p-value obtained through the statistics of the test strongly suggests the existence of significant differences among the algorithms considered. However, since the results in this table are obtained by multiple uses of the same data, a post hoc test must be applied to control FWER and before extracting any conclusion. For this purpose, first the (unadjusted) p-values corresponding to the Friedman ranks presented in Table 6 are calculated (see [24] for details) and then the corresponding adjusted p-values are obtained using the Holm procedure (the same as the one discussed in Section 4.1.2.). The results are presented in Table 7. As we can see in this table the Friedman test shows an improvement of RRA over PSO and CHC with the level of significance α=0.05. However, no improvement of RRA over the remaining 7 algorithms can be concluded.In the following we present the sensitivity analysis on control parameters of RRA. The reason for usefulness of this analysis is that it indicates the amount of robustness of algorithm to changes in control parameter settings. Clearly, smaller sensitivity is more desired since it means easier tuning procedure. For this purpose, F9 and F25 are chosen among the 25 different benchmark problems studied at the beginning of this section and the effect of changing the control parameters on the average error of these problems is studied (this approach is similar to the method used in [34] for sensitivity analysis). The reason for choosing F25 is that according to the data provided in Tables 2 and 3 RRA leads to the best results compared to other algorithms in dealing with this problem. Hence, the following discussion aims to show that this superiority is preserved after changing the values assigned to control parameters of RRA in this simulation. The reason for choosing F9 is that, as it is observed in Tables 2 and 3, in dealing with this problem RRA does not lead to the best results. Hence, the following sensitivity analysis aims to show that this algorithm is capable of performing considerably better by appropriate choice of its control parameters.Figs. 2 and 3show the sensitivity analysis results for F9 and F25, respectively. At each figure the value of control parameter is changed around its nominal value and then the corresponding value of average error is calculated (the horizontal line at each figure passes through the nominal value, where the values droot={10−3, 5×10−3, 10−2, 5×10−2, 10−1}, a={0.01, 0.05, 0.1, 0.5, 1}, and tol={10−4, 10−3, 10−2, 10−1} are used in simulations). Fig. 2 clearly shows that the average error in this example is highly affected by stall_max which controls the exploration ability of algorithm through the rate of re-initializations. In this example increasing the value assigned to stall_max decreases the rate of re-initializations, and consequently, provides the algorithm with a chance for more exploitation (more searches around the best solution obtained so far), which often improves the accuracy of results in dealing with unimodal and some multimodal problems. It is also observed that, as it is expected, decreasing the value assigned to tol has almost the same effect as increasing stall_max but with a lower severity.Fig. 3 shows the sensitivity analysis results for F25. The main point in relation to this figure is that, despite the variations in control parameters, the algorithm preserves its superiority over other algorithms. In this figure it is observed that increasing the value of tol, and consequently, increasing the rate of re-initialization significantly improves the accuracy of results.In this example we introduce an unsolved problem in the field of robust control theory and provide a numerical solution for it using RRA. Consider the single-input single-output (SISO) feedback system shown in Fig. 4where the uncertainty of process is modeled with the full multiplicative input uncertainty (ΔI∞≤1) [35]. In this figure assuming that the process nominal transfer function, G(s), and uncertainty weight,wI(s), are stable and known, the controller which simultaneously satisfies nominal performance (NP), robust stability (RS), and robust performance (RP) is obtained by solving the following H∞-norm inequality [35]:(11)|wPS|+|wIT|∞<1,where S=(1+KG)−1, T=KG(1+KG)−1, K is the unknown controller, and wpis the stable weight function used to determine the desired performance (i.e., it is assumed that the nominal feedback system with ΔI=0 has a desired performance if and only if we have|S|<|wP|−1, ∀ω).Note that the only unknown parameter in (11) is the transfer function of controller, K. As a classical result [35], the controller which satisfies (11) also guarantees NP, RS, and RP, but the nominal stability (NS) is not guaranteed in this case, i.e., the controller satisfies (11) may result in an unstable feedback system. Hence, any solution for (11) must also be checked from the NS point of view. In the following, we will consider the NS condition as a constraint for a minimization problem.At this time there is no method available to find a K which simultaneously satisfies (11) and guarantees the stability of nominal feedback system [35]. Instead, algorithms like hinfsyn in Matlab, find K such that the following closely related mixed sensitivity H∞ condition is satisfied(12)wpSwIT∞=maxω|wpS|2+|wIT|2<1.Although the above condition is within a factor of at most2to condition (11), they are not exactly the same [35]. Note that similar to (11), the NS is not included in (12). The very important point in relation to (11) (as well as (12)) is that it may or may not have a solution. However, when it has, often it is not unique (infinity many solutions exist in general). For that reason, this problem is often formulated as a minimization problem in whichγ≜|wPS|+|wIT|∞(orγ≜wpSwIT∞in dealing with (12)) is minimized by suitable choice of the (stabilizing) K. According to the above discussion it is obvious that the robust control problem under consideration really has a solution if for some stabilizing K we haveγ=|wPS|+|wIT|∞<1.The aim of this paper is to calculate K directly from (11). For this purpose we find K by solving the following constrained minimization problem:(13)minKγ=|wPS|+|wIT|∞s.t.1+KG(s)≠0,Re{s}≥0,where the constraint 1+KG(s)≠0, Re{s}≥0 represents the stability of the nominal closed-loop system. A classical approach for solving constrained optimization problems is to express the problem as an equivalent one without any constraints (a survey of techniques used for handing the constraints can be found in [26]). As the simplest method, the solution of (13) can be obtained by solving the following unconstrained optimization problem(14)minF(x)≜|wPS|+|wIT|∞+λ〈g(x)〉,where x is a vector containing the unknown parameters of controller, λ>0 is the penalty factor, g(x) is equal to the real part of the rightmost pole of the nominal closed-loop system (i.e., the system of Fig. 13 when ΔI=0), and 〈.〉 is the bracket function defined as the following(15)〈g(x)〉≜g(x)g(x)≥00g(x)<0.Note that according to (14) and (15), when the candidate solution x does not violate the stability condition, the real part of the rightmost pole of the nominal closed-loop system is negative, and consequently, the cost function is simply equivalent toF(x)=|wPS|+|wIT|∞. But, when the stability condition is violated, the second term in the right hand side of (14) puts an extra force on the algorithm to obtain solutions that lead to stable feedback systems. Clearly, larger the value of λ, higher the force on algorithm to find the solutions that stabilize the feedback system.In the following we use the above procedure to find a controller for a process with nominal transfer function G(s)=1000/(0.1s2+s) assumingwI=0.2andwP=(0.2s+1)/(s+0.001). In this example G(s) is the approximate model of a DC motor andwI=0.2represents the fact that this model has 20% uncertainty at all frequencies. Considering the fact that the order of K is at least equal to the order of process plus the weightswIandwP[30], the transfer function of controller can be considered as the following(16)K(s)=b2s2+b1s+b0s3+a2s2+a1s+a0,whereai,bi∈ℝ(i=0, 1, 2) are unknown parameters of the controller to be determined by solving (14) (note that here we have x=[a0a1a2b0b1b2]). Assuming λ=105, Npop=10, drunner=1010, droot=108, a=0.1, stall_max=2000, tol=10−3 and xu=−xl=1010, and after few independent runs (each stops after 2000 FE's) the solution of (14) using RRA is obtained as(17)K(s)=2.504×108s2+1.679×109s+1×1010s3+1.922×106s2+1×1010s+1×1010,for which we haveγ=|wPS|+|wIT|∞=0.2879and g(x∗)=−3.2364. Note that since the solutions that lead to unstable feedback systems are quite useless in practice, the value of λ is considered very large to make sure that such solutions are abandoned rapidly by algorithm. Moreover, no re-initialization occurs in this problem since each run stops after 2000 FE's which is equal to the value assigned to stall_max. Fig. 5shows|wPS|+|wIT|versus frequency (in log scale) for the controller given in (17). As it is observed, the plot is under 0dB at all frequencies which guarantees NP, RS, and RP (the NS is achieved by the negative value obtained for g(x∗) in log scale).Fig. 6shows the objective function value (as defined in (14)) versus the number of FE's in this problem (the simulations are performed assuming λ=105, Npop=10, drunner=1010, droot=108, a=0.1, stall_max=2000, tol=10−3 and the results are averaged over 100 independent runs). It is concluded from this figure that the average value of objective function becomes less than unity after 362 FE's, which means that it is expected that the algorithm can find a solution for this problem after such number of FE's. Fig. 7shows the unit step response of the closed-loop system under consideration for 30 different random Δ’s when the controller given in (17) is used.In order to convince the readers about the good performance of RRA for solving this special problem, the results are also compared with those obtained by using state-of-the-art algorithms DE (the DE/rand/1/bin with per-generation-dither variant) and ABC (the version presented in [36]). For problem solving using DE the number of population members, differential weighting factor (F), and crossover probability constant (CR) are considered equal to 10, 0.3, and 0.5, respectively. When using ABC, the number of colony size and limit are considered equal to 14 and 200, respectively. The parameters of RRA are also considered exactly equal to those used in simulations of Fig. 6. Each algorithm is independently run 100 times and each time it stops after 2000 FE's. Note that the control parameters of each algorithm are selected by trial and error such that it exhibits the best performance. The average value of objective function (14) and the corresponding standard deviation are plotted versus the number of FE's in Fig. 8(a) and (b), respectively (note that in order to make a fair comparison it is always better to plot the objective function value versus the number of FE's [37–39]). As it can be observed in this figure the performance of RRA is comparable with ABC and DE.

@&#CONCLUSIONS@&#
