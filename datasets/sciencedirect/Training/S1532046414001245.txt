@&#MAIN-TITLE@&#
Lessons learnt from the DDIExtraction-2013 Shared Task

@&#HIGHLIGHTS@&#
DDIExtraction aims to the extraction of drug–drug interactions from texts.Non-linear kernel-based methods overcome linear SVMs.Most results are statistically significant.Resolution of complex sentences could lead to better performance.

@&#KEYPHRASES@&#
Information extraction,Relation extraction,Drug interaction,

@&#ABSTRACT@&#
The DDIExtraction Shared Task 2013 is the second edition of the DDIExtraction Shared Task series, a community-wide effort to promote the implementation and comparative assessment of natural language processing (NLP) techniques in the field of the pharmacovigilance domain, in particular, to address the extraction of drug–drug interactions (DDI) from biomedical texts. This edition has been the first attempt to compare the performance of Information Extraction (IE) techniques specific for each of the basic steps of the DDI extraction pipeline. To attain this aim, two main tasks were proposed: the recognition and classification of pharmacological substances and the detection and classification of drug–drug interactions. DDIExtraction 2013 was held from January to June 2013 and attracted wide attention with a total of 14 teams (6 of the teams participated in the drug name recognition task, while 8 participated in the DDI extraction task) from 7 different countries. For the task of the recognition and classification of pharmacological names, the best system achieved an F1 of 71.5%, while, for the detection and classification of DDIs, the best result was an F1 of 65.1%. The results show advances in the state of the art and demonstrate that significant challenges remain to be resolved. This paper focuses on the second task (extraction of DDIs) and examines its main challenges, which have yet to be resolved.

@&#INTRODUCTION@&#
Pharmacovigilance is formally defined by the WHO as “the science and activities related to the detection, assessment, understanding and prevention of adverse effects or any other drug-related problems” [1]. One of the major aims of pharmacovigilance is the early detection of adverse drug reactions (ADRs), which are unintended and harmful reactions to drugs. Several studies point out that the number of ADRs has increased significantly in recent years [2] and are responsible for about 5% of all hospital admissions [3,4]. More seriously, ADRs cause more than 300,000 deaths per year in the USA and Europe [5,6]. As a result, ADRs are a direct cause of the increase in health care costs [2]. Thus, the pharmacovigilance process is considered vital by pharmaceutical companies and drug agencies due to the high and growing incidence of drug safety incidents as well as their high associated costs.Healthcare professionals are responsible for recognizing and reporting side effects by spontaneous post-marketing reporting systems. However several published drug safety issues have shown that the adverse effects of drugs may be detected too late, when millions of patients have already been exposed to them [7]. This fact poses a serious problem for patient safety giving rise to a growing interest in improving the early detection of ADRs. Drug–Drug Interactions (DDIs), which can be defined as alterations in the effects of a drug due to the recent use or simultaneously one or more other drugs, are an important subset of ADRs. Although there are different databases supporting healthcare professionals in the detection of DDIs (such as DrugBank [8]), the quality of these databases is very uneven and the consistency of their content is limited, so it is very difficult to assign a real clinical significance to each interaction [9,10]. On the other hand, these databases do not scale well to the large and growing number of pharmacovigilance literature in recent years [10]. In addition, a large amount of the most current and valuable information is unstructured, written in natural language and hidden in published articles, scientific journals, books and technical reports [11]. Thus, the large number of databases with information on DDIs and the deluge of published research have overwhelmed most healthcare professionals because it is not possible to remain up to date on everything published about DDIs.Therefore, there is an increasing interest in facilitating automated access to information relevant on DDIs described in biomedical texts. Information Extraction (IE) techniques applied to pharmacovigilance literature can be of great benefit in the pharmaceutical industry allowing the identification and extraction of relevant information and providing an interesting way of reducing the time spent by healthcare professionals and researchers on reviewing the literature.With the support of collaborative events such as BioCreative [12–15], BioNLP [16–18], i2b2 [19,20], ShARe/CLEF eHealth [21] and SemEval-2014 Task 7 Analysis of Clinical Texts1http://alt.qcri.org/semeval2014/task7/.1shared tasks, there has been significant progress in IE techniques in the biological domain. However IE technology applied to pharmacovigilance still remains quite unexplored compared to biology.The extraction of DDIs from biomedical texts has gained popularity and has seen significant advances recently with the organization of the DDIExtraction Shared Tasks in 2011 [22] and 2013 [23]. The main goal of these community challenges is to provide a common framework for the evaluation of information extraction techniques applied to the extraction of DDIs from biomedical texts. While the first event in 2011 only focused on the identification of all possible pairs of interacting drugs, the 2013 edition also included, in addition to DDI detection, the classification of each DDI. Furthermore, a supporting task, the recognition and classification of pharmacological substances, was proposed in 2013.In the latest edition of DDIExtraction, a total of 14 teams submitted runs for at least one of the proposed subtasks (6 of the teams participated in the drug name recognition task, while 8 participated in the DDI extraction task). In the drug name recognition subtask, the top scoring team reached an F-score of 71.5%. In the relation extraction task, the best system achieved an F1 of 65.1%. This paper focuses on the second task (extraction of DDIs). The aim of this paper is twofold: to provide a detailed description and discussion on the 8 participating systems in the second task, the extraction of DDIs, and to discuss the remaining challenges revealed by the error analysis on these systems.This paper proceeds as follows: Section 2 describes the corpus used in the shared task; in Section 3 we give a detailed discussion of the participating systems; Section 4 presents the results obtained by the participating systems; Section 5 describes the major sources of errors in these systems; Section 6 presents a study as to whether the results are significant statistically; in Section 7 we propose an ensemble system of combining the top three methods using majority and union voting strategies; and finally, we close with a discussion in Section 8 of possible future steps of the DDIExtraction Shared Task.The major contribution of DDIExtraction has been to provide a benchmark corpus, the DDI corpus. The DDI corpus is a valuable gold-standard for those research groups interested in the recognition of pharmacological substances or those specifically working in the field of DDI relation extraction. It consists of 792 texts selected from the DrugBank database (DDI-DrugBank dataset) and other 233 Medline abstracts (DDI-MedLine dataset) on the subject of DDIs. The corpus was manually annotated with a total of 18,502 pharmacological substances and 5028 DDIs, including both pharmacokinetic (PK) as well as pharmacodynamic (PD) interactions. Four entity types were proposed to annotate pharmacological substances: drug, brand, group and drug_n. The drug type is used to annotate those human medicines known by a generic name, whereas those drugs described by a trade or brand name are annotated as brand entities. The use of either generic or brand names depends on the drug information source. Thus, while generic names are used in medical and pharmacological textbooks as well as scientific medical journals, brand names are used in drug product labels. The group type was used to annotate groups of drugs. This type was included because the descriptions of DDIs involving groups of drugs are very common in texts. The last entity type, drug_n, refers to those active substances not approved for human use, such as toxins or pesticides. This type was included because interactions between drugs and substances not approved for human use are frequently reported in Medline documents.DDIs were annotated at the sentence level and, thus, interactions spanning over several sentences were not annotated. Four different types of DDI relationships are proposed: mechanism (this type is used to annotate DDIs that are described by their pharmacokinetic mechanism), effect (this type is used to annotate DDIs describing an effect or a pharmacodynamic mechanism), advice (this type is used when a recommendation or advice regarding a drug interaction is given) and int (this type is used when a DDI appears in the text without providing any additional information). Tables 1 and 2show the numbers of the annotated entities and relationships in each corpus, respectively.Fig. 1shows some examples of annotated texts in the DDI corpus. This figure has been taken from the WBI corpora repository.2http://corpora.informatik.hu-berlin.de/.2The DDI corpus was adapted to the Stav format by the WBI team in order to be visualized using Stav on-line visualization tool [24]. The first example (A), taken from the MedLineDDI dataset, describes a DDI of mechanism type between a drug (named using a synonym different from its most common generic name, fomepizole) that inhibits the metabolism of a substance not-approved to be used in humans (1,3-difluoro-2-propranol). The second example (B) is also a sentence taken from MedLine and describes the consequence of a DDI (effect type) between estradiol (a generic drug) and endotoxin (a drug-n) in an experiment performed in animals. The last example (C) is a paragraph from the DDI-DrugBank dataset. Its first sentence describes the consequence of the interaction (effect type) of a drug, denominated by its brand name (Inapsine), when is co-administered with five different groups of drugs. The third sentence in C shows a recommendation to avoid these DDIs (advice type).Inter-annotator agreement (IAA) was measured in order to assess the consistency and quality of the corpus as well as the complexity of the annotation task. Tables 3 and 4present the results for the agreement per type of entity and per type of relationship, respectively. Results were calculated in terms of the standard Kappa statistic [25]. The overall IAA results suggest that the DDI corpus has enough quality to be used for training and testing NLP techniques applied to the field of pharmacovigilance. A detailed description of the DDI corpus can be found in [26].This section reviews the 8 systems participating in the task of extracting DDIs and presents their results. For the evaluation of this task, the participants were given the test data with gold annotation only for pharmacological substances. The evaluation was then carried out by comparing the annotation predicted by each participant to the gold annotation. To simplify the task, the detection of DDIs was conducted at the sentence-level. The evaluation results are reported using the standard recall/precision/f-measure metrics, under different criteria: partial (only detection of DDIs) and exact (detection and classification of DDIs).The system consisted of two separate steps: first the DDIs were detected and second, the extracted DDIs were classified according to the proposed types (mechanism, effect, advice and int) in the guidelines task. In the DDI detection phase, filtering techniques based on the scope of negation cues and the semantic roles of the entities involved were proposed to rule out possible negative instances from the test dataset. In particular, a binary SVM classifier was trained using contextual and shallow linguistic features to find less informative sentences. A sentence is considered less informative when all its entities as well as its relation clues fall under the scope of a negation cue (no, n’t, not). Less informative sentences were not considered in the relation extraction phase. Also, less informative negative instances were ruled out according to the following exclusion criteria: (1) if two mentions in a sentence refer to the same entity, this pair is not considered as a candidate DDI, (2) for any expression of the form “Drug1 (Drug2)”, the pair was ruled out because both entities refer to the same entity (Drug2 is usually the abbreviation of Drug1), and (3) a candidate pair was ruled out when its two mentions had anti-positive governors with respect to the type of the relation. Anti-positive governors are words that tend to prevent mentions, which are directly dependent on those words, from participating in a certain relation of interest with any other mention in the same sentence [27]. We refer the reader to [28] for detailed description of anti-positive governors.Once these negative instances were discarded from the test dataset, a hybrid kernel (combining a feature-based kernel, the shallow linguistic kernel (SL) [29] and the Path-enclosed Tree (PET) kernel [30]) was used to train a RE classifier. For the classification of the extracted DDIs, four separate models were trained for each DDI type (using ONE-vs-ALL). If none of the separate models is able to assign a class label to a predicted DDI, a default class label was chosen (for example, effect). The trained models were applied only on the extracted DDIs (by the DDI detection module) from the test dataset. Experiments on the training dataset showed that the filtering techniques improve both precision and recall with respect to applying only the hybrid kernel. This team achieved the best three submitted runs. The only difference between the three runs was the default class label which was “int”, “effect” and “mechanism” for run 1, 2 and 3 respectively. The top run showed an F1 of 0.80 for DDI detection and 0.65 for DDI detection and classification.The second best system was developed by the WBI team. The system relied on two step processes which first detected DDIs using ensembles of five different classifiers, and then the extracted DDIs were classified with one of the four proposed types. Several experiments were conducted combining the following eight machine learning methods: all-paths graph (APG) [31], the Shallow Linguistic Kernel (SL), SubTree (ST) kernel [32,33], Spectrum tree (Spt) [34], Turku Event Extraction System (TEES) [35], the case-based reasoning Moara system [36] and a self-developed feature based classifier (SLW), which is an extension of SL. Experiments were performed using 10-fold cross validation (CV) on the training set, and showed that the best results were achieved by the following majority voting ensembles: (1) Moara+SL+TEES, (2) APG+Moara+SL+SLw+TEES, and (3) SL+SLW+TEES. These ensembles were submitted as runs. This team was ranked second behind the FBK-irst team. Its best run was the third one, which yielded an F1 of 0.76 for DDI detection and 0.609 for DDI detection and classification.The third best team was the Uturku team. The TEES system was used to participate in both tasks: drug named entity recognition and extraction of DDIs. TEES is a machine learning system based on SVM, which was originally developed to extract events (and relations) in the BioNLP shared task. The event extraction is tackled as a graph generation task where nodes are keywords and edges are the words that connect nodes. The node detection task is similar to named entity recognition, while the edge detection task can be thought of as a relation extraction task. Deep syntactic features and information from external domain resources such as DrugBank or MetaMap [37] were used to model the Turku system. In run 1, the Uturku system was trained using only a feature set from syntactic parses. In run 2, DrugBank features were added to the syntactic features. Run 3 further extended run 2 with MetaMap information. The results of each run seem to be very close to each other. The best performance was provided by run 2 (an F1 of 0.696 for DDI detection and 0.594 for DDI detection and classification). While drug name recognition benefits from the use of domain knowledge resources, these external resources do not achieve a significant improvement in the relation extraction task. This may indicate that the extraction of DDIs seems to depend more on the syntactic interpretation of parse trees. TEES (version 2.1) is available for research purposes from http://bionlp.utu.fi/eventextractionsoftware.html. The authors also provided their DDI predictions for all DDIExtraction-2013 participants.The system was based on SVM using lexical, morphosyntactic and parse tree features. Information Gain ranker was used to eliminate the less informative features. The team submitted two different runs: (1) to train a SVM classifier with 5 categories (effect, mechanism, int, advice, null) and (2) to train a binary SVM classifer (DDI, non-DDI), and then, the extracted DDI were used to train a second SVM classifier with four categories (effect, mechanism, int, advice). The second run achieved better results (an F1 of 0.656 for DDI detection and 0.548 for DDI detection and classification) than the first one.The system was based on the SL Kernel. First, the SL was trained to distinguish positive instances from negative instances, and then, a SL model was trained for each DDI type. The SL kernel uses the following features: tokens, lemmas, PoS tags and entity types. In addition to the features listed above, the Anatomical Therapeutic Chemical (ATC) code of each drug name was obtained from the ATC system,3www.whocc.no/atc/,3the drug classification system adopted by the World Health Organization (WHO). The team submitted two runs. In the first run, the team used the default setting of SL, while in the second one, the lemma feature was replaced by the ATC code of the drug. The first run achieved an F1 of 0.676 for DDI detection and 0.537 for DDI detection and classification. However, the use of ATC codes seems to give rise to a significant detriment to the performance with an F1 of 0.537 for DDI detection and only 0.294 for DDI detection and classification.The system relied on two step processes: the first one detected DDIs using a binary weighted SVM classifier to discriminate positive instances (that is, DDIs) from negative instances, and then, a multi-class weighted SVM classifier was applied on the extracted DDIs (by the binary SVM) in order to classify each DDI. The team’s hypothesis is that separating the detection and classification tasks into two different phases can help to handle the highly unbalanced class distribution. Texts were transformed into lower-case, drug names blinded and number were normalized. A feature set of lexical (such as bag of words and bigrams) and semantic features (synsets from WordNet [38]) was used to train a binary weighted classifier to discriminate positive instances from negative instances. Tokens were stemmed and lemmatized. The authors also used different stopwords lists of different size. The number of false positives was relatively high since the positive class was favored in the weighted SVM. The authors also defined a set of post-processing rules which were applied after the binary SVM classifier. For example, a rule consisted of discarding those pairs of interacting drugs referring to the same entity. Another example of a rule was when an interacting drug is a drug class of the other one; in this case, this pair should be ruled out since, in general, these pairs represent a hyponym/hyperonym relationship and not an interaction [39]. Other rules were aimed at detecting (without using any syntactic information) those pairs of drugs appearing in the same coordinative structure, since in general they are not interacting drugs.Then, a multi-class SVM was trained on the set of extracted DDI classified by the previous binary classifier. In this case, the team proposed a rule that would assign the same type to all pairs obtained from drug mentions in a coordinative structure and other drug mention.The team submitted three runs. The only difference between them was the size of the stopwords list used in each run. Experiments showed that the list of bigest size (263 stopwords) and the use of stems instead of lemmas achieve better results (F1=0.599 for DDI detection and F1=0.47 for DDI detection and classification) than the other settings.This system was based on the combination of three machine learning techniques: LibLINEAR [40] (linear SVM), Naïve Bayes and Voting Perceptron. While the first run was generated using only LibLINEAR, the second and third ones were based on majority and union ensemble learning strategies, respectively. All ML techniques used a rich feature vector consisting of lexical, syntactic and semantic features. The classification of extracted DDIs was performed by a post-processing step. This post-processing step uses a list of trigger words related for each type DDI which were manually created based on the observation of the MedLine dataset. The authors also applied an undersampling technique to balance the corpora and study its influence on the performance (only on the training dataset).According to the official scores, their best result was obtained by run 3 (union voting strategy) with an F1 of 0.704 for DDI detection and 0.458 for DDI detection and classification. As regards the results for DDI classification, the system achieved the top score on MedLine (micro F1=0.42), however the system ranked at 5th position for DrugBank. This may be due to the trigger words collected were based on the observation of MedLine abstracts. Therefore, it would be advisable to define trigger words for each DDI type depending on the corpus.This team used LIBSVM [41] trained with morphosyntactic, lexical and semantic features. The team applied the one-vs-all multi-class classification technique to handle the different DDI types. Lexical and semantic features were used to train the classifiers. In run 2, the team also added features from TEES analysis provided by the UTurku team, and in run 3, features used in run 2 along with a list of interaction words were used as feature set. Their best run was the third one, achieving an F1 of 0.491 for DDI detection and 0.336 for DDI detection and classification.

@&#CONCLUSIONS@&#
