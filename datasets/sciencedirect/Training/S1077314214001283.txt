@&#MAIN-TITLE@&#
Scale recovery in multicamera cluster SLAM with non-overlapping fields of view

@&#HIGHLIGHTS@&#
A SLAM framework for multicamera clusters is proposed.Use of three or more cameras avoids the need for field of view overlap.System fully initialized using the first set of image measurements.Motions leading to scale ambiguity are identified for three-camera cluster.Experiments demonstrate increased accuracy of solution against two-camera cluster.

@&#KEYPHRASES@&#
Localization,Mapping,Multicamera cluster,Non-overlapping FOV,SLAM,Degeneracy analysis,Critical motions,

@&#ABSTRACT@&#
A relative pose and target model estimation framework using calibrated multicamera clusters is presented. It is able to accurately track up-to-date relative motion, including scale, between the camera cluster and the (free-moving) completely unknown target object or environment using only image measurements from a set of perspective cameras. The cameras within the cluster may be arranged in any configuration, even such that there is no spatial overlap in their fields-of-view. An analysis of the set of degenerate motions for a cluster composed of three cameras is performed. It is shown that including the third camera eliminates many of the previously known ambiguities for two-camera clusters. The estimator performance and the degeneracy analysis conclusions are confirmed in experiment with ground truth data collected from an optical motion capture system for the proposed three-camera cluster against other camera configurations suggested in the literature.

@&#INTRODUCTION@&#
Many researchers have studied the use of visual feedback for environment mapping and camera localization, principally within two areas; mobile/industrial robotics, and computer vision. The robotics community refers to the problem as visual Simultaneous Localization and Mapping (SLAM) and frames it in terms of online tracking of a position and orientation state estimate (pose) with respect to an unknown environment through an image sequence [1]. On the other hand, the Structure From Motion (SFM) problem in computer vision focuses primarily on offline reconstruction of the 3D scene geometry using 2D image measurements over a (sparse) set of discrete camera frames [2].Recently, the trend has been to move away from using monocular or conventional-stereo cameras to perform localization and structure estimation, to using more sophisticated imaging systems, including camera clusters [3]. A camera cluster is composed of any number of simple perspective cameras mounted rigidly with respect to each other. An example configuration is shown in Fig. 1.The use of a multicamera cluster for localization and target modeling has several advantages over other camera systems. The individual cameras can be arranged into any configuration, including those with no spatial overlap in the camera fields-of-view (FOV) to make the most effective use of available camera pixels. Even without FOV overlap, non-zero baselines between the individual camera centers allows for full global motion scale recovery. Additionally, the cameras can be configured such that small translationâ€“rotation motion ambiguities [4] in one camera are compensated for by other cameras facing in orthogonal directions. With the large collective FOV and increased sensitivity, localization accuracy is dramatically improved when compared with monocular and stereo configurations. This is possible even when there is no inter-camera feature correspondence throughout the entire motion sequence.The intuition behind how a calibrated cluster is able to track its relative motion without finding correspondence between point features across cameras is as follows. Each individual camera is able to estimate its own local motion increment up-to-scale in its own frame using its image sequence. Using the known cluster calibration, these local motions are combined to find the unique cluster translation and rotation which includes the proper scale value. Therefore, the world scale is embedded in the camera cluster extrinsic calibration.This work presents an estimation system capable of tracking the relative position and orientation of a calibrated camera cluster with respect to an unknown target object or environment. Additionally, it is demonstrated through analysis and experimentation that a cluster composed of three or more non-collinear cameras is able to overcome the estimation degeneracies of two-camera systems identified in the literature [5,6]. The nonlinear estimation problem can be solved using a single recursive filter that is initialized using only the first set of image measurements from the cluster cameras. Finally, the tracked target object or environment is free to move independently of the cluster motion since only relative measurements are used for the estimation, thereby solving a superset of the SLAM problem.An ideal application of this algorithm would be one in which the camera cluster is surrounded by a moving target which is visible in the non-overlapping FOV of more than one of the component cameras at the same point in time. One example would be an aerial robot maneuvering in close proximity to a moving ship during a docking or inspection task. In this case, both the camera cluster and the target are in free motion, and auxiliary sensors such as Global Positioning Satellite (GPS) receivers or Inertial Measurement Units (IMU) mounted on the robot cannot be used to estimate the relative motion since they provide a measure of only the cluster motion in an Earth-fixed coordinate frame. Applicability of these multicamera clusters will increase with the continued miniaturization of robotic systems and sensors as it will be more likely that the vehicle will need to operate in or around a moving target.The remainder of the paper is arranged as follows: Section 2 contains a detailed review of existing techniques using camera clusters for motion and structure estimation; Section 3 presents the proposed multicamera cluster pose estimation framework, including parameterizations and the initialization process; a novel degeneracy analysis for a three-camera cluster is presented in Section 4 to identify motion sets leading to solution scale ambiguity; experimental results demonstrating and evaluating the performance of the proposed method with a variety of cluster configurations are provided in Section 5; finally, conclusions are drawn in Section 6.

@&#CONCLUSIONS@&#
A framework for calibrated multicamera clusters is presented which accurately estimates both relative motion and model structure of the cluster and an unknown rigid target object or environment. An estimator based on this parameterization is able to maintain an online estimate of the relative pose when both the camera cluster and the target are in free motion. The framework is also easily extendable when other measurements, such as GPS, IMUs, or robot motion dynamics are available and the target is stationary in the inertial frame.Any configuration of perspective cameras may be used, including arrangements with spatially non-overlapping FOV, and the estimator is able to resolve the global motion and model scale as soon as the information is available in the image measurements, assuming the relative motion is not strictly critical or degenerate, and the ratio of camera baseline distance to point feature depth is sufficiently large. A novel analysis of the degenerate configurations was performed to identify the set of critical motions present when using a camera cluster consisting of three cameras arranged with non-overlapping FOV. The set of critical motions, compared with that of the two-camera cluster is significantly reduced with the addition of the third camera, enabling scale-recovery in more generic relative motion profiles.Finally, experimental results demonstrate the accuracy of the estimates using a variety of camera cluster configurations, against a set of high-precision motion tracking system measurements. The degeneracy analysis conclusions are confirmed for the three-camera clusters with the large collective FOV, showing reliable stability and accuracy in the estimates, including the correct scale in general motion profiles. It is shown that because the critical motion set is reduced, it is not necessary to maintain overlap in the FOV, and the non-overlapping three-camera cluster provides more accurate motion estimates compared to the divergent stereo configuration, and is a better choice for high-precision robotic applications.