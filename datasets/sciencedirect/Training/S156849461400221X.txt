@&#MAIN-TITLE@&#
A multi-swarm cooperative multistage perturbation guiding particle swarm optimizer

@&#HIGHLIGHTS@&#
Propose a novel multi-swarm cooperative multistage perturbation guiding particle swarm optimizer.Multi-swarm information sharing idea aims to improve the evolving efficiency via information communicating and sharing among different sub-swarms.Multistage perturbation guiding strategy aims to slow down the learning speed and intensity.Comprehensive studies on algorithm are presented.

@&#KEYPHRASES@&#
Particle swarm optimizer,Multi-swarm PSO,Information sharing,Multistage perturbation,Swarm intelligence,

@&#ABSTRACT@&#
Inspired by the ideas of multi-swarm information sharing and elitist perturbation guiding a novel multi-swarm cooperative multistage perturbation guiding particle swarm optimizer (MCpPSO) is proposed in this paper. The multi-swarm information sharing idea is to harmoniously improve the evolving efficiency via information communicating and sharing among different sub-swarms with different evolution mechanisms. It is possible to drive a stagnated sub-swarm to revitalize once again with the beneficial information obtained from other sub-swarms. Multistage elitist perturbation guiding strategy aims to slow down the learning speed and intensity in a certain extent from the global best individual while keeping the elitist learning mechanism. It effectively enlarges the exploration domain and diversifies the flying tracks of particles. Extensive experiments indicate that the proposed strategies are necessary and cooperative, both of which construct a promising algorithm MCpPSO when comparing with other particle swarm optimizers and state-of-the-art algorithms. The ideas of central position perturbation along the global best particle, different computing approaches for central position and important parameters influence analysis are presented and analyzed.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO) [12,31] is a population-based stochastic search technique for solving optimization problems. It has been proven to be efficient and effective for various applications in scientific and engineering domains. It is inspired by the regularity of birds clustering activities, using the organizational social behaviors to replace the natural selection mechanism of evolutionary algorithm [5]. Each particle has the abilities of “individual cognition” and “social cognition”. PSO manages to search the optimal solutions by the cooperations of particles in the swarm. Since PSO is simple, easy to realize and has few parameters, it has gained increasing popularity among researchers and practitioners as a robust and efficient technique for solving complex and difficult optimization problems [1,10,18,20,22,32]. Furthermore, many other evolutionary optimization algorithms emerge and attract extensive attentions, such as differential evolution [4,29,36], real-coded genetic/memetic algorithms [6,21,23], artificial bee colony [9,14].The flying velocity of each particle is modified iteratively by its personal best position and the best position found by the entire swarm. As a result, each particle searches around a region defined by its personal best position and the position of the population best [13]. That is, PSO is somewhat arbitrary to make all the particles get acquainted with the same “social cognition” from the best position (gbest). In this condition, no matter how far the particle is from the gbest, every particle learns information from the same source, i.e., gbest. As a result, all of them are quickly attracted to the optimal position, and the swarm diversity is decreasing very fast. Therefore, avoiding being trapped by local optima while accelerating convergence speed has become a most important and appealing goal in PSO research [28].As PSO is simple in concept and effective to explore global solutions for various optimization problems, it has become more and more important and has been one of the most popular optimization techniques. Mendes et al. [19] think that each individual of PSO is not simply influenced by the best performer among his neighbors and they decided to make the individuals “fully informed”. Li [15] proposed a simple yet effective niching particle swarm optimization algorithm, which uses a ring neighborhood topology and does not require any niching parameters. It evolves by using individual particles’ local memories to form a stable network retaining the best positions found so far, while these particles explore the search space more broadly. Liang et al. [16] proposed a novel learning strategy whereby all other particles’ historical best information is used to update a particle's velocity. This strategy enables the diversity of the swarm to be preserved to discourage premature convergence and achieves very competitive performance for multimodal functions. Perturbed particle swarm algorithm [37] is based on a concept of particles update strategy with possibility. Perturbing the global optimal particle in a certain range, the population diversity is somewhat increased while remaining the elitist leaning mechanism of PSO. Nickabadi et al. [25] proposed a new adaptive inertia weight by using the success rate of the swarm as its feedback parameter to ascertain the particles’ situation in the search space. Zhan et al. [35] proposed an orthogonal learning (OL) strategy for PSO to discover more useful information that lies in the above two experiences via orthogonal experimental design. The appropriate adaptive or self-adaptive learning mechanism [33,30,8,11] are the most important strategies to keep the well balance between global exploration and local exploitation. Multi-swarm cooperative particle swarm optimization [26] is a multiple swarm-based improved algorithm with center communication. This algorithm divides the whole search space into local subspaces, and different sub-swarms communicate and share exploitation information each other, reducing the possibility of getting into the local optimum. Neri et al. [24] proposed a novel compact particle swarm optimization (cPSO). It does not use a swarm of particles and does not store neither the positions nor the velocities. On the contrary, cPSO employs a probabilistic representation of the swarm's behavior. Based on the observations that a particle surfing on sine waves in nature and a particle seeking an optimal location attempted to catch another wave randomly, manipulating its frequency and amplitude, Pehlivanoglu [27] proposed a periodic mutation operation and a multifrequency vibrational PSO. Chen et al. [3] transplanted the aging mechanism to particle swarm optimization and proposed a PSO with an aging leader and challengers. It is characterized by assigning the leader of the swarm with a growing age and a lifespan, and allowing the other individuals to challenge the leadership when the leader becomes aged. Zhao et al. [38] proposed a new PSO searching mechanism based on principal component analysis (PCA) and line search (LS), in which PCA is mainly used to efficiently mine population information for the promising principal component directions and then LS strategy is utilized on them. In order to overcome the suffers of the premature convergence, Campos et al. [2] proposed a variant of PSO, bare bones particle swarm optimization with scale matrix adaptation (SMA-BBPSO). In the SMA-BBPSO, the position of a particle is selected from a multivariate t-distribution with a rule for adaptation of its scale matrix.Inspired by the ideas of multi-swarm information sharing and elitist perturbation guiding, this paper presents a novel multi-swarm cooperative multistage perturbation guiding particle swarm optimizer (MCpPSO) with multi-swarm information sharing mechanism and multistage global perturbation guiding strategy. In this algorithm, the flying velocity is updated with a different manner from the traditional PSO. Each particle updates itself by its own experience, the optimal position of its sub-swarm, and the information coming from other sub-swarms. During the evolution, the diversity is also increased a little by a perturbation operation around the global optimal solution. Two main strategies increase the possibilities of jumping out of local optima, and make the particles approach to the global optimal solution as near as possible. So the comprehensive performance of the algorithm is possible to be improved greatly. Furthermore, the synchronous perturbation operation of central position along the global best particle, different computing models for central position and important parameters influence analysis are also presented.The rest of this paper is organized as follows. The related algorithms and foundations are introduced in Section 2. The proposed algorithm MCpPSO is detailed described in Section 3. The comprehensive experimental comparisons and algorithmic analysis on MCpPSO are presented in Section 4. The questions on the central position perturbation along the global best particle, different computing approaches for central position and important parameters influence analysis are analyzed in Section 5. The overall conclusion and the possible future research are given in Section 6.PSO [12,31] executes its search in the definition domain through the accumulating velocity and position information. Each particle enhances itself by keeping its track learning from two “optimal solutions” in PSO population: one is the optimal solution found by itself and the other is the optimal solution found by the particle swarm.A standard particle swarm optimizer maintains a swarm of particles and each individual is composed of three D-dimensional vectors, where D is the dimensionality of the search space. These are the current position xi, the previous best position pi, and the velocityvi. The current position xi=(xi,1, …, xi,D) can be considered as a set of coordinates describing a point in the space. The best solution found so far is stored in pi=(pi,1, …, pi,D). New positions are obtained by addingvi=(vi,1,…,vi,D)coordinates to xi, and the algorithm aims at a new promising position by adjustingvi, which can be seen as a step size as the usual optimization algorithm.In essence, the trajectory of each particle is updated according to its own flying experience as well as to that of the best particle in the swarm. The velocity and position updating equations are given as Eqs. (1) and (2).(1)vi,dk+1=ωvi,dk+c1r1k(pi,dk−xi,dk)+c2r2k(pg,dk−xi,dk)(2)xi,dk+1=xi,dk+vi,dk+1wherevi,dkis the dth dimension velocity of particle i in cycle k;xi,dkis the dth dimension position of particle i in cycle k;pi,dkis the dth dimension of personal best (pbest) of particle i in cycle k;pg,dkis the dth dimension of the gbest in cycle k; ω is the inertia weight; c1 is the cognitive weight and c2 is the social weight; and r1 and r2 are two random values uniformly distributed in the range of [0, 1]. Experimental results suggest that it is preferable to initialize the inertia weight to a large value, giving the priority to global exploration of the search space, and gradually decreasing so as to obtain refined solutions.PSO is easy to be trapped by evolution stagnation if population size is too small. However, the overlarge population size will affect the converging speed of algorithm. So it is difficult to decide the population size for different questions. Based on these observations, the large swarm is divided into several sub-swarms with independent evolution in this paper. On one hand, particles independently search for even better solutions as traditional PSOs. On the other hand, they also acquire information from the other sub-swarms [26], which are independently evolving and have distinctive evolution information from each other. The evolution information is then sent to other sub-swarms and to guide the search of all the particles. The information sharing mechanism of this paper is implemented with the central position, which is the average position of the current-to-found optimal solutions from the sub-swarms:(3)pc,d=1Q∑q=1Qpg,dqwhere Q represents the number of sub-swarms. The central position doesn’t evolve independently since there is a lack of flying velocity. Therefore, it is looked on as a virtual particle.In PSO, particle swarm converges rapidly within the intermediate vicinity of the gbest. However, such a high convergence speed often results in: (1) the lost of diversity and (2) the premature convergence if the gbest particle corresponds to a local optima. This motivates the development of pPSA-a perturbed particle swarm algorithm [37] based on the perturbed gbest updating strategy, which is based on the concept of possibility measure to model the lack of information about the true optimality of gbest. In contrast to conventional approaches, the gbest in pPSA is denoted as “possibly at gbest (p-gbest)=(pg,1×pg,2×⋯×pg,D)”, instead of a crisp location. Consequently, the calculation of particle velocity can be rewritten as(4)pg,dk′=N(pg,dk,σ)(5)σ=F(k)(6)vi,dk+1=ω×vi,dk+c1×r1k×(pi,dk−xi,dk)+c2×r2k×(pg,dk′−xi,dk)wherepg,dk′is the dth dimension of p-gbest in cycle k after perturbing operation. It can be observed from (4) that p-gbest is characterized by a normal distributionN(pg,dk,σ), where σ represents the degree of uncertainty about the optimality of the gbest [7]. In order to account for the information received over time that reduces uncertainty about the gbest position, σ is modeled as a non-increasing function with respect to the number of iteration as Eq. (7). For simplicity, F(k) is defined as(7)F(k)=σmax,k<α×Gσmin,otherwisewhere σmaxand σminare the maximal and minimal values of parameter σ. G is the maximal iteration number and α is a manually switching parameter controlling σ to switch from σmaxto σmin.The perturbed global best updating strategy Eqs. (4)–(6) should be distinguished from conventional mutation operator (1), which applies a random perturbation to the global best particle. The function of p-gbest is to encourage the particles to explore a region beyond that defined by the search trajectory. By considering the uncertainty associated with each gbest as a function of time, p-gbest provides a simple and efficient exploration at the early stage when σ is large and encourages local fine-tuning at the latter stage when σ is small. Subsequently, this approach helps to reduce the likelihood of premature convergence and guides the search toward the promising search area.Well balance of exploration and exploitation has critical pertinence with the performance of the population-based stochastic optimization algorithm [17]. Based on the ideas of multi-swarm information sharing mechanism and multistage global perturbation guiding search strategy, a novel multi-swarm cooperative multistage perturbation guiding particle swarm optimizer (MCpPSO) is presented. The multi-swarm information sharing idea is to improve the evolving efficiency by information communicating and sharing among sub-swarms which have different evolution mechanisms. It is possible to drive some sub-swarms to revitalize once again with the new information learned from other sub-swarms if they had been stagnated. Multistage perturbation guiding idea is to slow down the learning speed and intensity to some extent from the global best solution while remaining the elitist learning mechanism. It enlarges the exploration domain around the elitist neighborhood and diversifies the flying tracks of particles. Two main strategies increase the possibilities of jumping out of local optima, and make the particle approach to the global optimal solution as near as possible.Multi-swarm sharing operation divides the whole swarm into several sub-swarms, and there exist communications among each other. Since the sub-swarms are independent in a great degree and search from different initial solutions, this method can reduce the possibilities of falling into the same local optima as the single swarm-based PSO and has a larger chance find the true optimal solution. That is, every particle updates itself by its own experience, the optimal flying experience of its sub-swarm, and the guiding information learned from the other sub-swarms. The velocity and position updating equations of multi-swarm cooperative PSO for central information sharing are as follows:(8)vi,dq(k+1)=ωvi,dq(k)+c1r1(pi,dq(k)−xi,dq(k))+c2r2(pg,dq(k)−xi,dq(k))+c3r3(pc,d(k)−xi,dq(k))(9)xi,dq(k+1)=xi,dq(k)+vi,dq(k+1)wherevi,dq(k)is the dth dimension velocity of particle i in cycle k of the qth sub-swarm;xi,dq(k)is the dth dimension velocity of particle i in cycle k of the qth sub-swarm;pi,dq(k)is the dth dimension of personal best (pbest) of particle i in cycle k of the qth sub-swarm;pg,dq(k)is the dth dimension of the gbest in cycle k of the qth sub-swarm. The central position, pc(k)=(pc,1(k), …, pc,d(k), …, pc,D(k)), is the average position of the current-to-found optimal solutions from several sub-swarms in cycle k. Its component pc,d(k)(d=1, …, D) is updated as Eq. (3). ω is the inertia weight; c1 is the cognition weight, c2 is the social weight and c3 is the learning factor from other sub-swarms; and r1, r2 and r3 are three random numbers uniformly distributed in the range of [0, 1].The first part of formula (8) is called momentum part, representing a single particle's confidence on its current motion state. It provides a necessary momentum and makes an inertial move according to its own experience. The second part is called the cognition part, which represents the particle's thinking about its behavior and encourage particle to follow the best position found by itself. The third part is called social part, representing the elitist learning process of particle swarm optimization, and it guides the particle to learn from the global best particle. The fourth part is called swarm communication part, which represents the central information sharing mechanism to attract particles to the central position. The position of the central particle is decided by the average position of the several sub-swarms’ optimal positions. The mutual promotion and restriction balance of these four parts cooperatively decides the performance of the algorithm. Of course, Eq. (8) degenerates to Eq. (1) if the learning factor c3 is zero.At the same time, the traditional learning strategy of PSO can cause the “oscillation” phenomenon and the “two steps forward, one step back” phenomenon as reference [35] analyzed. It is likely to be caused by linear summation of the personal influence and the neighborhood influence. Therefore, the fourth part of Eq. (8) is necessary to drag the particle population out and modify the direction when this phenomenon happens.The traditional perturbed PSO is based on Eqs. (5) and (7). The inherent function of p-gbest is to provide a simple yet efficient exploration at the early stage when σ is large and encourages local fine-tuning at the latter stage when σ is small. This strategy can effectively diversify the current swarm when the elitist learning process is executing. However, it is not consistent to the convergence requirement for the exact location of the global best solution at the final stage of algorithm, when it is still perturbing although the perturbation radius is very small. For example, the final results of benchmarks for pPSA in [37] are approximately in the 10−6 order of magnitude, which is clearly affected by the perturbation radius σmin. Therefore, a three-stage perturbation guiding strategy is proposed for an even reasonable perturbation and convergence balance around the global best particle.Three-stage perturbation guiding idea divides the execution process of algorithm into three stages. The early stage is mainly for diversification exploration when perturbation radius σ is large. The middle stage is mainly focus on the search around the promising areas found at the first stage when perturbation radius σ is reduced. The final stage is mainly for the exact location of the final solution without perturbation. The three-stage perturbation guiding idea imposes different influences on population search at the corresponding stages of algorithm, which is coincident with the inherent search requirement of iteration algorithm. However, it is not to say that it will be better and better with more and more stages of elitist perturbation process are divided into.The strategies proposed in this paper are not heavily biased toward either aspects between exploration and exploitation. The main idea of multi-swarm information sharing mechanism is to add population diversity to algorithm through information communicating among sub-swarms, as well as it accelerates the search process by the elitist learning mechanism, especially from the other best sub-swarm. Three-stage perturbation guiding search strategy favors the elitist learning process as Eq. (6) shows. At the same time this operation diversifies the searching trajectories of all the particles, i.e., it enlarges the exploration range. That is, our proposed strategies consider both population diversity and selection pressure simultaneously. The operations of MCpPSO hybridized with two strategies are given as Eqs. (10)–(12) and Eq. (9), wherepg,dq′(k)is the “possible global optimal position” (global optimal position after perturbation).(10)pg,dq′(k)=N(pg,dq(k),σ)(11)vi,dq(k+1)=ωvi,dq(k)+c1r1(pi,dq(k)−xi,dq(k))+c2r2(pg,dq′(k)−xi,dq(k))+c3r3(pc,d(k)−xi,dq(k))(12)σ=F(k)=σmax,k≤α1×Gσmin,α1×G<k≤α2×G0,otherwiseThe new particle positions are possible to be out of the search region after the velocity and position updating. A simple and popular repair operator is adopted for the case of out of the search region, which works as follows: if the dth elementxi,dqof the position/solution vectorxiq=(xi,1q,…,xi,dq,…,xi,Dq)is out of the search region [LBd, UBd], thenxi,dqis reset as follows:(13)xi,dq=min{UBd,2LBd−xi,dq},ifxi,dq<LBdmax{LBd,2UBd−xi,dq},ifxi,dq>UBdThe flow chart and main operations for MCpPSO are shown as Fig. 1.As Fig. 1 shows, there are two additional steps of “Disturb the optimal position” and “Update the central position” (textboxes with gray background in Fig. 1) when comparing the computing costs between MCpPSO and traditional PSO in one iteration. In addition to the above-mentioned, the “Velocity updating step” has also a little difference, i.e., the fourth part of Eq. (8).Therefore the newly added fundamental operations are analyzed as follows in one iteration, where m is the swarm size, D is the problem dimension, Q is the number of sub-swarms, G is the maximal iteration number.•Disturb the optimal position: Eqs. (4) and (5) add mD fundamental operations individually, so 2mD operations are introduced here.Update the central position: Q+1 fundamental operations are introduced here.The fourth part of Eq. (8): there are 2mD addition operations and 2mD multiplication operations, so 4mD operations are introduced here.The experiments are designed to validate the necessity and excellent performance of the proposed strategies outlined in the previous sections and also to provide the empirical support for the above analysis. Fifteen benchmarks [34] are adopted, and the results are compared with standard PSO, PSO with central information sharing (MCPSO) and perturbed PSO (pPSA), fast evolutionary programming (FEP) [34], fully information particle swarm (FIPS) [19], comprehensive learning particle swarm optimizer (CLPSO) [16] and orthogonal learning particle swarm optimization with best performance (OLPSO-L) [35]. The main aim here is not to show MCpPSO is better or worse than the previous algorithms, but to find out why and when MCpPSO is better (or worse) than its competitors.Ten high-dimensional benchmarks and five low-dimensional functions (Tables A1 and A2 in Appendix) are used in the experimental studies chosen from [34], where D is the dimension number, Domain is the search definition domain and fminis the known optima of the functions.Functions f1–f6 are unimodal functions which are to verify the convergence abilities of various algorithms. The difficulty of f3 lies in the search along the coordinate axes only providing a poor convergent rate since its gradient is not oriented along the axes. It presents similar difficulties as f4, but its valley is narrower. The optimum of f4 is located in a steep parabolic valley with a flat bottom and the nonlinear variables interact each other, i.e., it is nonseparable. These features make the search direction have to continually change to reach the optimum. It is specially to say that, function f4 is unimodal in case of its dimensionality less than 4. However, it becomes a difficult multimodal function when its dimensionality is no less than 4. Experiments show that it is even more difficult than some multimodal benchmarks. Function f5 is the step function, which is characterized by plateaus and discontinuity. Function f6 is a noisy quartic function, where random[0, 1) is a uniformly distributed random variable in [0, 1). Functions f7–f10 are multimodal functions where the number of local minima increases exponentially with the increase of the problem dimension. They appear to be the most difficult class of problems for many optimization algorithms. They are to verify the exploration ability and the ability to avoid falling into the traps of problems’ landscape. Functions f11–f15 are the low-dimensional multimodal functions.Since the aim of conducting these numerical experiments is nothing more than to illustrate the rationality and necessity of multi-swarm information sharing mechanism and three-stage perturbation guiding strategy, the parameters fine-tuning process are presented in Section 5. What our only requirement for the numerical experiments is to make the comparison impartial.All the experimental results of 30 independent runs are summarized in Tables 1 and 3. The reason that the comparison item “Median” is introduced besides “Mean” is that there are few exceptional results which may decrease the mean performance greatly for some benchmarks and conceal their essential properties in some cases.The algorithmic parameters for high-dimensional benchmarks are set as follows. The number of sub-swarms Q is 5. Both the swarm size m and the dimension number D of benchmarks are 30. The maximal iteration number G is 2000. The inertia weight ω is 0.9 and the accelerate constants c1=0.5, c2=0.3, c3=0.15. The perturbation radii σmax=0.4, σmin=0.001 and the division constants α1=0.2, α2=0.4 of Eq. (12). All the experiments and comparison analysis are all based on the statistical results over 30 independent runs.In general, the proposed algorithm MCpPSO greatly outperforms PSO, pPSA, MCPSO for most benchmarks except for functions f1, f3, and f8. The “Best, Mean” and “Median” items of MCpPSO are much better than those of PSO, pPSA, MCPSO for the other benchmarks observed from Table 1. These results clearly indicate that multi-swarm information sharing mechanism and three-stage perturbation guiding strategy can benefit each other and enhance the performance of algorithm greatly. However, the “Best, Mean, Median” items of f1 of MCPSO and the items of f3 of pPSA are better than those of MCpPSO. It indicates that three-stage perturbation guiding idea is not always helpful to the unimodal functions although it considers population diversity and selection pressure simultaneously. The “Median, Mean” and “STD” items of pPSA of f8 are slightly better than those of MCpPSO. However, the “Best” item of MCpPSO is greatly better than that of pPSA which illustrates the pinpoint locating ability of MCpPSO.The even more accurate results of MCpPSO indicate the necessity and superiority of the multi-swarm information communicating and sharing idea when comparing with pPSA for all functions but f3 and f8. When comparing with MCPSO the even better results of MCpPSO prove to be the prerequisite of three-stage perturbation operation for all the functions but f1. In a word, the hybridization with PSO of multi-swarm information sharing idea and three-stage perturbation operation is feasible, necessary and promising.Two-tailed t-test values with 29 degrees of freedom in Table 1, which are significant at α=0.05, further verify the performance of the proposed multi-swarm cooperative multistage perturbation guiding particle swarm optimizer.It is quite satisfiable for arriving at such excellent performance because the difference between MCpPSO and pPSA are the multi-swarm information communicating and sharing mechanism and the different perturbation operations. The difference between MCpPSO and MCPSO is the three-stage perturbation guiding strategy along the global best particle. At the same time, only a few simple numerical operations are added whatever information sharing mechanism and perturbation guiding search strategy. That is, the computing costs of pPSA, MCPSO and MCpPSO are nearly equivalent. However, the performance of MCpPSO is highly superior to those of pPSA and MCPSO. In other words, the excellent performance of the proposed MCpPSO algorithm is reached without introducing any expensive computing costs. It is reasonable to believe that even better algorithm can be obtained with even excellent performance if more specific domain knowledge is hybridized.The proposed MCpPSO is further compared with some state-of-the-art evolutionary algorithms in Table 2, in which “–” means that the corresponding results are not provided. These algorithms include fast evolutionary programming (FEP) with Cauchy mutation [34], fully informed particle swarm (FIPS) [19], comprehensive learning particle swarm optimizer (CLPSO) [16] and orthogonal learning particle swarm optimization with best performance (OLPSO-L) [35]. These algorithms are widely researched by many scholars since their appearance.When comparing with these state-of-the-art evolutionary algorithms, i.e., FEP, FIPS, CLPSO and OLPSO-L, we can see that the performance of MCpPSO is also comparable with that of FEP, FIPS, CLPSO and OLPSO-L. However, OLPSO-L performs overall best among them and other competitors perform comparably.The parameters are all the same as the above experiments except for the maximal iteration number G, which varies from different functions. G is 100 for function f11 and 500 for other four functions. The statistical experiment results are presented in Table 3.Observed from Table 3 we can find that these algorithms can find all the optimal results of these low-dimensional multimodal functions. When items “Median”, “Mean” and “STD” are considered, algorithm MCpPSO demonstrates great advantages over the other three algorithms. Together with the above group experiments for high-dimensional benchmarks, it can be believed that the proposed algorithm MCpPSO outperforms other comparison algorithms remarkably.In order to intuitively compare the average online convergence properties of the evolutionary performance besides final results, the average online evolutionary performance comparisons of four algorithms are presented now in Figs. 2 and 3. The abscissa is the evolutionary generation (iteration number). The vertical axis is the logarithmic plot of the average best function values per iteration over 30 runs for functions f1–f12. However, the average best function values (not logarithmic) per iteration over 30 runs are plotted for functions f13–f15 because their function values are negative.Observed from Fig. 2 we can find that all the average online best evolutionary function values per iteration of MCpPSO are much better than those of the other three algorithms (PSO, pPSA, and MCPSO) except for f1, f3 and f8, which are inherently coincident with the numerical comparison and analysis in Table 1.Generally speaking, most of the average online best evolutionary function values converge to much better solutions with much faster speed at the latter stage of algorithms. However, there are different convergent behaviors at the former stage for several algorithms. There are some stages that MCpPSO's converging speed is outperformed by some other algorithms for some functions. A sudden decline of the converging speed of MCpPSO for function f5 is because the average best function values of MCpPSO have arrived at zero and the logarithmic values approach to the negative infinity.Both the final results comparison of Table 1 and the average online best evolutionary performance comparison of Fig. 2 illustrate that MCpPSO takes precedence over algorithms PSO, pPSA, MCPSO for most of high-dimensional benchmarks.The online evolutionary performance comparisons for low-dimensional benchmarks, i.e., the average best function values per iteration over 30 runs vs. iteration numbers, are presented in Fig. 3. Due to the function values of functions f13–f15 are negative, the average function values on y-axis are not logarithmic, but their initial function values.Fig. 3 illustrates that the online evolutionary behaviors of MCpPSO outperform other three algorithms consistently for the low-dimensional benchmarks, although it is surpassed by other algorithm(s) in the initial or middle stages. All the functions exhibit this feature for the proposed algorithms. In a word, MCpPSO's performance validates the effects of the multi-swarm information communicating and sharing and three-stage global perturbation guiding search strategies.Equally exciting results can also be found in Table 4on the shifted optima experiments which further verified the stability and robustness of the proposed approach.In order to verify the performance of MCpPSO better, another group of comparison has been done with the optima shifted benchmarks. For instance, the sphere function f1 could bef(X)=∑i=1D(xi−5)2, so the best solution would be located at position (5, 5, …, 5) now. The optima shifted benchmarks will add some difficulties to the searching algorithms because the best solution vector of zeros may be biasing to the search engines.In this paper, the shifted row vector SHIFT is generated as the following Eq. (14), which is used to generated a 1×D integer matrix whose elements are integers within the range of [LB/2, UB/2],(14)SHIFT=randiLB2,UB2,1,Dwhere LB, UB are the lower and upper bounds of variables and D is the dimensionality of benchmark. For the special domain of function f6, its shifted row vector is generated as Eq. (15).(15)SHIFT=LB2+rand(1,D)UB2−LB2The experimental results are listed in Table 4.Generally speaking, the performance of all four algorithms become worse with different extents when comparing with Table 1 without shifted optima. Once again, MCpPSO outperforms its three competitors greatly for most of the benchmarks with shifted optima except for functions f6 and f8, which indicates the stability and robustness of MCpPSO. For functions f6, the mean results of MCPSO is slightly better than that of MCpPSO as t-test value indicates. However, there is no statistical difference between them. The performance of pPSA is statistically better than that of MCpPSO for functions f8 as t-test indicates. However, MCpPSO found much better solution (5.55×10−16) than pPSA (3.13×10−7).The multi-swarm cooperative perturbation guiding particle swarm optimizer has displayed encouraging performance as the above experiments and analysis show. However, further questions deserve to be considered if Eq. (11) is more concerned. (1) The global best particle (gbest) is perturbed when the velocities of particles of the current sub-swarm are updated. What will happen if the central position of the population perturbs together with gbest? (2) The gbest has imposed guidance effects on the velocity update process through the third term of Eq. (11). However, gbest still affects the velocity updating process through the central position as Eq. (3) shows. The motivation of these considerations is to further analyze the newly proposed updating strategy of Eq. (8) from different views. Two unimodal functions (f1, f3) and two multimodal functions (f7, f9) are adopted in the following first two groups of experiments.As we know, some related parameters are possible to have crucial/important/inessential influences on the performance of algorithms. Therefore, the influences of several parameters are also analyzed empirically besides the above mentioned considerations with three unimodal functions (f1, f2 and f3) and three multimodal functions (f7, f8 and f9) in the following latter three groups of experiments.The aim of this section is to consider the impact of the perturbation operation of the central position. Can the performance of MCpPSO be clearly improved with the central position perturbed as gbest perturbation guiding idea shows [37]? For simplicity the central position is perturbed similarly with three-stage perturbation guiding operation (Eqs. (10) and (12)). Then the central position is perturbed as Eq. (16) and the velocity updating operations of Eq. (11) will be modified as Eq. (17) accordingly. The other operations and parameters remain unchanged to keep our modification of MCpPSO to a minimum. Algorithm MCpPSO with central perturbation is denoted as MCpPSO+cp. The average online best evolutionary performance comparison between MCpPSO and MCpPSO+cp are given in Fig. 4based on four typical benchmarks.(16)pc,d′(k)=N(pc,d(k),σ)(17)vi,dq(k+1)=ωvi,dq(k)+c1r1(pi,dq(k)−xi,dq(k))+c2r2(pg,dq′(k)−xi,dq(k))+c3r3(pc,d′(k)−xi,dq(k))Fig. 4 shows that most parts of evolving curves nearly overlap each other for both MCpPSO and MCpPSO+cp on all these functions. There is a little difference between MCpPSO and MCpPSO+cp for function f1. For unimodal function f1, the convergence speed of MCpPSO+cp lags a bit at the final stage, which may be that the perturbation operation of the central position slows it down. However, MCpPSO and MCpPSO+cp have nearly equivalent average online evolutionary performance overall for all the functions. It illustrates that the central position perturbation-based guiding search strategy has no remarkable influence on algorithmic performance.The aim of this subsection is to consider the impacts of the different computing methods for the central position. That is, the velocity updating formula (11) and the computing formula (3) of the central position have or have not the global best particle of the present sub-swarm that the current particle belongs to. Then whether gbest of the sub-swarm has overmuch impact on the velocity updating of particles will be considered and analyzed accordingly. Algorithm MCpPSO without the global best particle of the current sub-swarm when computing the central position is denoted as MCpPSO-cg. The other operations and parameters remain unchanged to keep our modification of MCpPSO to a minimum.The average online best evolutionary performance comparison between MCpPSO and MCpPSO-cg are given in Fig. 5based on four typical benchmarks. Fig. 5 shows that the average evolving plots of MCpPSO-cg and MCpPSO have little difference on all the functions. It indicates that the computing formula (3) of the central position has little impacts on the performance of algorithm between with and without the global best particle of the present sub-swarm that the current particle belongs to.The number of sub-swarms, Q, is sure to have some influence on the performance of algorithm for the proposed multi-swarm cooperative multistage perturbation PSO algorithm. As the swarm size is 30, four cases of Q being 3, 5, 10 and 15 are considered in this group of experiment and all other parameters keep unchanged as Section 4 set.Generally speaking, the number of sub-swarms have important impacts on the performance of the proposed algorithm. As we observe from Fig. 6, the case of Q being 5 ranks highest for four functions and ranks the second for function f3. All the cases perform comparably for function f9. This case generally performs best and encouraging. At the same time, the case of Q being 3 ranks highest function f3, however, it performs significantly worse than the case of Q being 5. It performs similarly with the case of Q being 5 for unimodal functions. However, it seems not to be suitable for the multimodal functions. The case of Q being 15, which has rather many sub-swarms and the sub-swarm size is very small (sub-swarm size being 2), performs worst for most functions. The case of Q being 10 is a little better than the case of Q being 15 and performs comprehensively the second worst after the case of Q being 15.In a word, the number of sub-swarms Q being about 20% with respect to the total swarm size has comprehensively best performance whatever the unimodal or the multimodal functions. The number of sub-swarms Q being too large, i.e., the sub-swarm size being too small, may be discouraging.The perturbation radii σmaxand σminalso have some influences on the performance of algorithm for the proposed multistage perturbation operations. Five cases of (σmax, σmin) are considered in this group of experiment, which are (0.2, 0.0001), (0.4, 0.001), (0.6, 0.005), (0.8, 0.01) and (1, 0.015). All other parameters keep unchanged as Section 4 set.Observed from Fig. 7, five cases of (σmax, σmin) performs comparably for unimodal functions and multimodal f9, which indicates that the parameters of (σmax, σmin) are not significantly sense for the unimodal problems. The cases of (σmax, σmin) being (0.4, 0.001) and (0.6, 0.005) have the best performance for the multimodal functions. Therefore, any of these two cases can be adopted for algorithms.In a word, the parameters of (σmax, σmin) are not sense to the unimodal problems and they are suggested as the cases of (0.4, 0.001) and (0.6, 0.005) for multimodal functions.The division points (α1, α2) deciding when the perturbation operation will be switched have influences on the performance of algorithm for the proposed multistage perturbation strategy. Four cases of (α1, α2) are considered in this group of experiment, which are (0.2, 0.4), (0.3, 0.6), (0.4, 0.7) and (0.5, 0.8). All other parameters keep unchanged as Section 4 set.Generally speaking, none of the cases of (α1, α2) have clear bias to the unimodal or multimodal functions. There are also no bias for these four cases on function f9. Observed from Fig. 8, the case of (α1, α2) being (0.2, 0.4) ranks highest for functions f1, f2 and f7 and ranks last for functions f3 and f8. The case of (α1, α2) being (0.5, 0.8) ranks highest for functions f3 and f8, however, it ranks last for functions f1, f2 and f7.In a word, the division points for perturbation (α1, α2) with (0.2, 0.4) has comprehensively best performance whatever the unimodal or the multimodal functions.

@&#CONCLUSIONS@&#
