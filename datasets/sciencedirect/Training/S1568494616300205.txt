@&#MAIN-TITLE@&#
Evolutionary multi-objective blocking lot-streaming flow shop scheduling with interval processing time

@&#HIGHLIGHTS@&#
A conversion of the BLSFS problem with interval processing time is proposed.A variant of single-heuristic is incorporated in population initialization.A novel crossover operator is proposed.An ideal-point assisted local search is applied to improve the exploitation.It contributes to enhance the capacity of the algorithm in tackling uncertainties.

@&#KEYPHRASES@&#
Blocking lot-streaming flow shop scheduling,Interval parameter,Evolutionary multi-objective optimization,Local search,

@&#ABSTRACT@&#
A blocking lot-streaming flow shop scheduling problem with interval processing time has a wide range of applications in various industrial systems, however, not yet been well studied. In this paper, the problem is formulated as a multi-objective optimization problem, where each interval objective is converted into a real-valued one using a dynamically weighted sum of its midpoint and radius. A novel evolutionary multi-objective optimization algorithm is then proposed to solve the re-formulated multi-objective optimization problem, in which non-dominated solutions and differences among parents are taken advantage of when designing the crossover operator, and an ideal-point assisted local search strategy for multi-objective optimization is employed to improve the exploitation capability of the algorithm. To empirically evaluate the performance of the proposed algorithm, a series of comparative experiments are conducted on 24 scheduling instances. The experimental results show that the proposed algorithm outperforms the compared algorithms in convergence, and is more capable of tackling uncertainties.

@&#INTRODUCTION@&#
Various real-world applications, e.g., chemical, iron and steel, and manufacturing industries [1], can be formulated as flow shop scheduling problems, among which the lot-streaming flow shop (LSFS) scheduling problem is most typical. The main difference between the LSFS and the permutation flow shop scheduling problems is that the former splits a job into several sublots, with each being transferred to the downstream machine after it has been completed in the current one [2]. In most practical manufacturing enterprises, there is no intermediate buffer between machines to store completed jobs. Therefore, these completed jobs have to remain in the current machine, until its following one is available for processing, which increases waiting time and the production period. Previous research has already been done to tackle a blocking flow shop (BFS) scheduling problem [3], so as to improve the production efficiency. Similarly, in a lot-streaming flow shop (LSFS) scheduling problem, each sublot will also be blocked when there is no intermediate buffer to store completed sublots. These practical scenarios encourage us to apply the blocking constraint to a LSFS scheduling problem, and form a blocking LSFS (BLSFS) scheduling problem.Since the LSFS scheduling problem has a high complexity and a large number of constraints, significant efforts have been made on applying metaheuristics, such as chaos-induced discrete self organizing migrating algorithm (DSOMA)[4], artificial bee colony (ABC) [5] and estimation of distribution algorithms (EDA)[6] to solve such problems. However, a manager pays more attention to a scheduling problem with more than one objective [7]. If the due date is set in advance, the shorter makespan of a scheduling strategy, the longer its earliness time. Based on this fact, if one expects to simultaneously minimize makespan and earliness time, the scheduling problem will have two conflicting objectives. Further, if the scheduling problem is a BLSFS scheduling problem, one can formulate a BLSFS scheduling problem with two conflicting objectives, makespan and earliness time. For the above scheduling problem, it is in essence a multi-objective optimization problem. Up to date, evolutionary multi-objective optimization algorithms are the most commonly used and effective methods to tackle a multi-objective optimization problem, therefore, we apply an evolutionary multi-objective optimization algorithm to solve the considered problem. What is more, we propose a novel evolutionary multi-objective optimization algorithm to tackle the problem.Apart from the above-mentioned blocking constraint and multiple objectives characters, successfully solving practical scheduling problems are usually subject to a great number of uncertainties [8], such as uncertain processing time, machine breakdowns, arrival of new jobs, and resources shortages. The uncertainty in processing time of a flow shop scheduling problem has been addressed using stochastic, fuzzy, and interval programming techniques [9].In stochastic approaches, processing time is assumed to obey a known probability distribution [10]. Typically, some non-negative probability distributions, e.g., normal or exponential distributions, are adopted to convert stochastic processing time into its deterministic counterpart. Since this approach is quite straightforward, increasing attention has been paid to tackle stochastic scheduling problems [11–13]. In the literature, the probability distribution of processing time is usually assumed to be known, which is, however, not true in real-world situations, since processing time may change due to human factors or wrong operations.In the fuzzy approaches for solving scheduling problems, processing time is represented as a fuzzy value, and completion time can also be a fuzzy set [14]. Gao et al. [15] adopted a discrete harmony search algorithm for a flexible job shop scheduling problem with fuzzy processing time, in which three operations, i.e., addition, max, and ranking, are employed to compute and compare fuzzy completion time. Xu et al. [16] employed an effective teaching-learning-based optimization algorithm to solve the same problem considered in [14], in which processing and completion time are represented as the triangular fuzzy numbers. In addition, Alcan and BaşLıGil [17] utilized a genetic algorithm incorporating with fuzzy sets to tackle a non-identical parallel machine scheduling problem with uncertain processing time. Since processing time can be represented using different types of fuzzy numbers, it is difficult to choose an appropriate one.Although processing time is subject to uncertainties, its upper and lower bounds are often easy to know, which makes it very practical to use intervals to represent uncertain processing time [18]. Pereira studied a robust total weighted completion time problem with interval processing time. The author put forward valid methods to evaluate the maximal regret, and proposed a branch-and-bound method to obtain the sequence that minimizes the maximal regret [19]. Aydilek et al. proposed a heuristic algorithm with polynomial time, in which a weighted average of the lower and upper bounds of processing time is used to convert the processing time with interval type into real values [20]. Their experimental results showed that the proposed algorithm performs considerably well when the same weight is applied for the lower and upper bounds. After this, Allahverdi et al. [21] proposed several new heuristics with polynomial time based on the upper and lower bounds of processing time to solve single machine scheduling problems with uncertain processing time. The results indicated that the proposed heuristics perform significantly better than the heuristics compared in their work. One common idea in the above literature is that interval process time is transformed into a deterministic real value using a weighting function.In addition to the above methods for dealing with interval processing time, Matsveichuket et al. produced a minimal dominant set of schedules using a dominance relation digraph [22], resulting in a (some) dominant schedule(s) that is (are) optimal for all possible realizations of processing time.Although the above-mentioned methods have been successfully employed to solve the flow shop scheduling problems with uncertain processing time, no multi-objective optimization approach to BLSFS with interval process time has been reported. Since processing time is an interval, the resulted multi-objective BLSFS will have interval objective values, which makes it non-trivial to determine the dominance relation of different solutions. Therefore, it is high time that efforts be dedicated to the BLSFS scheduling problem whose criteria, such as makespan and earliness time, are subject to uncertain processing time.This study has the following twofold novelties:(1)This study first proposes a method of converting a multi-objective BLSFS scheduling problem with interval processing time into a conventional multi-objective BLSFS scheduling problem. Instead of converting interval processing time into a real value, we first calculate an objective interval based on interval processing time, and then convert the objective interval into a deterministic real value through a dynamically weighting. Such a dynamically weighted approach makes an optimization algorithm focus on minimizing both makespan and earliness time in early search stage, and dealing with uncertain processing time in later search stage. In this way, the algorithm can well balance between convergence and uncertainty handling during optimization.Following that, a novel evolutionary multi-objective optimization algorithm is then proposed to solve the re-formulated multi-objective scheduling problem. The proposed evolutionary algorithm has threefold of features. The first is that the population is initialized with solutions obtained by a variable single-objective heuristic algorithm. The second is that non-dominated solutions and differences among parents are taken advantage of when designing the crossover operator. Finally, an ideal-point assisted local search strategy for multi-objective optimization is employed to improve the exploitation capability of the algorithm.This work focuses on the BLSFS scheduling problem with makespan and earliness time, in which processing time of each job is an interval. LetPπ(j),tLandPπ(j),tU(0<Pπ(j),tL≤Pπ(j),tU) be the lower and the upper bounds of processing time of π(j) on machine t, respectively. The scheduling problem is subject to the following constraints:(1)Each job can be split into several sublots, and each sublot has different processing time on different machines;A job can be processed on the current machine only when all sublots of its foregoing job have been completed on the machine;At any time, each machine can process at most one sublot, and each sublot can be processed on at most one machine at the same time;All sublots of the same job should be continuously processed;A sublot has to be blocked on the current machine until its downstream one is available;Any two adjacent sublots of each job allow idle time at the same stage;Both the setup and the sublot transportation time are included in processing time.For the scheduling problem with interval processing time, it is difficult to compute complete time of each job on each machine. Generally, if the parameter of an optimization problem is an interval, the corresponding objective(s) of the problem is (are) also an interval. Even if complete time and earliness time are obtained it is also difficult to compare the interval objectives of two solutions and to obtain the dominance relation between them, thus increasing the difficulty in selecting the superior solution. To overcome the difficulty, it is of necessity to convert the BLSFS scheduling problem with interval processing time into a conventional optimization problem, and solve the converted problem using previous evolutionary algorithms.As shown in [23], an interval can be described with its characteristic values, namely, the midpoint and the radius, where the midpoint reflects the position of the interval, and the radius represents the amount of uncertainty of the interval. Most commonly used approaches for solving an interval scheduling problem reported in the literature convert interval processing time into a deterministic real value using a weighted sum of the midpoint and the radius. They are, however, inappropriate and imprecise for solving a scheduling problem with interval process time, since the problem is usually highly non-linear. For an uncertain scheduling problem, we often concern its average and stability of uncertain objective function(s). In view of this, we can capture the uncertainty by calculating the midpoint and the radius of an objective function, and then convert an interval objective value into a real value.In this study, we aim to minimize both the expected values and uncertainties of interval makespan and earliness time. To this end, we are going to convert the objectives with interval type into real values using a weighted sum approach, which is different from methods reported in the literature that usually convert interval processing time into real values and then calculate the fitness function.The two objective functions with integer type are converted into real-valued objectives, F1 and F2(2)F1=λ×m(f1)+(1−λ)×r(f1)(3)F2=λ×m(f1)+(1−λ)×r(f2)wherem(f1)=(f1L+f1U)/2;r(f1)=(f1U−f1L)/2;m(f2)=(f2L+f2U)/2;r(f2)=(f2U−f2L)/2fiLandfiUare the lower and upper bounds of fi(i=1, 2), respectively. m(fi) and r(fi) are the midpoint and the radius of the interval objective functions, fi, respectively.To clearly illustrate the aforementioned conversion process, an example of computing Eqs. (2) and (3) is given here. Suppose that there are 4 jobs, denoted as π(j), j=1, 2, 3, 4, processed on 3 machines, interval processing time of each job on 3 machine, are listed as follows:π(1):[3,6],[7,8],and[4,9];π(2):[4,7],[5,9],and[3,6];π(3):[3,6],[5,8],and[2,6];π(4):[5,9],[5,8],and[4,8];First, we randomly sample 3 times from interval processing time, to generate process time of each job on each machine, and obtain 3 specific process time sets,p4×31=[4,7,4,4,5,5,3,7,2,5,5,6,],p4×32=[5,8,6,6,7,6,6,8,2,6,8,4,],p4×33=[3,7,5,5,9,4,4,6,4,8,7,8]Second, for each determinate process time set, the corresponding determinate makespan and earliness time values, f1 and f2, are obtained using Eq. (1), that is,f11=36,f12=53,f13=45,f21=69,f22=82,f23=91Third, setf1L=mink=1,2,3f1k=36,f1U=maxk=1,2,3f1k=53,f2L=mink=1,2,3f2k=69,f2U=maxk=1,2,3f2k=91, and obtain the values of F1 and F2 according to Eqs. (2) and (3),F1=λ×(f1L+f1U)/2+(1−λ)×(f1U−f1L)/2=λ×44.5+(1−λ)×8.5F2=λ×(f2L+f2U)/2+(1−λ)×(f2U−f2L)/2=λ×80+(1−λ)×11It is notable that the values of the midpoint and the radius of makespan have different ranges. For a easy tradeoff, it is helpful to normalize their values into the same range, [0,1], usingm(f1)−minm(f1)maxm(f1)−minm(f1)andr(f1)−minr(f1)maxr(f1)−minr(f1), where min m(f1) and max m(f1) are the minimum and the maximum values of the midpoint of makespan, respectively; min r(f1) and max r(f1) are the minimum and the maximum values of the radius of makespan, respectively. Similarly, the midpoint and the radius of earliness time can also be normalized. For simplicity, the notations for the normalized makespan and earliness time remain unchanged.From Eqs. (2) and (3), it is clear that λ plays an important role in the reformulated BLSFS scheduling problem and it is thus properly essential to specify its value. Most methods reported in the literature convert interval processing time into a real values using a fixed, predefined weighting function of the midpoint and the radius and then calculate the objective. Unlike these methods, in this work, we first calculate the objective function using interval processing time, and then convert the interval objective values into real values. Furthermore, we believe that in solving the BLSFS scheduling problem in the presence of uncertainty in processing time, the optimization will be more efficient if an evolutionary algorithm focuses on minimizing makespan and earliness time in the early search stage and then concentrates on minimizing the uncertainty of optimal solutions in the later stage. Based on the above reasons, this work converts the objective values with interval type into real values using a dynamical weight that monotonously decreases from a value slightly less than 1 to a value slightly larger than 0 over time using a Gaussian-like function. The detailed setting of the parameter λ will be discussed in Section 4.1.Many effective multi-objective evolutionary optimization algorithms (MOEAs) have been developed, among which NSGA-II [24] has most widely been studied due to its effectiveness. However, existing MOEAs experience various difficulties when solving multi-objective BLSFS scheduling problems. First, random initialization has shown to be not a good strategy in solving scheduling problems. Second, a large amount of randomness in generating offspring using canonical crossover and mutation operators often slows down the convergence speed and degrades the efficiency of the algorithm. Last but not the least, there is a lack of effective local search strategies suited for multi-objective scheduling problems.Aiming at overcoming the above weaknesses in conventional MOEAs, we propose a new multi-objective optimization algorithm based on the selection mechanism in NSGA-II. First, the population is partly initialized using solutions obtained by a variable single-objective heuristic. Second, a new crossover operator is developed utilizing valuable information embedded in non-dominated solutions and differences between parents. Finally, a new local search strategy for multi-objective optimization has been proposed that uses the ideal point for selecting solutions generated by mutation operators.The main steps of the proposed evolutionary optimization algorithm are as follows:Step 1:Set the values of the parameters.Initialize the population using solutions generated by the heuristic and random method.Evaluate the initial solutions and put all the non-dominated solutions into the external archive.Repeat the following steps, until the termination condition has been fulfilled.Step 4.1:Generate a temporary population by employing a crossover operator that can utilize valuable information provided by both non-dominated solutions and the differences among parents;Mutate the temporary population using the insert and swap operators proposed in [2];Choose solutions with a certain probability from the temporary population, keep the better ones based on their distances to the ideal point;Merge the temporary population with the parent populations into a combined population, perform non-dominated sorting and calculate the crowding distance. Select the better individuals based on the Pareto dominance and the crowded distance to form the parent population of the next generation in which all the non-dominated solutions are used to dynamically update the external archive. Refer to [24] for details about non-dominated sorting and crowding distance calculation.The combination of MM (MinMax) with NEH (Nawaz, Enscore and Ham), termed MME, proposed by Ronconi et al. is often used for population initialization when solving a scheduling problem using meta-heuristics, with the purpose of reducing blocking time of a job on machines by utilizing the shortest critical path. MME has shown to perform better than other heuristics when optimizing makespan of a blocking flow shop scheduling problem [25]. To efficiently produce multiple solutions for the multi-objective scheduling problem considered in this study, a variant of MME, denoted as vMME, is designed to generate individuals for initializing a part of the population. To maintain the diversity of the population, the rest individuals are randomly generated in the neighborhood of these individuals. The following algorithm shows the detailed steps of vMME, in which pπ(j),tis the average sample value of process time of job π(j) on machine t.Algorithm 1The vMME heuristicInput: the number of jobs, n; a unscheduled sequence S, S={1, 2, …, n}.Output:num non-dominated solutions.1:Set π=∅, π*=∅;2:Setπ(1)=argminπ(j)∈Spπ(j),1; S=S\π(1);3:Setπ(n)=argminπ(j)∈Spπ(j),m; S=S\π(n);4:k=2;5:whilek<ndo6:Computeθπ(j)=φ∑t=1m−1|pπ(j),t−pπ(k−1),t+1|+(1−φ)∑q=1mpπ(j),q,π(j)∈S7:Setπ(k)=argminπ(j)∈Sθπ(j)8:S=S\π(k);9:k=k+1;10:end while11:Pick the first 2 jobs of π; form two subsequences, i.e. π1={π(1), π(2)} and π2={π(2), π(1)}, and select the one with the minimal value of 0.5*F1+0.5*F2 as the current sequence, π*;12:Set k=3;13:whilek≤n−1 do14:Pick the kth job from π, obtain k subsequences by inserting it into the current sequence, π*, at k possible positions, and select the subsequence with the minimal value of 0.5*F1+0.5*F2 as the current sequence, π*.15:k=k+1;16:end while17:/*There is no following statements for MME.*/18:Insert π(n) into the current sequence π* at n possible positions, simultaneously evaluate two objectives, F1 and F2. Denote the n complete sequences asTS;19:SetC=∅andTS′←TS;20:while|C|<numdo21:Seek non-dominated solutions inTS′→Dbased on the Paeto dominance relation;22:Setk=|D|.23:ifk≥(num−|C|)then24:Randomly selectnum−|C|non-dominated solution(s) fromD→E.25:C=C⋃E.26:else27:SetC=C⋃DandTS′=TS′∖D.28:end if29:end while30:OutputC.To clearly demonstrate the process of generating multiple solutions using vMME heuristic, the example used in Section 2.2 is provided here. First, the average sample value of each job on each machine is yielded according to the sample values of 3 times obtained in Section 2.2, which is,p4×3=[4,7,5,5,7,5,5,7,3,6,7,6]Suppose that the unscheduled sequence and the number of generated solutions are S={1, 2, 3, 4} and num=3, respectively. Processing time of job 1 on the first machine is the shortest, i.e., 1, we will arrange job 1 at the first position of π. On this circumstance, π(1)=1, and S=S\π(1)={2, 3, 4}. Following that, processing time of job 3 on the last machine is the shortest, we will arrange job 3 at the last position of π. In this case, π(4)=3, and S=S\π(4)={2, 4}. Let k=2,∀π(j)∈S,θ2=φ×∑t=1m−1|p2,t−p1,t+1|+(1−φ)×∑q=1mp2,q;θ4=φ×∑t=1m−1|p4,t−p1,t+1|+(1−φ)×∑q=1mp4,q;Suppose that φ=0.75, we can compute that θ2=7.25, and θ4=7, so job 4 with the smallest value of θ is selected, i.e., π(2)=4, and S=S\π(2)={2}. In this way, a seed sequence, π={1, 4, 2, 3}, is yielded by executing MM heuristic (seeing lines 2–10).The first 2 jobs in π, 1 and 4, are first taken, and their two possible permutations, {1, 4} and {4, 1}, are evaluated using 0.5*f1+0.5*f2. Since 0.5*f1({1, 4})+0.5*f2({1, 4})=23.62, and 0.5*f1({4, 1})+0.5*f2({4, 1})=21.57, the subsequence with smaller makespan, {4, 1}, is selected as the current one, π*.If k=3, the third job in π, 2, is taken, and three possible permutations, {2, 4, 1}, {4, 2, 1}, and {4, 1, 2}, are evaluated using 0.5*f1+0.5*f2. Since0.5*f1({2,4,1})+0.5*f2({2,4,1})=53.66,0.5*f1({4,2,1})+0.5*f2({4,2,1})=42.51,0.5*f1({4,1,2})+0.5*f2({4,1,2})=62.31,the best subsequence, {4, 2, 1}, is selected as the current one, π*.Following that, insert π(4) into the current subsequence, π*, at 4 possible positions, and simultaneously evaluate the two objectives of 4 permutations,f1({3,4,2,1})=69.21,f2({3,4,2,1})=86.36,f1({4,3,2,1})=56.32,f2({4,3,2,1})=87.25,f1({4,2,3,1})=69.21,f2({4,2,3,1})=95.22,f1({4,2,1,3})=72.10,f2({4,2,1,3})=88.27.Denote the 4 complete sequences asTS,TS={{3,4,2,1},{4,3,2,1},{4,2,3,1},{4,2,1,3}}. LetC=∅, andTS′←TS. Select non-dominated solutions inTS′based on the Pareto dominance relation, that is,TS′→D. So,D={3,4,2,1},{4,3,2,1}. Letk=|D|=2, andC=C⋃D={3,4,2,1},{4,3,2,1}, thenTS′=TS′∖D={{4,2,3,1},{4,2,1,3}}. Since|C|<3, we continue to put non-dominated solutions inTS′based on the Pareto dominance relation intoD. Herein,D={4,2,3,1},{4,2,1,3}is selected. Sincek=|D|=2, and k>=3−2, we randomly select a non-dominated solution fromD→E. SoE={4,2,1,3}.Lastly, 3 solutions, {3, 4, 2, 1}, {4, 3, 2, 1}, and {4, 2, 1, 3} are selected using the proposed vMME heuristic.In most crossover operators for solving scheduling problems, offspring can not only inherit information from their parents [26–28] but also take advantage of the differences information among the parents to seek the global optimum [29]. When solving a multi-objective scheduling problem, an evolutionary algorithm will converge with a rapid speed to the Pareto front if information embedded in all the non-dominated solutions in the current external archive can also be taken full advantage of [2] in crossover in addition to the parents or the population. To the best of our knowledge, no such crossover operators have been designed for solving scheduling problems. Our idea is to make use of valuable information provided by non-dominated solutions and the differences among parents in performing crossover. Denote the proposed crossover operator based on information of non-dominated solutions and the differences among parents as NDE. Algorithm 2 shows the detailed steps of NDE.Algorithm 2The proposed crossover operatorInput: a non-dominated solution set, and the current solution, π.Output: a new solution.1:Randomly select three different solutions, πa, πb, πc, from the current population, and obtain a temporary solution, πt, using the following equation [29,30],πt=πa∘flag•(πb−πc)2:Obtain a subsequence,πt′, by eliminating the repeated job(s) from the temporary solution, πt.3:Set πref=∅, /*πrefis a reference solution*/4:Count the times that each job in the non-dominated solution set appears at each position;5:Put the job not existing in πrefwith the most times at the position into the same position of πref. If there are two or more jobs with the identical times at the same position, randomly select one. Repeat this step, until πrefhas been a complete job;6:Eliminate job(s) included inπt′from πref, and obtain a subsequence,πtt′;7:Put the job(s) included inπt′into the vacant position(s) ofπtt′in turn;8:Update the current solution. Ifπtt′is better than π,π=πtt′In Algorithm 2, the equation, πt=πa∘flag•(πb−πc), can be represented as πt=πa∘Δ, where Δ=flag•(πb−πc) refers to the difference between parents, and parameter flag∈{0, 1} is a Boolean variable. For the jth dimension, Δj, of Δ,(4)Δjj=1,2,…,n=πb(j)−πc(j)rand<μ0otherwisewhere rand is a random value in the range of [0, 1], and μ is a scale to reflect the frequency of using the difference between parents. πa∘Δ is used to produce a temporary solution, πt, whose jth dimension, πt(j), is generated by Eq. (5):(5)πt(j)=πa(j)∘Δj=mod((πa(j)+Δj+n),n)+1,j=1,2,…,nwhere ‘mod’ means the modulus operator, whose result is the remainder of the first operand, (πa(j)+Δj+n), being divided by n to guarantee that each dimension of πtcan represent a job.It is worth noting that the proposed crossover operator takes advantage of not only the differences among parents, but also non-dominated solutions, which is demonstrated by an example given in Fig. 2.Suppose that there are 4 non-dominated solutions in the current archive, denoted as NS, with each containing 6 jobs as shown below.NS4×6=2,6,3,1,4,5,3,5,1,6,2,4,4,5,2,1,3,6,4,1,2,6,3,5Fig. 2(a) provides a process of generating the temporary solution, πt, based on line 1 of Algorithm 2. Fig. 2(b) shows that a subsequence,πt′, is produced by deleting the repeated jobs in πt. In Fig. 2(c), the reference solution, πr, is first yielded by counting the times that job j appears at position k (k=1, 2, …, 6) for j=1, 2, …, 6. The results are shown in Table 1. Then a subsequence,πtt′is generated by deleting jobs included inπt′. Fig. 2(d) illustrates a process of mendingπtt′, by re-inserting jobs inπt′into the vacant positions ofπtt′in turn.Various studies on evolutionary optimization have shown that incorporating local search into multi-objective optimization can enhance its exploitation capability [31]. In [32], a linear aggregation function is used to select a local optimal solution after local search, in which each objective is assigned with a weight, and solution(s) with the minimal value(s) of the linear aggregated function is (are) chosen. Due to its effectiveness and easiness to implement, the linear aggregation method has been successfully applied in a variety of multi-objective flow shop scheduling problems. Similarly, Sindhya et al.[33] employed an achievement scalar function to select solutions that are close to the reference point and have small values of the achievement scalar function. Inspired from the above ideas, a new local search strategy is suggested, which selects solutions based on their distances to the ideal point.The proposed local search is shown in Algorithm 3. In the algorithm, a solution, π, is first randomly selected with a probability of pls∈[0, 1] from the temporary population. Then the insert-neighborhood-based reference local search presented in [29] is performed on π to obtain a number of mutants in its neighborhood. Following that, an ideal point is generated, whose the kth dimension is equal to the best value of the kth objective function in the current population, and then the distance between the objective values of each mutant πi(the ith mutant) generated by the insert-and-neighborhood-based reference local search and the ideal point is computed as follows.(6)d(πi)=∑k=12(Fk(πi)−rk)2,i=1,2,…,nwhere r=(r1, …, rk) is the ideal point, rkis the best value of the kth objective function in the current population. d(πi) is the distance between the objective value of the mutant solution, πi, and the ideal point. Clearly, the smaller d(πi), the closer the solution to the ideal point in the objective space. Based on the above distance, the solution closest to the ideal point will be selected, which will replace solution π, if d(πi)<d(π).Algorithm 3Local searchInput: an ideal point, r; a reference solution, πnd={πnd(1), …, πnd(n)}, randomly selected from the non-dominated set.Output: a new solution π*.1:Select a solution, π={π(1), …, π(n)} with a probability pls from the temporary population.2:Set j=1;3:whilej<=n or the given stopping time is not met do4:Remove πnd(j) from π and form a subsequence, π′;5:Insert πnd(j) into another position of π′ n times, and obtain n neighbor solutions, i.e., π1, π2, …, πn, by considering all the insertion positions and keeping the relative positions of the other jobs unchanged;6:Compute the objective function values of the n neighbor solutions;7:Compute the distance between the objective value of each neighbor solution and r, and select the solution with the minimal distance as π*;8:If d(π*) is smaller than d(π), π=π*;9:j=j+1.10:end whileFig. 3provides an illustration of the proposed local search strategy. In this figure, a dot represents a solution in the temporary population. Solution π (denoted by the shaded circle) in Fig. 3(a) indicates a solution that is selected to perform local search; Fig. 3(b) shows four mutant solutions obtained using the insert-neighborhood-based reference local search, π1, π2, π3 and π4, wit each being denoted by a circle; Fig. 3(c) shows that an ideal point, r is generated, denoted by a diamond. d(π), d(π1), d(π2), d(π3), and d(π4), denoted as d, d1, d2, d3, and d4, for short are the distances between π, π1, π2, π3, π4 and r, respectively; Fig. 3(d) indicates that the solution, π4, with the minimal distance to the ideal point is now denoted as π*, which is used to replace solution π.In this section, the proposed algorithm is evaluated on 24 instances of the BLSFS scheduling problem with interval processing time. The following comparisons will be performed:(1)Comparison between the proposed vMME and MME heuristics;Comparison between the proposed crossover operator and the existing ones;Comparison between the proposed local search and the existing ones;Comparison of the performance between with and without converting the interval processing time into real values;Comparison between the proposed algorithm and the existing multi-objective algorithms.In this study, we adopt HV-U and HV-D to evaluate the performance of the proposed algorithm. The larger the value of HV-U, the better of the algorithm in terms of convergence, whereas, the smaller the value of HV-D, the better of the algorithm in terms of handling uncertainties. In addition, Mann–Whitney U test is employed to determine whether the results obtained by an algorithm are significantly different from those obtained by another, and the null hypothesis is rejected at the significance level of 0.05.In this study, all the algorithms adopt the same maximal elapsed CPU time with the unit of millisecond as the termination criterion. As mentioned in [36], all the experiments should be conducted and compared under the same or stricter conditions. If different algorithms are implemented on different PCs, the implementation settings of different algorithms will be different. On this circumstance, using execution time as the stopping criterion will not be reliable any longer, since execution time may be affected by the operating system and other applications running during the experiments. Thus, all the algorithms are written in Visual C++ 6.0 and the same library functions are adopted in this study to make a fair comparison. For their implementations, all the algorithms are realized on a PC with Pentium (R) Dual 2.79GHz and 1.96G memory, in which the operating system is Microsoft Windows 7 X64. In addition, the same background running environment is employed, the background processes that may occupy system resources are closed, and no other programs are executed in parallel during implementing an algorithm.For the LSFS scheduling problem, the standard test instances used in the experiments were proposed by Yoon and Ventura [37], and Tseng and Liao [38], in which 24 instances with the size of n={10, 30, 50, 70, 90, 110} and m={5, 10, 15, 20} are randomly generated, and the related data, i.e., due date and number of sublots, are provided based on the discrete uniform distributions listed in Table 2. Each instance is independently run for 30 times. We randomly sample 300 cases from interval processing time between [1, 31].As mentioned in Section 2.2, λ monotonously decreases over time. In this study, λ is specified using a Gaussian function defined as follows:(7)λ(t)=α×(e−t2/β×T2+γ)where t is elapse time and T is stopping time. Parameters α, β and γ are determined by our pilot experiments, which suggest that α=0.9626, β=0.465, and γ=−0.0128 can produce good results. Fig. 4depicts the change of λ over time given the parameters defined above.

@&#CONCLUSIONS@&#
Most algorithms in the literature address the flow shop scheduling problem without considering uncertainties. In real-world applications, however, scheduling problems are often subject to various uncertainties. In this study, the BLSFS scheduling problem with interval processing time is investigated, in which the interval objectives are converted into the real-valued ones using a dynamically weighted sum of the mid-point and the radius. On top of this, an novel multi-objective evolutionary algorithm is proposed to solve the re-formulated multi-objective optimization problem, in which an ideal-point assisted local search strategy for multi-objective optimization is employed to improve the exploitation capability of the algorithm.The performance of the proposed algorithm is empirically evaluated on 24 instances of the BLSFS scheduling problem with interval processing time. Sensitivity analysis on parameters pls and λ are carried out, comparison between with and without conversion method is investigated, comparison between the proposed local search and the existing ones is conducted, and comparison between the proposed algorithm and the existing multi-objective ones is studied. The above experimental results demonstrate that the interval conversion method is of necessary, and the proposed algorithm is efficient in seeking optimal solutions and tackling uncertainties.There are several opportunities for future research on the BLSFS scheduling problem with interval processing time. First, the mutation operator is randomly selected from two to generate offspring in this study. It might be desirable to develop a self-adaptive mechanism to select the mutation operator from them so as to improve the exploration capability of the algorithm. Second, the proposed local search strategy can be further improved to reduce the computational complexity of the algorithm. Third, uncertainties related to machine breakdowns, wrong operations and changes in the due date should also be considered when tackling the BLSFS scheduling problem. Last, to remedy the current unsatisfactory situation regarding the experiment replication and comparison, the termination criterion of an algorithm should be appropriately designed, such as replacing the maximal elapsed CPU time with the number of fitness evaluations, to fulfill the comparisons among heuristics algorithms for the flow shop scheduling problem.