@&#MAIN-TITLE@&#
Robust common spatial patterns with sparsity

@&#HIGHLIGHTS@&#
A new approach, termed as sp-CSPL1, is proposed for single-trial EEG classification.L1-norm is used as sparsity regularization, as well as robust modeling.A theoretically validated iterative algorithm is presented.

@&#KEYPHRASES@&#
Brain–computer interface (BCI),Common spatial patterns,Robust feature extraction,Sparsity regularization,

@&#ABSTRACT@&#
Robust and sparse modeling are two important issues in brain–computer interface systems. L1-norm-based common spatial patterns (CSP-L1) method is a recently developed technique that seeks robust spatial filters by using L1-norm-based dispersions. However, the spatial filters obtained are still dense, and thus lack interpretability. This paper presents a regularized version of CSP-L1 with sparsity, termed as sp-CSPL1. It produces sparse spatial filters, which eliminate redundant channels and retain meaningful EEG signals. The sparsity is induced by penalizing the objective function of CSP-L1 with the L1-norm. The sp-CSPL1 approach uses the L1-norm twice for inducing sparsity and defining dispersions simultaneously. The presented sp-CSPL1 algorithm is evaluated on two publicly available EEG data sets, on which it shows significant improvement in classification accuracy.

@&#INTRODUCTION@&#
In recent years, electroencephalogram (EEG)-based brain computer interfaces (BCI) have drawn progressively attention of researchers due to its non-invasiveness and high temporal resolution [1]. One core issue in BCI is to perform robust and accurate classification of EEG signals recorded under different mental states [2,3].For the purpose of mental states classification, spatial filtering is an effective technique for extracting useful discriminative features [4]. The way of common spatial patterns (CSP) [5] is one of the most widely used spatial filtering approaches in the field of BCI. For two classes of EEG signals under different mental states, CSP finds the optimal few directions that project EEG signals onto a subspace where the variances of projected signals from one class are maximized meanwhile the other class minimized. While CSP has been proven to be effective for feature extraction, its sensitiveness to noise and/or outlier is still an intractable problem. Accordingly, the robust modeling of CSP has been studied in the last few years [4,6,7]. Particularly, Samek et al. [8,9] unify many CSP variants in a framework based on divergences, in which the problem of robust modeling of CSP is considered. Roijendijk et al. [10] present an alternative formulation of CSP. Recently, a robust method, named L1-norm-based CSP (CSP-L1) [11], was developed. The CSP-L1 technique models EEG signals using the L1-norm dispersions rather than the conventional L2-norm so as to suppress bad effects caused by outliers. It was demonstrated that CSP-L1 has prospective classification performance for robust modeling [11]. CSP is also formulated by using the L1-norm technique, instead of the L2-norm, in performing the eigen-decomposition for estimating spatial filters (L1-SVD-CSP) [12].The neurophysiological study suggests that, when people are performing cognitive or motor imaginary tasks, only several task-specific areas of their cerebral cortex rather than the whole cerebral cortex are activated [13]. It is thus beneficial to obtain meaningful signals from these spatially separated regions for classification. However, the spatial filters induced by CSP-L1, as well as L1-SVD-CSP, are still dense. That is, the entries of the spatial filters, which are used as weighs, are typically many non-zeroes. A variation of signals from any channels may result in a variation of the extracted features, since the features are weighted combinations of signals from all channels. Besides, there may be redundant channels, which make little contribution to the classification of specific mental states and even deteriorate the classification performance due to the artifacts and/or noise collected by these channels.In this paper, motivated by the lasso-based sparsity modeling [14], we plug an L1-norm regularization term into the original CSP-L1 criterion so as to seek sparse spatial filters. We term the proposed method as sparse CSP-L1 (sp-CSPL1). We point it out that the L1-norm is employed twice in the objective function of sp-CSPL1. One is used as the penalty term to induce sparsity, and the other is used to define sample dispersions for robust modeling (which is inherited from CSP-L1). Accordingly, different from the existing sparse versions of CSP [15,16] and the channel selection in CSP via solving a series of quadratic problems [17], sp-CSPL1 yields sparse and robust filters by optimizing one single objective function. The optimization for the objective function of sp-CSPL1 with the sparsity-inducing penalty and the robust dispersions by the L1-norms is not straightforward due to the non-differentiability of the L1-norm. We thus design an iterative algorithm to tackle the optimization problem of sp-CSPL1. It is well known that the L1-norm is widely used for sparsity [18,19] and robust modeling [20–22] individually in the fields of computer vision and signal processing. Especially for individual sparsity modeling, a general framework underlying optimization tools and techniques, called as variational lower bound, is presented by Bach et al. [23]. The sparsity optimization is also casted as an iteratively reweighted least squares (IRWLS) problem [24]. Different from the individual sparsity modeling or the individual robust modeling, in this paper, we use the L1-norm for simultaneous sparsity and robust modeling in one objective function.The remainder of this paper is organized as follows. In Section 2, the conventional CSP and CSP-L1 are briefly reviewed. The proposed sp-CSPL1 method and its efficient iterative algorithm are introduced in Section 3. Section 4 presents experimental results on two EEG data sets. Finally, we conclude this paper in Section 5.Both the conventional CSP approach and its robust version CSP-L1 are applied to a two-class paradigm. They find the best few pairs of filters to optimize the quotient of the two classes of filtered EEG signals. LetXl=(x1l,x2l,…,xSl)∈RC×S(l=1,2,…,tx)be the lth EEG trial from one class andYr=(y1r,y2r,…,ySr)∈RC×S(r=1, 2, …, ty) the rth trial from the other class, where txand tyare the numbers of trials of the two classes, C is the number of channels, and S is the number of samples in a single EEG trial. To simplify the symbolic representation, let X=(X1, X2, …, Xtx)=(x1, x2, …, xm)∈RC×mand Y=(Y1, Y2, …, Yty)=(y1, y2, …, yn)∈RC×ndenote the concatenated EEG measurements of all the trials from the two classes. Here m=tx×S and n=ty×S. We assume that all the trials have already been band-pass filtered, centered and scaled.The CSP objective function is given by(1)JCSP(ω)=ωTCxωωTCyωwhere Cxand Cyare the average covariance matrices of the two classes. Thus, the objective function can be further formulated as(2)JCSP(ω)=∥ωTX∥22/tx∥ωTY∥22/tywhere ∥·∥2 denotes the L2-norm. The spatial filters ω can be determined by solving the generalized eigenvalue equation(3)Cx=λCyωSpecifically, the few eigenvectors from both end of the eigenvalue spectrum are chosen to comprise a filter matrix. The log-transformed variances of the filtered signals from the two classes are used as features for classification.The CSP-L1 approach modifies the objective function of CSP by replacing the conventional L2-norm with the L1-norm in the dispersion formulation, which results in the objective function(4)JCSP-L1(ω)=∥ωTX∥1/tx∥ωTY∥1/ty=∑i=1m|ωTxi|/tx∑j=1n|ωTyj|/tywhere ∥·∥1 indicates the L1-norm. The computational issue of CSP-L1 is solved by an iterative algorithm [11].In the process of calculating the spatial filters by CSP-L1, all the channels are equally considered. The entries of the CSP-L1 filters, which measure the importance of corresponding channels, are usually not zeroes. However, for a specific cognitive task, not all encephalic regions are involved. It is beneficial to eliminate redundant channels in the filtering process. In other words, it is expected to achieve sparse spatial filters. Note that volume conduction means that a single compact source will propagate to all electrodes unequally. However, in some cases the signal-to-noise will be such that it's not worth being used.We commence inducing sparsity via a lasso-based penalty, which limits the L1-norm length of ω to a relatively small value. This is implemented by optimizing the objective function of CSP-L1 with an inequality constraintω1<τ. Mathematically, we propose maximizing the objective function(5)Jsp-CSPL1(ω)=∑i=1m|ωTxi|/tx∑j=1n|ωTyj|/ty−γ∥ω∥1where γ is a positive parameter that controls the sparsity of the resulting filters. Another paired filter is obtained analogously by maximize the dual form of (5) where the two classes of signals are swapped. For concise expression, in the following part, we assume that xiand yjhave already been normalized as xi/txand yj←yj/tyrespectively.We term the proposed method as sparse CSP-L1 (sp-CSPL1). Clearly, the objective function of sp-CSPL1 involves the L1-norm twice. One is used as the penalty term to induce sparsity, and the other is used to define the sample dispersions for robust modeling. Specifically, the first term in the right hand of (5) involves the sum of the absolute values of filtered samples (i.e., L1-nrom), the robustness of which is demonstrated by Wang et al. [11]. The second term is the penalty term based on the L1-norm, which is the lasso expression and thus induces sparsity [14]. The computational problem of sp-CSPL1, nevertheless, is not straightforward. Inspired by recent researches on the L1-norm-based optimization problem [11,22,25], we propose an iterative algorithm of maximizing Jsp-CSPL1(ω) in Table 1. The maximization of the dual form of Jsp-CSPL1(ω) is likewise implemented by exchanging the positions of X and Y.The computational complexity of the iterative algorithm is O((m+n)c) in each iteration.It will be justified that the objective function of sp-CSPL1 would be increased monotonously through the iterative procedure outlined in Table 1, i.e., Jsp-CSPL1(ω(t))≤Jsp-CSPL1(ω(t+1)). For this purpose, at iteration t, we define a function given by(6)J(ϖ)=∑i=1m|ϖTx_i|∑j=1n|ϖTy_j|−γ∥ϖ∥1Then, according to the definition ofω_(t), we haveJsp-CSPL1(ω(t))=J(ω_(t)). If we can updateω_(t)such thatJ(ω_(t))≤J(ω_(t+1)), and further combineJsp-CSPL1(ω(t+1))=J(ω_(t+1))due to the formulation of ω(t+1), then the monotonicity of the iterative algorithm of sp-CSPL1 is achieved. Below, we aim to showJ(ω_(t))≤J(ω_(t+1))with the update step (e) in Table 1.We start with the introduction of bound optimization [26], by which we transfer the optimization of J(ϖ) to the optimization of a surrogate functionQ(ϖ|ω_(t)). The core ingredient of this transfer requires thatJ(ϖ)−Q(ϖ|ω_(t))attains its minimum at the pointω_(t). Then we only need to find the updatedω_(t+1)that maximizes or loosely raises the value of the surrogate functionQ(ϖ|ω_(t)). It is thus guaranteed that the objective function J(ϖ) would be increased, i.e.,J(ω_(t))≤J(ω_(t+1))[26].We present a surrogate function given by(7)Q(ϖ|ω_(t))=2ϖTu(t)ϖTV(t)ϖ+h(t)−γ2(ϖTB(t)ϖ+∥ω_(t)∥1)whereu(t)=∑i=1mpi(t)x_i,V(t)=∑j=1n(y_jy_jT)/|ω_T(t)y_j|,h(t)=∑j=1n|ω_T(t)y_j|, and B(t)=diag(b11(t), b22(t), …, bcc(t)) in which the entries are given bybkk(t)=|ω_k(t)|−1for k=1, 2, …, c. Here,ω_(t)=(ω_1(t),ω_2(t),…,ω_c(t))Tand c is number of non-zero entries. The validity of the surrogate function is demonstrated below.For the numerator inQ(ϖ|ω_(t)), noting the definition of pi(t), we have that(8)2ϖTu(t)=2ϖT∑i=1mpi(t)x_i≤2∑i=1m|ϖTx_i|Clearly, the equality is attained atϖ=ω_(t). For the denominator, we have that(9)ϖTV(t)ϖ+h(t)=∑j=1n(ϖTy_j)2|ω_T(t)y_j|+∑j=1n|ω_T(t)y_j|≥2∑j=1n|ϖTy_j|The above inequality in (9) holds due to the variational equality [27]: for any vector z=(z1, z2, …, zn)T, there exists the equality2||z||1=minτ∈R+n∑j=1n(zj2/τj)+||τ||1and the minimum is uniquely gained when τj=|zj| for j=1, 2, …, n. Here, τ is the vector τ=(τ1, τ2, …, τn)T. Also, (9) attains its equality if takingϖ=ω_(t). For the quadratic form inQ(ϖ|ω_(t)), again by the variational equality, we have that(10)ϖTB(t)ϖ+||ω_(t)||1=∑k=1cϖk2|ω_k(t)|+||ω_(t)||1≥2||ϖ||1where ϖ=(ϖ1, ϖ2, …, ϖc)Tand the equality holds atϖ=ω_(t).Combining (8)–(10), it follows thatJ(ϖ)≥Q(ϖ|ω_(t))with the equality holding atϖ=ω_(t). It is thus proven thatQ(ϖ|ω_(t))is a validate surrogate function. Differentiating the surrogate functionQ(ϖ|ω_(t))with respect to ϖ, it reads that d(t) is the gradient at the pointω_(t). Consequently, with the update step (e) in Table 1, we haveQ(ω_(t)|ω_(t))≤Q(ω_(t+1)|ω_(t)). By the principle of bound optimization, we haveJ(ω_(t))≤J(ω_(t+1)). The proof is then established.After obtaining the first k spatial filters, the (k+1)th filter ωk+1 is extracted on the deflated data of X and Y. That is, we apply the same iterative algorithm to maximize the objective function of sp-CSPL1 by using the deflated samples, given by(11)xik+1=xi−∑l=1kωl||ωl||2Txiωl||ωl||2(12)yjk+1=yj−∑l=1kωl||ωl||2Tyjωl||ωl||2With the above deflation procedure, we acquire a few pairs of spatial filters by maximizing Jsp-CSPL1(ω) andJˆsp-CSPL1(ω). The feature extracted from one single EEG trial E∈RC×Sis a k-dimensional vector(∥ω1TE∥1,∥ω2TE∥1,…,∥ωkTE∥1)T, where k is number of spatial filters. The L1-norm-based features are used to train a classifier.We use two publicly available real EEG data sets to evaluate the performance of the proposed sp-CSPL1 method in dealing with the classification problem of single-trial EEG. The first one is the data set IVa from BCI competition III [28]. The second data set consists of EEG trials of 109 subjects from EEG motor/imagery data set recorded using BCI2000 instrumentation system provided by Physionet [29,30]. We train spatial filters using the training data and then apply them to the testing data, and thus acquire classification accuracy. We desire to investigate the sparsity of the spatial filters, which is main contribution of this paper.Data set IVa from BCI competition III. This data set contains EEG data from five subjects, i.e., aa, al, av, aw, and ay, recorded using 118 channels. For each subject, 280 trials in total are available, among which 168, 224, 84, 56, and 28 trials are used for training for aa, al, av, aw, and ay, respectively. In each session, a visual cue is indicated for 3.5s, during which the subject should perform the following three motor imageries (MI): (L) left hand, (R) right hand, and (F) right foot. We focus on the classification problem of left hand and foot MI in this study.BCI2000 data set. In this data set, each subject performs 14 experimental runs including two one-minute baseline runs and three two-minute runs of four different motor/imagery tasks while 64-channel EEG are recorded using the BCI2000 system. We focus on the third, seventh and eleventh runs where left and right fist motor/imagery tasks are executed. There are 45 trials for each subject. There are seven subjects whose recorded signals are not annotated properly, and are excluded in our experiment. We use the strategy of five-fold cross-validation for the remaining 102 subjects, and the average classification rate of the five folds is computed.For both of the two data sets, time segments from 0.5 s to 2.5 s after visual cues of the raw EEG signals are chosen. Then the time segments are filtered by the fifth order Butterworth filter with cutoff frequency of 8–35Hz to capture the event-related desynchronization (ERD) rhythm in the two motor movements. Note that the slope of the filter decades when the order increases. The larger the order, the sharper the cutoff will be. Particularly, the gain turns out to be a rectangle function as the order becomes infinity. In the field of BCI, as suggested by Lotte and Guan [31], the order of the Butterworth filter is seat as five.We compare the classification accuracy of sp-CSPL1 with other three methods: the conventional CSP, a representative regularized CSP with Tikhonov regularization (TRCSP) [31], and CSP-L1. We also demonstrate the sparsity of the spatial filters produced by sp-CSPL1. The regularization parameters of TRCSP and sp-CSPL1 are searched in {1e−6,1e−5,…,1e1} and {1e−3,1e−2,…,1e5}e−6, 1e−5, …, 1e1} and {1e−3, 1e−2, …, 1e5}, respectively, via ten-fold cross-validation on the training data. For sp-CSPL1 and CSP-L1, the initial solutions are set to be the corresponding ones of the standard CSP. In the implementation of the sp-CSPL1 algorithm, we search an optimal value of η from {1e−5,1e−4,…,1e1}e−5, 1e−4, …, 1e1} in each iteration rather than using one single value.

@&#CONCLUSIONS@&#
