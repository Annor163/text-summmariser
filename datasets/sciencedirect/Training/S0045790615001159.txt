@&#MAIN-TITLE@&#
Detection of objects on waters’ surfaces using CEIEMV method

@&#HIGHLIGHTS@&#
A new method for detecting salient objects on waters’ surfaces is proposed.The proposed object-detection method enables an efficient and robust detection.Four different methods were compared with the proposed CEIEMV method.The proposed method equals or outperforms the methods being compared.

@&#KEYPHRASES@&#
Colour elimination,Hydro power plants,Image eroding,Object detection,Waters’ surfaces,

@&#ABSTRACT@&#
This article presents a new method for detecting objects on waters’ surfaces using colour elimination based on image erosion with a morphological variable. The proposed object detection method includes definitions of the target’s colour space and colour deviation using Euclidean distance. It also introduces a procedure for image erosion using a morphological variable. In order to evaluate the proposed object detection method, the experiments were performed on two different image databases: the MSRA (Microsoft Research Asia) salient object database and a proprietary image database containing pictures of water activities typically encountered near hydro power plants. The experimental results show that the proposed object detection method enables efficient and robust detection of objects on of waters’ surfaces, compared to other methods primarily based on the optimisation of image contrast and edge detection.

@&#INTRODUCTION@&#
Detecting objects on waters’ surfaces, especially vessels and driftwood, is an increasingly important problem, particularly in the area of automatic surveillance systems [1] such as those in the vicinity of hydro power plants. As with many other automatic surveillance systems [2], hydro power plants and their vicinities are covered with video cameras and equipped with video surveillance systems. Nowadays, many hydro power plants are remotely controlled from control centres, and any system capable of detecting objects on waters’ surfaces, especially vessels and driftwood, using an existing video surveillance system onsite would therefore be of great interest. Navigation on rivers within the vicinity of hydro power plants is problematic, not only because of direct threats from outside persons but also due to the potential for various work-related consequences that can pose a serious risk to the power plants themselves. These consequences range from negligible events to those that can seriously endanger the functioning of the power plant for a certain period of time and threaten the safety of the persons involved. In the surroundings of a hydro power plant, there are defined areas in which any kind of river navigation is prohibited. In the accumulation pool areas, however, some sports activities such as boating, rafting, swimming, driving motorboats and so on take place. These can cause grave problems in cases when a person or object is swept away towards the hydro power plant. If we could detect and recognise these kinds of objects by automatic means, we would be able to adequately warn the crew at the guidance centre, who could take appropriate action. The second issue is the detection of driftwood, which, like navigation, can present serious problems for those working at hydro power plants. Driftwood is a relatively serious problem in hydro power plant areas, especially during times of increased river flow, because it demands regular cleaning of the entrance grids of turbine flows and the removal of driftwood from barriers.Several methods of object detection on waters’ surfaces or on other complex backgrounds have been introduced in the past based on the optimisation of image contrast and other procedures. Some of these methods [3,4] use contrast or multiple difference images as one of the key features for distinguishing objects from their backgrounds. Robust detection of objects within a complex background is an appealing task, especially in real-life situations such as surveillance systems in all-weather situations. Detecting objects on waters’ surfaces can be regarded as a complex background problem, especially considering the variability of water surfaces due to various weather conditions, lighting, water colour changes, etc.A number of object detection methods dealing with complex backgrounds have been introduced in the past. In order to achieve better results, many of these methods use edge detection [5–7] as part of their method for detecting objects, while some methods [8,9] use contrast optimisation for improved edge detection. Several methods for object detection or for the detection of moving objects are based on extracting objects from their backgrounds [10–13]. Nowadays, many state-of-the-art methods deal with salient object detection [14–19], which is generally defined as the detection of that which captures human perceptual attention. The Colour Elimination method based on Image Eroding using a Morphological Variable (CEIEMV), as proposed in this article, combines all of the aforementioned approaches.The present paper is organised as follows. A definition of the base colour value, which is specific for each application domain within which the proposed method could be used, is given next in Section 2.1. Section 2.2 defines colour deviation, in which pixel-based image processing is performed. The result of colour deviation calculation is a table of values of individual pixels. Section 2.3 describes the definition of the threshold value. All of the values of the individual pixels that do not satisfy border criteria and do not fall into a specific colour space are eliminated from further processing and are considered to be useless. Section 2.4 provides the definition of a morphological variable with which we can later, during the procedure of eroding specific colour segments, easily detect those elements within the image that actually present the objects for detection. After the erosion procedure, we obtain a created mask that contains the elements of the defined colour space. By eliminating these areas, we extract the object that we want to detect from its original image (Section 2.5). Definitions of boundary conditions, parameters and edge conditions are given in Section 3. In order to evaluate the effectiveness of the proposed method, we perform a comparison with selected methods (Section 3.2) using the MSRA (Microsoft Research Asia) salient object database [14] and a proprietary image database containing pictures of various water activities. The experimental results for the proposed method and the comparison of the results with the results of other methods are given in Section 4.The proposed object detection method (Fig. 1) encompasses the phases of defining the colour space, colour deviation using Euclidean distance, transformation of the image into a grey image, borders, thresholding, and image erosion using morphological variables.The term colour space represents a complex description of colour spectra that is distinctive for a specifically observed image area. This method enables adjustment of the base colour space [21] by defining different base colours, thus allowing the use of a wide colour spectrum.Let I denote an image of size M×N, where (x, y) are coordinates of image I (Fig. 4a). Then(1)I=i11…i1N⋮⋱⋮iM1⋯iMNrepresents a two-dimensional image of any size. Each pixel P=I(x, y) can be presented within an RGB colour space as(2)P=IM,N(x,y)=[RM,N(x,y),GM,N(x,y),BM,N(x,y)]where RM,N(x, y), GM,N(x, y), and BM,N(x, y) are the values for the three colour channels of the analysed pixel P in image I, of size M×N. The base colour space value Bcs is then specified as(3)BcsM,N=[RM,N,GM,N,BM,N]where RM,N,GM,N, and BM,Nare the values for each of the three coloured channels. Definition of the base colour values is obtained by experimental tests and is based on images from the image database used in these experiments.The Euclidean distance [21] measurement is used to define a table of colour deviations for individual pixels (used later for the definition of thresholds for the elimination of specific pixels). The colour values for individual colour elements are defined as:RM,N(x, y)=value of the red of the analysed pixel,GM,N(x, y)=value of the green of the analysed pixel,BM,N(x, y)=value of the blue of the analysed pixel.Using a previously defined base colour space, we mark the colour values of the pixel named Base with:RM,N=value of the red on the predefined pixel,GM,N=value of the green on the predefined pixel,BM,N=value of the blue on the predefined pixel.The Euclidean distance between points a and b within image I is the length of theline segmentconnecting them. The distance from a to b or from b to a is stated as:(4)d(a,b)=d(b,a)=(b1-a1)2+(b2-a2)2+⋯+(bn-an)2=∑i=1n(bi-ai)2The result is a table T, size M×N, containing values that show the comprehensions of red, green and blue within an individual pixel, in terms of the predefined values for the pixel Base. By using the predefined base colour values and the colour values of the individual colour elements, each value in T is defined as:(5)ValueM,N=((RM,N-RM,N(x,y))2+(GM,N-GM,N(x,y))2+(BM,N-BM,N(x,y))2)The minimum and maximum values that each ValueM,Ncan take in T are limited, as the colour values of the pixels are also limited. The values of RM,N,GM,N,BM,N, RM,N(x, y), GM,N(x, y), and BM,N(x, y) are limited from 0 to 255. Based on RGB colour value definition, each of the three base colours (red, green and blue) can be represented within 256 different colour values. Therefore, the minimum and the maximum values of ValueM,Nare also limited.Let us assume that the values of RM,N,GM,N,BM,N, RM,N(x, y), GM,N(x, y) and BM,N(x, y) are 0.(6)RM,N=0∧GM,N=0∧BM,N=0∧RM,N(x,y)=0∧GM,N(x,y)=0∧BM,N(x,y)=0Based on (5) and (6), we define the ValueM,N(min) as:(7)ValueM,N(min)=0=0In order to obtain the value of ValueM,N(max), each pair of analysed and predefined pixels (RM,N, RM,N(x, y); GM,N, GM,N(x, y); BM,N, BM,N(x, y)) in (5) must have a total value of 255. For:(8)(RM,N=0∧RM,N(x,y)=255)∨(RM,N=255∧RM,N(x,y)=0)and(9)(GM,N=0∧GM,N(x,y)=255∨(GM,N=255∧GM,N(x,y)=0)and(10)(BM,N=0∧BM,N(x,y)=255)∨(BM,N=255∧BM,N(x,y)=0)then:(11)ValueM,N(max)=442After calculating each pixel in image I, we obtain a table T with those sizes of M×N that contain values showing the comprehensions of red, green and blue components within individual pixels in terms of the predefined values of the pixel Base.(12)ValueM,N=i11,i12…i1N-1,i1N⋮⋱⋮iM1,iM2⋯iM-1N-1,iMNFor the sake of easier threshold definition, the min and max table values are denoted as:(13)ValueM,N(min)=0ValueM,N(max)=255All pixels in image I that have values x greater than the ValueM,N(max) are assumed to have value ValueM,N(max).(14)ValueM,N(i)=ValueM,N(min),x=0ValueM,N(i),0<x<255ValueM,N(max),255⩽x⩽442An example of element values is shown in Fig. 2in the form of a histogram.The next step is the scaling of the individual pixel values ValueM,N(i) of the image I (Fig. 4b) in order to define a scaled image. The basic images are converted into images of specific colour spectra, depending on the values ValueM,N(i) that individual pixels take in table T. The darker shades within the image represent those colour spaces that should be eliminated from the original image during the next step. After defining a colour deviation and RGB to luminosity, greyscale is performed (Fig. 4c) based on [26].The definition of the threshold method anticipates the data-driven definition of threshold [22,24]. Let us assume that image I is a group of discrete values for brightness. The proposed threshold definition method, based on histogram analysis, uses an interpretation of the histogram image (Fig. 2). From this image, the method can estimate a threshold above which the values are 1 and below which the values are 0. This kind of thresholding translates a greyscale multilayer image into a double layer or binary image. The threshold method is defined as:(15)T(x,y)=fb(I(x,y),t),fb(I,t)=1;I⩾t0;I<twhere I (x, y) is a greyscale image and t is a threshold value. If we threshold image I by the threshold value t, we divide a group of grey levels GL={0, 1… L−1}, with the distribution of grey levels D={D0, D1…DL−1}, into two separate subgroups:(16)GA={0,1…t}and(17)GB={t+1,t+2…L-1}to which the following distributions belong:(18)DA=D0D∗(t),D1D∗(t)…DtD∗(t)and(19)DB=Dt+11-D∗(t),Dt+21-D∗(t)…DL-11-D∗(t)where(20)D∗(t)=∑i=0tDiAssuming that the pair (GA, DA) and (GB, DB) are the probabilistic functions of two random discrete variables with information:(21)HA(t)=-∑i=0tDiD∗(t)logDiD∗(t)(22)HB(t)=-∑i=t+1L-1Di1-D∗(t)logDi1-D∗(t)The optimal threshold value t∗ is the value that maximises the sum of the information:(23)t∗=argMaxt∈GL{HA(t)+HB(t)}All of the values for individual pixels P=I(x, y) that do not reach the threshold value t and do not fall into a certain colour space are eliminated from further processing and denoted with the value 0. All of the values that reach the threshold value t are denoted with value 1. The binary image can be defined (Fig. 4d) based on these values. White colour – represented by the value 1 in Fig. 4e – represents the individual pixels P=I(x, y) that denote the appropriate result. Black colour – represented by the value 0 in Fig. 4d – represents the areas of individual pixels that are to be eliminated. From Fig. 4d, we can clearly see that during this phase we achieved the initial requirements of colour elimination. We can also see from Fig. 4d that, besides the eliminated object (seen as white colour), some additional elements exist that have reached the threshold value and are shown in the image as additional objects distributed across the image. These objects should be further eliminated from the final image.By eroding the colour spaces using a morphological variable (24), we seek to additionally eliminate those areas from the image that do not represent the detected target object. In general, the erosion procedure [23,24,26] reduces the size of the object within the image on which the procedure is performed, as well as eliminating smaller anomalies.Firstly, the structuring element, the morphological variable, is defined (Fig. 3a).(24)S(j,k)The structuring element consists of a pattern, specified as a number of discrete points relative to a certain shape. The origin (the main pixel in the structuring element, marked as darker in Fig. 3a) is often at the centre of the structuring element. The structuring element, which is much smaller than the image, is itself a binary image and can be of different shapes.In general, the erosion procedure of the image I(j, k) is expressed as:(25)G(j,k)=I(j,k)θS(j,k)where S(j, k) is an odd-size N×N structuring element and θ denotes the erosion function. If we define the translation of the image as(26)G(j,k)=Tr,c{I(j,k)}where r represents rows, and c columns within the image I(j, k), then the erosion procedure is defined as(27)G(j,k)=∩∩Tr,c︸(r,c)∈M{I(j,k)}meaning that the eroding of the image I(j, k) by the structuring element S(j, k) is the intersection of all of the translates of I(j, k) within which the row and column indexes of the pixels of the structuring element S(j, k) have the value 1 [23,25,32].The erosion phase completely removes those objects smaller than the structural element from the binary image (Fig. 4e), or removes the areas of single-detected points from the larger image objects. In the method of detecting objects on waters’ surfaces using colour elimination based on image erosion with a morphological variable, the erosion phase is defined as a procedure that, during the first step, erodes the image with a structuring element S(j, k) at an angle of 90°. During the second step, we again erode the image with the same element, but the angle is now 0° (Fig. 3b). The structuring element S(j, k) slides over the image I and transforms it in such a way that the origin is left as it is if a shape is the same as the structuring element, otherwise the pixel is set to black. If we compare the image after the erosion procedure (Fig. 4e) with the image after the thresholding phase (Fig. 4d), we can see that with the eroding procedure most of the image regions in the picture that were perceived as suitable have been removed after determining the threshold border phase.By overlaying the defined mask on the original image, we extract the target objects from the basic image (Fig. 4f). All of the pixels ValueM,Nthat have values 0 in the table were eliminated from the image – denoted as black in Fig. 4f – whereas the pixels with values 1 are shown in Fig. 4f in the form of a mask over the original image. We can see from Fig. 4f that we have eliminated the basic colour space from the image determined at the beginning. With the proper definition of colour deviation, we have successfully eliminated all shades of the base colour space representing the water’s surface in the basic image. Those pixel areas foreign to the target object were successfully removed after the image erosion process.We will later compare the results of the proposed method with those of methods that use Sobel edge detection as part of the overall method [6,7], The Sobel edge detection method is applied over the masked part of image I (Fig. 4g). This procedure takes a binary image G, obtained after eroding image I, by using the morphological variable S as its input,(28)G(j,k)=I(j,k)θS(j,k)and returns a binary image of the same size as I, with values of 1 where the method finds edges and values of 0 elsewhere. If we compare the results of edge detection over the original image (Fig. 8 1b) with the final results from Fig. 4g, it is evident that the proposed method improves edge detection in a such way that the object’s shape clearly stands out from the original image. From Fig. 4, we can also clearly see that the proposed CEIEMV method (Fig. 4f) successfully eliminates all unsuitable pixels from the original image (Fig. 4a), and that the target object is successfully detected.In the experimental setup, the image size was limited to 800×600 pixels, as this is the output image size of the images from which the image database containing pictures of water activities near hydro power plants was created. In addition, all of the other images in the MSRA image database used in the evaluation of the proposed method have the same size. The limitation of the image size did not affect the results of the method; therefore, any other image size could also be used.The next initial condition is an edge condition, requiring a definition of ValueM,Nthat an individual pixel can take from table T, which is filled with values that show the comprehensions of red, green and blue colours within an individual pixel. Given the limited image size used in the experiments, the size of table T is 800×600 elements. The definition of Euclidean distance and the values of RM,N, GM,N, BM,N, RM,N(x, y), GM,N(x, y), BM,N(x, y), which are limited based on colour value definition with an interval from 0 to 255, limits the highest possible value of ValueM,Nto 442, based on (5) and (13). However, the maximum value of ValueM,Nwas limited to ValueM,N(max)=255. The applied limiting value of the edge condition for an individual pixel is set at ValueM,N(max) and equals 255, because all values higher than ValueM,N(max) (14) are considered to be results that are over the threshold, which means that such pixels are suitable for further processing. In the case that a certain random pixel or a small number of pixels take values above 255 and are not considered as being appropriate for further processing, this colour space or individual pixel will be eliminated during the erosion phase.The proposed CEIEMV method is designed in a Matlab development environment. The shape and size of the morphological structuring element (Fig. 3a) is selected based on extensive testing within the Matlab development environment, thus ensuring that the erosion procedure (25) provides the best results for further processing. Due to the proposed method’s modular design, the algorithm could easily be implemented in any other system. Furthermore, its simple design enables further improvement of results by incorporating additional modules where appropriate.The proposed object detection method has been extensively tested and evaluated on two databases: the publicly available MSRA (Microsoft Research Asia) salient object database [14] and a proprietary image database containing pictures of water activities that typically take place near hydro power plants. The MSRA database contains 25,000 images in two separate image sets. Image set A contains 20,000 images with the ground truth manually labelled by three users, while image set B contains 5000 images with the ground truth manually labelled by nine users. The proprietary image database used for evaluation of the proposed method was collected from images that represent one of four groups of objects. It contains over 500 different images that represent scenes, vessels, driftwood and sports activities on waters’ surfaces, all of which are typically present in the vicinity of hydro power plants. The images were divided into four groups of objects (scenes of people in the water, vessels on the water’s surface, sport activities on the water’s surface, driftwood and other floating objects on the water’s surface). Besides the images showing different objects on the water’s surface, both databases also contain other images that do not contain water surfaces and that are used for evaluating the robustness of the proposed method.Four different methods were compared with the proposed CEIEMV method. The first was the SED method (Sobel Edge Detection), which performed Sobel edge detection [7] on the original image. The second was the ALHV method (Auto Levelling Histogram Values), which enhanced the contrast [30] of the image by transforming the values within an intensity image, so that the histogram of the output image approximately matched a specified histogram. In the third method, the MLHV (Manually Levelling Histogram Values) method, the histogram [31] was manually levelled based on establishing upper and lower values. Liu [14] proposed an approach that learns to detect the salient object, and also constructed the MSRA image database. The salient objects are detected by combining their local, regional and global saliences with conditional random field learning. The fourth method used in the analysis was therefore the SOD (Salient Object Detector) method [14], based on Ordonez implementation [20].As we will later also compare the results of the proposed method with methods that use Sobel edge detection as part of the overall method [6,7], Sobel edge detection is applied over the original image I (Fig. 4a).A high-pass filter is applied on the image to detect whether there are changes presented at every pixel. The Sobel operator is the linear filter used for high-pass filtering over the image. It uses the following 3×3 masks:(29)-1-2-1000121-101-202-101Let I denote the image from which we want to eliminate objects. The two Sobel masks are convolved with image I separately, in order to measure the strengths of the horizontal Ehand vertical Evedges, as presented in each pixel (30).(30)Ei,jh=-xi-1,j-1-2xi-1,j-xi-1,j+1+xi+1,j-1+2xi+1,j+xi+1,j+1Ei,jv=-xi-1,j-1-2xi,j-1-xi+1,j-1+xi-1,j+1+2xi,j+1+xi+1,j+1These two strengths are added to obtain Etotal, which represents the total value that each pixel P in image I can take.(31)Ei,jtotal=(Ei,jh)2+(Ei,jv)2The value of Etotal is compared to the predefined threshold T, in order to determine the existence of an edge in each pixel P=I(x, y)(32)P=I(x,y)=1,Ei,jtotal>T0,Ei,jtotal⩽Twhere 0 means no edge, as represented by the black colour, 1 means edge pixel, as represented by the white colour, and T is the edge detector threshold value computed by a technique for estimating a threshold value described by Pratt [23].

@&#CONCLUSIONS@&#
