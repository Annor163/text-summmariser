@&#MAIN-TITLE@&#
Adaptive large window correlation for optical flow estimation with discrete optimization

@&#HIGHLIGHTS@&#
A method based on using large correlation windows with adaptive support-weightsThree new weighting constraints from image gradient, color statistics and occlusionContributes to suppress the effect of cluttered background in the windowsElevates the quality of estimations especially on object boundaries

@&#KEYPHRASES@&#
Window correlation,Optical flow,Data cost,Discrete optimization,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Optical flow estimation aims to find dense visual correspondence between reference and target images. Obtaining dense correspondence between images can benefit computer vision algorithms, such as super-resolution, video denoising, and 3D scene reconstruction, of which performances are easily influenced by image matching quality [1–3]. A basic clue to the problem is the brightness constancy constraint, assuming that the intensity value of a pixel may not change in both the images. However, optical flow estimation remains a difficult problem as it is highly under-constrained, with ambiguity that one pixel in the reference image may correspond to many pixels in the target image.Various approaches have been introduced. In [4], a global formulation is combined with the linearized brightness constancy assumption, to enforce spatial coherence between locally adjacent flows, using a quadratic function. Although this seminal approach has been employed as a baseline algorithm in numerous follow-up researches, but it suffers from over-penalized outliers included in the motion boundaries. To address this challenge, many works proposed more robust penalizing functions. Black et al. [5] replace the quadratic error function with the Lorentzian function, which is robust to outliers, but is very difficult to find the optimum due to its non-convexity. The functions based on L1-norm [6–8] have been shown to be a good substitute for the non-convex robust function, utilizing variational methods for optimization.Filtering approaches may also be applied to address the boundary issue. In [9], a multi-cue driven bilateral filter is employed to discard background clutter in the smoothing kernel. Sun et al. [10] reveal that applying the median filter to intermediate flow estimations [11] is a very effective approach to the issue. They incorporate this heuristic scheme in their energy function as non-local L1 smoothness prior and present state-of-the-art results.While most of these works employ the variational method for optimization, several works reported promising results using discrete optimization methods [12–14]. In [15], proposal solutions using continuous optimization are first computed and then, combined with discrete optimization. To reduce the high complexity of discrete methods, Glocker et al. [16] incrementally update flow vectors, only within highly probable regions. In [17], an input image is represented as a tree of over-segmented regions, which defines an energy function to be optimized by dynamic programming. A non-local smoothness prior on the discrete framework [18] is also proposed, showing competitive results to the variational models. In contrast, Rhemann et al. [19] present plausible estimations, using cost-volume filtering without using any prior information, which reduces much of the computational complexity.In this work, we address the estimation based on the discrete MAP–MRF framework [16,20], comprising the data matching cost and the spatial smoothness cost. In comparing brightness of pixel for the data cost calculation, we employ local neighborhoods of the pixel [21,7], instead of the single pixel of interest. This pixel set of local neighborhoods is referred to as a correlation window. We aim to improve the estimation, by enhancing the quality of the correlation window matching.One critical factor for the quality of the matching is the size of the window. A large correlation window can address the aperture phenomenon, and other robustness issues, such as illumination change and/or random noise. On the other hand, the large window may also include cluttered background motion segments, which may cause incorrect window matching on motion boundaries. To address this issue, the support-weight based approach [22,23] has been widely employed in the field of stereo matching. It imposes different weights on each pixel t in the window according to geometric and photometric constraints, e.g., the pixel's proximity and the color difference to the central pixel s, defined as follows:(1)wsproxt=exp−xs−xt22σg2,(2)wscolort=exp−Is−It22σp2,where xs, and xtindicate 2D coordinates, and I(s), and I(t) mean color values of the points s and t, respectively.This strategy gives an effect accentuating the foreground object, and outperforms previous works, such as adaptively changing window size [24] and using multiple windows [25]. However, the fixed variances (σg, σp) that are applied to all image regions can degrade the performance on certain image regions, particularly for very large correlation windows. Learning the parameters on test images can be a solution, but it requires extra time complexity, and may not cover the variety of real world scenes.We propose to employ three new types of weight constraints, which are adaptively adjusted, based on contents in the correlation window.Gradient structure constraint: The previous proximity constraint applies the homogeneous weight to every correlation window regardless of the image contents in each window. This may help coherent estimation on a single large object, but may degrade results on objects with detailed geometric structures, such as small branches of a tree. Since such objects form strong image gradients in general, we propose to use the structure tensor of the window, to adaptively apply the weight distribution according to the geometric structure. We assign strong weights normal to the predominant gradient directions in the window. As a result, the shape of weighted region in the window appears to be a sharp ellipse along with the objects, reducing the effect of background regions outside the objects.Perceptual color constraint: In the previous color constraint in Eq. (2), σpneeds to be small enough, to clearly distinguish a foreground object from background objects by their color difference. However, the small variance may result in over-segmented estimation on a single large object containing various colors inside, which could stem from object texture, image noise or specular illumination. Addressing the issue, we propose to use perceptual color distance that takes account of color distribution and accordingly calculate the weight. By applying a new perceptual color distance instead of the Euclidean color distance, we could obtain relatively high coherence inside the single object, while using the small σpfor the boundary distinction.Occlusion constraint: Occlusion indicates the phenomenon that a certain area of the reference image is not seen in the target image due to various reasons, such as object movement and/or view change. Since the pixels in the occlusion do not correspond to any pixel in the target image, we propose to exclude this region in computing widow correlation.We compare our results with results using the proximity and color constraints in [22,23], and show that the proposed constraints outperform the previous constraints in our experiments. To demonstrate the effect of the occlusion constraint, we show that adding the occlusion constraints to the geometric and photometric constraints leads to improvements in quantitative evaluation. We also show that the proposed constraints jointly yield highly competitive performance on various datasets, especially on motion boundaries.The rest of this paper is organized as follows. Section 2 briefly defines our energy formulation for the discrete framework. In Section 3 we propose the new adaptive correlation window design and show its advantages. Section 4 introduces a method to enhance the efficiency of the discrete optimization, and Section 5 presents experimental results evaluating the proposed model. We finalize this work by providing the conclusion and the future work in Section 6.

@&#CONCLUSIONS@&#
