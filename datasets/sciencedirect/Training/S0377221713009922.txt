@&#MAIN-TITLE@&#
Row-reduced column generation for degenerate master problems

@&#HIGHLIGHTS@&#
We propose a new algorithm to solve degenerate column generation master problems potentially faster.We generalize and unify the previous methods “Improved Primal Simplex” and “Dynamic Constraints Aggregation”.We formulate a characterization of linear programming optimality.

@&#KEYPHRASES@&#
Column generation,Degeneracy,Dynamic row-reduction,

@&#ABSTRACT@&#
Column generation for solving linear programs with a huge number of variables alternates between solving a master problem and a pricing subproblem to add variables to the master problem as needed. The method is known to often suffer from degeneracy in the master problem. Inspired by recent advances in coping with degeneracy in the primal simplex method, we propose a row-reduced column generation method that may take advantage of degenerate solutions. The idea is to reduce the number of constraints to the number of strictly positive basic variables in the current master problem solution. The advantage of this row-reduction is a smaller working basis, and thus a faster re-optimization of the master problem. This comes at the expense of a more involved pricing subproblem, itself eventually solved by column generation, that needs to generate weighted subsets of variables that are said compatible with the row-reduction, if possible. Such a subset of variables gives rise to a strict improvement in the objective function value if the weighted combination of the reduced costs is negative. We thus state, as a by-product, a necessary and sufficient optimality condition for linear programming.This methodological paper generalizes the improved primal simplex and dynamic constraints aggregation methods. On highly degenerate linear programs, recent computational experiments with these two algorithms show that the row-reduction of a problem might have a large impact on the solution time. We conclude with a few algorithmic and implementation issues.

@&#INTRODUCTION@&#
Column generation, invented to solve large-scale linear programs (LPs), is particularly successful in the context of branch-and-price (Barnhart, Johnson, Nemhauser, Savelsbergh, & Vance, 1998; Lübbecke & Desrosiers, 2005) for solving well-structured integer programs. Column generation is used to solve the LP relaxations at each node of a search tree, and often produces strong dual bounds. It alternates between solving a restricted master problem (an LP) and one or several subproblems (usually integer programs) in order to dynamically add new variables to the model. Like the primal simplex method, column generation suffers from degeneracy. This defect is particularly visible when solving LP relaxations of combinatorial optimization problems, a main application area of branch-and-price.In this methodological paper, we present a row-reduced column generation (RrCG) method which turns degeneracy into a potential advantage. Our method differs from standard column generation only in iterations where degeneracy occurs in the restricted master problem (RMP). We dynamically partition the RMP constraints based on the numerical values of the current basic variables. The idea is to keep only those constraints in the RMP that correspond to strictly positive basic variables. This leads to a row-reduced restricted master problem which does not only discard most variables from consideration in column generation, but also reduces the number of constraints, and in particular the size of the current working basis. In linear algebra terms, we work with a projection into the subspace spanned by the column-vectors of the non-degenerate variables. This is similar to the idea of a deficient basis in the simplex method (Pan, 1998). This row reduction comes at the expense of a computationally more involved pricing subproblem which needs itself to be solved by column generation.Degeneracy in column generation has been dealt with using perturbation of the right-hand side as in the standard primal simplex method. In particular, certain dual variable stabilization approaches explicitly use perturbation, see Ben Amor, Desrosiers, and Frangioni (2009) for a stabilized column generation framework and the many references therein. Recently, a new line of research emerged for coping with primal degeneracy in linear programming, namely theimproved primal simplexmethod (IPS) (Elhallaoui, Metrane, Desaulniers, & Soumis, 2010; Raymond, Soumis, & Orban, 2010). Our work generalizes IPS for solving degenerate linear programs and the dynamic constraints aggregation method (Elhallaoui, Desaulniers, Metrane, & Soumis, 2008; Elhallaoui, Villeneuve, Soumis, & Desaulniers, 2005; Elhallaoui, Metrane, Soumis, & Desaulniers, 2010) for solving LP relaxations of set partitioning problems (by column generation) stemming from vehicle routing and crew scheduling applications. The referenced papers suggest that, on highly degenerate linear programs, a row-reduction of a problem shows great promise in reducing overall solution times.The paper is organized as follows. Section 2 recalls the column generation method with the definitions of the master problem MP, its variable-restricted version RMP and its pricing subproblem SP. Section 3 presents the RrCG approach. It essentially defines the row and column partitions of the master problem based on a current degenerate solution, introduces the row-reduced restricted master problem RrRMP and its associated pricing subproblem rSP, and finally brings in a specialized column generator cSP for single columns compatible with the row-reduced master problem. Section 3.4 discusses the case of inequality constraints followed by an algorithm. Section 3.6 provides a necessary and sufficient optimality condition for linear programs. Finally, Section 4 discusses some properties followed by implementation issues. Our conclusions complete the paper in Section 5.Let us briefly recall the mechanism of standard column generation, see Lübbecke and Desrosiers (2005) for a general introduction. We would like to solve the following linear program, called the master problem (MP), with a prohibitively large number of variablesλ∈R+n(1)zMP★≔minc⊺λs.t.Aλ=b[π]λ⩾0,whereA∈Rm×Rn,c∈Rn, andb∈Rm. The corresponding dual variablesπ∈Rmare listed in brackets. We assume thatλincludes m non-negative artificial variables, hence A is of full row rank, and MP is feasible ifb⩾0. In applications, every coefficient columnaof A encodes a combinatorial objectx∈Xlike a path, permutation, set, or multi-set. To stress this fact, we writea=a(x)andc=c(x)for its cost coefficient. Column generation works with a restricted master problem (RMP) which involves a small subset of variables only. At each iteration, RMP is solved to optimality first. Then, like in the primal simplex algorithm, we look for a non-basic variable to price out and enter the current basis. That is, we either find a columna(x)of costc(x)with a negative reduced costc¯(x)or need to prove that no such variable exists. This is accomplished by solving the pricing subproblem (SP)(2)c¯SP★≔minx∈Xc(x)-π⊺a(x).Ifc¯SP★⩾0, no negative reduced cost columns exist and the current solutionλof RMP (embedded intoR+n) optimally solves MP (1) as well. Otherwise, a minimizer of SP (2) gives rise to a variable to be added to RMP, and we iterate.Functionsc(x)anda(x)may be linear functions, as in a Dantzig-Wolfe reformulation of a linear program (Dantzig & Wolfe, 1960), butc(x)is typically non-linear in many practical applications such as in rich vehicle routing and crew scheduling (Desaulniers et al., 1998). Functionsa(x)are also non-linear when Chvátal-Gomory cuts are derived from the master problem variables, see Desaulniers, Desrosiers, and Spoorendonk (2011). Non-linearities may increase the difficulty in solving SP, but it always ends up in a scalar costcjand a vectorajof scalar coefficients for each variableλjin MP,j∈{1,…,n}.Vectors are written in bold face. We denote byIkthek×kidentity matrix and by0(resp. 1) a vector/matrix with all zero (resp. one) entries of appropriate contextual dimensions. For subsetsI⊆1,…,mof row-indices and subsetsJ⊆1,…,nof column-indices we denote byAIJthe sub-matrix of A containing the rows and columns indexed byIandJ, respectively. We further use standard linear programming notation likeAJλJ, the subset of columns of A which are indexed byJmultiplied by the corresponding sub-vector of variablesλJ. There is one notable exception: The set N will not denote the non-basis (but usually a superset). Even though one never actually computes the inverse of a basis matrix, our exposition will sometimes rely on“tableau data,” when it is conceptually more convenient.RMP is a column-reduced MP and its variables are generated as needed by solving SP. The row-reduced column generation comes into play when the current solution of RMP is degenerate withp<mpositive variables. In what follows, we define a row-reduced RMP, denoted RrRMP, which decreases the number of rows to only p. The case with equality constraints is treated first as formulated in (1), and a generalization to the inequality-constrained case is presented in Section 3.4.Letλbe a feasible solution to MP, with the index setF⊂{1,…,n}of variables at strictly positive value, that is,λF>0. These variables are free to increase or decrease relatively to their current values. All other possibly present variables assume a null value, that is,λN=0forN≔{1,…,n}⧹F. We assume thatλis degenerate in the sense that the number of positive variables is less than the number of rows of MP, i.e.,|F|=p<m. The columns ofAFare required to be linearly independent, which is no restriction whenλis computed with a simplex algorithm. This assumption allows us to construct a basis matrixABfor MP representing the solutionλin the following way. Identify a subsetP⊂{1,…,m}of p linearly independent rows ofAFand “fill up” withm-punit columns to provide for artificial basic variables in the rows indexed byZ≔{1,…,m}⧹P. More precisely, this yields the following form(3)AB=APF0AZFIm-p.One way to accomplish this form is to initialize the RMP with columnsAFand m artificial variables and apply a phase I of the primal simplex algorithm. The above construction induces row and column partitions, and MP (and the corresponding vector of dual variablesπ) reads as(4)zMP★≔mincF⊺λF+cN⊺λNs.t.APFλF+APNλN=bP[πP]AZFλF+AZNλN=bZ[πZ]λF,λN⩾0.The inverse of the above basis matrix (3) has a particularly easy form,(5)AB-1=APF-10-AZFAPF-1Im-p.If we left-multiply (4) byAB-1, we obtain the equivalent “tableau data” formulationzMP★≔mincF⊺λF+cN⊺λNs.t.λF+A‾PNλN=b¯PA‾ZNλN=0λF,λN⩾0,whereA‾PN=APF-1APNandA‾ZN=AZN-AZFAPF-1APN. We can see that our choice of basis reveals that our row partition reflects the degenerate solution in the tableau form, whereP={i|b¯i>0}andZ={i|b¯i=0}. Indeed,(λF,λN)=(b¯P,0)is a degenerate basic solution to MP whereλF=APF-1bPis computed using the smaller working basisAPF-1, ap×pmatrix. Finally, observe that there is no need to left-multiply the system of constraints in row-set P byAPF-1. Hence, MP can be expressed as follows:(6)zMP★≔mincF⊺λF+cN⊺λNs.t.APFλF+APNλN=bP[ψP]A‾ZNλN=0[ψZ]λF,λN⩾0,where the new dual vectorψis given by(7)[ψP⊺,ψZ⊺]=[πP⊺,πZ⊺]Ip0AZFAPF-1Im-p=[πP⊺+πZ⊺AZFAPF-1,πZ⊺].Pricing subproblem SP now equivalently writes as(8)c¯SP★≔minx∈Xc(x)-ψP⊺aP(x)-ψZ⊺a¯Z(x).We emphasize that the basis we constructed for MP is not unique. The form we propose has convenient properties, but even there it is our choice which rows appear in P, see Section 4.1.To exploit the degeneracy of the solution exhibited in (6), we row-reduce the RMP, denoted by RrRMP. To this end, we discard the rows in set Z:(9)zRrRMP★≔mincF⊺λF+cN⊺λNs.t.APFλF+APNλN=bP[ψP]λF,λN⩾0.Solution(λF,λN)is optimal for MP (6) if no negative reduced cost columns exist, that is, ifc¯SP★⩾0, or equivalently, ifc¯N⩾0. From (6) or (9), it holds thatψP⊺=cF⊺APF-1. However, the value of dual vectorψZis not known. Consequently, we cannot solve the pricing subproblem SP as expressed in (8), and we need to come up with an alternative.Compute the partial reduced cost vectorc̃N⊺≔cN⊺-ψP⊺APN=cN⊺-cF⊺APF-1APNand write the current reduced cost vectorc¯Nin (6) in terms of the unknown vectorψZof dual variables:c¯N⊺=c̃N⊺-ψZ⊺A‾ZN. To verify the non-negativity ofc¯N, one can find the minimum value of its components by solvingmax{μ|μ⩽c¯j,∀j∈N}, i.e., by solving the following pricing subproblem rSP overμand the unknown vectorψZ(10)c¯rSP★≔maxμs.t.1μ+A‾ZN⊺ψZ⩽c̃N[λN],whereλN⩾0acts as the dual variable vector. In other words, given only the non-degenerate variablesλF>0of costcFand the associated columns inAFfrom which we derive the row-partition, we compute the dual vectorψPand check whether any vectorψZexists such thatμ<0(to generate a column with negative reduced cost to be added to problem RrRMP) or to otherwise prove the optimality ofλFfor RrRMP and hence for MP (see Theorem 1 for this necessary and sufficient optimality condition). The dual of (10) defines the pricing problem rSP in terms ofλN, the current vector of null variables:(11)c¯rSP★≔minc̃N⊺λNs.t.1⊺λN=1[μ]A‾ZNλN=0[ψZ]λN⩾0.We have assumed (1) to be feasible which means that it either has a finite optimal value or is unbounded. In both scenarios, the pricing problem (11) and its dual are always feasible and bounded. Indeed, in a context of column generation, it is always possible to generate a basic variable of reduced cost 0. With respect to the unbounded case, the detection of this eventuality is done during the step size stage according to the ratio-test mechanism as stated in the following section.The reader who is more accustomed to IPS will remember that the basic variables are not available for pricing. That being said, one could modify the convexity constraint with a less-than-or-equal-to sign. The repercussion in (10) is the added upper bound ofμ⩽0. For all intent and purposes, this is equivalent to having an artificial column of null content priced at 0 that could be selected in the pricing problem when the current solution is optimal.An optimal solutionλN★to (11) may contain a single variableλj★=1,j∈N, for whicha¯Zj=0, or more generally, a convex combination of several positive variables such thatA‾ZNλN★=0. In the pricing step, we consider two subproblems: rSP as defined by (11) for the general case and a specialized one denoted cSP and used first to generate an optimal solution comprising a single variable, if any. Subproblem cSP exploits the following property:Definition 1Given the solution vectorλF>0of positive variables, vectora=aPaZis called compatible with row-set P if and only ifa¯Z≔aZ-AZFAPF-1aP=0.Vectorbis compatible sinceb¯Z=0and so are the column-vectors ofAF. When appropriate, we also say that a variable associated with a compatible column is compatible. The artificial basic variables we selected are incompatible. More generally, degenerate basic variables are incompatible. The interest in compatibility comes from the fact that a compatible columnajwith negative reduced costc¯jyields a non-degenerate pivot. Indeed, the step size given by the ratio-test is computed only on the row-setP, that is,ρj=mini∈Pb¯ia¯ij|a¯ij>0. Becauseb¯i>0,∀i∈P, thenρj>0and the objective of MP strictly improves byρjc¯j<0, unlessa¯ij⩽0,∀i∈P, in which case MP is unbounded.On the one hand, if we restrict our attention to only generating compatible columns (which is a natural idea in our context), matters can sometimes simplify considerably as there is no need to knowψZ. Given the dual vectorψP⊺=cF⊺APF-1retrieved from the solution of RrRMP (9), we define a specialized subproblem cSP which is the pricing subproblem SP (8) augmented with a set of linear constraints imposing compatibility with the row-reduced master problem for solution-columna(x), that is,(12)c¯cSP★≔minx∈Xc(x)-cF⊺APF-1aP(x)|aZ(x)-AZFAPF-1aP(x)=0.Adding the set of constraintsaZ(x)-AZFAPF-1aP(x)=0may destroy the structure of the subproblem and makes it more difficult to solve in some cases. Anyhow, if a non-basic compatible columnaj,j∈N, withc¯j=c¯cSP★<0is generated from the solution of (12), one updates the current solution as:(13)λj=ρjλk=0∀k∈N⧹{j}λF=b¯P-ρja¯PjzRrRMP=cFb¯P+ρjc¯cSP★.The number of positive variables in the new solution is at most p, that is, it can be more degenerate.On the other hand, we can solve rSP (11) to look for a convex combination of columns to improve the objective value of MP. Subproblem rSP is a linear program solved by column generation over X. In its pricing step, we look for a column1a¯Z(x)with a reduced costc¯(x)=-μ+c̃(x)-ψZ⊺a¯Z(x)of negative value, wherec̃(x)≔c(x)-ψP⊺aP(x)anda¯Z(x)≔aZ(x)-AZFAPF-1aP(x). GivenψP⊺=cF⊺APF-1obtained from the solution of RrRMP (9) together withμandψZretrieved from the current solution of (11), the pricing subproblem for generating variables as needed for solving rSP is given by(14)c¯★≔-μ+minx∈Xc(x)-cF⊺APF-1aP(x)-ψZ⊺a¯Z(x)=-μ+minx∈Xc(x)-(cF⊺APF-1-ψZ⊺AZFAPF-1)aP(x)-ψZ⊺aZ(x).Apart from the constant term-μ, (14) is the usual subproblem SP (2) with dual vector(πP⊺,πZ⊺)=(cF⊺APF-1-ψZ⊺AZFAPF-1,ψZ⊺).Subproblem rSP (11) combines variables in N such thatA‾ZNλN★=0. Hence, vectorANλN★(of reduced cost valuec¯rSP★) is compatible with row-set P. GivenλN★, the updated values are computed according to RrRMP (9) as(15)λN=ρλN★λF=b¯P-ρA‾PNλN★zRrRMP=cFb¯P+ρc¯rSP★.The number of positive variables is at mostp+(m-p+1)-1=mand the new solution could be less as well as more degenerate.Finally, several compatible columns can be retrieved from the pricing problem cSP and added simultaneously to (9). Moreover, the positive variables ofλN★solution of rSP can be entered one by one in RMP (1), in any order, see Elhallaoui, Metrane, Desaulniers, et al. (2010): the last variable entered ensures a non-degenerate pivot because the convex combinationANλN★is compatible.Consider the following linear master problem MP with inequalities:(16)zMP★≔minc⊺λs.t.Aλ⩾b,λ⩾0.Introducing a vector of surplus variablesδ∈R+m, one obtains MP in standard form:(17)zMP★≔minc⊺λs.t.Aλ-δ=b,λ,δ⩾0.The case with less-than-or-equal-to constraintsAλ⩽bcan be treated in a similar way by considering the transformation-Aλ⩾-b. When the current basic solution to (16) with vector of positive variablesλF>0is such thatAFλF≠b, the basis also contains some vector of surplus variablesδS>0, forS⊂1,…,m. Let|S|=sand denote byZ≔1,…,m⧹(F∪S)the set of remaining rows. The basis can be written in terms ofλF>0, the slack variablesδS>0, and again artificial variables for them-p-sremaining constraints. BasisABand its inverse write asUpon left-multiplication by the inverse, the transformed master problem becomes:(18)zMP★≔mincF⊺λF+cN⊺λNs.t.λF+A‾PNλN-APF-1δP=b¯PδS+A‾SNλN-ASFAPF-1δP=b¯SA‾ZNλN-AZFAPF-1δP-δZ=0λF,δS,λN,δP,δZ⩾0.From (18), we can derive RrRMP, cSP, and rSP. The row-reduced master problem withp+sconstraints is obtained by discarding row-set Z from the formulation while keeping the original data matrices and inequality constraints:(19)zRrRMP★≔mincF⊺λF+cN⊺λNs.t.APFλF+APNλN⩾bP[ψP]ASFλF+ASNλN⩾bS[ψS]λF⩾0,λN⩾0,whereψP⩾0andψS⩾0. Current (known) dual values areψP⊺=cF⊺APF-1andψS⊺=0. Therefore, subproblem cSP for generating compatible variables is given by (12) and it only depends on the column-vectorsAFof the positive variablesλF>0. Subproblem rSP, again written in terms of the current null variable vectorsλN,δP, andδZ, becomes:(20)zrSP★≔minc̃N⊺λN+cF⊺APF-1δPs.t.1⊺λN+1⊺δP+1⊺δZ=1[μ]A‾ZNλN-AZFAPF-1δP-δZ=0[ψZ]λN,δP,δZ⩾0.It is solved by column generation except that theδPandδZvariables need not be generated. Therefore, (14) can be used to price out the valuable columns ofλN. Its solution is a convex combination of the variables inλN,δPandδZsuch thatA‾ZNλN★-AZFAPF-1δP★-δZ★=0.We summarize our discussion with a pseudo-code of our row-reduced column generation algorithm for degenerate master problems. As long as the solution is non-degenerate, we have the classical alternation between RMP and SP (until line 9). When a degenerate solution is identified in line 10 (p<m), the row-reduced RrRMP benefits from this (lines 11 to 19).After solving RMP (line 4) or RrRMP (line 13), the optimality test for MP is via the solution of a pricing subproblem, either the classical SP (line 8) if the current solution is non-degenerate or rSP which is solved by column generation (line 17). In both situations, new columns are added to RMP ifc¯SP★<0orc¯rSP★<0, otherwise MP is optimal.If the current RMP solution is degenerate in line 10, row-index sets P and Z are defined/updated (line 11), and the RrRMP is built and solved (line 13). In that case, priority can be given to the specialized pricing subproblem cSP (line 14) and, ifc¯cSP★<0, compatible columns are added to RrRMP (line 15). Otherwise, the pricing subproblem rSP needs to be solved by column generation (line 17). Ifc¯rSP★<0in line 18, we add subsets of incompatible columns to RMP and iterate (again from line 4). The algorithm stops when RMP and hence MP are optimal (line 19).Algorithm 1Column generation generalizes the primal simplex algorithm. In the same spirit, the improved primal simplex method (IPS) used for solving degenerate linear programs (Elhallaoui, Metrane, Desaulniers, et al., 2010; Raymond et al., 2010) can be seen as a special case of the row-reduced column generation RrCG. The main difference is that rSP (11) itself needs to be solved by column generation, whereas in IPS all columns are explicitly given in advance. Moreover, given basisAB, all variables can be characterized a priori as either compatible or incompatible. Hence, in IPS, the row-reduced master problem is defined on the compatible variables and a complementary pricing subproblem is solved over the incompatible variables only. Although not explicitly stated in previous IPS papers, the following result is a direct consequence of the pricing subproblem structure.Theorem 1A feasible solution(λF>0,λN=0),|F|⩽m, is optimal for the linear program(1)if and only if there exists some dual vectorψZsuch thatc¯rSP★⩾0, rSP being defined by(11).For necessity, recall that MP (1) is equivalent to MP (6). Firstly,λF=APF-1bPandλN=0is primal feasible for MP (6). Secondly,λFbeing basic,c¯F⊺=0, i.e.,ψP⊺=cFAPF-1. If there exists a dual vectorψZsuch thatc¯N⊺=cN⊺-cF⊺APF-1APN-ψZ⊺A‾ZN⩾0, the reduced costs of all variables are non-negative and(cF⊺APF-1,ψZ⊺)is dual feasible for MP (6). Thirdly, sinceλN=0andb¯Z=0, primal objective functioncF⊺λFis equal to the dual objective functionψP⊺bP. Therefore[λF,λN]is optimal.To show sufficiency, let[λF,λN]be an optimal solution and assumec¯rSP★<0. With the row-partition induced by basisAB, vectorANλN★=APNλN★AZNλN★. Because vectorA‾ZNλN★=0in (11),ANλN★is compatible. IfλN★contains a single variableλj★=1,j∈N, thena¯jZ=0, vectorajis compatible, andc¯j=c̃j=c¯rSP★<0. The p-dimensional columnaPj, and the associated variableλjin MP enters the basis of RrRMP, a non-degenerate pivot occurs (unlessa¯Pj⩽0in which case MP is unbounded), and the objective function improves byρjc¯rSP★<0.More generally, ifλN★contains several positive variables, the p-dimensional vectorAPNλN★can enter the basis of RrRMP as a single column. Let(a¯i)i∈P≔A‾PNλN★. BecauseA‾ZNλN★=0, its reduced cost is computed asc¯N⊺λN★=c̃N⊺λN★=c¯rSP★<0. Unless all components of vector(a¯i)i∈Pare non-positive, it strictly improves the objective function value byρc¯rSP★<0when added to RrRMP, whereρ=mini∈Pb¯ia¯i|a¯i>0. This contradicts the optimality of(λF,λN)and completes the proof. □Given the current solution(λF,λN)to RMP, thep×pworking basisAPFis a matrix containing p linearly independent rows ofAF, not uniquely defined ifp<m. MatrixAPFdoes not only characterize the row-partition of the constraints of RrRMP, rSP and cSP, but also, forj∈N, the partial reduced costs coefficientsc̃j=cj-cF⊺APF-1aPj, and column components ofa¯j, that is,a¯Pj=APF-1aPjanda¯Zj=aZj-APF-1aPj. However, we show by a linear algebra argument that, for any set of p linearly independent rows ofAF, the pricing subproblem holds the same information based onAFand thus provides the same solution set. That is, the latter is independent of the row-partition induced by the selected working basisAPF. This comes from the fact that only compatible columns belong to the vector space spanned byAF.Proposition 1Given the solution vectorλF>0of positive variables, vectorais compatible with the row-set P if and only if it belongs to the vector space spanned byAF.Assume vectora=AFy, that is, it can be written as a linear combination of the columns ofAF, or equivalently,APFAZFy=aPaZ. SinceAPFis invertible, one obtainsy=APF-1aPfrom the first set of constraints. Substituting in the second set, we haveAZFAPF-1aP=aZwhich means thatais compatible by Definition 1. To show the converse, letabe compatible with with the row-set P, that is,a¯Z≔aZ-AZFAPF-1aP=0, wherea¯P≔APF-1aP. Hence,aZ=AZFa¯PandaP=APFa¯P, or equivalently,a=AFa¯P. Henceabelongs to the vector space spanned byAF. □This has a nice interpretation in set partitioning models that are common in vehicle routing, crew scheduling, and many other applications. Given an integer solution,AFforms a set of p groups of rows. Hence, compatible columns are those combining these groups (andAPFis the identity matrixIp). For a fractional solution, the p independent rows ofAPFcan be chosen as follows: keep one row from each group of identical rows ofAPF. Again this forms a set of p groups of rows, and the same compatibility interpretation applies. This is what is being used in the dynamic constraints aggregation method (Elhallaoui et al., 2005; Elhallaoui et al., 2008; Elhallaoui, Metrane, Soumis, et al., 2010; Benchimol, Desaulniers, & Desrosiers, 2012). Furthermore, the convex combination of incompatible variables in (11) simply expresses the fundamental exchange mechanism of set partitioning solutions, that is, removing elements from some groups to insert them back in other groups.Another interpretation can be given in the context of the minimum cost flow problem with non-negative flow variables, see Ahuja, Magnanti, and Orlin (1993). Any feasible flow can be represented (in the residual network) as a collection of positive arcs (the non-degenerate arcs forming a forest) and all other arcs at zero (the degenerate ones). The column-vectors of the positive arcs formAF. A degenerate arc is compatible if and only if it can be written in terms of the unique subset of positive arcs forming a cycle with it. Fig. 1represents the residual network in which the flow on the non-degenerate (positive) arcs is free to go in both directions while the degenerate arcs are at zero. Arc (8,9) can be written in terms of the free arcs (9,10), (11,10) and (11,8), hence the corresponding variablex8,9is compatible. An incompatible arc must link two trees of the forest. The combination of several incompatible arcs together with a selection of free arcs can form a cycle. In Fig. 1 are two incompatible arcs. However, combined with free arcs (9,10), (11,10), (5,1) and (1,6), they form a cycle, hence the sumx6,9+x5,11of these two incompatible variables is compatible as well as their convex combination with an equal weight of one-half on each. Now observe the row partition derived from that network flow example. In the small tree composed of free arcs (1,5) and (1,6), two independent flow conservation constraints need to be selected to be part of set P, hence any one amongst nodes 1, 5 or 6 appears in set Z. This is the same mechanism for the larger tree composed of the five arcs (2,11), (2,7), (11,10), (11,8), and (9,10): any one amongst nodes 2, 7, 11, 10, 8 or 9 is selected to be part of set Z while the remaining four flow conservation constraints are in the set of independent rows of P. This leads us to the following two propositions regarding the choice of the working basis.Consider two different working basesAPFandAQF, where Q provides an alternative set of p linearly independent rows ofAF. The reduced costs of the positive basic variables are zero, hence independent of the selected working basis. However, their column coefficients in RrRMP (9) are different since they are given by the column coefficients of the selected working basis. For cSP, Proposition 2 shows that the reduced costs of the compatible variables are indeed identical in the two subproblem versions, namely cSPPand cSPQand their coefficient components are equivalent. Therefore cSP, the specialized pricing subproblem for generating compatible variables, is independent of the selected working basis. The proof is presented in Appendix A.Proposition 2Given two working basesAPFandAQFofAF, the corresponding pricing subproblems cSPPand cSPQare equivalent programs.Although the reduced cost coefficients and column components of incompatible variables in rSP (11) clearly depend on the selected working basis, say eitherAPForAQF, Proposition 3 shows that the solution set of the corresponding pricing subproblems rSPPand rSPQis the same as well as the values of their optimal objective functions. Hence they are equivalent programs. Again the proof is postponed to Appendix A.Proposition 3Given two working basesAPFandAQFofAF, the corresponding pricing subproblems rSPPand rSPQare equivalent programs.Regarding the interpretations in set partitioning models and minimum cost flow problems, we have the following. In the first case, for both integer or fractional solutions, each group is composed of identical rows inAF, hence a single one per group is selected to appear in row-set P. The choice is therefore irrelevant. In the second case, each tree t of the forest containsntnodes andnt-1free arcs. One (root) node per tree has to be removed and its flow conservation constraint appears in row-set Z. The choice of a root node per tree of the forest, currently nodes 1 and 2 in Fig. 1, does not change the composition of any cycle nor its cost or reduced cost.A consequence of the necessary and sufficient optimality condition of Theorem 1 is that the role of RrRMP could be relegated to only updating the current feasible solution, see (15). Indeed, there is no need to keep the generated columns, except those comprised in the current solution. Pricing problem rSP is sufficient to prove optimality of the solution or to provide a convex combination of columns for a strict improvement of the objective function. However in practice, several subsets of columns are selected at every iteration, either from cSP or from rSP, and sent to RrRMP or to RMP for an improvement of the current solution, by solving a linear program. This is possible because the compatibility notion is somewhat flexible. For example, one can include or not in the set of degenerate variables a variable that is at an implicit upper bound. In set partitioning models, this is the case for variables at value one.Definition 2Given the solution vectorλF>0of non-degenerate variables, vectorais compatible with row-setQ⊆Pif and only ifa¯Z=0forZ≔1,…,m⧹Q.This row-compatibility induces a two-step pivot procedure to enforce a strict improvement of the current solution. Firstly, a selected row-setQ⊆Pfor RrRMP (still of row-sizep⩽m) constrains the set of possible exiting variables from the current basis, the ratio-test being computed only for those|Q|≔q⩽pconstraints. Secondly, a specialized pricing subproblem cSP selects an entering variableλj,j∈N, such thatc¯j<0anda¯Zj=0, this zero vector being defined onZ≔1,…,m⧹Qaccording to the row-compatibility in use. This supports various implementation strategies. For example, one could temporarily restrain the search for entering variables to those for which Q is a strict subset of P and, for alli∈Q,b¯iare relatively large. This can be considered as a partial pricing strategy and should accelerate the solution of RrRMP since only significant step sizes are expected.Alternatively, when the entering variable is compatible with the solutionλF, the pivot is non-degenerate but the new basic solution may become degenerate, sayλQ>0,λN⧹Q=0, withQ⊆P. Then one can update or not the current row-partition of RrRMP, namely RrRMPP. If it is updated, it becomes RrRMPQwith only q rows andZ≔1,…,m⧹Q. If not, it should be pointed out that this also results in an exact algorithm as it still solves the transformed MP formulation in (6). In that case, the current compatibility rule with row-set P is simply maintained. No overhead computations are needed for an update of RrRMPPand the entering variables are still selected such thata¯Zj=0, whereZ≔1,…,m⧹Pis a strictly smaller set of rows than what would be required in an updated pricing subproblem. In that case, degenerate pivots may occur because of the degeneracy of some RrRMPPsolutions.Classical column generation works with a restricted master problem (RMP), that is, a subset of a model’s variables that are dynamically added via a pricing subproblem SP. Like the simplex method, column generation is known to suffer from degeneracy. Inspired by recent successes in coping with degeneracy in the primal simplex method, we propose a row-reduced column generation method (RrCG). RrCG exploits degeneracy as the restricted master problem only has as many rows as there are positive basic variables.Columns/variables are characterized as compatible or incompatible with respect to RrRMP. Compatible columns allow for a strict decrease of the objective function when entered into the basis, that is, a non-degenerate pivot. Two types of subproblems are proposed to generate variables: a specialized subproblem cSP for compatible variables, and rSP to price out any type of variables. The latter also needs to be solved by column generation. Pricing subproblem cSP is the original subproblem SP augmented with a set of linear constraints imposing compatibility requirements. It selects compatible columns as long as they are useful for non-degenerate pivots in RrRMP. When the reduced costs of all compatible columns are zero (or larger than a specified threshold), the pricing subproblem rSP is solved. It selects a convex combination of columns such that, again, the objective value strictly improves when they all enter into the current basis. In both cases, the row-size of RrRMP can be dynamically modified. The structure of the pricing problem rSP allows to derive a necessary and sufficient optimality condition for linear programs.Decomposition in column generation for integer programs is based on the modeling structure of a compact formulation. It exploits the pricing subproblem for the selection of objectsx∈X. Row-partition in RrCG takes advantage of degenerate solutions, reduces the row-size of the master problem and its associated working basis, and thus, the computational effort for re-optimization. Combining column generation and dynamic row-partition during the solution process allows for exploiting both the modeling structure of its formulation and the algebraic structure of its solutions. Two special cases of RrCG are the improved primal simplex method and the dynamic constraints aggregation method for solving by column generation LP relaxations of set partitioning problems. On highly degenerate instances, recent computational experiments with these algorithms have shown a substantial impact on the solution time. This already opened the door to further research within that field, notably an integral simplex algorithm for the set partitioning problem (Zaghrouti, Soumis, & Elhallaoui, 2011) and a specialized version for the capacitated network flow problem which turns out to be strongly polynomial (Desrosiers, Jacques, Gauthier, Jean Bertrand, & Lübbecke, 2013).Of course, only experimentation can show whether the potential speedup when re-optimizing the master problem is not overcompensated by a slowed down solution of the pricing step. Specialized subproblem cSP may be more difficult to solve than rSP or the original SP, in particular when the latter is solved by a customized algorithm. The additional constraints enforcing compatibility in cSP may modify or even destroy the subproblem structure. On the positive side, the subproblems do not automatically inherit degeneracy from the master problem, since at least part of the overrepresentation of the current basic solution is removed from the pricing subproblem as well.We expect that the new method is most helpful in cases where re-optimization of the master problem is very difficult, as it is the case for many large-scale vehicle routing and crew scheduling problems. As for any simplex or column generation algorithm, future work is needed on RrCG, mainly on implementation strategies. Amongst these are the moment for an update of the row-partition of RrRMP, efficient solvers for cSP and rSP, which pricing subproblem to call, whether to add many incompatible columns or their (single column) convex combination as returned from rSP, and much more on relaxed compatibility.

@&#CONCLUSIONS@&#
