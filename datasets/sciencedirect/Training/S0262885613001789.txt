@&#MAIN-TITLE@&#
Unsupervised multiphase color–texture image segmentation based on variational formulation and multilayer graph

@&#HIGHLIGHTS@&#
A new color texture feature is constructed.Multiphase successive active contour model (MSACM) is proposed.MSACM can be discretely optimized by multilayer graph.The combined energy of local and global is iteratively optimized.Performances are assessed through the qualitative and quantitative comparisons.

@&#KEYPHRASES@&#
Variational formulation,Multiphase successive active contour model (MSACM),Unsupervised color–texture image segmentation,Multilayer graph,

@&#ABSTRACT@&#
This paper proposes an unsupervised variational segmentation approach of color–texture images. To improve the description ability, the compact multi-scale structure tensor, total variation flow, and color information are integrated to extract color–texture information. Since heterogeneous image object and nonlinear variation exist in color–texture image, it is not appropriate to use one single/multiple constant in the Chan and Vese (CV) model to describe each phase [1,2]. Therefore, a multiphase successive active contour model (MSACM) based on the multivariable Gaussian distribution is presented to describe each phase. As geodesic active contour (GAC) has a stronger ability in capturing boundary. To inherit the advantages of edge-based model and region-based model, we incorporate the GAC into the MSACM to enhance the detection ability for concave edge. Although multiphase optimization of our proposed MSACM is a NP hard problem, we can discretely and approximately solve it by a multilayer graph method. In addition, to segment the color–texture image automatically, an adaptive iteration convergence criterion is designed by incorporating the local Kullback–Leibler distance and global phase label, so that we can control the segmentation process converges. Comparing to state-of-the-art unsupervised segmentation methods on a substantial of color texture images, our approach achieves a significantly better performance on capture ability of homogeneous region/smooth boundary and accuracy.

@&#INTRODUCTION@&#
Image segmentation based on variational method recently attracted a widespread concern, and it has been extensively used in the computer vision field including visual tracking, object detection, scene understanding, industrial testing, content-based image retrieval, medical image analysis [3,4], etc. The main reason for that is that the variational method can provide some smooth and enclosed contours, and meanwhile it can easily integrate with prior knowledge. As we know, a natural image usually contained a wealth of color–texture information, if we only use color information or texture information to implement segmentation, though some specific segmentation tasks can be achieved, usually, we are confronted with difficulty in capturing satisfactory segmentation results. As a result, incorporating the color information and texture information into the segmentation process may be more effective. With regard to multiphase segmentation, some methods [1,8] have been presented to tackle with color image. Although they were accurate, and have achieved some impressive segmentation results, however, they are all confronted with user interaction by using many initial curves enclosed with interested objects or sub-objects. Additionally, the initialization process of these mentioned methods is tedious and time consuming. Consequently, a fully automatic partitioning method should be designed to segment the color–texture image into some significant regions, distinct scenes, or desired object boundaries, thus it is still an opening problem, yet not solved effectively.Generally, a variational method can be categorized as edge-based model [9–12] and region-based model [5,6,13]. The edge-based model uses local gradient information to attract the active contour toward the object boundaries. A well-known and successful active contour/snake model was initially proposed by Kass, Witkin and Terzopoulos [10]. Then, Cohen and Kimmel [9] presented an interactive edge-based segmentation approach by putting a single point close to the boundary of the target, and then the corresponding energy minimization was converted into a cost accumulation problem, consequently, a global minimal path will be produced between two end points. Appleton and Talbot [14] developed an interactive segmentation process by adopting minimal paths to find an optimal geodesic after user initialized a single point inside the interested object, and then induce a cut. Caselles et al. [12] proposed a geodesic active contour (GAC) model by defining an energy function along a curve C and minimizing the evolving curve in the normal direction. Li et al. [15] designed a new variational formulation for geometric active contours to force the level set function close to a signed distance function, and then the costly re-initialization procedure is eliminated completely. Although these mentioned edge-based approaches have achieved some impressive segmentation results, there exist some problems about the segmentation which are greatly dependent on the initial curves and points, and the corresponded global optimization is easily sank into local minimization. Besides, the initialized location placed in different parts of the image will capture the different objects or targets. More importantly, it has been proven that its final segmentation results are very sensitive to image noise, as well.Region-based method posses many advantages when compared with the edge-based method, such as robustness against initial placement of curve, and insensitivity to image noise. A well-known example of the region-based method is the Mumford–Shah model [5]. As it is known, its smoothness term is hard to minimize as gradients introduce, thus, a simplified version of the MS model has been studied by Chan and Vese [16], then, an image can be described with a piecewise constant function, and it can be minimized with level set simultaneously. Herein, the constants can be calculated through the average value of the interior region and exterior region of curve C respectively, and then the curve is attracted to evolve toward the ground truth boundary. More recently, active contour methods have focused on the region-based flow that is inspired by the region competition idea of Zhu and Yuille [17]. This approach models the interior region and exterior region statistically, and meanwhile it assumes that these regions are constant intensities, and homogeneous. However, this strategy is using global constant statistics for region modeling that is usually not ideal when segmenting heterogeneous objects. Moreover, if the provided image contains some complex and inhomogeneous objects, finally, the segmented results will be degenerated seriously. Lankton and Tannenbaum [18] proposed an approach to overcome the intensity inhomogeneity by adopting a localized energy function that is based on the CV model [16]. Although the localization information can be used to improve the segmentation performance; nevertheless, the sensitivity of the initialized placement of curve will be increased greatly due to losing some global characteristics. Additionally, the scale size is also hard to choose for distinct objects adaptively. More importantly, the segmentation task of multiple objects cannot be effectively achieved by employing these local methods, unless multiple initialized curves are placed around the interested objects, simultaneously. Vese and Chan [8] proposed a new multiphase level set [19] approach to fulfill the multi-class segmentation task as multiple objects appeared. The proposed method is a generalize case of the CV model. It can overcome the problem such as vacuum and overlap automatically. Nonetheless, the number of multiphase must be configured as even, and meanwhile it is hard to capture the concave edge precisely because it is very sensitive to noise and shadows.Majority of the segmentation algorithms mentioned above used either edge-based model or region-based model. Here, we should note that edge-based model owns better capture ability on boundary; however, it is sensitive to initial placement. While region-based segmentation algorithm has robustness contrast with the initial curve and is less susceptible to local minima, but it neglects the spatial constrain. As a result, a variety of methods have been proposed to integrate them together [1,2,7,20]. Paragios and Deriche [21] developed an early unifying model (integrate the edge-based model and region-based model), however, this method is time consuming, and hard to deal with heterogeneous objects. Tao [1] presented a multiple piecewise constant (MPC) active contour model, and it is extended to deal with multiphase case (MMPC). Although this proposed multiphase model can be optimized efficiently by computing minimum cuts, the corresponding segmentation process needs to label the interested objects with scribbles in advance. Liu [7] presented an iteratively unsupervised image segmentation algorithm which is based on multiphase multiple piecewise constant model and graph cuts optimization. This method adopts the four-color theorem to re-label the segmented regions in subsequent iteration, so that the segmentation results can represent an arbitrary phase number in just four colors. However, these mentioned methods do not consider the texture information during the multiphase segmentation process.For the above reasons, a lot of color–texture segmentation approaches [22–24,27,28] have been developed in the last decade. For instance, Brox et al. [29] integrated the color, texture, and movement information into the framework of level set, and evolved the contours of objects through minimizing a specific designed energy function. Although this method can divide an image into two phases or multiphase, however, the accuracy that is acquired greatly depends on user interaction. Moreover, the segmentation process needs user interaction many times toward interested objects or sub-objects; actually, this is unrealistic to achieve the segmentation task for image sequence. Nevertheless, Deng and Manjunath put forward an unsupervised segmentation method for color–texture images and video (JSEG) [23], which has been considered as a benchmark in the field of computer vision. In [23], the segmentation process of JSEG is divided into two stages. For one thing, the color will be quantified into 10 to 20 prototypes, and then each pixel obtains a prototype label. For the other thing, it calculates the local homogeneity in a quantitative J-image, and then uses the multi-scale region growing method for clustering. The authors of this paper argue that extracting color information and texture information in succession is beneficial, but it is hard to analyze the color similarity and spatial relationship between the neighboring pixels simultaneously. Yang et al. [28] proposed a color–texture image segmentation approach named compression-based texture merging (CTM). It extracts texture information from each channel in Lab color space with a constant sized window, and then reduces the dimension of texture to eight using principal component analysis (PCA). After that, it uses the degenerated Gaussian mixture distribution to describe the probability density function (PDF). Nevertheless, its segmentation performance greatly depends on the choice of difference texture threshold during the clustering. A small threshold will lead to some scattered regions which without any visual entirety or consistency, vice versa; the long and narrow interested regions will be lost. Abeles et al. [24] presented a contour detection and hierarchical image segmentation approach; it can provide some detailed results in different scales, and acquire a significant accuracy [25], but the texture information was extracted involving in high dimension and information redundancy. Li et al. [26] designed a bipartite graph partitioning approach (SAS). Although it used super pixels to provide powerful grouping cues for guiding segmentation, and achieved the best performance on the Berkeley Segmentation Database compared to state-of-the-art techniques, the initialized number of multiphase (class) has to be manually set (semi-supervised method) in advance. Additionally, Chen et al. [27] used the maximum a posteriori and maximum likelihood (MAP–ML) estimation method to achieve the color–texture segmentation task. It regarded image segmentation as a labeling problem in the framework of probability maximization. Meanwhile, it extracted the texture using contrast information. Although this approach can unsupervisedly segment color–texture images in multiphase, the valid number of multiphase still needs to be set manually. Moreover, the simplified texture information will lead to some problems, such as rich color–texture objects cannot be divided out. What causes these different segmentation results? The reason for that is that the methods mentioned above do not possess the description ability for main texture information in multi-scale. Furthermore, they do not own the boundary detection ability to keep the spatial change successively.To alleviate these problems, we propose an unsupervised color–texture image segmentation approach by integrating edge-based model and region-based model into energy functional together, so that we can greatly improve the effectiveness of color–texture image segmentation. Due to the complexity, randomness and heterogeneity of color–texture image, the compact multi-scale structure tensor, total variation flow and color information are extracted, and then combined to enhance the description ability for color–texture. In addition, as heterogeneous objects and nonlinear variation existed in color–texture image, using one single/multiple constant to describe each phase is not appropriate, therefore, a multiphase successive active contour model (MSACM) incorporated with GAC is presented by adopting the multivariable Gaussian distribution to describe each phase. For the proposed MSACM, it can not only describe the nonlinear variation of color–texture image, but also capture the concave boundaries more precisely and robustly. Especially, to achieve the unsupervised segmentation, the valid multiphase number of our proposed MSACM can be acquired through the component-wise expectation-maximization for mixtures (CEM2) [30] algorithm. Since the minimization of our proposed MSACM is a NP hard problem, we cannot directly use the multiphase level set method for getting an optimal solution. As a result, based on cut metric in graph theory [31], a discrete representation of the MSACM is presented. Meanwhile, the proposed variational model can be approximately optimized using multilayer graph [1,7,32–34]. However, one round of segmentation process is not stable, thus, an iteratively unsupervised convergence criterion is developed by adopting a local Kullback–Leibler (KL) [35] distance among multiphase regions, and then combined with global phase label, so that we can acquire a better segmentation result, unsupervisedly.The outline of this paper is organized as follows. In Section 2, the compact MSST texture, TV flow and RGB color information are extracted to represent the color–texture feature. In Section 3 we introduce a multiphase successive active contour model (MSACM). And then the energy functional of MSACM can be discretely represented and approximately minimized adopting multilayer graph in Section 4. In Section 5 we put forward a new adaptive iteration convergence criterion to control the segmentation process automatically. We validate our model by extensive experiments on a large number of color–texture images in Section 6, and going after by a brief conclusion in Section 7.With regard to color–texture image, the color-alone or texture-alone [36] information is not sufficiently robust to describe the image content in many practical scenes. The reason for that is that color–texture image exhibits significant inhomogeneities in color and texture, and contained contents are often characterized with a high degree of complexity, randomness and irregularity. To understand these impacts deeply, a natural image which contains rich texture information is used for illustration. As we know, the color-alone information can provide visual sensitive information, however, if we only use color information for color–texture description, it may produce some discrete and small regions which without any visual semantics. Comparatively, if we adopt the traditional Gabor wavelet [36,37] to extract texture information, although the extracted feature has a powerful multi-scale analytical ability, it is hard to choose a suitable scale number and direction number. Therefore, the segmentation performance is heavily dependent on the choice of Gabor filters, furthermore, the overlarge scale number and direction number that are selected will lead to the extracted texture feature owing overly-high dimension and excessive information redundancy. In contrast, [38] proposes an interactive color–texture image segmentation method which combines the L*a*b* color and the multi-scale nonlinear structure tensor (MSNST) texture. Here, the MSNST can effectively avoid the choice of direction number, and meanwhile it can compact the whole orientation information contrasted with the Gabor wavelet. Nevertheless, the whole segmentation process of [38] treats the color and texture separately, which ignores the intrinsic relationship and holistic nature between color and texture. More importantly, the mentioned MSNST texture descriptor can discriminate regular and concentrated texture regions effectively, but, it does not work well in an area with large-scale texture. To compensate this, the total variation (TV) flow [39] can be auxiliarily used to extract local scale information. Consequently, a combination formation of color, texture, and local scale is raised. In the following section, we will illustrate the detailed extraction process about a color–texture descriptor.Given MSST (MSNST [38] without nonlinear filtering), it can extract the multi-scale texture information effectively and avoid the choosing of direction number completely, and meanwhile it owns the ability to compact the whole orientation information. Thus, for an image I, we can calculate the MSST by using the non-orthogonal discrete wavelet [40]. Let Γsas the sth scale tensor of MSST, which can be formulated using the tensor product of gradient as:(1)Γs=∑n=1N∇I∗θsn∇I∗θsnT=σ−2s∑n=1NDn,sx2∑n=1NDn,sxDn,sy∑n=1NDn,syDn,sx∑n=1NDn,sy2,s=0,1,⋯,S−1where I∗θsrepresents the convolution operation for image I with convolution operator θsin sth scale, and ∇ is used to calculate gradient. S is the total number of scales in multi-scale, which determines the richness of extracted texture. As far as we know, the main texture information is mostly concentrated in the first three scales, therefore, we can set S as 3 in all our experiments. σ is the basis of wavelet, which can be set as 2 to decrease the storage cost and computation. Besides, the notations of Dxand Dydenote the partial derivative in x and y directions respectively. Subscript n is the nth channel of original image I, and superscript N represents the total channels.Due to the fact that the color (vector) and MSST texture (matrix) have different feature structures; we cannot integrate them directly. To overcome this problem, firstly, we use the SVD [41] in tensor space for matrix decomposition, then, each scale of MSST can be rewritten as:(2)Γs=Vs1Vs2Tλs100λs2Vs1Vs2where Vs1 and Vs2 are the calculated eigenvectors after using the SVD in tensor space, and λs1 and λs2 are the corresponded eigenvalues accordingly, they meet with the constraint condition as λs1≥λs2. Herein, Vs1 and λs1 are the maximal change of direction and amplitude of Γsrespectively, thus, we can obtain the main texture information Λsas follows:(3)Λs=ηλs1Vs1where η is an enhancement factor, which can properly enhance the description ability of texture in each scale, and meanwhile it can reasonably widen the texture differences among different scales. Consequently, the multi-scale texture information can be represented through connecting the main texture Λs, then, we can acquire a 2S-dimensional row vector asΞ=Λ0T⋯ΛS−1T.In terms of the difference of various color–texture images, the main multi-scale texture information may be focused on a few scales or some certain scale. Therefore, we can compact the extracted Ξ by using the PCA algorithm [41], it can not only reduce the information redundancy, but also reduce the calculation burden and memory consumption. Under the requirement of saving the major information of Ξ in each pixel, we can compute the compacted multi-scale texture information γ as follows:ℑui=riuiArgMinH∑m=1Hrm∑n=12Srn−ξ≥0ϒ=Ξ·u1⋯uHwhere ℑ is a covariance matrix, and it is calculated with all the multi-scale texture information Ξ. riand ui(a column vector) are the corresponded eigenvalue and eigenvector of ℑ, respectively, by using feature decomposition. ξ is an information compacted factor, set as 95% usually. γ is an acquired compacted multi-scale texture information in final, with H dimensions.For TV flow [39], it can be used to auxiliarily enhance the description ability of γ in an area with large-scale texture through extracting the local scale information. To extract the local scale, [39] terminates the iterative calculation process of TV flow by manual means, which may greatly impact the flexibility and availability. Consequently, a new iteration convergence criterion is designed to extract the local scale information, more suitably and adaptively. Then, the iteration convergence can be controlled through the change detection of TV value as follows:(4)∂tun=div∇un∇unTMax=argMintlog∑n=1N∂t−1un−∂t−2un∑n=1N∂tun−∂t−1un+ϑ≥0where ∂tundenotes the TV flow change of the nth image channel in the tth iteration, and the initialized condition meets with ∂(t=0)un=un. Meanwhile, ϑ is a proportionality factor which controls the value change of TV flow until stabilization, and TMaxis the corresponded maximum iteration number.Then, the local scale information can be calculated using the accumulative change of TV flow [39] as follows:(5)γ¯=4τ∫0TMax∑n=1Nϕ∂tun0dt−1⋅∫0TMax∑n=1N∂tundtwhere τ is a step size of diffusion of TV flow, and it can be set as 2 to ensure the extracted local scale stability. Besides, φ(x,0) is a decision function, which is true if x>0, otherwise, φ(x,0)=0. To formulate the color–texture feature reasonably, the extracted local scale should be further scaled to the specified range as [0, 255], this makes sure that the finally extracted local scale information has the same range as RGB color.From our knowledge, the visual completeness and accuracy of the segmentation result are greatly dependent on the feature expression. Therefore, a reliable and efficient color–texture feature ΓSC can be constructed through integrating the compact MSST vector Υ, local scaleγ¯, and RGB color together (it is well known that all colors are perceived by humans as combinations of three primary colors red (R), green (G), and blue (B). The RGB is considered to meet with the spectral primary system, and meanwhile almost all color image acquisition devices can easily output the vector valued images in RGB space, as a consequence, we use the RGB to describe the color) asΓSC=ϒγ¯RGBT. Furthermore, the extracted feature ΓSC contains a substantial of noise. In order to smooth the noise and enhance the region boundary simultaneously, we apply the nonlinear diffusion filtering to strengthen the description ability of ΓSC as:(6)∂tΓSCj=divR∑g=1H+4∇ΓSCg2∇ΓSCjwhere R(•) is a coefficient function of diffusion filtering, and it has the representation as R(|∇u|)=1/(|∇u|ρ+ε). The small positive constant ε is introduced to avoid division by zero, and constant ρ is usually used to balance the edge enhancement and denoising. Additionally, the additive operator splitting (AOS) scheme [42] is also adopted to accelerate the corresponded implementation, effectively. Then, a much more powerful color–texture feature is acquired as ΓSC⁎.For the typical variational methods, such as Mumford and Shah (MS) [5] model, and Chan and Vese (CV) [6] model, due to the fact that these two models can provide some smooth and enclosed contours, they have been extensively applied in the image segmentation field. Taking the MS model for example, its target is to search an approximated minimal solution with smoothness piecewise and minimum edge length, and meanwhile it can achieve the denoising. However, there is a large gap between the fine theoretical application and its practical application, since the corresponding MS energy function is hard to optimize actually. Consequently, a simplified formation of the MS model was proposed, namely, the CV model [6]. It can describe the image with piecewise constant functions instead of piecewise smooth functions.Given a color–texture image u0, Ω→R corresponds to the image u0domain. Here, Ω is consisted by a finite unconnected region components Ωjand an enclosed smooth curves subset C, then, Ω can be represented asΩ=∪j=1NΩΩj∪C. Where N(Ω) denotes the total number of sub-regions, and any two regions meet withΩi∩Ωji≠j=ϕ. For the CV model [6], the corresponded energy function can be represented as:(7)FCVc1c2C=α∬Ω1u0−c1x2+β∬Ω2u0−c2x2+ν∫0LCsdswhere the total region number N(Ω)=2, α and β denote the tuning weights between interior region Ω1 and exterior region Ω2 respectively, and ν is a constraint coefficient of the boundary length L(C). Usually, these parameters are fixed as constants in advance. Constants c1 and c2 are the calculated mean intensity of regions Ω1 and Ω2 accordingly. Here, the CV model becomes two phases, however, it can extend to multiphase, such as the Multiple Piecewise Constant (MPC) [2] model and Multiphase Multiple Piecewise Constant (MMPC) [1,7] model. These techniques also assume that multiple regions can be described with multiple piecewise constant functions. However, they cannot provide a precise description about PDF (Probability Density Function), because there exist a nonlinear variation of each region Ωj. In addition, these proposed models will reduce the correlation and continuity between regions. As a result, we cannot accurately describe the complexity and randomness of color–texture image by adopting the constant functions due to the most features that meet with the Gaussian distribution. Consequently, the multivariable Gaussian distribution is applied to describe the phase intensity; it may be more suitable instead of constant intensity cj. Then, we proposed a multiphase successive active contour model (MSACM) which can be described as follows.(8)FMSACMΘ1Θ2⋯ΘKPhaseC=∑k=1KPhaseαk∫Ωk−log12πH+4Σk12exp−12u0x−ukTΣk−1u0x−ukdx+ν∫0LCsdswhere KPhasedenotes the total number of phases, and each phase can be statistically described with a multivariable Gaussian Θk={αk,uk,Σk}. These statistical parameters αk, ukand Σkare corresponded to the regional weight, mean, and covariance matrix of the kth phase respectively. Usually, it is not easy to set some suitable initialized values for statistical parametersΘk1≤k≤ΘKPhaseand valid number of multiphase KPhasein advance. Therefore, the common strategy is to build up the image description in the Gaussian mixture model (GMM) with a large initialized value KPhase[27]. But, the initialized value KPhasethat will cause the segmentation process is not accurate and flexible. To address this problem, the CEM2 algorithm [30,59] is adopted for getting the valid phase number. And meanwhile, the CEM2 algorithm can improve the convergence speed by updating the statistical parameters sequentially rather than on the large completed data space simultaneously. If one phase was removed, its probability mass will be redistributed to the other phases immediately. Therefore, the CEM2 algorithm can be extended to select the valid multiphase number KPhaseadaptively, and meanwhile it can achieve the initialization process of our proposed MSACM.In formula (8), the boundary curve is constrained with length ∫0L(C(s))ds, which lacks the gradient information for boundary detection. Therefore, when shadow and noise are close to the contour, this caused the captured boundaries which appeared in the phenomenon as skewing and sharp edged. To acquire a good capture capability and local characteristic for boundary, the geodesic active contour (GAC) model is incorporated into our proposed MSACM in formula (8). Then, the cost function can be rewritten as:(9)FMSACMΘ1Θ2⋯ΘKPhaseC=∑k=1KPhaseαk∫Ωk−log12πH+4Σk12exp−12u0x−ukTΣk−1u0x−ukdx+ν∫0LCsgCsdswhere g(u0)=exp(−ϖ|∇u0|) is a boundary indicator function. The second term of formula (9) is a geodesic active contour instead of the length ∫0L(C(s))ds with an integral function g (along with curve C). As a result, we can detect the boundary more accurately. Except that, the proposed MSACM is incorporated with edge-based model and region-based model, thus, it can further improve the completeness of color–texture segmentation.With respect to the statistical parametersΘ1Θ2⋯ΘKPhasein formula (9), the multiphase level set has been proposed in [8], and it can be used to minimize the energy function of our proposed MSACM. To minimize the energy function in formula (9), firstly, we consider M=⌈log(KPhase)⌉ level set functions as ϕk(1≤k≤M):Ω→R. And then the collected ϕkzero-level sets can be used to represent the segmented boundaries. To express expediently, the vector formation of level set function can be denoted as Φ={ϕ1,ϕ2, ⋯,ϕM}, and its corresponded Heaviside function is H(Φ)={H(ϕ1), H(ϕ2), ⋯, H(ϕM)}. Here, we should specially mention that each component of H(Φ) is either one or zero. Therefore, the corresponded multiphase level set of the energy function in formula (9) can be expressed as follows:(10)FMSACMΘ1Θ2⋯ΘKPhaseC=∑k=1KPhaseαk∫Ω−log12πH+4Σk12exp−12u0x−ukTΣk−1u0x−uk⋅Πl=1MHϕlfk1−Hϕl1−fkdx+ν∑l=1M∫Ω∇HϕlgCxdxwhere fkdenotes the distance sign of sample x to level set function ϕk, if ϕk>0, fkwill be set as one, otherwise, as zero. Then, the gradient decent equation can be acquired by minimizing formula (10) in the Euler–Lagrange equations as(11)∂ϕl∂t=δϕlνdivgCx⋅∇ϕl∇ϕl−∑k=1Kphaseαk∫Ω−log12πH+4Σk12exp−12u0x−ukTΣk−1u0x−uk⋅fkHϕlfk−11−Hϕlfk−1−1−fkHϕlfk1−Hϕi−fk⋅Πi=1i≠lnHϕifk1−Hϕi1−fkdx.Usually, the gradient decent equation of formula (11) can be used to solve the minimization of formula (10) using an explicit finite difference scheme. Nevertheless, this technique involves the contour evolution only in a local sense, thus, it is easily draped in local minimization. Furthermore, its computing burden is costly. Consequently, to alleviate these problems, we will discrete formula (9) with a multilayer graph for getting an approximate optimal solution in the following section (Actually, here, we provide a uniform expression. If we ignore the computing burden and local minimization, formula (11) can also be used for getting an approximate optimization).Note that the integral formation of MSACM is complex. Thus, we need to discrete it firstly, then, the discrete optimization can be solved in a multilayer graph.Let color–texture image u0as a 2D grid graph R, R={(i,j)|i∈{1,2, ⋯,W}, j∈{1,2, ⋯ H}}, where W is width, and H is height. For convenient expression, we can induce an auxiliary function φ(x) asφx=01,,ifx≠0else.Then, a label function {ψ(m)|ψ(m)∈{1,2, ⋯,KPhase}, m=(i,j)∈R} is defined in the grid graph R. And then, we can discrete the first term of energy functional (9) with the representation as(12)E1=−∑k=1Kphaseαk∑m∈Rφψm−klog12πH+4Σk12exp−12u0m−ukTΣk−1u0m−uk.To simplify the expression of formula (12), we setpk,m=12πH+4Σk12exp−12u0m−ukTΣk−1u0m−uk,where pk,mdescribes the similarity degree of color–texture feature u0(m)=ΓSC∗(m) that belongs to the kth phase. However, to further improve the discrimination capability, we can replace pk,min formula (12) using −log(pk,m), then,(13)E1=−∑k=1Kphaseαk∑m∈Rφψm−klogpk,m.Based on the cut metric theory in [43], the length of the curve C[44,45] can be written as ∫CnSds=2|C|E, where nSis the number of times the line S intersects the contour C, and |C|Eis the corresponded Euclidean length. To discrete the energy functional in formula (9), the Euclidean length of curve C is approximately calculated by using Q (where Q=4, 8, 16) neighborhood system as Fig. 1presented. Here, we should notice that all the sets of straight lines can be expressed as {(ρ,θ)|xcos(θ)+ysin(θ)=ρ} in polar coordinate plane, and then the length of curve C can be calculated in Cauchy–Crofton formula as follows:(14)CE=12∫−∞+∞∫0πncρθdρdθwhere nc(ρ,θ) denotes the interaction times between the curve C and the line xcos(θ)+ysin(θ)=ρ. Notice that these lines that intersect with curve C can be categorized into a certain number of types. To calculate the length of curve C, we set Q neighborhood system to a special designed grid graph G. Then, the neighborhood system can be expressed as a set NG={ek|1≤k≤nG}, where ekis a direction vector, and nGis the corresponded direction number in Q neighborhood system (Q=2nG). Let Δθkas an angular difference between each pair of the nearest direction vector, and it can be represented asΔθk=πnG. Then, the discrete representation of formula (14) can be further formulated as:(15)CE=∑k=1nGnckδ2Δθk2ekwhere δ is the step size of grid graph G, and∑k=1nGnckis the total number of intersection times between curve C and all the families of edge lines. To calculate the edge weight for each family of lines, we can formulate it withωk=δ2Δθk2ek. Then, for an enclosed contour C,CE=∑k=1nGnckωkwill denote a cut cost on the grid graph G.Given a 2D flow network G[46], an optimization of graph cut on G is used to divide out the set of vertices V into two disjoint sets as S (source) and T (sink), and then the corresponded cost of the cut (S,T) of curve C can be defined asCG=∑m∈S,n∈Tmn∩C≠∅wm,nwhere (m,n) represents a divided edge, and its cost weight corresponds to wm,n. As the cut metric of |C|Gis equivalent to the discrete approximation of the curve length |C|Ein formula (15), therefore, we haveCE≈CG.Based on the cut metric theory [43], the discrete formation of the curve length |C|Ein formula (15) can be represented asCE=∑m∈R∑n∈NQm1−φψm−ψnwm,nwhere NQ(m) denotes the neighbor system of node m, and Q is the neighbor size. In this lecture, Q is set as 8, and wm,nis a weight which depends on the direction of edge (m,n) and neighbor system NQ. By incorporating the length of the curve C and the geodesic active contour g(u0)=exp(−ϖ|∇u0|), the discrete representation of the second term in formula (9) can be expressed as(16)E2=∑m∈M∑n∈NQmwm,n1−φψm−ψnexp−ϖΓSC∗m−ΓSC∗n2where the parameter ϖ can be calculated adaptively asϖ=2Z∑mn∈ZDisΓSC∗m,ΓSC∗n2−1. Z is a set of pairs of neighboring grid points in graph R, and |Z| denotes the total pair number of the set Z. dis(•) represents the dissimilarity between color–texture features in Euclidean space. Therefore, the complete discrete representation of MSACM can be denoted as follows(17)FMSACM=∑m∈Mαk∑k=1Kphaseφψm−k⋅−logpk,m+∑m∈M∑n∈NQmνwm,n⋅1−φψm−ψn⋅exp−ϖΓSC∗m−ΓSC∗n2+τwhere τ is a denoising constant that we newly added, and it is used to enhance the robustness of our proposed MSACM. Furthermore, one may ask for an error analysis about the discrete representation. Actually, we can formulate the approximation gap between the continuous solution and discrete solution ranged in [0, πν|L|].As far as we know, formula (17) corresponds to a multi-label Potts model [47] whose minimization is hard to tackle with actually, namely, it is a NP-hard problem. To address this problem, Boykov [48] proposed the α–β swap method and α-expansion method to minimize the multiphase energy function, and these techniques can acquire an approximate minimization solution quickly. Then, Ishikawa [33] devised a multilayer graph which can exactly optimize the multi-label MRF energy function with convex priors in terms of a linear-ordered label set. Bae [34] proposed a piecewise constant level set method (PCLSM) which has been applied in the multiphase Mumford–Shah model for image segmentation. Tao [1] presented a multiphase model which can be optimized effectively by solving the corresponding minimal cut with a specially devised multilayer graph. Based on the proposed energy function in [1] and its corresponded graph cuts optimization, an interactive multiphase method was presented. Due to the fact that the second term of the proposed MSACM is a multi-label Potts model [44] in formula (17), the methods of multilayer graph in [33,34] cannot provide an exact minimization. But, as an approximate computing, these methods in [1,7,33,48] can be adopted for optimization.In order to minimize the energy function FMSACM, we can construct a weighted multilayer graph for getting the minimal cut. For instance, a color–texture image with 4 phases is presented in Fig. 2(a), and the corresponded multilayer graph is shown as Fig. 2(b) (with 3 layers). We should notice that the displayed multilayer graph is consisted of KPhase−1 layers, and each layer owns the same n-link, while between each two layers has the different t-link.Let G=(V,E) represent a multilayer graph, where V is a set of vertices and E is the corresponded set of edges. For each layer of G, it contains the same 2D grid graph P, and then G can be defined as {(m,l)∈R2×R|m∈P, l∈(1, 2, ⋯, KPhase−1)}, where m is a position of any pixel in grid graph P. To facilitate the description, we denote vm,las a point which is located at the position of m in the lth layer. Consequently, V can be defined as V={vm,l|m∈P, l∈(1, 2, ⋯, KPhase−1)}∪{s,t}. For the set of edges E, we will rearrange it into two groups as EDand ES. Where EDis the set of t-link edges which corresponds to the region-based energy term E1, and it can be denoted asED=∪m∈PEm,Em=esvm,1∪l=1KPhase−2evm,lvm,l+1∪evm,KPhase−1t.Emdenotes the set of t-link edges that linked with grid point m. For each t-link edge e(vm,l,vm,l+1) is weighted as w(e(vm,l,vm,l+1)) to represent the feature similarity of pixel m to the (l+1)th phase, and the corresponded weight value can be calculated as—log (pl+1,m). Particularly, w(e(s,vm,1)) andwevm,KPhase−1tare represented as the feature similarities of pixel m to the first phase and the KPhaseth phase respectively. In the same vein, the set of n-link edges EScorresponds to the edge-based energy term E2 which can be represented asES=evm,lvn,lm∈P,n∈NmQ,l∈1,2,⋯,KPhase−1where Q and Nm(Q) follow the definition of formula (16), and the n-link edge e(vm,l,vn,l) is weighted as w(e(vm,l,vn,l)), which indicates the feature similarity between each pair of neighboring pixels (m,n), and meanwhile it can be calculated as w(e(vm,l,vn,l))=νwm,n⋅exp(−ϖ|ΓSC∗(m)−ΓSC∗(n)|2)+τ.Based on the constructed multilayer graph G, each pixel m∈P is configured with at least one phase label after graph cuts optimization, otherwise, {s} and {t} cannot be separated. Consequently, any cut on G must be severed at least L edges from ED(L is the size of color–texture image u0). Normally, it is supposed that a cut is admissible [34] just as G severs only one edge in Emfor each pixel m∈P. For instance, Fig. 2(c) presents a 2D multilayer graph which is corresponded to Fig. 2(b), where each 2D layer has been converted as a 1D form. The red line displays a non-admissible cut (ABCDEFGHMNOPQIL) for that the t-link edges that link to nodes X3and X4are divided out three times respectively. Taking the node X3for illustration, it linked t-link edges asesvX3,1,evX3,1vX3,2andevX3,2vX3,3, we can see that these edges are divided out by the same cut(ABCDEFGHMNOPQIL). Thus, this means that the node X3is configured with three different phase labels as {1, 2, 3}. Obviously, this result is conflicted with the admissible metric. However, we can resort to the idea in [33,34] to exclude the non-admissible cut, and then an admissible cut (A⁎B⁎C⁎D⁎EFGHIL) is obtained as shown by the green line displayed. Through the analysis mentioned above, we can use the max-flow/min-cut algorithm [49,50] to minimize the energy functional E, so that we can acquire an approximately optimized segmentation for any tested color–texture image in multiphase.Due to the diversity, complexity and randomness of different color–texture images, the parameter ν in energy function E is hard to set adaptively. If a large initialized value is configured to ν, it can dampen the impact of noise, however, some details are also lost simultaneously. Vice versa, a small value ν that is chosen will cause some meaningless, smaller, and discrete regions. To alleviate these problems, we apply the prior information such as region size, and common edge between regions [51] to avoid this phenomenon. In addition, since the segmentation results of one round of segmentation process are not stabilized, we design an iterative segmentation metric to terminate the segmentation process adaptively by incorporating ratio change of multiphase labels and Kullback–Leibler (KL) [35] distance between KPhase(t) phases. During the segmentation process, we should note that the statistical parametersΘ1tΘ2t⋯ΘKPhasetand the valid phase number KPhase(t) should be updated after each iteration time. Here, the statistical parameters of the kth phase can be updated as follows,(18)αtk=∑x∈M1−φψx−k∑l=1KtPhase∑x∈M1−φψx−l,utk=∑x∈M1−φψx−k⋅ΓSC∗x∑l=1KtPhase∑x∈M1−φψx−lΣtk=∑x∈M1−φψx−k⋅ΓSC∗x−utkTΓSC∗x−utk∑l=1KtPhase∑x∈M1−φψx−l.Through these statistical parameters and multiphase labels, we can achieve the segmentation process adaptively by integrating them as follows. Commonly, the straightforward criterion is to check whether the whole ratio change of multiphase labels is less than one predefined threshold. If true, the segmentation process will be terminated, vice versa, it is continue. Here, we can firstly set EL(t) as the whole ratio change of multiphase labels (global information) in the tth iteration, and then it can be calculated as follows:(19)ELt=01−L−1∑m∈Pφψtm−ψt−1m,,ifKPhaset≠KPhaset−1elsewhere |L| denotes the total pixel number of provided color–texture image. ψ(t)(m) is denoted as a configured phase label at m position in the tth iteration. To avoid impact on the iteration process, EL(t) will be set as 0 when a valid phase number is changed (the reason for that is that the corresponded relationship between multiphase labels has been lost in two adjacent iterations). Although this strategy is less time consuming and owns the description ability in global, it will lose some local dissimilarity and stability measure. Thus, in this lecture, a criterion based on dissimilarity measure of KPhase(t) phases multivariate Gaussian is designed by using extended KL divergence [35].For each phase k, it can be described with a multivariate Gaussian asΘtk=αtkutkΣtk, where k∈(1,2, ⋯,KPhase(t)). Then, the KL distance D(t)(k,n) between the kth phase and the nth phase can be calculated as follows(20)Dtkn=KLGaussiantkGaussiantn=12logΣntΣkt+trΣnt−1Σkt+μkt−μntTΣnt−1μkt−μnt.Let EKL(t) represent the dissimilarity measure of KPhase(t) phases. We can calculate the EKL(t) with the sum of the minimum KL [38] distance between KPhase(t) phases as follows(21)EKLt=∑k=1KPhasetαkt⋅Minn∈1⋯KPhaset∩n≠kDtkn.Due to the fact that the ratio change of EKL(t) can be used to describe the local dissimilarity and stability, then, we can set the ratio change as ΔEKL(t) and it can be computed as(22)ΔEKLt=exp−Mint′=1,⋯,tEKLt′−EKLt′−1EKLt′where ΔEKL(t) and EL(t) represent the information change in local and global respectively, andEKLt′=Maxj=1,⋯,tEKLj. Then, we can design an adaptive convergence criterion by integrating formula (19) and formula (22) as follows:ELt≥β1andΔEKLt≥β2,where β1 and β2 are the discriminate thresholds, which can be used to control the convergence speed and segmentation accuracy. Through a substantial of experiment testing, we can set them as 0.99 and 0.95, respectively.

@&#CONCLUSIONS@&#
