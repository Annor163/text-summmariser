@&#MAIN-TITLE@&#
FPGA multi-filter system for speech enhancement via multi-criteria optimization

@&#HIGHLIGHTS@&#
We study the signal enhancement problem.We propose a multi-filter system.We study the multi-criteria design of the system.We propose an implementation of the system with an FPGA embedded system.

@&#KEYPHRASES@&#
Signal enhancement,Multi-criteria,FPGA,

@&#ABSTRACT@&#
Speech is the main medium for human communication and interaction. Apart from the traditional telephones, more and more applications come with speech interfaces, which use speech signal as an input for various purposes. However, many of these applications might fail to perform in noisy environments as the signal-to-noise ratio (SNR) degrades. Two important measures for any speech enhancement algorithm are noise suppression and speech distortion. Naturally, different speech enhancement algorithms will have different trade-offs. Moreover, depending on the environment, it is possible that one algorithm will outperform the others in some respects. This paper proposes a multi-filter system, which has the capability of continually adjusting the noise suppression level and the speech distortion level in a Pareto fashion. Moreover, we show that the system works under a variety of noisy environments and we obtain the efficient frontier of the combined filters for each background noise. Because the multi-filters are adapting in parallel, the final system can be implemented on FPGA efficiently.

@&#INTRODUCTION@&#
Being a natural interface between human and machine, speech input engine has already been integrated into many telecommunication systems like call centres and mobile phones, including Philips noise void mobile phone and more recently iPhone Siri system. Voice control feature is an attractive functionality that can be embedded in many products like electrical appliances. It provides a natural mean of remote control making the products more user-friendly. However, in real environments like living rooms or factories, the speech signal picked up by a microphone can be very difficult to analyze because of interference. The performance of the speech input engine diminishes rapidly when there is a mismatch between the training and testing conditions [1,2]. Since noise is additive in nature, one way to improve the signal-to-noise ratio (SNR) is to estimate the noise statistics during non-speech periods. With the availability of the noise characteristics, noise reduction algorithms can then be performed.One of the most popular single channel speech enhancement techniques is spectral subtraction. It was originally suggested by Boll [3] and has since gained popularity due to its simplicity. Spectral subtraction relies on the assumption that the target signal and noise signal are uncorrelated [3,4]. Therefore, if the noise spectral components are estimated correctly, the target signal can be recovered by just subtracting the estimated spectral noise from the noisy spectral observation. Spectral subtractive-type algorithms can be viewed as filtering of noisy observation with a time-varying linear filter dependent on the characteristics of the noisy observation and on the estimated noise spectral components.Whilst Boll's original spectral subtraction is simple and efficient, the musical artifacts from the residual noise can be very annoying. As reported in [6,7], a critical parameter to reduce the musical noise is the a priori SNR. Ephraim and Malah [8] proposed a computationally efficient approach to determine the a priori SNR by using the decision-directed estimator. Nevertheless, the a priori SNR estimator has a trade-off between the response time and the musical residual noise [5]. Generally speaking, each of the speech enhancement algorithm has its own trade-off in terms of noise suppression capability and speech distortion level. Depending on the observed noise signal, one algorithm might outperform another in certain aspects. This is because different additive noise may have different sensitivity towards the spectral distortion of the original signal. As a result, it would be difficult to find a single type of speech enhancement algorithm that works for all types of noise.In an effort to generalize the solution for a wide range of noise, this paper proposes to optimally combine several gain functions for the best trade-off between noise suppression and speech distortion. In this paper, we propose to formulate the optimal filter design as a multi-criteria decision problem with the use of a system of parallel filters to trade-off between suppression and distortion. It was previously reported in [9–11] that the trade-offs played a crucial role in enhancing speech recognition accuracy for voice control devices. However, those works focused on the optimization of speech recognization accuracy and no work has been conducted to combine the gain functions to establish a Pareto optimal solution in the form of an efficient frontier [12]. Therefore, we study the use of the Non-dominated Sorting Genetic Algorithm-II (NSGA-II) [13] here for solving the formulated multi-criteria decision problem and demonstrate how to construct efficient frontiers for a variety of noisy environments.This paper aims to combine different filter characteristics as a means to cater for a wide range of noise profiles. As mentioned, the motivation stems from the fact that different gain functions may have different performance limitations on different types of noise. Thus by optimizing the gain functions in a Pareto sense, the best compromise can be obtained, in the form of an efficient frontier. In terms of computational requirement, it is possible to implement the filters in parallel, which will yield a lower overall delay and improved computational efficiency. The contribution of the paper is therefore twofold. The first is to formulated the multi-criteria optimization problem for a system of parallel filters and to study the Pareto optimum solutions under a variety of background noisy environments. We show that the proposed parallel filter system can continually adjust the noise suppression level and the speech distortion level in a Pareto fashion. The second contribution is associated with the proposed real-time implementation scheme. As the proposed filters are parallel in nature, we adopt the use of field programmable gate array (FPGA), which is usually be used to integrate large amounts of logic in a single integrated circuit [21–24]. In this case, we analyze the common computational intensive operations for all filters and design dedicated processing units. The proposed design is implemented in fixed point arithmetic with a suitable bitwidth, which can reduce the overall circuit size significantly when compared with a direct realization of the software onto an FPGA platform. The acceleration is evaluated on a Virtex-4 platform, showing that the FPGA-based implementation at 184MHz can achieve real-time performance by processing a maximum of 21,375 samples per second. As a result, real-time adaptation to changing noise is feasible.Single channel speech enhancement relies solely on the temporal and spectral information of the observations to remove the background noise. For simplicity assume that the received signal x(t) only consists of the observed source speech signal s(t) and the background noise,v(t)given as(1)x(t)=s(t)+n(t).The M-point short-time Fourier representation of (1) can be written as(2)x(ω,ℓ)=s(ω,ℓ)+n(ω,ℓ).where s(ω, ℓ) and n(ω, ℓ) are the transformed representation of s(t) and n(t), respectively. The variable ω denotes one of the real angular centre frequencies, (ω∈ω0, …, ωM−1) and ℓ is the associated time index. Assume that active period of the speech signal is identifiable (typically identified through a voice activity detector (VAD)). Then one straightforward way to suppress n(ω, ℓ) is to estimate its statistics during periods of non-speech. There have been numerous variations of Boll's spectral subtraction over the years. In this paper, we concentrate on four types of the subtractive algorithm, namely the conventional Boll's spectral subtraction [3], the Wiener filter [14], Ephraim-Malah's minimum mean-square error (MMSE) log-spectral amplitude estimator [8] and the recently developed Cohen's noncausal a priori SNR estimator [6]. The following section briefly details each of the spectral subtractive algorithmic variations.The gain function for the Boll's spectral subtraction is described by(3)GSS(ω,ℓ)=max1−Pn(ω,ℓ)Px(ω,ℓ),δfloorwhere Pn(ω, ℓ) and Px(ω, ℓ) are the noise and signal averages. The constant, δflooris the noise floor introduced to avoid a vanishing gain function. In this case, Px(ω, ℓ) is estimated as(4)Px(ω,ℓ)=αPx(ω,ℓ−1)+(1−α)|x(ω,ℓ)|pwhere α is a smoothing constant and |·| is the absolute value operator. The factor p determines whether it is a magnitude subtraction (p=1) or power subtraction (p=2). From (3), it can be seen that spectral subtraction works on the principle of subtracting the estimate of the noise spectrum from the noisy signals.In this paper, the noise spectrum, Pn(ω, ℓ) is estimated by using the minimum statistics approach [15]. Briefly, minimum statistics is based on the observation that a short-time subband power of a noisy speech signal exhibits distinct peaks and valleys [15]. The peaks refer to speech active period and the valleys are the representative values of the noise power level. Therefore by tracking the minimum power (hence the name minimum statistics) within a finite window large enough to bridge high power speech periods, the noise statistics can be efficiently estimated.Unlike the conventional spectral subtraction, which is primarily based on heuristics formulation, Wiener filter formulation is optimally derived in the mean square sense [1]. The gain function can be written as(5)GWF(ω,ℓ)=SNR(ω,ℓ)SNR(ω,ℓ)+1where(6)SNR(ω,ℓ)=Px(ω,ℓ)Pn(ω,ℓ).Eq. (5) reveals that when SNR(ω, ℓ)≈0, the Wiener gain function approaches zero. On the other hand, at high SNR, the Wiener gain function approaches unity. This suggests that Wiener formulation suppresses the signal when the SNR is low and passes the signal when SNR is good.Whilst the Wiener filter is an optimal complex spectral estimator in the mean square sense, it is not an optimal spectral magnitude estimator [1]. Since it is well known that the short time spectral amplitude plays an important role in determining the overall speech quality, a spectral magnitude estimator is proposed in [16]. It has been reported in [17] that the squared error of the log magnitude spectra yields a better performance compared to its predecessor, the spectral magnitude estimator. The gain function for the log spectral amplitude estimator is given as(7)GLOG(ω,ℓ)=SNRpriori(ω,ℓ)SNRpriori(ω,ℓ)+1exp12∫λ(ω,ℓ)∞exp−κκdκwhere(8)SNRpriori(ω,ℓ)=αGLOG(ω,ℓ−1)SNR(ω,ℓ−1)+(1−α)maxSNR(ω,ℓ)−1,0.Here, α is the smoothing constant and SNR(ω, ℓ) is readily defined in (6). The integral parameter λ(ω, ℓ) is defined as(9)λ(ω,ℓ)=SNRpriori(ω,ℓ)SNRpriori(ω,ℓ)+1SNR(ω,ℓ).From (8), it can be seen that if SNR(ω, ℓ) is much greater than 0dB, SNRpriori(ω, ℓ) corresponds to a frame delayed version of SNR(ω, ℓ). Moreover, if it is lower than 0dB, SNRpriori(ω, ℓ) is a smoothed delayed version of SNR(ω, ℓ). It is precisely this smoothing effect that reduces the effects of musical tones with the log spectral amplitude estimator gain function. However, the delay introduced in the estimate may introduce reverberation effects especially during speech onset and offset periods.As described earlier, the estimation of SNRpriori(ω, ℓ) in (8) assumes a speech presence probability of unity. This means that the information estimated in SNRpriori(ω, ℓ) cannot discriminate between speech onsets and noise irregularities under speech presence uncertainties. The work by Cohen in [6] proposed a noncausal SNRpriori(ω, ℓ) estimator to overcome the deficiency. The proposed method aims to better estimate the spectral variance of the clean speech. It was shown that the noncausal approach has the ability to distinguish speech onsets and noise irregularities intervals in the estimation process by just having a few subsequent spectral measurements. The basic idea is to employ the “propagation and update” technique to estimate the noncausal SNRpriori(ω, ℓ). For brevity, the readers may refer to [6] for a detailed explanation of the technique.Since different additive noise has a different sensitivity toward spectral distortion of the original signal, it would be difficult to find a single type of filter that works for all types of noise. In other words, each gain function has its own unique property in terms of noise reduction and signal distortion. For instance, Boll and Wiener formulation may yield the best suppression, but will also generate a fair amount of musical noise. Whilst the MMSE log spectral estimator is good, Cohen's approach may improve its performance in terms of musical artifacts. Nevertheless, Cohen's solution may not be as robust as Boll, Wiener and MMSE log spectral estimator as it requires a non-causal estimation. Quite plainly, each of the gain functions has its own ideal operating conditions, depending on the noisy observations at hand. In order to improve the performance of the gain functions collectively, we attempt to form a linear combination of different filters in a Pareto optimal sense, namely a four-filter system. In this case, the combined gains will have the degrees of freedom to cater for a wide range of background noise.We propose to let the gain functions be combined as(10)G(γ,ω,ℓ)=(a1GSS(ω,ℓ)+a2GWF(ω,ℓ)+a3GLOG(ω,ℓ)+a4GCO(ω,ℓ))where GSS, GWF, GLOGand GCOare the gain functions for the Boll's spectral subtraction, Wiener formulation, Ephraim-Malah log spectral estimator and Cohen's approach, respectively. The parameters a1, a2, a3 and a4 are the weighting function of each of the gain function. Depending on the type of noise, the gain functions should be scaled optimally among them. Applying this gain function as the noise filter and synthesize all the subband signals, we can obtain the filtered signal y(t). Fig. 1shows the parallel nature of these four filters. The optimization of the proposed combination is detailed in the following section.The objective specified in (10) is in fact a separate measure to the distortion caused by the filters measured by the deviation between the filter output and the source signal, and the noise suppression. There are different ways of measuring distortion and suppression [1]. Following [18], some intuitive measures are employed here. The normalized distortion quantity,D, is(11)D=12π∫−ππ|CdPˆys(w)−Pˆxs(w)|dwwherew=2πf, and f is normalized frequency. The constant, Cdis for normalization and can be defined as(12)Cd=∫−ππPˆxs(w)dw∫−ππPˆys(w)dwwherePˆxs(w)is a spectral power estimate of the observed signal andPˆys(w)is the spectral power estimate of the filter output when the source signal is active alone. The constant Cdnormalizes the mean output spectral power to that of the single sensor spectral power. The measure of distortion in Eq. (11), is the mean output spectral power deviation from the observed signal spectral power. Ideally, the distortion is zero.The normalized noise suppression quantity, Sn, is(13)Sn=Cs∫−ππPˆyn(w)dw∫−ππPˆxn(w)dwwhere(14)Cs=1Cdand wherePˆyn(w)andPˆxn(w)are spectral power estimates of the filter output and the observation, respectively, when the surrounding noise is active alone. The noise suppression measures are normalized to the amplification/attenuation caused by the filter to the observation when the source signal is active alone, i.e. if the filter attenuates the source signal by a specific amount, the noise suppression quantities are reduced with the same amount.Because there is more than one objective in the design of the filters, it is basically a multi-criteria design problem. When different scaling factors are applied to the criteria in the design process, a solution set can be derived in which all solutions are efficient, or Pareto optimum. In the present context, the set of weightsa* is Pareto optimum if and only if there does not exist a set of weightsasuch that(15)Sn(a)≥Sn(a*),(16)D(a)≤D(a*),with strict inequality to at least one of the criteria. In order to solve for the Pareto optimum, we employ the well-known Non-dominated Sorting Genetic Algorithm-II (NSGA-II) with these two criteria and construct the set of Pareto optima.The four filter algorithms described in previous sections are implementable under ergodic signal property assumptions where the expectation operator may be interchanged with time averaging estimations. Further, the source signal and the noise signal components, have to be accessible separately so that we may estimate the source and the noise correlation estimates individually. In the following it is assumed that these constraints are fulfilled.In contrast to traditional software development, designing a system on an FPGA platform always involves an estimation of the length of bitwidth which affects the circuit size, the system performance and the quality of the calculation. As the design employs a fixed point representation and the saturation arithmetic [19] to avoid the overflow case, a set of fixed point library is developed which allows the exploration of how the bitwidth affects the quality of the signal during signal processing. Bitwidth analysis can identify a near-optimal bitwidth for the hardware which can ensure the quality of the signal with less area consumption.Many DSP algorithms rely upon fixed point arithmetic and its inherent speed advantage over floating-point. Often, a fixed point algorithm requires the evaluation of FIR filter and FFT, etc. We run an experiment using a 32-bit fixed point representation, while varying the integer size and disable the saturation arithmetic in order to determine the suitable integer size in this system. In case of any overflow, the coefficients will change dramatically and the results will be invalid. The integer size is finally determined as 12-bit. In practice it may be possible to overflow occasionally even if the integer size is 12-bit, so saturation arithmetic and scaling have been employed in the hardware implementation to minimize the impact of overflow.During the calibration phase of the Cohen and Log filters, it is needed to compute the exponential and exponential integral functions for log spectral gain. Due to computational complexity, it is hard to compute the exponential term in such 32-bit fixed point arithmetic and implement in digital hardware. However, as Fig. 2depicts, the exponential results approximate to one when calculating exp(0.5*expint(x)). So we use the Lookup table method and employ a new fixed-floating point data representation method to compute the exponential term to get the results more accurate. Simulation results show that floating point computation occupies very little time of the whole process and there is no significant degradation in performance.In the time domain, the main operation of the filters is the calculations given by equations in Section 2. These operations are greatly reduced by carrying out the actual filtering in the frequency domain and transforming the results back to the time domain described using the dataflow shown in Fig. 3, which performs the following calculations:1.Analyze the input signal to their frequency domain representations via FFT.Filter the subband signals by the subband impulse response estimates.Synthesize the impulse response estimates back to the time domain via IFFT (inverse FFT).The algorithm was carefully analyzed to determine an optimal way to map them to the hardware available, which tries to guarantee computational efficiency by taking advantage of the parallelism property of the algorithm running in the frequency domain, which can be exploited at several levels:•Loop level parallelism, consecutive loop iterations can be executed in parallel.Task level parallelism, that entire procedures inside the program can be executed in parallel.Data parallelism.Since the algorithm is made up of a control part and a computation part, the first stage consists in locating the computational kernels of the algorithms. When profiling is carried out, the most time consuming operations can be determined and will be implemented in hardware. The profiling results of the main operations are shown in Table 1, clearly indicating that the FFT/IFFT could be the best candidates to be moved to hardware, since they occupy over 86% of the CPU time. These kernels are mapped on dedicated processing engines of the system, optimized to exploit the regularity of the operations operated on large amounts of data, while the remaining parts of the code is implemented by software running on the PowerPC processor. The FPGA presents on the Virtex 4 is suitable to carry out this implementation. The new Auxiliary Processor Unit (APU) controller simplifies the integration of hardware accelerators and co-processors. These hardware accelerator functions operate as extensions to the PowerPC, thereby offloading the CPU from demanding computational tasks.A block diagram of this architecture is shown in Fig. 4. As shown the hardware accelerator is connected to the PowerPC processor using two APU channels. The first channel is used for data I/O from/to the FFT/IFFT module. The second is used to connect with vector-matrix multiplication module. The hardware accelerator was designed to be as much reusable, flexible, and customizable as possible. A set of constants are defined to specify the values for a set of key parameters of the architecture like the bus width, the polarity of control signals, the functional units which should be inserted or removed, and so forth. In order to minimize the execution time difference between the four filters, multiple instances can be instantiated into the hardware accelerator to improve the performance. Since these operations are performed in the subband/frequency-domain, a high degree of parallelism can be achieved. Thus, the implementation may be exploited by optimizing area, by optimizing performance, or even by obtaining an optimal area/performance trade-off point.Key features of the hardware accelerator:•High parallelism, because functional units can operate independently from each other in subband frequency domain. When different functional units commit their elaboration simultaneously, a multi-port register file allows the concurrent write-back of their results;Scalability and adaptability: the functional units can be inserted or removed from the architecture in an immediate way, just setting the value of dedicated VHDL generics. Also many key parameters of the architecture can be tuned to taste of the user (width of the bus, latency of the functional units, throughput, etc.);Modularity of the functional units: each functional unit is dedicated to implement an elementary arithmetic operation in particular. It can be removed from the architecture and also be used as a stand-alone computational element inside other designs;Easy to integrate with and controlled by PowerPC: the OPB register interface gives access to control and status registers to configure the operation of the hardware coprocessor by software.The details of the hardware accelerator is shown in Fig. 5, which contains two FCB channel interfacing logic modules responsible for data transfer from/to the accelerator, a FFT/IFFT module is responsible for analyzing and synthesizing data, a vector-matrix multiplication module is used to calculate main loop operations, and some temporary storage modules are used for constructing the data structure. When the APU passes an instruction to the hardware accelerator, the decoder logic decodes the instruction and waits for data from memory to arrive via the APU and then execute it. After decoding the instruction, the state machines handle data transfers between the APU and the operation module, using registers to store data for the consequent operations. Data is transferred between the APU and the interfacing logic via load and store instructions. The data is then transferred between the interfacing logic to the operation module via a user-defined protocol.In this system, the flow of data is as follows:1.A filter operation begins with the processor forwarding an load instruction for filter input data to the APU.The APU passes the instruction to the interface logic, which decodes the instruction and waits for data from memory to arrive via the APU.The interface logic sends the input data to the specified operation module.When load instructions are completed, the processor forwards a store instruction to the APU in anticipation of the filter output.The interface logic decodes the store instruction and waits for data from the filter module.After processing, the operation module returns results to the interface logic.Finally, the interface logic returns the output data to the processor via the APU. This data is written back to memory.In the FCB interface logic, a hardware state machine manages the data transfer. That is to send and receive some data from software to hardware or vice versa. Fig. 6shows the main state machine that is responsible for load and store operations. This state machine communicates with the processor using the APU.The hardware state machine asserts a ready flag which means that it is ready to accept the data. The PowerPC provides the data, address and a valid signal. The valid signal is the indication to write. As soon as the hardware gets the valid signal it writes the data at the address provided by the PowerPC and after writing it asserts a flag which tells the PowerPC that data has been written. The state machine then goes to wait state to wait for result. Once the result is ready, it asserts a result ready flag. The PowerPC can detect this completion in two ways. Firstly, the processor can continuously poll a bit in order to detect when the calculation has completed. Secondly, an interrupt can be enabled and on completion the interrupt output signal will be asserted. If the hardware accelerator interrupt signal is correctly connected to the processor and configured for use, an interrupt will occur to indicate completion. In this way, the processor can avoid wasting the valuable time in polling loops to do other calculations while the hardware accelerator is updating the log spectral gain of one filter. The final result from the filter can be sent back to PowerPC to combine with the results from other filters.In order to maximize system performance, the FFT/IFFT are implemented using the core generator provided by the vendor tools, while the vector-matrix multiplication module must be designed from scratch. Because the adaptation is a data-oriented application, it can easily be implemented by a combinational circuit in theory, however, the approach uses a large number of functional units and thus requires a significant amount of hardware resources. The dependency and movement of the data is examined, so we can design the multiplication function in a time-multiplexed fashion, and schedule the operations sequentially to achieve the desired trade-off between performance and circuit complexity. And the output from mac unit is stored in either register file or dual-port block ram. In this way, the real and imag part of the result can be saved in parallel.Once the scheduling and binding are done, the dataflow graph can be transformed into an ASMD chart. Since each time interval represents a state in the chart, a register is needed when a signal is passed through the state boundary. Additional optimization schemes can be applied to reduce the number of registers and to simplify the routing structure. For example, instead of creating a new register for each variable, we can reuse an existing register if its value is no longer needed.

@&#CONCLUSIONS@&#
This paper has presented a fixed point FPGA-based speech enhancement scheme, which is based on a linear combination of signal channel filters. The proposed method synergistically combined different filters in a Pareto-optimal sense and allows an investigation into the trade-off between noise suppression and speech distortion for the combined filter. In this way, various distortion and suppression patterns can be produced for a variety of noise. Results demonstrate that the proposed method can be implemented efficiently in the embedded FPGA system and real-time performance can be achieved. As a future extension, it would certainly be of interest to study the incorporation of other kinds of single channel speech enhancement techniques into the proposed system, and to study the use of the proposed system together with sophisticated beamforming algorithms.