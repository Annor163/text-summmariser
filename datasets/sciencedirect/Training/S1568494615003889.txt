@&#MAIN-TITLE@&#
Rule-based OneClass-DS learning algorithm

@&#HIGHLIGHTS@&#
One-class learning algorithms are used in situations when training data are available only for one class, called target class. Data for other class(es), called outliers, are not available.One-class learning algorithms are used for detecting outliers, or novelty, in the data.The common approaching one-class learning is to use density estimation techniques or adapt standard classification algorithms to define a decision boundary that encompasses the target data.In this paper we introduce OneClass-DS learning algorithm that combines rule-based classification with greedy search algorithm based on density of features.Its performance is tested on 25 data sets and compared with eight one-class algorithms; the results show that it performs on par with the eight algorithms.

@&#KEYPHRASES@&#
One-class learning algorithm: OneClass-DS,Outlier detection,Anomaly detection,Novelty detection,

@&#ABSTRACT@&#
One-class learning algorithms are used in situations when training data are available only for one class, called target class. Data for other class(es), called outliers, are not available. One-class learning algorithms are used for detecting outliers, or novelty, in the data. The common approach in one-class learning is to use density estimation techniques or adapt standard classification algorithms to define a decision boundary that encompasses only the target data. In this paper, we introduce OneClass-DS learning algorithm that combines rule-based classification with greedy search algorithm based on density of features. Its performance is tested on 25 data sets and compared with eight other one-class algorithms; the results show that it performs on par with those algorithms.

@&#INTRODUCTION@&#
In a classical supervised learning problem, data instances that represent several classes are available for designing a classifier and a learning algorithm uses this information to discriminate between the classes. In a single-instance learning scenario, the simplest, we have class label for each instance, while in multiple-instance learning scenario we have class label for a group of instances, called bags [1,2]. In the third, more difficult, learning scenario we have data available only for a single class, called Target (each instance belongs to Target). Once a classifier is designed it can be used for predicting whether a new instance belongs to the Target class or not. If an instance does not belong to a Target class it is called an outlier, also known as “ignorance” [3]. Therefore this type of learning problem is known as outlier, or novelty, or anomaly detection. One-class learning algorithms are often designed using information about distribution of the Target training data. Several methods have been developed to solve this challenging problem and they can be divided into density estimation, boundary, reconstruction, and rule-based methods. They differ in their ability to cope with, or exploit, different characteristics of data such as feature scaling, grouping of data into clusters, or taking advantage of data distribution convexity. These methods are briefly described next.The common and most straightforward method is to estimate density of the training data [4] and then use some threshold to encompass the data. When data are sufficiently large and a density model, such as Parzen, is used this approach works quite well. The drawback, however, is that it requires a large number of instances to overcome the curse of dimensionality [5]. If the dimensionality of data and complexity of the density model are restricted then a large bias is introduced resulting in the model that does not fit the data well. Finding the right model to describe Target data distribution is a bias-variance dilemma. Using the density approach one needs to assume a distribution type, such as Gaussian [6–8], or mixture of Gaussians [5,6,8], or Parzen [9–11]. Algorithm introduced in [1] builds density function from a chosen distribution and then combines this function with a class probability to form an adjusted estimate of the density function of the Target class, which is then used for constructing a decision tree.Boundary methods define a closed boundary around the target data first and then it is optimized. These methods rely heavily on distances between instances and are sensitive to feature scaling [8,12]. Although the volume of data is not always minimized, most of these methods have a strong bias toward a minimal-volume solution. How small the volume is to be depends on the model. The advantage of the boundary methods is that the number of instances required for training is smaller than one required by the density methods. The difficulty, however, is shifted into defining appropriate distance measures. One such example method is the k-center, which covers the data with k small balls with equal radii [13]. The ball centers, μk, are placed on training instances such that the maximum of all minimum distances between training instances and the centers is minimized. To fit the model the following error is minimized:εk-centre=maximinkxi−μk2It uses a greedy search strategy, starting with random initialization. The radius is determined by maximum distance to the instances that the corresponding ball captures. Because of this, the method is sensitive to outliers possibly present in the target data but works well when data have good (compact) clustering structure. However, the user needs to specify in advance both the number of balls, k, and the maximum number of tries (the number of runs with random initialization).Another such method is the nearest-neighbor, NN-d, which is designed from local density estimation by the nearest neighbor classifier [5]. It avoids explicit density estimation and uses only distances to the first nearest neighbors. It is similar to the methods of [14] and [15] that were used for outlier detection in large databases. In the nearest neighbor density estimation a cell, often a hypersphere in a d dimensional space, is centered around the training instance z. The volume of this cell is grown until it captures k instances of the training data. Support vector machine with RBF kernel was also used for anomaly detection [16]. For each new instance, the method determines if it falls within the learned region: if it does then the instance is considered to be a target instance, otherwise it is an outlier instance. Similar approach, called Robust SVM, was used for intrusion detection [17].Reconstruction methods use prior knowledge about data and make assumptions about the data-generating process to build a classifier. The assumption is that a compact representation of the target data can be obtained that decreases noise influence [6,18]. The reconstruction methods assume that outlier instances do not satisfy assumptions about the target class distribution. During testing a new instance may have low or large noise component and thus the corresponding low or high reconstruction error, calculated as a distance to the target training data. Users need to choose appropriate thresholds when using these methods. For example, in learning vector quantization [18] and in k-means clustering [6] it is the number of clusters. In self-organizing feature maps [19] it is the dimensionality of the manifold, the number of prototypes per manifold, and the learning rate. In Principal Component Analysis (PCA) [6] it is the mean and basis vectors for each of the subspaces and the noise variance outside of the subspaces. In diabolo networks [20,21] and auto-encoder networks [22] it is the number of layers and neurons, learning rates, and stopping criteria.Rule-based methods are of key interest here as the introduced below algorithm is rule-based. Rule-based algorithms generate rules that capture target behavior of a system [23–25]. An instance that is not covered by any of the rules is considered an outlier. Different techniques generate rules in different ways. Classification techniques such as IREP and RIPPER [26] learn rules from data by adding outlier class data into the training data. Outlier class is artificially generated so a binary classifier (such as RIPPER) can learn the boundaries between the two classes. In [25,27] supervised outlier detection method was introduced to detect network intrusions while [28] adapted C4.5 algorithm for outlier detection. A similar approach was used in [29] where a query by Bagging method was used.A similar approach is to use association rule mining algorithm for rule generation, which requires users to specify minimum support and confidence thresholds [30–32]. The advantage of this approach is that it utilizes the fact that outliers occur very rarely in the data, and can be dealt with by choosing appropriate support threshold to ensure that outliers are not taken into account in the process of rule generation. To ensure that rules correspond to strong patterns the rules with low support values are pruned. An application of this technique for intrusion detection was used in ADAM system [30,31] and in [33] for intrusion detection embedded on the network interface card. LERAD method [34] generates association rules from data in the form P(notW|U), which is conditional probability of one subset of attributes taking on a particular set of values (denoted by notW) given that a disjoint subset of attributes takes on a particular set of values (denoted by U). In order to deal with possibly high number of rules that can be generated the authors used sampling and randomization techniques. Similar approach was used for credit card fraud detection and for fraud detection in spacecraft house-keeping data [35]. Observing that an outlying transaction occurs in fewer frequent itemsets when compared with a normal transaction, in [36,37] an approach similar to an outlier detection algorithm for categorical data sets was proposed. The authors also introduced a measure called Frequent Pattern Outlier Factor that ranked the transactions based on the number of frequent itemsets they occur in. A different approach, based on fuzzy classifiers [38–40], uses a fuzzy classifier learning algorithm to create rules from data with noise. For instance, fuzzy classifiers eClass and FLEXFIS-Class [41] can be used with different model architectures for solving one-class problems.In a classical binary classification problem there are positive and negative instances, representing two classes, which are available for training. When rules for the positive (or negative) class are generated they are found based on comparisons between positive and negative instances. During testing, an instance is assigned to either the positive or the negative class. This simple scheme, however, cannot be used for solving one-class classification problems since only instances representing one Target class are available. Moreover, Target instances may contain noise so they can be either true targets or false outliers (FO); this is illustrated in the left rectangle in Fig. 1. Similarly, the Outlier instances (to be identified only during testing) can be either true outliers or false targets; see the right rectangle in Fig. 1.OneClass-DS algorithm generates rules by performing greedy hill-climbing search in a manner similar to the DataSqueezer algorithm [42]. However, DataSqueezer was designed only for binary classification problems and generates rules by comparing the positive class instances with the negative class instances. Thus, OneClass-DS uses four user-specified heuristic parameters to guide the rule generation process to generate rules from one-class data only. They are: Threshold, MinCoverTager, MinAttribute and MaxAttribute. The last two are used for accepting the generated rules only if the total number of selectors in a rule is in the range between MinAttribute and MaxAttibute. The OneClass-DS generated rules are in the format:IF(Featurex=valuea)and(Featurey=valueb)…THENTargetFurthermore, all selectors in a rule must satisfy two conditions: they must cover a minimum number of target instances (MinCoverTarget) and have the summed-up value equal to or larger than the Threshold. The summed-up value of a selector is calculated by multiplying the number of values a feature takes on by the number of times it appears in the target training data. The pseudocode of the OneClass-DS algorithm is shown in Fig. 2.The process of generating rules is repeated several times with different settings of the four parameters. To choose the best model from the generated ones a Target Rate (sensitivity) measure is used in the following way.TargetRate=TrueTargets(TT)TotalTargets(TT+FO)=SensitivityAlthough target data instances should consist only of true target instances, some of the target instances may ve false outliers (FO), as illustrated in Fig. 1. To identify the FO instances we use 10-FCV as follows. The model is built from 9/10 of the target data but when testing it on the 1/10 of the remaining data, some of the instances that are not recognized as true targets and are identified as false outliers (FO). At the end of the 10-FCV process all the instances that were recognized as FO (in 10 runs) are subtracted from the Target data instances. The model that has the largest Target Rate is then chosen as the best one. The pseudocode for building the model is shown in Fig. 3, while Fig. 4illustrates the process.Computational complexity of OneClass-DS algorithm is approximately O(RKNlogN), where R is the number of rules in rules, N is the number of instances, and K is the number of attributes.To summarize, OneClass-DS is simple, greedy, effective rule learner that generates a set of production rules. The rules are compact, easy to comprehend, and have accuracy on par with rules (models) generated by other one-class rule-based algorithms. The main advantages of the algorithm are its high efficiency and robustness to missing data (shown later). In general, using higher values of the four algorithm's parameters results in generation of “stronger” rules that may predict new test instances with higher accuracy, while lower values of the parameters result in generating “weaker” rules.Data shown in Table 1are used to illustrate the working of the algorithm.Suppose we choose the following values of the parameters: MinCoverTarget=25%, Threshold=0, MaxAttribute=MinAttribute=2. The summed-up values (vij) are calculated as shown in Table 2, where I denotes a feature, j is feature number, and (vij)=(the number of times a value appears in target data)×(the number of values the feature takes on).Notice that F1, F2 and F3 have the same maximal summed-up values, namely, v11=v42=v13=8. We choose the first feature, F1, and add selector “F1=1″ to start the process of generating the first rule:IFF1=1Table 3shows instances covered (all but one) by F1=1. We continue calculating summed-up values for features F2 through F4, shown in Table 4, in order to choose the next selector for the first rule (because MinAttribute=2).Features F2 and F3 have the same max summed-up values, namely, v42=v13=8. Thus, we choose F2 with value 4 as the next selector and finish (because MaxAttribute=2) generation of the first rule:IFF1=1ANDF2=4This rule (IF F1=1 AND F2=4 THEN Class=T) covers 40% of Target data (instances 3 and 4 in Table 1) so we need to continue rule generation. After all instances covered by the first rule are deleted the reduced data set is shown in Table 5.We repeat the process and the second generated rule isIFF1=1ANDF3=1This rule (IF F1=1 AND F3=1 THEN Class=T) also covers 40% of Target data (instances 1 and 2 in Table 1).After deleting two instances covered by the second rule we are left with just one data instance shown in Table 6.Because MinCoverTarget=25% (i.e., we allowed for 25% of target instances not to be covered) the OneClass-DS algorithm converges and stops generating rules.In the next section, in order to perform comparisons of the results we use performance measures typically used in evaluating one-class algorithms, namely, the FAR and IPR measures [11]:FAR=FalseOutliers(FO)TrueOutliers(TO)+FalseOutliers(FO)IPR=FalseTargets(FT)TrueTargets(TT)+FalseTargets(FT)where FAR (false alarm rate) specifies the number of true Target instances incorrectly identified as outliers (false negatives), and IPR (impostor pass rate) specifies the number of outlier instances that are wrongly classified (false positives) as belonging to the Target class. A higher FAR corresponds to a lower IPR and vice versa. We will also use measures of precision and accuracy:Precision=TrueTargets(TT)TrueTargets(TT)+FalseTargets(FT)Accuracy=TrueTargets(TT)+TrueOutliers(TO)Totalinstancesintestdata(TT+FO+TO+FT)

@&#CONCLUSIONS@&#
We have introduced a rule-based OneClass-DS learning algorithm and compared it with eight algorithms on 25 data sets. It was designed for solving one-class problems where data for other classes are not available. OneClass-DS combined rule-based classification with greedy search algorithm based on density of features. When OneClass-DS was compared with the eight one-class algorithms on 25 data sets (representing numerical, nominal, and image data) it performed on par with almost all other algorithms in terms of Accuracy, IPR (impostor pass rate) and FAR (false alarm rate) measures.The advantages of OneClass-DS over other algorithms, however, are that it generates rules only from Target data, including on data with missing values, without the need to create an artificial data set as “the other” class, which is typical of many other one-class algorithms. It was also shown that OneClass-DS also performed well on highly unbalanced data sets when one-class model was generated for a majority class and not the much smaller minority class.OneClass-DS can be used to analyze one-class data in a variety of application domains such as strange traffic patterns in computer networks (possibly caused by a hacked computer which sends sensitive data to an unauthorized destination), abnormal patterns in patient medical records (that could be symptoms of a new disease), outliers in credit card transactions (that could indicate credit card theft), unusual changes in satellite images of an adversary area (that could indicate troop movements), and many more.In the future, we plan using OneClass-DS as a general framework to be combined with other rule-based algorithms, such as fuzzy classifiers, to possibly speed up learning when solving challenging real one-class problems.