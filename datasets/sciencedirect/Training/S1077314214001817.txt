@&#MAIN-TITLE@&#
Covariance estimation for minimal geometry solvers via scaled unscented transformation

@&#HIGHLIGHTS@&#
Scaled unscented transformation (SUT) for minimal geometry solvers (MGS).SUT vs. first-order-propagation (FOP) in uncertainty estimation of MGS.Since MGS are highly nonlinear, SUT is a better uncertainty estimator than FOP.

@&#KEYPHRASES@&#
Covariance estimation,Camera calibration,Epipolar geometry,

@&#ABSTRACT@&#
Covariance is a well-established characterisation of the output uncertainty for estimators dealing with noisy data. It is conventionally estimated via first-order forward propagation (FOP) of input covariance. However, since FOP employs a local linear approximation of the estimator, its reliability is compromised in the case of nonlinear transformations. An alternative method, scaled unscented transformation (SUT) is known to cope with such cases better. However, despite the nonlinear nature of many vision problems, its adoption remains limited. This paper investigates the application of SUT on common minimal geometry solvers, a class of algorithms at the core of many applications ranging from image stitching to film production and robot navigation. The contributions include an experimental comparison of SUT against FOP on synthetic and real data, and practical suggestions for adapting the original SUT to the geometry solvers. The experiments demonstrate the superiority of SUT to FOP as a covariance estimator, over a range of scene types and noise levels, on synthetic and real data.

@&#INTRODUCTION@&#
The output of a parameter estimator is of limited utility without a measure of its reliability. In practice, Gaussians are deemed an adequate uncertainty representation, and therefore, reliability is often assessed by propagating the input covariance to the output. However, since the output covariance is itself an estimate, its accuracy is a valid concern.In this paper, we study the quality of covariance estimates computed via first-order propagation (FOP) and scaled unscented transformation (SUT), for a collection of common minimal geometry problems; namely, homography, epipolar geometry and calibration estimation, and triangulation. The associated solvers recover the mappings relating a set of image-image, or scene-image correspondences from a minimum number of correspondences, by using all available constraints. Their covariance is of interest in a number of practical applications. For example, in RANSAC [1], the covariance estimate computed from the minimal set with the best score is an upper bound to the actual uncertainty of the result. This is employed in [14] to approximate the measurement covariances in a prediction–correction scheme with an unscented Kalman filter (UKF), which estimates the internal and external calibration parameters of a moving camera. In [21], the covariance estimates are utilised within the RANSAC cycle to reject ambiguous/unstable solutions and to improve the hypothesis evaluation, resulting in significantly faster operation. It can also potentially be used for determining the search regions in guided matching [11], global registration of pairwise relative pose estimates [4], sensor fusion, and keyframe selection in structure-from-motion [26]. Finally, in film production, commercial software packages typically allow an operator to make use of known survey points for manually establishing correspondences for calibration [2]. A minimal geometry solver (MGS) requires less effort, and an estimate of the covariance can guide the operator to more reliable correspondences.An MGS can be expressed as a function mapping a set of measurements (i.e. image-image, or scene-image correspondences) to a set of parameters (e.g. a camera pose). For such a map, covariance propagation via FOP involves substituting the original function with a local first order linear approximation [5]. Visual SLAM via extended Kalman filter (EKF) [8] is a well-known application of this approach, as FOP lies at the core of EKF. Other examples include the estimation of fundamental matrix [7,22], 2D homography [6], and relative and absolute orientation [9].The accuracy of FOP depends on the fidelity of the linear approximation to the original function. For example, EKF-SLAM is prone to underestimating the covariance (inconsistency) due to the accumulation of the linearisation errors [3]. An alternative approach is SUT [16]. It involves the generation of a number of “particles” by deterministically perturbing the original input, which are to be propagated through the function, in order to compute the sample covariance of the output. This technique approximates the output distribution by a Gaussian, as opposed to FOP, which approximates the function in such a way that the output distribution is a Gaussian [16]. SUT was recently employed in SLAM [12], by replacing EKF with UKF, and superior estimate consistency is reported. SUT is also utilised in [14] to estimate the uncertainty of a number of perspective-n-point (PnP) solvers.The superiority of SUT over FOP is already established in the control and robotics literature (e.g.[16,12]): it offers a performance identical to a second-order linear approximation (SOP). SUT is preferable to SOP as well, as it does not involve any Jacobians or Hessians [16]. However, the adoption of SUT in the computer vision field remains limited. In this paper, we aim to highlight the benefits of SUT on a collection of minimal geometry solvers. Our main contribution is twofold:•We show that SUT is superior to FOP, by comparing the covariance estimates with the true covariance obtained through Monte-Carlo (MC) simulations in synthetic and real data.The original SUT is formulated for 1:1 functions mapping Euclidean vectors. We describe how SUT can be implemented when these conditions are violated, as is the case for most of the solvers.The organisation of the paper is as follows: Section 2 introduces the notation, and provides a brief background on FOP, MC and SUT. Section 3 discusses some solver-specific implementation details. The experimental results are presented in Section 4, followed by the conclusions in Section 5. Two appendices include further details on the solvers, and additional experiments.Consider a solver S, an explicit function that maps a measurement vector (x) to a vector representing the estimated parameters (y). Given the measurement covariance matrix (Cx), our aim is to find an estimate (C^y) to the output covariance (Cy). This can be accomplished either by linearising S (FOP), or by computing the sample statistics ofy.The first two terms of the Taylor series expansion ofS(x)about anx¯provide a locally linear approximation to S inΔx=x-x¯, i.e.(1)y=S(x)≅S(x¯)+JΔx,whereJis the Jacobian of S with respect tox, evaluated atx¯. Ifxis distributed as a Gaussian with the meanx¯and covarianceCx, i.e.x∼N(x¯,Cx), the distribution ofycan be approximated asN(S(x¯),JCxJT)[5]. This technique is known as first order (forward) propagation of covariance (FOP) [11].Jcan be computed analytically or numerically. The analytical method involves the algebraic derivation of a closed-form expression for∇xS(through the chain rule, when S is a composition of several distinct stages). The numerical method computes one partial derivative at a time, by applying deterministic perturbations to each element ofx¯, and passing the results through a discrete high-pass filter. A common implementation, the central difference scheme, approximates the partial derivatives as(2)∂S∂xj=S(x+δjej)-S(x-δjej)2δj,whereδjdenotes the magnitude of the perturbation.xjis the jth element ofx, andejis a vector whose elements are all zeros, except for the jth, which is 1. The appropriate perturbation is problem-dependent; however, for geometry problems, [11] suggestsmax(10-6,|10-4xj|)(p. 602).The analytical method has advantages in terms of accuracy and computational cost (a single evaluation of∇xS, as opposed to2Mevaluations of S, for an M-elementx). However, we adopted the numerical approach for the following reasons:•We are not aware of any closed-form expressions of the Jacobians for some components of the solvers (e.g. Gröbner basis solvers).For a very common component, SVD, [32] offers a method to compute the exact Jacobian, but states that the results are identical to those obtained by the numerical approach.In practice, for geometry estimation problems, the error introduced by the numerical approximation is insignificant[11], especially, compared to the error due to the first-order approximation of S (i.e. Eq. (1)).Therefore, we believe that this decision is unlikely to have a qualitative impact on the results.A related method is backward propagation of covariance (BP): consider a functionxˆ=T(y)that minimises‖x-xˆ‖Cx, i.e. the Mahalanobis distance. Ifx∼N(T(y),Cx)|y=y¯, andJT=∂T∂yjj|y=y¯,Cycan be approximated as(JTTCx-1JT)-1[11]. When T is an analytical function,JTcan be computed without resorting to multiple evaluations. However, the applicability of this technique is limited to the cases whereT(y)uniquely defines a vector in the measurement space, e.g. a T projecting a 3D scene point to the image plane of a camera (BP in structure-from-motion). Of the minimal solvers studied in this paper (Section 3), only the two-view triangulation case satisfies this condition, with T being the perspective projection operator, which maps a 3D point to two unique 2D image points, through two known camera matrices: alone, a camera matrix or an epipolar geometry relation is not sufficient to identify a unique scene-image or image-image correspondence, respectively. Furthermore, most solvers either do not minimise the Mahalanobis distance (e.g. epipolar geometry estimation), or perform a constrained minimisation (e.g. metric calibration estimation). Therefore, we will not consider BP further as an alternative linearisation method.Given a set of measurements{xk}∼N(x¯,Cx),C^ycan be computed as the sample covariance of{yk}=S({xk}),(3)y¯ˆ=∑k=1LukS(xk),C^y=∑k=1Lwk(S(xk)-y¯ˆ)(S(xk)-y¯ˆ)T,whereukandwkare two sets of scalar weights, and L is the number of samples [5]. Both MC and SUT make use of Eq. (3), but differ in the way{xk}is generated.In MC,{xk}is randomly drawn fromN(x¯,Cx).ukandwkare uniformly set to1Land1L-1, respectively. However, the simplicity of MC comes with two problems: redundant parametrisations and the computational complexity.A parametrisation is redundant, when aD– dimensional entity is represented by Q parameters, withD<Q(e.g. a rotation matrix encodes the space of 3 dimensional rotations with 9 parameters:D=3andQ=9). Since there are D degrees-of-freedom, the rank ofCyis at most D. However, MC does not enforce this constraint, and, the rank could be as high as Q. This issue can be remedied by converting the estimated parameters to a D-dimensional, minimal representation, as discussed in Section 3.The computational complexity of MC is proportional to L, the number of samples in{xk}. However, accurate estimates ofy¯andCyoften require a large L[11]. Therefore, in terms of computational complexity, MC is usually impractical as a covariance estimator. However, sincelimL→∞C^y(L)=Cy, for sufficiently large L, it is considered a good approximation to the true statistics [5,7,11].SUT deterministically generates{xk}as aL=2M+1element sample set, for anM×1measurement vector [16]. Specifically, for the Cholesky decomposition(4)Cx=ΨΨT,the corresponding{xk}is constructed as [23](5)x1=x¯,xk+1=x¯+α2(M+κ)Ψk,k=1…M,xk+1+M=x¯+α2(M+κ)Ψk,k=1…M,whereΨkdenotes the kth row of the Cholesky factorΨ. α and κ are two scaling parameters, controlling the spread of{xk}aroundx¯.The weightsukandwkare calculated as follows [23]:(6)u1=1-Mα2(M+κ),w1=u1+(1-α2+β),uk=wk=12α2(M+κ),k=2…(2M+1),where β is a parameter used to incorporate prior information about known higher order statistics.Julier and Uhlmann [16] and Merwe et al. [23] discusses the selection ofα,κand β, and suggest optimal values forx∼N(x¯,Cx)(i.e. the case of interest for this work):•Merwe et al. [23] states thatκ⩾0guarantees a positive semi-definiteC^y, however the specific value is not critical. Therefore, it recommendsκ=0.α should be in[0,1]. Merwe et al. [23] recommends a small value when the transformation (i.e. S) is highly nonlinear.It is important that{xk}accurately characterises the distribution ofx. Whenx∼N(x¯,Cx), the moments of{xk}andxmatch up to the 3rd order [16]. Settingu1=1-M3ensures a match in some of the 4th order moments [16]. It is also shown in [16] thatβ=2minimises the error in the 4th order moments.Ifκ=0,u1=1-M3implies thatα=3M(Eq. (6)).Therefore, throughout the paper, we follow the recommendations for the Gaussian case, and setκ=0,α=3Mandβ=2. We specifically indicate the cases where a smaller α is chosen due to the nonlinearity of the solver.The computational cost of SUT is2M+1evaluations of S (as opposed to2Mof FOP), plus the Cholesky decomposition of anM×Mmatrix. However, under the assumption of independent measurements,Cxis either diagonal, or block-diagonal with2×2and3×3submatrices; therefore, the cost of the Cholesky decomposition is negligible.The formulation in Section 2 is not suitable for all minimal geometry solvers covered in this paper. Below is a presentation of the solver-specific issues, and implementation guidelines. Since all cases involve either image-image (2D–2D), or image-scene (2D–3D) correspondences as input,x¯is formed by concatenating the individual coordinates. The dimensionalities of the measurement and the parameter space are presented in Table 1.In order to maintain the focus on covariance estimation, we choose to omit a detailed discussion of the solvers. However, each section provides the relevant references for the interested reader, and a brief exposition is included in Appendix A. Unless otherwise stated, the parameters for SUT are set to the values mentioned in Section 2.2, and those for the minimal solvers, to the defaults recommended by the original authors.2-Point triangulation (T2) solver estimates the 3D coordinates of a scene point, given its 2D projections on the image planes of two known cameras. The solver we employ is the optimal triangulation algorithm [11].yis the triangulated scene point. The application of SUT and FOP is straightforward: it only requires the computation of the 3D points corresponding to the various perturbations of the original pair of image points (as discussed in Section 2).An epipolar relationYdefines a constraint of typepTYr=0, and describes the epipolar geometry between the images to which the image correspondence(p;r)belongs [11]. When the internal calibration parameters are unknown,Yis the fundamental matrix, and can be estimated via the 8-point (F8),1The 8-point algorithm is not a true minimal solver, as it does not use all available constraints.1or the 7-point (F7) method, which involves 8 and 7 image correspondences, respectively [11]. Otherwise, one solves for the essential matrix from 5 image correspondences (E5), via [19].Y, being a 3×3 matrix, is a redundant representation of the underlying entity: a fundamental matrix has 7 degrees of freedom, whereas an essential matrix has only 5. In order to avoid a singular covariance matrix,Ymust be reparametrised by a minimal representation.A 7-element minimal parametrisation for fundamental matrix can be obtained through the singular value decomposition (SVD) ofY, as proposed in [25]: given the decompositionY=USVT,UandVare rotation matrices, each of which can be encoded by a 3-parameter axis-angle vector. Since a non-degenerate fundamental matrix must be of rank-2,Sis a diagonal matrix with two non-zero entries. However, sinceYis a homogeneous entity, i.e.Y≡cY∀c∈R⧹{0}, it can be scaled so that the largest singular value is 1. Therefore, a fundamental matrix can be represented by 2 axis-angle vectors and a scalar. Computation of the sample statistics of parametrisations with a rotation component is discussed in Section 3.4.A non-degenerate essential matrix can be decomposed into a rotation matrix, and a rank-2 skew-symmetric matrix representing a unit-norm translation vector [11]. This decomposition forms the basis of a minimal representation: similar to the fundamental matrix case, the rotation component can be represented by 3 parameters, as an axis-angle vector. The translation component is a vector on the 3D unit sphere, and therefore, can be encoded by its azimuth and elevation angles. When the elevation is±π2, the azimuth can take any arbitrary value, which is chosen as 0.The epipolar geometry case poses an additional challenge to SUT and FOP: both methods assume that S is a one-to-one transformation. However, the solutions to the F7 and E5 algorithms are the roots of a 3rd and a 10th degree polynomial, respectively: there could be as many solutions as the real roots. We identified two strategies for such one-to-many solvers:•All solutions satisfy the epipolar constraint forx¯. However, barring degeneracies, only one can represent the epipolar geometry between the images. Therefore, a small set of additional matches can be used as a validation set, to identify the correct solution. This approach, effectively, makes a one-to-many solver one-to-one.Alternatively, one can estimate a separate covariance for each solution. However, it may not be obvious with which covariance a solution should be associated. Moreover, the number of real solutions may vary for different perturbations ofx¯.In practice, often the epipolar geometry is estimated from a redundant set of correspondences; therefore, in our experiments, we chose the former approach.This class of problems aims to find a mappingYthat satisfies the projective equality relationp≈Yrfor a homogeneous point correspondence(p;r).Yis estimated via the normalised direct linear transform algorithm (DLT) [11]. The instances we study are resectioning (i.e. projective camera matrix estimation) from 6 scene-image correspondences (P6P), and 2D homography from 4 image correspondences (H4).SinceYis a homogeneous transformation, identifyingywith the elements ofYleads to a redundant parametrisation, and a singular covariance matrix. Begelfor and Werman [27] proposes to mitigate this problem by characterising the uncertainty as a Lie-normal distribution. Although this distribution has a functional form that is superficially similar to a Gaussian, we deem it outside of the scope of this paper, which is limited to the covariance estimation, i.e. Gaussian characterisations. A more relevant, and common non-redundant representation involves the removal of the redundancy via a projection to a plane tangent to the unit sphere at the vector representation ofY[11,24]. Despite its success in 2D- and 3D-point cases [24], in our experiments, due to numerical issues, this approach occasionally resulted in rank-deficient covariance matrices: Fig. 1depicts the rank histogram for the H4 and P6P problems for a set of covariance matrices computed via the procedure described in Section 4.1.1 (steps 1–3), by using the parameter set N1 (Table 3) and the MC technique. As shown in Table 1, the rank of valid covariance matrices for H4 and P6P are 8 and 11, respectively.An alternative representation for H4 is inspired by the fundamental matrix case, discussed in Section 3.2: a homography can be decomposed into two rotations and two scalars, obtained via the SVD of the homography matrix. Unlike a fundamental matrix, there is no rank constraint for a homography matrix. Therefore, the scalars are the second and the third largest singular values, which are normalised with the largest singular value.As for the P6P, a projective camera matrix can be decomposed into a set of intrinsic and extrinsic parameters [11]. Although this may yield an improbable camera, with skew and aspect ratio exhibiting significant deviations from 0 and 1, respectively, the decomposition is an algebraically valid minimal representation.Both alternative parametrisations are equivalent to their “tangent-plane” counterparts, in that they represent the same entity. However, due to the numerical issues, they differ in their suitability for the covariance estimation problem: Fig. 1 indicates that, unlike the “tangent-plane” parametrisation [24], the decomposition-based parametrisations effectively mitigate the rank-deficiency problem. It should be noted that, since both methods operate on the same data, the observed difference cannot be explained by a degeneracy in the homographies involved.Upon decomposition, FOP and SUT can be employed without any issues, to obtain a full-rankC^y.A calibration estimator utilises the projective equality relationp≈Y(K,r)between the scene-image correspondence pair(r;p), induced by the projection operator Y, to recover K, the unknown internal and/or external calibration parameters. What K represents defines a sequence of progressively more difficult problems: 2-point orientation (P2P) [14]; 2-point orientation and focal length (P2Pf) [14]; 3-point orientation and position (P3P) [10,13]; and 4-point orientation, position, focal length and lens distortion coefficient (P4P) [15] (Table 2). All solvers except for P2P involve polynomial equations of varying degrees, hence yield multiple real solutions (up to 2, 4 and 12, respectively). There are two more issues specific to the calibration estimation problem: sample statistics of the orientation component, and the selection of α (Eq. (6)).Consider the P2P case, where the only output is the orientation. The use of Eq. (3) is not appropriate, as neithery¯ˆ, norS(xk)-y¯ˆis guaranteed to represent a valid rotation. Instead,y¯ˆcan be calculated as [18](7)qk=S(xk),y¯ˆ=argminq∑kuk‖R(qk)-R(q)‖F2,whereqandqkare quaternions,R(q)is the rotation matrix corresponding toq, and‖·‖Fis the Frobenius norm operator. As for the covariance, the difference quaternion is computed by inverse-rotation, and then converted to the axis-angle representation, to obtain a non-singular covariance [17]:(8)ak=A(qk⊗conj(y¯ˆ)),C^y=∑kwkakakT.In (8), ⊗ denotes the quaternion multiplication operator andconj(·), the quaternion conjugate. A converts a quaternion to an axis-angle vector.In other solvers, in which the orientation is only a part of the output, the mean orientation and{ak}, the set of orientation differences, are computed separately, and concatenated to the other components (e.g. focal length in P2P, and position vector in P3P) for use in Eq. (3). Sinceukmust be non-negative [18],α=1.Another issue with α stems from the smoothness of the manifold on whichx¯reside. α determines the magnitude of the perturbations. If the manifold is smooth, the perturbed points remain on the manifold. However, in some cases, the perturbation may result in anx, for which no real solution exists. In our experience, only P4P is susceptible to this problem, which can be mitigated by picking smaller α.

@&#CONCLUSIONS@&#
