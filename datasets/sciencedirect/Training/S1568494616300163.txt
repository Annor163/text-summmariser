@&#MAIN-TITLE@&#
Memory-based adaptive partitioning (MAP) of search space for the enhancement of convergence in Pareto-based multi-objective evolutionary algorithms

@&#HIGHLIGHTS@&#
Convergence was better improved by the MAP algorithm than by local search methods.MAP-NSGAII improved the convergence accuracy of NSGAII by a factor of 50 in average.Memory-based partitioning allowed avoiding unnecessary function calls (40% average).Convergence improvements were achieved for both unimodal and multimodal problems.

@&#KEYPHRASES@&#
Multi-objective evolutionary algorithms,Memory-based adaptive partitioning,Convergence improvement,

@&#ABSTRACT@&#
A new algorithm, dubbed memory-based adaptive partitioning (MAP) of search space, which is intended to provide a better accuracy/speed ratio in the convergence of multi-objective evolutionary algorithms (MOEAs) is presented in this work. This algorithm works by performing an adaptive-probabilistic refinement of the search space, with no aggregation in objective space. This work investigated the integration of MAP within the state-of-the-art fast and elitist non-dominated sorting genetic algorithm (NSGAII). Considerable improvements in convergence were achieved, in terms of both speed and accuracy. Results are provided for several commonly used constrained and unconstrained benchmark problems, and comparisons are made with standalone NSGAII and hybrid NSGAII-efficient local search (eLS).search spacepartitioning multiplierstep size for a given search space iPareto front improvement within the last r generationsEuclidian distancerestricted search space ihypervolume indicatorvariable importanceinverted generational distancehypervolume distance between the Pareto optimal front and an approximated Pareto frontinterval numbers relative to a same category of variables ipartitioning degreenumber of objective functionsmemory matrixpopulation sizenumber of variablesstatistical p-valuepopulationPareto frontoptimal Pareto frontpartitioning tendencypartitioning vectorsolution belonging to a restricted search spaceD_ivector of decision variablesvector of restricted decision variablesvector of congruent variables ivector of restricted congruent variables imaximum value in a set of restricted congruent variablesx˜_iminimum value in a set of restricted congruent variablesx˜_imatrix of restricted solution vectorslowerupper

@&#INTRODUCTION@&#
Real-world optimization problems usually involve several conflicting objectives. The main aim in multi-objective optimization is to select the best trade-offs among these conflicting objectives. Multi-objective optimization problems (MOPs) can be mathematically stated as,(1)MinimizeFx=f1x,…,fmxSubjecttox∈Λwhere, m is the number of objective functions, x∈Λ is the vector of decision variables, andFxconsists of m objective functionsfix. Conflicting trade-offs occur when an improvement in one objective function mirrors the deterioration of another one. Given two solutions x1 and x2, the solution x1∈Λ is said to dominate x2∈Λ if and only iffix1≤fix2for all objective functions andfix1<fix2on at least one objective function, and is designated by x1≺x2. The Pareto front comprises all the optimal solutions belonging to the set of non-dominated optimal solutions known as the Pareto Set (PS).Multi-objective evolutionary algorithms (MOEAs) [1–3] are regarded as promising methods for dealing with MOPs, owing to their ability to generate a population of solutions for efficiently approximating the diverse set of optimal solutions in a single run. Traditionally, MOEAs use derivative-free search algorithms [4], adapted to situations with different degrees of complexity: non-linear, stiff, black-box, and multimodal. Indeed, due to their population-based trait, MOEAs provide a wide range of conflicting alternatives for design (regarding the Pareto front), equivalent to an appropriate decision-making plan.Since MOEAs were first implemented, following Schaffer [5]’s development of the vector evaluated genetic algorithm (VEGA), they have undergone considerable improvements, gaining a high profile and prompting many discussions. An interesting survey undertaken by Zhou et al. [6] highlighted the extensive developments made to MOEA frameworks over the past 10 years, ranging from decomposition-based (MOEA/D), preference-based, indicator-based, memetic and co-evolutionary MOEAs, to MOEAs with specific search methods and metaheuristics. Two main currents can be identified, each meeting to a contemporary scientific and industrial need: (i) improvements in the convergence accuracy/speed ratio for MOEAs, through the development and integration of new and efficient metaheuristics [7–11]; and (ii) the processing of expensive MOPs [12–14], the aim is to reduce the high numbers of physical experiments or time-consuming simulations that are currently performed.The present study concentrated on the first current; seeking to improve the accuracy/speed ratio in MOEAs by refining the search space with no aggregation in objective space and no deterioration in the formulation of MOPs. To this end, we developed a memory-based adaptive partitioning (MAP) algorithm, applicable to the structure of Pareto-based MOEAs. In the context of the present study, the term speed corresponded to the number of function evaluations required to achieve convergence toward an optimal Pareto front, in order to be able to compare different algorithms independently of the performance of the computing facilities used.It should however be noted that in the two main fields of research mentioned above, more attention has been generally paid to behavior in the objective space, rather than in the search space. A rare exception to this general tendency is the use of harmony search algorithms in multi-objective optimization, despite their major drawbacks, e.g. the low convergence and diversity performance. For instance, Dai et al. [15] investigated a self-adaptive multi-objective harmony search (SAMOHS) algorithm based on harmony memory (HM) variance. The harmony search comprises a memory-based stochastic search technique, where each solution is expressed by a real vector, dubbed a harmony. The memory will be updated if a better newly generated harmony can be found. SAMOHS was reported as being able to overcome the well-known drawbacks of MOHS, by providing enhanced local and global search abilities, and by applying a novel self-adaptive mechanism to the search algorithm.Much of the contemporary literature on MOEAs deals with aggregated objectives. An aggregation-based approach entails either the conversion of MOPs into Single-objective Optimization Problems (SOPs) or else the decomposition of MOPs into a number of scalar objective optimization problems (parallel SOPs). One of the reasons why aggregation-based approaches are so commonly used in MOEAs is that most ingenious search algorithms were initially invented within an SOP landscape. Based on the same conventional aggregation approach, other methods, such as MOEA/D [16], involve decomposing an MOP into a number of sub-problems (SOPs). Each SOP is then optimized in a collaborative manner, using information provided by its neighboring SOPs. Here, the objective for each sub-problem is the weighted aggregation of the individual objectives. MOEA/D is a recent and very efficient MOEA that has been successfully applied in a number of areas. Moreover, by transforming an MOP into a parallel set of SOPs, advanced local search metaheuristics such as iterative local search (ILS), greedy randomized adaptive search (GRASP) or tabu search can easily be incorporated [17]. MOEA/D is therefore suited to the incorporation of other local search methods and selection operators. For instance, the combination of a new bandit-based adaptive operator selection (AOS) in MOEA/D [18], and the new memetic MOEA/D framework proposed by Qi et al. [19] can be mentioned. AOS allows the automatic selection of appropriate operators in an online manner within an optimization process. In the new memetic MOEA/D framework [19], a novel selection operator was designed to overcome limitations related the established Tchebycheff metric widely used in the original MOEA/D, together with three local search methods (Swap, Lamda interchange, Single route 2-opt) in order to deal with the multi-objective vehicle routing problem with time windows (MO-VRPTW).The focus of the present study, however, was neither to modify commonly used frameworks and their evolutionary operators done by Alberto et al. [20], or by Yevseyeva et al. [21] in their new approach to selection in MOEAs based on portfolio selection problem, for instance, nor to reorganize the objective space and objective functions, as in the case of MOEA/Ds or clustering in multi-objective particle swarm optimization [22,23]. Rather, we sought to highlight the importance of search space refinement for improving convergence in MOEAs by preserving MOPs in their original multi-objective formulation. This is why we did not investigate aggregation-based MOEA frameworks. It should also be noted that the aggregation of objectives results in a prior ordering of objectives, where realistic interactions among objectives and their importance are susceptible to misevaluation or loss.Despite their impressive capabilities, EGO-based frameworks such as ParEGO [14], SMS-EGO [13] and MOEA/D-EGO [12] were not included in our comparisons, because these methods are primarily used to deal with computationally expensive MOPs or when the computational budget in terms of function evaluations is extremely limited. It should be noted that when MOPs involve time-consuming simulations, it is sometimes useful to provide model-assisted algorithms with high computational complexity, in order to restrict the number of function evaluations required. However, in the case of SMS-EGO, this can result in a considerable increase in calculation time (several hours for a test problem with 8 variables and 200 function evaluations). MOEA/D-EGO involves the decomposition of MOPs. It uses parallel computations, where the algorithm builds a Gaussian stochastic process model for each of the sub-problems and simultaneously optimizes their improvement. The Gaussian stochastic process model is one of the most popular methods for dealing with expensive problems.In recent decades, special attention has been paid to hybrid and memetic MOEAs, all the while acknowledging that original evolutionary algorithms result in a lower level of accuracy for optimal solutions, compared with deterministic approaches. The general trend in the hybrid approach is either to combine global and local search patterns, or else to combine the search operators of different algorithms. The framework of memetic MOEAs incorporates local search methods, to speed up convergence and provide better accuracy, deeply motivated by varying applications from engineering to business, economics, and finance [24–26]. Since our focus was on improving the convergence accuracy/speed ratio in MOEAs, we looked at both hybrid and memetic MOEAs in order to conduct a fair comparison. It should, however, be admitted that if an efficient memetic or hybrid MOEA algorithm offers simultaneous improvements in both accuracy and speed, the latter may also be regarded as a potential solution for processing expensive MOPs.The local search metaheuristics involved in hybrid MOEAs perform either neighborhood-based or directional local searches. A neighborhood-based approach provides perturbations around a given solution to improve convergence [9]; while with a directional local search, a search direction is determined either by running a sensitivity analysis of objective functions [8] or by using previously evaluated solutions in neighborhoods to progressively build an efficient search direction [7]. Additional function evaluations are required to explicitly determine gradient vectors in the objective space for sensitivity-based directional local searches.The combination of evolutionary algorithms and local search methods can be made in two ways: only applying local search methods to the final solutions yielded by the evolutionary algorithms [11]; or implementing them as supplementary search engines within the main evolutionary algorithm framework [7,8,27]. Deb and Goel [11] applied a hill climbing local search method to the final solutions of evolutionary algorithms. Lara et al. [8], on the other hand, introduced a new gradient-free local search strategy, known as the Hill Climber with Sidestep (HCS), within the NSGAII and SPEA-2 state-of-the-art frameworks, creating a new memetic MOEA. This hybrid HCS-MOEA framework was shown to improve performances for unimodal functions such as CONV1, CONV2, and DTLZ2. The hill climber tries to improve convergence to the Pareto front, while the sidestepper provides a lateral search for a better solution spread. As HCS is gradient-free, it utilizes the randomly generated neighbors of a present solution within a given radius in the search space. The line search procedure for HCS is to minimize a convex single objective by quadratic polynomial fitting. Inspired by the HCS local search operator, Kim and Liou [7] introduced a novel directional local search operator for EMOAs, called efficient local search (eLS). This uses a hill climbing method to improve convergence, but does not adopt the sidestepper in order to reduce the number of additional function evaluations. eLS follows a similar line search procedure to HCS except that eLS minimizes the aggregated and normalized composite objective, instead of running separate line searches for each objective function. The algorithm also performs adaptive tuning of the two sensitive local search parameters: local search probability and neighborhood search radius.The recent hybrid MOEA-HCS and MOEA-eLS are among the most promising metaheuristics for improving the accuracy/speed ratio in MOEAs. In the present study, however, we only included the hybrid eLS in our comparisons, owing to its memory-based peculiarity of performing directional local search through previously evaluated solutions in the neighborhood without sidestepping. This procedure is intended to considerably reduce the number of additional function evaluations.In the following sections, we begin by introducing the MAP algorithm. The state-of-the-art fast and elitist non-sorting genetic algorithm (NSGAII) developed by Deb et al. [3] was chosen to show how MAP can be integrated within a conventional MOEA framework and to demonstrate its ability to enforce convergence in a given Pareto-based MOEA. The hybrid MAP-NSGAII is then compared with both the original standalone NSGAII and the hybrid NSGAII-eLS, using several commonly used constrained and unconstrained multi-objective benchmarks. In order to perform a fair comparison, both extreme local search probabilities in NSGAII-eLS (5% and 100%) were investigated.The main feature of the memory-based adaptive partitioning (MAP) algorithm is the amount of attention paid to partitioning the search space, bearing in mind that efforts to bring about improvements in contemporary MOEA frameworks are generally focused on the objective space. The Adaptive Partitioning algorithm, on the other hand, is primarily based on a partitioning of the search space. Fig. 1illustrates such partitioning for a two-dimensional search space with decision variables x1 and x2∈R, where instead of searching optimal solutions in infinite real-type search spaces (R2), search efforts are reduced to limited number of restricted solutions (here, s1,jands2,j∈D1_andD2_, ∀j=1, …, total number of intervals). However, the so-called partitioning of search space is dynamic and adaptive, which is to say that the discretization degree over each search space varies independently during the calculations, the more the need to attain better accuracy rises and the more the tendency to proceed to a deeper partitioning of search space is amplified.In order to tune the number of discretization intervals for each decision variable space (see Section 2.2), the design of the partitioning algorithm described here was driven by two main key parameters: partitioning tendency (PT), and relative importance (Ii). PT, common to all search spaces, refers to the general tendency to increase or decrease the number of discretization intervals as a function of the overall improvement in the quality of previously evaluated Pareto fronts (see Section 2.2, Step 6). By contrast, Iirefers to the fast sensitivity-like information, specific to each decision variable, that allows the global partitioning tendency to be independently adjusted for each decision variable (see Section 2.2, Step 7).An unlimited real-type search space can thus be restricted to a limited number of real-type solutions. Moreover, a memory is used to store previously evaluated solutions, in order to avert the unnecessary evaluation of new solutions that are close to them.The hybrid Pareto-based MAP-MOEA framework rearranges search efforts in variable spaces more efficiently and at the same time preserves the pertinent global search faculty of evolutionary operators through a population of solutions.The MAP algorithm is intended to steer optimization operations at a relevant level of accuracy with an optimal computational requirement in terms of function evaluations. In the present study, the MAP algorithm was integrated within an MOEA as an efficient search space monitoring and refinement tool, in order to enhance the convergence accuracy/speed ratio. Fig. 2illustrates the flow diagram of the MAP-MOEA framework developed and investigated here.The present study adopted NSGAII developed by Deb et al. [3] for evolutionary operations and non-dominated sorting (Fig. 2, parts with no highlighting). The initial set of solutions, together with any new offspring generated by MOEA, is continually readjusted through restrictions provided by the MAP algorithm (Fig. 2, parts highlighted in gray). The first three operations in the MAP algorithm (search space partitioning, restriction of solutions, and memory-based evaluations) serve to filter and restrict any new MOEA solution, while the fourth one (dynamic parameter refining), dynamically tunes the discretization intervals per decision variable space, according to the overall improvement in the quality of previously achieved Pareto fronts. These operations are extensively explained in Section 2.2 and illustrated as a flow diagram in Fig. 3.When given an MOP, the MAP algorithm adaptively refines the search space, in order to achieve faster (fewer function evaluations) and more accurate convergence. In this section, a step-by-step description of operations within the MAP algorithm is provided. A summary of these different operations is also provided in Fig. 3.According to the MOEA framework, an initial random population of solutionsP0xk∈Rnv,∀k=1,…,N, well-distributed on variables by linear regression between upper and lower bounds of variables must be provided at the beginning; where, N is the population size. Each solution vector xkin P0 involves nVindependent variablesxkxk,i∈R,∀i=1,⋯,nV. MOP has as many real search spaces as the number of variablesnv.Step 1: A partitioning vector PV is defined by collecting the number of intervals (INi), provided through the last dynamic parameter refining (see gray arrow between dynamic parameter refining and search space partitioning blocks, Fig. 2), and chosen to homogenously discretize the search space. In the present study, INiwere chosen to delimit the discretization of search space by a minimum partitioning tendency PTminand a maximum PTmaxintervals (INi∈PTmin,PTmax). PT is a general parameter that indicates the overall tendency, common to all variable spaces, to increase or decrease the number of discretization intervals. The statistical analyses in Section 3.5 provided the optimal values of PTminand PTmaxfor all the test instances investigated in this paper.Initially, all the INivalues were set to their minimum value (PTmin), thusPV0=PTmin,⋯,PTmin, where the size of PV0 is equal to the number of variables.(2)PT0=PTmin(3)INi0=PT0,∀i=1,…,nV(4)PV0=IN10,…,INnv0=PTmin,…,PTminStep 2: Next, each search space is partitioned by the PV's INivalues. Givenx˜ix˜i,k=xk,i∈P,∀k=1,…,Na vector of all congruent variables i in the population,•Search spaces are partitioned through their INi. For each vector of congruent variablesx˜i, a partitioning step size is defined:(5)Δx˜i=x˜iu−x˜il/INiwhere,x˜iu,x˜il∈Rare variable boundaries the same for all variables of the same type.New restricted search spacesD_i,∀i=1,…,nvare defined per variable type,Step 3: New restricted sets of congruent variables are then proposed by projectingx˜ionto the partitioned search space, resulting in a new set of restricted congruent variablesx˜_i∈D_i, as follows:•The value of a variable xk,ibelonging to an interval j bounded bys_i,j,s_i,j+1∈D_i(Fig. 4), will be restricted (replaced) by either the upper or the lower boundary value of that interval, whichever is closer, resulting in a new restricted variablex_k,i:(7)x_k,i=s_i,j∈D_iifxk,i−s_i,j<s_i,j+1−xk,is_i,j+1∈D_ielseA new matrix of restricted solution vectorsx_x_k,i,∀k=1,…,N,∀i=1,…,nvis this formed and the population is updated:x_→PIn other words, each projection generates a new restricted search spaceD_i, for a given category i of variables. The progressive reticulation of the search spaces has three main benefits:(1)The initial search space containing infinite possibilities ∈R is reduced to a limited circle of restricted solutions∈D_i, considerably reducing search efforts;Areas of global optimality can rapidly be detected, with substantially fewer function evaluations, if the algorithm starts by grossly partitioning of the search space;As the search space is reduced to a limited circle of finite real values, a memory can be constructed, thereby avoiding multiple evaluations of adjacent solutions.Step 4: A memory matrixMis gradually constructed and enriched, by incorporating new restricted solutionsx_k,∀k=1,…,N. Ifx_kalready exists in the memoryx_k∈M, the previously evaluated objective values will be used for any new solution. Otherwise, a function call will take place and the results will be added to the memory. This information exchange was illustrated in Fig. 2 by gray arrows between the memory matrix and the evaluation block.Step 5: The reticulation of each search space is gradually and independently readjusted by dynamically refining the key partitioning parameters as a function of the Pareto front improvement or stagnation. Here, stagnation is deemed to occur when no improvement in the PS is detected.The hypervolume indicatorHVIof P is then provided, indicating the quality of the current Pareto front, and the results are recorded in a history vector. In the present study, the HVI calculations were based on the dimension-sweep method [27]. The evolution or stagnation of the Pareto front is continuously verified by evaluating the normalized standard deviation over the last r HVI values relative to the last r generations,(8)Er=∑i=1r(HVI¯−HVIi)2/(r.HVI¯2),whereHVI¯=∑i=1rHVIi/rStep 6: If stagnation is detected in the HVI values (here, for Er<10−3), PT is updated in a probabilistic fashion. PT can be either doubled or halved (here, the multiplier Ω=2 was chosen), to increase accuracy or avoid further partitioning if a reasonable partitioning degreekˆhas already been attained. Given a real random numberβ∈0,1,(9)PT=PT×2:ifβ>kˆ/kˆmax+1andPT<PTmaxPT÷2:elseifβ≤kˆ/kˆmax+1andPT>PTminThe parameterkˆindicates how frequently a minimum PT (PTmin) has been doubled since the outset.(10)PT=PTmin×ΩkˆIn this fashion,kˆcan be ranged from a minimum valuekˆmin=0to a maximum valuekˆmax=lnPTmax/PTmin/ln2. The current value ofkˆis then determined as follows,(11)kˆ=lnPT/PTmin/ln2The so-called probabilistic procedure helps to adaptively bias the probabilities of PT doubling and PT halving, according to the current PT (Table 1). Table 1 shows that when PT values are low, the algorithm mostly tends to increase PT. However, when PT values are high, it tends to decrease it. In order to avoid a sudden shift to one of the boundary values PTminor PTmax, a nonzero probability for both repartitioning modes (doubling and halving) for all PT>PTmin, is simultaneously maintained.Step 7: In most Pareto-based MOEA frameworks, attention is focused solely on the analysis of objective values in the PS. The main reason for this may be to avoid the computational complexity of MOEAs being increased by further sensitivity-based operations. As a result, information is seldom inferred from the fluctuation of variables in the PS, even though it could help to steer future rearrangements of the search space. One alternative is to identify the overall fluctuation of variables onto each set of restricted congruent variablesx˜_i, by directly observing their upper and lower values (x_˜i+andx_˜i−, respectively). For each set of restricted congruent variablesx˜_i,(12)x_˜i+=maxx˜_ix˜_i,k,∀k=1,…,N(13)x_˜i−=minx˜_ix˜_i,k,∀k=1,…,N,withNequaltothepopulationsizeRelative importance can thus be assigned to each set of restricted congruent variables:(14)Ii=x_˜i+−x_˜i−maxx_˜j+−x_˜j−,j=1,…,nVAt this level (Step 7), all the variables must be normalized∈0,1.Step 8: For a given population, the importance parameter (Ii) induces the effective variation of each set of restricted congruent variablesx˜_i. In other words, Iiprovides a fast sensitivity-like evaluation of variables, based on the solutions in the current PS. If sensitivity for a given category of variables is high, importance increases, and vice versa. In addition to the current PT, which is common to all variables, the INifor each category of variables can then be adaptively refined, by allocating their relative importance Ii:(15)INi=PTmin×2Ii×kˆ−kˆmin+kˆmin,∀i=1,…,nvPV can thus be updated by new values of INi, and used to discretize search space in a manner better suited to the next generation. To this extent, PV is heterogeneously refined, generation after generation, to achieve two goals: an increase in accuracy for specific congruent variables when needed, and a reduction in unnecessary search efforts within the search space of insensitive variables.A broad set of unconstrained test problems similar to those proposed by Alberto et al. [20] and Huang et al. [28] was studied, in order to determine how MAP performs in situations of differing complexity and high dimensionality. Table 2provides a brief description of these well-known test problems, for which the Pareto-optimal front is known.This computational study was extended by considering five multi-objective test problems (see Table 3). These included the three constrained problems (CONSTR, SRN, and TNK) investigated by Deb et al. [3], and two complex constrained problems with disconnected Pareto-optimal fronts (CF1 and CF2) [29]. All the constrained test problems mentioned and investigated here are provided in Appendix A.To carry out a fair comparison, the NSGAII's two original evolutionary operators were chosen: the simulated binary crossover (SBX) [30] with ηc=15 and pc=1, and the polynomial mutation operator with ηm=20 andpm=1/nv. The population size was set at 100 for all frameworks. For the unconstrained problems, we set the total number of decision variables at 30 for both unimodal and multimodal test instances. The computational budget was limited to 3000 function calls for bi-objective test problems (here, the ZDT problems), and 10,000 function calls for three-dimensional test problems (here, the three-dimensional DTLZ family).For the constrained problems, the number of decision variables was set at two for CONSTR, SRN and TNK, and the computational budget was limited to 3000 function calls. However, for CF1 and CF2, four decision variables were considered, and a larger computational budget of 40,000 function calls was fixed, owing to the highly complex nature of these two constrained problems.The constrained binary Tournament selection and the principle of constrained-domination proposed by Deb et al. [3] were used to handle constraints. In binary Tournament selection, there are three possibilities: (i) neither solution is feasible; (ii) only one solution is feasible; or (iii) both are feasible. For the first case, the solution with the smallest constraint violation was chosen, whereas for the second, only the feasible solution was selected. For the third, the constrained-dominating solution was chosen, with a modified definition of domination:A solution j is constrained-dominated by a solution i, if any of following conditions is true:(1)Neither solution is feasible, but solution i has a smaller constraint violation;Solutioniis feasible, whereas solution i is not;Both solutions are feasible, but solution i dominates solution j, following the principle of non-domination in multi-objective optimization.MOEA performances are measured by unary quality indicators. The inverted generational distance (IGD) and hypervolume difference indicatorIH−are among the most commonly used. The hypervolume indicator (HVI) was calculated by the dimension-sweep method [27].IH−was the difference between the HVI values of the Pareto-optimal front and the current population P (the smaller, the better).The IGD between a set of points uniformly distributed across the Pareto-optimal front PF* and an approximation of the Pareto front (PF) is defined as:(16)IGD=∑ni=1dinwhere n is the number points in PF*, and diis the minimum Euclidian distance between a reference solution i and non-dominated solutions.IH−allows the quality of a given Pareto front to be indicated in terms of both convergence and diversity. However, according to IGD a sufficient number of uniformly distributed points over the optimal Pareto front must be provided (500 for 2D test instances, and 1000 for 3D test instances), if both convergence and diversity for a given Pareto front are to be verified. In the present study, bothIH−and IGD were adopted as the unary quality indicators. If known Pareto fronts with a sufficiently high number of uniformly distributed points are used, IGD andIH−should yield the same indications.Statistical analyses allowed to tune of the two important parameters PTminand PTmax, and justified the values initially established as PT boundaries (see Section 2.2). Based on the commonly used benchmark test functions described earlier (see Section 3.1), Table 4summarizes the best parameter tunings, resulting in the optimal values of 10 and 320 for PTminand PTmax, respectively. The optimal values in Table 4 are highlighted in gray, corresponding to the minimum number of times a parameter value was dominated by others.Given the limited computational budget (function evaluations), MAP-NSGAII was compared with three other frameworks (original standalone NSGAII, NSGAII-eLS(5%) and NSGAII-eLS(100%)) on accuracy and computational speed. Two extreme local search probabilities in eLS (5% and 100%) were selected, in order to ensure a fair comparison between the two extreme functioning rates of their metaheuristics.For statistical reasons, each framework was run 30 times. The Kruskal Wallis statistical test (Conover [31]) was adapted with a p value below 0.05 (95% confidence level). Fig. 5shows the results of statistical analyses of theIH−and IGD values (the smaller the better) obtained for the bi-objective ZDT test problems using the four above-mentioned frameworks. Calculations were based on a maximum computational budget of 3000 function calls for all test cases and all frameworks. A net improvement in the accuracy of the final Pareto front was observed when we introduced the MAP algorithm into the NSGAII framework. This was true for both the unimodal (ZDT1, ZDT2) and multimodal (ZDT3, ZDT4, ZDT6) test problems (Fig. 5). It should be noted that the convergence of Pareto-optimal fronts underwent a considerable shift in accuracy (by a factor of 10 on average) when the hybrid MAP-NSGAII was used.Moreover, Fig. 6shows a very satisfactory diversity in the Pareto-optimal fronts yielded by MAP-NSGAII. Those yielded by other methods were either incomplete or distant from the Pareto-optimal fronts, owing to the limited computational budget. It should be noted that a maximum budget of 3000 function calls is extremely limited for a population of 100 individuals. In terms of the-state-of-the-art NSGAII, this is equal to 30 generations of genetic operations.For NSGAII-eLS(5%) and NSGAII-eLS(100%) the local search radius was set at its maximum of 1.0, as Kim and Liou [7] observed that the maximum local search radius and adaptive local search radius give rise to similar maximum algorithm performances. Fig. 5 shows that NSGAII did not bring about any significant improvement in bi-objective test instances, even when eLS was applied. This was presumably due to our limited computational budget (3000 function calls), compared with that chosen by Kim and Liou [7] (20,000 function calls) using relatively similar general settings. It should be noted that NSGAII-eLS looks for previously evaluated solutions in the neighborhood. Its performance should logically appear after a reasonable number of function calls.Another interesting point arising from this primary analysis of the Pareto quality indicators for the ZDT test problems is the strong search capacity of standalone NSGAII during the first generations, compared with that of the two hybrid NSGAII-eLS frameworks.By focusing on the three-dimensional DTLZ test problems (Fig. 7), we again observed a net improvement in the accuracy of the final Pareto front when the search space was adaptively refined by the MAP algorithm (here, MAP-NSGAII). Results for DTLZ1, DTLZ2 and DTLZ3 attested the ability of NSGAII-eLS(100%) to attain satisfactory convergence accuracy, in comparison with NSGAII and NSGAII-eLS(5%) (Fig. 7). This was due to the relatively high number of function evaluations authorized for the three-dimensional problems (10,000). Nonetheless, MAP-NSGAII achieved the greatest convergence accuracy, even though no parallel local search procedure was used to enhance convergence accuracy.The shapes of the final Pareto fronts for the DTLZ test problems and the MOEA frameworks used to calculate them are given in Fig. 8. The standalone NSGAII had by far the greatest convergence difficulty. NSGAII-eLS(100%) yielded more acceptable Pareto front distributions for the DTLZ2 and DTLZ3 test problems than NSGAII and NSGAII-eLS(5%).Fig. 9shows the convergence rates based on the improvement rate ofIH−values for all the frameworks. The overall improvement rate was better for MAP-NSGAII than for all the other frameworks investigated, indicating that MAP-NSGAII ensures not only greater accuracy for the Pareto-optimal front for a fixed computational budget (owing to its adaptive refinement of the search space), but also greater speed. We can therefore conclude that the MAP algorithm represents a promising new approach and considerably enhances both accuracy and speed in the convergence of NSGAII.MAP-NSGAII was also compared with other NSGAII-based frameworks on constrained problems (Table 3). For statistical reasons, each framework was run 30 times. The results for the quality of convergence are provided in Fig. 10, based on a maximum computational budget of 3000 function evaluations for CONSTR, SRN and TNK, and 40,000 for CF1 and CF2. These results indicate more or less the same quality of convergence with NSGAII, NSGAII-eLS(5%) and MAP-NSGAII, for these computational budgets. Nevertheless, when we look at the improvement rate of Pareto fronts for CONSTR, SRN and TNK in Fig. 12, we see MAP-NSGAII had a far greater convergence speed than the other frameworks. CF1 and CF2 are complex constrained problems, where both objective functions and constraints are highly nonlinear and the Pareto-optimal fronts are discontinuous with additional isolated points. As we saw with the disconnected ZDT3 Pareto-optimal front in Fig. 5, the convergence speed of MAP-NSGAII for CF1 and CF2 decreased, such that it was equal to or even lower than that of NSGAII.Fig. 11illustrates the shapes of Pareto-optimal fronts for the constrained problems. In CONSTR, part of the unconstrained Pareto-optimal front was infeasible. In SRN, the constrained Pareto-optimal set was a subset of the unconstrained Pareto-optimal set. TNK had a disconnected Pareto-optimal zone, and failed completely at the first constraint boundary. CF1 and CF2 both had disconnected Pareto-optimal fronts with isolated solution points. These two problems were mainly selected to evaluate MAP's performance when applied to stiff problems with extremely limited feasible zones.To provide a more practical vision of the MAP strategy, the interactions between the three main partitioning parameters, namely:PT, INi, and Ii, were examined for DTLZ1, DTLZ2 and DTLZ3 (see Fig. 13), based on new independent runs. An increase in PT exhibits an overall tendency toward deeper partitioning of the search space (Fig. 13(c)). When we compare PT variations (Fig. 13(c)) with HVI variations (Fig. 13(e)) for the unimodal problem DTLZ2, we can see that PT mostly increased in near convergence conditions. By contrast, for the multimodal problems (DTLZ1 and DTLZ3), the increase in PT occurred at the beginning, during the exploration phase (e.g. by comparing Fig. 13(c) with 13(e) for DTLZ3 test problem). PT is, in fact, a general indicator of the reticulation of search space, based on the evolution of Pareto front Er(Fig. 13(d)). Practical observations identified Ernot to be sensitive. Consequently, all values of Erbelonging to [10.E-2, 10.E-8] led to the same quality of Pareto-optimal fronts. As can be seen in Fig. 13(a), INiapplied the partitioning tendency (PT) solely to the categories of important congruent variables, by following their relative importance (Ii) (Fig. 13(b)). After the first exploration phase, when zones of global optimality were detected, partitioning increased for a few selected sensitive variables. Likewise, as illustrated in Fig. 13(b), most Iivalues tended to decrease after this initial exploration phase, apart from a few sensitive congruent variables and their corresponding search space (sensitive congruent variables are indicated by bold green lines in Fig. 13(a) and (b)).Memory use is one of the important issues related to the MAP algorithm. A new restricted solution is only evaluated if it is not already stored in the memory. Hence, the size of the memory matrix is equal to the total number of function evaluations carried out up to that point (x-axis in Fig. 14). This means that the size of the memory matrix can be monitored by tracking changes in the total number of function evaluations. Moreover, we can indicate the proportion of non-dominated solutions in the matrix among the non-dominated fronts, and how this proportion varies during the search. Fig. 14 illustrates just such a variation in the number of Pareto-optimal solutions in memory during search efforts. A total number of 10,000 function evaluations was fixed ZDT1, ZDT4 and DTLZ1. Fig. 14 shows that the number of non-dominated solutions in memory exceeded 300 for ZDT1 and ZDT4 after 10,000 function evaluations, while it reached 200 for the 3D DTLZ1. It should be noted that the number of function evaluations (or memory matrix size) corresponding to a total number of 100 Pareto-optimal solutions in memory (population size fixed for the algorithm) represented the maximum size of memory required to attain the first satisfying and high-quality Pareto-optimal front. Accordingly, the maximum memory size required was 3000 for ZDT1, 3000 for ZDT4, and 4000 for DTLZ1. This is also in keeping with the improvement rate of Pareto fronts for the test problems mentioned in Fig. 9. As we can see in this figure, Pareto-optimal fronts for ZDT1, ZDT4, and DTLZ1 reached convergence after 3000, 3000, and 4000 function evaluations.The numbers of function evaluations per test instance that were avoided owing to the memory-based feature of the MAP algorithm are shown in Fig. 15(referred to as “memory use (%)”). In order to illustrate all the 2D and 3D test instances together, the total number of function evaluations along the x axis has been normalized (%). We would expect to observe less memory use during the initial search phase, dominated by exploration. The lowest levels of memory use were observed for the multimodal problems, which usually have a longer exploration phase. The shift in memory use for all test instances (Fig. 15) was directly related to the shift in HVIs (Fig. 13(e)). When a population of solutions approaches the optimum solutions (near-convergence conditions), it triggers deeper exploitation and finer partitioning. Increased reticulation of the search space gives rise to greater accuracy, while increased memory use during the exploitation, reduces the number of unnecessary function evaluations in the immediate vicinity of insensitive variables.The probabilistic nature of the search algorithms suggests that evolutionary algorithms may lack robustness in finding solutions. This issue is generally examined in relation to the effect of the algorithm starting conditions or control parameters on the robustness of the search in finding near-optimum solutions. Though the MAP algorithm performs, however by providing an initial population of solutions, well-distributed on variables by linear regression between upper and lower bounds of variables. Providing a well-distributed initial population is quite important for the algorithm so that it can conduct an efficient global search during the exploration phase. Otherwise, if random initialization procedure is used, the robustness of algorithm can be disrupted, as illustrated in Fig. 16.In Fig. 16, the robustness of algorithm was examined for a set of four representative test functions (unimodal and multimodal). The robustness was expressed in terms of the variability of final approximation of Pareto fronts from different random initial solutions. The vertical axis expressed in terms of inverted generational distance (IGD) depicts the distance in the objective space between the final Pareto fronts approximated and their well-known optimal Pareto front. While the horizontal axis, illustrates the spread of the initial solution in the variable space. Here, the spread in the variable space is described by the average normalized Euclidean distance (ANED) between a set of solutions (X), which in the present case is the set of initial solutions, and those belonging to the optimal Pareto set (X*).(17)ANED=∑ni=1diX,X*nHere, diis the minimum Euclidian distance between a given solution i and the non-dominated solutions, and n is the total number of points over PF*. The optimal Pareto set is represented by X*, and corresponds to a set of points uniformly distributed across the optimal Pareto front PF*.For each test function, the robustness of algorithm with random initialization procedure (+ marks in Fig. 16) was compared to the proposed initialization procedure in this work using a linear regression between upper and lower bounds of the variables (● marks in Fig. 16). It can be observed that the random initialization procedure could not provide a good convergence quality (high IGD values in Fig. 16), while additionally deteriorating the algorithm robustness (fluctuating IGD values). On the contrary, when a good coverage was provided in the initial population through the linear regression between upper and lower bounds of variables, an excellent convergence quality was attained, owing to the potential of a well-distributed initial population to afford proper exploration in the variable space at the beginning of the search.The influence of partitioning parameters such as partitioning tendency (PT), relative importance (Ii), and number of partitioning interval per variable (INi) on the convergence performance were extensively discussed in Section 3.8 and illustrated in Fig. 13(a)--(c). Additional information on the tuning of partitioning tendency boundaries were given in Section 3.5 where the values 10 and 320 were set for PTminand PTmax, respectively, to maintain the robustness of the MAP algorithm.The flexibility comes with choosing appropriate and tangible operators so as to create an efficient and consistent search. It is more precisely related to the generality and reversibility of the procedure, understood as a possibility to return to a previous iteration in order to change the preference information provided at that stage. MAP algorithm is adaptive and can use different granularities for the partitioning of the search space, both in a probabilistic fashion and according to the evolution of Pareto front quality. Moreover, the effective partitioning for each search space is flexible and individually variable depending on its relative importance (Ii). The range, nature and dimension of a search space can vary greatly; nevertheless the effective partitioning granularity can be readjusted correspondingly based on the Iiinformation. In this fashion, the algorithm can be considered as flexible to different search space ranges and dimensions, and also suited to discrete optimization problems.The use of a relative importance per variable (Ii) allows readjusting the partitioning depth for each specific variable space, independently from the global value of partitioning tendency (PT) common to all search spaces. Hence, the algorithm is capable of immediately identifying the sensitive and insensitive variables during the exploration phase. When the relative importance parameter (Ii) is used, the algorithm would be able to discriminate between multiple search spaces and focus mostly on sensitive variables rather than the insensitive ones. Following such search strategy, the algorithm remains flexible and the convergence performance does not deteriorate when applied to high-dimensional search spaces.The use of tournament selection for constraint-handling based on feasibility rules has been already explored by other authors [32,33]. Jimenez and Verdegay [33] adopted an approach similar to a min-max formulation for multi-objective optimization. Their approach however was guided by the first feasible solution found, and therefore lacked an appropriate mechanism to avoid the premature convergence. According to Deb's approach [3], feasible solutions always discriminate infeasible ones. Such an approach would have difficulties where the optimum lies on the boundary between the feasible and the infeasible zones, because it does not allow infeasible individuals to remain in the population.It should be noted that feasibility is related to the constraint-handling strategies in MOEAs, which for instance consists in completing the definition of domination during the selection procedure with the information related to the constraint violation. Therefore, this issue must be raised and studied independently from the proposed algorithm in the present work.The reliability of the algorithm can be checked by monitoring the convergence accuracies in terms of IGD values. Statistical analyses based on convergence performance over the varying test functions were provided in Figs. 5, 7 and 10, for both constrained and unconstrained problems, and revealed the excellent convergence accuracy of the algorithm to reach the optimal Pareto fronts.Figs. 9 and 12 demonstrated at the same time the convergence speed and the stability of the algorithm at near-optimum conditions, for both unconstrained and constrained problems, respectively. Detailed information on the stability of the algorithm was provided in Section 3.8. For instance, the stable shift in HVI values in Fig. 13(e) justified the global stability of the algorithm when coupled within a MOEA framework. Furthermore, for almost all insensitive variables at the end of the exploitation phase of search, both interval numbers (INi) and relative importances (Ii) tended to decrease, due to the adaptive partitioning characteristic of MAP. This behavior together with the use of a memory, which is composed of a finite number of restricted solutions, allowed for a considerable reduction of eventual noises or perturbations at the near-optimum conditions. Yet, it should be noted also that the stability of an algorithm depends also on the global efficiency of MOEA framework itself.This work adopted a fixed partitioning multiplier (Ω=2). Hence, the interval numbers (INi) in the search space could be halted if a necessity to provide finer discretization rose up. Table 5indicates the advantage of using an adaptive partitioning strategy using the relative importance of variables (Ii). In this table, the minimization of search space efforts by different partitioning strategies were examined for different dimensions of variable space (nv=5, 10, and 30). It can be noted that when PT increases, inevitably, the maximum number of possibilities on a partitioned search space would increase too. For a fixed partitioning strategy (P columns in Table 5) without dynamic readjustment of interval numbers (INi), an exponential increase was observed in the maximum amount of search efforts required when the partitioning tendency increased from PTminto PTmax. The reason is that when the partitioning structure is fixed (predefined PT values), the total number of possibilities for nv-dimensional solutions is determined as the product of all partitioning tendency per variable space [PT+1×⋯×PT+1︷nV=PT+1nV]. In this case and by comparing P columns in Table 5, average increase factors of 107, 1015 and 1044 were observed for the search space dimensions nv=5, 10 and 30, respectively. However, when the partitioning is conducted dynamically and adaptively from gross to finer discretization and if the relative importance is provided (API columns in Table 5), the increase in the maximum amount of search efforts required remains almost constant and independently from the dimension of the variable space. The latter can be explained by the progressive attempt of the algorithm to pass from lower PT values to higher PT values (dynamic increase in partitioning). Let us envisage the MAP algorithm passing from PTminto PTmaxduring the search. At each PTivalue (each partitioning step) the maximum amount of search efforts is given byPTi+1nV. However, in this case the total number of possibilities by passing from PTminto PTmaxwill be the sum of search efforts per PTiincrement∑i=1kˆPTi+1nV, and not their product. If one assigns an average importance per variable to the adaptive partitioning, for instance 40%, then the maximum number of search efforts would decrease furthermore, represented by∑i=1kˆPTi+1nV⋅Ii. In this case, by comparing API columns in Table 5, the average increase factor of 6 was found for all search space dimensions.It should be noted that the number of possibilities mentioned in Table 5 represents the maximum amount of search efforts required. In reality the actual computational efforts are far below these values; as it was reported in this work that 3000 and 10,000 function evaluations were enough for 2-dimensional and 3-dimensional problems, respectively, even for a high dimensional optimization problem (nv=30).In addition, Figs. 6 and 8 illustrated the excellent diversity of solutions over the optimal Pareto fronts when MAP algorithm was used, even for multimodal problems. This is another proof to indicate that MAP does not limit the search space capability thanks to the gross partitioning tendencies (PT) during the exploration search, and improves the global aspect of the search algorithm. It can be concluded then that the adaptive partitioning strategy in MAP does not deteriorate the search space capability; on the contrary, it improves the convergence performance.Following the adaptive partitioning strategy, two supplementary benefits were additionally attained, first, a significant reduction of the number of possibilities on the search space, and second, the possibility to transform a continuous search space to a discrete one with bounded variations of variables. The latter is also suited for industrial applications where decision variables are generally bounded through their physical thresholds, despite the broadness of their ranges.

@&#CONCLUSIONS@&#
