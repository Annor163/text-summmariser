@&#MAIN-TITLE@&#
A hybrid method for large-scale short-term scheduling of make-and-pack production processes

@&#HIGHLIGHTS@&#
Complex batch production processes of the make-and-pack type.Hybrid method consists of decomposition, construction and improvement phase.Novel strategies for efficient integration of MILP scheduling models.Computational results for a real-world process of The Procter & Gamble Company.Hybrid method can devise optimal solutions and compares favourably to the state-of-the-art.

@&#KEYPHRASES@&#
Scheduling,Make-and-pack production,Hybrid method,Real-world production process,

@&#ABSTRACT@&#
Due to the ongoing trend towards increased product variety, fast-moving consumer goods such as food and beverages, pharmaceuticals, and chemicals are typically manufactured through so-called make-and-pack processes. These processes consist of a make stage, a pack stage, and intermediate storage facilities that decouple these two stages. In operations scheduling, complex technological constraints must be considered, e.g., non-identical parallel processing units, sequence-dependent changeovers, batch splitting, no-wait restrictions, material transfer times, minimum storage times, and finite storage capacity. The short-term scheduling problem is to compute a production schedule such that a given demand for products is fulfilled, all technological constraints are met, and the production makespan is minimised. A production schedule typically comprises 500–1500 operations. Due to the problem size and complexity of the technological constraints, the performance of known mixed-integer linear programming (MILP) formulations and heuristic approaches is often insufficient.We present a hybrid method consisting of three phases. First, the set of operations is divided into several subsets. Second, these subsets are iteratively scheduled using a generic and flexible MILP formulation. Third, a novel critical path-based improvement procedure is applied to the resulting schedule. We develop several strategies for the integration of the MILP model into this heuristic framework. Using these strategies, high-quality feasible solutions to large-scale instances can be obtained within reasonable CPU times using standard optimisation software. We have applied the proposed hybrid method to a set of industrial problem instances and found that the method outperforms state-of-the-art methods.scheduled batchesnew batchestasks {PM,FM,S,P}unitsgroups of identical batchesscheduled make batchesnew make batchesscheduled pack batchesnew pack batchesscheduled batches that require taskk∈Kscheduled batches whose taskk∈Kis performed on unit/tankj∈Jknew batches that require taskk∈Knew batches that require taskk∈Kand can be assigned to unitj∈Jknew batches that require task k and belong to groupg∈Gscheduled make batches that supply scheduled pack batchi∈IPnew make batches that can supply new pack batchi∈NPscheduled pack batches that are supplied by scheduled make batchi∈IMnew pack batches that can be supplied by new make batchi∈NMunits that perform taskk∈Kassigned unit for scheduled batchi∈Ikand available units for new batchi∈Nk(k∈K)final-mix units that can be connected to premix unitj∈JPMimmediate successor(s) of batchi∈Ik(k∈K)last pack batch in the processing sequence of unitj∈JPduration of taskk∈{PM,FM}for batchi∈Ik∪Nkduration of taskk∈K⧹{S}for batchi∈Ik∪Nkon unitj∈Jik(=αikfork∈{PM,FM})quarantine time of make batchi∈IM∪Nktransfer time of make batchi∈IPM∪NPMpump out time of make batchi∈IM∪NMchangeover time between batchi∈Ik∪Nkandi′∈Ik∪Nkon unitj∈Jik∩Ji′kcapacity of tankj∈Jssize of make batchi∈IM∪NM(batch independent)size of pack batchi∈IP∪NP(batch independent)position of taskk∈K⧹{S}of batchi∈Ik∪Nkin processing sequencevalue ofpikin previous iteration; in the first iteration,piprev,k=1position of storage task of batchi∈IM∪NMin tank j in storing sequencevalue ofpijSin previous iteration; in the first iteration,pijprev,S=1makespan of previous iteration; in the first iteration, Cprev=0makespan of packing linej∈JPof previous iteration; in the first iteration,Cjprev=0sufficiently large numberstart time of taskk∈K⧹{S}of batchi∈Ik∪Nkamount of material that make batchi∈NMsupplies to pack batchi′∈NiPthrough tankj∈JSmakespan of production planmakespan of packing linej∈JP=1, if make batchi∈NMsupplies pack batchi′∈NiP; =0, otherwise=1, if batchi∈Nis assigned to unitj∈Jikfor taskk∈K; =0, otherwise=1,if batchi∈Nkis processed/stored before batchi′∈Ik∪Nkfor taskk∈K⧹{S}=0,if batchi∈Nkis processed/stored after batchi′∈Ik∪Nkfor taskk∈K⧹{S}

@&#INTRODUCTION@&#
In Europe, the process industries account for 59% of the gross value added by all manufacturing industries.1Source: Statistics on the production of manufactured goods 2011, Eurostat, as of 2012-10-04.1Many companies in these industries are increasing their product range to better meet the individual needs of their customers, especially in the fast-moving consumer goods sector, in which products such as beer, ice-cream, dairy products, candy, condiments, drugs, toothpaste, detergents, and hair dyes are sold in various versions and package types. The production process generally consists of a make stage and a pack stage, which are decoupled by storage facilities. In the make stage, various intermediates are manufactured. In the pack stage, these intermediates are packed into different package types. The efficient utilisation of the available production resources is of particular importance because of the competitiveness and low unit contribution margins in these industries.In make-and-pack production processes, raw materials are transformed into (final) products through a series of transformation tasks, e.g., mixing, curing, and packing. The typical operating conditions include non-identical parallel processing units, partial equipment connectivity, sequence-dependent changeovers, batch splitting, no-wait restrictions, material transfer times, minimum storage times, and multipurpose storage units with limited capacities. Because of the maximum filling level of the processing units and storage tanks, the total demand must be divided into batches. In the following, we assume that the size of these batches is predetermined. This is often the case in practice, e.g., to utilise the maximum capacity of the processing and storage units or to satisfy safety regulations (in the pharmaceutical industry, for instance). We refer to the combination of a task and a batch as an operation. The planning problem discussed in this paper consists of assigning a start time and processing unit to each operation such that all technological constraints are met, the demand is fulfilled and a certain planning objective is optimised. Typical planning objectives are the minimisation of the makespan or total weighted tardiness. In practical applications, a large number of batches are processed, rendering the short-term scheduling of make-and-pack production processes a difficult task.In the literature, a large variety of mixed-integer linear programming (MILP) formulations has been proposed for this short-term scheduling problem. Owing to improvements in modelling techniques, optimisation software, and computer hardware, nowadays such MILP formulations are not only applicable to small, but also to medium-sized problem instances. However, the performance of these formulations for large-scale problem instances is still insufficient for practical applications. In addition to these MILP formulations, various heuristics and metaheuristics have also been proposed; however, these algorithms are designed for relatively simple production processes. Heuristic approaches become less efficient in the presence of complex technological constraints because it is already difficult to devise feasible schedules. In addition, the quality of the solutions cannot be controlled systematically. Eventually, some hybrid methods have been successfully applied to medium-sized problem instances. These heuristic algorithms combine exact methods with decomposition or aggregation techniques, allowing for systematic control of the size of the search space to balance the trade-off between solution quality and CPU time. The techniques for reducing the search space include, e.g., preordering rules (cf. Méndez & Cerdá, 2002b), block planning (cf. Günther, Grunow, & Neuhaus, 2006) and iterative scheduling (cf. Kopanos, Méndez, & Puigjaner, 2010; Roslöf, Harjunkoski, Westerlund, & Isaksson, 2002).In this paper, we present a hybrid method designed for large-scale instances that consists of three phases: decomposition, construction, and improvement. In the decomposition phase, the set of all batches is decomposed into groups of a predefined size. In the construction phase, an initial schedule is generated by iteratively scheduling the groups of batches using an MILP model. To obtain a suitable model formulation, we start from the MILP model introduced in Baumann and Trautmann (2013); this precedence-based model is designed for complex make-and-pack production processes and can be applied to small and medium-sized problem instances. We propose two adaptations of this model. First, we modify the objective function to account for situations in which several alternativ solutions exist in a given iteration. Second, we show how to eliminate redundant variables and constraints to reduce the CPU time required per iteration. In the improvement phase, the initial schedule is iteratively improved by identifying and rescheduling critical groups of batches. We show how to identify the critical groups of batches efficiently by solving two LP models that are derived directly from the MILP model. We apply this hybrid method to a set of real-world instances introduced in Honkomp, Lombardo, Rosen, and Pekny (2000). The results indicate that the heuristic outperforms the best solution method found in the literature (cf. Fündeling & Trautmann, 2006). We also compare the proposed hybrid method to an exact MILP model using a set of small- and medium-sized instances derived from the same real-world production process. The hybrid method (approximately) solves all of these instances to optimality.Due to the algorithmic limitations of standard optimisation software, most MILP formulations of scheduling problems cannot achieve optimal or even feasible solutions for large-scale problem instances. However, a major advantage of MILP formulations is the flexibility to account for the specific structures and operating conditions involved in complex production processes. We therefore use the MILP approach as our starting point for developing a solution methodology that can be applied to large-scale instances of real problems. The general aim of this paper is to provide simple and effective strategies for integrating a generic MILP formulation into the construction and improvement phases of a hybrid method, such that the resulting MILP models can be solved using standard optimisation software within reasonable CPU times.The remainder of this paper is organised as follows. We describe the characteristics of make-and-pack production processes in Section 2, using the real-world process presented in Honkomp et al. (2000) as an example. In Section 3, we review the related literature. In Section 4, we present the solution strategy of our hybrid method and describe the implementation of this strategy in the decomposition, construction and improvement phases in detail. We describe the MILP and LP formulations employed in Section 5; in particular, we introduce the modified objective function and demonstrate how to eliminate redundant variables and constraints. We report our computational results in Section 6 and provide concluding remarks and directions for further research in Section 7.In this section, we illustrate the characteristics of make-and-pack production processes using the real-world process described in Honkomp et al. (2000). All of the data were provided by the Procter & Gamble Company. In Section 2.1, we sketch the structure of the production process. In Sections 2.2, 2.3, and 2.4, we describe the operating conditions for the make stage, storage, and pack stage, respectively. In Section 2.5, we state the resulting short-term scheduling problem.The equipment structure of the production process is depicted in Fig. 1. The make stage consists of three non-identical groups of premix units and final-mix units. A premix unit can only be connected to a final-mix unit that belongs to the same group. The pack stage consists of seven parallel, non-identical packing lines. Eighty storage tanks with different capacities decouple the make stage from the pack stage.In the make stage, 59 different intermediates are produced in batches of size ten. Most of the intermediates require both a premix and a final-mix task (see Fig. 2, Batch A). First, the raw material is converted into a compound in an appropriate premix unit. The compound is then directly transferred into a final-mix unit in which further material is added. During the transfer, both involved processing units are occupied. The remaining intermediates only require a final-mix task (Batch B). For those intermediates, the entire raw material transformation takes place in the final-mix unit. It can be assumed that raw material is available in sufficient quantity.Each compound and each intermediate belongs to a wash-out family. Between the processing of batches belonging to specific pairs of wash-out families, the premix and final-mix units must be cleaned. The duration of the cleaning is neither unit- nor intermediate-dependent. The processing times of the premix and final-mix operations depend on the compound and intermediate but not on the processing unit.All of the storage tanks are multipurpose, i.e., different intermediates can be stored in the same tank, but only one at a time. In this process, every intermediate can be stored in every storage tank. Six of the tanks have a capacity of ten, and the remaining 74 tanks have a capacity of five. Immediately following the completion of the final-mix task, the intermediate is pumped into either two tanks with capacity five (Batch A) or one tank with capacity ten (Batch B). The intermediate must stay within the tank(s) for at least a specified quarantine time (δAorδB). Before a batch is pumped out into a storage tank, the tank must be cleaned. The duration of the pumping and quarantine time depend on the intermediate, but not on the storage tank.In the pack stage, the intermediates are packed in batches of size five, and 22 different package types are used. We refer to the combination of an intermediate and a package type as a product. In total, 203 different products are sold to customers. Intermediates stored in tanks with capacity ten are split into two portions of size five, which can be packed on the same packing line or on two different packing lines (Batch B). During the packing operation, the intermediate is continuously extracted from the storage tank. It can be assumed that unlimited storage space is available for all products.The duration of a packing operation depends on the intermediate, package type and packing line. The packing lines must be cleaned between the packing of intermediates belonging to specific pairs of wash-out families. In addition, a changeover is required when the package type is switched. The cleaning and changeover can be performed in a single operation, which has a shorter duration than the sum of the cleaning and changeover times. In Fig. 2, we assume that Batch A is packed in two different types of packages and that Batch B is packed in a third type of package.A given set of operations is required to fulfil the product demand for a planning horizon of one week; the due date of the demand coincides with the end of the planning horizon. There are typically 500–1500 operations to be scheduled.We seek (a) an assignment of the processing units and storage tanks to the operations and (b) a start time for the processing of each operation such that all technological constraints are satisfied and the makespan of the production schedule is minimised. As noted in Honkomp et al. (2000), a low makespan results in lower labour costs. Moreover, minimising the makespan generally reduces the total changeover time and thereby contributes to an efficient utilisation of the production resources.We assume that the changeover times satisfy the weak triangular inequality, i.e., the changeover time from batch A to batch C is less than or equal to the sum of the processing time of batch B and the total changeover time from A to B followed by B to C. The data provided by the Procter & Gamble Company for the production process described above satisfies this assumption.In this section, we provide an overview of various models and solution methods for the short-term scheduling of make-and-pack production processes. In Sections 3.1 and 3.2, we review MILP models and heuristic methods for the scheduling of multi-product batch processes, respectively. In Section 3.3, we cover hybrid methods that combine heuristic techniques with exact methods. In Section 3.4, we describe hybrid approaches that rely on a decomposition approach in detail.A large variety of MILP models for multi-stage batch scheduling has been proposed in the literature; for general reviews, we refer the reader to Kallrath (2002), Floudas and Lin (2004), Méndez, Cerdá, Grossmann, Harjunkoski, and Fahl (2006). In these models, the planning horizon is divided into a set of time intervals. In continuous-time models, the length of these intervals is determined implicitly in the course of the solution of the MILP. In discrete-time models, the length of the time intervals is fixed and is usually determined as the highest common factor of the processing times, material transfer times, quarantine times, and changeover times. A large number of time intervals is required for most real-world problems, rendering the resulting discrete-time model prohibitively large (see, e.g., Stefansson, Sigmarsdottir, Jensson, & Shah, 2011). In the following, we therefore concentrate on continuous-time models, which we further classify into network-based and batch-based models.In network-based models, the production process is represented either by a so-called state-task network (cf. Kondili, Pantelides, & Sargent, 1993) or by a resource-task network (cf. Pantelides, 1994). Models of the former type have been proposed by, e.g., Maravelias and Grossmann (2003), Sundaramoorthy and Karimi (2005), and Erdirik-Dogan and Grossmann (2008); for models of the latter type, we refer the reader to, e.g., Castro and Grossmann (2005), Castro, Grossmann, and Novais (2006), Castro and Novais (2009), and Shaik and Floudas (2008). The model described in Giménez, Henning, and Maravelias (2009a, 2009b) covers the broadest range of technological constraints occurring in make-and-pack production processes. A major advantage of network-based models is that batching and scheduling decisions are considered simultaneously, i.e., the decision regarding the number and size of the batches is part of the optimisation. Therefore, network-based models are typically used to address production processes that involve flexible batch mixing and splitting, cyclic material flows, and multiple storage policies. However, additional tasks are required to model partial equipment connectivity, sequence-dependent changeovers, and time-consuming material transfers. These additional tasks usually deteriorate the computational performance of the models considerably.In batch-based models, batches are treated as discrete entities that move sequentially through the stages of the production process. In most models, the processing sequence of the batches is defined by immediate- or general-precedence relationships. In immediate precedence-based models (cf. e.g., Cerdá, Henning, & Grossmann, 1997; Gupta & Karimi, 2003), an immediate predecessor batch is defined for each batch. This approach makes it possible to efficiently consider sequence-dependent changeover times or costs. In general precedence-based models (cf. e.g., Jain & Grossmann, 2000; Kopanos, Lanez, & Puigjaner, 2009; Kopanos, Puigjaner, & Georgiadis, 2011; Méndez & Cerdá, 2000, 2002a, 2002b, 2003b; Méndez, Henning, & Cerdá, 2001; Sundaramoorthy & Maravelias, 2008a, 2008b; Elzakker, Zondervan, Raikar, Grossmann, & Bongers, 2012), all direct and indirect predecessor batches are considered for each batch. The latter approach requires fewer binary variables and allows shared resources such as storage tanks to be handled without the need for additional variables. To our knowledge, the general precedence-based model proposed by Baumann and Trautmann (2013) is the only MILP model that accounts for all of the technological constraints in make-and-pack production processes such as that described in Honkomp et al. (2000). Despite the sparse use of binary variables and introduction of symmetry-breaking constraints, the model can only be applied to instances with up to 180 operations. For larger instances, the computational cost becomes prohibitively high.We conclude that MILP models offer the flexibility to easily accommodate complex technological constraints, but they are not appropriate for large-scale instances. For our hybrid approach we use the general-precedence framework for two reasons. First, it has been shown that general-precedence based models generally require less computational effort than network-based models. Second, a broad range of production processes and important operating conditions can be modelled using general-precedence variables.Compared with the large variety of MILP models, only a few heuristic approaches have been proposed for short-term scheduling of make-and-pack production processes. For a particular make-and-pack production process in the shampoo industry, Belaïd, T’kindt, and Esswein (2010, 2012) and Belaïd, T’kindt, and Esswein (2011) propose specific heuristics for the scheduling of the storage and make stage, respectively. The start times for the batches in the pack stage are derived from the due dates of the customer orders and represent deadlines for the corresponding operations in the preceding stage. The objective is to minimise the number of cleanings of the processing units and storage tanks. Fündeling and Trautmann (2006) develop a priority rule-based heuristic tailored to the production process described in Honkomp et al. (2000). The priority rule determines the order in which the batches are scheduled, and a problem-specific selection rule is used to assign the batches to processing units and storage tanks. Fündeling and Trautmann (2006) propose 287 different multi-level priority rules for determining the scheduling order of batches. The heuristic can be applied as a single-pass method using one specific priority rule or as a multi-pass sampling method that computes for the same problem instance multiple schedules, each with a different priority rule. The computational results reported in Baumann and Trautmann (2013) indicate a considerable performance gap relative to the MILP models even when multi-pass sampling is employed.For metaheuristics such as simulated annealing, tabu search, and population-based search methods, good performance has been reported for various scheduling problems. However, no such metaheuristics have been developed for make-and-pack production processes, possibly because these methods often generate infeasible solutions during the search when complex technological constraints are imposed. Three different approaches have been proposed to overcome this drawback. The first approach is to repair infeasible solutions. Raaymakers and Hoogeveen (2000) propose a simulated annealing method with such a repair procedure for a scheduling problem with no-wait restrictions between operations. Depending on the number of constraint violations, the repair procedure may require a considerable amount of CPU time. The second approach is to avoid infeasibility. Venditti, Pacciarelli, and Meloni (2010) developed a tabu search algorithm that uses an acyclic graph to represent a schedule. Prior to each schedule modification, a feasibility test is performed to ensure that the resulting graph does not contain any cycles. Although the feasibility test requires little CPU time, the performance is better in less constrained problems. Ruiz and Maroto (2006) present a genetic algorithm in which a solution is represented as a permutation of batches. A schedule-generation scheme translates the permutation into a feasible schedule. Due to the simplified representation, the search is limited to a specific area of the solution space. In the so-called random-key genetic algorithm of Kurz and Askin (2004), the representation is less simplified because both the sequencing and unit assignment decisions are included. A real number is assigned to each batch, whose integer part defines the assigned machine and whose fractional part is used to order the jobs assigned to each machine. A larger area of the solution space is thereby covered. However, in the presence of unit assignment restrictions, infeasible schedules may be generated. The third approach to handle infeasibility is to impose a penalty on constraint violations, cf. e.g., Ramteke and Srinivasan (2011). Although this approach is attractive in that it does not involve additional computational cost, the performance of the search is hardly improved by this modification, as penalties generally do not provide direct information on promising search directions.We conclude that heuristic approaches are either problem-specific or designed for relatively simple production processes. They become less efficient in the presence of complex technological constraints because it is already difficult to devise feasible schedules. In addition, the quality of the solutions cannot be controlled systematically.The use of exact methods for solving large-scale scheduling problems with complex constraints has become more attractive with the development of hybrid methods such as model-reduction methods, aggregation techniques, and decomposition methods. The key idea of these methods is to exploit the flexibility provided by mixed-integer linear programming to easily accommodate complex technological constraints, while limiting the number of simultaneous decisions to achieve reasonable CPU times. In the following, we sketch these three types of hybrid methods; for our approach we apply a decomposition method. Therefore, we will review related decomposition methods in more detail in Section 3.4.Model reduction methods reduce the dimensionality of the problem by fixing a large number of the decision variables of the original MILP model so that only critical decisions are to be taken. Méndez and Cerdá (2002b) use preordering rules to reduce the size of a process-specific MILP model. Similarly, Günther et al. (2006) apply the block-planning technique, in which the sequence of batches within a block is determined in advance based on an analysis of the sequence-dependent changeover times. Bilgen and Günther (2010) extend this work to account for the transportation between the plants and distribution centres. For problems with a bottleneck stage, Marchetti and Cerdá (2009) propose to replace the individual general-precedence sequencing variables for each stage by sequencing variables that define a unique ordering of the batches for all stages.Aggregation techniques replace groups of related decision variables by aggregate variables. Wilkinson, Shah, and Pantelides (1995) propose a temporal aggregation technique for discrete-time models in which short time periods are aggregated into longer time periods. Dimitriadis, Shah, and Pantelides (1997) separate the planning horizon into two time intervals; the first interval is modelled in detail, and the second interval is modelled using the aggregation technique proposed by Wilkinson et al. (1995).Decomposition methods divide the problem at hand into several smaller subproblems that can be solved within short CPU times. Harjunkoski and Grossmann (2002) decompose single- and multi-stage scheduling problems into an assignment and a scheduling subproblem, which are solved using mixed-integer linear programming and constraint programming, respectively. Maravelias (2006) proposes a similar decomposition strategy for a problem in which the sequencing subproblems can be solved efficiently. For a review of decomposition methods that are more closely related to the method proposed in the present paper, we refer the reader to the next section.In this section, we review hybrid decomposition methods that iteratively schedule groups of one or more batches. We focus on those methods that are methodologically related to our approach in the sense that an MILP formulation is used to solve the resulting scheduling problems.Roslöf, Harjunkoski, Björkqvist, Karlsson, and Westerlund (2001) address a rescheduling problem for a single-stage, single-unit production process. They propose an MILP formulation for inserting a given group of batches into a given schedule; the relative order of the batches in that schedule is maintained by a set of (direct and indirect) precedence constraints. Méndez and Cerdá (2003a) propose a similar approach for the rescheduling of a single-stage production process with parallel units. Roslöf et al. (2002) adapt the approach presented in Roslöf et al. (2001) to the problem of generating an initial schedule. In each iteration, new batches are added to the current partial schedule using an MILP formulation, and the relative order of the batches that have already been scheduled is thereby maintained, in a similar fashion to the method of Roslöf et al. (2001). The proposed approach is applied to an industrial paper-converting process. In contrast to the present paper, the three papers mentioned above report computational results for relatively small problem instances.The technique for maintaining the relative order of the batches that was proposed in the papers cited above cannot be extended straightforwardly to multi-stage processes with more complex structures. Instead, various authors have proposed to maintain the relative order by fixing the values of the corresponding decision variables while maintaining the corresponding variables and constraints in the MILP model. However, the preprocessing algorithms of commercial solvers may not eliminate all redundant variables and constraints, resulting in models that are considerably larger than necessary. In Section 6, we will provide computational results for such a variable-fixing strategy showing that the preprocessing procedure of the Gurobi solver does not always eliminate all variables and constraints that become redundant when values of decision variables are fixed. Castro, Harjunkoski, and Grossmann (2009) consider a multi-stage, multi-product batch process with parallel, non-identical processing units for each stage, sequence-independent changeover times and unlimited intermediate storage space. The groups to be scheduled iteratively are computed and sorted using some simple priority rules. After all of the groups have been scheduled, the groups are iteratively rescheduled in the same order. For the scheduling of the individual groups, both a batch-based and a network-based MILP model are proposed, but the computational cost of the latter turns out to be significantly higher. Kopanos et al. (2010) consider the same type of production process, but additionally account for sequence-dependent changeover times. In an experimental analysis of the effect of group sizes, the best results were obtained when only a single batch was scheduled per iteration. The method of Kopanos et al. (2010) comprises a constructive step and an improvement step. In the constructive step, the batches are ordered according to the number of suitable processing units; for the scheduling of the batches, two alternative batch-based MILP formulations are proposed. The improvement step consists of a reordering and a reinsertion stage. In the reordering stage, an improvement is attempted by swapping the order of batches that are processed consecutively. In the reinsertion stage, single batches are rescheduled. Both stages are repeated until no improvement is achieved within a predefined number of iterations. The computational results are presented for a pharmaceutical production process with six stages, 17 processing units and up to 336 operations. Kopanos, Puigjaner, and Georgiadis (2012) and Aguirre, Méndez, Gutierrez, and Prada (2012) apply a similar solution method to an ice-cream production process of the make-and-pack type and a multi-stage, single-unit production process in the semiconductor manufacturing industry, respectively. For a production process with identical parallel processing units but without changeover times, Gomes, Barbosa-Póvoa, and Novais (2010) propose to combine a similar strategy with a discrete-time network-based model for inserting additional batches into an existing schedule.In this section, we present the solution strategy of our hybrid method for large-scale short-term scheduling of make-and-pack production processes. The method consists of three phases: decomposition, construction, and improvement. In the decomposition phase, the set of all batches is decomposed into groups of a predefined size such that (a) batches of the same group can form a feasible partial schedule and (b) the groups of batches can be scheduled independently of one another. In the construction phase, an initial feasible schedule is generated by iteratively scheduling the groups of batches. Similar to the related papers mentioned in Section 3.4, we apply a batch-based MILP formulation to the solution of the scheduling problem in each iteration. However, in contrast to the methods of Castro et al. (2009) and Kopanos et al., 2010, we eliminate a large number of the variables and constraints that have become redundant due to the decisions taken in previous iterations. For large-scale instances, this elimination technique reduces the overall computational cost considerably. In the improvement phase, a local search heuristic is applied to the initial schedule. In each iteration of this heuristic, we identify a group of critical batches by solving two linear programs derived directly from the batch-based MILP formulation of the construction phase. This group of batches is then removed from the current schedule and reinserted, again by applying an appropriate MILP formulation.The remainder of this section is organised as follows. In Section 4.1, we introduce an example that will be used to illustrate the individual phases of our hybrid method. In Sections 4.2, 4.3 and 4.4, we describe the decomposition, construction, and improvement phases in detail.A preliminary version of the decomposition and construction phases can be found in Baumann and Trautmann (2011). In the present paper, we provide an enhanced version of these phases that requires less computational effort and provides superior results.To illustrate the individual phases of the hybrid method, we use an example introduced by Baumann and Trautmann (2013). In this section, we provide the main data of this example.The demand for five products (P1–P5) that must be produced from four different intermediates (I1–I4) is given. The production facility consists of one premix unit (PM1), which is connected to two final-mix units (FM1, FM2), three storage tanks (S1, S2, S3) and two packing lines (PL1, PL2). Table 1lists the demand, intermediate, package type, and index of the pack batches for each product. The complete data of the example can be found in Baumann and Trautmann (2013). Given the predetermined sizes of the make batches (10 units) and pack batches (5 units), the total number of required make and pack batches can be derived directly from the total demand. In this case, 12 pack batches and six make batches must be scheduled to meet the total demand of 60 units.The size of an instance of the problem discussed in the present paper is driven primarily by the number of batches to be scheduled. We therefore propose to decompose the set of batches into smaller groups as follows.(D1)A priority value is computed for each pack batch. The pack batches are then sorted according to these values. In preliminary tests, we have analysed various priority rules, such as the number of suitable packing lines, the wash-out family, or the package type. However, we have obtained the best results using a random number for the priority value, possibly because the order of the batches in the resulting schedule may be quite different from the order in which the batches are scheduled.The batches are assigned to groups based on the order determined in step (D1). The number of make batches within a group must be defined as an input parameter to the hybrid method. The assignment of make and pack batches to groups proceeds as follows. First, a pack batch with the highest priority value that has not yet been assigned is added to the current group. Second, a make batch that produces the required intermediate and has not yet been assigned is added. Third, further pack batches that have not yet been assigned and require the same intermediate are added in order of non-increasing priority values, such that the entire quantity of the intermediate provided by the make batch is consumed by these pack batches. These three steps are repeated until the specified group size has been reached. In Fig. 3, the set of batches is decomposed into six groups of size one.Fig. 3 provides a flowchart of the decomposition phase and visualisation of each step of this phase for the illustrative example.In the construction phase, an initial feasible schedule is generated as follows.(C1)The first or next group of batches is scheduled by solving MILP model (C) (cf. Section 5.5). The main decision variables of this model are (a) allocation variables for new batches and (b) general-precedence variables among new batches and between new and scheduled batches. The unit allocation and relative ordering of the scheduled batches is preserved by imposing timing constraints on the scheduled batches that are processed consecutively. In each iteration, a new instance of the MILP model is generated based on updated sets of new and already-scheduled batches. Using this strategy, the size of the MILP model grows only slowly from iteration to iteration because a large number of constraints and variables that have become redundant are eliminated.From the resulting (partial) schedule, the final values of the allocation and general-precedence variables are retrieved and translated into immediate-precedence relationships (cf. Algorithms 1–4, see Appendix A). This information is used to set up model (C) in the next execution of step (C1).The construction phase terminates when all groups have been scheduled. Otherwise, the next group of batches is selected and scheduled (step C1).Fig. 4provides a flowchart of the construction phase and visualisation of each step of this phase for the illustrative example. In each schedule, new operations are marked with a triangle.Once the construction phase is complete, an iterative improvement procedure is applied to the initial schedule. This algorithm proceeds as follows. At the beginning of the procedure, all make batches are unmarked. During the procedure, a make batch is temporarily marked if removing and reinserting the related operations has not resulted in an improvement of the makespan.(I1)All critical operations of the current schedule are identified by solving two LP models. First, model (E) (cf. Section 5.5) is solved to compute the earliest possible start times of the premix, final-mix and packing operations, given the unit allocation and order of the operations in the current schedule. Second, model (L) (cf. Section 5.5) is solved to compute the latest possible start times of the operations, given the unit allocation, order of the operations in the current schedule, and makespan of the current schedule. Both models can be solved efficiently because they contain only continuous decision variables. Operations are considered critical when their earliest and latest start times coincide, i.e., when a delay of the operation causes an increase in the makespan. In other words, the makespan is determined by the set of critical operations. In the following, we consider a make batch as critical if at least one of its related operations (premix, final-mix, storage or assigned packing operation(s)) is critical.We determine the set of make batches that are critical and unmarked. If this set is empty, then the procedure is terminated. Otherwise, we randomly select and mark one of these batches.All operations related to the make batch selected in step (I2) are unscheduled. The immediate-precedence relations are then updated using Algorithm 7 (cf. Appendix A). Finally, the unscheduled operations are reinserted by solving MILP model (I) (cf. Section 5.5).If the makespan can be improved, then we unmark all make batches and proceed with set (I1). Otherwise, the procedure directly continues with step (I1).Note that in each iteration, the unscheduled operations may be reinserted at the same position; therefore, the makespan does not deteriorate during the improvement phase. Fig. 5provides a flowchart of the improvement phase and visualisation of each step of this phase for the illustrative example and the initial schedule shown in Fig. 4. The critical operations in the respective schedules are accentuated by a thick border, and the operations selected for removal are marked with a cross.The scheduling models used in the construction and improvement phases of the hybrid method are derived from the model presented in Baumann and Trautmann (2013). The model of Baumann and Trautmann (2013) can be applied to production processes such as presented in Honkomp et al. (2000) and therefore covers a wide range of operating conditions that are typical for make-and-pack plants.The main difference of the model proposed in the present paper is that we divide the set of all batches into two sets, I and N. Set I consists of the batches that have already been scheduled in an earlier iteration, and set N consists of the batches that are to be scheduled in the current iteration. This distinction gives rise to three different groups of constraints. The first group of constraints involves only new batches. The second group of constraints involves both new and scheduled batches, and the third group involves only scheduled batches. In each iteration of the construction and improvement phases, the sets of new and already-scheduled batches and their parameters are initialised, and a new instance of the model is generated.In Sections 5.1, 5.2 and 5.3, we provide a detailed description of these three groups of constraints. In Section 5.4, we introduce the objective function used in the model for the construction phase. In Section 5.5, we summarise the various MILP and LP models used for the construction and improvement phase.In this section, we present the constraints related to the allocation (cf. Section 5.1.1), material flow (cf. Section 5.1.2), timing (cf. Section 5.1.3), sequencing (cf. Section 5.1.4), and symmetry-breaking decisions (cf. Section 5.1.5).Constraints (1) allocate a suitable final-mix unitj∈JiFMto the final-mix task of each new make batchi∈NFMand a suitable packing linej∈JiPto the packing task of each new pack batchi∈NP.(1)∑j∈JikYijk=1(k∈{FM,P};i∈Nk)For make batchesi∈NPMrequiring a premix task, constraints (2) ensure that the premix and final-mix tasks are allocated to a pair of premix and final-mix unitsj∈JiPM,j′∈JjFMthat can be connected to one another.(2)YijPM=∑j′∈JjFMYij′FM(i∈NPM;j∈JiPM)Constraints (3) allocate one or two storage tanksj∈JSto every new make batchi∈NM, such that the total capacity of the allocated tanks is equal to the sizeβMof batch i.(3)∑j∈JScjYijS=βM(i∈NM)Constraints (4) allocate exactly one storage tankj∈JSto each new pack batchi∈NP. The allocation of a single tank is sufficient because each tank has at least the capacity to store an entire pack batch of sizeβP.(4)∑j∈JSYijS=1(i∈NP)Material flow constraints ensure that each new make batchi∈NMsupplies two new pack batchesi′∈NiPwith material. We use the continuous variableFii′jto denote the amount of material that make batch i delivers to pack batchi′through storage tank j. Constraints (5) ensure that every make batch i delivers all of its materialβMto some set of pack batchesi′.(5)∑i′∈NiP;j∈JSFii′j=βM(i∈NM)Similarly, constraints (6) guarantee that the total amount of material supplied to each pack batchi′∈NPequalsβP.(6)∑i∈Ni′M;j∈JSFii′j=βP(i′∈NP)Material can only flow between make batch i and pack batchi′if the binary variableUii′equals one, as expressed by constraints (7).(7)∑j∈JSFii′j=βPUii′(i∈NM;i′∈NiP)Moreover, constraints (8) and (9) ensure that the same storage tankj∈JSis allocated to both make batch i and pack batchi′whenever i delivers material toi′.(8)Fii′j⩽βPYi′jS(i∈NM;i′∈NiP;j∈JS)(9)Fii′j⩽βPYijS(i∈NM;i′∈NiP;j∈JS)Constraints (10) prevent the capacitycjof storage tankj∈JSfrom being exceeded.(10)∑i′∈NiPFii′j⩽cj(i∈NM;j∈JS)Fig. 6illustrates the material-flow constraints for a situation with two identical make batches, two storage tanks, and four identical pack batches.Constraints (11) represent the no-wait restriction between the premix and final-mix task of each make batchi∈NPMrequiring a premix task. The start time of the final-mix taskSiFMis computed such that the premix and final-mix tasks overlap for exactly the transfer timeτi(see Fig. 7).(11)SiFM=SiPM+αiPM-τi(i∈NPM)Constraints (12) ensure that the processing of a pack batchi′∈NiPthat consumes material from make batchi∈NMcannot start before the supplying make batch has been stored for at least its quarantine timeδi.(12)Si′P⩾SiFM+αiFM+δi-M(1-Uii′)(i∈NM;i′∈NiP)We use the general-precedence concept to derive the processing sequence of batches at each processing unit or storage tank. In this concept, one sequencing variableXii′kis defined for each pair of batchesi,i′∈Nkthat can be allocated to the same processing unit or storage tankj∈Jik∩Ji′k. If batches i andi′are processed on different units, then constraints (13) and (14) both become redundant and the variableXii′kis meaningless for unit j (see final-mix tasks in Fig. 7). Otherwise, if both batches are processed at the same unit (Yijk=Yi′jk=1), then either constraint (13) or constraint (14) becomes active. IfXii′k=1, then constraint (13) becomes active and forces the start timeSi′kof batchi′to be greater than or equal to the completion time of batch i plus the durationωii′jkof the subsequent changeover (see premix tasks in Fig. 7). Constraint (14) becomes redundant in that case.(13)Si′k⩾Sik+αijk+ωii′jk-M(1-Xii′k)-M(2-Yijk-Yi′jk)(k∈K⧹{S};i∈Nk;i′∈Nk;j∈Jik∩Ji′k:i<i′)In the opposite case, whereXii′k=0, constraint (13) becomes redundant, and constraint (14) becomes active and ensures that batchi′is processed before batch i.(14)Sik⩾Si′k+αi′jk+ωi′ijk-MXii′k-M(2-Yijk-Yi′jk)(k∈K⧹{S};i∈Nk;i′∈Nk;j∈Jik∩Ji′k:i<i′)A major advantage of the general-precedence concept is that we can use the final-mix sequencing variablesXii′FMto sequence the storage operations without compromising the optimality of the solution. However, this strategy requires that we also define a variableXii′FMfor pairs of make batches that do not share a common final-mix unit because they can still be allocated to the same storage tank. Again, we define two sets of sequencing constraints, constraints (15) and (16), for each pair of new make batchesi,i′∈NMand each storage tankj∈JS. Whenever i andi′are allocated to the same tank, the variableXii′FMdefines their relative storage sequence. IfXii′FM=1, then constraint (15) ensures that the storage task of make batchi′begins after both the storage task of batch i and the subsequent changeover of durationωii′jSare complete. Due to the no-wait restriction between the final-mix task and storage task of batch i, we derive the start time of the storage task directly from the start time of the corresponding final-mix task. As illustrated in Fig. 7, the start time of the storage task is equal to the start time of the final-mix taskSiFMplus its durationαiFMminus the pump out timeρi. Similarly, the completion time of the storage task of batch i is derived from the completion time of the corresponding packing task, which is equal to the start timeSi″Pplus the unit-dependent packing timeαi″j′P. Because we do not know a priori which pack batchi″will be supplied by make batch i, we must impose constraints (15) and (16) for all pack batchesi″∈NiPthat could be supplied by make batch i. However, the constraints are relaxed if make batch i does not supply pack batchi″(Uii″=0). Moreover, the constraints are only active if both make batch i and pack batchi″are allocated to the same storage tankj∈JS. Constraint (16) holds ifXii′FM=0.(15)Si′FM+αi′FM-ρi′⩾Si″P+∑j′∈Ji″Pαi″j′PYi″j′P+ωii′jS-M(1-Xii′FM)-M(2-Yi′jS-Yi″jS)-M(1-Uii″)(i∈NFM;i′∈NFM;i″∈NiP;j∈JS:i<i′)(16)SiFM+αiFM-ρi⩾Si″P+∑j′∈Ji″Pαi″j′PYi″j′P+ωi′ijS-MXii′FM-M(2-YijS-Yi″jS)-M(1-Ui′i″)(i∈NFM;i′∈NFM;i″∈Ni′P;j∈JS:i<i′)In other production processes (cf. e.g., Bongers & Bakker, 2006), the intermediate is continuously pumped into the storage tank as soon as the mixing task starts. With some minor modifications to constraints (15) and (16), namely the substitution ofαi′FM–ρi′withτi′and the substitution ofαiFM–ρiwithτi, respectively, the model could also account for continuous material flow on the make stage.In a given schedule, identical batches, i.e., batches that produce the same intermediate or product, can be interchanged with no impact on value of the objective function. The elimination of such symmetries generally accelerates the solution algorithm. Constraint (17) removes these symmetries by imposing an arbitrary sequence for each groupg∈Gof identical new batches and each taskk∈K⧹{S}required by these batches.(17)Sik⩽Si′k(g∈G;k∈K⧹{S};i∈Ngk;i′∈Ngk:i<i′)This group of constraints is concerned with the proper insertion of new batches among scheduled ones. Whenever a taskk∈{PM,FM,P}of a new batch i is allocated to a unit designated to process a previously scheduled batchi′, the variableXii′kdefines the processing order of i andi′. IfXii′k=1, then constraint (18) requires that the new batch i delays the previously scheduled batchi′. The constraint is relaxed if batch i is not allocated to the same processing unit as batchi′.(18)Si′k⩾Sik+αijk+ωii′jk-M(1-Xii′k)-M(1-Yijk)(k∈K⧹{S};i∈Nk;i′∈Ik;j∈Jik∩Ji′k)In the opposite case, whereXii′k=0, constraint (19) ensures that batch i is processed after batchi′.(19)Sik⩾Si′k+αi′jk+ωi′ijk-MXii′k-M(1-Yijk)(k∈K⧹{S};i∈Nk;i′∈Ik;j∈Jik∩Ji′k)Note that for the premix and packing tasks, the variableXii′kis only defined when the processing unitj∈Ji′kthat is allocated to the scheduled batchi′is among the available processing unitsj∈Jikfor the new batch i.Whenever a new make batch i is allocated to a storage tank designated to process a previously scheduled make batchi′, constraints (20) and (21) ensure that the respective storage tasks do not overlap. IfXii′FM=1, then constraint (20) ensures that the storage task of batchi′begins after both the storage task of batch i and the subsequent changeover are complete. Recall that the completion time of the storage task of batch i is determined by the completion time of the latest pack batchi″∈NiPthat consumes material from make batch i. Constraint (20) is only active if pack batchi″is allocated to storage tankj∈Ji′Sand make batch i supplies pack batchi″.(20)Si′FM+αi′FM-ρi′⩾Si″P+∑j′∈Ji″Pαi″j′PYi″j′P+ωii′jS-M(1-Xii′FM)-M(1-Yi″jS)-M(1-Uii″)(i∈NFM;i′∈IFM;i″∈NiP;j∈Ji′S)Constraint (21) is enforced if make batchi′is stored before make batch i (Xii′FM=0).(21)SiFM+αiFM-ρi⩾Si″P+αi″j′P+ωi′ijS-MXii′FM-M(1-YijS)(i∈NFM;i′∈IFM;i″∈Ii′P;j′∈Ji″P;j∈Ji″S)Fig. 8provides a visualisation of constraints of type (18)–(21) in a situation in which a group of one new make batch i and two new pack batchesi″are scheduled between previously scheduled batches.The third group of constraints models the timing relations among scheduled batches. Constraints (22) ensure that the processing of the immediate successori′∈SUCikof batch i cannot begin before the processing of batch i and subsequent changeover are complete. These precedence relationships are established for the premix, final-mix and packing tasks.(22)Si′k⩾Sik+αijk+ωii′jk(k∈K⧹{S};i∈Ik;j∈Jik;i′∈SUCik)The precedence relationships between storage tasks are expressed by constraints (23). If make batchi′is stored immediately after make batch i in tankj∈Ji′S, constraint (23) establishes a precedence relationship between each pack batchi″that consumes material from make batch i through storage tankj∈Ji′Sand make batchi′.(23)Si′FM+αi′FM-ρi′⩾Si″P+αi″j′P+ωii′jS(i∈IFM:i′∈SUCiS;i″∈IiP;j∈Ji′S∩Ji″S;j′∈Ji″P)Constraints (24) represent the no-wait restrictions between the premix and final-mix tasks of each scheduled make batchi∈IPMthat requires a premix task.(24)SiFM=SiPM+αiPM-τi(i∈IPM)For each scheduled make batchi∈IM, constraints (25) guarantee that each consuming pack batchi′∈IiPdoes not start before make batch i has been stored for at least its quarantine timeδi.(25)Si′P⩾SiFM+αiFM+δi(i∈IM;i′∈IiP)Fig. 9illustrates all active constraints of type (22)–(25) that involve make batch i and its two corresponding pack batches,i″.Two groups of constraints are used to compute the makespan C of the production schedule. Constraints (26) ensure that the makespan C is greater than or equal to the completion time of every new pack batchi∈NP.(26)C⩾SiP+∑j∈JiPαijPYijP(i∈NP)Constraints (27) ensure that the makespan C is greater than or equal to the completion time of the last scheduled batch in the processing sequence of every packing line j.(27)C⩾SiP+αijP(j∈JP;i∈LASTjP)The minimisation of the overall makespan, C, of a partial schedule may result in adverse planning decisions. If, for example, the makespan of a partial schedule is driven by one packing line only, then new batches may be allocated to any of the less occupied packing lines, irrespective of unit-specific processing times or sequence-dependent changeovers. We therefore propose to compute a separate makespanCjfor each packing linej∈JPthat satisfies constraints (28) and (29) in addition to the overall makespan, which is subject to constraint (30).(28)Cj⩾SiP+αijP(j∈JP;i∈LASTjP)(29)Cj⩾SiP+αijP-M(1-YijP)(i∈NP;j∈JiP)(30)C⩾Cj(j∈JP)We then minimise the weighted sum of all makespans. Here, the weight of each separate makespanCjis one, and the weight of the overall makespan C is seven, which corresponds to the number of packing lines in the production process described by Honkomp et al. (2000). This objective function favours schedules in which new batches do not extend the overall makespan and changeovers and long processing times on non-critical packing lines are avoided. Fig. 10shows an example, in which the extended objective function leads to a more promising partial schedule. For simplicity, only the packing lines are pictured. In this example, pack batches one to four have been scheduled in a previous iteration, and pack batches five and six must be scheduled in the current iteration. The overall makespan C is driven by packing line one. Both schedules shown in Fig. 10 are optimal with respect to the overall makespan. The extended objective function favours the schedule on the right, which does not require an additional changeover.The following two constraints are aimed at tightening the makespan constraints. During the construction phase, the overall makespan of the current iteration must be greater than or equal to the makespan obtained in the previous iteration,Cprev.(31)C⩾CprevThe separate makespans can be tightened in a similar manner.(32)Cj⩾Cjprev(j∈JP)In this section, we summarise all models that are used in the proposed hybrid method.The MILP model that is used to construct an initial schedule reads as follows.(C)Min.7C+∑j∈JPCjs.t.(1)–(25), (28)–(32)Sik⩾0(k∈K⧹{S};i∈Nk∪Ik)Uii′∈{0,1}(i∈NM;i′∈NiP)Yijk∈{0,1}(k∈K;i∈Nk;j∈Jik)Xii′k∈{0,1}(k∈{PM,P};i∈Nk;i′∈{{Nk:i<i′}∪Ik}:Jik∩Ji′k≠∅)Xii′FM∈{0,1}(i∈NFM;i′∈{NFM:i<i′}∪IFM)In the improvement phase, the earliest possible start times of all operations are computed by solving optimisation problem (E).(E)Min.C+∑k∈K⧹{S};i∈Ik∪NkSiks.t.(22)–(25), (27)Sik⩾0(k∈K⧹{S};i∈Nk∪Ik)The makespanC‾in the optimal solution to problem (E) is then used as an upper bound in computing the latest possible start times of all operations. The latest start times are computed by solving problem (L).(L)Max.∑k∈K⧹{S};i∈Ik∪NkSiks.t.(22)–(25), (27)Sik⩾0(k∈K⧹{S};i∈Nk∪Ik)C⩽C‾In each iteration of the improvement phase, we reinsert the unscheduled operations by solving problem (I).(I)Min.Cs.t.(1)–(27)Sik⩾0(k∈K⧹{S};i∈Nk∪Ik)Uii′∈{0,1}(i∈NM;i′∈NiP)Yijk∈{0,1}(k∈K;i∈Nk;j∈Jik)Xii′k∈{0,1}(k∈{PM,P};i∈Nk;i′∈{{Nk:i<i′}∪Ik}:Jik∩Ji′k≠∅)Xii′FM∈{0,1}(i∈NFM;i′∈{NFM:i<i′}∪IFM)We implemented the proposed hybrid method in Ansi-C and used the Gurobi Optimizer 5.0.2 to solve the MILP and LP models. All computations were performed on an HP Z820 workstation with two Intel Xeon CPU E5-2687W processors and 128gigabytes RAM. For the construction phase of the heuristic, we set a CPU time limit of 5seconds per iteration for the Gurobi Optimizer; for the improvement phase, no CPU time limit was set. Similar to Kopanos et al. (2010), who conclude that larger group sizes do not guarantee better schedules but require more CPU time, we chose for both phases a group size of one make batch. Moreover, we applied the preprocessing methodology described in Baumann and Trautmann (2013) in both phases to exclude certain matchings between make batches and pack batches without loss of generality.For our analysis we used two test sets, which we will refer to as set I and set II. Set I consists of the 20 small- and medium-sized instances proposed in Baumann and Trautmann (2013) with up to 234 operations to be scheduled. Set II consists of 10 large-sized instances provided by The Procter & Gamble Company (cf. Honkomp et al., 2000) with up to 1391 operations to be scheduled. In the second column of Tables 2 and 3, we list for each instance the corresponding number of operations to be scheduled.For set I, we applied the hybrid heuristic with two different configurations. First, we used the 287 priority rules proposed by Fündeling and Trautmann (2006) to determine the assignment of batches to groups in the decomposition phase. For each of these rules, we applied the hybrid heuristic to each instance. Second, we applied the hybrid heuristic 100 times to each instance, each time using different random numbers to determine the assignment of batches to groups in the decomposition phase.The results for both configurations are presented in Table 2. In columns seven and eight, we provide for each instance from all 287 runs with priority rules the best makespan that was obtained after the construction and after the improvement phase. In column nine, we state the total amount of CPU time required by the 287 runs. In columns ten to twelve and thirteen to fifteen, we provide the same results after 4 runs with random numbers and after 100 runs with random numbers, respectively.We compare our results to the preliminary version of the hybrid method of Baumann and Trautmann (2011) and to the mixed-integer programming approach of Baumann and Trautmann (2013). We apply the preliminary version of Baumann and Trautmann (2011) 200 times to each instance, each time using random numbers to determine the assignment of batches to groups. The best makespan found for each instance is reported in column five of Table 2; note that the preliminary version does not include an improvement phase. Baumann and Trautmann (2013) propose 6 different model formulations; in the third and fourth column of Table 2, we list for each instance the makespan obtained by the formulation that found the largest number of feasible solutions and the corresponding CPU time requirements. The entry lim means that the MILP solver has stopped because of the prescribed time limit of one hour; the entry na means that no feasible solution was found within this time limit. In the last two columns of Table 2, we state the relative difference between the makespans obtained with the hybrid method and the analysed model of Baumann and Trautmann (2013) and the preliminary version of Fündeling and Trautmann (2006), respectively. For each instance, we report the shortest makespan in boldface.From Table 2 we draw the following conclusions.•The hybrid method generates better schedules in the construction phase when random numbers are used to assign batches to groups. Although we used 287 different priority rules, we found only for instance I-12 a better schedule after the construction step compared to the 100 runs where we used random numbers for the assignment of batches to groups. After the improvement phase, the best schedules found by either configuration are equally good. However, the required CPU time per run is higher when priority rules are applied.The proposed hybrid heuristic (100 runs) considerably outperforms the preliminary version presented in Baumann and Trautmann (2011) (200 runs). To allow for a fair comparison, we applied the preliminary version 200 times since this version does not include an improvement phase. In general, the proposed hybrid method provides better schedules in less CPU time.The model of Baumann and Trautmann (2013) solves nine of the 20 instances to optimality; for 8 of these 9 instances an optimal solution has been devised using the proposed hybrid method (100 runs). Moreover, a feasible solution was obtained using the proposed hybrid method for the instance for which no feasible solution was found within the CPU time limit by the model of Baumann and Trautmann (2013). In general, the proposed hybrid method computes solutions with the same or a slightly worse makespan than the MILP model; for the medium-sized instance I-19, a considerably better solution was obtained, even when the hybrid heuristic is only applied 4 times.For set II, we compared the results of the proposed hybrid method with the results of the heuristic presented in Fündeling and Trautmann (2006). Fündeling and Trautmann (2006) propose 287 different multi-level priority rules; we have applied the heuristic of Fündeling and Trautmann (2006) 700 times for each of these rules per instance, which required an average CPU time of approximately 45minutes. We applied the proposed hybrid method four times per instance, which corresponds to the same average CPU time. Table 3 shows the best makespan obtained by the heuristic of Fündeling and Trautmann (2006) and the proposed hybrid method for each instance in set II. The results indicate that the hybrid method considerably outperforms the heuristic proposed by Fündeling and Trautmann (2006). In columns eight and nine of Table 3, we list the average number of improvement iterations per run and the maximum number of improvement iterations over all four runs, respectively. These numbers indicate that even for instances with a large number of operations, the stopping criteria used for the improvement phase is met after a reasonable number of improvement iterations.In Tables 4 and 5, we compare the proposed strategies to eliminate redundant variables and constraints to the variable-fixing strategy presented in Castro et al. (2009) and Kopanos et al. (2010). In Table 4, we analyse the illustrative example presented in Section 4.1 and state for both strategies the size of the MILP models that are solved during the construction phase. In each iteration, the model size, i.e., the number of constraints and variables, is indicated before and after the application of the preprocessing (PP) procedure of the Gurobi solver. Table 4 shows that the preprocessing procedure of Gurobi can eliminate only part of the redundant constraints and that the relative size of this part decreases in each iteration. In Table 5, we compare the two strategies for the first 135 iterations of instance II-1. The results show that applying the proposed strategies to eliminate redundant variables and constraints greatly reduces the CPU time required to solve the MILP models.

@&#CONCLUSIONS@&#
We have presented a novel hybrid method for the short-term scheduling of make-and-pack production processes. The method consists of the following phases: decomposition, construction, and improvement. We have presented novel strategies for integrating MILP models into the construction and improvement phases of the hybrid method to efficiently solve the scheduling problems that arise in these phases. In an experimental performance analysis with large-scale, real-world instances provided by a consumer goods company, the novel hybrid method provides considerably better results compared with an existing state-of-the-art method. Moreover, in an analysis of small-scale instances for which optimal solutions are known, the novel hybrid method generates optimal or near-optimal schedules.A major advantage of our hybrid method is its applicability to a wide range of production processes. The flexibility originates from the MILP model which can easily be modified to account for process-specific operating conditions. For example periodical cleaning of the processing equipment can be considered by introducing a sufficient number of unit-specific cleaning operations and a set of constraints that impose a given maximum time difference between consecutive cleaning operations on each unit. In future studies, we will further develop the MILP model to cover such operating conditions and also extend the improvement phase from a local search procedure to a variable neighbourhood search procedure, in which a neighbourhood is defined by the size of the groups of operations to be scheduled. Another promising direction for future research is the analysis of alternative objective functions to be used in the improvement phase, possibly starting from the objective function proposed for the construction phase. An additional analysis of the convergence characteristics of the improvement phase may also provide further insights. Eventually, we intend to apply the MILP integration strategies developed in this paper to hybrid methods for other related types of production process.