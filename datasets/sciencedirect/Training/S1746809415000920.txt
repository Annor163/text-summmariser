@&#MAIN-TITLE@&#
Closed-loop control of anesthesia and mean arterial pressure using reinforcement learning

@&#HIGHLIGHTS@&#
Closed-loop anesthesia controller using reinforcement learning (RL) algorithm.Q-learning algorithm for the control of multiple parameters in dynamical systems.The proposed method is tested on 30 randomized simulated patients.Simulations demonstrate comparable performance with the recent clinical trials conducted.

@&#KEYPHRASES@&#
Active drug dosing,Anesthesia control,Hemodynamic regulation,Reinforcement learning,

@&#ABSTRACT@&#
General anesthesia is required for some patients in the intensive care units (ICUs) with acute respiratory distress syndrome. Critically ill patients who are assisted by mechanical ventilators require moderate sedation for several days to ensure cooperative and safe treatment in the ICU, reduce anxiety and delirium, facilitate sleep, and increase patient tolerance to endotracheal tube insertion. However, most anesthetics affect cardiac and respiratory functions. Hence, it is important to monitor and control the infusion of anesthetics to meet sedation requirements while keeping patient vital parameters within safe limits. The critical task of anesthesia administration also necessitates that drug dosing be optimal, patient specific, and robust. In this paper, the concept of reinforcement learning (RL) is used to develop a closed-loop anesthesia controller using the bispectral index (BIS) as a control variable while concurrently accounting for mean arterial pressure (MAP). In particular, the proposed framework uses these two parameters to control propofol infusion rates to regulate the BIS and MAP within a desired range. Specifically, a weighted combination of the error of the BIS and MAP signals is considered in the proposed RL algorithm. This reduces the computational complexity of the RL algorithm and consequently the controller processing time.

@&#INTRODUCTION@&#
Recent research in clinical pharmacology has focused on identifying “best practices” for ensuring patient safety by maximizing the desired drug effect and minimizing the drug induced side effects. This is particularly important when developing paradigms for anesthetic drug dosing. Surgical patients typically require deep sedation over a short duration of time. However, ICU patient sedation, especially patients assisted by mechanical ventilation to treat pulmonary insufficiency, can be more challenging [1]. Critically ill patients who are assisted by mechanical ventilators require moderate sedation for several days to ensure cooperative and safe treatment in the ICU. Moreover, clinical research shows that closed-loop control of anesthetic drug administration can have positive outcomes in terms of patient safety, early recovery, reduced treatment cost, and effective and practical use of clinician expertise [1–4].When continuous anesthetic drug infusion is used, a protocol incorporating daily awakening from sedation is advocated for minimizing sedative accumulation, slowing the build up to drug tolerance, and reducing the length of ICU stay [5]. Accounting for the residual drug effect of prior sedation (i.e., the effect of the drug left over due to sedation before interruption) while calculating the drug dose to be administrated after the period of daily interruption of sedation, further restricts the probability of oversedation and the associated complications. Ideally, anesthetic drug dosing should account for the patient's physiological condition, drug interaction due to coadministration of several anesthetic and physiologic drugs, residual drug effect due to daily interruption from sedation, physiological disturbances such as hemorrhage or renal impairment, interpatient variability, and changes in the characteristics of the monitoring devices and the infusion pump apparatus.Optimal drug dosing that considers the aforementioned factors is essential since oversedation or undersedation is not acceptable. Oversedation can cause hypotension, prolonged recovery time, delayed weaning from mechanical ventilation, ileus, nausea, and immunosuppression; whereas undersedation can cause anxiety, agitation, hyperoxia, tachycardia, myocardialischemia, atelectasis, tracheal tube intolerance, and infection [6]. Achieving acceptable clinical effects, while avoiding or minimizing undesired effects, is a major objective in general anesthesia. Furthermore, open-loop control can be tedious, imprecise, and time-consuming. Hence, closed-loop control for anesthesia administration is imperative to improve quality of medical care and to restrain the increasing cost of health care [1].Currently, intraoperative anesthesia administration is facilitated manually or is assisted by an open-loop target controlled infusion (TCI) pump, which is programmed using a nominal patient model to calculate the required drug dose. However, due to the interdisciplinary (medicine–mathematics–engineering) nature of the problem and the associated clinical and ethical constraints in performing clinical experiments, there is a lack of accurate mathematical models that characterize the drug disposition (pharmacokinetics) and the drug effect (pharmacodynamics) in the human body. The case of mechanically ventilated critically ill patients in the ICU is challenging since such patients require administration of multiple drugs to regulate key physiological variables, such as the level of unconsciousness, heart rate, mean arterial pressure (MAP), respiratory rates, and other vital parameters within desired limits.A few clinical and in silico trials have been conducted to validate various closed-loop control strategies for anesthesia administration [2–4,7]. Due to system complexity and system uncertainty, however, fixed-gain linear controllers have proved inadequate [1,2]. Investigations using model predictive controllers (MPC) for surgical patients with system constraints have also proved deficient in terms of prolonged parameter identification time and model dependence [8]. Even though optimal control strategies can offer “the best” solution for a given system with a given set of state and control constraints, the method is model-based and requires refinements to address system uncertainties and system disturbances [9,10]. In general, adaptive disturbance rejection controllers can work well without an accurate system model in the presence of system uncertainties and system disturbances [11,12]. However, adaptive controllers cannot directly address system optimality considerations. Hence, it is imperative to develop control techniques that can account for system modeling uncertainty and system disturbances, while providing optimal solutions that improve the reliability and applicability of closed-loop control for ICU sedation.Reinforcement learning (RL) is a developing and promising approach which offers an ideal framework for on-line identification and control of complex uncertain nonlinear dynamical systems [13]. RL allows for the learning of optimal actions without the knowledge of the complete system dynamics (or system disturbances). Moreover, since the controller (RL agent) design is performed by interacting with the system, unknown and time-varying dynamics as well as changing performance requirements can be accounted for by the controller. RL exploits the computational efficiency and speed of digital computers to stochastically employ all possible control actions and assesses a best or optimal action.Reinforcement learning-based feedback control methods have demonstrated promising performance in robot control, wind turbine speed control, image evaluation, and autonomous helicopter control [14,15]. In medical pharmacology, reinforcement learning has been used for long-term clinical planning tasks, such as the optimization of erythropoietin dosage for the treatment of anemia in hemodialysis patients [16]. RL methods basically explore the response of a system for every possible action and then learn the optimal action by evaluating how close the last action drives the system towards a desired state. The controller then exploits the learned optimal policies. RL is suitable for drug disposition control scenarios as it does not rely on a system model and learns optimal control policies based on the response to the control actions (drug infusion) of the system.In [17], the authors discuss RL-based optimal control of hypnosis for intraoperative patients. Specifically, the authors modeled the drug disposition system as a discrete-time system with three states corresponding to ΔBIS>0, ΔBIS<0, and ΔBIS=0, where ΔBIS denotes the change in the bispectral index (BIS); and three control actions (propofol dose) u corresponding to 0mg, 20mg, or 40mg. The BIS index is derived from the electroencephalogram and provides a measure of depth for anesthesia [18]. In [19], the authors present the first clinical trial for closed-loop control of anesthesia administration using reinforcement learning on 15 human volunteers. In this study, RL demonstrated patient specific control of anesthesia administration marked by improved control accuracy as compared to performance metrics of other studies reported in the literature.Surgery is a highly uncertain and hostile environment. Sedation requirements during surgery typically involve moderate to deep sedation for a short duration. In the case of ICU sedation, however, even though sedation requirements are light to moderate, they usually require long term (for several days) continuous infusion of anesthetics; and since the patient is critically ill, several life supporting drugs are typically required. Hence, drug interaction can be a factor. In addition, sedated patients may require daily interruption from sedation to reduce drug tolerance development and overall drug dosage. Hence, residual drug effect due to prior sedation periods need to be accounted.Furthermore, long term anesthetic infusion often results in drug habituation, and hence, patient pharmacologic response may change. Hence, the case of ICU sedation is challenging and necessitates long term maintenance of moderate sedation along with the regulation of vital physiological parameters of critically ill patients. Propofol administration lowers sympathetic tone and causes vasodilation, which can decrease preload and cardiac output and consequently lower the mean arterial pressure and other interrelated hemodynamic parameters. This can lead to blood pressure instability, overdose, and cardiovascular collapse [20]. Therefore, ensuring a desired range for MAP as one of the important hemodynamic parameters is vital during propofol infusion [21,22].The main objective of this paper is to apply reinforcement learning for the control of continuous intravenous infusion of propofol for ICU patients by utilizing the BIS index, while simultaneously regulating the mean arterial pressure at a desired range. Specifically, a weighted combination of the error of the BIS and MAP signals is considered in the proposed RL algorithm. This reduces the computational complexity of the RL algorithm and consequently the controller processing time. The proposed method is tested by means of simulations on 30 randomized simulated patients. Moreover, the paper presents a general framework to utilize RL-based methods such as the Q-learning algorithm for the control of multiple parameters in nonlinear dynamical systems.The remainder of the paper is organized as follows. Section 2 presents a RL-based control problem for dynamical systems and illustrates the development of an optimal control policy using a Q-learning algorithm. In addition, the pharmacokinetics and pharmacodynamics of the drug propofol in human body are discussed. In Section 2.4, the implementation of a reinforcement learning-based, closed-loop control predicated on BIS and MAP measurements is presented. Then, in Section 3, simulation results are provided and the performance of the proposed framework is evaluated. In Section 4, the limitations of this study are discussed. Finally, in Section 5, conclusions and recommendations for future work are presented.

@&#CONCLUSIONS@&#
In this paper, a reinforcement learning-based approach for the simultaneous control of sedation and hemodynamic parameter management is proposed using the regulation of the anesthetic drug propofol. Simulation results using 30 patient models with varying pharmacokinetic and pharmacodynamic parameters show that the proposed RL control strategy is promising in designing closed-loop controllers for ICU sedation to regulate sedation and hemodynamic parameters simultaneously. Furthermore, our simulations show that the RL-based, closed-loop control is robust to system uncertainties. With additional experiments to further refine and validate the optimal RL agent, and accounting for other vital parameters such as respiratory rate and heart rate variability, this method can prove promising in automating anesthesia administration in the ICU.