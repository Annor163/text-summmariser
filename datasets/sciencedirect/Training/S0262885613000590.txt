@&#MAIN-TITLE@&#
The Weibull manifold in low-level image processing: An application to automatic image focusing

@&#HIGHLIGHTS@&#
We model filtered image responses with the Weibull distribution.We represent images as points on the 2D Weibull manifold.We solve image processing problems as optmisation on the manifold.Application to automatic image focusing

@&#KEYPHRASES@&#
Weibull distribution,Image processing,Weibull manifold,Image autofocus,

@&#ABSTRACT@&#
In this paper, we introduce a novel framework for low-level image processing and analysis. First, we process images with very simple, difference-based filter functions. Second, we fit the 2-parameter Weibull distribution to the filtered output. This maps each image to the 2D Weibull manifold. Third, we exploit the information geometry of this manifold and solve low-level image processing tasks as minimisation problems on point sets. For a proof-of-concept example, we examine the image autofocusing task. We propose appropriate cost functions together with a simple implicitly-constrained manifold optimisation algorithm and show that our framework compares very favourably against common autofocus methods from literature. In particular, our approach exhibits the best overall performance in terms of combined speed and accuracy.

@&#INTRODUCTION@&#
Low-level image processing typically involves the application of some type of filter function onto the image data, which results in the extraction of a number of desired feature descriptors. These descriptors are identified, isolated and subsequently evaluated in the later stages of the image analysis pipeline. The analysis step is often carried out in some representation of the resulting feature space (e.g. histogram), an endeavour which can be both difficult and inefficient due to the arbitrary-dimensional, discretised nature and inconvenient form of the space. So for example, distances, angles and directions between elements of the feature space may not always be defined or easily and accurately approximated. Furthermore, notions such as mean and dispersion might not be applicable in certain feature spaces. Therefore, explicit information about the geometry of the feature space is usually desirable, if not necessary, for reliable processing and image analysis.The responses of difference-based filter functions on image data, are known to be Weibull distributed [16,2,49]. As such, every filtered image may be represented as a single, unique point on a statistical manifold. We exploit this fact and carry out the analysis in the 2-dimensional Weibull manifold, which is much simpler than the original feature space. The 2D, smooth Weibull manifold has well known properties that have been examined in statistical literature, but this is the first time its geometry has been applied to the area of image processing and analysis. In this new lower-dimensional representation, one may easily make use of the established notions of distance, arc-length, curvature and mean, in order to perform basic image analysis tasks in a more principled and efficient manner.We have devised a modular framework (see Fig. 1) that casts the image processing and analysis tasks as an implicitly-constrained optimisation problem, where we exploit the known manifold geometry to drive the optimisation algorithm to a good solution. For the purpose of feature extraction, we will be using simple line and edge filters in the form of the dihedral filters originally proposed by [27]. These filters, constructed with the aid of representation theory of discrete groups, are both fast and simple and allow for very efficient implementation for parallel execution. Their application in tasks such as content-based image retrieval and classification of high-level scene concepts has been described in a previous publication [49]. We demonstrate the efficacy of our framework and in particular the advantage of the Weibull manifold solution over standard methods, in the well known problem of automatic image focusing.This paper is organised as follows. In Section 2 we describe in more detail the individual components of our framework. We then continue onto Section 3 with a brief introduction to automatic image focusing and include some of the common approaches from literature. In the same section, we describe how our proposed framework may be applied to the solution of the autofocusing problem. Section 4 follows with a description of the comparative experiments run and a description of the datasets used, as well as an analysis of the results. We conclude in Section 6.The image processing framework we are introducing in this paper consists of a number of individual components that work together in a loop. First is the image acquisition component. This is the module which captures the images to be processed and makes them available to the rest of the system. This could be as simple as a look-up table of a stack of images or some interface to an imaging device. In general, the rest of the system does not have an explicit model of the imaging process, and the contents of and the conditions in the imaged scene. However, modification of some parameters or physical properties of the acquisition system is carried out and is controlled by the rest of the framework.The next step, is the filtering component. This component isolates important characteristic features from the image, such as edges or corners and generates a new representation of the image data in this new feature space. The output of the filtering stage is a vector of magnitudes of filter responses, which is known to be Weibull distributed. The natural next step therefore is to fit a Weibull distribution to the data and describe the filtered image with just two numbers, the Weibull scale and shape. Note that this is of course a global application of the filters to the whole image. One may subdivide the image in patches and apply the filters at each patch. The per-patch filtered results are still Weibull distributed, but now they capture the local image properties instead.Every such scale-shape pair may be considered as a point on the 2D Weibull manifold, and the manifold can be given a Riemannian metric, by the Fisher matrix, at every such point. Abstraction of images as manifold coordinates, allows us to turn the image processing task into corresponding operations on points such as curve fitting or optimisation. Using this line of thought, the next component is a cost function defined on the manifold, which should obtain an appropriate minimum related to the image processing task at hand. We may recover such a minimum using a manifold-based optimisation algorithm.The image acquisition modification parameters are adjusted, driven by the optimisation component and the main loop (Fig. 1) is repeated until convergence to a good solution. The main framework components are described in more detail in the rest of this section.In the proposed processing scheme we characterise the visual properties of images with the help of low-level filter systems. We use the so-called dihedral filter systems that meet the requirements of both, fast execution times and simplicity. These filters are constructed with the help of the representation theory of discrete groups, which is a generalisation of the theory of the discrete Fourier transform. Their usage is based on three observations: almost all digital images consist of pixels located on a square or hexagonal grid; the transformations that map these grids into themselves are the so-called dihedral groups; The filter functions should be adapted to these transformations. In this paper we will use filters defined on a 5×5 window and on grayscale images. The filters are constructed as follows. First we define two positions in the window as equivalent if there is a group element in the dihedral group (i.e. a rotation or a reflection) that maps one point into the other. As a result we get the six equivalence classes c1,c2,a1,a2,i and o shown in the matrix(1)c1ia1ic1ic2a2c2ia1a2oa2a1ic2a2c2ic1ia1ic1.The value at the origin o will be ignored. For the remaining 24 points we use the tools from the representation theory of the dihedral groups to divide them into six subsets of 4 points each. The first four subsets are the points in the equivalence classes c1,c2,a1,a2. The other two contain the points in the class i. From the general theory it follows that for each of these quadruples of points there are two linear combinations gx, gywhich transform like the traditional 2×2 edge detectors. For the four points (a,b,c,d) defined by the corners c1 or c2 we get the following(2)ci=abcdand gx=(a+c)−(b+d), gy=(a+b)−(c+d). We combine them to obtain the magnitude value given by the squared norm ∥e∥2=gx2+gy2 which corresponds to the output of a simple edge detector on the 2×2 pixels. A similar construction is used for all quadruples resulting in a vector E=(e12,…,e62) containing all magnitude values from the six quadruples. Finally we compute the Euclidean length ∥E∥ of the vector and use this as a measure of the “edge-strength” of the pixel distribution in this 5×5 window. The important properties of this construction is that the value ∥E∥ does not change when the underlying 5×5 pixel pattern undergoes one of the dihedral transformations (rotation and reflection) and that there are an equal number of +1 and −1 coefficients involved in the filtering.The filters used here represent one special type of edge detectors and in the framework of the representation theory, they transform like the two-dimensional representation of the group. For a detailed description of the group theoretical filter systems we refer the interested reader to the references [27,28,31]. The choice for using the dihedral filters was dictated by their simplicity of representation, their execution speed and their ease of parallelisation. In principle, it is possible to utilise other “edge-type” filters instead, which are similarly based on the calculation of pixel differences. This is because such types of filters naturally lead to the same distribution families (Weibull, discussed next) that are fundamental to our framework, meaning that we do not need to make any alterations to the rest of the framework when switching to a different filter function. Notable choices with a Weibull connection are the Gaussian-based derivative filters [16], and the Gabor filters (see [3] and Fig. 2(a)), and possibly many others.The Weibull distribution is a member of the family of extreme value distributions, and arises as a natural limiting distribution of the extrema in a random sample with size n→∞[21]. The probability density function (pdf) of a Weibull random variable x is defined as(3)px|μ,σ,k=kσx−μσk−1exp−x−μσk,forx≥μ,μ∈R,k,σ∈R+and where θ=(μ,σ,k) are the location, scale and shape parameters of the distribution respectively. For μ=0, we obtain the 2-parameter Weibull distribution.The Weibull distribution has a large domain of applications and has been traditionally used in survival analysis, reliability engineering, extreme event modelling, and material sciences. Quite recently [18,16] have established a link between the Weibull distribution and difference filters on images. In [18] the authors suggested the connection to extreme value theory [21], via the properties of sums of correlated variables [2], whereas [16] follows the alternative path of fragmentation theory [7]. We have also subsequently exploited these ideas and presented a connection between the dihedral filters from Section 2.1 and extreme value theory in [49]. More specifically, for dihedral filter systems whose kernels consist of an identical number of +1 and −1 coefficients, we have found that the statistical distribution of their norm ∥E∥ follows the Weibull model, for a vast class of natural images.The Weibull distribution is quite versatile in that, for different parameter values it can obtain the form of other commonly known distributions. For example, when k=1 its mode vanishes and becomes the exponential distribution, and for k=2, we obtain the Rayleigh distribution (see Fig. 2(a)). In addition, the Weibull pdf is roughly symmetrical for k near 3.6, when k<3.6 the distribution is left-skewed, and right-skewed otherwise (see Fig. 2(b)).The maximum likelihood estimation (MLE) of the Weibull distribution(4)θ^=argminθ∑ilnpxi|θfrom a data sample x, generally involves solving a numerical optimisation problem, since there are no closed-form solutions for the estimates of its 3 parameters. In this paper, we provide a standard steepest-descent fitting scheme for estimating the Weibull parameters from a data sample. However, for the interested reader we suggest the book by [38], which offers an extensive discussion on more advanced iterative schemes and effective initial estimates for θ.Therefore, given the Weibull log-likelihood function(5)Lx|θ=nlogk−klogσ+k−1∑ilogxi−μ−∑ixi−μσk,with n being the size of the data sample x, and a current estimate of the Weibull parametersθ^t, we may obtain the next-best estimate asθ^t+1=θ^t−λ∇θL(x|θ^t, where λ>0 is the step size parameter. The gradient components of the log-likelihood∇θLx|θ^tare given by:(6)∂Lx|θ∂μ=−k−1∑i1xi−μ+kσ∑ixi−μσk−1,∂Lx|θ∂σ=kσ−n+∑ixi−μσk,∂Lx|θ∂k=nk−nlogσ+∑ilogxi−μ−∑ixi−μσklogxi−μσ.In this work we restrict ourselves to the 2-parameter Weibull distribution, since it has a simpler form and various analytic properties of its manifold are known. We still fit the 3-parameter model p(x|μ,σ,k) as explained above, but we work with the 2-parameter equivalent p(x|σ,k)≈p(x|0,σ,k). This has the same effect as fitting the 2-parameter model to the normalised sample x–μ, and as a result no additional fitting is required. Since in practice the parameter μ accounts for very little variation in the data, we can work on the simple 2-parameter Weibull instead, without much loss of generality.A set of probability densities can, under certain smoothness conditions, be equipped with a metric that makes them into a Riemannian manifold. A Riemannian manifold may be thought of as a geometrical object that locally looks like a flat Euclidean space. This means that at every point on the manifold we have a tangent space and on this tangent space a positive definite matrix defining distances and angles between elements on the tangent space. If these matrices vary smoothly along the manifold then they define a Riemannian metric on that manifold. In the case where the points on the manifold are given by probability distributions these manifolds are known as statistical manifolds. Statistical manifolds allow for differential geometry tools to be applied to information theoretic and statistical problems. The study of such statistical manifolds has led to the development of information geometry[1] as a novel research field.From information geometry, one can show [15,37] that the Fisher information(7)gi,j=E∂2Lx|θ∂θi∂θj,induces a Riemannian metric on the parameter space of the distribution family p(θ), using for coordinates the parameters θ. For the particular case of the 2-parameter Weibull distribution, the Fisher information matrix is given by(8)gi,j=σ2k2ξ−1kξ−1kξ2−2ξ+π2/6+1σ2,whereξ=limn→∞∑k=1n1k−lnnis the Euler–Mascheroni constant.A large range of image processes, such as automatic focusing and colour mapping, when examined through our framework, will produce point sequences (along some implicit curves), lying on the Weibull manifold. There, we can analyse and characterise these processes using information geometric tools and the specific properties of the manifold. Working on this manifold, is significantly more convenient than some arbitrary-dimensional discretised histogram space that is produced from the filtered image data. Additional properties of the Weibull 2-manifold are presented in detail in [34,9].Every image that has been processed by the filtering and Weibull fitting steps of our framework, will generate one point on the manifold, which encapsulates the statistical properties of that filtered image. The next step is to assign some type of “quality” to these points, that in a way represents the suitability of the extracted features in relation to the problem which we wish to solve.This is achieved with the introduction of a cost function F, defined on the Weibull manifold. One is free to construct a wide array of cost functions that incorporate some knowledge about the problem at hand, but as long as they are expressed in the Weibull coordinate system (σ,k), we can use the same basic methodology in every case to obtain the best solution.Since we are exploring the problem of automatic image focusing in this paper, we suggest two different cost functions, which are suited for, but not necessarily restricted to, this particular problem. The first and simplest cost function, is the variance of the Weibull distribution [14], and is defined as(9)Fvσk=σ2Γk+2k−Γ2k+1k,with Г being the gamma function. The Weibull variance is a smooth, scalar valued function which increases quadratically in σ, while decreasing as a power-law in k. It behaves much in the same way as the sample variance, describing the frequency content of a signal. Variance-type cost functions are widely used in autofocus research due to their connection with Fourier optics [19]. There, the imaging system is modelled as a linear system that can be characterised by its point spread function. One can show that increased focus results in an increased high-frequency content in the image. As such, on average, the difference between neighbouring pixels will increase and so will the pixel sample variance. In addition, the variance will attain a maximum value at the best focused image of the sequence.An alternative cost function, is the arctangent of the principal eigen-vector of the Fisher information matrix gij(10)Faσk=arctanV21V11,where V[2×2] is the symmetric eigen-vector matrix of gij. Eq. (10) can be rewritten in closed form as(11)Faσk=arctan−6k4+σ2γ−ω−12ξ−1σk2,where(12)γ=6ξ−12+π2andω=−24π2σ2k4+σ2γ+6k42.Fahas similar properties to Fvbut it is smoother. It is based on the idea that during autofocusing, most of the data variance is explained by σ2, so an optimum path is one of increasing σ. When at maximum focus, there is very little variance left to be explained by σ, so the principal eigen-vector will align with the k-coordinate axis, meaning that min(Fa(σ,k))=π/2.Both of these cost functions will be evaluated in a number of focusing experiments and compared against other standard cost functions. They are illustrated in Fig. 3.We are restricting ourselves to image processing tasks where only a single parameter is modified. This is because such processes will define an implicit curve on the manifold, meaning a pre-defined search orientation along the curve. Here we present a basic approach for solving these very specific types of optimisation problems defined on manifolds. Note that for the remainder of this paper we shall consider the optimisation problem in terms of minimisation.Therefore, given a modification parameter t defined in some arbitrary interval, and some non-trivial mappingm:R→R2from the domain of t onto an implicit curve xton the Weibull manifold, we seek to minimise the expression(13)argminFtmt=argminFtxt=argminFtσt,kt,where F is some cost function defined on the Weibull coordinate system. The mapping m includes the image generation, dihedral filtering and Weibull fitting steps and maps each image onto a point on the manifold (see Fig. 4). Thus for a time sequence of t values, we obtain a sequence of manifold points that determine an implicit curve.As Eq. (13) suggests, our approach will be to work exclusively on the manifold and constrained to lie on the curve, without explicit knowledge of the curve or the mappings involved. In short, we deal with an implicitly constrained optimisation problem on a manifold.We propose an iterative estimate-update stepping solution, where given an existing sample xtwe estimate the next pointx^t+1on the curve and map back onto the modification space to obtain t+1. We then generate the actual sample xt+1, update our observations and proceed with the optimisation until convergence. We do not employ an explicit correction step betweenx^t+1and xt+1, although such a functionality can be introduced if desired.First we explore this problem in its simpler form, defined in the Euclidean space. From standard numerical optimisation theory, given a smooth cost function F(x), its gradient field ∇F(x) and a current evaluation xiof the location of the solution, we can obtain the next best, first order, estimate of the solution along the direction of the steepest descent as(14)x^i+1=xi−λi∇Fxi,where λiis some positive step-length. In the case where we are restricted to lie on an implicit curve, then the orientation of the search is pre-determined and Eq. (14) can be re-written as(15)x^i+1=xi+λiTi,where Tirepresents the (normalised) tangent vector at the point xi. The direction along Tirepresents our best (first order) estimate of the form of the curve beyond the point xi. In addition, Tiis numerically approximated via finite differences asTi=xi−xi−1xi−xi−1.The step-length λi, is chosen using the very simple analogy of the planar motion of a particle along a curve. At each location xi, we may define 3 vectors. The gradient vector ∇F(xi),Tiand its orthogonal complement Ti⊥=[−Ti(2),Ti(1)], using a right-hand orientation convention (see Fig. 5). We already have analytic expressions for F(xi) and ∇F(xi) and Ti⊥ is easily calculated given Ti. We may further decompose ∇F(xi) into its two components. The tangential part Ft=〈−∇F(xi)|Ti〉, which is the scalar projection of the gradient vector on the curve tangent, and the centripetal part Fc=〈−∇F(xi)|Ti⊥〉, which is the projection of the gradient vector along the tangent normal. The interaction between Ftand Fcis what determines the increase or decrease of the next step-length. In particular, we may formulate the step-length as(16)λi=sgnFcKFtFcλi−1,where λi−1 is the step-length at the previous iteration, K(.) is some damping kernel that maps from [−∞,∞] to [−1,1] and sgn(Fc) is used to determine the correct sign change for all possible configurations of Ti⊥ in space, relative to the gradient field. For the damping kernel we chose the logistic function(17)Kx=2a1+exp−2x−a,where a≥1 is some acceleration scaling factor (see Fig. 6). This formulation essentially suppresses infinitely large increases in acceleration when Fc→0.The behaviour of these acceleration components is easily understood if we isolate the two extremal cases in Fig. 7. In the first case, when Fc→0 then Eq. (16) reduces to λi=aλi−1 and the new step-length represents an acceleration by a. Furthermore, since ∇F(xi)∥Ti, Eq. (15) becomes the standard gradient descent in Eq. (14). In the second case, when the tangential component vanishes Ft→0 then also λi→0, because we are approaching the point of equilibrium, where the particle stops. This is the stationary point where the cost function is at a minimum along the curve.The final component is the mapping from the cost function domain, where the optimisation is carried out, onto the modification space of t. We chose the simple inverse mapping(18)Δti=λiwhereti+1=ti+Δti,which is sufficient and both Δtiand λiwill converge to 0 without any oscillations, provided that the initial step-length λ0 is not too large. The rate of convergence depends on the difference in scale between the two quantities and is adjusted by the acceleration scaling factor a in Eq. (17).As a result, we present the main optimisation routine in Algorithm 1 in Appendix B. We also include a Wolfe-type estimation step getWolfe() in Algorithm 2, to avoid unnecessary step evaluations during overshoots (see Fig. 8). For the termination conditions, we typically look at the number of maximum iterations iter, a tolerance on the decrease of the cost function Ftol, a tolerance on the change of the modification parameter Δttol and the distance between samples in the cost function space xtol.The algorithms that we have presented for the Euclidean space, have a simple and natural extension to the Weibull manifold, since at each point xi, both Tiand ∇F(xi) lie on the tangent space of xi. Thus the scalar products in Eq. (16) are now defined in the same way as the dual maps Ft=−Tik∇Flglkand Fc=−Tik⊥∇Flglk, and the orthogonal complement Ti⊥ now satisfies the two equations ∑ijTiTj⊥gij=0 and ||Ti⊥||=||Ti||, giving:(19)T⊥2=1/1+ρ2,T⊥1=−T⊥2ρ,with(20)ρ=T2g22+T1g21T1g11+T2g12.Finally, the xtol termination criterion in Algorithm 1 now changes from the Euclidean distance to the Rao distance between two points (σ1,k1) and (σ2,k2) on the Weibull manifold, and which was given by [34] as(21)s=2btanh−1logσ2/σ1−ak2−k1/k2k12+b2k2−k1/k22k12logσ2/σ1−ak2−k1/k2k12+b2k2+k1/k22k121/2,whereb=π/6and a=1−ξ.In the previous sections, we have presented all the individual components of our framework. In the next few sections, we will investigate the application of the complete framework to the solution of a typical image processing problem, and that is automatic image focusing. Automatic image focusing, or autofocusing is an interesting problem to explore since it belongs to the family of single-parameter image processing tasks, the modification of the parameter is done in some arbitrary (lens) space outside the image domain, and also additional image samples are very expensive, which makes for a good test case for our optimisation approach. Finally, this problem has been explored by various authors in the past and so comparative baseline methods are available for further evaluation.Passive autofocus systems, determine the correct image focus by analysing the data that enters the optical device. Such methods are usually based on the calculation of a “sharpness function” (SF), which is a real-valued estimate of the image focus. Commonly used sharpness functions in literature have been based on image derivatives [45,6,32,12,47,40], statistics [13,20,46,35,39] and Fourier transforms [24,44].The most desirable property that an ideal SF should possess, is that of unimodality. In other words, for a through focus series of images (i.e. images sampled between the closest and furthest possible focal points) the SF must obtain a unique global optimum at the position of best focus. Beyond this basic behaviour, there are no widely agreed requirements for an SF. In [20], the authors proposed a set of criteria that a useful SF should fulfil. From those we note the two most important, accuracy: the global optimum must be present when the image is in focus, and range: the range over which an in-focus image can be obtained must be as large as possible. This means that the SF around the global optimum must have a wide basin of attraction so that any numerical optimisation algorithm has a good chance of locating the point of best focus. The same authors also mention reproducibility, that is, the existence of a sharp peak at the global optimum as a desirable property. However, we argue that this might not always be advantageous, especially if we employ a gradient-based numerical optimisation method, or if we wish to model the region around the optimum with a low degree polynomial model (e.g. quadratic).Besides the type of SF used, passive autofocusing methods may be categorised based on their strategy for locating the global optimum (focus point). The simplest strategy [4], involves capturing a small number of images at some distance apart, thereby coarsely sampling the SF. This process is repeated at finer scales, around the location of the current optimum, until convergence. More advanced methods, such as [23,25], start by evaluating the SF at a random focus position. The camera lens is moved around the current position and additional SF samples are computed. The focus search continues along the lens direction of improving sharpness with preferably an adaptive step-length.These methods sample the SF directly and as a result they can be quite slow and expensive, since they typically require a large number of images to be captured. For faster autofocusing, other strategies have been proposed where they try to model the SF based on a limited number of coarse samples. Chen et al. [10] use a second order discrete difference equation prediction model and [43,17,41] use a second order polynomial model.Even more recently, novel methods have been introduced, which are trained on specific objects, lens positions and imaging conditions, and which can recover the optimal focus very fast and efficiently, by means of matching and a lookup table query. Most notable are those by [11,22]. The obvious drawback, is that these approaches are highly specific to the device used, the object of interest and the imaging conditions, and as such, do not scale very well as the number of possible objects increases.Our framework may be used on the autofocusing problem by direct application of the Algorithms 1 and 2, together with either of the cost functions presented in Section 2.5. Furthermore, in this particular case, the modification parameter t represents the lens position which has been mapped into the interval [0,1]. For illustration purposes, we examine a synthetic focus sequence of a real image that has been convolved with a Gaussian kernel of increasing width. The implicit curve that is generated onto the manifold is shown in Fig. 9(a) together with the contour plot of the cost function from Eq. (9). The path traced by the curve on the cost function determines the one-dimensional SF F(σ(t),k(t)) in Fig. 9(b). Observe how this SF behaves much in the same way as common SFs from literature. We stress once again that although we seek a minimum for F(σ(t),k(t)), we are in fact carrying out the optimisation in the 2-dimensional manifold curve in Fig. 9(a) where the derivatives of F are well defined, unlike the unknown derivatives of F w.r.t t in Fig. 9(b), that require costly numerical approximations.Also notice in Fig. 9(b) that for regular sampling in the lens parameter space t, we get irregular samples in the SF domain. This is more apparent near the narrow region around the minimum where the SF drops significantly, but otherwise is almost flat. The same behaviour occurs also in the 2d curve in Fig. 9(a).The basic interpretation of this is that when the images are blurred they all look very similar and one has to take very large lens steps to move away from the “blurred region” of the focus space. This is why the tail(s) of the SF typically look flat. The danger here is that for a fixed lens step λ the optimisation might terminate if no significant progress is made.On the opposite side, when we start to obtain focused images, then each subsequent focused image will look considerably different from its predecessor. The SF will change dramatically, which explains the sharp drop. In the “focused region” (i.e. near the basin of the SF) a fixed lens step will lead to an ever-decreasing SF value until the minimum is obtained. The risk here of course is that we might overshoot a very narrow basin.We may understand this behaviour further if we examine the squared arc length element in Fig. 9(c), which is given by(22)ds2=k2σ2dσ2+2ξ−1σdσdk+ξ2−2ξ+π2/6+1k2dk2,at an infinitesimally small region of the manifold around each position t. Where ds2 is large, i.e. in the blurred region, neighbouring points on the manifold are far apart and for a fixed, small step-length we may not move very much on the manifold. The SF might thus appear flat and one would need to take larger steps λ in order to make progress. On the contrary, where ds2 is small, i.e. on the focused region, neighbouring points on the manifold are very close together and so the same λ might produce a very large manifold step. One would therefore need to take smaller steps to avoid missing the solution.We emphasise here that regular t sampling versus irregular SF responses is not an effect of the manifold, since it occurs for all SFs (see for example the Tenenbaum gradient and sample variance in Fig. 9(b)). All the pictured SFs have a similar monotonic decrease. However, we argue that ours is the only method that by using additional information from the geometry of the manifold, can provide a way of designing optimisation algorithms that can adaptively adjust λ depending on where in the focus space we are.

@&#CONCLUSIONS@&#
