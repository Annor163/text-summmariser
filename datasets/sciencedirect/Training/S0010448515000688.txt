@&#MAIN-TITLE@&#
h-graphs: A new representation for tree decompositions of graphs

@&#HIGHLIGHTS@&#
h-graphs, a new representation for tree decompositions of constraints graph is presented.h-graphs explicitly capture construction steps dependencies in a tree decomposition.An application to speed up computing feasibility ranges for constraint parameters is described.

@&#KEYPHRASES@&#
Parametric solid modeling,Geometric constraint solving,Constraint graphs,Tree-decompositions,Construction steps dependencies,Parameter ranges,

@&#ABSTRACT@&#
In geometric constraint solving, 2D well constrained geometric problems can be abstracted as Laman graphs. If the graph is tree decomposable, the constraint-based geometric problem can be solved by a Decomposition–Recombination planner based solver. In general decomposition and recombination steps can be completed only when steps on which they are dependent have already been completed. This fact naturally defines a hierarchy in the decomposition–recombination steps that traditional tree decomposition representations do not capture explicitly.In this work we introduce h-graphs, a new representation for decompositions of tree decomposable Laman graphs, which captures dependence relations between different tree decomposition steps. We show how h-graphs help in efficiently computing parameter ranges for which solution instances to well constrained, tree decomposable geometric constraint problems with one degree of freedom can actually be constructed.

@&#INTRODUCTION@&#
Many applications in computer-aided design, computer-aided manufacturing, kinematics, robotics or dynamic geometry are conveniently modeled by geometric problems defined by geometric constraints with parameters, some of them representing dimensions. These generic models allow the user to easily generate specific instances for various parameter and constraint values.When parametric models are used in real applications, it is often found that instantiation may fail for some parameter values. Assuming that failures are not due to bugs in the system, they should be attributed to a more basic problem, that is, a certain combination of constraints in the model and values of parameters do not define a valid shape.The failure to instantiate the model poses naturally the question of how to compute ranges for parameters such that model instantiation is feasible. This problem or restricted versions of it have been addressed in the literature. Shapiro and Vossler,  [1], and Raghothama and Shapiro,  [2–4], developed a theory on validity of parametric family of solids by investigating the relationship between Brep and CSG schemas in systems with dual representations for solid modeling. The formulation is built on formalisms of algebraic topology. Unfortunately, it seems a rather difficult problem transforming these formalisms into effective algorithms.Joan-Arinyo and Mata  [5] reported a method to compute feasible ranges for parameters in geometric constraint solving under the assumption that values assigned to parameters are non-trivial-width intervals. The method applies to complex systems of geometric constraints in both 2D and 3D and has been successfully applied in the dynamic geometry field,  [6]. It is a general method, the main drawback, however, is that it is based on numerical sampling.Hoffmann and Kim  [7] developed a constructive approach to calculate parameter ranges for systems of geometric constraints that include sets of isothetic line segments and distance constraints between them. Model instantiation for distance parameters within the ranges output by the method preserve the topology of the set of isothetic lines.Sitharam et al. in  [8,9] reported recent theoretical results concerning the computation of intervals of realizable solutions to linkages, that is, 2D geometric constraint problems with one degree of freedom where the parameter is a distance value.For the first time, van Der Meiden and Bronsvoort  [10] described a method to directly figure out the allowable range for a single parameter in the problem, called variant parameter, such that an actual solution exists for any value in the range. The method was formalized by Hidalgo and Joan-Arinyo in  [11,12] where a correctness proof along with specific implementation details were given. This approach heavily relies on identifying the set of construction steps in the solution to the constraint problem the actual execution of which depends on the current value assigned to the variant parameter. So far identifying the dependencies concerning the construction step under consideration required a specific computation,  [10]. Hence devising a method able to efficiently identify beforehand the whole set of dependencies existing between the construction steps of a constraint problem would be a valuable accomplishment.In this work we introduce h-graphs, a new representation for graph based constructive solutions to the geometric constraint problem. The h-graph captures the naturally occurring dependency relationships between construction steps in the solution of a geometric constraint problem. As well, computing parameter ranges where the solution is feasible using h-graphs improves over the method described by Hidalgo and Joan-Arinyo in  [11,12].In what follows we first give a short intuitive introduction to the geometric constraint solving problem to motivate the need for computing parameter ranges. Then we recall the graph tree decomposition, we give technical definitions related to dependence, define h-graphs, show some properties of h-graphs and, we describe an algorithm to compute h-graphs from a tree decomposition which is a solution to a geometric constraint problem. Finally we illustrate how actual dependencies are computed applying the h-graph to a geometric constraint problem with one degree of freedom.Assume that we want to build a triangle the vertices of which are the pointsa,b,clike those shown in Fig. 1(a). We want pointato be placed at a distanced1from pointband pointcto be placed at a distanced2from pointb. Moreover we want that the edge bounded by pointsa,bmakes an angleλwith respect to the edge bounded by pointsa,c. It is well known that this description properly defines a triangle in the Euclidean space. A ruler-and-compass procedure to build the triangle is illustrated in Fig. 1(b) and can be described as follows,1.Draw an arbitrary straight line, sayX.On lineXmark an arbitrary pointa.On lineXmark a pointbat a distanced1froma.Draw a lineLthrough pointaand at an angleλwith lineX.Draw a circleCwith centerband radiusd2.Intersections of circleCand lineLyield pointscandc′that along with pointsaandbdefine triangles which fulfill the requirements described.If the procedure is applied after assigning specific values tod1,d2andλ, the geometric construction can be carried out depending on the specific assignment of values.Many techniques have been reported in the literature that provide powerful and efficient methods for solving geometric problems defined by constraints. For a review, see Hoffmann et al.  [13]. Computer programs that solve geometric problems defined by constraints are called solvers. Among all the geometric constraint solving techniques, our interest here focuses on the one known as constructive. See  [14–18] and the references there in for an in depth discussion on this topic.Constructive solvers belong to the Decomposition–Recombination solvers, in short DR-solvers, class  [15] and have two main components: the analyzer and the constructor. Given the geometric elements and the constraints defined on them, the analyzer figures out a description of how geometric elements are placed with respect to each other in such a way that the constraints are fulfilled. This description is called construction plan.If the analyzer succeeds, actual values are assigned to the parameters and the constructor builds an instance of a placement for the geometric objects, provided that no numerical incompatibility arises due to geometric degeneracy.In the example described above and illustrated in Fig. 1, the set of geometric elements includes the points{a,b,c}while the constraints are the distancesd1,d2and the angleλ.In this scenario asking for the set of values ofλfor which the construction is actually feasible seems natural. To answer this question, efficiently computing dependencies between construction steps in the construction plan plays a central role.In this work we capture a 2D geometric constraint problem as a graphG=(V,E)whereVis a finite set of nodes or vertices which stand for the geometric elements in the problem andEis a collection of edges. An edge is an unordered pair(u,v)of distinct verticesu,v∈V(G). In generalV(G)andE(G)will denote respectively the set of vertices and edges of the graphG.In what follows we only consider 2D well constrained geometric constraint problems, that is, problems with a finite number of solution instances. In this work, these problems are abstracted as Laman graphs,  [19],G=(V,E)with|V|≥3and such that1.|E|=2|V|−3.For every subgraphG′=(V′,E′)withV′⊂VandE′⊂E,|E′|≤2|V′|−3.Tree decompositions, also known as triangular decompositions, are a tool widely used in geometric constraint solving mainly when the underlying solving technique belongs to the DR solvers class. The resulting decomposition describes the solution to the geometric constraint problem by fixing how geometric elements are placed with respect to each other to fulfill the constraints. In this section we recall the concept of tree decomposition of a graph, we formalize the tree decomposition as a rewrite system and show some properties which will be used later on.We start by introducing the concept of set decomposition illustrated in Fig. 2. LetSbe a set with, at least, three different members, saya,b,c. We say that three subsets ofS, sayS1,S2andS3​are a set decomposition ofSif1.S1∪S2∪S3=S,S1∩S2={a},S2∩S3={b}andS3∩S1={c}.Next we introduce the concept of tree decomposition step of a graph. See Fig. 3. LetG=(V,E)be a graph, the subsetsV1(G),V2(G)andV3(G)define a tree decomposition step ofGif they are a set decomposition ofV(G)and for every edgee=(v1,v2)withe∈E(G),v1,v2∈V(Gi)for somei,1≤i≤3. SubgraphsGi=(Vi,Ei)induced inGby a tree decomposition step are called clusters.Roughly speaking, a tree decomposition step of a graphG, is a graph decomposition induced by a set decomposition of verticesV(G)such that the two vertices bounding each edge inE(G)belong to a given cluster.Finally we define the tree decomposition of a graph. LetG=(V,E)be a graph. We say that a ternary treeTis a tree decomposition ofGif1.Gis the root ofT,Each nodeG′⊂GofTis the father of exactly three nodes, sayG1′,G2′andG3′, which are the clusters output by a tree decomposition step applied to a subgraph ofG, andEach leaf node contains a cluster with exactly two verticesa,bofVsuch that edge(a,b)is inE(G).A graph for which there is a tree decomposition is called tree-decomposable. In general, a tree decomposition of a graph is not unique. Fig. 4shows two different tree decompositions for the graph given in Fig. 3(a). Notice that some decompositions are applied in the tree in Fig. 3(a) in different levels than they applied in the tree in Fig. 3(b). For the sake of clarity, tree decompositions only show the set of vertices included by clusters. Labels on the tree edges will be defined later on.As shown in  [20,17], the process of actually building a solution to a geometric constraint problem described as a tree decomposition of a graph, that is, the solution constructor, can be abstracted as a rewrite system,  [21], where terms are sets of clusters. Given a graphG=(V,E)the starting set of clusters is defined asCG={{u,v}:(u,v)∈E(G)}.Clusters are rewritten using the tree decomposition step as a reduction rule, which is denoted by an arrow→and formally defined as follows.Definition 3.1LetCbe a set of clusters where there are three clustersCi,1≤i≤3such that pairwise share one vertexV(C1)∩V(C2)={a},V(C2)∩V(C3)={b},V(C3)∩V(C1)={c}witha,bandcdistinct. Then the rewrite ruleC→C∗is defined asC∗=(C−{C1,C2,C3})∪{C1∪C2∪C3}.Definition 3.2A derivation is a sequence of applications of the rewriting rule in (C,→). We will denote a derivation byC→∗C∗.Definition 3.3A termC∗is derived fromCif and only if there is a derivation such thatC→∗C∗. A termCto which the tree decomposition rule does not apply is called irreducible or normal form.To us, the most important result in reduction systems is that the reduction system(CG,→)has a unique normal form that is obtained after finitely many reductions,  [20,17]. In these conditions, if the geometric constraint problem is well constrained, that is, the problem has a finite number of solution instances, the derivation reduces the initial setCGto a single cluster. The sequence of construction steps identified by the derivation places a fixed set of triplets of geometric elements in relative positions such that the constraints hold.If{a,b,c}are the nodes pairwise shared by clustersC1,C2,C3, denote by→{a,b,c}the reduction that merges the clusters. In these conditions, the setRC(∗)={{a,b,c}:→{a,b,c}∈→∗}is the set of triplets or reductions in the derivation→∗.According to  [20,22], each triplet of hinges is used once and only once in a reduction process. This means that given two different reduction sequences over the same starting and ending terms,C→∗C∗andC→∗′C∗we haveRC(∗)=RC(∗′).Edges in the tree decompositions shown in Fig. 4 are labeled with the reduction that merges three clusters into a new one. The set of triplets is the same in both tree decompositions,RC(∗)={{a,b,c},{a,d,c},{a,h,f},{b,f,e},{c,d,e},{f,i,g},{f,i,j},{g,h,i}}.From now on, given a tree-decomposable graphG=(V,E), the derivationCG→∗C∗applied by the solution constructor to the tree decomposition ofGto actually build a solution, will be called the derivation associated with the graphG. We close this section showing a property of clusters generated by a derivation.Remark 3.1Consider the derivationC→∗C∗. For each pair of clustersCi∗,Cj∗∈C∗withi≠j,|V(Ci∗)∩V(Cj∗)|≤1.ProofBy definition, a cluster places a set of vertices with respect to a local framework of reference in such a way that constraints defined on them hold. For a contradiction assume thatCi∗andCj∗are two different clusters inC∗withui,vi∈V(Ci∗)anduj,vj∈V(Cj∗)such that the pairsui,ujandvi,vjrespectively designate the same pair of vertices sayu,v∈V(C∗). Then the pairsui,vianduj,vjdefine a rigid transformation that places vertices in one cluster with respect to the other one. That isV(Ci∗)andV(Cj∗)belong to the same cluster.□In what follows the clusters merged by the reduction→{u,v,w}will be sometimes distinguished from each other by explicitly giving the pair of vertices in the reduction triplet included in the cluster, that is denoting them asCuv,CvwandCwu.We have seen in Section  3 that given a tree decomposable graphG=(V,E), in general, the tree decomposition is not unique. But the set of hinges is unique and the final cluster derived by the reductionCG→∗Cis canonical. This means that when in a tree decomposition several reduction steps can be applied, the specific reduction selected does not matter. For example in the tree decomposition shown in Fig. 4(a), if the current cluster term includes the clusters{a,b},{b,c},{c,a},{f,g},{g,i},{i,f}, then reductions{a,b},{b,c},{c,a}→{a,b,c}{a,b,c}and{f,g},{g,i},{i,f}→{f,g,i}{f,g,i}can be applied in any sequence without affecting the resulting set of clusters.However, in general, some reductions in a tree decomposition derivation can only be carried out after completing some other reductions. For example, reduction→{f,h,j}in Fig. 4(a) can be completed only after completing reductions→{f,g,i}and→{g,h,i}. We say that reduction→{f,h,j}depends on reductions→{f,g,i}and→{g,h,i}. Dependence naturally introduces a hierarchy in the reduction steps of a derivation over a tree decomposition.We start by defining the concept of minimal well constrained cluster induced by two vertices within a cluster.Definition 4.1Consider a well constrained Laman clusterCand letu,vbe two vertices inV(C). The minimal well constrained cluster inCwith respect to the pair of verticesu,vis the clusterC′=(V′,E′)induced inCby the minimal set of verticesV′⊆V(C)such thatu,v∈V′andC′is well constrained.In what follows we shall denote the minimal well constrained cluster within clusterCwith respect to the verticesu,v∈V(C)asmwcC(u,v). Notice that if verticesu,vdefine the edge(u,v)∈E, triviallymwcC(u,v)=({u,v},{(u,v)}).Clusters in(CG,→)are Laman well constrained, tree-decomposable graphs. Moreover the set of reductionsRC(∗)leading the starting termCGto its normal form is unique. By definition,mwcC(u,v)is well constrained. Moreover, given thatCis Laman, well constrained and tree-decomposable and thatmwcC(u,v)is a subgraph ofC,mwcC(u,v)is a Laman tree-decomposable graph with reductions inRC(∗). ThereforemwcC(u,v)is well defined and there is a derivationCG→∗mwcC(u,v)with reductions inRC(∗).In what follows clustersCishall be denoted asCabwhereaandbare vertices in a triplet{u,v,w}on which the reduction is applied. Thus we will denote the minimal well constrained clustermwcCab(a,b)just asmwcCab.We consider two different dependence categories: co-dependence and indirect dependence. Technically we define them as follows. Refer to Fig. 5.Definition 4.2Consider the termC. Let→{u1,v1,w1}be a reduction inRC(∗)involving three clustersCabwitha,b∈{u1,v1,w1}anda≠b. LetmwcCabbe such that(a,b)is an edge inE(mwcCab). Let→{a,b,w}be the reduction inRC(∗)which merged the clusters({a,b},{(a,b)}),CbwandCwa. Then we say that reductions→{u1,v1,w1}and→{a,b,w}are co-dependent on each other.Co-dependence is symmetric and relates a set of reductions at the same hierarchical level. Fig. 5(a) shows the general case of co-dependence. Assume that clustersCu1w1,Cv1w1,Caw,Cbwand some cluster, sayCab, including the edge(a,b)belong to the current term. Then reductions→{a,b,w1}and→{a,b,w}can be applied in any sequence. Fig. 5(b) is a particular example for the clusterCab. Fig. 5(c) shows the minimal well constrained clustermwcCu1v1(a,b). The clusterCu1v1is generated by the reduction→{a,b,w}.Indirect dependence relates reductions at different hierarchical levels by capturing the idea that there are reductions which can be carried out only after completing other reductions. Generically we define indirect dependence as follows.Definition 4.3Consider the termC. Let→{u1,v1,w1}be a reduction inRC(∗)involving three clustersC(ab)witha,b∈{u1,v1,w1}anda≠b. LetmwcC(ab)be such that|E(mwcC(ab))|>3. We say that reduction→{u1,v1,w1}indirectly depends on the set of reductions in the derivationCG→∗mwcC(ab).It is easy to see that indirect dependence is transitive. Fig. 6(a) illustrates the definition of indirect dependence in the general case. Fig. 6(b) is a particular example and Fig. 6(c) details the minimal well constrained clustermwcC(u1v1). Notice that on the one hand vertexaand the edges incident on it have been removed without affecting the rigidity of the resulting graph. On the other hand, it is clear that before attempting to apply reduction→{u1,v1,w1}, reductions→{u1,u2,w2},→{u2,v2w2}and→{v1,v2,w2}must be completed to build the clustermwcC(u1v1). In these conditions, consider the reductionCuv,Cvw,Cwu→{u,v,w}Cuvw.LetRab(∗)denote the set of reductions in the derivationCG→∗mwcC(ab). Clearly reduction→{u,v,w}indirectly depends on the reductions in the setRuv(∗)∪Rvw(∗)∪Rwu(∗).Dependencies between reductions over a tree decomposition of a graph are not explicitly captured by the tree representation. Here we introduce a new way to represent a tree decomposition of a graph which explicitly captures the hierarchy introduced by dependencies in the reduction steps over the tree decomposition.The new representation for graph tree decomposition is called hinges graph, in shorth-graph, and we formally define it as follows.Definition 5.1LetG=(V,E)be a tree-decomposable graph. Theh-graph, associated toGis the graphHG=(V,EC∪EI), whereVis the set of reductions in the associated derivationCG→∗C∗,ECis the set of unordered pairs(ν1,ν2)such that reductionsν1,ν2are co-dependent and,EIis the set of ordered pairs(ν1,ν2)such that reductionν2indirectly depends on reductionν1.Co-dependencies are represented by non-directed edges. Indirect dependencies are represented by directed edges. Fig. 7shows the h-graphHGassociated to the tree decompositions in Fig. 4 for the graphGin turn shown in Fig. 3(a).We shall now show that the h-graph for a given graph is unique.Theorem 5.1LetG=(V,E)be a tree-decomposable graph. The h-graphHGassociated withGis unique.ProofLetTbe a tree decomposition ofG. The set of hinges triplets inTor equivalently the set of reductions in the derivationCG→∗C∗is unique. Thus the set of nodesV(HG)is unique. Since the derivation is canonical and a co- or indirect dependency can always be identified between a pair of adjacent reductions, the h-graphHGis unique.□Given a tree-decomposable graphG=(V,E)and the associated derivationCG→∗C∗for it, there is an associatedHG. Moreover, given a tree-decomposable subgraphG′⊂Gand a derivation for itCG′→∗C′∗, there is a h-graphHG′.Consider now the h graphHGand letH′be a subgraph ofHGdefined in the usual way. Due to the dependencies, it is unclear whether there is a tree-decomposable subgraphG′ofGsuch thatH′=HG′′. In what follows we describe the conditions under whichG′exists. First we define h-subgraphs.Definition 5.2LetG=(V,E)be a tree-decomposable graph andHG=(V,EC∪EI)the associated h-graph.HG′=(V′,EC′∪EI′)is ah-subgraph ofHGif and only ifV⊂V′,EC′⊂ECandEI′⊂EI.Letνandν′be reductions inV(HG)and denote bydepHG(ν)the set of reductions inHGthat indirectly depend on reductionν.Definition 5.3LetG=(V,E)be a tree decomposable graph andHG=(V,EC∪EI)the associated h-graph. Consider the h-subgraphHG′=(V′,EC′∪EI′)⊆HG. We say that the h-subgraphHG′is complete if for allν∈V′,depHG(ν)⊆V′.Fig. 8(a) and (b) shows complete h-subgraphs of the h-graph in Fig. 7. Notice that complete h-subgraphs include all the reductions needed to complete a derivation for the h-subgraph. Fig. 8(c) shows a h-subgraph where reduction→{b,e,f}cannot be carried out because reductions→{a,b,c},→{a,c,d}and→{c,d,e}are missing. Hence this h-subgraph is not complete.Fig. 9shows tree decompositions built from the complete h-subgraphs in Fig. 8(a) and (b).Theorem 5.2LetG=(V,E)be a tree-decomposable graph,HGthe associated h-graph andHG′a complete h-subgraph ofHG. Then there is a tree decomposable subgraphG′⊆Gsuch thatHG′′=HG′.ProofIfHG′=HGthe theorem trivially holds.Assume now thatHG′(V′,EC′∪EI′)is a complete proper h-subgraph ofHG. Clearly a graph, sayG′=(V′,E′), can always be built fromHG′withV′⊆VandE′⊆Einduced fromEC∪EI. Given thatHG′is complete, the set of decomposition steps inG′built fromHG′can be carried out thusG′is tree decomposable.□Fig. 10shows graphs associated to the complete h-subgraphs in Fig. 8(a) and (b) which illustrate Theorem 5.2.Finally we prove that inclusion is preserved for h-subgraphs.Theorem 5.3LetG1=(V1,E1)andG2=(V2,E2)be two tree-decomposable graphs, andHG1,HG2the respective associated h-graphs. Then,HG1⊂HG2if and only ifG1⊂G2.ProofFor the if part apply Theorem 5.2 withG′=G1andG=G2.For the only if part assume thatHG2(V2,EI2∪EC2)⊆HG1(V1,EI1∪EC1). This would imply thatV2⊆V1orE2⊆E1or both hold. ThereforeG2⊆G1. This contradiction completes the proof.□Before describing how the minimal well constrained cluster is computed we need to prove some simple results. Letdeg(v)denote the degree of a vertexvin a given graphG=(V,E).Theorem 5.4LetG=(V,E)be a well constrained graph with|V(G)|>3. Then there is at least one vertexv∈V(G)such thatdeg(v)≥3.ProofBecauseGis well constrained we have that|E|=2|V|−3. We know that for a well constrained graph with|V(G)|>3, the minimum degree of a vertex is 2. For a contradiction assume now that for each vertexv∈V(G),deg(v)=2. Then|E|=|V|.□Theorem 5.5LetG=(V,E)be a well constrained Laman graph with|V(G)|≥3. The graphG′=(V′,E′)resulting from removing a vertex of degree two fromV(G)and the edges inE(G)incident onvis well constrained and Laman.ProofBy hypothesis|E|=2|V|−3. But|V′|=|V|−1and|E′|=|E|−2. Then|E′|+2=2(|V′|+1)−3. That is|E′|=2|V′|−3. The graphG′resulting from removing a vertex of degree 2 from a Laman graphGpreserves the internal distribution of edges carried over fromG, see Fig. 11. ThusG′is a well constrained Laman graph.□Theorem 5.6LetG=(V,E)be a well constrained graph with|V(G)|≥3. The graphG′=(V′,E′)resulting from removing a vertex of degree three or higher fromV(G)and the edges inE(G)incident onvis no longer well constrained.ProofLetvbe the vertex withdeg(v)≥3removed fromV(G). By hypothesis|E|=2|V|−3. But|V′|=|V|−1and|E′|=|E|−deg(v). Then|E′|+deg(v)=2(|V′|+1)−3. That is|E′|=2|V′|−3+(2−deg(v)). Now,deg(v)≥3makes that2−deg(v)≤−1. Hence|E′|<2|V′|−3.□Taking into account the results shown above, to compute the minimal well constrained cluster we need to distinguish two situations. First consider that the cluster is a leaf node of the graph tree decomposition which contains the edge(u,v). Then trivially the edge itself is the minimal well constrained cluster. Notice that if the cluster has exactly three vertices the minimal well constrained cluster is a triangle’s edge.For clusters with more than three vertices we compute themwcC(u,v)in two steps. First we compute the lowest common ancestor of verticesuandv, denotedLCAG(u,v), in the tree decompositionTassociated to the constraint graph at handG. Clearly this is the smallest cluster inTwhich includes verticesuandv. Then we iteratively remove fromLCAG(u,v)all the two degree vertices except verticesuandv.In the general case, the minimal well constrained cluster includes the two vertices consideredu,vplus, at least, one vertex with degree three or higher. In this case, we recursively remove from theLCAG(u,v)two out of the three subclusters induced by triplets{a,b,c}inLCAG(u,v)while keeping the subcluster, sayLCAab, such thatu,v∈V(LCAab). Then the procedure is recursively applied toLCAabuntil no more degree 2 vertices different fromuandvcan be removed. Procedures are shown in Algorithms 1 and 2.Fig. 12illustrates how the algorithms compute themwcC(a,d). First vertices of degree 2,v2,v1andv3, are sequentially removed. Then the triplet{a,b,c}and clustersLCAab,LCAbcandLCAacare identified. Next the clusterLCAabis selected because verticesa,dbelong toV(LCAab). Then the procedure is recursively applied toLCAabuntil no more degree 2 vertices can be removed. The resulting cluster is themwcC(a,d).The set of reductions that builds the minimal tree-decomposable cluster is well defined and is easily identified by visiting nodes in the tree decomposition rooted atLCAC(u,v).Next we describe how to compute the h-graph associated to a given graphG=(V,E)for which a tree decompositionTis known. The approach takes advantage of two facts. First, as described in Section  3.2, the reduction system (CG,→) is canonical. Therefore when more than one reduction applies, the specific sequence in which they are applied does not matter and we choose to apply first those reductions which rewrite edges in the starting termCGinto triangles. Second, dependencies between reductions over the starting term, if any, are co-dependencies. Having these facts in mind the algorithm includes three main steps. First we compute a starting graph by identifying in the tree decompositionTthe set of starting co-dependencies. Then a raw h-graph is computed by expanding the starting graph with the remaining co-dependencies and the full set of indirect dependencies. In the last stage, the h-graph is simplified.The algorithm makes use of the following data structures. A reductionrrepresents a tuple(Cuv,Cvw,Cwu,u,v,w)whereCuv,Cvw,Cwuare the three clusters to be rewritten andu,v,wis the hinges triplet for the reduction.The set of clusters in the current term of the rewriting system is stored in a listC.The set of reductions which can be applied on the current set of clustersCis stored in the listR. This list is provided with the iteratorR.first()andR.next().The listVcollects the set of the h-graph vertices. Each vertexvinV=V(HG)will store a reductionr.The procedure to compute the starting h-graph is described in Algorithm 3. The algorithm inputs a pointer to the tree decompositionT. The starting h-graph is the empty graph andCis initialized to the set of clusters corresponding to the leaf nodes inT.Rinitially stores the set of reductions which can be applied on the set of the tree decomposition leaf nodes. Clearly, for any pair of reductions inRthey are either independent or co-dependent on each other. Accordingly, the set of co-dependent edgesECis conveniently updated. Finally, reductions inRare included inVand the set of clustersCis updated by serially applying the reductions inRto the current rewriting system term.Once the h-graph has been initialized, the computation proceeds as described in Algorithm 4. In the graph-based constructive geometric constraint solving approach, the solution constructor has figured out a solution to the constraint problem when all the vertices in the graph are placed with respect to a common framework of reference. This means that all the construction steps have been carried out. Equivalently, the underlying rewrite system has just rewritten the normal form and|C|=1should hold for the number of clusters in the current term.The loop in the algorithm first identifies one reduction which applies to the current term. Then the minimal well constrained clusters induced by the vertices in the reduction triplet within each cluster involved in the reduction considered are computed. Next h-graph edges are identified and included in the corresponding set of h-graph edges according to whether the dependencies are either co-dependent, EC, or indirect, EI. Finally the reduction under consideration is both added to the set of h-graph vertices,V(HG), and actually applied to the current term C to update it.When the main loop in Algorithm 4 is over, we end up with a raw h-graph. For example, for the tree decompositions shown in Fig. 4, the h-graph generated would be the one depicted in Fig. 13.In general, the raw h-graph includes some extra edges. Taking into account that indirect dependence is transitive, directed edges({a,b,c},{a,h,f}),({a,c,d},{a,h,f})and({c,d,e},{a,h,f})∈V(HG)in the raw graph depicted in Fig. 13 are redundant. If we do not consider undirected edges, the raw h-graph is a directed acyclic graph. Thus the final h-graph is computed as the unique transitive reduction of the raw h-graph,  [23,24]. The h-graph output by the simplification process is shown in Fig. 7.In the geometric constraint problem described in Fig. 1, when values for, say, distancesd1andd2are fixed while the value assigned to the angleλchanges, the problem has one degree of freedom andλis the variant parameter. Consider now the geometric constraint problem abstracted by the graphG=(V,E)depicted in Fig. 14. Edge(c,d)∈V(G)defines a variant parameterλfor the degree of freedom in the underlying geometric problem. The associated h-graphHG=(V,EC∪ES)is shown in Fig. 7.Constraint-based geometric problems with one degree of freedom can be found in the core of, among others, parametric solid modeling and dynamic geometry.  [11,12,10]. In these fields, knowing beforehand which is the set of values forλsuch that the geometric construction can actually be built plays a central role. This challenging and longtime standing problem used to be solved by regular sampling in the parameters space. See  [6].A direct method to compute the set of values ofλfor which the construction plan solution to a constraint problem is feasible was described for the first time in  [25,10]. The method was formalized in  [11,12] where a correctness proof along with specific implementation details were given.In this section we describe an efficient algorithm to compute as a preprocess the set of reduction steps in a tree decomposition of a graphG=(V,E)which depend on the variant parameterλ. The hierarchy captured by the h-graphHG=(V,EC∪ES)associated to the tree decomposition of graphGleverages the computation of dependencies and the method improves over the approach reported in  [11]. Recall that given a tree-decomposable graphG, the associatedHGis unique.Dependencies are computed in two steps as described in Algorithm 5. Assume that the variant parameter isλ=(u,v)∈E(G). First we collect the set of co-dependencies of the variant parameter which are those reductions inV(HG)including edge(u,v). This set, say DD, is computed visiting once each vertex inV(HG).In the second step, we first store in a stack the indirect dependencies, if any, related to each co-dependence. Then all what we need to do is to figure out the set of indirect reductions ID by recursively visiting the reductions inV(HG). When the stack is empty, the ID set has been completed.To illustrate how the algorithm works consider again the graphG=(V,E)in Fig. 14 where edge(c,d)defines the variant parameterλand the associated h-graphHG=(V,EC∪ES)is shown in Fig. 7. Reductions inV(HG)which include verticescanddas hinges are→{a,c,d}and→{c,d,e}. These reductions are co-depend and allow to fix the range forλ. Reductions which indirectly depend on→{a,c,d}and→{c,d,e}are→{b,e,f}and→{a,f,h}. These reductions indirectly depend onλ.Notice that the complexity of the constraint problem does not matter. When the geometric constraint problem is solved by the tree decomposition approach, a parameter range is always figured out on a triangle. For a detailed description on how to compute feasible ranges for the variant parameter in geometric constraint problems with one degree of freedom see  [11,22]. As an example, assume that edges(a,c),(a,d),(c,e)and(e,d)are point–point distance constraints with valuesd1,d2,d3andd4respectively. Assume thatλ=(c,d)is a point–point distance constraint for which we want to know the range of values such that both reductions,→{a,c,d}and→{c,d,e}, can be carried out. This range can now be figured out as follows. On the one hand, the triangle inequality for reduction→{a,c,d}fixes that|d1−d2|≤λ≤d1+d2. On the other hand for reduction→{c,d,e}, we have that|d3−d4|≤λ≤d3+d4. Denoteλmin=max(|d1−d2|,|d3−d4|)andλmax=min(d1+d2,d3+d4). Then the set of values forλisλmin≤λ≤λmax.

@&#CONCLUSIONS@&#
It is often found that parametric models used in real applications which are abstracted as geometric constraint problems fail when computing a solution instance for some parameter values. This fact naturally poses the question of how to compute ranges for parameters for which the solution instantiation succeeds.When the 2D geometric constraint problem is solved by the tree decomposition approach, the symbolic solution is a graph decomposition represented as a ternary tree where each node captures the construction of a triangle and the leaf nodes capture the set of geometric elements in the problem. Thus construction feasibility is always solved applying geometric properties of triangles.We find two different scenarios when computing the feasibility of a triangle. If the triangle is defined by three vertices (geometric elements) connected by three edges (constraints) all what we need to do is to apply the triangular inequality. If there are two or more triangles sharing an edge (co-dependencies), the feasibility range is just the intersection of the ranges computed for each of these triangles.When two vertices are connected by an already completed construction, (indirect dependencies) feasible ranges can be computed only after propagating those parameter ranges that limit the feasibility of the already completed construction. This situation entails an intensive search in the tree decomposition to identify the set of constructions actually involved.In existing approaches, parameter ranges are figured out on the fly while computing solution instances. This entails repeating searches in the tree decomposition in both when identifying dependencies for a given parameter and when computing feasibility ranges for different parameters in the problem at hand.Considering that the set of dependencies in a constraint graph is unique, the h-graph introduced in this work captures both co-dependencies and indirect dependencies. The h-graph improves the performance of computing parameter ranges in two ways. First, the h-graph is computed as a preprocess once and for all independently of the parameter the range of which must be figured out. Second, the h-graph clearly avoids the search in the tree decomposition for the existence of dependencies when actually computing ranges of parameters.In general, a tree decomposition that symbolically solves the geometric constraint problem is not the most convenient representation to be actually carried out to effectively compute solution instances. Thus usually the tree decomposition is transformed into some sort of functional program. Hence, an additional benefit we get with the h-graph derives from the fact that the h-graph defines a convenient representation for the construction to be directly executed. This plan naturally captures precedences between construction steps and fixes the order that should be applied to actually carry out the geometric construction. Moreover, computing ranges and instantiating solutions can be performed in a single step avoiding further searches in the tree decomposition.