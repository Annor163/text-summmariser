@&#MAIN-TITLE@&#
Incremental probabilistic Latent Semantic Analysis for video retrieval

@&#HIGHLIGHTS@&#
A study of the use of topic models for video retrieval is presented.A new topic model to deal with incremental retrieval scenarios is proposed.Comparison of four topic models using two different retrieval functionsThe results highlight the performance differences among the topic models.

@&#KEYPHRASES@&#
Content-based Video Retrieval,Latent topics,probabilistic Latent Semantic Analysis (pLSA),Relevance Feedback,Information retrieval,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
With the expansion of new technologies, video collections are increasingly larger and more complex, therefore one of the biggest current challenges is how to retrieve users' relevant data from this huge amount of information. The Content-based Video Retrieval (CBVR) problem is concerned about how to provide users with videos which satisfy their queries by means of video content analysis. Over the past years, CBVR has become a very important research field and several CBVR systems have been developed [1–4]. In general, a CBVR system has three main components involved in the retrieval process: (1) a query, represented by a few video examples of the semantic concept that the user is looking for; (2) a database, which is used to extract videos related to the query concept; and (3) a ranking function, which sorts the database according to the relevance to the query. These three components are usually integrated together with the user in a Relevance Feedback (RF) scheme [5] to provide the most relevant videos through several feedback iterations.One of the most used rankings in multimedia retrieval is distance-based ranking. Such ranking is performed according to the minimum distance or maximum similarity to the query in the video representation space [6,7]. However, these measures tend not to work properly when the multimedia data is rather complicated [8]. Other ranking algorithms are based on inductive learning [9,10] which typically use a bank of classifiers to represent a set of possible events to test. Nevertheless, the performance of this approach heavily depends on the training data that limits its usage in unconstrained retrieval applications. Alternative ranking methods are based on transductive ranking which use the topology of the data distribution to improve the output ranking [11,12]. The main drawback of these functions is their high computational cost because they need to carry out demanding matrix operations over the retrieval process.Several of these approaches have shown to be successful at retrieval tasks when they are used on reduced databases with a small number of concepts [13]. However, the so-called semantic gap [14] between computable low-level features and query concepts is still a challenge for large unconstrained video collections. The visual variability of unconstrained queries is so high that current approaches often do not adequately scale semantic concepts [8]. As a result, new capabilities are required in CBVR to bring the video characterization to a higher semantic level.Ranking functions work in a specific representation space where videos are encoded in feature vectors according to the information provided by a descriptor. Different types of descriptors have been developed using static information (Scale Invariant Feature Transform — SIFT [15]), spatio-temporal (Spatial Temporal Interest Points — STIP [16]) or audio (Mel Frequency Cepstral Coefficients — MFCC [17]). The standard procedure to encode all this low-level information in feature vectors is the visual Bag of Words (vBoW) [18]. The vBoW quantization starts by learning a visual vocabulary made up of the clustering of the local features. Then, each video is represented in a single histogram of visual words by accumulating the number of local features into their closest clusters. In the literature, it is quite common to see how authors refer to this quantized space as descriptor space although it is not the direct output of the descriptor functions.Some recent works have presented more advanced descriptors which are able to achieve better results for a specific sort of applications. For example, in [19] Wang and Schmid presented a video representation based on dense trajectories specially designed for action recognition which outperforms the most common motion-based descriptors. However, in unconstrained CBVR the type of concepts to deal with is so wide that simpler and non-specialized descriptors are commonly used [8].Although early research on topic models suggested that they may be used in video retrieval, it was not until recently that topic models were successfully applied to large unconstrained video collections [20]. In general, topic models provide for automatically organizing, understanding, searching and summarizing large electronic archives [21]. For many years, topic models have not been considered useful in tasks where precision is important because traditional ranking functions tend to perform worse in the latent space than in the original characterization space. The latent topic space is usually a lower dimensionality representation where concepts and classes are more diffuse and besides it allows connections among different concepts through patterns defined by topics. As a result, the most effective ranking functions in the original feature space are usually not useful in the topic space because this space has an utterly different nature.However, this fact does not mean the topics' lack of usefulness. In those applications in which the semantic gap is important, the retrieval precision in the original feature space tend to be very low and topic models can provide a competitive advantage by means of hidden patterns which may be interpreted as a higher characterization level. It is the case of unconstrained CBVR, where the difference between the low-level characterization of the videos and the query concepts that users can manage is so huge that topic models can help us to obtain a better performance in retrieval tasks.The majority of the topic methods are in the families of two reference models: probabilistic Latent Semantic Analysis (pLSA) [22] and Latent Dirichlet Allocation (LDA) [23]. These two algorithms and other topic models are typically used by retrieval systems in three steps: (1) Extract the hidden patterns (topics) that pervade the data collection; (2) annotate the documents according to these topics; (3) use these annotations to rank the documents according to users' queries. The topic extracting process has shown to be affordable when it is carried out in moderate size databases with a limited number of concepts. However, current video collections tend to be very large and besides they grow day by day with a wide range of concepts. For these incremental databases, topic extraction algorithms such as pLSA and LDA, have a computational burden too heavy to recompute topics each time the databases increase their size with new samples. In other kinds of applications, some authors [24] have shown the advantages of considering an incremental scenario to manage large video collections in an efficient way, therefore this scheme may help us to improve the topic extraction task. In this work, we are interested in exploring whether video retrieval performance is affected by the use of different topic models and how video retrieval systems based on topic models are able to efficiently manage these incremental databases.In the literature, several alternative models have been proposed in order to improve the computational efficiency of the topic extraction process. Some authors have proposed dynamic models which are able to adapt topic structure over time. One of the most representative ones is presented in [25] where Blei and Lafferty developed the Dynamic Topic Model which can capture the evolution of topics in a sequentially organized corpus of documents. Other authors have developed window-based models where the database is considered a temporal flow in which old documents are removed as new documents are introduced. For instance, Chou and Chen [26] presented a pLSA version to address the problem of on-line event detection and Wu et al. [27] developed a pLSA extension for automatic question recommendation. In general, these models follow the same idea than that of the dynamic models but allow the management of new words in documents. Dynamic models as well as window-based models use the concept incremental in the sense of changing word distribution of topics over time, that is, they maintain the number of topics fixed and adapt these topics to the new samples. However, in an incremental retrieval environment the new samples may require additional topics to capture new patterns for retrieving these new samples. This fact makes these models unsuitable for an incremental retrieval scenario and in this work we use the concept incremental in the sense of extending the number of topics by adding new patterns.Traditional topic models assume that topics have a non-zero contribution to generate documents and this leads to a dense representation with a high computational complexity. Other authors have proposed more efficient approaches which assume sparse topic proportions in documents. In [28], Khoat and Bao presented the Full Sparse Topic Model (FSTM) which is able to reduce significantly the computational burden with respect to pLSA and LDA. Although experimental results in [28] are encouraging, there are not works in the literature which have tested the performance of FSTM in a video retrieval system based on latent topics.In this scenario, the presented work has a dual target. On the one hand, we pretend to study the performance of pLSA, LDA and FSTM models for the unconstrained video retrieval problem. On the other hand, we present an extension of the pLSA model in order to enable CBVR systems based on latent topics to handle incremental collections in an effective and efficient way. Some works [29–31] have already explored topic performance but always related to text or image retrieval, in this case we would like to test if the same behavior can be observed in an unconstrained video retrieval system. In particular, we are going to use as a testing protocol two different retrieval systems based on latent topics: (1) the retrieval method proposed in [20] and (2) the cosine similarity function used in [32].The rest of the paper is organized as follows. In Section 2, a short review about topic models is provided mainly focused on pLSA and the reasons to extend this model rather than any other. Section 3 presents the Incremental probabilistic Latent Semantic Analysis (IpLSA) model which is an extension of pLSA in order to reduce computational complexity and to deal with the over-fitting problem. In Section 4, the experimental setting is described as well as the empirical results obtained by the retrieval systems [20] and [32], including a comparison among pLSA, LDA, FSTM and IpLSA in terms of video retrieval performance using the Columbia Consumer Video database [33] and the collection TRECVID 2007 [34] . Finally, Section 5 discusses the results and Section 6 draws the main conclusions arising from this work.

@&#CONCLUSIONS@&#
This paper has presented an incremental extension of the pLSA model in order to enable video retrieval systems based on latent topics to deal with incremental databases in an effective way as well as an experimental study on the performance of different topic models for the video retrieval problem.Using the video retrieval systems presented in [20] and [32], four retrieval scenarios have been simulated using two different databases and four topic extraction algorithms. From the results, we can draw three main trends in CBVR: (1) LDA is able to outperform pLSA in unambiguous and dense conditions; (2) pLSA-based models performs better in fuzzy and sparse distributions; (3) IpLSA is able to obtain good results in both cases using an incremental approach. In general, the IpLSA model has shown to be more effective in dealing with incremental databases than the rest of the tested global methods. In terms of video retrieval precision, the IpLSA model is able to outperform pLSA and LDA when these two models obtain the lowest performance. Moreover, when they achieved the highest precision, IpLSA was able to work without statistical differences. Related to the computational complexity, the results have shown that IpLSA is able to significantly reduce the time of the LDA/pLSA models and the space of the pLSA as well.Although the results are encouraging, much more progress is needed to really address the efficiency problems of the topic extraction methods for video retrieval. Thus, further work is directed to extend the work in the following directions:•Automatic strategies to choose the number of new topics at each iteration of the incremental scheme.Extension of the model to allow the use of multi-modal data from multiple channels.Reduction of the over-fitting in pLSA-based models by applying quantization techniques over the samples used to extract the topics.