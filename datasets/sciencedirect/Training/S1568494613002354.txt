@&#MAIN-TITLE@&#
Synergizing fitness learning with proximity-based food source selection in artificial bee colony algorithm for numerical optimization

@&#HIGHLIGHTS@&#
An improved variant of the ABC algorithm is presented by simulating a learning mechanism.The onlooker bees position is modified using proximity based perturbation scheme and a probabilistic weighted selection strategy.The algorithm is competitive against several state-of-the-art methods for box-constrained continuous optimization.The algorithm also shows competitive performance on a few real world optimization problems.

@&#KEYPHRASES@&#
Swarm intelligence,Artificial bee colony algorithm,Biologically-inspired optimization,Exploration,Exploitation,Fitness learning,

@&#ABSTRACT@&#
Evolutionary computation (EC) paradigm has undergone extensions in the recent years diverging from the natural process of genetic evolution to the simulation of natural life processes exhibited by the living organisms. Bee colonies exemplify a high level of intrinsic interdependence and co-ordination among its members, and algorithms inspired from the bee colonies have gained recent prominence in the field of swarm based metaheuristics. The artificial bee colony (ABC) algorithm was recently developed, by simulating the minimalistic foraging model of honeybees in search of food sources, for solving real-parameter, non-convex, and non-smooth optimization problems. The single parameter perturbation in classical ABC resulted in fairly commendable performance for simple problems without epistasis of variables (separable). However, it suffered from narrow search zone and slow convergence which eventually led to poor exploitation tendency. Even with the increase in dimensionality, a significant deterioration was observed in the ability of ABC to locate the optimum in a huge search volume. Some of the probable shortcomings in the basic ABC approach, as observed, are the single parameter perturbation instead of a multiple one, ignoring the fitness to reward ratio while selecting food sites, and most importantly the absence of environmental factors in the algorithm design. Research has shown that spatial environmental factors play a crucial role in insect locomotion and foragers seem to learn the direction to be undertaken based on the relative analysis of its proximal surroundings. Most importantly, the mapping of the forager locomotion from three dimensional search spaces to a multidimensional solution space calls forth the implementation of multiple modification schemes. Based on the fundamental observation pertaining to the dynamics of ABC, this article proposes an improved variant of ABC aimed at improving the optimizing ability of the algorithm over an extended set of problems. The hybridization of the proposed fitness learning mechanism with a weighted selection scheme and proximity based stimuli helps to achieve a fine blending of explorative and exploitative behaviour by enhancing both local and global searching ability of the algorithm. This enhances the ability of the swarm agents to detect optimal regions in the unexplored fitness basins. With respect to its immediate surroundings, a proximity based component is added to the normal positional modification of the onlookers and is enacted through an improved probability selection scheme that takes the T/E (total reward to distance) ratio metric into account. The biologically-motivated, hybridized variant of ABC achieves a statistically superior performance on majority of the tested benchmark instances, as compared to some of the most prominent state-of-the-art algorithms, as is demonstrated through a detailed experimental evaluation and verified statistically.

@&#INTRODUCTION@&#
The search for solution to difficult computational problems has prompted researchers to draw inspiration from Nature. Optimization is at the heart of many natural processes and the need was felt to devise heuristics for solving difficult optimization problems by linking biological evolution with optimization. This led to the advent of evolutionary algorithms (EAs) [1] that were devised by drawing inspiration from the dynamics of Darwinian evolution and natural genetics. The EC researchers [2,3] made use of population-based models that relied on iterative development of a population comprised of parallel search agents. It was in the sixties when branches of EC techniques began developing in the form of evolutionary programming (EP) [4], evolution strategies (ESs) [5], and later genetic algorithms (GAs) [6] and genetic programming (GP) [7]. Speaking of population-based models, insect colonies present a high level of interaction through mutual co-operation and organizational behaviour resulting in a sustained continuum of life processes necessary for survival. Computer scientists observed that modelling of algorithms based on their typical behaviour for problem solving domain can lead to the development of efficient metaheuristics that rely on co-operation, decentralization of the task force and mutual interaction as means of guidance towards the optimal sink located in the solution space. Swarm denotes an aggregation of natural creatures like fishes, birds and insects such as ants, termites, and bees exhibiting intelligent group behaviour. Members of a swarm behave without any central supervision and each of them moves under a stochastic dynamics based on the information from its neighbourhood. Swarm intelligence (SI) [8] is defined as any attempt to design algorithms or distributed problem solving devices inspired by the collective behaviour of social insect colonies and other animal societies. The intelligence of the swarm lies in the networks of interactions among the simple agents, and between agents and the environment. SI is already established as an important research area for computer scientists, engineers, economists, bioinformaticians, operational researchers, and many other disciplines. This is because the problems that the natural intelligent swarms can solve (finding food, dividing labour among nest mates, building nests, etc.) have important counterparts in several engineering areas of real world.Prominent swarm intelligent algorithms includes particle swarm optimization (PSO) [9] based on the movement of a bird flock or fish school, ant colony optimization (ACO) [10] developed by observing the ability of certain ant species to find the shortest path by exploiting communication based only on pheromones, firefly algorithm [11], inspired from the flashing mechanism in fireflies, cuckoo search [12] imitating the breeding behaviour of cuckoos, and bees algorithm (BA) [13] based on the foraging pattern of honeybees. In 2005 Karaboga [14] proposed an improved bee colony inspired algorithm in the form of ABC. The classical ABC framework synergized minimalistic foraging procedure with waggle dance mechanism and was enacted through a bee colony equally partitioned among employed and onlooker bees. Owing to its simple design and effectiveness, ABC has been considered by researches for solving continuous real-parameter optimization problems, which is our main focus.Generally optimization involves search for a vector of the formX→=x1,x2,x3,…xDTwhich contains the parameters deciding the system performance. Going by the name, each component xiof the vector is a real number for real parameter or continuous optimization. The common practice [15] is to model an objective function (also called cost function) that determines the system behaviour and based on its value, obtained iteratively, we are able to judge how far we have reached in our search for the best solution. It can be simply put that our task is to perform search in solution space in order to find a parameter vectorX→*which minimizes an objective functionf(X→)(f:℧⊆ℜD→ℜ), i.e.,f(X→*)<f(X→)∇X→∈℧, where ℧ is a non-empty set representing the search domain.ABC is a simple algorithm that proceeds sequentially through cycles. The foragers are the search agents and the algorithm proceeds through two stages – employed phase and onlooker phase. The neighbourhood search is performed through positional perturbation of the foragers in search for food sources (solution vectors) having good nectar content (fitness value) followed by the greedy selection technique so as to memorize the location of the fitter food source. The waggle dance mechanism is carried out in the onlooker phase through a fitness based source site selection followed by positional modification. Although ABC possesses efficient searching ability but there has been certain shortcoming associated with it. Zhu and Kwong [16] inferred that the classical ABC framework facilitates global exploration more in comparison to the exploitation. It is essential for an efficient black-box optimizer to properly balance these two tendencies and obtain an optimal tradeoff (T:ER & EI). Kang et al. [17] mentioned the limitations of ABC in handling functions that have a narrow curving valley, a high eccentric ellipse, or are rugged and multimodal in nature. Tsai et al. [18] pointed out that the artificial bee can only move straight to one of the nectar sources by the employed bees. This characteristic can narrow down the search zones for bees to explore. Although a good portion of research works involving ABC dealt with proposals for improving its performance; some dealing with chaotic maps for parameter adaptation [19], introduction of new parameters MR for improving convergence rate [20], utilization of best so far solution [16,21,22], hybridization with other basic algorithms [23]; however these modifications focussed on particular areas in the ABC dynamics and were able to mitigate these localized problems. By synergizing the improvements pertaining to different framework flaws can provide a way out of existing problems and harmoniously boost up the performance of the unified approach.Motivated by these findings, we propose a novel variant of ABC called Fitness learning-based ABC with proximity stimuli (FlABCps). The FlABCps has few distinguishing features which sets it apart from the classical ABC. Firstly, it recognizes the importance of spatial surrounding in locomotion of bees and combines it with associative learning. The fitness learning mechanism is enacted for mixing the components of the top q% population members unlike the approaches using the best-so-far solution. Secondly, an important observation relating to the selection of parameters for positional modification has been implemented. Unlike the modified ABC approach [20], which uses the parameter MR for deciding on the choice of perturbation, we form a set of randomly picked up objective parameters subjected to the condition that the cardinality does not exceed 1/5th of the total number of parameters. This is inspired from Rechenberg's 1/5th rule [1] which implies that the ratio of successful mutations to all mutations should be 1/5 and provides competitive results as shall be demonstrated later. This selective parameter set is used in an improved positional modification balancing attraction towards the functionally elite and the adjacent sites used in. Lastly, the selection of food sources based on the proximity stimuli in the foragers. This is implemented through a weighted probabilistic selection that differs from the classical one in inhibiting overcrowding of foragers which lead to stagnation in search moves.Organization of the rest of the paper is in order. Section 2 provides a literature review of the ABC algorithm followed by the outline of the ABC algorithm in Section 3. Section 4 presents our FlABCps algorithm by explaining the steps involved in detail. Discussion on the parametric setup, benchmark simulation, performance metrics and tabulation of results is done in Section 4. The study of the proposed approach is covered in Section 5 with special focus on comparative analysis, run-time complexity and the effect of algorithmic components. Section 6 concludes the paper and provides an insight into scope for future work and changes that may be undertaken.

@&#CONCLUSIONS@&#
