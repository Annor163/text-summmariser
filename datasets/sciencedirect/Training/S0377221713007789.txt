@&#MAIN-TITLE@&#
Optimal strategies for selecting project portfolios using uncertain value estimates

@&#HIGHLIGHTS@&#
We use Bayesian methods to model uncertainties in project portfolio selection.The proposed methods serve to increase the expected value of the selected portfolio.Bayesian uncertainty modeling helps to eliminate post-decision disappointment.The methods support the optimal targeting of additional project evaluations.We propose a project performance measure that accounts for portfolio constraints.

@&#KEYPHRASES@&#
Decision analysis,Portfolio selection,Bayesian methods,Value of information,

@&#ABSTRACT@&#
Practically all organizations seek to create value by selecting and executing portfolios of actions that consume resources. Typically, the resulting value is uncertain, and thus organizations must take decisions based on ex ante estimates about what this future value will be. In this paper, we show that the Bayesian modeling of uncertainties in this selection problem serves to (i) increase the expected future value of the selected portfolio, (ii) raise the expected number of selected actions that belong to the optimal portfolio ex post, and (iii) eliminate the expected gap between the realized ex post portfolio value and the estimated ex ante portfolio value. We also propose a new project performance measure, defined as the probability that a given action belongs to the optimal portfolio. Finally, we provide analytic results to determine which actions should be re-evaluated to obtain more accurate value estimates before portfolio selection. In particular, we show that the optimal targeting of such re-evaluations can yield a much higher portfolio value in return for the total resources that are spent on the execution of actions and the acquisition of value estimates.

@&#INTRODUCTION@&#
Making choices among alternative courses of action is a recurring activity in most organizations (Salo, Keisler, & Morton, 2011). Industrial firms, for instance, launch research and development projects with the aim of laying the foundation for businesses that generate future revenues. Municipalities take decisions about which facilities will be built in order to deliver social and educational services to their citizens. Even if these problems are seemingly different, they resemble each other in that the decision maker (DM) selects a portfolio of actions (referred to as projects in what follows), subject to the availability of scarce resources and other relevant constraints.Typically, projects are selected based on ex ante estimates about how much value they will offer ex post. Depending on the context, estimates about this future value can be generated through approaches such as net present value calculations, benefit-to-cost studies, or multi-attribute decision analysis. Because these estimates are usually uncertain, it is difficult to select the optimal portfolio which consists of projects that have the highest sum of ex post values and satisfy relevant budget and other constraints as well. In particular, even if the ex ante value estimates are unbiased, those projects whose value has been overestimated most are more likely to be selected. It therefore follows that the realized ex post value of the selected portfolio often falls short of what is suggested by the ex ante estimates of the projects that it contains. In other words, the DM is likely to experience post-decision disappointment (Brown, 1974; Harrison & March, 1984; Smith & Winkler, 2006; Begg & Bratvold, 2008).In this paper, we show that, in comparison with the straightforward portfolio selection based on ex ante value estimates, the explicit Bayesian modeling of estimation uncertainties and the use of resulting revised estimates in portfolio selection (i) helps select a portfolio which can be expected to offer more value ex post, (ii) serves to increase the number of projects which belong to the optimal portfolio, and (iii) reduces the amount of disappointment that the DM can expect to experience. Moreover, Bayesian modeling allows us to study how resources should be spent in order to derive more accurate value estimates, for instance by acquiring additional independent evaluations about some selected projects. Specifically, we show that such additional evaluations should be acquired about projects (i) whose ex ante value estimates have a probability distribution with a comparatively large variance and a mean near the selection threshold, and (ii) which can be re-evaluated relatively accurately with a reasonable cost. Our computational experiments suggest that by following these guidelines, the expected portfolio value can be increased significantly by re-evaluating only a small fraction of projects (rather than spending resources on the re-evaluation of all projects, which can be very costly). This important result helps improve the cost-efficiency of project portfolio selection processes.The rest of the paper is structured as follows. In Section 2, we discuss earlier approaches to the modeling of uncertainties in project portfolio selection. Section 3 develops our framework for treating estimation uncertainties. Comparative results on Bayesian revisions and guidelines for acquiring additional evaluations are presented in Section 4. Section 5 discusses the managerial implications of our results, and Section 6 concludes.Methods of portfolio decision analysis are widely employed to support project selection both in public administration (e.g. Golabi, Kirkwood, & Sicherman, 1981; Kleinmuntz & Kleinmuntz, 1999) and industrial firms (e.g. Stummer & Heidenberger, 2003; Liesiö, Mild, & Salo, 2008). Many of these methods capture uncertainties about how much value the projects will offer to the organization. For example, methods that use set inclusion to characterize projects’ values through lower and upper bounds have been used in the selection of road pavement projects (Liesiö, Mild, & Salo, 2007), the development of strategic plans for air traffic management (Grushka-Cockayne, De Reyck, & Degraeve, 2008), the selection of a strategic product portfolio in a telecommunications company (Lindstedt, Liesiö, & Salo, 2008), and the formation of scenario-based strategies in the shaping of industrial policies (Liesiö & Salo, 2012).Bayesian modeling of uncertainties has a long tradition in financial portfolio optimization. Specifically, Bayesian analyses have been proposed for revising model parameters in response to the most recent market information, in order to predict security prices better and, by doing so, to support the determination of optimal investments into securities (Winkler & Barry, 1975; Barry & Winkler, 1976; Aguilar & West, 2000; Polson & Tew, 2000; Brandt, Goyal, Santa-Clara, & Stroud, 2005; Soyer & Tanyeri, 2006). Yet financial portfolio optimization differs from project portfolio selection in many respects. First, projects do not have market prices that one could observe in the markets. Rather, project values are typically estimated by eliciting expert evaluations which may reflect intangible considerations such as societal impacts. Second, projects are ‘lumpy’ investments which are either selected or rejected, and thus the decision variables are binary. This differs from financial portfolio optimization where essentially any fractional amount of resources can be invested into any security. Third, although security prices may be correlated, most investments into securities are not logically dependent on each other. But in project portfolio selection, there can be many forms of interdependencies due to logical relationships. For example, projects can be mutually exclusive (e.g., only one of projects A and B can be selected) or otherwise interdependent (e.g., if B is a sequel project to A, it can be selected only if A is also selected). Owing to differences such as these, the analysis of estimation uncertainties in project portfolio selection merits detailed attention.Behavioral studies indicate that when people are faced with prediction tasks, they tend to underestimate prior information about the ‘base rate’ of the event which is being predicted. Instead, they tend to take decisions based on most recent evidence, which can lead to errors in predicting rare events and extreme realizations (Kahneman & Tversky, 1973, 1979). Specifically, when the DM seeks to maximize value by choosing one out of many alternatives based on ex ante value estimates that reflect recent evidence, she will choose the alternative with the highest estimate. But this estimate is very likely to be higher than what the real value of the alternative is, and consequently the DM will be disappointed when this alternative’s value is realized. In these kinds of choose-one-out-of-many problems, the Bayesian revision of value estimates has been shown to eliminate this post-decision disappointment phenomenon, defined formally as the expected negative gap between the realized value of the selected alternative, on one hand, and its estimated value, on the other hand (Brown, 1974; Harrison & March, 1984; Smith & Winkler, 2006).Harrison and March (1984) recognize the practical difficulties of estimating the parameters needed for Bayesian modeling in a general decision context. As a more viable approach, they suggest that it often pays off to obtain more accurate value estimates, because doing so helps choose an alternative which has a higher expected value, thus mitigating post-decision disappointment. This realization has spurred research on how the value of information depends on the characteristics of the decision problem. There are many studies which conclude that the value of information varies in unexpected, ambiguous and sometimes counterintuitive ways (Gould, 1974; Laffont, 1976; Hilton, 1981; Eeckhoudt & Godfroid, 2000), but Delquié (2008) shows conclusively that, under quite general assumptions, the value of information in making choices between two alternatives is highest when the DM is initially indifferent between the two, and that this value is lower when there is strong initial preference for choosing one of the alternatives over another. Bickel (2008) obtains an analogous result for the value of imperfect information in selection problem with normal priors and exponential utility.Frazier and Powell (2010) study the optimal acquisition of information when choosing one of many alternatives subject to the assumption that the prior value distribution and the sampling distribution for inferring value estimates are both normal. They conclude that when the alternatives are identical a priori, it pays off to obtain additional evaluations about a subset of alternatives only, and that this subset is smaller when the estimation accuracy is better. In portfolio decision analysis, the value of information has been studied to-date primarily through simulation studies. Keisler (2004), for instance, simulates different portfolio selection strategies and shows that the systematic prioritization of project proposals based on value estimates (as opposed to the random selection of projects) tends to contribute more value than the efforts to acquire more accurate estimates about the projects’ values. In Keisler (2009), he studies the value of assessing weights in multicriteria portfolio decision analysis using a similar approach.Consider a set of project proposals i=1,…,m which, if funded, will yield values v=[v1,…,vm]′ to the DM. These values capture the benefits resulting from the projects, and they will be realized and observed only after the projects have been executed; see e.g. Arnott, Li, and Sherrerd (2009). In what follows, these values are modeled as realizations of random variables V=[V1,…,Vm]′∼f(v) whose joint distribution function f(v) is assumed to be known.1Throughout this paper, random variables are denoted by capital letters and their realizations by lower-case counterparts, respectively.1The DM seeks to select a portfolio consisting of a subset of proposed projects such that the sum of the selected projects’ values will be maximized, subject to the requirement that the portfolio fulfils relevant resource and other constraints. This selection decision is denoted by the decision variable z=[z1,…zm] with binary elements such that zi=1 if and only if project i is selected. The set of portfolios which satisfy the relevant constraints is denoted by Z. If the values v were known to the DM, she would determine the optimal portfolio z(v) by solving the optimization problem2If there are multiple solutions to the maximization problem, z(·) is selected at random among these solutions.2(1)z(v)=argmaxz∈Zzv.Yet, the DM does not know the values v=[v1,…,vm]′ but, rather, value estimatesvE=v1E,…,vmE′of v. These estimates are assumed to be a realization of a random variable (VE∣V)∼f(vE∣v) with a known distribution function f(vE∣v). We assume that the estimates are conditionally unbiased so thatEViE|V=v=∫-∞∞viEfviE|vdviE=vi. Now, if the DM were to choose projects based on these value estimates vE, she would choose portfolio z(vE) which solves the optimization problem(2)z(vE)=argmaxz∈ZzvE.Making the selection decision based on estimates vEwithout accounting for the uncertainties that are embodied in the distributions f(v) and f(vE∣v) typically leads to a non-optimal portfolio. For example, assume there are ten project proposals A,…,J which cost between 1 to 12M€, and that the budget is 25M€. The values of these projects are realizations of independent and identically distributed random variables Vi=μi+Eisuch that μi=10 and Ei∼N (0,32), i=A,…,J. Projects A through D are conventional projects whose future performance can be estimated relatively accurately. This is modeled so that the value estimates areViE|Vi=vi=vi+Δiwith Δi∼N (0,12) for i=A,…,D. Projects E through J, on the other hand, are novel, radical projects whose values are more difficult to estimate reliably: this is modeled asViE|Vi=vi=vi+Δiwith Δi∼N (0,2.82) for i=E,…,J. Moreover, project B is a follow-up project of A. Thus, it can be selected only if A is selected.Fig. 1illustrates one realization of this portfolio selection problem. The size of the markers is proportional to project costs. If the DM knew the projects’ values in advance, she would select projects {C,D,G,I,J}. However, if she takes the value estimates as a basis for decision, she will choose projects {C,D,E,H,J} which are marked using black circles.This simple example illustrates three phenomena that tend to occur when selecting projects based on uncertain value estimates:(i)The realized portfolio value is less than the optimum: In Fig. 1, the value of the selected portfolio (51.6M€) is 7% lower than that of the optimal portfolio (55.3M€).The selected portfolio contains non-optimal projects: The selected portfolio contains the ‘radical’ projects E and H which have been selected due to their high value estimates, but which are not in the optimal portfolio.The DM experiences post-decision disappointment: The ex ante value estimate for the selected portfolio (62.1M€) is 21% higher than what is actually realized ex post (51.6M€).Although Fig. 1 is but a single realization of a portfolio selection problem, these phenomena occur when averaged over many selection processes, too. Thus, if the DM chooses portfolios based on uncertain value estimates only, she does not maximize the expected portfolio value or the expected number of projects that belong to the optimal portfolio. Furthermore, the value of the selected portfolio will, on average, be lower than the sum of the value estimates for the projects in this portfolio. This is caused by the fact that the more the value of a project has been overestimated, the more likely it is to have been selected. Thus, even if the value estimates are unbiased a priori, the optimization-based selection process implies that the estimates for the recommended projects in (2) have an upward bias. This phenomenon is formalized in Proposition 1 which makes no specific assumptions about the prior and conditional distributions f(v) and f(vE∣v) or about the feasibility constraints. All proofs are in Appendix A.Proposition 1Let VEbe a conditionally unbiased estimator of V. Then,E[z(VE)V-z(VE)VE]⩽0,where z(VE) fulfils(2). Moreover, ifP(z(V)≠z(VE))>0, where z(V) fulfils(1), thenE[z(VE)V-z(VE)VE]<0.Proposition 1 states that, on average, the value of the selected portfolio z(vE) will not be more than its estimated value. Furthermore, if there is a non-zero probability of selecting ‘wrong’ projects (as there always is, unless the estimates are fully accurate) the expected gap between the realized and estimated portfolio value is strictly negative. In particular, even if the value estimates are unbiased, the portfolio value will be systematically overestimated so that the DM will experience post-decision disappointment.The more uncertain the value estimates, the larger the expected disappointment. That is, very uncertain value estimates not only make it more difficult to identify the projects with highest values, but they also make it more likely that the values of the selected projects will have been systematically overestimated. This is illustrated in Fig. 2which shows how the magnitude of post-decision disappointment (PDD) depends on the impacts of estimation uncertainties. Here, portfolios of 10 projects have been selected out of 100 project proposals whose values vihave been drawn from the standard normal distribution N (0,1), and whose value estimatesviEhave been generated using an additive zero-mean estimation error modelviE=vi+δiwhere δi∼N (0,τ2). For instance, when τ=0.8, the average estimated value of the selected portfolio is 22.16, which is 65% higher than the expected portfolio value 13.45.In project portfolio selection, just as in problems in which only one of many alternatives is chosen, post-decision disappointment can be mitigated by revising value estimates with Bayesian methods (for an overview, see e.g. Gelman, Carlin, Stern, & Rubin, 2004). That is, the posterior distribution f(v∣vE) for project values, given the estimates, can be obtained from the prior distribution f(v) and the likelihood distribution f(vE∣v) by using the Bayes’ rule f(v∣vE)∝f(v)f(vE∣v). The posterior distribution can then be used to determine the expected valueE[Vi|VE=vE]for project i, given the value estimates, or the probabilityP(zi(V)=1|VE=vE)with which project i belongs to the optimal portfolio.The posterior distribution can be used to formulate optimization problems for project portfolio selection with the aim of (i) maximizing the expected portfolio value or (ii) maximizing the expected number of optimal selections. Furthermore, the posterior distribution allows us to study the value of information in portfolio selection and to develop guidelines for cost-efficient project re-evaluation strategies.The objective function for maximizing the expected portfolio value iszE[V|VE=vE]. Thus, project selection is based on the Bayes estimatesvB=v1B,…,vmB′, which can be computed from the observed estimates vEthrough(3)viB=E[Vi|VE=vE]=∫-∞∞vif(vi|vE)dvi.The Bayes estimate for project i is thus the mean of the posterior distribution f(vi∣vE). The portfolio that maximizes the expected value is now determined by(4)z(vB)=argmaxz∈ZzE[V|VE=vE]=argmaxz∈ZzvB.To study the average performance of selection rule (4), we define the Bayes estimatorVB=V1B,…,VmB′(a random variable), which is obtained from (3) by replacing the observed estimates vEwith the random variable VE:(5)ViB=E[Vi|VE]=∫-∞∞vif(vi|VE)dvi.Under very general assumptions, selecting the portfolio based on these Bayes estimates will yield at least as much value as the portfolio which maximizes the sum of value estimates vE.Proposition 2Let VE, V, and z(VE) be as inProposition 1. Then,E[z(VE)V-z(VB)V]⩽0,where VBis given by(5)and z(VB) satisfies(4). Moreover, if there is a possibility that z(vE)≠z(vB), thenE[z(vE)V-z(vB)V]<0and thusE[z(VE)V-z(VB)V]<0.This is an intuitive result because by (4), z(vB) maximizes the expected portfolio value. Nevertheless, if there is a possibility that the use of Bayes estimates leads to the selection of a different portfolio than the use of value estimates vE, the expected value of the portfolio based on Bayes estimates is strictly better.A closed form expression for the Bayes estimate can be provided if the distributions of project values and value estimates are conjugate distributions. For example, assume that project values and value estimates follow the self-conjugate normal distribution so that for each project iValues:Vi=μi+Ei,Ei∼N(0,σi2),Estimates:ViE|Vi=vi=vi+Δi,Δi∼N(0,τi2).Then, the Bayes estimate in (3) becomes(6)viB=αiviE+(1-αi)μi,whereαi=1+τi2σi2-1.For the normal distribution, the Bayes estimate is thus a weighted average of the prior mean and the observed estimate. The weighting is determined by the variance ratioτi2/σi2. If the estimation error varianceτi2is large compared to the prior varianceσi2, the weight αiof the estimateviEis small, and more emphasis is given to the prior expectation μi. On the other hand, if the estimation error varianceτi2is small compared to the prior varianceσi2, then αiis closer to one, reflecting the fact that the estimateviEoffers relatively reliable information about how much value will be realized.If the values and estimation errors are normally distributed, the Bayes estimates shift expectations from the initial estimates towards prior value information f(v) and, more specifically, towards the prior mean μi. These estimates therefore tend to yield more conservative (i.e., less overestimated) information about the value of the selected portfolio. It turns out, that without specific assumptions about the distributions f(v) and f(vE∣v) or about the problem constraints, these Bayes estimates eliminate the expected gap between the realized and estimated value of the selected portfolio.Proposition 3Let V, VE, VB, and z(·) be as inProposition 2. ThenE[z(vB)V-z(vB)vB|VE=vE]=0for all vE, and henceE[z(VB)V-z(VB)VB]=0.Proposition 3 states that, for the selected portfolio, the expected difference between the realized ex post value and the value indicated by the Bayes estimates is zero. Even in individual cases, the Bayes estimates tend to alleviate post-decision disappointment, because extreme Bayes estimatesviBare less probable than extreme estimatesviE. Fig. 3illustrates the Bayesian adjustment of uncertain value estimates using the same data as in Fig. 1. Based on the Bayes estimates in Fig. 3b, portfolio {A,B,C,D,I,J} is selected.Compared to the estimates in Fig. 3a, the Bayes estimates in Fig. 3b are nearer the common prior mean 10, especially for projects E through J which have a high estimation error variance. For instance, the Bayes estimate of project H with initial estimatevHE=16.56isvHB=1+2.8232-1·16.56+1-1+2.8232-1·10=13.96.Due to the Bayesian adjustment of value estimates, the degree of overestimation of project H and underestimation of project I is much lower. If the portfolio is selected based on the initial estimates vE, its estimated value of will be 21% higher than what the portfolio actually offers. In contrast, when the selection is made by maximizing the sum of Bayes estimates vB, the estimated value of the resulting portfolio z(vB) will be only 7% higher than what this portfolio delivers. Moreover, the value of the portfolio is only 1% lower than optimal.The Bayesian approach makes it possible to analyze how many of the selected projects can be expected to belong to the optimal portfolio. For example, when appointing public officials, the appointing body has an interest in avoiding procedural complaints, because it can be costly and time-consuming to deal with such complaints. Maximizing the number of optimal selections would reflect this objective.The portfolio that maximizes the expected number of optimal selections can be determined from the optimization problem(7)zOS(vE)=argmaxz∈ZE[z(V)z′|VE=vE],where the optimal portfolio z(V) is obtained from (1). Proposition 4 below states that the objective function in (7) is the sum of probabilities with which the projects are included in the optimal portfolio. In what follows, these probabilities will be referred to as Pi-measures.Proposition 4Eq.(7)can be written aszOS(vE)=argmaxz∈Z∑i=1mPizi,wherePi=P(zi(V)=1|VE=vE)is the probability that project i belongs to the optimal portfolio.Table 1shows the Pi-measures using the same data as in Figs. 1 and 3. The boldface numbers in each column of Table 1 indicate which projects are selected. Here z(vB)=zOS(vE). In general, however, the Bayes estimates and the Pi-measures do not lead to the same portfolio. In fact, the expected value of portfolio zOS(vE) may in some cases be far from optimal, and in this sense, the available resources may not be efficiently utilized.For example, assume that there are five projects A,…,E such that projects A and B consume one resource unit and projects C, D, E four resource units each. The budget is five resource units. The Bayesian estimated benefit-to-cost ratio (BCR; value divided by cost) is the same for each project. Moreover, the prior distribution of the BCR and the conditional distribution of the estimated BCR are the same for all projects. All optimal portfolios which maximize the expected portfolio value thus contain one project from set {A,B} and one from set {C,D,E}, and there are six such portfolios which are optimal with equal probability. Hence, we have PA=PB=1/2 and PC=PD=PE=1/3. If the expected number of optimal selections is maximized, projects A and B are selected, which would yield 60% lower expected portfolio value and leave three resource units unused.This caveat notwithstanding, Pi-measures can be helpful in the analysis of individual projects even if the primary objective is to maximize the expected portfolio value. This is because Piis a project performance measure which reflects not only what the project’s value and cost are, but also how the project contributes to the entire portfolio. That is, apart from reflecting the reliability of the estimation information, Piaccounts for factors such as the project’s cost relative to the budget and interdependencies with other projects.Using the example of Table 1, Fig. 4illustrates the Bayes estimatesviB, standard deviations of these estimates ρi, and project costs. Projects D and H have the same benefit-to-cast ratio, 1.75. The fact that H would consume one third of the budget by itself, thus constraining possibilities for including other, even more profitable projects, is reflected in the fact that it has a lower Pi-measure (i.e., PD=0.7, PH=0.3). Furthermore, when examined independently, project A is inferior to project H, because A offers less value and is more expensive. But it is a necessary precondition for selecting the inexpensive project B which has a high benefit-to-cost ratio (3.13). Thus, A has a higher Pi-measure (PA=0.56) than H (PH=0.3). In this way, Pi-measures offer a more meaningful approach to project prioritization than conventional comparisons based on benefit-to-cost ratios which do not account for project interactions.Uncertainties about the future value of projects can be reduced by obtaining additional ex ante project evaluations. But because such evaluations can be expensive and time-consuming to acquire, the DM should re-evaluate only those projects for which this additional information can be expected to help select a portfolio which offers so much more value that the resulting value increase offsets the costs of re-evaluation. Here, in keeping with the standard convention, we model value of information as the increase in the expected value that can be achieved by acting optimally in keeping with this information (La Valle, 1968; Marschak & Radner, 1972; Gould, 1974; Laffont, 1980; Delquié, 2008).Definition 1The expected value of information VEisEVI[VE]=E[maxz∈ZzE[V|VE]]-maxz∈ZzE[V].This definition can be applied when one or more project evaluation rounds have been completed and the DM seeks to know if additional evaluations can be expected to lead to a better decision than what is suggested by the earlier rounds (i.e., the current portfolio). In what follows,E[V]denotes the vector of expected project values resulting from all the earlier evaluations. Prior to observing vE, the additional information is a random variable VE, and thus the expected project values that have been revised based on this additional information are represented by the random variableE[V|VE]. Additional evaluations can be elicited for one project at a time or, alternatively, in a batch mode for several projects at a time.In its general form, the evaluation of EVI is a stochastic optimization problem with binary decision variables. This problem can be solved, for instance, through simulation by sampling values of vE, by using the posterior distribution to obtainE[V|VE=vE], and by solving the optimization problemmaxz∈ZzE[V|VE=vE]in each simulation round. Fig. 5shows the EVI for the data in Fig. 4 in a situation where an additional evaluation is acquired only for a single project at a time.A comparison of Fig. 5 and Fig. 4 shows that the EVI is low for projects C and J whose Pi-measures are close to 1, and also for project G whose Pi-measure is close to 0. This makes sense: if a project is optimal/non-optimal with a high probability, additional information is of little use. Re-evaluating project E with the highest benefit-to-cost ratio among the currently rejected projects increases the expected portfolio value by about 214k€, because it is likely that the additional estimate will introduce E into the portfolio which is optimal for the revised estimates. The interdependent projects A and B in the currently optimal portfolio also have a high EVI, because A is expensive and has the lowest current estimate among the selected projects. Based on the additional estimates, it may be that either A, B or both of them are not valuable enough to be retained, in which case almost half the budget is released for possibly more profitable projects.To derive analytic results on EVI, we consider the case in whichViEis independent of Vjfor all j≠i, there is a single feasibility constraint on the number of projects in the portfolio, and one additional evaluation is acquired for project i only. If project i is not included in the currently optimal portfolio, this optimal portfolio changes only if the evaluationviEis high enough so thatEVi|ViE=viEexceeds the lowest expected project value in the current portfolio (denoted by x+). In this case the expected value of the portfolio grows byEVi|ViE=viE-x+. On the other hand, if project i is included in the current portfolio, then the portfolio value changes byEVi|ViE=viE-E[Vi]unlessviEis low enough so thatEVi|ViE=viEbecomes smaller than the greatest expected value among those projects that are not included in the portfolio (denoted by x−). In this case, the value of the optimal portfolio changes byx--EVi|ViE=viE. Prior to observingviE, the EVI is computed by taking expectations over randomViE.Proposition 5LetZ={z∈{0,1}m|∑izi=b},b∈{1,…,m-1}, and letViE,Vjbe independent for all i≠j andz∗∈argmax{zE[V]|z∈Z}. The expected value of an additional evaluationViEof project i isEVIViE=Emax0,EVi|ViE-x+,ifzi∗=0Emax0,x--EVi|ViE,ifzi∗=1,wherex+=minjE[Vj]|zj∗=1andx-=maxjE[Vj]|zj∗=0.By the law of total expectation, the expected value of the Bayes estimate after the additional evaluation equals the current expected project valueEEVi|ViE=E[Vi]. Thus, the value of acquiring an additional estimateViEdepends on the tails of the distribution ofEVi|ViE. If project i is not included in the current portfolio, a fat tail above the threshold value x+ means that the additional evaluation has more value, because there is a higher probability that it pushes the project with the lowest expected value x+ out of the current portfolio, resulting in a higher portfolio value. Similarly, the fatter the tail below x− for a project in the current portfolio, the higher the value of an additional evaluation.Unless ViandViE|Vihave conjugate distributions, there is usually no closed-form expression forEVi|ViEand its distribution. However, conjugate relationships have been established for many distributions used in the modeling of prior and estimated value information (Fink, 2012). The self-conjugate normal distribution, for instance, provides a base case for modeling the randomness of many types of real-world phenomena. The normal distribution also has the maximum entropy among all real-valued distributions with a known mean μ and standard deviation σ. This means that minimal prior structure needs to be specified beyond these two parameters (Park & Bera, 2009). Moreover, by the Bayesian central limit theorem, the posterior distribution approaches normal distribution under very general conditions as the sample-size grows. Thus, the analysis of the normally distributed case provides insights into the process of reducing uncertainties even if the underlying distributions are not normal.Proposition 6Let the assumptions ofProposition 5hold. Assume that based on current information,Vi∼Nμi,σi2andViE=Vi+Δi, whereΔi∼N0,τi2. ThenEVi|ViE∼Nμi,ρi2, whereρi2=σi4/σi2+τi2, and the expected value of an additional evaluation of project i is(8)EVIViE=h(x+-μi,ρi),ifzi∗=0h(μi-x-,ρi),ifzi∗=1,whereh:R+2→R+such that h(d,0)=0 and h(d,ρ)=ρφ(−d/ρ)−dΦ(−d/ρ), if ρ>0. Furthermore, h is increasing in ρ, decreasing in d andh(0,ρ)=ρ/2π. Here φ and Φ denote the probability density function of the standard normal distribution and its cumulative distribution function, respectively.By Proposition 6, the expected value of additional information can be maximized by targeting the evaluations on projects (i) whose expected value is closest to the threshold x∗ (either x∗=x− or x∗=x+ depending on whether the project is included in the current portfolio or not) and (ii) that have the highest posterior varianceρi2=σi4/σi2+τi2. On the one hand, if two projects have equally uncertain current expected values that are equally far from the threshold before the additional evaluation (σi=σjand ∣μi−x∗∣=∣μj−x∗∣), it would be optimal to re-evaluate the project about which more accurate information can be acquired (i.e., τ2 is smaller). On the other hand, if two projects are equally close to their respective thresholds and can be evaluated with equal accuracy, then the one whose current expected value is more uncertain (i.e., greater σ2) should be re-evaluated. Finally, if the posterior variances are equalρi2=ρj2, then it pays off to re-evaluate the project whose expected value is closest to the threshold.The above results are intuitively reasonable. First, if the current expectation is close to the threshold, it is more likely that an additional estimate will ‘tip the scales’ in one way or another. Second, the larger the varianceσi2of the current estimate, the more probable it is that the new estimate will be sufficiently different from the current one to cause a change in the recommended portfolio. Finally, the smaller the estimation error varianceτi2, the greater the impact of an additional evaluation in (6). Conversely, if the additional estimate is very uncertain, it is less likely that the optimal portfolios suggested by the current and new estimates will differ.Fig. 6illustrates how these results can be used to guide the acquisition of additional evaluations. This Figure shows an example of selecting the 20 best projects out of 100, when the projects’ values are realizations of independent normally distributed random variables with a common prior mean 3. The project population consists of two types (50 projects each) such that, in comparative terms, projects of type 1 exhibit more variability in values and are easier to evaluate than project of type 2: this is reflected by the numerical parameters σi=2 and τi=1 for type 1 and σi=1 and τi=2 for type 2. Fig. 6 shows one possible realization of this decision setting and, more specifically, the contours of h as a function of the distances of the projects’ current expected values to the thresholds x− and x+ (bottom horizontal axes) and the standard deviation ρiof the posterior expected valueEVi|ViE(vertical axes).On the right-hand side of Fig. 6, we have projects that are included in the current portfolio. The corresponding threshold x+=4.14 is the minimum expected value of these projects. Similarly, x−=4.03 is the maximum expected value of the projects that do not belong to the currently optimal portfolio (left-hand-side chart). Now, assume that there are resources available for re-evaluating 30 projects. Following a ‘short list’ approach, the additional evaluations would be obtained for the 30 projects that have the highest current expected value, marked with black circles. The 30 projects with the highest EVI, however, lie within the dashed ellipse, reaching maximal values at the threshold and decreasing as the distance from the threshold increases. This example illustrates how projects with a better evaluation accuracy (and hence greater ρ) have a higher EVI than projects which are equally close to the threshold but which cannot be evaluated with equal accuracy. In fact, not a single type 2 project with higher evaluation uncertainties is included among the 30 projects that have the highest EVI.Propositions 5 and 6 suggest an evaluation scheme in which the EVIs are computed for all projects and, if there is at least one project whose EVI exceeds the cost of obtaining one additional evaluation, the project with the maximal EVI is selected for re-evaluation. This process can be repeated several times.However, because evaluation takes time, it may be necessary to submit simultaneously many or even all projects for re-evaluation. For instance, one approach would be to choose k⩽n projects for re-evaluation based on some selection criterion. Then, the DM could choose the optimal portfolio based on estimates revised according to the additional information or, alternatively, organize another re-evaluation round using a subset of similar or different size.Fig. 7compares the performance of such ‘batch mode’ approaches to other re-evaluation strategies for different numbers of evaluation rounds using the value and estimation error distributions in Fig. 6. For purposes of illustration, the cost of acquiring a single project evaluation is set at 0.01 or 0.03. This represents 1% or 3% of the cost of each project which is set at 1.00. This corresponds to 0.33% or 1% of the average project value μ=3.Importantly, the targeting of additional evaluations based on the projects’ EVIs appears to outperform all other strategies, including the often applied ‘short list’ approach (where k projects with the highest expected values are re-evaluated), and the baseline strategy where additional evaluations are obtained for randomly selected k projects. Also, the benefits of acquiring better information through a complete re-evaluation of all projects can be offset by the evaluation costs. For example, if the cost of each evaluation is 0.03, then the net value, defined as the portfolio value minus total evaluation costs, will decrease if all projects are re-evaluated. As a strategy, the complete re-evaluation is outperformed even by re-evaluating 30 randomly selected projects in each round.The shares of optimal selections corresponding to all four evaluation strategies are shown in Fig. 8. Here, the evaluation costs are not explicitly accounted for; consequently, the strategy of complete re-evaluation yields the highest share of optimal selections for any number of evaluation rounds, but appears to perform only slightly better than the much less expensive strategy of re-evaluating 30 projects with the highest EVI in each round.Clearly, there is a high number of variations in how many evaluation rounds can be organized and how many evaluations are obtained in each. Assuming that the same number of evaluations is acquired in each round, the optimal number of rounds and evaluations can be determined from the optimization problem(9)maxk,e[E[maxz∈ZzE[V|VE(k,e)]]-(n+k(e-1))ce],where n is the number of project proposals, e is the number of evaluation rounds (with e=1 referring to the initial round of evaluating all projects) and ceis the cost of evaluating one project. Here, VE(k,e) denotes the random variable which represents the value estimates based on the initial evaluations for all projects as well as the additional evaluations obtained in rounds 2,…,e for projects with the k highest EVIs in these rounds.This optimization problem can be solved by simulating values of the objective function (9) for different combinations (k,e). Based on the data in Figs. 6 and 7, Table 2shows that the optimal batch size and the number of evaluation rounds depend significantly on the evaluation costs. For instance, when the cost of evaluating a project is 0.05, only one additional round focused on 17 projects should be organized. The total evaluation cost is 5.85, resulting from the evaluation of 100 projects initially (100×0.05=5.00) and the additional round in which 17 projects are subjected to re-evaluation (1×17×0.05=0.85). Table 2 also confirms the intuition that the more costly it is to evaluate projects, the fewer evaluations should be obtained. More generally, it suggest that it is important to optimize not only the selection of projects but also how the evaluation process is organized and how much resources are given to this process.Here, our framework helps decide how much resources should be reserved to project evaluation as a share of the total budget comprising the costs of funding projects and evaluating them. For example, Fig. 9shows the optimal division of resources between project funding and project evaluation for the data in Table 2. Because 20 projects are selected regardless of the evaluation costs, the absolute amount of resources spent on project funding is the same (20 units) regardless of the cost of a single evaluation ce. However, because more resources need to be spent on evaluating projects when the evaluation costs are higher, the total budget reserved for project evaluation should be increased accordingly, leaving relatively less resources to for project funding.In developing the above results, we have assumed that the distributions of project values f(v) (prior) and value estimates f(vE∣v) (likelihood) are known. Because project portfolio selection is a recurring activity in many organizations, there may exist historical data about the projects’ values and value estimates which allows these distributions to be estimated (Jose, 2010). But if the projects represent entirely new activities, such historical data may not exist or it can be irrelevant, wherefore other estimation methods are needed.To characterize a normal prior, the DM can be asked to specify the prior mean μiand varianceσi2. If the DM has information about the location and scale of the value of project i, it is possible to match these with μiandσi2. As a rule of thumb, most of the probability mass (99.9%) lies in the interval I=[μi±3σi]. If the DM can specify plausible upper and lower bounds for vi, the prior mean μiand varianceσi2can be determined so that these bounds correspond to the endpoints of interval I (Bolstad, 2007).In some settings, the prior distribution f(v) is not normal. For instance, the project values may be asymmetrically distributed with a large part of the probability mass concentrated on smaller values. One possible prior in such cases is the triangular distribution, which is defined by lower and upper bounds for possible values of viand which has a peak at the most likely value (the mode).The DM can also be asked to assess the percentiles of the project values vifor each i; i.e., the values below which a certain percentage (e.g., 10%, 20%,…,90%) of observed viare assumed to fall. The resulting step functions can be transformed into continuous distribution functions by using kernel smoothing methods (e.g. Hastie, Tibshirani, & Friedman, 2009). If the DM does not have any prior information about the projects, it is possible to use an uninformative prior (e.g. Price & Manson, 2002), in which case the posterior distribution will be based on evaluation information only.If the estimation errors are additive, project-specific, and normally distributed with a zero mean, the specification of the likelihood corresponds to assessing the estimation error varianceτi2for i=1,…,m. To assessτi2, the DM can be asked to specify a range within which she would expect to see, say, 80% of the estimates given the value of the project. Then,τi2could be determined to correspond to this range.Alternatively, if the project is evaluated by multiple experts, the variance across the experts’ assessments could be interpreted asτi2. Such an approach has been advocated by some researchers (e.g. Gaur, Kesavan, Raman, & Fisher, 2007). Furthermore, because this method does not require the person(s) evaluating the projects to directly specifyτi2, it helps overcome the empirically observed tendency of consistently overestimating the precision of one’s own value assessments (Lichtenstein & Fischhoff, 1977; Kahneman & Tversky, 1979; Soll & Klayman, 2004; Van den Steen, 2011).As an alternative for assessingτi2in the case of normal prior and likelihood, Smith and Winkler, 2006 propose that the posterior varianceρi2be estimated by asking questions such as: If you had another year and unlimited resources for additional analysis, how much might the estimate change? If the DM is asked to specify a range (e.g., 10th and 90th percentiles) for the potential change, this can be used to estimateρi2. Then, by noting thatρi2=(1-αi)σi2, the weight αiof the value estimate in (6) can be readily computed.If the prior and likelihood distributions are conjugate, the posterior distributions f(vi∣vE) for each project i can be obtained analytically (Fink, 2012). If the prior and the likelihood are not conjugate, the posterior distributions need to be approximated. This can be done, for instance, by first discretizing the distributions for Viand VEby sampling L values of vi(ℓ), ℓ=1,…,L from the prior and then, corresponding to each vi(ℓ), K vectors of vE(ℓ,k), k=1,…,K from the likelihood distribution for (VE∣Vi=vi(ℓ)). The posterior distribution that corresponds to the initial estimates vEcan then be found by setting VE=vEin the discrete joint distribution and by normalizing the resulting marginal distribution function.If the discretization is dense enough, this approach works well in problems in which the project values are independently distributed. There are many decision contexts in which this is the case. For instance, in the funding of public research projects, the value which is realized by funding a given project proposal does not usually depend on what other projects are funded. However, if there are dependencies among the projects’ values and value estimates, sampling a sufficient amount of data at every point in a dense multi-dimensional grid may require a prohibitive computational effort. Simulation and numerical integration strategies for such cases have been developed by, e.g., Müller (1999) and Gelman et al. (2004).Given the estimates vE, the posterior distributions f(vi∣vE), i=1,…,m can be used to compute the Pi-measures. This is done by sampling L vectors of values v(l),l=1,…,L from the posterior distributions, and then approximating the vector P=[P1,…,Pm] of the Pi-measures by(10)P=1L∑l=1Lz(v(l)),where z(·) is given by Eq. (1).

@&#CONCLUSIONS@&#
Our results improve project selection processes by explicitly modeling uncertainties in the estimation of project values. In particular, we have shown that the Bayesian modeling of estimation uncertainties tends to give more accurate project value estimates, resulting in a higher expected portfolio value as well as a higher expected number of optimal selections. Furthermore, we have shown that the Bayesian revision of value estimates decreases the level of expected post-decision disappointment, defined as the negative gap between the realized and estimated portfolio value.It is important to understand the logic of post-decision disappointment in practical applications. Otherwise, the average negative gap between the realized and estimated portfolio value may be interpreted as a systematic underperformance of projects, or even as the deliberate misrepresentation of their values and costs. Flyvbjerg, Skamris Holm, and Buhl (2002), for instance, study the estimated and realized costs of public transportation infrastructure projects and conclude that the statistically significant average gap between the realized and estimated project costs (ca. 28% for 258 projects, p<0.001) can be best explained by strategic misrepresentation by the project promoters, that is, lying. From the perspective of this context, our results suggest that by consistently selecting projects with the lowest cost estimates and without accounting for estimation uncertainties the DM is bound to experience post-decision disappointment. Against this backdrop, we postulate that the underestimation of project costs can, at least in part, be attributed to the underlying uncertainties and decision processes, and not only to lying or unwarranted optimism.Apart from the debiasing of value estimates, our framework is useful in many other ways as well. First, it makes it possible to compute the probability with which a project belongs to the optimal portfolio. This probability is a useful project performance measure, because it has an intuitive interpretation and accounts for constraints and possible project interdependencies. Second, the Bayesian framework can be used to explore – both analytically and computationally – how much additional value can be created at the portfolio level by eliciting improved estimates about the project’s future value; it also helps identify those projects about which additional evaluations should be acquired. Here, our results show that it often suffices to re-evaluate only a subset of the projects. Because the available time and monetary resources for project evaluation are often limited, this result is of considerable practical interest.This research opens up promising directions for future work. For instance, instead of a one-shot decision, portfolio selection can be modeled as a dynamic process in which projects are not only selected or rejected, but possibly discontinued with the aim of releasing resources for new project opportunities that offer more value. In such settings, it can be important to apply different management practices to projects with different degrees of uncertainties, because the optimal time intervals for re-evaluating projects are likely to depend on how large these uncertainties are. Moreover, the parameters of the prior and conditional distributions could be modeled not as constants (as we have done), but through probability distributions that will be revised with Bayesian approaches based on the evidence that is obtained through evaluating projects. Also the DM’s risk attitude could be explicitly accounted for when making comparisons among project portfolios whose values are inherently uncertain.