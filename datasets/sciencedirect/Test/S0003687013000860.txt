@&#MAIN-TITLE@&#
The effects of prototype medium on usability testing

@&#HIGHLIGHTS@&#
Interface medium has no effect on users' perception of usability.The impact of medium on usability issues detected varies by application tested.Usability testing can begin with low fidelity models.

@&#KEYPHRASES@&#
Usability,Perception,Human computer interaction,Prototype,Fidelity,

@&#ABSTRACT@&#
Inconsistencies among testing methods and results in previous research prompted this study that builds upon a systematic usability testing research framework to better understand how interface medium influences users' abilities to detect usability flaws in applications. Interface medium was tested to identify its effects on users' perceptions of usability and abilities to detect usability problems and severe usability problems. Results indicated that medium has no effect on users' abilities to detect usability problems or perceptions of usability. However, results did indicate an interaction between the medium and the tested application in which users were able to identify significantly more usability problems on a higher fidelity medium using a particular application. Results also indicated that as users' perceptions of an application's usability increases, the users are less able to detect usability problems in that application. Usability testing should begin early in the design process, even if low fidelity mediums will be used.

@&#INTRODUCTION@&#
The general idea of fidelity in user interfaces is agreed upon in literature as describing how different a prototype is from a finished product (Walker et al., 2002). Many researchers simply take this general definition and perform studies using fidelity as an independent variable (Catani and Biers, 1998; Sefelin et al., 2003). Even with a common general definition of fidelity, these studies have demonstrated vastly different interpretations of the definition and, therefore, have resulted in different outcomes. Sauer et al. (2010) acknowledge these inconsistencies and propose a four-factor framework of contextual fidelity which asserts that the definition of fidelity is too narrow. They expand the definition to include the fidelity of the testing environment, user characteristics, and task scenarios along with the currently accepted system prototype. Their assumption is that research results are varied because these results are not considering every important factor. Virzi et al. (1996) also address the poor definition of fidelity but believe fidelity can be broken into separate parts, and explain that fidelity is composed of multiple components or dimensions. These dimensions include breadth of features, degree of functionality, similarity of interaction, and aesthetic refinement. Breadth of features describes the number of final system functions a prototype has. Degree of functionality describes how functional each final system function is in a prototype. Similarity of interaction describes how similar a user's interaction with the prototype is to his or her interaction with the final system. Aesthetic refinement describes how similar a prototype looks compared to the final design. Table 1shows how a number of studies that have been designed to test the effects of variations in fidelity have often varied fidelity by changing different, and sometimes multiple, components within a single study.The simultaneous variation of multiple components of fidelity shown in Table 1 make it clear why the results of these studies have often been split, with some saying fidelity has no impact on usability testing and others saying just the opposite. Therefore, the appropriate method for testing the effects of fidelity is testing each of its components as separate variables rather than grouping them together under the umbrella of general fidelity. Walker et al. (2002) support this conclusion, agreeing that fidelity should be separated into components for experimentation, but they divide fidelity differently than Virzi et al. (1996) do by identifying interface medium (e.g. computer, paper, etc.) as one of the separate components. While a change in interface medium could simultaneously change multiple components of fidelity as defined by Virzi et al. (1996), Walker et al. (2002), either intentionally or by chance, avoided these impacts in their study and only affected the degree of functionality of the interface.Increasing or decreasing the fidelity of an interface medium (e.g. advancing from a paper prototype to a computer prototype) has a direct impact on an interface's overall fidelity. However, the opposite is not necessarily true. An interface's overall fidelity may be increased or decreased without actually changing the interface medium. For example, an interface can lose overall fidelity by no longer having interactive buttons but still be presented using the same medium (e.g. a computer).The research authored by Walker et al. (2002) most inspired this study. The idea behind their research is that in order to evaluate fidelity, it must first be broken down into components. In their case, the component that was studied was interface medium or degree of functionality. The challenge in studying the effects of interface mediums is keeping all fidelity components consistent (except the one being tested) across each medium. For the Walker et al. (2002) experiment, this involved keeping the breadth of features, similarity of interaction, and aesthetic refinement stable while testing the degree of functionality as an independent variable.While Walker et al. (2002) found no significant impact in the number, type, or severity of usability issues discovered by the users due to interface medium, there is a shadow cast on the results because of the small number of participants tested. And while Virzi et al. (1996) found no effect from variation in interface medium, the systems in their experimentations are somewhat outdated today, and a similar methodology applied to more modern technology could prove valuable. Furthermore, more research is needed before the usefulness of low-fidelity prototypes can be fully evaluated (Sauer et al., 2010).A review of current literature led to the following question: how do reduced fidelity interface mediums affect a user's ability to detect usability problems? With this question, four hypotheses were formed:1.Users are equally likely to detect usability problems using either computer or paper mediums to test a prototype.Users are equally likely to detect severe usability problems using either computer or paper mediums to test a prototype.Users' perceptions of applications' usability is unaffected by using either computer or paper mediums to test a prototype.The fewer usability problems a user detects, the higher the user's perception of the application's usability will be. As users' perceptions of applications' usability increases, they are less likely to detect usability problems.

@&#CONCLUSIONS@&#
This study sought to examine the effects of a prototype's medium on the user's perception and ability to detect overall usability problems and severe usability problems. The study also sought to explore the relationship between the user's perception of usability and ability to detect usability problems. The results indicated that although interface medium does not affect the user's ability to detect usability problems, interface medium does sometimes affect the user's ability to detect severe usability problems, depending on the application the user is evaluating. Results also indicated that the user's perceived usability of an application is unaffected by interface medium and that as the user's perception of an application increases, his or her ability to detect usability problems decreases. A possible way to implement these results would be to evaluate applications early with lower fidelity interface mediums and evaluate later with higher fidelity interface mediums, and to utilize user surveys and questionnaires to easily measure applications' usability.This study can naturally lead in two directions for future research. While this study did uncover an issue with an application effect, the focus was not on applications. Therefore, the first direction is one in which a large variety of applications are tested to determine which application types are sensitive to interface mediums. This route would focus on deciphering the possible cause or causes for the severe usability discrepancies between applications. The second direction would be testing one of the other Virzi et al. (1996) components of fidelity which include: breadth of features, degree of functionality, similarity of interaction, and aesthetic refinement. Of course, there are also a number of other issues surrounding public kiosk systems (e.g. glare, finger size, etc.) that were outside the scope of this study but could provide valuable results.